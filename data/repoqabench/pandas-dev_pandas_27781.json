{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "27781",
  "issue_description": "# Filtering dataframe with sparse column leads to NAs in sparse column\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas as pd\r\n\r\ndf1 = pd.DataFrame({\"A\": pd.SparseArray([0, 0, 0]), 'B': [1,2,3]})\r\n# df1_filtered will have NAs in column A\r\ndf1_filtered = df1.loc[df1['B'] != 2]\r\n\r\ndf2 = pd.DataFrame({\"A\": pd.SparseArray([0, 1, 0]), 'B': [1,2,3]})\r\n# df2_filtered has no NAs in column A\r\ndf2_filtered = df2.loc[df2['B'] != 2]\r\n```\r\nwhere `df1_filtered` will look like\r\n```\r\n\tA\tB\r\n0\tNaN\t1\r\n2\tNaN\t3\r\n```\r\nand `df2_filtered` like\r\n```\r\n\tA\tB\r\n0\t0\t1\r\n2\t0\t3\r\n```\r\n#### Problem description\r\n\r\nFiltering a dataframe with an all-zero sparse column can lead to NAs in the sparse column.\r\n\r\n#### Expected Output\r\n\r\nBoth data frames should be the same, as filtering a dataframe with non-missing data should not lead to missing data.\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\n[paste the output of ``pd.show_versions()`` here below this line]\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\n\r\npandas           : 0.25.0\r\nnumpy            : 1.16.2\r\npytz             : 2019.1\r\ndateutil         : 2.8.0\r\npip              : 19.2.1\r\nsetuptools       : 39.1.0\r\nCython           : None\r\npytest           : 4.3.1\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : 2.8.3 (dt dec pq3 ext lo64)\r\njinja2           : 2.10.1\r\nIPython          : 7.6.1\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfastparquet      : None\r\ngcsfs            : 0.2.1\r\nlxml.etree       : None\r\nmatplotlib       : 3.1.1\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : 0.13.0\r\npytables         : None\r\ns3fs             : 0.2.0\r\nscipy            : 1.2.1\r\nsqlalchemy       : 1.3.5\r\ntables           : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nxlsxwriter       : None\r\n</details>\r\n",
  "issue_comments": [
    {
      "id": 518837184,
      "user": "jorisvandenbossche",
      "body": "@stelsemeyer Thanks for the report! \r\nThis seems to be a regression compared to 0.23 (compared to SparseSeries).\r\n\r\nThis is a bug in the `SparseArray.take` implementation, when `allow_fill=True` it uses a wrong fill value (nan instead of 0):\r\n\r\n```\r\nIn [3]: df1.A.array.take([0, 2]) \r\nOut[3]: \r\n[0, 0]\r\nFill: 0\r\nBlockIndex\r\nBlock locations: array([], dtype=int32)\r\nBlock lengths: array([], dtype=int32)\r\n\r\nIn [4]: df1.A.array.take([0, 2], allow_fill=True) \r\nOut[4]: \r\n[nan, nan]\r\nFill: 0\r\nIntIndex\r\nIndices: array([0, 1], dtype=int32)\r\n```\r\n\r\n(both above should give the same result)\r\n\r\nAlways welcome to take a look to see how it could be fixed!"
    },
    {
      "id": 519133539,
      "user": "stelsemeyer",
      "body": "@jorisvandenbossche: Thanks for investigating!\r\nI checked the SparseArray, a naive solution would be to use `self.fill_value` if `fill_value` is `None` in `_take_with_fill`, here: https://github.com/pandas-dev/pandas/blob/d1accd032b648c9affd6dce1f81feb9c99422483/pandas/core/arrays/sparse.py#L1173-L1174"
    },
    {
      "id": 522671612,
      "user": "TomAugspurger",
      "body": "Removing from the 0.25.1 milestone, but if anyone is working on this LMK and we can probably get it in.\r\n\r\n@stelsemeyer your proposal looks reasonable."
    },
    {
      "id": 532022720,
      "user": "scottgigante",
      "body": "I think this is a related issue:\r\n```\r\n>>> import pandas as pd\r\n>>> X = pd.DataFrame([[0,1,0], [1,0,0], [1,1,0]]).astype(pd.SparseDtype(float, fill_value=0.0))\r\n>>> X\r\n     0    1    2\r\n0  0.0  1.0  0.0\r\n1  1.0  0.0  0.0\r\n2  1.0  1.0  0.0\r\n>>> X.loc[0]\r\n0    0.0\r\n1    1.0\r\n2    0.0\r\nName: 0, dtype: Sparse[float64, 0.0]\r\n>>> X.loc[[0,1]]\r\n     0    1   2\r\n0  0.0  1.0 NaN\r\n1  1.0  0.0 NaN\r\n>>> X.iloc[[0,1]]\r\n     0    1   2\r\n0  0.0  1.0 NaN\r\n1  1.0  0.0 NaN\r\n```"
    },
    {
      "id": 533821915,
      "user": "scottgigante",
      "body": "I edited the proposed line, but to no avail. The error in @jorisvandenbossche's answer is resolved:\r\n\r\n```\r\n>>> import pandas as pd\r\n>>> df1 = pd.DataFrame({\"A\": pd.SparseArray([0, 0, 0]), 'B': [1,2,3]})\r\n>>> df1.A.array.take([0, 2])\r\n[0, 0]\r\nFill: 0\r\nBlockIndex\r\nBlock locations: array([], dtype=int32)\r\nBlock lengths: array([], dtype=int32)\r\n>>> df1.A.array.take([0, 2], allow_fill=True)\r\n[0, 0]\r\nFill: 0\r\nIntIndex\r\nIndices: array([], dtype=int32)\r\n```\r\nbut my and @stelsemeyer's issues remain.\r\n```\r\n>>> df1.loc[df1['B'] != 2]\r\n    A  B\r\n0 NaN  1\r\n2 NaN  3\r\n>>> \r\n>>> X = pd.DataFrame([[0,1,0], [1,0,0], [1,1,0]]).astype(pd.SparseDtype(float, fill_value=0.0))\r\n>>> X.loc[[0,1]]\r\n     0    1   2\r\n0  0.0  1.0 NaN\r\n1  1.0  0.0 NaN\r\n```\r\n\r\nSeems to me that there is another problem here: \r\n\r\nhttps://github.com/pandas-dev/pandas/blob/a45760fd45b434caf9107bb19f1536636cc3fbd8/pandas/core/internals/managers.py#L1262\r\n\r\n```\r\n>>> blk = X._data.blocks[2]\r\n>>> blk.take_nd(indexer=np.array([0,1]), axis=1).values\r\n[0.0, 0.0]\r\nFill: 0.0\r\nIntIndex\r\nIndices: array([], dtype=int32)\r\n>>> blk.take_nd(indexer=np.array([0,1]), axis=1, fill_tuple=(blk.fill_value,)).values\r\n[nan, nan]\r\nFill: 0.0\r\nIntIndex\r\nIndices: array([0, 1], dtype=int32)\r\n```\r\n\r\nwhich is because of a discrepancy between `blk.fill_value` and `blk.dtype.fill_value`\r\n\r\n```\r\n>>> blk.fill_value\r\nnan\r\n>>> blk.dtype.fill_value\r\n0.0\r\n```\r\n\r\nI don't know if we should a) reference `blk.dtype.fill_value` or b) make `blk.dtype.fill_value` consistent with `blk.fill_value`."
    },
    {
      "id": 536139620,
      "user": "scottgigante",
      "body": "@TomAugspurger any thoughts on this? I'm happy to write the PR, just need some guidance."
    },
    {
      "id": 537715243,
      "user": "TomAugspurger",
      "body": "Mmm I'm not sure I understand the issue. But note that doing a `.take` which introduces missing values via a `-1` in the indices should result in a NaN in the output, regardless of the fill value. Not sure if that helps or not."
    },
    {
      "id": 538463297,
      "user": "scottgigante",
      "body": "Can you give an example of how/why that would happen? I don't understand quite how we should get a NaN when the fill_value is not nan."
    },
    {
      "id": 538486398,
      "user": "scottgigante",
      "body": "Here's my proposed solution:\r\n\r\nReplace\r\n```\r\n    @property\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        return self.values.dtype.na_value\r\n```\r\nfrom https://github.com/pandas-dev/pandas/blob/master/pandas/core/internals/blocks.py#L1730 with\r\n```\r\n    @property\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        try:\r\n            return self.values.dtype.fill_value\r\n        except AttributeError:\r\n            return self.values.dtype.na_value\r\n```\r\nThoughts?"
    },
    {
      "id": 565257697,
      "user": "akdor1154",
      "body": "Pretty sure my dataset is showing this. Seems to apply to some columns but not all.\r\n[strange_test.pickle.gz](https://github.com/pandas-dev/pandas/files/3958518/strange_test.pickle.gz)\r\n\r\nIf anyone wants a large real-world set to test this on:\r\n```python\r\nimport pandas as pd\r\ntest = pd.read_pickle('strange_test.pickle.gz')\r\nany(test.DistinctSKUs_SEPB.isna())\r\n> False\r\nany(test.loc[lambda _: _.IsBTS].DistinctSKUs_SEPB.isna())\r\n> True # !?!\r\n```"
    },
    {
      "id": 565319232,
      "user": "scottgigante",
      "body": "@akdor1154 can you try this monkey patch and see if it solves your issue?\r\n\r\n```\r\ndef fill_value(self):\r\n    # Used in reindex_indexer\r\n    try:\r\n        return self.values.dtype.fill_value\r\n    except AttributeError:\r\n        return self.values.dtype.na_value\r\n\r\nfrom pandas.core.internals.blocks import ExtensionBlock\r\n\r\nsetattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n```"
    },
    {
      "id": 616253132,
      "user": "mroeschke",
      "body": "As mentioned https://github.com/pandas-dev/pandas/issues/29321#issuecomment-551251530, it may be an issue as well when the sparse series matches the fill value"
    },
    {
      "id": 620863882,
      "user": "scottgigante",
      "body": "Pretty sure my monkey patch works. I can write a PR if I can get approval from @TomAugspurger or @jorisvandenbossche \r\n\r\n\r\n```\r\n>>> import pandas as pd\r\n>>> df1 = pd.DataFrame({\"A\": pd.arrays.SparseArray([0, 0, 0]), 'B': [1,2,3]})\r\n>>> df1.loc[df1['B'] != 2]\r\n    A  B\r\n0 NaN  1\r\n2 NaN  3\r\n>>> def fill_value(self):\r\n...     # Used in reindex_indexer\r\n...     try:\r\n...         return self.values.dtype.fill_value\r\n...     except AttributeError:\r\n...         return self.values.dtype.na_value\r\n...\r\n>>> from pandas.core.internals.blocks import ExtensionBlock\r\n>>>\r\n>>> setattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n>>> df1.loc[df1['B'] != 2]\r\n   A  B\r\n0  0  1\r\n2  0  3\r\n```\r\n\r\n```\r\n>>> import pandas as pd\r\n>>> X = pd.DataFrame([[0,1,0], [1,0,0], [1,1,0]]).astype(\r\n...     pd.SparseDtype(float, fill_value=0.0))\r\n>>> X.loc[[0,1]]\r\n     0    1   2\r\n0  0.0  1.0 NaN\r\n1  1.0  0.0 NaN\r\n>>> def fill_value(self):\r\n...     # Used in reindex_indexer\r\n...     try:\r\n...         return self.values.dtype.fill_value\r\n...     except AttributeError:\r\n...         return self.values.dtype.na_value\r\n...\r\n>>> from pandas.core.internals.blocks import ExtensionBlock\r\n>>>\r\n>>> setattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n>>> X.loc[[0,1]]\r\n     0    1    2\r\n0  0.0  1.0  0.0\r\n1  1.0  0.0  0.0\r\n```\r\n\r\n```\r\n>>> import pandas as pd\r\n>>> test = pd.read_pickle('strange_test.pickle.gz')\r\n>>> any(test.DistinctSKUs_SEPB.isna())\r\nFalse\r\n>>> any(test.loc[lambda _: _.IsBTS].DistinctSKUs_SEPB.isna())\r\nTrue\r\n>>> def fill_value(self):\r\n...     # Used in reindex_indexer\r\n...     try:\r\n...         return self.values.dtype.fill_value\r\n...     except AttributeError:\r\n...         return self.values.dtype.na_value\r\n...\r\n>>> from pandas.core.internals.blocks import ExtensionBlock\r\n>>>\r\n>>> setattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n>>> any(test.loc[lambda _: _.IsBTS].DistinctSKUs_SEPB.isna())\r\nFalse\r\n```"
    },
    {
      "id": 620989041,
      "user": "akdor1154",
      "body": "@scottgigante sorry, from memory I tested it at the time and it worked, thanks."
    },
    {
      "id": 627791292,
      "user": "connesy",
      "body": "@scottgigante Just tested your monkey patch, it works for me in `pandas 1.0.2`."
    },
    {
      "id": 658793493,
      "user": "TomAugspurger",
      "body": "The fix here is being revereted in https://github.com/pandas-dev/pandas/pull/35287. Some discussion on a potential fix at https://github.com/pandas-dev/pandas/issues/35286#issuecomment-658788801.\r\n\r\ncc @scottgigante if you want to take another shot :)"
    },
    {
      "id": 877691655,
      "user": "mroeschke",
      "body": "This looks fixed on master. Could use a test\r\n\r\n```\r\nIn [4]: df1_filtered\r\nOut[4]:\r\n   A  B\r\n0  0  1\r\n2  0  3\r\n\r\nIn [5]: df2_filtered\r\nOut[5]:\r\n   A  B\r\n0  0  1\r\n2  0  3\r\n```"
    },
    {
      "id": 1447884273,
      "user": "EnerH",
      "body": "What about this:\r\n\r\n`df1_filtered['A'] = df1_filtered['A'].fillna(0)`\r\n\r\nSimilarly, to change the NaN values in column 'A' of df2_filtered to 0, you can use the same method:\r\n\r\n`df2_filtered['A'] = df2_filtered['A'].fillna(0)` \r\n\r\n"
    },
    {
      "id": 1489098221,
      "user": "ConnorMcKinley",
      "body": "Take"
    }
  ],
  "text_context": "# Filtering dataframe with sparse column leads to NAs in sparse column\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas as pd\r\n\r\ndf1 = pd.DataFrame({\"A\": pd.SparseArray([0, 0, 0]), 'B': [1,2,3]})\r\n# df1_filtered will have NAs in column A\r\ndf1_filtered = df1.loc[df1['B'] != 2]\r\n\r\ndf2 = pd.DataFrame({\"A\": pd.SparseArray([0, 1, 0]), 'B': [1,2,3]})\r\n# df2_filtered has no NAs in column A\r\ndf2_filtered = df2.loc[df2['B'] != 2]\r\n```\r\nwhere `df1_filtered` will look like\r\n```\r\n\tA\tB\r\n0\tNaN\t1\r\n2\tNaN\t3\r\n```\r\nand `df2_filtered` like\r\n```\r\n\tA\tB\r\n0\t0\t1\r\n2\t0\t3\r\n```\r\n#### Problem description\r\n\r\nFiltering a dataframe with an all-zero sparse column can lead to NAs in the sparse column.\r\n\r\n#### Expected Output\r\n\r\nBoth data frames should be the same, as filtering a dataframe with non-missing data should not lead to missing data.\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\n[paste the output of ``pd.show_versions()`` here below this line]\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\n\r\npandas           : 0.25.0\r\nnumpy            : 1.16.2\r\npytz             : 2019.1\r\ndateutil         : 2.8.0\r\npip              : 19.2.1\r\nsetuptools       : 39.1.0\r\nCython           : None\r\npytest           : 4.3.1\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : 2.8.3 (dt dec pq3 ext lo64)\r\njinja2           : 2.10.1\r\nIPython          : 7.6.1\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfastparquet      : None\r\ngcsfs            : 0.2.1\r\nlxml.etree       : None\r\nmatplotlib       : 3.1.1\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : 0.13.0\r\npytables         : None\r\ns3fs             : 0.2.0\r\nscipy            : 1.2.1\r\nsqlalchemy       : 1.3.5\r\ntables           : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nxlsxwriter       : None\r\n</details>\r\n\n\n@stelsemeyer Thanks for the report! \r\nThis seems to be a regression compared to 0.23 (compared to SparseSeries).\r\n\r\nThis is a bug in the `SparseArray.take` implementation, when `allow_fill=True` it uses a wrong fill value (nan instead of 0):\r\n\r\n```\r\nIn [3]: df1.A.array.take([0, 2]) \r\nOut[3]: \r\n[0, 0]\r\nFill: 0\r\nBlockIndex\r\nBlock locations: array([], dtype=int32)\r\nBlock lengths: array([], dtype=int32)\r\n\r\nIn [4]: df1.A.array.take([0, 2], allow_fill=True) \r\nOut[4]: \r\n[nan, nan]\r\nFill: 0\r\nIntIndex\r\nIndices: array([0, 1], dtype=int32)\r\n```\r\n\r\n(both above should give the same result)\r\n\r\nAlways welcome to take a look to see how it could be fixed!\n\n@jorisvandenbossche: Thanks for investigating!\r\nI checked the SparseArray, a naive solution would be to use `self.fill_value` if `fill_value` is `None` in `_take_with_fill`, here: https://github.com/pandas-dev/pandas/blob/d1accd032b648c9affd6dce1f81feb9c99422483/pandas/core/arrays/sparse.py#L1173-L1174\n\nRemoving from the 0.25.1 milestone, but if anyone is working on this LMK and we can probably get it in.\r\n\r\n@stelsemeyer your proposal looks reasonable.\n\nI think this is a related issue:\r\n```\r\n>>> import pandas as pd\r\n>>> X = pd.DataFrame([[0,1,0], [1,0,0], [1,1,0]]).astype(pd.SparseDtype(float, fill_value=0.0))\r\n>>> X\r\n     0    1    2\r\n0  0.0  1.0  0.0\r\n1  1.0  0.0  0.0\r\n2  1.0  1.0  0.0\r\n>>> X.loc[0]\r\n0    0.0\r\n1    1.0\r\n2    0.0\r\nName: 0, dtype: Sparse[float64, 0.0]\r\n>>> X.loc[[0,1]]\r\n     0    1   2\r\n0  0.0  1.0 NaN\r\n1  1.0  0.0 NaN\r\n>>> X.iloc[[0,1]]\r\n     0    1   2\r\n0  0.0  1.0 NaN\r\n1  1.0  0.0 NaN\r\n```\n\nI edited the proposed line, but to no avail. The error in @jorisvandenbossche's answer is resolved:\r\n\r\n```\r\n>>> import pandas as pd\r\n>>> df1 = pd.DataFrame({\"A\": pd.SparseArray([0, 0, 0]), 'B': [1,2,3]})\r\n>>> df1.A.array.take([0, 2])\r\n[0, 0]\r\nFill: 0\r\nBlockIndex\r\nBlock locations: array([], dtype=int32)\r\nBlock lengths: array([], dtype=int32)\r\n>>> df1.A.array.take([0, 2], allow_fill=True)\r\n[0, 0]\r\nFill: 0\r\nIntIndex\r\nIndices: array([], dtype=int32)\r\n```\r\nbut my and @stelsemeyer's issues remain.\r\n```\r\n>>> df1.loc[df1['B'] != 2]\r\n    A  B\r\n0 NaN  1\r\n2 NaN  3\r\n>>> \r\n>>> X = pd.DataFrame([[0,1,0], [1,0,0], [1,1,0]]).astype(pd.SparseDtype(float, fill_value=0.0))\r\n>>> X.loc[[0,1]]\r\n     0    1   2\r\n0  0.0  1.0 NaN\r\n1  1.0  0.0 NaN\r\n```\r\n\r\nSeems to me that there is another problem here: \r\n\r\nhttps://github.com/pandas-dev/pandas/blob/a45760fd45b434caf9107bb19f1536636cc3fbd8/pandas/core/internals/managers.py#L1262\r\n\r\n```\r\n>>> blk = X._data.blocks[2]\r\n>>> blk.take_nd(indexer=np.array([0,1]), axis=1).values\r\n[0.0, 0.0]\r\nFill: 0.0\r\nIntIndex\r\nIndices: array([], dtype=int32)\r\n>>> blk.take_nd(indexer=np.array([0,1]), axis=1, fill_tuple=(blk.fill_value,)).values\r\n[nan, nan]\r\nFill: 0.0\r\nIntIndex\r\nIndices: array([0, 1], dtype=int32)\r\n```\r\n\r\nwhich is because of a discrepancy between `blk.fill_value` and `blk.dtype.fill_value`\r\n\r\n```\r\n>>> blk.fill_value\r\nnan\r\n>>> blk.dtype.fill_value\r\n0.0\r\n```\r\n\r\nI don't know if we should a) reference `blk.dtype.fill_value` or b) make `blk.dtype.fill_value` consistent with `blk.fill_value`.\n\n@TomAugspurger any thoughts on this? I'm happy to write the PR, just need some guidance.\n\nMmm I'm not sure I understand the issue. But note that doing a `.take` which introduces missing values via a `-1` in the indices should result in a NaN in the output, regardless of the fill value. Not sure if that helps or not.\n\nCan you give an example of how/why that would happen? I don't understand quite how we should get a NaN when the fill_value is not nan.\n\nHere's my proposed solution:\r\n\r\nReplace\r\n```\r\n    @property\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        return self.values.dtype.na_value\r\n```\r\nfrom https://github.com/pandas-dev/pandas/blob/master/pandas/core/internals/blocks.py#L1730 with\r\n```\r\n    @property\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        try:\r\n            return self.values.dtype.fill_value\r\n        except AttributeError:\r\n            return self.values.dtype.na_value\r\n```\r\nThoughts?\n\nPretty sure my dataset is showing this. Seems to apply to some columns but not all.\r\n[strange_test.pickle.gz](https://github.com/pandas-dev/pandas/files/3958518/strange_test.pickle.gz)\r\n\r\nIf anyone wants a large real-world set to test this on:\r\n```python\r\nimport pandas as pd\r\ntest = pd.read_pickle('strange_test.pickle.gz')\r\nany(test.DistinctSKUs_SEPB.isna())\r\n> False\r\nany(test.loc[lambda _: _.IsBTS].DistinctSKUs_SEPB.isna())\r\n> True # !?!\r\n```\n\n@akdor1154 can you try this monkey patch and see if it solves your issue?\r\n\r\n```\r\ndef fill_value(self):\r\n    # Used in reindex_indexer\r\n    try:\r\n        return self.values.dtype.fill_value\r\n    except AttributeError:\r\n        return self.values.dtype.na_value\r\n\r\nfrom pandas.core.internals.blocks import ExtensionBlock\r\n\r\nsetattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n```\n\nAs mentioned https://github.com/pandas-dev/pandas/issues/29321#issuecomment-551251530, it may be an issue as well when the sparse series matches the fill value\n\nPretty sure my monkey patch works. I can write a PR if I can get approval from @TomAugspurger or @jorisvandenbossche \r\n\r\n\r\n```\r\n>>> import pandas as pd\r\n>>> df1 = pd.DataFrame({\"A\": pd.arrays.SparseArray([0, 0, 0]), 'B': [1,2,3]})\r\n>>> df1.loc[df1['B'] != 2]\r\n    A  B\r\n0 NaN  1\r\n2 NaN  3\r\n>>> def fill_value(self):\r\n...     # Used in reindex_indexer\r\n...     try:\r\n...         return self.values.dtype.fill_value\r\n...     except AttributeError:\r\n...         return self.values.dtype.na_value\r\n...\r\n>>> from pandas.core.internals.blocks import ExtensionBlock\r\n>>>\r\n>>> setattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n>>> df1.loc[df1['B'] != 2]\r\n   A  B\r\n0  0  1\r\n2  0  3\r\n```\r\n\r\n```\r\n>>> import pandas as pd\r\n>>> X = pd.DataFrame([[0,1,0], [1,0,0], [1,1,0]]).astype(\r\n...     pd.SparseDtype(float, fill_value=0.0))\r\n>>> X.loc[[0,1]]\r\n     0    1   2\r\n0  0.0  1.0 NaN\r\n1  1.0  0.0 NaN\r\n>>> def fill_value(self):\r\n...     # Used in reindex_indexer\r\n...     try:\r\n...         return self.values.dtype.fill_value\r\n...     except AttributeError:\r\n...         return self.values.dtype.na_value\r\n...\r\n>>> from pandas.core.internals.blocks import ExtensionBlock\r\n>>>\r\n>>> setattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n>>> X.loc[[0,1]]\r\n     0    1    2\r\n0  0.0  1.0  0.0\r\n1  1.0  0.0  0.0\r\n```\r\n\r\n```\r\n>>> import pandas as pd\r\n>>> test = pd.read_pickle('strange_test.pickle.gz')\r\n>>> any(test.DistinctSKUs_SEPB.isna())\r\nFalse\r\n>>> any(test.loc[lambda _: _.IsBTS].DistinctSKUs_SEPB.isna())\r\nTrue\r\n>>> def fill_value(self):\r\n...     # Used in reindex_indexer\r\n...     try:\r\n...         return self.values.dtype.fill_value\r\n...     except AttributeError:\r\n...         return self.values.dtype.na_value\r\n...\r\n>>> from pandas.core.internals.blocks import ExtensionBlock\r\n>>>\r\n>>> setattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n>>> any(test.loc[lambda _: _.IsBTS].DistinctSKUs_SEPB.isna())\r\nFalse\r\n```\n\n@scottgigante sorry, from memory I tested it at the time and it worked, thanks.\n\n@scottgigante Just tested your monkey patch, it works for me in `pandas 1.0.2`.\n\nThe fix here is being revereted in https://github.com/pandas-dev/pandas/pull/35287. Some discussion on a potential fix at https://github.com/pandas-dev/pandas/issues/35286#issuecomment-658788801.\r\n\r\ncc @scottgigante if you want to take another shot :)\n\nThis looks fixed on master. Could use a test\r\n\r\n```\r\nIn [4]: df1_filtered\r\nOut[4]:\r\n   A  B\r\n0  0  1\r\n2  0  3\r\n\r\nIn [5]: df2_filtered\r\nOut[5]:\r\n   A  B\r\n0  0  1\r\n2  0  3\r\n```\n\nWhat about this:\r\n\r\n`df1_filtered['A'] = df1_filtered['A'].fillna(0)`\r\n\r\nSimilarly, to change the NaN values in column 'A' of df2_filtered to 0, you can use the same method:\r\n\r\n`df2_filtered['A'] = df2_filtered['A'].fillna(0)` \r\n\r\n\n\nTake",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/52772",
  "code_context": [
    {
      "filename": "pandas/tests/arrays/sparse/test_array.py",
      "content": "import re\n\nimport numpy as np\nimport pytest\n\nfrom pandas._libs.sparse import IntIndex\n\nimport pandas as pd\nfrom pandas import isna\nimport pandas._testing as tm\nfrom pandas.core.arrays.sparse import (\n    SparseArray,\n    SparseDtype,\n)\n\n\n@pytest.fixture\ndef arr_data():\n    \"\"\"Fixture returning numpy array with valid and missing entries\"\"\"\n    return np.array([np.nan, np.nan, 1, 2, 3, np.nan, 4, 5, np.nan, 6])\n\n\n@pytest.fixture\ndef arr(arr_data):\n    \"\"\"Fixture returning SparseArray from 'arr_data'\"\"\"\n    return SparseArray(arr_data)\n\n\n@pytest.fixture\ndef zarr():\n    \"\"\"Fixture returning SparseArray with integer entries and 'fill_value=0'\"\"\"\n    return SparseArray([0, 0, 1, 2, 3, 0, 4, 5, 0, 6], fill_value=0)\n\n\nclass TestSparseArray:\n    @pytest.mark.parametrize(\"fill_value\", [0, None, np.nan])\n    def test_shift_fill_value(self, fill_value):\n        # GH #24128\n        sparse = SparseArray(np.array([1, 0, 0, 3, 0]), fill_value=8.0)\n        res = sparse.shift(1, fill_value=fill_value)\n        if isna(fill_value):\n            fill_value = res.dtype.na_value\n        exp = SparseArray(np.array([fill_value, 1, 0, 0, 3]), fill_value=8.0)\n        tm.assert_sp_array_equal(res, exp)\n\n    def test_set_fill_value(self):\n        arr = SparseArray([1.0, np.nan, 2.0], fill_value=np.nan)\n        arr.fill_value = 2\n        assert arr.fill_value == 2\n\n        arr = SparseArray([1, 0, 2], fill_value=0, dtype=np.int64)\n        arr.fill_value = 2\n        assert arr.fill_value == 2\n\n        # TODO: this seems fine? You can construct an integer\n        # sparsearray with NaN fill value, why not update one?\n        # coerces to int\n        # msg = \"unable to set fill_value 3\\\\.1 to int64 dtype\"\n        # with pytest.raises(ValueError, match=msg):\n        arr.fill_value = 3.1\n        assert arr.fill_value == 3.1\n\n        # msg = \"unable to set fill_value nan to int64 dtype\"\n        # with pytest.raises(ValueError, match=msg):\n        arr.fill_value = np.nan\n        assert np.isnan(arr.fill_value)\n\n        arr = SparseArray([True, False, True], fill_value=False, dtype=np.bool_)\n        arr.fill_value = True\n        assert arr.fill_value\n\n        # FIXME: don't leave commented-out\n        # coerces to bool\n        # TODO: we can construct an sparse array of bool\n        #      type and use as fill_value any value\n        # msg = \"fill_value must be True, False or nan\"\n        # with pytest.raises(ValueError, match=msg):\n        #    arr.fill_value = 0\n\n        # msg = \"unable to set fill_value nan to bool dtype\"\n        # with pytest.raises(ValueError, match=msg):\n        arr.fill_value = np.nan\n        assert np.isnan(arr.fill_value)\n\n    @pytest.mark.parametrize(\"val\", [[1, 2, 3], np.array([1, 2]), (1, 2, 3)])\n    def test_set_fill_invalid_non_scalar(self, val):\n        arr = SparseArray([True, False, True], fill_value=False, dtype=np.bool_)\n        msg = \"fill_value must be a scalar\"\n\n        with pytest.raises(ValueError, match=msg):\n            arr.fill_value = val\n\n    def test_copy(self, arr):\n        arr2 = arr.copy()\n        assert arr2.sp_values is not arr.sp_values\n        assert arr2.sp_index is arr.sp_index\n\n    def test_values_asarray(self, arr_data, arr):\n        tm.assert_almost_equal(arr.to_dense(), arr_data)\n\n    @pytest.mark.parametrize(\n        \"data,shape,dtype\",\n        [\n            ([0, 0, 0, 0, 0], (5,), None),\n            ([], (0,), None),\n            ([0], (1,), None),\n            ([\"A\", \"A\", np.nan, \"B\"], (4,), object),\n        ],\n    )\n    def test_shape(self, data, shape, dtype):\n        # GH 21126\n        out = SparseArray(data, dtype=dtype)\n        assert out.shape == shape\n\n    @pytest.mark.parametrize(\n        \"vals\",\n        [\n            [np.nan, np.nan, np.nan, np.nan, np.nan],\n            [1, np.nan, np.nan, 3, np.nan],\n            [1, np.nan, 0, 3, 0],\n        ],\n    )\n    @pytest.mark.parametrize(\"fill_value\", [None, 0])\n    def test_dense_repr(self, vals, fill_value):\n        vals = np.array(vals)\n        arr = SparseArray(vals, fill_value=fill_value)\n\n        res = arr.to_dense()\n        tm.assert_numpy_array_equal(res, vals)\n\n    @pytest.mark.parametrize(\"fix\", [\"arr\", \"zarr\"])\n    def test_pickle(self, fix, request):\n        obj = request.getfixturevalue(fix)\n        unpickled = tm.round_trip_pickle(obj)\n        tm.assert_sp_array_equal(unpickled, obj)\n\n    def test_generator_warnings(self):\n        sp_arr = SparseArray([1, 2, 3])\n        with tm.assert_produces_warning(None):\n            for _ in sp_arr:\n                pass\n\n    def test_where_retain_fill_value(self):\n        # GH#45691 don't lose fill_value on _where\n        arr = SparseArray([np.nan, 1.0], fill_value=0)\n\n        mask = np.array([True, False])\n\n        res = arr._where(~mask, 1)\n        exp = SparseArray([1, 1.0], fill_value=0)\n        tm.assert_sp_array_equal(res, exp)\n\n        ser = pd.Series(arr)\n        res = ser.where(~mask, 1)\n        tm.assert_series_equal(res, pd.Series(exp))\n\n    def test_fillna(self):\n        s = SparseArray([1, np.nan, np.nan, 3, np.nan])\n        res = s.fillna(-1)\n        exp = SparseArray([1, -1, -1, 3, -1], fill_value=-1, dtype=np.float64)\n        tm.assert_sp_array_equal(res, exp)\n\n        s = SparseArray([1, np.nan, np.nan, 3, np.nan], fill_value=0)\n        res = s.fillna(-1)\n        exp = SparseArray([1, -1, -1, 3, -1], fill_value=0, dtype=np.float64)\n        tm.assert_sp_array_equal(res, exp)\n\n        s = SparseArray([1, np.nan, 0, 3, 0])\n        res = s.fillna(-1)\n        exp = SparseArray([1, -1, 0, 3, 0], fill_value=-1, dtype=np.float64)\n        tm.assert_sp_array_equal(res, exp)\n\n        s = SparseArray([1, np.nan, 0, 3, 0], fill_value=0)\n        res = s.fillna(-1)\n        exp = SparseArray([1, -1, 0, 3, 0], fill_value=0, dtype=np.float64)\n        tm.assert_sp_array_equal(res, exp)\n\n        s = SparseArray([np.nan, np.nan, np.nan, np.nan])\n        res = s.fillna(-1)\n        exp = SparseArray([-1, -1, -1, -1], fill_value=-1, dtype=np.float64)\n        tm.assert_sp_array_equal(res, exp)\n\n        s = SparseArray([np.nan, np.nan, np.nan, np.nan], fill_value=0)\n        res = s.fillna(-1)\n        exp = SparseArray([-1, -1, -1, -1], fill_value=0, dtype=np.float64)\n        tm.assert_sp_array_equal(res, exp)\n\n        # float dtype's fill_value is np.nan, replaced by -1\n        s = SparseArray([0.0, 0.0, 0.0, 0.0])\n        res = s.fillna(-1)\n        exp = SparseArray([0.0, 0.0, 0.0, 0.0], fill_value=-1)\n        tm.assert_sp_array_equal(res, exp)\n\n        # int dtype shouldn't have missing. No changes.\n        s = SparseArray([0, 0, 0, 0])\n        assert s.dtype == SparseDtype(np.int64)\n        assert s.fill_value == 0\n        res = s.fillna(-1)\n        tm.assert_sp_array_equal(res, s)\n\n        s = SparseArray([0, 0, 0, 0], fill_value=0)\n        assert s.dtype == SparseDtype(np.int64)\n        assert s.fill_value == 0\n        res = s.fillna(-1)\n        exp = SparseArray([0, 0, 0, 0], fill_value=0)\n        tm.assert_sp_array_equal(res, exp)\n\n        # fill_value can be nan if there is no missing hole.\n        # only fill_value will be changed\n        s = SparseArray([0, 0, 0, 0], fill_value=np.nan)\n        assert s.dtype == SparseDtype(np.int64, fill_value=np.nan)\n        assert np.isnan(s.fill_value)\n        res = s.fillna(-1)\n        exp = SparseArray([0, 0, 0, 0], fill_value=-1)\n        tm.assert_sp_array_equal(res, exp)\n\n    def test_fillna_overlap(self):\n        s = SparseArray([1, np.nan, np.nan, 3, np.nan])\n        # filling with existing value doesn't replace existing value with\n        # fill_value, i.e. existing 3 remains in sp_values\n        res = s.fillna(3)\n        exp = np.array([1, 3, 3, 3, 3], dtype=np.float64)\n        tm.assert_numpy_array_equal(res.to_dense(), exp)\n\n        s = SparseArray([1, np.nan, np.nan, 3, np.nan], fill_value=0)\n        res = s.fillna(3)\n        exp = SparseArray([1, 3, 3, 3, 3], fill_value=0, dtype=np.float64)\n        tm.assert_sp_array_equal(res, exp)\n\n    def test_nonzero(self):\n        # Tests regression #21172.\n        sa = SparseArray([float(\"nan\"), float(\"nan\"), 1, 0, 0, 2, 0, 0, 0, 3, 0, 0])\n        expected = np.array([2, 5, 9], dtype=np.int32)\n        (result,) = sa.nonzero()\n        tm.assert_numpy_array_equal(expected, result)\n\n        sa = SparseArray([0, 0, 1, 0, 0, 2, 0, 0, 0, 3, 0, 0])\n        (result,) = sa.nonzero()\n        tm.assert_numpy_array_equal(expected, result)\n\n\nclass TestSparseArrayAnalytics:\n    @pytest.mark.parametrize(\n        \"data,expected\",\n        [\n            (\n                np.array([1, 2, 3, 4, 5], dtype=float),  # non-null data\n                SparseArray(np.array([1.0, 3.0, 6.0, 10.0, 15.0])),\n            ),\n            (\n                np.array([1, 2, np.nan, 4, 5], dtype=float),  # null data\n                SparseArray(np.array([1.0, 3.0, np.nan, 7.0, 12.0])),\n            ),\n        ],\n    )\n    @pytest.mark.parametrize(\"numpy\", [True, False])\n    def test_cumsum(self, data, expected, numpy):\n        cumsum = np.cumsum if numpy else lambda s: s.cumsum()\n\n        out = cumsum(SparseArray(data))\n        tm.assert_sp_array_equal(out, expected)\n\n        out = cumsum(SparseArray(data, fill_value=np.nan))\n        tm.assert_sp_array_equal(out, expected)\n\n        out = cumsum(SparseArray(data, fill_value=2))\n        tm.assert_sp_array_equal(out, expected)\n\n        if numpy:  # numpy compatibility checks.\n            msg = \"the 'dtype' parameter is not supported\"\n            with pytest.raises(ValueError, match=msg):\n                np.cumsum(SparseArray(data), dtype=np.int64)\n\n            msg = \"the 'out' parameter is not supported\"\n            with pytest.raises(ValueError, match=msg):\n                np.cumsum(SparseArray(data), out=out)\n        else:\n            axis = 1  # SparseArray currently 1-D, so only axis = 0 is valid.\n            msg = re.escape(f\"axis(={axis}) out of bounds\")\n            with pytest.raises(ValueError, match=msg):\n                SparseArray(data).cumsum(axis=axis)\n\n    def test_ufunc(self):\n        # GH 13853 make sure ufunc is applied to fill_value\n        sparse = SparseArray([1, np.nan, 2, np.nan, -2])\n        result = SparseArray([1, np.nan, 2, np.nan, 2])\n        tm.assert_sp_array_equal(abs(sparse), result)\n        tm.assert_sp_array_equal(np.abs(sparse), result)\n\n        sparse = SparseArray([1, -1, 2, -2], fill_value=1)\n        result = SparseArray([1, 2, 2], sparse_index=sparse.sp_index, fill_value=1)\n        tm.assert_sp_array_equal(abs(sparse), result)\n        tm.assert_sp_array_equal(np.abs(sparse), result)\n\n        sparse = SparseArray([1, -1, 2, -2], fill_value=-1)\n        exp = SparseArray([1, 1, 2, 2], fill_value=1)\n        tm.assert_sp_array_equal(abs(sparse), exp)\n        tm.assert_sp_array_equal(np.abs(sparse), exp)\n\n        sparse = SparseArray([1, np.nan, 2, np.nan, -2])\n        result = SparseArray(np.sin([1, np.nan, 2, np.nan, -2]))\n        tm.assert_sp_array_equal(np.sin(sparse), result)\n\n        sparse = SparseArray([1, -1, 2, -2], fill_value=1)\n        result = SparseArray(np.sin([1, -1, 2, -2]), fill_value=np.sin(1))\n        tm.assert_sp_array_equal(np.sin(sparse), result)\n\n        sparse = SparseArray([1, -1, 0, -2], fill_value=0)\n        result = SparseArray(np.sin([1, -1, 0, -2]), fill_value=np.sin(0))\n        tm.assert_sp_array_equal(np.sin(sparse), result)\n\n    def test_ufunc_args(self):\n        # GH 13853 make sure ufunc is applied to fill_value, including its arg\n        sparse = SparseArray([1, np.nan, 2, np.nan, -2])\n        result = SparseArray([2, np.nan, 3, np.nan, -1])\n        tm.assert_sp_array_equal(np.add(sparse, 1), result)\n\n        sparse = SparseArray([1, -1, 2, -2], fill_value=1)\n        result = SparseArray([2, 0, 3, -1], fill_value=2)\n        tm.assert_sp_array_equal(np.add(sparse, 1), result)\n\n        sparse = SparseArray([1, -1, 0, -2], fill_value=0)\n        result = SparseArray([2, 0, 1, -1], fill_value=1)\n        tm.assert_sp_array_equal(np.add(sparse, 1), result)\n\n    @pytest.mark.parametrize(\"fill_value\", [0.0, np.nan])\n    def test_modf(self, fill_value):\n        # https://github.com/pandas-dev/pandas/issues/26946\n        sparse = SparseArray([fill_value] * 10 + [1.1, 2.2], fill_value=fill_value)\n        r1, r2 = np.modf(sparse)\n        e1, e2 = np.modf(np.asarray(sparse))\n        tm.assert_sp_array_equal(r1, SparseArray(e1, fill_value=fill_value))\n        tm.assert_sp_array_equal(r2, SparseArray(e2, fill_value=fill_value))\n\n    def test_nbytes_integer(self):\n        arr = SparseArray([1, 0, 0, 0, 2], kind=\"integer\")\n        result = arr.nbytes\n        # (2 * 8) + 2 * 4\n        assert result == 24\n\n    def test_nbytes_block(self):\n        arr = SparseArray([1, 2, 0, 0, 0], kind=\"block\")\n        result = arr.nbytes\n        # (2 * 8) + 4 + 4\n        # sp_values, blocs, blengths\n        assert result == 24\n\n    def test_asarray_datetime64(self):\n        s = SparseArray(pd.to_datetime([\"2012\", None, None, \"2013\"]))\n        np.asarray(s)\n\n    def test_density(self):\n        arr = SparseArray([0, 1])\n        assert arr.density == 0.5\n\n    def test_npoints(self):\n        arr = SparseArray([0, 1])\n        assert arr.npoints == 1\n\n\ndef test_setting_fill_value_fillna_still_works():\n    # This is why letting users update fill_value / dtype is bad\n    # astype has the same problem.\n    arr = SparseArray([1.0, np.nan, 1.0], fill_value=0.0)\n    arr.fill_value = np.nan\n    result = arr.isna()\n    # Can't do direct comparison, since the sp_index will be different\n    # So let's convert to ndarray and check there.\n    result = np.asarray(result)\n\n    expected = np.array([False, True, False])\n    tm.assert_numpy_array_equal(result, expected)\n\n\ndef test_setting_fill_value_updates():\n    arr = SparseArray([0.0, np.nan], fill_value=0)\n    arr.fill_value = np.nan\n    # use private constructor to get the index right\n    # otherwise both nans would be un-stored.\n    expected = SparseArray._simple_new(\n        sparse_array=np.array([np.nan]),\n        sparse_index=IntIndex(2, [1]),\n        dtype=SparseDtype(float, np.nan),\n    )\n    tm.assert_sp_array_equal(arr, expected)\n\n\n@pytest.mark.parametrize(\n    \"arr,fill_value,loc\",\n    [\n        ([None, 1, 2], None, 0),\n        ([0, None, 2], None, 1),\n        ([0, 1, None], None, 2),\n        ([0, 1, 1, None, None], None, 3),\n        ([1, 1, 1, 2], None, -1),\n        ([], None, -1),\n        ([None, 1, 0, 0, None, 2], None, 0),\n        ([None, 1, 0, 0, None, 2], 1, 1),\n        ([None, 1, 0, 0, None, 2], 2, 5),\n        ([None, 1, 0, 0, None, 2], 3, -1),\n        ([None, 0, 0, 1, 2, 1], 0, 1),\n        ([None, 0, 0, 1, 2, 1], 1, 3),\n    ],\n)\ndef test_first_fill_value_loc(arr, fill_value, loc):\n    result = SparseArray(arr, fill_value=fill_value)._first_fill_value_loc()\n    assert result == loc\n\n\n@pytest.mark.parametrize(\n    \"arr\",\n    [\n        [1, 2, np.nan, np.nan],\n        [1, np.nan, 2, np.nan],\n        [1, 2, np.nan],\n        [np.nan, 1, 0, 0, np.nan, 2],\n        [np.nan, 0, 0, 1, 2, 1],\n    ],\n)\n@pytest.mark.parametrize(\"fill_value\", [np.nan, 0, 1])\ndef test_unique_na_fill(arr, fill_value):\n    a = SparseArray(arr, fill_value=fill_value).unique()\n    b = pd.Series(arr).unique()\n    assert isinstance(a, SparseArray)\n    a = np.asarray(a)\n    tm.assert_numpy_array_equal(a, b)\n\n\ndef test_unique_all_sparse():\n    # https://github.com/pandas-dev/pandas/issues/23168\n    arr = SparseArray([0, 0])\n    result = arr.unique()\n    expected = SparseArray([0])\n    tm.assert_sp_array_equal(result, expected)\n\n\ndef test_map():\n    arr = SparseArray([0, 1, 2])\n    expected = SparseArray([10, 11, 12], fill_value=10)\n\n    # dict\n    result = arr.map({0: 10, 1: 11, 2: 12})\n    tm.assert_sp_array_equal(result, expected)\n\n    # series\n    result = arr.map(pd.Series({0: 10, 1: 11, 2: 12}))\n    tm.assert_sp_array_equal(result, expected)\n\n    # function\n    result = arr.map(pd.Series({0: 10, 1: 11, 2: 12}))\n    expected = SparseArray([10, 11, 12], fill_value=10)\n    tm.assert_sp_array_equal(result, expected)\n\n\ndef test_map_missing():\n    arr = SparseArray([0, 1, 2])\n    expected = SparseArray([10, 11, None], fill_value=10)\n\n    result = arr.map({0: 10, 1: 11})\n    tm.assert_sp_array_equal(result, expected)\n\n\n@pytest.mark.parametrize(\"fill_value\", [np.nan, 1])\ndef test_dropna(fill_value):\n    # GH-28287\n    arr = SparseArray([np.nan, 1], fill_value=fill_value)\n    exp = SparseArray([1.0], fill_value=fill_value)\n    tm.assert_sp_array_equal(arr.dropna(), exp)\n\n    df = pd.DataFrame({\"a\": [0, 1], \"b\": arr})\n    expected_df = pd.DataFrame({\"a\": [1], \"b\": exp}, index=pd.Index([1]))\n    tm.assert_equal(df.dropna(), expected_df)\n\n\ndef test_drop_duplicates_fill_value():\n    # GH 11726\n    df = pd.DataFrame(np.zeros((5, 5))).apply(lambda x: SparseArray(x, fill_value=0))\n    result = df.drop_duplicates()\n    expected = pd.DataFrame({i: SparseArray([0.0], fill_value=0) for i in range(5)})\n    tm.assert_frame_equal(result, expected)\n\n\ndef test_zero_sparse_column():\n    # GH 27781\n    df1 = pd.DataFrame({\"A\": SparseArray([0, 0, 0]), \"B\": [1, 2, 3]})\n    df2 = pd.DataFrame({\"A\": SparseArray([0, 1, 0]), \"B\": [1, 2, 3]})\n    result = df1.loc[df1[\"B\"] != 2]\n    expected = df2.loc[df2[\"B\"] != 2]\n    tm.assert_frame_equal(result, expected)\n\n    expected = pd.DataFrame({\"A\": SparseArray([0, 0]), \"B\": [1, 3]}, index=[0, 2])\n    tm.assert_frame_equal(result, expected)\n"
    }
  ],
  "questions": [
    "Can you give an example of how/why that would happen? I don't understand quite how we should get a NaN when the fill_value is not nan.",
    "Here's my proposed solution:\r\n\r\nReplace\r\n```\r\n    @property\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        return self.values.dtype.na_value\r\n```\r\nfrom https://github.com/pandas-dev/pandas/blob/master/pandas/core/internals/blocks.py#L1730 with\r\n```\r\n    @property\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        try:\r\n            return self.values.dtype.fill_value\r\n        except AttributeError:\r\n            return self.values.dtype.na_value\r\n```\r\nThoughts?",
    "Pretty sure my dataset is showing this. Seems to apply to some columns but not all.\r\n[strange_test.pickle.gz](https://github.com/pandas-dev/pandas/files/3958518/strange_test.pickle.gz)\r\n\r\nIf anyone wants a large real-world set to test this on:\r\n```python\r\nimport pandas as pd\r\ntest = pd.read_pickle('strange_test.pickle.gz')\r\nany(test.DistinctSKUs_SEPB.isna())\r\n> False\r\nany(test.loc[lambda _: _.IsBTS].DistinctSKUs_SEPB.isna())\r\n> True # !?!\r\n```",
    "@akdor1154 can you try this monkey patch and see if it solves your issue?\r\n\r\n```\r\ndef fill_value(self):\r\n    # Used in reindex_indexer\r\n    try:\r\n        return self.values.dtype.fill_value\r\n    except AttributeError:\r\n        return self.values.dtype.na_value\r\n\r\nfrom pandas.core.internals.blocks import ExtensionBlock\r\n\r\nsetattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n```"
  ],
  "golden_answers": [
    "Here's my proposed solution:\r\n\r\nReplace\r\n```\r\n    @property\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        return self.values.dtype.na_value\r\n```\r\nfrom https://github.com/pandas-dev/pandas/blob/master/pandas/core/internals/blocks.py#L1730 with\r\n```\r\n    @property\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        try:\r\n            return self.values.dtype.fill_value\r\n        except AttributeError:\r\n            return self.values.dtype.na_value\r\n```\r\nThoughts?",
    "Pretty sure my dataset is showing this. Seems to apply to some columns but not all.\r\n[strange_test.pickle.gz](https://github.com/pandas-dev/pandas/files/3958518/strange_test.pickle.gz)\r\n\r\nIf anyone wants a large real-world set to test this on:\r\n```python\r\nimport pandas as pd\r\ntest = pd.read_pickle('strange_test.pickle.gz')\r\nany(test.DistinctSKUs_SEPB.isna())\r\n> False\r\nany(test.loc[lambda _: _.IsBTS].DistinctSKUs_SEPB.isna())\r\n> True # !?!\r\n```",
    "@akdor1154 can you try this monkey patch and see if it solves your issue?\r\n\r\n```\r\ndef fill_value(self):\r\n    # Used in reindex_indexer\r\n    try:\r\n        return self.values.dtype.fill_value\r\n    except AttributeError:\r\n        return self.values.dtype.na_value\r\n\r\nfrom pandas.core.internals.blocks import ExtensionBlock\r\n\r\nsetattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n```",
    "Pretty sure my monkey patch works. I can write a PR if I can get approval from @TomAugspurger or @jorisvandenbossche \r\n\r\n\r\n```\r\n>>> import pandas as pd\r\n>>> df1 = pd.DataFrame({\"A\": pd.arrays.SparseArray([0, 0, 0]), 'B': [1,2,3]})\r\n>>> df1.loc[df1['B'] != 2]\r\n    A  B\r\n0 NaN  1\r\n2 NaN  3\r\n>>> def fill_value(self):\r\n...     # Used in reindex_indexer\r\n...     try:\r\n...         return self.values.dtype.fill_value\r\n...     except AttributeError:\r\n...         return self.values.dtype.na_value\r\n...\r\n>>> from pandas.core.internals.blocks import ExtensionBlock\r\n>>>\r\n>>> setattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n>>> df1.loc[df1['B'] != 2]\r\n   A  B\r\n0  0  1\r\n2  0  3\r\n```\r\n\r\n```\r\n>>> import pandas as pd\r\n>>> X = pd.DataFrame([[0,1,0], [1,0,0], [1,1,0]]).astype(\r\n...     pd.SparseDtype(float, fill_value=0.0))\r\n>>> X.loc[[0,1]]\r\n     0    1   2\r\n0  0.0  1.0 NaN\r\n1  1.0  0.0 NaN\r\n>>> def fill_value(self):\r\n...     # Used in reindex_indexer\r\n...     try:\r\n...         return self.values.dtype.fill_value\r\n...     except AttributeError:\r\n...         return self.values.dtype.na_value\r\n...\r\n>>> from pandas.core.internals.blocks import ExtensionBlock\r\n>>>\r\n>>> setattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n>>> X.loc[[0,1]]\r\n     0    1    2\r\n0  0.0  1.0  0.0\r\n1  1.0  0.0  0.0\r\n```\r\n\r\n```\r\n>>> import pandas as pd\r\n>>> test = pd.read_pickle('strange_test.pickle.gz')\r\n>>> any(test.DistinctSKUs_SEPB.isna())\r\nFalse\r\n>>> any(test.loc[lambda _: _.IsBTS].DistinctSKUs_SEPB.isna())\r\nTrue\r\n>>> def fill_value(self):\r\n...     # Used in reindex_indexer\r\n...     try:\r\n...         return self.values.dtype.fill_value\r\n...     except AttributeError:\r\n...         return self.values.dtype.na_value\r\n...\r\n>>> from pandas.core.internals.blocks import ExtensionBlock\r\n>>>\r\n>>> setattr(ExtensionBlock, \"fill_value\", property(fill_value))\r\n>>> any(test.loc[lambda _: _.IsBTS].DistinctSKUs_SEPB.isna())\r\nFalse\r\n```"
  ],
  "questions_generated": [
    "What is the root cause of the issue where filtering a DataFrame with a sparse column results in NaNs appearing in the sparse column?",
    "How does the `SparseArray.take` method behave differently when `allow_fill` is set to True versus False?",
    "In the context of the issue described, how would you modify the `SparseArray.take` method to use the correct fill value?",
    "What does the output of `df1.A.array.take([0, 2])` indicate about the state of the sparse array before the bug manifests?",
    "Why does the issue not manifest when filtering `df2`, which has a non-zero value in the sparse column?"
  ],
  "golden_answers_generated": [
    "The root cause of the issue is a bug in the `SparseArray.take` method implementation within the pandas library. When `allow_fill=True`, the method uses an incorrect fill value (NaN instead of the expected zero) during the take operation, which results in NaNs appearing in the sparse column after filtering.",
    "When `allow_fill=False`, the `SparseArray.take` method returns values based on the provided indices without altering the underlying data, using the sparse array's fill value. However, when `allow_fill=True`, the method is supposed to fill positions specified by negative indices with a fill value, but due to the bug, it incorrectly uses NaN instead of the array's defined fill value.",
    "To correct the behavior of the `SparseArray.take` method when `allow_fill=True`, the method should be modified to use `self.fill_value` instead of NaN when the `fill_value` parameter is `None`. This change should be made in the `_take_with_fill` function to ensure that the fill value aligns with the sparse array's intended fill value.",
    "The output of `df1.A.array.take([0, 2])` shows the sparse array `[0, 0]` with a fill value of `0` and an empty block index, indicating that the array correctly maintains its sparse structure with zero values at the specified indices. This output is consistent with expected behavior, as no NaNs appear, demonstrating the correct handling of indices when `allow_fill` is not involved.",
    "The issue does not manifest in `df2` because the sparse column contains a non-zero value. The presence of non-zero values means that the sparse array does not rely solely on the fill value to infer missing data. As a result, when filtering, the non-zero values are retained properly, and the take operation does not default to using the incorrect NaN fill value."
  ]
}