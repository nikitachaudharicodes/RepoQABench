{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "50207",
  "issue_description": "# CI check each minimum dependency is enforced in *.yaml and environment.yml files\n\nxref https://github.com/pandas-dev/pandas/pull/50205#discussion_r1046097646\r\n\r\nIf any dependency has a minimum version specified in \r\n\r\nhttps://github.com/pandas-dev/pandas/blob/16b9c98bfedcfae031df5d570ef68a2d126826b7/pyproject.toml#L57-L119\r\n\r\nthen if that dependency appears in `environment.yml` or any of the `*.yaml` files, then it should either be pinned to that minimum version, or be marked as `>=` that minimum version\r\n\r\nLet's add a script to automate checking this!\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/main/scripts/validate_min_versions_in_sync.py is kind of related\r\n\r\n---\r\n\r\nFeel free to tag me for review if you take this on",
  "issue_comments": [
    {
      "id": 1347199558,
      "user": "mroeschke",
      "body": "Notes:\r\n\r\n1. `ci/deps/actions-*-minimum_versions.yaml` should be pinned as `=` instead of `>=`\r\n2. IMO `validate_min_versions_in_sync.py` should be updated to ensure the dependency files are also in sync\r\n\r\nPersonally not sure if this is a good first issue as there are a lot of moving parts but happy to be wrong"
    },
    {
      "id": 1347312158,
      "user": "seanjedi",
      "body": "Hmm, I believe I understand the ask. \r\nSo essentially get all the dependencies from pyproject.toml optional-dependencies, and compare them against the dependencies within environment.yml, and if there are any dependencies that are newer within pyproject.toml tan environment.yaml, then update environment.yaml to either `=` or `>=` correct?\r\nSo if that is the case, then:\r\n1) how do we determine when we want to have it `=` or `>=`? Would that be depdendent on how pyproject.toml has it?\r\n2) what if environment.yml somehow has a newer depdency, then should be ignore it, or should we downgrade it to the version that pyproject has it at?\r\n\r\nAlso can I take this? "
    },
    {
      "id": 1347313780,
      "user": "MarcoGorelli",
      "body": "I'd say:\r\n1. if it already has `=` then keep as-is, else, add `>=`\r\n2. not sure I understand the question, can you show an example?\r\n\r\nAnd yes, sure!"
    },
    {
      "id": 1347330248,
      "user": "seanjedi",
      "body": "For 2 let's say hypothetically we have a situation where\r\nIn environment.yml we have:\r\n```\r\n- numba=0.53.1\r\n```\r\nand in pyproject we have:\r\n```\r\nnumba>=0.52\r\n```\r\n\r\nShould I check if the dependencies in pyproject are indeed greater than the ones in environment, or if they differ then set the dependencies to pyproject\r\nThis might be all moot, but I wanted to doublecheck since in my head the way I was thinking of comparing the two is if pyproject has a dependency greater than environment, then update environment, otherwise stay the same, or do we want the two be equal? \r\nI think the case we have, is that we want it to be equal, so above even though environment has a great version, we should have it pinned to be `numba>=0.52`"
    },
    {
      "id": 1347330456,
      "user": "seanjedi",
      "body": "take"
    },
    {
      "id": 1347335650,
      "user": "MarcoGorelli",
      "body": "If there's already a pin, then as long as the version is greater than the minimum version, you can leave it as it is\r\n\r\nIf there's no pin, then just put `>=` and the minimum version"
    },
    {
      "id": 1347371070,
      "user": "seanjedi",
      "body": "So should I create a new file for this, or extend [validate_min_versions_in_sync.py](https://github.com/pandas-dev/pandas/blob/main/scripts/validate_min_versions_in_sync.py) to be able to update these dependencies as well? "
    },
    {
      "id": 1347372695,
      "user": "MarcoGorelli",
      "body": "it's probably fine to extend that file if possible"
    },
    {
      "id": 1347748916,
      "user": "seanjedi",
      "body": "Created a branch here to work on the issue: [seanjedi-50207](https://github.com/seanjedi/pandas/tree/seanjedi-50207_check_each_minimum_dependency_is_enforced_in_yaml_and_environment_files)"
    },
    {
      "id": 1352514114,
      "user": "seanjedi",
      "body": "@MarcoGorelli I have a question regarding which YAML files to check\r\nRight now I am checking this list of YAML file (these are all the *.y*ml files I can find in both the `root` and `ci/deps`, not all of these have dependencies, that is correct right? )\r\n\r\nAlso looking at how we were checking the dependencies earlier, it seems that we were only concerned with the optional dependencies, should I only be checking optional dependencies, or if I find any dependency that is both within pyproject.toml and any yaml file, then I should pin it?\r\n\r\n<img width=\"944\" alt=\"image\" src=\"https://user-images.githubusercontent.com/18587013/207766296-0e93cc28-59c9-4283-94f9-3cafd2222ad8.png\">\r\n"
    },
    {
      "id": 1352687110,
      "user": "MarcoGorelli",
      "body": "you only need to look at `environment.yml` and `ci/deps/*.yaml`, the other yaml files are irrelevant\r\n\r\n> I find any dependency that is both within pyproject.toml and any yaml file, then I should pin it\r\n\r\nyup (unless it's pinned already)"
    },
    {
      "id": 1386054739,
      "user": "seanjedi",
      "body": "Update (Since I have not updated in a long while): I am still working on this issue, but progress has slowed down a lot since the last commit I made in my branch. \r\nThis began with the Holiday's taking my time away so that I can spend it with family. \r\nNow it is due to graduate school, and a few requirements for graduation that appeared that I have to appeal against now due to administration.\r\nI bring this up so that if someone sees this, I want to ensure that this issue is not dead and that if anyone else wants to work on this issue, I would be open to that (especially collaboratively), and please let me know so that I can let you know what I have worked on so that we don't end up doing the same work. \r\n\r\nOtherwise, I will continue working on this issue when I have the chance. "
    },
    {
      "id": 1386062048,
      "user": "MarcoGorelli",
      "body": "cool, thanks - I've removed the assignment so it's clear this is open"
    },
    {
      "id": 1410881102,
      "user": "kathleenhang",
      "body": "take"
    },
    {
      "id": 1410899539,
      "user": "kathleenhang",
      "body": "@seanjedi Hi there, I saw you mentioned about working collaboratively, and I'm open to that. I did see the branch you created for this issue. Feel free to let me know if you worked on anything extra or details on how you'd like to collaborate together. I'm going to start working on this issue now.\r\n\r\nEdit: Here is the WIP [scripts/validate_min_versions_in_sync.py](https://github.com/pandas-dev/pandas/compare/main...kathleenhang:pandas:kathleenhang-50207)\r\n\r\nAlso, I have a question. What types of characters are allowed for the version portion of the YAML dependency files? I ask this because the only dependency file in ci/deps/ which breaks the script is:\r\n\r\nci/deps/actions-pypy-38.yaml - line 8 - contains:  \r\n\r\n`- python=3.8[build=*_pypy] # TODO: use this once pypy3.8 is available\r\n`\r\n\r\nBecause it contains 2 \"=\" signs. I am wondering if I should write code to accommodate this or if this is out of place and only digits and decimals should be accommodated for the version portion?"
    },
    {
      "id": 1413089977,
      "user": "kathleenhang",
      "body": "@MarcoGorelli Could you please review my script? I linked it above. I'm wondering if it will run too slow or be too risky since it would create a new file and delete the old one. I'm still working on it, but wanted to know if I'm headed in the right direction."
    },
    {
      "id": 1413326773,
      "user": "MarcoGorelli",
      "body": "nice! taking a look ðŸ‘€ "
    },
    {
      "id": 1413340993,
      "user": "MarcoGorelli",
      "body": "hey @kathleenhang, looks like you're on the right path - the script doesn't run at the moment though: if you have a list, then `.append` will return `None`, you probably wanted something like\r\n```\r\n    all_yaml_files = list(YAML_PATH.iterdir())\r\n    all_yaml_files.append(ENV_PATH)\r\n```\r\n\r\nAnd\r\n```\r\n            data = yaml_f.read()\r\n            yaml_file = yaml.safe_load(yaml_f)\r\n```\r\nshould probably have been\r\n```\r\n            data = yaml_f.read()\r\n            yaml_file = yaml.safe_load(data)\r\n```\r\n?\r\n\r\nIf you can get it to run without errors, then I'll take a closer look"
    },
    {
      "id": 1414589167,
      "user": "kathleenhang",
      "body": "@MarcoGorelli Got it working! I commented out line 8 from ci/deps/actions-pypy-38.yaml which shows` - python=3.8[build=*_pypy] # TODO: use this once pypy3.8 is available `. If you run the script again, make sure to comment that line out, or the script breaks.\r\n\r\nWhat should be done for these edge cases?\r\n```\r\n- pyqt5==5.15.1\r\n- numpy<1.24.0\r\n- sqlalchemy<1.4.46\r\n- python=3.8[build=*_pypy] # TODO: use this once pypy3.8 is available\r\n```\r\nAlso the script does mess up on a line in environment.yml:  `- jinja2>=3.0.0>=3.0.0`. I'm planning to fix that. Other than that, it works for me. \r\n\r\nI'm not sure if it will work for you since I am using the imported os python module. I'm not sure if that may be different on Windows due to differing paths, etc.\r\n\r\nLet me know what you think, thanks.\r\n\r\n"
    },
    {
      "id": 1415982303,
      "user": "MarcoGorelli",
      "body": "thanks for updating!\r\n\r\nso:\r\n- `pyqt5==5.15.1` - you should check that the pin (here, `5.15.1`) is greater or equal to the minimum version\r\n- `numpy<1.24.0` - this should be greater than the minimum version. You can set both greater than and less than in pip, see https://stackoverflow.com/questions/50842144/requirements-txt-greater-than-equal-to-and-then-less-than\r\n- `python=3.8[build=*_pypy]` - I think we can exclude this one, like in an exclusions list in the script"
    }
  ],
  "text_context": "# CI check each minimum dependency is enforced in *.yaml and environment.yml files\n\nxref https://github.com/pandas-dev/pandas/pull/50205#discussion_r1046097646\r\n\r\nIf any dependency has a minimum version specified in \r\n\r\nhttps://github.com/pandas-dev/pandas/blob/16b9c98bfedcfae031df5d570ef68a2d126826b7/pyproject.toml#L57-L119\r\n\r\nthen if that dependency appears in `environment.yml` or any of the `*.yaml` files, then it should either be pinned to that minimum version, or be marked as `>=` that minimum version\r\n\r\nLet's add a script to automate checking this!\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/main/scripts/validate_min_versions_in_sync.py is kind of related\r\n\r\n---\r\n\r\nFeel free to tag me for review if you take this on\n\nNotes:\r\n\r\n1. `ci/deps/actions-*-minimum_versions.yaml` should be pinned as `=` instead of `>=`\r\n2. IMO `validate_min_versions_in_sync.py` should be updated to ensure the dependency files are also in sync\r\n\r\nPersonally not sure if this is a good first issue as there are a lot of moving parts but happy to be wrong\n\nHmm, I believe I understand the ask. \r\nSo essentially get all the dependencies from pyproject.toml optional-dependencies, and compare them against the dependencies within environment.yml, and if there are any dependencies that are newer within pyproject.toml tan environment.yaml, then update environment.yaml to either `=` or `>=` correct?\r\nSo if that is the case, then:\r\n1) how do we determine when we want to have it `=` or `>=`? Would that be depdendent on how pyproject.toml has it?\r\n2) what if environment.yml somehow has a newer depdency, then should be ignore it, or should we downgrade it to the version that pyproject has it at?\r\n\r\nAlso can I take this? \n\nI'd say:\r\n1. if it already has `=` then keep as-is, else, add `>=`\r\n2. not sure I understand the question, can you show an example?\r\n\r\nAnd yes, sure!\n\nFor 2 let's say hypothetically we have a situation where\r\nIn environment.yml we have:\r\n```\r\n- numba=0.53.1\r\n```\r\nand in pyproject we have:\r\n```\r\nnumba>=0.52\r\n```\r\n\r\nShould I check if the dependencies in pyproject are indeed greater than the ones in environment, or if they differ then set the dependencies to pyproject\r\nThis might be all moot, but I wanted to doublecheck since in my head the way I was thinking of comparing the two is if pyproject has a dependency greater than environment, then update environment, otherwise stay the same, or do we want the two be equal? \r\nI think the case we have, is that we want it to be equal, so above even though environment has a great version, we should have it pinned to be `numba>=0.52`\n\ntake\n\nIf there's already a pin, then as long as the version is greater than the minimum version, you can leave it as it is\r\n\r\nIf there's no pin, then just put `>=` and the minimum version\n\nSo should I create a new file for this, or extend [validate_min_versions_in_sync.py](https://github.com/pandas-dev/pandas/blob/main/scripts/validate_min_versions_in_sync.py) to be able to update these dependencies as well? \n\nit's probably fine to extend that file if possible\n\nCreated a branch here to work on the issue: [seanjedi-50207](https://github.com/seanjedi/pandas/tree/seanjedi-50207_check_each_minimum_dependency_is_enforced_in_yaml_and_environment_files)\n\n@MarcoGorelli I have a question regarding which YAML files to check\r\nRight now I am checking this list of YAML file (these are all the *.y*ml files I can find in both the `root` and `ci/deps`, not all of these have dependencies, that is correct right? )\r\n\r\nAlso looking at how we were checking the dependencies earlier, it seems that we were only concerned with the optional dependencies, should I only be checking optional dependencies, or if I find any dependency that is both within pyproject.toml and any yaml file, then I should pin it?\r\n\r\n<img width=\"944\" alt=\"image\" src=\"https://user-images.githubusercontent.com/18587013/207766296-0e93cc28-59c9-4283-94f9-3cafd2222ad8.png\">\r\n\n\nyou only need to look at `environment.yml` and `ci/deps/*.yaml`, the other yaml files are irrelevant\r\n\r\n> I find any dependency that is both within pyproject.toml and any yaml file, then I should pin it\r\n\r\nyup (unless it's pinned already)\n\nUpdate (Since I have not updated in a long while): I am still working on this issue, but progress has slowed down a lot since the last commit I made in my branch. \r\nThis began with the Holiday's taking my time away so that I can spend it with family. \r\nNow it is due to graduate school, and a few requirements for graduation that appeared that I have to appeal against now due to administration.\r\nI bring this up so that if someone sees this, I want to ensure that this issue is not dead and that if anyone else wants to work on this issue, I would be open to that (especially collaboratively), and please let me know so that I can let you know what I have worked on so that we don't end up doing the same work. \r\n\r\nOtherwise, I will continue working on this issue when I have the chance. \n\ncool, thanks - I've removed the assignment so it's clear this is open\n\ntake\n\n@seanjedi Hi there, I saw you mentioned about working collaboratively, and I'm open to that. I did see the branch you created for this issue. Feel free to let me know if you worked on anything extra or details on how you'd like to collaborate together. I'm going to start working on this issue now.\r\n\r\nEdit: Here is the WIP [scripts/validate_min_versions_in_sync.py](https://github.com/pandas-dev/pandas/compare/main...kathleenhang:pandas:kathleenhang-50207)\r\n\r\nAlso, I have a question. What types of characters are allowed for the version portion of the YAML dependency files? I ask this because the only dependency file in ci/deps/ which breaks the script is:\r\n\r\nci/deps/actions-pypy-38.yaml - line 8 - contains:  \r\n\r\n`- python=3.8[build=*_pypy] # TODO: use this once pypy3.8 is available\r\n`\r\n\r\nBecause it contains 2 \"=\" signs. I am wondering if I should write code to accommodate this or if this is out of place and only digits and decimals should be accommodated for the version portion?\n\n@MarcoGorelli Could you please review my script? I linked it above. I'm wondering if it will run too slow or be too risky since it would create a new file and delete the old one. I'm still working on it, but wanted to know if I'm headed in the right direction.\n\nnice! taking a look ðŸ‘€ \n\nhey @kathleenhang, looks like you're on the right path - the script doesn't run at the moment though: if you have a list, then `.append` will return `None`, you probably wanted something like\r\n```\r\n    all_yaml_files = list(YAML_PATH.iterdir())\r\n    all_yaml_files.append(ENV_PATH)\r\n```\r\n\r\nAnd\r\n```\r\n            data = yaml_f.read()\r\n            yaml_file = yaml.safe_load(yaml_f)\r\n```\r\nshould probably have been\r\n```\r\n            data = yaml_f.read()\r\n            yaml_file = yaml.safe_load(data)\r\n```\r\n?\r\n\r\nIf you can get it to run without errors, then I'll take a closer look\n\n@MarcoGorelli Got it working! I commented out line 8 from ci/deps/actions-pypy-38.yaml which shows` - python=3.8[build=*_pypy] # TODO: use this once pypy3.8 is available `. If you run the script again, make sure to comment that line out, or the script breaks.\r\n\r\nWhat should be done for these edge cases?\r\n```\r\n- pyqt5==5.15.1\r\n- numpy<1.24.0\r\n- sqlalchemy<1.4.46\r\n- python=3.8[build=*_pypy] # TODO: use this once pypy3.8 is available\r\n```\r\nAlso the script does mess up on a line in environment.yml:  `- jinja2>=3.0.0>=3.0.0`. I'm planning to fix that. Other than that, it works for me. \r\n\r\nI'm not sure if it will work for you since I am using the imported os python module. I'm not sure if that may be different on Windows due to differing paths, etc.\r\n\r\nLet me know what you think, thanks.\r\n\r\n\n\nthanks for updating!\r\n\r\nso:\r\n- `pyqt5==5.15.1` - you should check that the pin (here, `5.15.1`) is greater or equal to the minimum version\r\n- `numpy<1.24.0` - this should be greater than the minimum version. You can set both greater than and less than in pip, see https://stackoverflow.com/questions/50842144/requirements-txt-greater-than-equal-to-and-then-less-than\r\n- `python=3.8[build=*_pypy]` - I think we can exclude this one, like in an exclusions list in the script",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/51189",
  "code_context": [
    {
      "filename": "scripts/generate_pip_deps_from_conda.py",
      "content": "#!/usr/bin/env python3\n\"\"\"\nConvert the conda environment.yml to the pip requirements-dev.txt,\nor check that they have the same packages (for the CI)\n\nUsage:\n\n    Generate `requirements-dev.txt`\n    $ python scripts/generate_pip_deps_from_conda.py\n\n    Compare and fail (exit status != 0) if `requirements-dev.txt` has not been\n    generated with this script:\n    $ python scripts/generate_pip_deps_from_conda.py --compare\n\"\"\"\nimport argparse\nimport pathlib\nimport re\nimport sys\n\nif sys.version_info >= (3, 11):\n    import tomllib\nelse:\n    import tomli as tomllib\nimport yaml\n\nEXCLUDE = {\"python\", \"c-compiler\", \"cxx-compiler\"}\nREMAP_VERSION = {\"tzdata\": \"2022.1\"}\nRENAME = {\n    \"pytables\": \"tables\",\n    \"psycopg2\": \"psycopg2-binary\",\n    \"dask-core\": \"dask\",\n    \"seaborn-base\": \"seaborn\",\n    \"sqlalchemy\": \"SQLAlchemy\",\n}\n\n\ndef conda_package_to_pip(package: str):\n    \"\"\"\n    Convert a conda package to its pip equivalent.\n\n    In most cases they are the same, those are the exceptions:\n    - Packages that should be excluded (in `EXCLUDE`)\n    - Packages that should be renamed (in `RENAME`)\n    - A package requiring a specific version, in conda is defined with a single\n      equal (e.g. ``pandas=1.0``) and in pip with two (e.g. ``pandas==1.0``)\n    \"\"\"\n    package = re.sub(\"(?<=[^<>])=\", \"==\", package).strip()\n\n    for compare in (\"<=\", \">=\", \"==\"):\n        if compare in package:\n            pkg, version = package.split(compare)\n            if pkg in EXCLUDE:\n                return\n            if pkg in REMAP_VERSION:\n                return \"\".join((pkg, compare, REMAP_VERSION[pkg]))\n            if pkg in RENAME:\n                return \"\".join((RENAME[pkg], compare, version))\n\n    if package in EXCLUDE:\n        return\n\n    if package in RENAME:\n        return RENAME[package]\n\n    return package\n\n\ndef generate_pip_from_conda(\n    conda_path: pathlib.Path, pip_path: pathlib.Path, compare: bool = False\n) -> bool:\n    \"\"\"\n    Generate the pip dependencies file from the conda file, or compare that\n    they are synchronized (``compare=True``).\n\n    Parameters\n    ----------\n    conda_path : pathlib.Path\n        Path to the conda file with dependencies (e.g. `environment.yml`).\n    pip_path : pathlib.Path\n        Path to the pip file with dependencies (e.g. `requirements-dev.txt`).\n    compare : bool, default False\n        Whether to generate the pip file (``False``) or to compare if the\n        pip file has been generated with this script and the last version\n        of the conda file (``True``).\n\n    Returns\n    -------\n    bool\n        True if the comparison fails, False otherwise\n    \"\"\"\n    with conda_path.open() as file:\n        deps = yaml.safe_load(file)[\"dependencies\"]\n\n    pip_deps = []\n    for dep in deps:\n        if isinstance(dep, str):\n            conda_dep = conda_package_to_pip(dep)\n            if conda_dep:\n                pip_deps.append(conda_dep)\n        elif isinstance(dep, dict) and len(dep) == 1 and \"pip\" in dep:\n            pip_deps.extend(dep[\"pip\"])\n        else:\n            raise ValueError(f\"Unexpected dependency {dep}\")\n\n    header = (\n        f\"# This file is auto-generated from {conda_path.name}, do not modify.\\n\"\n        \"# See that file for comments about the need/usage of each dependency.\\n\\n\"\n    )\n    pip_content = header + \"\\n\".join(pip_deps) + \"\\n\"\n\n    # add setuptools to requirements-dev.txt\n    with open(pathlib.Path(conda_path.parent, \"pyproject.toml\"), \"rb\") as fd:\n        meta = tomllib.load(fd)\n    for requirement in meta[\"build-system\"][\"requires\"]:\n        if \"setuptools\" in requirement:\n            pip_content += requirement\n            pip_content += \"\\n\"\n\n    if compare:\n        with pip_path.open() as file:\n            return pip_content != file.read()\n\n    with pip_path.open(\"w\") as file:\n        file.write(pip_content)\n    return False\n\n\nif __name__ == \"__main__\":\n    argparser = argparse.ArgumentParser(\n        description=\"convert (or compare) conda file to pip\"\n    )\n    argparser.add_argument(\n        \"--compare\",\n        action=\"store_true\",\n        help=\"compare whether the two files are equivalent\",\n    )\n    args = argparser.parse_args()\n\n    conda_fname = \"environment.yml\"\n    pip_fname = \"requirements-dev.txt\"\n    repo_path = pathlib.Path(__file__).parent.parent.absolute()\n    res = generate_pip_from_conda(\n        pathlib.Path(repo_path, conda_fname),\n        pathlib.Path(repo_path, pip_fname),\n        compare=args.compare,\n    )\n    if res:\n        msg = (\n            f\"`{pip_fname}` has to be generated with `{__file__}` after \"\n            f\"`{conda_fname}` is modified.\\n\"\n        )\n        sys.stderr.write(msg)\n    sys.exit(res)\n"
    },
    {
      "filename": "scripts/tests/test_validate_min_versions_in_sync.py",
      "content": "import pathlib\nimport sys\n\nimport pytest\nimport yaml\n\nif sys.version_info >= (3, 11):\n    import tomllib\nelse:\n    import tomli as tomllib\n\nfrom scripts.validate_min_versions_in_sync import (\n    get_toml_map_from,\n    get_yaml_map_from,\n    pin_min_versions_to_yaml_file,\n)\n\n\n@pytest.mark.parametrize(\n    \"src_toml, src_yaml, expected_yaml\",\n    [\n        (\n            pathlib.Path(\"scripts/tests/data/deps_minimum.toml\"),\n            pathlib.Path(\"scripts/tests/data/deps_unmodified_random.yaml\"),\n            pathlib.Path(\"scripts/tests/data/deps_expected_random.yaml\"),\n        ),\n        (\n            pathlib.Path(\"scripts/tests/data/deps_minimum.toml\"),\n            pathlib.Path(\"scripts/tests/data/deps_unmodified_same_version.yaml\"),\n            pathlib.Path(\"scripts/tests/data/deps_expected_same_version.yaml\"),\n        ),\n        (\n            pathlib.Path(\"scripts/tests/data/deps_minimum.toml\"),\n            pathlib.Path(\"scripts/tests/data/deps_unmodified_duplicate_package.yaml\"),\n            pathlib.Path(\"scripts/tests/data/deps_expected_duplicate_package.yaml\"),\n        ),\n        (\n            pathlib.Path(\"scripts/tests/data/deps_minimum.toml\"),\n            pathlib.Path(\"scripts/tests/data/deps_unmodified_no_version.yaml\"),\n            pathlib.Path(\"scripts/tests/data/deps_expected_no_version.yaml\"),\n        ),\n        (\n            pathlib.Path(\"scripts/tests/data/deps_minimum.toml\"),\n            pathlib.Path(\"scripts/tests/data/deps_unmodified_range.yaml\"),\n            pathlib.Path(\"scripts/tests/data/deps_expected_range.yaml\"),\n        ),\n    ],\n)\ndef test_pin_min_versions_to_yaml_file(src_toml, src_yaml, expected_yaml):\n    with open(src_toml, \"rb\") as toml_f:\n        toml_map = tomllib.load(toml_f)\n    with open(src_yaml) as yaml_f:\n        yaml_file_data = yaml_f.read()\n    yaml_file = yaml.safe_load(yaml_file_data)\n    yaml_dependencies = yaml_file[\"dependencies\"]\n    yaml_map = get_yaml_map_from(yaml_dependencies)\n    toml_map = get_toml_map_from(toml_map)\n    result_yaml_file = pin_min_versions_to_yaml_file(yaml_map, toml_map, yaml_file_data)\n    with open(expected_yaml) as yaml_f:\n        dummy_yaml_expected_file_1 = yaml_f.read()\n    assert result_yaml_file == dummy_yaml_expected_file_1\n"
    },
    {
      "filename": "scripts/validate_min_versions_in_sync.py",
      "content": "#!/usr/bin/env python3\n\"\"\"\nCheck pandas required and optional dependencies are synced across:\n\nci/deps/actions-.*-minimum_versions.yaml\npandas/compat/_optional.py\nsetup.cfg\n\nTODO: doc/source/getting_started/install.rst\n\nThis is meant to be run as a pre-commit hook - to run it manually, you can do:\n\n    pre-commit run validate-min-versions-in-sync --all-files\n\"\"\"\nfrom __future__ import annotations\n\nimport pathlib\nimport sys\n\nimport yaml\n\nif sys.version_info >= (3, 11):\n    import tomllib\nelse:\n    import tomli as tomllib\n\nfrom typing import Any\n\nfrom scripts.generate_pip_deps_from_conda import RENAME\n\nDOC_PATH = pathlib.Path(\"doc/source/getting_started/install.rst\").resolve()\nCI_PATH = next(\n    pathlib.Path(\"ci/deps\").absolute().glob(\"actions-*-minimum_versions.yaml\")\n)\nCODE_PATH = pathlib.Path(\"pandas/compat/_optional.py\").resolve()\nSETUP_PATH = pathlib.Path(\"pyproject.toml\").resolve()\nYAML_PATH = pathlib.Path(\"ci/deps\")\nENV_PATH = pathlib.Path(\"environment.yml\")\nEXCLUDE_DEPS = {\"tzdata\", \"blosc\"}\nEXCLUSION_LIST = {\n    \"python=3.8[build=*_pypy]\": None,\n    \"tzdata\": None,\n    \"pyarrow\": None,\n}\n# pandas package is not available\n# in pre-commit environment\nsys.path.append(\"pandas/compat\")\nsys.path.append(\"pandas/util\")\nimport _exceptions\nimport version\n\nsys.modules[\"pandas.util.version\"] = version\nsys.modules[\"pandas.util._exceptions\"] = _exceptions\nimport _optional\n\n\ndef pin_min_versions_to_ci_deps() -> int:\n    \"\"\"\n    Pin minimum versions to CI dependencies.\n\n    Pip dependencies are not pinned.\n    \"\"\"\n    all_yaml_files = list(YAML_PATH.iterdir())\n    all_yaml_files.append(ENV_PATH)\n    toml_dependencies = {}\n    with open(SETUP_PATH, \"rb\") as toml_f:\n        toml_dependencies = tomllib.load(toml_f)\n    ret = 0\n    for curr_file in all_yaml_files:\n        with open(curr_file) as yaml_f:\n            yaml_start_data = yaml_f.read()\n        yaml_file = yaml.safe_load(yaml_start_data)\n        yaml_dependencies = yaml_file[\"dependencies\"]\n        yaml_map = get_yaml_map_from(yaml_dependencies)\n        toml_map = get_toml_map_from(toml_dependencies)\n        yaml_result_data = pin_min_versions_to_yaml_file(\n            yaml_map, toml_map, yaml_start_data\n        )\n        if yaml_result_data != yaml_start_data:\n            with open(curr_file, \"w\") as f:\n                f.write(yaml_result_data)\n            ret |= 1\n    return ret\n\n\ndef get_toml_map_from(toml_dic: dict[str, Any]) -> dict[str, str]:\n    toml_deps = {}\n    toml_dependencies = set(toml_dic[\"project\"][\"optional-dependencies\"][\"all\"])\n    for dependency in toml_dependencies:\n        toml_package, toml_version = dependency.strip().split(\">=\")\n        toml_deps[toml_package] = toml_version\n    return toml_deps\n\n\ndef get_operator_from(dependency: str) -> str | None:\n    if \"<=\" in dependency:\n        operator = \"<=\"\n    elif \">=\" in dependency:\n        operator = \">=\"\n    elif \"=\" in dependency:\n        operator = \"=\"\n    elif \">\" in dependency:\n        operator = \">\"\n    elif \"<\" in dependency:\n        operator = \"<\"\n    else:\n        operator = None\n    return operator\n\n\ndef get_yaml_map_from(\n    yaml_dic: list[str | dict[str, list[str]]]\n) -> dict[str, list[str] | None]:\n    yaml_map: dict[str, list[str] | None] = {}\n    for dependency in yaml_dic:\n        if (\n            isinstance(dependency, dict)\n            or dependency in EXCLUSION_LIST\n            or dependency in yaml_map\n        ):\n            continue\n        search_text = str(dependency)\n        operator = get_operator_from(search_text)\n        if \",\" in dependency:\n            yaml_dependency, yaml_version1 = search_text.split(\",\")\n            operator = get_operator_from(yaml_dependency)\n            assert operator is not None\n            yaml_package, yaml_version2 = yaml_dependency.split(operator)\n            yaml_version2 = operator + yaml_version2\n            yaml_map[yaml_package] = [yaml_version1, yaml_version2]\n        elif operator is not None:\n            yaml_package, yaml_version = search_text.split(operator)\n            yaml_version = operator + yaml_version\n            yaml_map[yaml_package] = [yaml_version]\n        else:\n            yaml_package, yaml_version = search_text.strip(), None\n            yaml_map[yaml_package] = yaml_version\n    return yaml_map\n\n\ndef clean_version_list(\n    yaml_versions: list[str], toml_version: version.Version\n) -> list[str]:\n    for i in range(len(yaml_versions)):\n        yaml_version = yaml_versions[i]\n        operator = get_operator_from(yaml_version)\n        assert operator is not None\n        if \"<=\" in operator or \">=\" in operator:\n            yaml_version = yaml_version[2:]\n        else:\n            yaml_version = yaml_version[1:]\n        yaml_version = version.parse(yaml_version)\n        if yaml_version < toml_version:\n            yaml_versions[i] = \"-\" + str(yaml_version)\n        elif yaml_version >= toml_version:\n            if \">\" in operator:\n                yaml_versions[i] = \"-\" + str(yaml_version)\n    return yaml_versions\n\n\ndef pin_min_versions_to_yaml_file(\n    yaml_map: dict[str, list[str] | None], toml_map: dict[str, str], yaml_file_data: str\n) -> str:\n    data = yaml_file_data\n    for yaml_package, yaml_versions in yaml_map.items():\n        if yaml_package in EXCLUSION_LIST:\n            continue\n        old_dep = yaml_package\n        if yaml_versions is not None:\n            for yaml_version in yaml_versions:\n                old_dep += yaml_version + \", \"\n            old_dep = old_dep[:-2]\n        if RENAME.get(yaml_package, yaml_package) in toml_map:\n            min_dep = toml_map[RENAME.get(yaml_package, yaml_package)]\n        elif yaml_package in toml_map:\n            min_dep = toml_map[yaml_package]\n        else:\n            continue\n        if yaml_versions is None:\n            new_dep = old_dep + \">=\" + min_dep\n            data = data.replace(old_dep, new_dep, 1)\n            continue\n        toml_version = version.parse(min_dep)\n        yaml_versions = clean_version_list(yaml_versions, toml_version)\n        cleaned_yaml_versions = [x for x in yaml_versions if \"-\" not in x]\n        new_dep = yaml_package\n        for yaml_version in cleaned_yaml_versions:\n            new_dep += yaml_version + \", \"\n        operator = get_operator_from(new_dep)\n        if operator != \"=\":\n            new_dep += \">=\" + min_dep\n        else:\n            new_dep = new_dep[:-2]\n        data = data.replace(old_dep, new_dep)\n    return data\n\n\ndef get_versions_from_code() -> dict[str, str]:\n    \"\"\"Min versions for checking within pandas code.\"\"\"\n    install_map = _optional.INSTALL_MAPPING\n    versions = _optional.VERSIONS\n    for item in EXCLUDE_DEPS:\n        versions.pop(item, None)\n    return {install_map.get(k, k).casefold(): v for k, v in versions.items()}\n\n\ndef get_versions_from_ci(content: list[str]) -> tuple[dict[str, str], dict[str, str]]:\n    \"\"\"Min versions in CI job for testing all optional dependencies.\"\"\"\n    # Don't parse with pyyaml because it ignores comments we're looking for\n    seen_required = False\n    seen_optional = False\n    seen_test = False\n    required_deps = {}\n    optional_deps = {}\n    for line in content:\n        if \"# test dependencies\" in line:\n            seen_test = True\n        elif seen_test and \"- pytest>=\" in line:\n            # Only grab pytest\n            package, version = line.strip().split(\">=\")\n            package = package[2:]\n            optional_deps[package.casefold()] = version\n        elif \"# required dependencies\" in line:\n            seen_required = True\n        elif \"# optional dependencies\" in line:\n            seen_optional = True\n        elif \"- pip:\" in line:\n            continue\n        elif seen_required and line.strip():\n            if \"==\" in line:\n                package, version = line.strip().split(\"==\")\n\n            else:\n                package, version = line.strip().split(\"=\")\n            package = package[2:]\n            if package in EXCLUDE_DEPS:\n                continue\n            if not seen_optional:\n                required_deps[package.casefold()] = version\n            else:\n                optional_deps[package.casefold()] = version\n    return required_deps, optional_deps\n\n\ndef get_versions_from_toml() -> dict[str, str]:\n    \"\"\"Min versions in pyproject.toml for pip install pandas[extra].\"\"\"\n    install_map = _optional.INSTALL_MAPPING\n    optional_dependencies = {}\n    with open(SETUP_PATH, \"rb\") as pyproject_f:\n        pyproject_toml = tomllib.load(pyproject_f)\n        opt_deps = pyproject_toml[\"project\"][\"optional-dependencies\"]\n        dependencies = set(opt_deps[\"all\"])\n\n        # remove pytest plugin dependencies\n        pytest_plugins = {dep for dep in opt_deps[\"test\"] if dep.startswith(\"pytest-\")}\n        dependencies = dependencies.difference(pytest_plugins)\n\n    for dependency in dependencies:\n        package, version = dependency.strip().split(\">=\")\n        optional_dependencies[install_map.get(package, package).casefold()] = version\n\n    for item in EXCLUDE_DEPS:\n        optional_dependencies.pop(item, None)\n    return optional_dependencies\n\n\ndef main() -> int:\n    ret = 0\n    ret |= pin_min_versions_to_ci_deps()\n    with open(CI_PATH, encoding=\"utf-8\") as f:\n        _, ci_optional = get_versions_from_ci(f.readlines())\n    code_optional = get_versions_from_code()\n    setup_optional = get_versions_from_toml()\n\n    diff = (ci_optional.items() | code_optional.items() | setup_optional.items()) - (\n        ci_optional.items() & code_optional.items() & setup_optional.items()\n    )\n\n    if diff:\n        packages = {package for package, _ in diff}\n        out = sys.stdout\n        out.write(\n            f\"The follow minimum version differences were found between  \"\n            f\"{CI_PATH}, {CODE_PATH} AND {SETUP_PATH}. \"\n            f\"Please ensure these are aligned: \\n\\n\"\n        )\n\n        for package in packages:\n            out.write(\n                f\"{package}\\n\"\n                f\"{CI_PATH}: {ci_optional.get(package, 'Not specified')}\\n\"\n                f\"{CODE_PATH}: {code_optional.get(package, 'Not specified')}\\n\"\n                f\"{SETUP_PATH}: {setup_optional.get(package, 'Not specified')}\\n\\n\"\n            )\n        ret |= 1\n    return ret\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n"
    }
  ],
  "questions": [
    "I'd say:\r\n1. if it already has `=` then keep as-is, else, add `>=`\r\n2. not sure I understand the question, can you show an example?\r\n\r\nAnd yes, sure!",
    "For 2 let's say hypothetically we have a situation where\r\nIn environment.yml we have:\r\n```\r\n- numba=0.53.1\r\n```\r\nand in pyproject we have:\r\n```\r\nnumba>=0.52\r\n```\r\n\r\nShould I check if the dependencies in pyproject are indeed greater than the ones in environment, or if they differ then set the dependencies to pyproject\r\nThis might be all moot, but I wanted to doublecheck since in my head the way I was thinking of comparing the two is if pyproject has a dependency greater than environment, then update environment, otherwise stay the same, or do we want the two be equal? \r\nI think the case we have, is that we want it to be equal, so above even though environment has a great version, we should have it pinned to be `numba>=0.52`",
    "So should I create a new file for this, or extend [validate_min_versions_in_sync.py](https://github.com/pandas-dev/pandas/blob/main/scripts/validate_min_versions_in_sync.py) to be able to update these dependencies as well?",
    "@MarcoGorelli I have a question regarding which YAML files to check\r\nRight now I am checking this list of YAML file (these are all the *.y*ml files I can find in both the `root` and `ci/deps`, not all of these have dependencies, that is correct right? )\r\n\r\nAlso looking at how we were checking the dependencies earlier, it seems that we were only concerned with the optional dependencies, should I only be checking optional dependencies, or if I find any dependency that is both within pyproject.toml and any yaml file, then I should pin it?\r\n\r\n<img width=\"944\" alt=\"image\" src=\"https://user-images.githubusercontent.com/18587013/207766296-0e93cc28-59c9-4283-94f9-3cafd2222ad8.png\">",
    "hey @kathleenhang, looks like you're on the right path - the script doesn't run at the moment though: if you have a list, then `.append` will return `None`, you probably wanted something like\r\n```\r\n    all_yaml_files = list(YAML_PATH.iterdir())\r\n    all_yaml_files.append(ENV_PATH)\r\n```\r\n\r\nAnd\r\n```\r\n            data = yaml_f.read()\r\n            yaml_file = yaml.safe_load(yaml_f)\r\n```\r\nshould probably have been\r\n```\r\n            data = yaml_f.read()\r\n            yaml_file = yaml.safe_load(data)\r\n```\r\n?\r\n\r\nIf you can get it to run without errors, then I'll take a closer look",
    "@MarcoGorelli Got it working! I commented out line 8 from ci/deps/actions-pypy-38.yaml which shows` - python=3.8[build=*_pypy] # TODO: use this once pypy3.8 is available `. If you run the script again, make sure to comment that line out, or the script breaks.\r\n\r\nWhat should be done for these edge cases?\r\n```\r\n- pyqt5==5.15.1\r\n- numpy<1.24.0\r\n- sqlalchemy<1.4.46\r\n- python=3.8[build=*_pypy] # TODO: use this once pypy3.8 is available\r\n```\r\nAlso the script does mess up on a line in environment.yml:  `- jinja2>=3.0.0>=3.0.0`. I'm planning to fix that. Other than that, it works for me. \r\n\r\nI'm not sure if it will work for you since I am using the imported os python module. I'm not sure if that may be different on Windows due to differing paths, etc.\r\n\r\nLet me know what you think, thanks."
  ],
  "golden_answers": [
    "For 2 let's say hypothetically we have a situation where\r\nIn environment.yml we have:\r\n```\r\n- numba=0.53.1\r\n```\r\nand in pyproject we have:\r\n```\r\nnumba>=0.52\r\n```\r\n\r\nShould I check if the dependencies in pyproject are indeed greater than the ones in environment, or if they differ then set the dependencies to pyproject\r\nThis might be all moot, but I wanted to doublecheck since in my head the way I was thinking of comparing the two is if pyproject has a dependency greater than environment, then update environment, otherwise stay the same, or do we want the two be equal? \r\nI think the case we have, is that we want it to be equal, so above even though environment has a great version, we should have it pinned to be `numba>=0.52`",
    "If there's already a pin, then as long as the version is greater than the minimum version, you can leave it as it is\r\n\r\nIf there's no pin, then just put `>=` and the minimum version",
    "Created a branch here to work on the issue: [seanjedi-50207](https://github.com/seanjedi/pandas/tree/seanjedi-50207_check_each_minimum_dependency_is_enforced_in_yaml_and_environment_files)",
    "you only need to look at `environment.yml` and `ci/deps/*.yaml`, the other yaml files are irrelevant\r\n\r\n> I find any dependency that is both within pyproject.toml and any yaml file, then I should pin it\r\n\r\nyup (unless it's pinned already)",
    "@MarcoGorelli Got it working! I commented out line 8 from ci/deps/actions-pypy-38.yaml which shows` - python=3.8[build=*_pypy] # TODO: use this once pypy3.8 is available `. If you run the script again, make sure to comment that line out, or the script breaks.\r\n\r\nWhat should be done for these edge cases?\r\n```\r\n- pyqt5==5.15.1\r\n- numpy<1.24.0\r\n- sqlalchemy<1.4.46\r\n- python=3.8[build=*_pypy] # TODO: use this once pypy3.8 is available\r\n```\r\nAlso the script does mess up on a line in environment.yml:  `- jinja2>=3.0.0>=3.0.0`. I'm planning to fix that. Other than that, it works for me. \r\n\r\nI'm not sure if it will work for you since I am using the imported os python module. I'm not sure if that may be different on Windows due to differing paths, etc.\r\n\r\nLet me know what you think, thanks.",
    "thanks for updating!\r\n\r\nso:\r\n- `pyqt5==5.15.1` - you should check that the pin (here, `5.15.1`) is greater or equal to the minimum version\r\n- `numpy<1.24.0` - this should be greater than the minimum version. You can set both greater than and less than in pip, see https://stackoverflow.com/questions/50842144/requirements-txt-greater-than-equal-to-and-then-less-than\r\n- `python=3.8[build=*_pypy]` - I think we can exclude this one, like in an exclusions list in the script"
  ],
  "questions_generated": [
    "How does the 'validate_min_versions_in_sync.py' script relate to the issue of ensuring minimum dependency versions in environment files?",
    "What is the rationale behind using '=' in 'ci/deps/actions-*-minimum_versions.yaml' instead of '>=' when specifying dependency versions?",
    "What are the potential challenges in extending 'validate_min_versions_in_sync.py' to handle dependency version synchronization across different files?",
    "In what scenario should a dependency version in 'environment.yml' be downgraded to match the version in 'pyproject.toml'?",
    "How does the 'generate_pip_deps_from_conda.py' script contribute to the management of dependency versions in the repository?"
  ],
  "golden_answers_generated": [
    "The 'validate_min_versions_in_sync.py' script checks that the minimum dependency versions specified in the 'pyproject.toml' file are synchronized with those in the 'environment.yml' and '*.yaml' files. The issue suggests extending this script to automate checking and enforcing these versions, ensuring they are either pinned or marked with '>=' in the environment files.",
    "Using '=' to pin versions in 'ci/deps/actions-*-minimum_versions.yaml' ensures that the exact version of a dependency is used, which can help avoid unexpected behavior caused by updates in newer versions. This approach is particularly useful in CI environments where consistency and reliability are crucial.",
    "Extending the script involves several challenges, including parsing multiple file formats (e.g., 'pyproject.toml', 'environment.yml', and '*.yaml'), handling different version specifications ('=', '>=', '=='), and ensuring that any changes made maintain compatibility across the various environments. Additionally, the script needs to address cases where dependencies are renamed or remapped between conda and pip formats.",
    "A dependency version in 'environment.yml' should be downgraded if it exceeds the minimum version specified in 'pyproject.toml' and is not already pinned with '='. If 'pyproject.toml' specifies a minimum version using '>=', the 'environment.yml' should reflect this to ensure consistency unless it is explicitly required to pin to a newer version for specific reasons.",
    "The 'generate_pip_deps_from_conda.py' script converts conda environment specifications in 'environment.yml' to pip requirements in 'requirements-dev.txt'. It ensures that the dependencies are consistent across conda and pip environments by remapping versions and renaming packages as needed. This script plays a key role in maintaining synchronization between different package management systems used in the repository."
  ]
}