{
  "repo_name": "oppia_oppia",
  "issue_id": "10432",
  "issue_description": "# Load dummy new structures data on activities tab for admins isn't working. \n\n**Describe the bug**\r\nI checked out develop and then merged with the updated upstream. I logged on as an admin, gave myself admin privileges and then tried to load the 'Load dummy new structures data' on the activities tab of the admin page. I got a 'Sever error: 'NoneType' object has no attribute 'version'' error. This was working a week ago. There seems to be a problem with getting the version in base_models delete_multi.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n 1. Run the dev server.\r\n 2. Sign on as an admin.\r\n 3. Go to the admin page and give yourself admin rights.\r\n 4. Go to the activities tab of the admin page and click load data for the 'Load dummy new structures data' section.\r\n 5. See error.\r\n\r\n**Screenshots**\r\nYou can see the error on the bottom right of the ui:\r\n<img width=\"1734\" alt=\"Screen Shot 2020-08-24 at 3 58 28 PM\" src=\"https://user-images.githubusercontent.com/19376937/91105057-f3fe6200-e623-11ea-97da-6537c4ff6bb8.png\">\r\n\r\nTerminal output:\r\n<img width=\"1252\" alt=\"Screen Shot 2020-08-24 at 3 58 49 PM\" src=\"https://user-images.githubusercontent.com/19376937/91105019-e1842880-e623-11ea-9968-e6aa7043801b.png\">\r\n\r\n**Desktop (please complete the following information; delete this section if the issue does not arise on desktop):**\r\n - OS: [Catalina, 10.15.16]\r\n - Browser [Chrome]\r\n - Version [84]",
  "issue_comments": [
    {
      "id": 682156525,
      "user": "Showtim3",
      "body": "Yeah even I noticed this, but seems like its fixed now. Can you confirm and close this? @kaylahardie "
    },
    {
      "id": 682231280,
      "user": "kaylahardie",
      "body": "No I'm still getting the error @Showtim3, thoughts?"
    },
    {
      "id": 682242370,
      "user": "DubeySandeep",
      "body": "@Hudda had also faced a similar issue and restarting the server had resolved the issue! @Hudda Can you please confirm?\r\n\r\n(just wild guess) Is it happening because of some redis cache/dump? Do you see any dump file in the repo?  [Note: the dump file is in .gitigone so you won't be able to check it through git status]"
    },
    {
      "id": 682352301,
      "user": "Hudda",
      "body": "Hi Sandeep,\n\nKevin is working on this one. I've added you to that thread.\n\nThanks,\nAnshul\n\nOn Fri, Aug 28, 2020 at 5:01 AM Sandeep Dubey <notifications@github.com>\nwrote:\n\n> @Hudda <https://github.com/Hudda> had also faced a similar issue and\n> restarting the server had resolved the issue! @Hudda\n> <https://github.com/Hudda> Can you please confirm?\n>\n> (just wild guess) Is it happening because of some redis cache/dump? Do you\n> see any dump file in the repo? [Note: the dump file is in .gitigone so you\n> won't be able to check it through git status]\n>\n> â€”\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/oppia/oppia/issues/10432#issuecomment-682242370>, or\n> unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AG5WB5FIGBCW2HTUJ53B7LLSC3UFBANCNFSM4QKAHBNQ>\n> .\n>\n"
    },
    {
      "id": 682883301,
      "user": "kevjumba",
      "body": "Hi I already merged the PR that fixed that issue. I don't think this is the same issue because when I merged the PR https://github.com/oppia/oppia/pull/10429, I tested the reload explorations feature and everything seemed to work fine. \r\n\r\nAlso @kaylahardie I also encountered that issue but once I merged from master it seemed to resolve itself."
    },
    {
      "id": 682991419,
      "user": "DubeySandeep",
      "body": "I'm also facing the issue on updated upstream/develop! (Issue with reloading new_structure dummy data)"
    },
    {
      "id": 683207618,
      "user": "kaylahardie",
      "body": "I think it's ok now @kevjumba. Is it still an issue for you @DubeySandeep? Can I close this?"
    },
    {
      "id": 683349019,
      "user": "DubeySandeep",
      "body": "It's still an issue for me, I'm working on a project related to new_strauture and I have to manually create lots of data to test the feature!\r\n\r\n![image](https://user-images.githubusercontent.com/16653571/91647240-0dfdd180-ea76-11ea-96b8-f5ac011e5051.png)\r\n"
    },
    {
      "id": 683394427,
      "user": "kevintab95",
      "body": "Current workaround: \"Flushing cache\" by going to the \"misc\" tab first before loading data should fix this. "
    },
    {
      "id": 706486323,
      "user": "DubeySandeep",
      "body": "Just as an update: This issue is still reproducible sometimes on the local server. (Though the workaround is working fine!)\r\n\r\n/cc @srijanreddy98 "
    },
    {
      "id": 847059954,
      "user": "oppiabot[bot]",
      "body": "Hi @oppia/core-maintainers, this issue is not assigned to any project. Can you please update the same? Thanks!"
    },
    {
      "id": 1833837239,
      "user": "seanlip",
      "body": "Update: I'm marking this as a good first issue. The fix is to, in the server handler function corresponding to the \"load dummy data\" action, add a call to flush the cache prior to loading the data. In other words:\n\n1) Investigate which backend handler is linked to from the \"Load dummy data\" buttons in the /admin tab\n2) Investigate which backend handler is linked to from the \"Flush cache\" buttons in /release-coordinator (you might need to give yourself release-coordinator permissions on the Roles tab in /admin)\n3) Call the relevant function in (2) from the handlers in (1) prior to loading any data.\n\nIf you would like to take up this issue, please provide an explanation of what your PR will do (with names of files you're changing, what you plan to change in each file, etc.). If it looks good, we can assign you to this issue. Thanks!"
    },
    {
      "id": 1879831494,
      "user": "Aakash-Jakhmola",
      "body": "Hi @seanlip , I would like to take up this issue.\r\n<img width=\"826\" alt=\"Screenshot 2024-01-07 at 02 43 56\" src=\"https://github.com/oppia/oppia/assets/58803066/ac470d1b-ecad-4c36-b36e-90a4d8cc7d27\">\r\n\r\nChanges to be made in core/controllers/admin.py file. "
    },
    {
      "id": 1880158736,
      "user": "seanlip",
      "body": "@Aakash-Jakhmola Seems good, go for it. One note though, please do this caching anywhere it is relevant, not just the method you showed here. Try to do it in a central place if possible so that we can avoid calling it in every function (but if that's not possible, it's OK). Thanks!"
    },
    {
      "id": 1881440817,
      "user": "Aakash-Jakhmola",
      "body": "@seanlip I am not sure what you meant by central place. Do you mean for all methods of admin handler ?"
    },
    {
      "id": 1881450761,
      "user": "seanlip",
      "body": "We'd want to do this for generate_dummy_classroom, generate_dummy_skill_and_questions, etc. as well, right? So maybe we can call this common \"flush cache\" function somewhere in the POST method, just before any regenerations happen, rather than adding it for every generation method.\r\n\r\nEDIT: Though I just realized that decouples the logic somewhat if this method gets called from somewhere else. So perhaps ignore that, it should be OK to add the line to each method that needs it. Please include a comment above it explaining why it's necessary, though.\r\n\r\nAlso, just to confirm, are you able to repro this locally -- does the issue still exist?"
    },
    {
      "id": 1881455309,
      "user": "Aakash-Jakhmola",
      "body": "@seanlip No, i was not able to reproduce it."
    },
    {
      "id": 1881478334,
      "user": "seanlip",
      "body": "OK, hm, given that the last occurrence was in mid-2021, I think I'd suggest that we just update [this wiki page](https://github.com/oppia/oppia/wiki/LaCE-onboarding-guide#3-generating-data-on-localhost) to say, if you run into this error, please go to the release-coordinator page and flush the cache. That way we don't add more stuff to the code, developers are still unblocked, and we can revisit this if it happens again.\r\n\r\n@Aakash-Jakhmola Do you think that seems sensible? If so, would you be up for making a PR to https://github.com/oppia/oppia-web-developer-docs/ instead? Thanks!"
    },
    {
      "id": 2042875113,
      "user": "Ash-2k3",
      "body": "I think, this is working fine now. I have not faced any errors in generating data via this.\r\n\r\n/cc @seanlip "
    },
    {
      "id": 2043983654,
      "user": "seanlip",
      "body": "Ah yup, I think we can close this. Thanks!"
    }
  ],
  "text_context": "# Load dummy new structures data on activities tab for admins isn't working. \n\n**Describe the bug**\r\nI checked out develop and then merged with the updated upstream. I logged on as an admin, gave myself admin privileges and then tried to load the 'Load dummy new structures data' on the activities tab of the admin page. I got a 'Sever error: 'NoneType' object has no attribute 'version'' error. This was working a week ago. There seems to be a problem with getting the version in base_models delete_multi.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n 1. Run the dev server.\r\n 2. Sign on as an admin.\r\n 3. Go to the admin page and give yourself admin rights.\r\n 4. Go to the activities tab of the admin page and click load data for the 'Load dummy new structures data' section.\r\n 5. See error.\r\n\r\n**Screenshots**\r\nYou can see the error on the bottom right of the ui:\r\n<img width=\"1734\" alt=\"Screen Shot 2020-08-24 at 3 58 28 PM\" src=\"https://user-images.githubusercontent.com/19376937/91105057-f3fe6200-e623-11ea-97da-6537c4ff6bb8.png\">\r\n\r\nTerminal output:\r\n<img width=\"1252\" alt=\"Screen Shot 2020-08-24 at 3 58 49 PM\" src=\"https://user-images.githubusercontent.com/19376937/91105019-e1842880-e623-11ea-9968-e6aa7043801b.png\">\r\n\r\n**Desktop (please complete the following information; delete this section if the issue does not arise on desktop):**\r\n - OS: [Catalina, 10.15.16]\r\n - Browser [Chrome]\r\n - Version [84]\n\nYeah even I noticed this, but seems like its fixed now. Can you confirm and close this? @kaylahardie \n\nNo I'm still getting the error @Showtim3, thoughts?\n\n@Hudda had also faced a similar issue and restarting the server had resolved the issue! @Hudda Can you please confirm?\r\n\r\n(just wild guess) Is it happening because of some redis cache/dump? Do you see any dump file in the repo?  [Note: the dump file is in .gitigone so you won't be able to check it through git status]\n\nHi Sandeep,\n\nKevin is working on this one. I've added you to that thread.\n\nThanks,\nAnshul\n\nOn Fri, Aug 28, 2020 at 5:01 AM Sandeep Dubey <notifications@github.com>\nwrote:\n\n> @Hudda <https://github.com/Hudda> had also faced a similar issue and\n> restarting the server had resolved the issue! @Hudda\n> <https://github.com/Hudda> Can you please confirm?\n>\n> (just wild guess) Is it happening because of some redis cache/dump? Do you\n> see any dump file in the repo? [Note: the dump file is in .gitigone so you\n> won't be able to check it through git status]\n>\n> â€”\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/oppia/oppia/issues/10432#issuecomment-682242370>, or\n> unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AG5WB5FIGBCW2HTUJ53B7LLSC3UFBANCNFSM4QKAHBNQ>\n> .\n>\n\n\nHi I already merged the PR that fixed that issue. I don't think this is the same issue because when I merged the PR https://github.com/oppia/oppia/pull/10429, I tested the reload explorations feature and everything seemed to work fine. \r\n\r\nAlso @kaylahardie I also encountered that issue but once I merged from master it seemed to resolve itself.\n\nI'm also facing the issue on updated upstream/develop! (Issue with reloading new_structure dummy data)\n\nI think it's ok now @kevjumba. Is it still an issue for you @DubeySandeep? Can I close this?\n\nIt's still an issue for me, I'm working on a project related to new_strauture and I have to manually create lots of data to test the feature!\r\n\r\n![image](https://user-images.githubusercontent.com/16653571/91647240-0dfdd180-ea76-11ea-96b8-f5ac011e5051.png)\r\n\n\nCurrent workaround: \"Flushing cache\" by going to the \"misc\" tab first before loading data should fix this. \n\nJust as an update: This issue is still reproducible sometimes on the local server. (Though the workaround is working fine!)\r\n\r\n/cc @srijanreddy98 \n\nHi @oppia/core-maintainers, this issue is not assigned to any project. Can you please update the same? Thanks!\n\nUpdate: I'm marking this as a good first issue. The fix is to, in the server handler function corresponding to the \"load dummy data\" action, add a call to flush the cache prior to loading the data. In other words:\n\n1) Investigate which backend handler is linked to from the \"Load dummy data\" buttons in the /admin tab\n2) Investigate which backend handler is linked to from the \"Flush cache\" buttons in /release-coordinator (you might need to give yourself release-coordinator permissions on the Roles tab in /admin)\n3) Call the relevant function in (2) from the handlers in (1) prior to loading any data.\n\nIf you would like to take up this issue, please provide an explanation of what your PR will do (with names of files you're changing, what you plan to change in each file, etc.). If it looks good, we can assign you to this issue. Thanks!\n\nHi @seanlip , I would like to take up this issue.\r\n<img width=\"826\" alt=\"Screenshot 2024-01-07 at 02 43 56\" src=\"https://github.com/oppia/oppia/assets/58803066/ac470d1b-ecad-4c36-b36e-90a4d8cc7d27\">\r\n\r\nChanges to be made in core/controllers/admin.py file. \n\n@Aakash-Jakhmola Seems good, go for it. One note though, please do this caching anywhere it is relevant, not just the method you showed here. Try to do it in a central place if possible so that we can avoid calling it in every function (but if that's not possible, it's OK). Thanks!\n\n@seanlip I am not sure what you meant by central place. Do you mean for all methods of admin handler ?\n\nWe'd want to do this for generate_dummy_classroom, generate_dummy_skill_and_questions, etc. as well, right? So maybe we can call this common \"flush cache\" function somewhere in the POST method, just before any regenerations happen, rather than adding it for every generation method.\r\n\r\nEDIT: Though I just realized that decouples the logic somewhat if this method gets called from somewhere else. So perhaps ignore that, it should be OK to add the line to each method that needs it. Please include a comment above it explaining why it's necessary, though.\r\n\r\nAlso, just to confirm, are you able to repro this locally -- does the issue still exist?\n\n@seanlip No, i was not able to reproduce it.\n\nOK, hm, given that the last occurrence was in mid-2021, I think I'd suggest that we just update [this wiki page](https://github.com/oppia/oppia/wiki/LaCE-onboarding-guide#3-generating-data-on-localhost) to say, if you run into this error, please go to the release-coordinator page and flush the cache. That way we don't add more stuff to the code, developers are still unblocked, and we can revisit this if it happens again.\r\n\r\n@Aakash-Jakhmola Do you think that seems sensible? If so, would you be up for making a PR to https://github.com/oppia/oppia-web-developer-docs/ instead? Thanks!\n\nI think, this is working fine now. I have not faced any errors in generating data via this.\r\n\r\n/cc @seanlip \n\nAh yup, I think we can close this. Thanks!",
  "pr_link": "https://github.com/oppia/oppia/pull/10429",
  "code_context": [
    {
      "filename": "scripts/common.py",
      "content": "# Copyright 2014 The Oppia Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Common utility functions and classes used by multiple Python scripts.\"\"\"\n\nfrom __future__ import absolute_import  # pylint: disable=import-only-modules\nfrom __future__ import unicode_literals  # pylint: disable=import-only-modules\n\nimport contextlib\nimport getpass\nimport os\nimport platform\nimport re\nimport shutil\nimport socket\nimport subprocess\nimport sys\nimport time\n\nimport feconf\nimport python_utils\nimport release_constants\n\n\nCURRENT_PYTHON_BIN = sys.executable\n\n# Versions of libraries used in devflow.\nCOVERAGE_VERSION = '5.1'\nESPRIMA_VERSION = '4.0.1'\nISORT_VERSION = '4.3.21'\nPYCODESTYLE_VERSION = '2.5.0'\nPSUTIL_VERSION = '5.7.0'\nPYLINT_VERSION = '1.9.5'\nPYLINT_QUOTES_VERSION = '0.1.8'\nPYGITHUB_VERSION = '1.45'\nWEBTEST_VERSION = '2.0.35'\n\n# Node version.\nNODE_VERSION = '12.16.2'\n\n# NB: Please ensure that the version is consistent with the version in .yarnrc.\nYARN_VERSION = '1.22.4'\n\n# Versions of libraries used in backend.\nPILLOW_VERSION = '6.2.2'\n\n# We use redis 6.0.5 instead of the latest stable build of redis (6.0.6) because\n# there is a `make test` bug in redis 6.0.6 where the solution has not been\n# released. This is explained in this issue:\n# https://github.com/redis/redis/issues/7540.\n# IMPORTANT STEPS FOR DEVELOPERS TO UPGRADE REDIS:\n# 1. Download the new version of the redis cli.\n# 2. Extract the cli in the folder that it was downloaded, most likely\n#    Downloads/.\n# 3. Change directories into the folder you extracted, titled\n#    redis-<new version>/ and change into that directory:\n#    cd redis-<new version>/\n# 4. From the top level of the redis-<new version> directory,\n#    run `make test`.\n# 5. All of the tests should pass with an [ok] status with no error codes. The\n#    final output should be 'All tests pass'.\n# 6. Be sure to leave a note in the PR description to confirm that you have read\n#    this message, and that all of the `make test` tests pass before you commit\n#    the upgrade to develop.\n# 7. If any tests fail, DO NOT upgrade to this newer version of the redis cli.\nREDIS_CLI_VERSION = '6.0.5'\n\nRELEASE_BRANCH_NAME_PREFIX = 'release-'\nCURR_DIR = os.path.abspath(os.getcwd())\nOPPIA_TOOLS_DIR = os.path.join(CURR_DIR, os.pardir, 'oppia_tools')\nOPPIA_TOOLS_DIR_ABS_PATH = os.path.abspath(OPPIA_TOOLS_DIR)\nTHIRD_PARTY_DIR = os.path.join(CURR_DIR, 'third_party')\nGOOGLE_CLOUD_SDK_HOME = os.path.join(\n    OPPIA_TOOLS_DIR_ABS_PATH, 'google-cloud-sdk-304.0.0', 'google-cloud-sdk')\nGOOGLE_APP_ENGINE_SDK_HOME = os.path.join(\n    GOOGLE_CLOUD_SDK_HOME, 'platform', 'google_appengine')\nGOOGLE_CLOUD_SDK_BIN = os.path.join(GOOGLE_CLOUD_SDK_HOME, 'bin')\nGCLOUD_PATH = os.path.join(GOOGLE_CLOUD_SDK_BIN, 'gcloud')\nNODE_PATH = os.path.join(OPPIA_TOOLS_DIR, 'node-%s' % NODE_VERSION)\nPYLINT_PATH = os.path.join(OPPIA_TOOLS_DIR, 'pylint-%s' % PYLINT_VERSION)\nPYCODESTYLE_PATH = os.path.join(\n    OPPIA_TOOLS_DIR, 'pycodestyle-%s' % PYCODESTYLE_VERSION)\nPYLINT_QUOTES_PATH = os.path.join(\n    OPPIA_TOOLS_DIR, 'pylint-quotes-%s' % PYLINT_QUOTES_VERSION)\nNODE_MODULES_PATH = os.path.join(CURR_DIR, 'node_modules')\nFRONTEND_DIR = os.path.join(CURR_DIR, 'core', 'templates')\nYARN_PATH = os.path.join(OPPIA_TOOLS_DIR, 'yarn-%s' % YARN_VERSION)\nOS_NAME = platform.system()\nARCHITECTURE = platform.machine()\nPSUTIL_DIR = os.path.join(OPPIA_TOOLS_DIR, 'psutil-%s' % PSUTIL_VERSION)\nREDIS_SERVER_PATH = os.path.join(\n    OPPIA_TOOLS_DIR, 'redis-cli-%s' % REDIS_CLI_VERSION,\n    'src', 'redis-server')\nREDIS_CLI_PATH = os.path.join(\n    OPPIA_TOOLS_DIR, 'redis-cli-%s' % REDIS_CLI_VERSION,\n    'src', 'redis-cli')\n\nRELEASE_BRANCH_REGEX = r'release-(\\d+\\.\\d+\\.\\d+)$'\nRELEASE_MAINTENANCE_BRANCH_REGEX = r'release-maintenance-(\\d+\\.\\d+\\.\\d+)$'\nHOTFIX_BRANCH_REGEX = r'release-(\\d+\\.\\d+\\.\\d+)-hotfix-[1-9]+$'\nTEST_BRANCH_REGEX = r'test-[A-Za-z0-9-]*$'\nUSER_PREFERENCES = {'open_new_tab_in_browser': None}\n\nFECONF_PATH = os.path.join('.', 'feconf.py')\nCONSTANTS_FILE_PATH = os.path.join('assets', 'constants.ts')\nMAX_WAIT_TIME_FOR_PORT_TO_OPEN_SECS = 1000\nREDIS_CONF_PATH = os.path.join('.', 'redis.conf')\n# Path for the dump file the redis server autogenerates. It contains data\n# used by the Redis server.\nREDIS_DUMP_PATH = os.path.join(CURR_DIR, 'dump.rdb')\n\n\ndef is_windows_os():\n    \"\"\"Check if the running system is Windows.\"\"\"\n    return OS_NAME == 'Windows'\n\n\ndef is_mac_os():\n    \"\"\"Check if the running system is MacOS.\"\"\"\n    return OS_NAME == 'Darwin'\n\n\ndef is_linux_os():\n    \"\"\"Check if the running system is Linux.\"\"\"\n    return OS_NAME == 'Linux'\n\n\ndef is_x64_architecture():\n    \"\"\"Check if the architecture is on X64.\"\"\"\n    # https://docs.python.org/2/library/platform.html#platform.architecture\n    return sys.maxsize > 2**32\n\n\nNODE_BIN_PATH = os.path.join(\n    NODE_PATH, '' if is_windows_os() else 'bin', 'node')\n\n# Add path for node which is required by the node_modules.\nos.environ['PATH'] = os.pathsep.join([\n    os.path.dirname(NODE_BIN_PATH), os.path.join(YARN_PATH, 'bin'),\n    os.environ['PATH']])\n\n\ndef run_cmd(cmd_tokens):\n    \"\"\"Runs the command and returns the output.\n    Raises subprocess.CalledProcessError upon failure.\n\n    Args:\n        cmd_tokens: list(str). The list of command tokens to execute.\n\n    Returns:\n        str. The output of the command.\n    \"\"\"\n    return subprocess.check_output(cmd_tokens).strip()\n\n\ndef ensure_directory_exists(d):\n    \"\"\"Creates the given directory if it does not already exist.\"\"\"\n    if not os.path.exists(d):\n        os.makedirs(d)\n\n\ndef require_cwd_to_be_oppia(allow_deploy_dir=False):\n    \"\"\"Ensures that the current working directory ends in 'oppia'.\n\n    If allow_deploy_dir is True, this also allows the cwd to be a directory\n    called 'deploy-*' which is a sibling of the oppia/ directory.\n    \"\"\"\n    is_oppia_dir = os.getcwd().endswith('oppia')\n\n    current_dirname = os.path.basename(os.path.normpath(os.getcwd()))\n    is_deploy_dir = (\n        current_dirname.startswith('deploy-') and\n        os.path.isdir(os.path.join(os.getcwd(), os.pardir, 'oppia')))\n\n    if is_oppia_dir or (allow_deploy_dir and is_deploy_dir):\n        return\n\n    raise Exception('Please run this script from the oppia/ directory.')\n\n\ndef open_new_tab_in_browser_if_possible(url):\n    \"\"\"Opens the given URL in a new browser tab, if possible.\"\"\"\n    if USER_PREFERENCES['open_new_tab_in_browser'] is None:\n        python_utils.PRINT(\n            '\\nDo you want the url to be opened in the browser? '\n            'Confirm by entering y/ye/yes.')\n        USER_PREFERENCES['open_new_tab_in_browser'] = python_utils.INPUT()\n    if USER_PREFERENCES['open_new_tab_in_browser'] not in ['y', 'ye', 'yes']:\n        python_utils.PRINT(\n            'Please open the following link in browser: %s' % url)\n        return\n    browser_cmds = ['chromium-browser', 'google-chrome', 'firefox']\n    for cmd in browser_cmds:\n        if subprocess.call(['which', cmd]) == 0:\n            subprocess.check_call([cmd, url])\n            return\n    python_utils.PRINT(\n        '******************************************************************')\n    python_utils.PRINT(\n        'WARNING: Unable to open browser. Please manually open the following')\n    python_utils.PRINT('URL in a browser window, then press Enter to confirm.')\n    python_utils.PRINT('')\n    python_utils.PRINT('    %s' % url)\n    python_utils.PRINT('')\n    python_utils.PRINT(\n        'NOTE: To get rid of this message, open scripts/common.py and fix')\n    python_utils.PRINT(\n        'the function open_new_tab_in_browser_if_possible() to work on your')\n    python_utils.PRINT('system.')\n    python_utils.INPUT()\n\n\ndef get_remote_alias(remote_url):\n    \"\"\"Finds the correct alias for the given remote repository URL.\"\"\"\n    git_remote_output = subprocess.check_output(\n        ['git', 'remote', '-v']).split('\\n')\n    remote_alias = None\n    for line in git_remote_output:\n        if remote_url in line:\n            remote_alias = line.split()[0]\n    if remote_alias is None:\n        raise Exception(\n            'ERROR: There is no existing remote alias for the %s repo.'\n            % remote_url)\n\n    return remote_alias\n\n\ndef verify_local_repo_is_clean():\n    \"\"\"Checks that the local Git repo is clean.\"\"\"\n    git_status_output = subprocess.check_output(\n        ['git', 'status']).strip().split('\\n')\n\n    branch_is_clean_message_1 = 'nothing to commit, working directory clean'\n    branch_is_clean_message_2 = 'nothing to commit, working tree clean'\n    if (\n            not branch_is_clean_message_1 in git_status_output and\n            not branch_is_clean_message_2 in git_status_output):\n        raise Exception(\n            'ERROR: This script should be run from a clean branch.')\n\n\ndef get_current_branch_name():\n    \"\"\"Get the current branch name.\n\n    Returns:\n        str. The name of current branch.\n    \"\"\"\n    git_status_output = subprocess.check_output(\n        ['git', 'status']).strip().split('\\n')\n    branch_message_prefix = 'On branch '\n    git_status_first_line = git_status_output[0]\n    assert git_status_first_line.startswith(branch_message_prefix)\n    return git_status_first_line[len(branch_message_prefix):]\n\n\ndef get_current_release_version_number(release_branch_name):\n    \"\"\"Gets the release version given a release branch name.\n\n    Args:\n        release_branch_name: str. The name of release branch.\n\n    Returns:\n        str. The version of release.\n    \"\"\"\n    release_match = re.match(RELEASE_BRANCH_REGEX, release_branch_name)\n    release_maintenance_match = re.match(\n        RELEASE_MAINTENANCE_BRANCH_REGEX, release_branch_name)\n    hotfix_match = re.match(\n        HOTFIX_BRANCH_REGEX, release_branch_name)\n    if release_match:\n        return release_match.group(1)\n    elif release_maintenance_match:\n        return release_maintenance_match.group(1)\n    elif hotfix_match:\n        return hotfix_match.group(1)\n    else:\n        raise Exception('Invalid branch name: %s.' % release_branch_name)\n\n\ndef is_current_branch_a_hotfix_branch():\n    \"\"\"Checks if the current branch is a hotfix branch.\n\n    Returns:\n        bool. Whether the current branch is hotfix branch.\n    \"\"\"\n    current_branch_name = get_current_branch_name()\n    return bool(\n        re.match(HOTFIX_BRANCH_REGEX, current_branch_name))\n\n\ndef is_current_branch_a_release_branch():\n    \"\"\"Returns whether the current branch is a release branch.\n\n    Returns:\n        bool. Whether the current branch is a release branch.\n    \"\"\"\n    current_branch_name = get_current_branch_name()\n    release_match = bool(re.match(RELEASE_BRANCH_REGEX, current_branch_name))\n    release_maintenance_match = bool(\n        re.match(RELEASE_MAINTENANCE_BRANCH_REGEX, current_branch_name))\n    hotfix_match = bool(\n        re.match(HOTFIX_BRANCH_REGEX, current_branch_name))\n    return release_match or release_maintenance_match or hotfix_match\n\n\ndef is_current_branch_a_test_branch():\n    \"\"\"Returns whether the current branch is a test branch for deployment.\n\n    Returns:\n        bool. Whether the current branch is a test branch for deployment.\n    \"\"\"\n    current_branch_name = get_current_branch_name()\n    return bool(re.match(TEST_BRANCH_REGEX, current_branch_name))\n\n\ndef verify_current_branch_name(expected_branch_name):\n    \"\"\"Checks that the user is on the expected branch.\"\"\"\n    if get_current_branch_name() != expected_branch_name:\n        raise Exception(\n            'ERROR: This script can only be run from the \"%s\" branch.' %\n            expected_branch_name)\n\n\ndef ensure_release_scripts_folder_exists_and_is_up_to_date():\n    \"\"\"Checks that the release-scripts folder exists and is up-to-date.\"\"\"\n    parent_dirpath = os.path.join(os.getcwd(), os.pardir)\n    release_scripts_dirpath = os.path.join(parent_dirpath, 'release-scripts')\n\n    # If the release-scripts folder does not exist, set it up.\n    if not os.path.isdir(release_scripts_dirpath):\n        with CD(parent_dirpath):\n            # Taken from the \"Check your SSH section\" at\n            # https://help.github.com/articles/error-repository-not-found/\n            _, stderr = subprocess.Popen(\n                ['ssh', '-T', 'git@github.com'],\n                stdin=subprocess.PIPE, stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE).communicate()\n            if 'You\\'ve successfully authenticated' not in stderr:\n                raise Exception(\n                    'You need SSH access to GitHub. See the '\n                    '\"Check your SSH access\" section here and follow the '\n                    'instructions: '\n                    'https://help.github.com/articles/'\n                    'error-repository-not-found/#check-your-ssh-access')\n            subprocess.check_call([\n                'git', 'clone',\n                'git@github.com:oppia/release-scripts.git'])\n\n    with CD(release_scripts_dirpath):\n        ask_user_to_confirm(\n            'Please make sure that the ../release-scripts repo is clean and '\n            'you are on master branch in ../release-scripts repo.')\n        python_utils.PRINT('Verifying that ../release-scripts repo is clean...')\n        verify_local_repo_is_clean()\n        python_utils.PRINT(\n            'Verifying that user is on master branch in '\n            '../release-scripts repo...')\n        verify_current_branch_name('master')\n\n        # Update the local repo.\n        remote_alias = get_remote_alias(\n            'git@github.com:oppia/release-scripts.git')\n        subprocess.check_call(['git', 'pull', remote_alias])\n\n\ndef is_port_open(port):\n    \"\"\"Checks if a process is listening to the port.\n\n    Args:\n        port: int. The port number.\n\n    Returns:\n        bool. True if port is open else False.\n    \"\"\"\n    with contextlib.closing(\n        socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:\n        return bool(not s.connect_ex(('localhost', port)))\n\n\ndef recursive_chown(path, uid, gid):\n    \"\"\"Changes the owner and group id of all files in a path to the numeric\n    uid and gid.\n\n    Args:\n        path: str. The path for which owner id and group id need to be setup.\n        uid: int. Owner ID to be set.\n        gid: int. Group ID to be set.\n    \"\"\"\n    os.chown(path, uid, gid)\n    for root, directories, filenames in os.walk(path):\n        for directory in directories:\n            os.chown(os.path.join(root, directory), uid, gid)\n        for filename in filenames:\n            os.chown(os.path.join(root, filename), uid, gid)\n\n\ndef recursive_chmod(path, mode):\n    \"\"\"Changes the mode of path to the passed numeric mode.\n\n    Args:\n        path: str. The path for which mode would be set.\n        mode: int. The mode to be set.\n    \"\"\"\n    os.chmod(path, mode)\n    for root, directories, filenames in os.walk(path):\n        for directory in directories:\n            os.chmod(os.path.join(root, directory), mode)\n        for filename in filenames:\n            os.chmod(os.path.join(root, filename), mode)\n\n\ndef print_each_string_after_two_new_lines(strings):\n    \"\"\"Prints the given strings, separating adjacent strings with two newlines.\n\n    Args:\n        strings: list(str). The strings to print.\n    \"\"\"\n    for string in strings:\n        python_utils.PRINT('%s\\n' % string)\n\n\ndef install_npm_library(library_name, version, path):\n    \"\"\"Installs the npm library after ensuring its not already installed.\n\n    Args:\n        library_name: str. The library name.\n        version: str. The library version.\n        path: str. The installation path for the library.\n    \"\"\"\n    python_utils.PRINT(\n        'Checking whether %s is installed in %s' % (library_name, path))\n    if not os.path.exists(os.path.join(NODE_MODULES_PATH, library_name)):\n        python_utils.PRINT('Installing %s' % library_name)\n        subprocess.check_call([\n            'yarn', 'add', '%s@%s' % (library_name, version)])\n\n\ndef ask_user_to_confirm(message):\n    \"\"\"Asks user to perform a task and confirm once they are done.\n\n    Args:\n        message: str. The message which specifies the task user has\n            to do.\n    \"\"\"\n    while True:\n        python_utils.PRINT(\n            '******************************************************')\n        python_utils.PRINT(message)\n        python_utils.PRINT('Confirm once you are done by entering y/ye/yes.\\n')\n        answer = python_utils.INPUT().lower()\n        if answer in release_constants.AFFIRMATIVE_CONFIRMATIONS:\n            return\n\n\ndef get_personal_access_token():\n    \"\"\"\"Returns the personal access token for the GitHub id of user.\n\n    Returns:\n        str. The personal access token for the GitHub id of user.\n\n    Raises:\n        Exception. Personal access token is None.\n    \"\"\"\n    personal_access_token = getpass.getpass(\n        prompt=(\n            'Please provide personal access token for your github ID. '\n            'You can create one at https://github.com/settings/tokens: '))\n\n    if personal_access_token is None:\n        raise Exception(\n            'No personal access token provided, please set up a personal '\n            'access token at https://github.com/settings/tokens and re-run '\n            'the script')\n    return personal_access_token\n\n\ndef check_blocking_bug_issue_count(repo):\n    \"\"\"Checks the number of unresolved blocking bugs.\n\n    Args:\n        repo: github.Repository.Repository. The PyGithub object for the repo.\n\n    Raises:\n        Exception. Number of unresolved blocking bugs is not zero.\n        Exception. The blocking bug milestone is closed.\n    \"\"\"\n    blocking_bugs_milestone = repo.get_milestone(\n        number=release_constants.BLOCKING_BUG_MILESTONE_NUMBER)\n    if blocking_bugs_milestone.state == 'closed':\n        raise Exception('The blocking bug milestone is closed.')\n    if blocking_bugs_milestone.open_issues:\n        open_new_tab_in_browser_if_possible(\n            'https://github.com/oppia/oppia/issues?q=is%3Aopen+'\n            'is%3Aissue+milestone%3A%22Blocking+bugs%22')\n        raise Exception(\n            'There are %s unresolved blocking bugs. Please ensure '\n            'that they are resolved before release summary generation.' % (\n                blocking_bugs_milestone.open_issues))\n\n\ndef check_prs_for_current_release_are_released(repo):\n    \"\"\"Checks that all pull requests for current release have a\n    'PR: released' label.\n\n    Args:\n        repo: github.Repository.Repository. The PyGithub object for the repo.\n\n    Raises:\n        Exception. Some pull requests for current release do not have a\n            \"PR: released\" label.\n    \"\"\"\n    current_release_label = repo.get_label(\n        release_constants.LABEL_FOR_CURRENT_RELEASE_PRS)\n    current_release_prs = repo.get_issues(\n        state='all', labels=[current_release_label])\n    for pr in current_release_prs:\n        label_names = [label.name for label in pr.labels]\n        if release_constants.LABEL_FOR_RELEASED_PRS not in label_names:\n            open_new_tab_in_browser_if_possible(\n                'https://github.com/oppia/oppia/pulls?utf8=%E2%9C%93&q=is%3Apr'\n                '+label%3A%22PR%3A+for+current+release%22+')\n            raise Exception(\n                'There are PRs for current release which do not have '\n                'a \\'PR: released\\' label. Please ensure that they are '\n                'released before release summary generation.')\n\n\ndef kill_processes_based_on_regex(pattern):\n    \"\"\"Kill any processes whose command line matches the provided regex.\n\n    Args:\n        pattern: str. Pattern for searching processes.\n    \"\"\"\n    regex = re.compile(pattern)\n    if PSUTIL_DIR not in sys.path:\n        sys.path.insert(1, PSUTIL_DIR)\n    import psutil\n    for process in psutil.process_iter():\n        try:\n            cmdline = ' '.join(process.cmdline())\n            if regex.match(cmdline) and process.is_running():\n                python_utils.PRINT('Killing %s ...' % cmdline)\n                process.kill()\n        # Possible exception raised by psutil includes: AccessDenied,\n        # NoSuchProcess, ZombieProcess, TimeoutExpired. We can safely ignore\n        # those ones and continue.\n        # https://psutil.readthedocs.io/en/latest/#exceptions\n        except psutil.Error:\n            continue\n\n\ndef convert_to_posixpath(file_path):\n    \"\"\"Converts a Windows style filepath to posixpath format. If the operating\n    system is not Windows, this function does nothing.\n\n    Args:\n        file_path: str. The path to be converted.\n\n    Returns:\n        str. Returns a posixpath version of the file path.\n    \"\"\"\n    if not is_windows_os():\n        return file_path\n    return file_path.replace('\\\\', '/')\n\n\ndef create_readme(dir_path, readme_content):\n    \"\"\"Creates a readme in a given dir path with the specified\n    readme content.\n\n    Args:\n        dir_path: str. The path of the dir where the README is to\n            be created.\n        readme_content: str. The content to be written in the README.\n    \"\"\"\n    with python_utils.open_file(os.path.join(dir_path, 'README.md'), 'w') as f:\n        f.write(readme_content)\n\n\ndef inplace_replace_file(filename, regex_pattern, replacement_string):\n    \"\"\"Replace the file content in-place with regex pattern. The pattern is used\n    to replace the file's content line by line.\n\n    Note:\n        This function should only be used with files that are processed line by\n            line.\n\n    Args:\n        filename: str. The name of the file to be changed.\n        regex_pattern: str. The pattern to check.\n        replacement_string: str. The content to be replaced.\n    \"\"\"\n    backup_filename = '%s.bak' % filename\n    shutil.copyfile(filename, backup_filename)\n    new_contents = []\n    try:\n        regex = re.compile(regex_pattern)\n        with python_utils.open_file(backup_filename, 'r') as f:\n            for line in f:\n                new_contents.append(regex.sub(replacement_string, line))\n\n        with python_utils.open_file(filename, 'w') as f:\n            for line in new_contents:\n                f.write(line)\n        os.remove(backup_filename)\n    except Exception:\n        # Restore the content if there was en error.\n        os.remove(filename)\n        shutil.move(backup_filename, filename)\n        raise\n\n\ndef wait_for_port_to_be_open(port_number):\n    \"\"\"Wait until the port is open and exit if port isn't open after\n    1000 seconds.\n\n    Args:\n        port_number: int. The port number to wait.\n    \"\"\"\n    waited_seconds = 0\n    while (not is_port_open(port_number)\n           and waited_seconds < MAX_WAIT_TIME_FOR_PORT_TO_OPEN_SECS):\n        time.sleep(1)\n        waited_seconds += 1\n    if (waited_seconds == MAX_WAIT_TIME_FOR_PORT_TO_OPEN_SECS\n            and not is_port_open(port_number)):\n        python_utils.PRINT(\n            'Failed to start server on port %s, exiting ...' %\n            port_number)\n        sys.exit(1)\n\n\ndef start_redis_server():\n    \"\"\"Start the redis server with the daemonize argument to prevent\n    the redis-server from exiting on its own.\n    \"\"\"\n    if is_windows_os():\n        raise Exception(\n            'The redis command line interface is not installed because your '\n            'machine is on the Windows operating system. The redis server '\n            'cannot start.')\n\n    # Check if a redis dump file currently exists. This file contains residual\n    # data from a previous run of the redis server. If it exists, removes the\n    # dump file so that the redis server starts with a clean slate.\n    if os.path.exists(REDIS_DUMP_PATH):\n        os.remove(REDIS_DUMP_PATH)\n\n    # Redis-cli is only required in a development environment.\n    python_utils.PRINT('Starting Redis development server.')\n    # Start the redis local development server. Redis doesn't run on\n    # Windows machines.\n    subprocess.call([\n        REDIS_SERVER_PATH, REDIS_CONF_PATH,\n        '--daemonize', 'yes'\n    ])\n    wait_for_port_to_be_open(feconf.REDISPORT)\n\n\ndef stop_redis_server():\n    \"\"\"Stops the redis server by shutting it down.\"\"\"\n    if is_windows_os():\n        raise Exception(\n            'The redis command line interface is not installed because your '\n            'machine is on the Windows operating system. There is no redis '\n            'server to shutdown.')\n\n    python_utils.PRINT('Cleaning up the redis_servers.')\n    # Shutdown the redis server before exiting.\n    subprocess.call([REDIS_CLI_PATH, 'shutdown'])\n\n\nclass CD(python_utils.OBJECT):\n    \"\"\"Context manager for changing the current working directory.\"\"\"\n\n    def __init__(self, new_path):\n        self.new_path = new_path\n        self.saved_path = None\n\n    def __enter__(self):\n        self.saved_path = os.getcwd()\n        os.chdir(self.new_path)\n\n    def __exit__(self, etype, value, traceback):\n        os.chdir(self.saved_path)\n"
    },
    {
      "filename": "scripts/common_test.py",
      "content": "#\n# Copyright 2019 The Oppia Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Unit tests for scripts/common.py.\"\"\"\n\nfrom __future__ import absolute_import  # pylint: disable=import-only-modules\nfrom __future__ import unicode_literals  # pylint: disable=import-only-modules\n\nimport contextlib\nimport getpass\nimport http.server\nimport os\nimport re\nimport shutil\nimport socketserver\nimport stat\nimport subprocess\nimport sys\nimport tempfile\n\nfrom core.tests import test_utils\n\nimport psutil\nimport python_utils\nimport release_constants\n\n\nfrom . import common\n\n_PARENT_DIR = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n_PY_GITHUB_PATH = os.path.join(\n    _PARENT_DIR, 'oppia_tools', 'PyGithub-%s' % common.PYGITHUB_VERSION)\nsys.path.insert(0, _PY_GITHUB_PATH)\n\nimport github # isort:skip  pylint: disable=wrong-import-position\n\n\nclass MockPsutilProcess(python_utils.OBJECT):\n    \"\"\"A mock class for Process class in Psutil.\"\"\"\n\n    cmdlines = [\n        ['dev_appserver.py', '--host', '0.0.0.0', '--port', '9001'],\n        ['downloads']\n    ]\n\n    def __init__(self, index):\n        \"\"\"Constructor for this mock object.\n\n        Args:\n            index: int. The index of process to be checked.\n        \"\"\"\n        self.index = index\n\n    def cmdline(self):\n        \"\"\"Return the command line of this process.\"\"\"\n        pass\n\n    def kill(self):\n        \"\"\"Kill the process.\"\"\"\n        pass\n\n    def is_running(self):\n        \"\"\"Check whether the function is running.\"\"\"\n        return True\n\n\nclass CommonTests(test_utils.GenericTestBase):\n    \"\"\"Test the methods which handle common functionalities.\"\"\"\n\n    def test_is_x64_architecture_in_x86(self):\n        maxsize_swap = self.swap(sys, 'maxsize', 1)\n        with maxsize_swap:\n            self.assertFalse(common.is_x64_architecture())\n\n    def test_is_x64_architecture_in_x64(self):\n        maxsize_swap = self.swap(sys, 'maxsize', 2**32 + 1)\n        with maxsize_swap:\n            self.assertTrue(common.is_x64_architecture())\n\n    def test_run_cmd(self):\n        self.assertEqual(\n            common.run_cmd(('echo Test for common.py ').split(' ')),\n            'Test for common.py')\n\n    def test_ensure_directory_exists_with_existing_dir(self):\n        check_function_calls = {\n            'makedirs_gets_called': False\n        }\n        def mock_makedirs(unused_dirpath):\n            check_function_calls['makedirs_gets_called'] = True\n        with self.swap(os, 'makedirs', mock_makedirs):\n            common.ensure_directory_exists('assets')\n        self.assertEqual(check_function_calls, {'makedirs_gets_called': False})\n\n    def test_ensure_directory_exists_with_non_existing_dir(self):\n        check_function_calls = {\n            'makedirs_gets_called': False\n        }\n        def mock_makedirs(unused_dirpath):\n            check_function_calls['makedirs_gets_called'] = True\n        with self.swap(os, 'makedirs', mock_makedirs):\n            common.ensure_directory_exists('test-dir')\n        self.assertEqual(check_function_calls, {'makedirs_gets_called': True})\n\n    def test_require_cwd_to_be_oppia_with_correct_cwd_and_unallowed_deploy_dir(\n            self):\n        common.require_cwd_to_be_oppia()\n\n    def test_require_cwd_to_be_oppia_with_correct_cwd_and_allowed_deploy_dir(\n            self):\n        common.require_cwd_to_be_oppia(allow_deploy_dir=True)\n\n    def test_require_cwd_to_be_oppia_with_wrong_cwd_and_unallowed_deploy_dir(\n            self):\n        def mock_getcwd():\n            return 'invalid'\n        getcwd_swap = self.swap(os, 'getcwd', mock_getcwd)\n        with getcwd_swap, self.assertRaisesRegexp(\n            Exception, 'Please run this script from the oppia/ directory.'):\n            common.require_cwd_to_be_oppia()\n\n    def test_require_cwd_to_be_oppia_with_wrong_cwd_and_allowed_deploy_dir(\n            self):\n        def mock_getcwd():\n            return 'invalid'\n        def mock_basename(unused_dirpath):\n            return 'deploy-dir'\n        def mock_isdir(unused_dirpath):\n            return True\n        getcwd_swap = self.swap(os, 'getcwd', mock_getcwd)\n        basename_swap = self.swap(os.path, 'basename', mock_basename)\n        isdir_swap = self.swap(os.path, 'isdir', mock_isdir)\n        with getcwd_swap, basename_swap, isdir_swap:\n            common.require_cwd_to_be_oppia(allow_deploy_dir=True)\n\n    def test_open_new_tab_in_browser_if_possible_with_user_manually_opening_url(\n            self):\n        try:\n            check_function_calls = {\n                'input_gets_called': 0,\n                'check_call_gets_called': False\n            }\n            expected_check_function_calls = {\n                'input_gets_called': 1,\n                'check_call_gets_called': False\n            }\n            def mock_call(unused_cmd_tokens):\n                return 0\n            def mock_check_call(unused_cmd_tokens):\n                check_function_calls['check_call_gets_called'] = True\n            def mock_input():\n                check_function_calls['input_gets_called'] += 1\n                return 'n'\n            call_swap = self.swap(subprocess, 'call', mock_call)\n            check_call_swap = self.swap(\n                subprocess, 'check_call', mock_check_call)\n            input_swap = self.swap(python_utils, 'INPUT', mock_input)\n            with call_swap, check_call_swap, input_swap:\n                common.open_new_tab_in_browser_if_possible('test-url')\n            self.assertEqual(\n                check_function_calls, expected_check_function_calls)\n        finally:\n            common.USER_PREFERENCES['open_new_tab_in_browser'] = None\n\n    def test_open_new_tab_in_browser_if_possible_with_url_opening_correctly(\n            self):\n        try:\n            check_function_calls = {\n                'input_gets_called': 0,\n                'check_call_gets_called': False\n            }\n            expected_check_function_calls = {\n                'input_gets_called': 1,\n                'check_call_gets_called': True\n            }\n            def mock_call(unused_cmd_tokens):\n                return 0\n            def mock_check_call(unused_cmd_tokens):\n                check_function_calls['check_call_gets_called'] = True\n            def mock_input():\n                check_function_calls['input_gets_called'] += 1\n                return 'y'\n            call_swap = self.swap(subprocess, 'call', mock_call)\n            check_call_swap = self.swap(\n                subprocess, 'check_call', mock_check_call)\n            input_swap = self.swap(python_utils, 'INPUT', mock_input)\n            with call_swap, check_call_swap, input_swap:\n                common.open_new_tab_in_browser_if_possible('test-url')\n            self.assertEqual(\n                check_function_calls, expected_check_function_calls)\n        finally:\n            common.USER_PREFERENCES['open_new_tab_in_browser'] = None\n\n    def test_open_new_tab_in_browser_if_possible_with_url_not_opening_correctly(\n            self):\n        try:\n            check_function_calls = {\n                'input_gets_called': 0,\n                'check_call_gets_called': False\n            }\n            expected_check_function_calls = {\n                'input_gets_called': 2,\n                'check_call_gets_called': False\n            }\n            def mock_call(unused_cmd_tokens):\n                return 1\n            def mock_check_call(unused_cmd_tokens):\n                check_function_calls['check_call_gets_called'] = True\n            def mock_input():\n                check_function_calls['input_gets_called'] += 1\n                return 'y'\n            call_swap = self.swap(subprocess, 'call', mock_call)\n            check_call_swap = self.swap(\n                subprocess, 'check_call', mock_check_call)\n            input_swap = self.swap(python_utils, 'INPUT', mock_input)\n            with call_swap, check_call_swap, input_swap:\n                common.open_new_tab_in_browser_if_possible('test-url')\n            self.assertEqual(\n                check_function_calls, expected_check_function_calls)\n        finally:\n            common.USER_PREFERENCES['open_new_tab_in_browser'] = None\n\n    def test_get_remote_alias_with_correct_alias(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'remote1 url1\\nremote2 url2'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            self.assertEqual(common.get_remote_alias('url1'), 'remote1')\n\n    def test_get_remote_alias_with_incorrect_alias(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'remote1 url1\\nremote2 url2'\n        check_output_swap = self.swap(\n            subprocess, 'check_output', mock_check_output)\n        with check_output_swap, self.assertRaisesRegexp(\n            Exception,\n            'ERROR: There is no existing remote alias for the url3 repo.'):\n            common.get_remote_alias('url3')\n\n    def test_verify_local_repo_is_clean_with_clean_repo(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'nothing to commit, working directory clean'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            common.verify_local_repo_is_clean()\n\n    def test_verify_local_repo_is_clean_with_unclean_repo(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'invalid'\n        check_output_swap = self.swap(\n            subprocess, 'check_output', mock_check_output)\n        with check_output_swap, self.assertRaisesRegexp(\n            Exception, 'ERROR: This script should be run from a clean branch.'):\n            common.verify_local_repo_is_clean()\n\n    def test_get_current_branch_name(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'On branch test'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            self.assertEqual(common.get_current_branch_name(), 'test')\n\n    def test_get_current_release_version_number_with_non_hotfix_branch(self):\n        self.assertEqual(\n            common.get_current_release_version_number('release-1.2.3'), '1.2.3')\n\n    def test_get_current_release_version_number_with_hotfix_branch(self):\n        self.assertEqual(\n            common.get_current_release_version_number('release-1.2.3-hotfix-1'),\n            '1.2.3')\n\n    def test_get_current_release_version_number_with_maintenance_branch(self):\n        self.assertEqual(\n            common.get_current_release_version_number(\n                'release-maintenance-1.2.3'), '1.2.3')\n\n    def test_get_current_release_version_number_with_invalid_branch(self):\n        with self.assertRaisesRegexp(\n            Exception, 'Invalid branch name: invalid-branch.'):\n            common.get_current_release_version_number('invalid-branch')\n\n    def test_is_current_branch_a_hotfix_branch_with_non_hotfix_branch(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'On branch release-1.2.3'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            self.assertEqual(common.is_current_branch_a_hotfix_branch(), False)\n\n    def test_is_current_branch_a_hotfix_branch_with_hotfix_branch(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'On branch release-1.2.3-hotfix-1'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            self.assertEqual(common.is_current_branch_a_hotfix_branch(), True)\n\n    def test_is_current_branch_a_release_branch_with_release_branch(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'On branch release-1.2.3'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            self.assertEqual(common.is_current_branch_a_release_branch(), True)\n\n    def test_is_current_branch_a_release_branch_with_hotfix_branch(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'On branch release-1.2.3-hotfix-1'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            self.assertEqual(common.is_current_branch_a_release_branch(), True)\n\n    def test_is_current_branch_a_release_branch_with_maintenance_branch(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'On branch release-maintenance-1.2.3'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            self.assertEqual(common.is_current_branch_a_release_branch(), True)\n\n    def test_is_current_branch_a_release_branch_with_non_release_branch(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'On branch test'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            self.assertEqual(common.is_current_branch_a_release_branch(), False)\n\n    def test_is_current_branch_a_test_branch_with_test_branch(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'On branch test-common'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            self.assertEqual(common.is_current_branch_a_test_branch(), True)\n\n    def test_is_current_branch_a_test_branch_with_non_test_branch(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'On branch invalid-test'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            self.assertEqual(common.is_current_branch_a_test_branch(), False)\n\n    def test_verify_current_branch_name_with_correct_branch(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'On branch test'\n        with self.swap(\n            subprocess, 'check_output', mock_check_output):\n            common.verify_current_branch_name('test')\n\n    def test_verify_current_branch_name_with_incorrect_branch(self):\n        def mock_check_output(unused_cmd_tokens):\n            return 'On branch invalid'\n        check_output_swap = self.swap(\n            subprocess, 'check_output', mock_check_output)\n        with check_output_swap, self.assertRaisesRegexp(\n            Exception,\n            'ERROR: This script can only be run from the \"test\" branch.'):\n            common.verify_current_branch_name('test')\n\n    def test_ensure_release_scripts_folder_exists_with_invalid_access(self):\n        process = subprocess.Popen(['test'], stdout=subprocess.PIPE)\n        def mock_isdir(unused_dirpath):\n            return False\n        def mock_chdir(unused_dirpath):\n            pass\n        def mock_popen(unused_cmd, stdin, stdout, stderr):  # pylint: disable=unused-argument\n            return process\n        def mock_communicate(unused_self):\n            return ('Output', 'Invalid')\n        isdir_swap = self.swap(os.path, 'isdir', mock_isdir)\n        chdir_swap = self.swap(os, 'chdir', mock_chdir)\n        popen_swap = self.swap(subprocess, 'Popen', mock_popen)\n        communicate_swap = self.swap(\n            subprocess.Popen, 'communicate', mock_communicate)\n        with isdir_swap, chdir_swap, popen_swap, communicate_swap:\n            with self.assertRaisesRegexp(\n                Exception, (\n                    'You need SSH access to GitHub. See the '\n                    '\"Check your SSH access\" section here and follow the '\n                    'instructions: '\n                    'https://help.github.com/articles/'\n                    'error-repository-not-found/#check-your-ssh-access')):\n                common.ensure_release_scripts_folder_exists_and_is_up_to_date()\n\n    def test_ensure_release_scripts_folder_exists_with_valid_access(self):\n        process = subprocess.Popen(['test'], stdout=subprocess.PIPE)\n        def mock_isdir(unused_dirpath):\n            return False\n        def mock_chdir(unused_dirpath):\n            pass\n        def mock_popen(unused_cmd, stdin, stdout, stderr):  # pylint: disable=unused-argument\n            return process\n        def mock_communicate(unused_self):\n            return ('Output', 'You\\'ve successfully authenticated!')\n        def mock_check_call(unused_cmd_tokens):\n            pass\n        def mock_verify_local_repo_is_clean():\n            pass\n        def mock_verify_current_branch_name(unused_branch_name):\n            pass\n        def mock_get_remote_alias(unused_url):\n            return 'remote'\n        def mock_ask_user_to_confirm(unused_msg):\n            pass\n        isdir_swap = self.swap(os.path, 'isdir', mock_isdir)\n        chdir_swap = self.swap(os, 'chdir', mock_chdir)\n        popen_swap = self.swap(subprocess, 'Popen', mock_popen)\n        communicate_swap = self.swap(\n            subprocess.Popen, 'communicate', mock_communicate)\n        check_call_swap = self.swap(\n            subprocess, 'check_call', mock_check_call)\n        verify_local_repo_swap = self.swap(\n            common, 'verify_local_repo_is_clean',\n            mock_verify_local_repo_is_clean)\n        verify_current_branch_name_swap = self.swap(\n            common, 'verify_current_branch_name',\n            mock_verify_current_branch_name)\n        get_remote_alias_swap = self.swap(\n            common, 'get_remote_alias', mock_get_remote_alias)\n        ask_user_swap = self.swap(\n            common, 'ask_user_to_confirm', mock_ask_user_to_confirm)\n        with isdir_swap, chdir_swap, popen_swap, communicate_swap:\n            with check_call_swap, verify_local_repo_swap, ask_user_swap:\n                with verify_current_branch_name_swap, get_remote_alias_swap:\n                    (\n                        common\n                        .ensure_release_scripts_folder_exists_and_is_up_to_date(\n                            ))\n\n    def test_is_port_open(self):\n        self.assertFalse(common.is_port_open(4444))\n\n        handler = http.server.SimpleHTTPRequestHandler\n        httpd = socketserver.TCPServer(('', 4444), handler)\n\n        self.assertTrue(common.is_port_open(4444))\n        httpd.server_close()\n\n    def test_permissions_of_file(self):\n        root_temp_dir = tempfile.mkdtemp()\n        temp_dirpath = tempfile.mkdtemp(dir=root_temp_dir)\n        temp_file = tempfile.NamedTemporaryFile(dir=temp_dirpath)\n        temp_file.name = 'temp_file'\n        temp_file_path = os.path.join(temp_dirpath, 'temp_file')\n        with python_utils.open_file(temp_file_path, 'w') as f:\n            f.write('content')\n\n        common.recursive_chown(root_temp_dir, os.getuid(), -1)\n        common.recursive_chmod(root_temp_dir, 0o744)\n\n        for root, directories, filenames in os.walk(root_temp_dir):\n            for directory in directories:\n                self.assertEqual(\n                    oct(stat.S_IMODE(\n                        os.stat(os.path.join(root, directory)).st_mode)),\n                    '0744')\n                self.assertEqual(\n                    os.stat(os.path.join(root, directory)).st_uid, os.getuid())\n\n            for filename in filenames:\n                self.assertEqual(\n                    oct(stat.S_IMODE(\n                        os.stat(os.path.join(root, filename)).st_mode)), '0744')\n                self.assertEqual(\n                    os.stat(os.path.join(root, filename)).st_uid, os.getuid())\n\n        shutil.rmtree(root_temp_dir)\n\n    def test_print_each_string_after_two_new_lines(self):\n        @contextlib.contextmanager\n        def _redirect_stdout(new_target):\n            \"\"\"Redirect stdout to the new target.\n\n            Args:\n                new_target: TextIOWrapper. The new target to which stdout is\n                    redirected.\n\n            Yields:\n                TextIOWrapper. The new target.\n            \"\"\"\n            old_target = sys.stdout\n            sys.stdout = new_target\n            try:\n                yield new_target\n            finally:\n                sys.stdout = old_target\n\n        target_stdout = python_utils.string_io()\n        with _redirect_stdout(target_stdout):\n            common.print_each_string_after_two_new_lines([\n                'These', 'are', 'sample', 'strings.'])\n\n        self.assertEqual(\n            target_stdout.getvalue(), 'These\\n\\nare\\n\\nsample\\n\\nstrings.\\n\\n')\n\n    def test_install_npm_library(self):\n\n        def _mock_subprocess_check_call(unused_command):\n            \"\"\"Mocks subprocess.check_call() to create a temporary file instead\n            of the actual npm library.\n            \"\"\"\n            temp_file = tempfile.NamedTemporaryFile()\n            temp_file.name = 'temp_file'\n            with python_utils.open_file('temp_file', 'w') as f:\n                f.write('content')\n\n            self.assertTrue(os.path.exists('temp_file'))\n            temp_file.close()\n\n        self.assertFalse(os.path.exists('temp_file'))\n\n        with self.swap(subprocess, 'check_call', _mock_subprocess_check_call):\n            common.install_npm_library('library_name', 'version', 'path')\n\n    def test_ask_user_to_confirm(self):\n        def mock_input():\n            return 'Y'\n        with self.swap(python_utils, 'INPUT', mock_input):\n            common.ask_user_to_confirm('Testing')\n\n    def test_get_personal_access_token_with_valid_token(self):\n        def mock_getpass(prompt):  # pylint: disable=unused-argument\n            return 'token'\n        with self.swap(getpass, 'getpass', mock_getpass):\n            self.assertEqual(common.get_personal_access_token(), 'token')\n\n    def test_get_personal_access_token_with_token_as_none(self):\n        def mock_getpass(prompt):  # pylint: disable=unused-argument\n            return None\n        getpass_swap = self.swap(getpass, 'getpass', mock_getpass)\n        with getpass_swap, self.assertRaisesRegexp(\n            Exception,\n            'No personal access token provided, please set up a personal '\n            'access token at https://github.com/settings/tokens and re-run '\n            'the script'):\n            common.get_personal_access_token()\n\n    def test_closed_blocking_bugs_milestone_results_in_exception(self):\n        mock_repo = github.Repository.Repository(\n            requester='', headers='', attributes={}, completed='')\n        def mock_get_milestone(unused_self, number):  # pylint: disable=unused-argument\n            return github.Milestone.Milestone(\n                requester='', headers='',\n                attributes={'state': 'closed'}, completed='')\n        get_milestone_swap = self.swap(\n            github.Repository.Repository, 'get_milestone', mock_get_milestone)\n        with get_milestone_swap, self.assertRaisesRegexp(\n            Exception, 'The blocking bug milestone is closed.'):\n            common.check_blocking_bug_issue_count(mock_repo)\n\n    def test_non_zero_blocking_bug_issue_count_results_in_exception(self):\n        mock_repo = github.Repository.Repository(\n            requester='', headers='', attributes={}, completed='')\n        def mock_open_tab(unused_url):\n            pass\n        def mock_get_milestone(unused_self, number):  # pylint: disable=unused-argument\n            return github.Milestone.Milestone(\n                requester='', headers='',\n                attributes={'open_issues': 10, 'state': 'open'}, completed='')\n        get_milestone_swap = self.swap(\n            github.Repository.Repository, 'get_milestone', mock_get_milestone)\n        open_tab_swap = self.swap(\n            common, 'open_new_tab_in_browser_if_possible', mock_open_tab)\n        with get_milestone_swap, open_tab_swap, self.assertRaisesRegexp(\n            Exception, (\n                'There are 10 unresolved blocking bugs. Please '\n                'ensure that they are resolved before release '\n                'summary generation.')):\n            common.check_blocking_bug_issue_count(mock_repo)\n\n    def test_zero_blocking_bug_issue_count_results_in_no_exception(self):\n        mock_repo = github.Repository.Repository(\n            requester='', headers='', attributes={}, completed='')\n        def mock_get_milestone(unused_self, number):  # pylint: disable=unused-argument\n            return github.Milestone.Milestone(\n                requester='', headers='',\n                attributes={'open_issues': 0, 'state': 'open'}, completed='')\n        with self.swap(\n            github.Repository.Repository, 'get_milestone', mock_get_milestone):\n            common.check_blocking_bug_issue_count(mock_repo)\n\n    def test_check_prs_for_current_release_are_released_with_no_unreleased_prs(\n            self):\n        mock_repo = github.Repository.Repository(\n            requester='', headers='', attributes={}, completed='')\n        pull1 = github.PullRequest.PullRequest(\n            requester='', headers='',\n            attributes={\n                'title': 'PR1', 'number': 1, 'labels': [\n                    {'name': release_constants.LABEL_FOR_RELEASED_PRS},\n                    {'name': release_constants.LABEL_FOR_CURRENT_RELEASE_PRS}]},\n            completed='')\n        pull2 = github.PullRequest.PullRequest(\n            requester='', headers='',\n            attributes={\n                'title': 'PR2', 'number': 2, 'labels': [\n                    {'name': release_constants.LABEL_FOR_RELEASED_PRS},\n                    {'name': release_constants.LABEL_FOR_CURRENT_RELEASE_PRS}]},\n            completed='')\n        label = github.Label.Label(\n            requester='', headers='',\n            attributes={\n                'name': release_constants.LABEL_FOR_CURRENT_RELEASE_PRS},\n            completed='')\n        def mock_get_issues(unused_self, state, labels):  # pylint: disable=unused-argument\n            return [pull1, pull2]\n        def mock_get_label(unused_self, unused_name):\n            return [label]\n\n        get_issues_swap = self.swap(\n            github.Repository.Repository, 'get_issues', mock_get_issues)\n        get_label_swap = self.swap(\n            github.Repository.Repository, 'get_label', mock_get_label)\n        with get_issues_swap, get_label_swap:\n            common.check_prs_for_current_release_are_released(mock_repo)\n\n    def test_check_prs_for_current_release_are_released_with_unreleased_prs(\n            self):\n        mock_repo = github.Repository.Repository(\n            requester='', headers='', attributes={}, completed='')\n        def mock_open_tab(unused_url):\n            pass\n        pull1 = github.PullRequest.PullRequest(\n            requester='', headers='',\n            attributes={\n                'title': 'PR1', 'number': 1, 'labels': [\n                    {'name': release_constants.LABEL_FOR_CURRENT_RELEASE_PRS}]},\n            completed='')\n        pull2 = github.PullRequest.PullRequest(\n            requester='', headers='',\n            attributes={\n                'title': 'PR2', 'number': 2, 'labels': [\n                    {'name': release_constants.LABEL_FOR_RELEASED_PRS},\n                    {'name': release_constants.LABEL_FOR_CURRENT_RELEASE_PRS}]},\n            completed='')\n        label = github.Label.Label(\n            requester='', headers='',\n            attributes={\n                'name': release_constants.LABEL_FOR_CURRENT_RELEASE_PRS},\n            completed='')\n        def mock_get_issues(unused_self, state, labels):  # pylint: disable=unused-argument\n            return [pull1, pull2]\n        def mock_get_label(unused_self, unused_name):\n            return [label]\n\n        get_issues_swap = self.swap(\n            github.Repository.Repository, 'get_issues', mock_get_issues)\n        get_label_swap = self.swap(\n            github.Repository.Repository, 'get_label', mock_get_label)\n        open_tab_swap = self.swap(\n            common, 'open_new_tab_in_browser_if_possible', mock_open_tab)\n        with get_issues_swap, get_label_swap, open_tab_swap:\n            with self.assertRaisesRegexp(\n                Exception, (\n                    'There are PRs for current release which do not '\n                    'have a \\'%s\\' label. Please ensure that '\n                    'they are released before release summary '\n                    'generation.') % (\n                        release_constants.LABEL_FOR_RELEASED_PRS)):\n                common.check_prs_for_current_release_are_released(mock_repo)\n\n    def test_kill_processes_based_on_regex(self):\n        killed = []\n\n        def mock_kill(p):\n            killed.append(MockPsutilProcess.cmdlines[p.index])\n\n        def mock_cmdlines(p):\n            return MockPsutilProcess.cmdlines[p.index]\n\n        def mock_process_iter():\n            return [MockPsutilProcess(0), MockPsutilProcess(1)]\n\n        process_iter_swap = self.swap_with_checks(\n            psutil, 'process_iter', mock_process_iter)\n        kill_swap = self.swap(MockPsutilProcess, 'kill', mock_kill)\n        cmdlines_swap = self.swap(MockPsutilProcess, 'cmdline', mock_cmdlines)\n        with process_iter_swap, kill_swap, cmdlines_swap:\n            common.kill_processes_based_on_regex(r'.*dev_appserver\\.py')\n        self.assertEqual(killed, [MockPsutilProcess.cmdlines[0]])\n\n    def test_kill_processes_based_on_regex_when_access_denied(self):\n        killed = []\n\n        def mock_kill(p):\n            killed.append(MockPsutilProcess.cmdlines[p.index])\n\n        def mock_cmdlines(p):\n            if p.index == 0:\n                raise psutil.AccessDenied()\n            return MockPsutilProcess.cmdlines[p.index]\n\n        def mock_process_iter():\n            return [MockPsutilProcess(0), MockPsutilProcess(1)]\n\n        process_iter_swap = self.swap_with_checks(\n            psutil, 'process_iter', mock_process_iter)\n        kill_swap = self.swap(MockPsutilProcess, 'kill', mock_kill)\n        cmdlines_swap = self.swap(MockPsutilProcess, 'cmdline', mock_cmdlines)\n        with process_iter_swap, kill_swap, cmdlines_swap:\n            common.kill_processes_based_on_regex(r'.*dev_appserver\\.py')\n        self.assertEqual(killed, [])\n\n    def test_kill_process_when_psutil_not_in_path(self):\n        path_swap = self.swap(sys, 'path', [])\n        def mock_process_iter():\n            return []\n        process_iter_swap = self.swap(psutil, 'process_iter', mock_process_iter)\n        with path_swap, process_iter_swap:\n            common.kill_processes_based_on_regex('')\n\n    def test_inplace_replace_file(self):\n        origin_file = os.path.join(\n            'core', 'tests', 'data', 'inplace_replace_test.json')\n        backup_file = os.path.join(\n            'core', 'tests', 'data', 'inplace_replace_test.json.bak')\n        expected_lines = [\n            '{\\n',\n            '    \"RANDMON1\" : \"randomValue1\",\\n',\n            '    \"312RANDOM\" : \"ValueRanDom2\",\\n',\n            '    \"DEV_MODE\": true,\\n',\n            '    \"RAN213DOM\" : \"raNdoVaLue3\"\\n',\n            '}\\n'\n        ]\n\n        def mock_remove(unused_file):\n            return\n\n        remove_swap = self.swap_with_checks(\n            os, 'remove', mock_remove, expected_args=[(backup_file,)]\n        )\n        with remove_swap:\n            common.inplace_replace_file(\n                origin_file, '\"DEV_MODE\": .*', '\"DEV_MODE\": true,')\n        with python_utils.open_file(origin_file, 'r') as f:\n            self.assertEqual(expected_lines, f.readlines())\n        # Revert the file.\n        os.remove(origin_file)\n        shutil.move(backup_file, origin_file)\n\n    def test_inplace_replace_file_with_exception_raised(self):\n        origin_file = os.path.join(\n            'core', 'tests', 'data', 'inplace_replace_test.json')\n        backup_file = os.path.join(\n            'core', 'tests', 'data', 'inplace_replace_test.json.bak')\n        with python_utils.open_file(origin_file, 'r') as f:\n            origin_content = f.readlines()\n\n        def mock_compile(unused_arg):\n            raise ValueError('Exception raised from compile()')\n\n        compile_swap = self.swap_with_checks(re, 'compile', mock_compile)\n        with self.assertRaisesRegexp(\n            ValueError, r'Exception raised from compile\\(\\)'), compile_swap:\n            common.inplace_replace_file(\n                origin_file, '\"DEV_MODE\": .*', '\"DEV_MODE\": true,')\n        self.assertFalse(os.path.isfile(backup_file))\n        with python_utils.open_file(origin_file, 'r') as f:\n            new_content = f.readlines()\n        self.assertEqual(origin_content, new_content)\n\n    def test_convert_to_posixpath_on_windows(self):\n        def mock_is_windows():\n            return True\n\n        is_windows_swap = self.swap(common, 'is_windows_os', mock_is_windows)\n        original_filepath = 'c:\\\\path\\\\to\\\\a\\\\file.js'\n        with is_windows_swap:\n            actual_file_path = common.convert_to_posixpath(original_filepath)\n        self.assertEqual(actual_file_path, 'c:/path/to/a/file.js')\n\n    def test_convert_to_posixpath_on_platform_other_than_windows(self):\n        def mock_is_windows():\n            return False\n\n        is_windows_swap = self.swap(common, 'is_windows_os', mock_is_windows)\n        original_filepath = 'c:\\\\path\\\\to\\\\a\\\\file.js'\n        with is_windows_swap:\n            actual_file_path = common.convert_to_posixpath(original_filepath)\n        self.assertEqual(actual_file_path, original_filepath)\n\n    def test_create_readme(self):\n        try:\n            os.makedirs('readme_test_dir')\n            common.create_readme('readme_test_dir', 'Testing readme.')\n            with python_utils.open_file('readme_test_dir/README.md', 'r') as f:\n                self.assertEqual(f.read(), 'Testing readme.')\n        finally:\n            if os.path.exists('readme_test_dir'):\n                shutil.rmtree('readme_test_dir')\n\n    def test_windows_os_throws_exception_when_starting_redis_server(self):\n        def mock_is_windows_os():\n            return True\n        windows_not_supported_exception = self.assertRaisesRegexp(\n            Exception,\n            'The redis command line interface is not installed because your '\n            'machine is on the Windows operating system. The redis server '\n            'cannot start.')\n        swap_os_check = self.swap(common, 'is_windows_os', mock_is_windows_os)\n        with swap_os_check, windows_not_supported_exception:\n            common.start_redis_server()\n\n    def test_windows_os_throws_exception_when_stopping_redis_server(self):\n        def mock_is_windows_os():\n            return True\n        windows_not_supported_exception = self.assertRaisesRegexp(\n            Exception,\n            'The redis command line interface is not installed because your '\n            'machine is on the Windows operating system. There is no redis '\n            'server to shutdown.')\n        swap_os_check = self.swap(common, 'is_windows_os', mock_is_windows_os)\n\n        with swap_os_check, windows_not_supported_exception:\n            common.stop_redis_server()\n\n    def test_start_and_stop_server_calls_are_called(self):\n        # Test that starting the server calls subprocess.call().\n        check_function_calls = {\n            'subprocess_call_is_called': False\n        }\n        expected_check_function_calls = {\n            'subprocess_call_is_called': True\n        }\n\n        def mock_call(unused_cmd_tokens, *args, **kwargs):  # pylint: disable=unused-argument\n            check_function_calls['subprocess_call_is_called'] = True\n            class Ret(python_utils.OBJECT):\n                \"\"\"Return object with required attributes.\"\"\"\n\n                def __init__(self):\n                    self.returncode = 0\n                def communicate(self):\n                    \"\"\"Return required method.\"\"\"\n                    return '', ''\n            return Ret()\n\n        def mock_wait_for_port_to_be_open(port): # pylint: disable=unused-argument\n            return\n\n        swap_call = self.swap(subprocess, 'call', mock_call)\n        swap_wait_for_port_to_be_open = self.swap(\n            common, 'wait_for_port_to_be_open',\n            mock_wait_for_port_to_be_open)\n        with swap_call, swap_wait_for_port_to_be_open:\n            common.start_redis_server()\n\n        self.assertEqual(check_function_calls, expected_check_function_calls)\n\n        # Test that stopping the server calls subprocess.call().\n        check_function_calls = {\n            'subprocess_call_is_called': False\n        }\n        expected_check_function_calls = {\n            'subprocess_call_is_called': True\n        }\n\n        swap_call = self.swap(subprocess, 'call', mock_call)\n        with swap_call:\n            common.stop_redis_server()\n\n        self.assertEqual(check_function_calls, expected_check_function_calls)\n\n    def test_start_server_removes_redis_dump(self):\n        check_function_calls = {\n            'os_remove_is_called': False\n        }\n\n        def mock_os_remove_file(file_path): # pylint: disable=unused-argument\n            check_function_calls['os_remove_is_called'] = True\n\n        def mock_os_path_exists(file_path): # pylint: disable=unused-argument\n            return True\n\n        def mock_call(unused_cmd_tokens, *args, **kwargs):  # pylint: disable=unused-argument\n            class Ret(python_utils.OBJECT):\n                \"\"\"Return object with required attributes.\"\"\"\n\n                def __init__(self):\n                    self.returncode = 0\n                def communicate(self):\n                    \"\"\"Return required method.\"\"\"\n                    return '', ''\n            return Ret()\n\n        def mock_wait_for_port_to_be_open(port): # pylint: disable=unused-argument\n            return\n\n        swap_call = self.swap(subprocess, 'call', mock_call)\n        swap_wait_for_port_to_be_open = self.swap(\n            common, 'wait_for_port_to_be_open',\n            mock_wait_for_port_to_be_open)\n        swap_os_remove = self.swap(os, 'remove', mock_os_remove_file)\n        swap_os_path_exists = self.swap(os.path, 'exists', mock_os_path_exists)\n        with swap_call, swap_wait_for_port_to_be_open, swap_os_remove, (\n            swap_os_path_exists):\n            common.start_redis_server()\n\n        self.assertTrue(check_function_calls['os_remove_is_called'])\n"
    }
  ]
}