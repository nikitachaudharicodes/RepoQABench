{
  "repo_name": "scipy_scipy",
  "issue_id": "2534",
  "issue_description": "# The sparse .sum() method with uint8 dtype does not act like the corresponding numpy method.\n\nWith NumPy calling the `.sum()` method along an axis upcasts the dtype from uint8 to uint64, probably to prevent rolling over back to 0:\n\n```\nIn [9]: np.matrix([[1, 255],\n                   [0, 0]], dtype=np.uint8).sum(1)\nOut[9]: matrix([256,   0], dtype=uint64)\n```\n\nWith the sparse package in SciPy, there is no upcasting, so 255 + 1 rolls over to 0. For the same data we get:\n\n```\n In [11]: sp.csc_matrix(np.array([[1, 255],\n                                  [0, 0]], dtype=np.uint8)).sum(1)\n Out[11]: \n matrix([[0],\n         [0]], dtype=uint8)\n```\n\nThe shapes are different too...\n\nSo should Sparse copy numpy's upcasting behavior? \n",
  "issue_comments": [
    {
      "id": 18795576,
      "user": "cowlicks",
      "body": "Am I not able to add labels to issues I created? This issue should be labeled with scipy.sparse\n"
    },
    {
      "id": 18860165,
      "user": "pv",
      "body": "Yes, I think this should be changed to match Numpy behavior. Numpy also IIRC used to work like this, but the accumulator type was bumped up to a larger one at some point. The expected behavior probably is: use platform integer (or, the spmatrix type if it is larger) as the accumulator.\n\nAlso, the reduction methods should gain a dtype argument.\n\nI think there we need mixed input and output type versions of the reduction routines in sparsetools. This again grows the SWIG wrappers...\n\nDeprecation of the old behavior is probably not doable here. Someone relying on the accumulator being of a smaller type is probably not so common occurrence (in contrast, there have been a number of people complaining on stackoverflow etc being surprised about the wraparound), so I think it is possible to change this behavior.\n"
    },
    {
      "id": 18953381,
      "user": "cowlicks",
      "body": "So... The `.mean()` and `.sum()` (and probably other) methods in sparse return results that are the same dtype as the spmatrix. In numpy these methods upcast to the platform default float or integer.\n\n@pv What do you mean by \"reduction methods\"?\n\nI don't think I understand you correctly, you say deprecation is \"not doable\", but then \"it is possible to change this behavior.\"\n"
    },
    {
      "id": 18960979,
      "user": "pv",
      "body": "\"Reduction\" is Numpy jargon for sum(), prod(), ...\n\nBy \"not doable\" I mean that it is not possible to make this change in stages, as the change of the accumulator type will cause backward incompatibility in any case, and trying to lessen this impact makes things worse.\n"
    },
    {
      "id": 18982728,
      "user": "cowlicks",
      "body": "Okay, I am including a change in the accumulator type in my next PR for bool dtype support.\n"
    },
    {
      "id": 187920336,
      "user": "Tiepies",
      "body": "@cowlicks @pv It seems that the `.sum()` method of SciPy sparse matrices is still not in line with the NumPy  `.sum()` method in terms of upcasting behavior. The original example of this issue still results in the same discrepancy (integer overflow for sparse matrices, upcasting for dense matrices) (SciPy 0.18.0.dev0+b2eea7c):\n\n```\nIn [19]: np.matrix([[1, 255],\n                    [0, 0]], dtype=np.uint8).sum(1)\nOut[19]: \nmatrix([[256],\n        [  0]], dtype=uint64)\n\n\nIn [20]: sp.csc_matrix(np.array([[1, 255],\n                                 [0, 0]], dtype=np.uint8)).sum(1)\nOut[20]: \nmatrix([[0],\n        [0]], dtype=uint8)\n\n```\n"
    },
    {
      "id": 187922468,
      "user": "pv",
      "body": "Fixable via `np.int_ -> np.integral`, `np.float_ -> np.floating` in the lines touched by gh-2549\n"
    },
    {
      "id": 188083495,
      "user": "maniteja123",
      "body": "If I remember it correctly, it should be `np.integer` right ? Please correct me if I am wrong.\n"
    },
    {
      "id": 188388583,
      "user": "Tiepies",
      "body": "@maniteja123  `np.integer` seems to be the correct fix, yes. \n\nI can easily submit a PR with the fix, but I am unsure what test to add to sparse/tests/test_base.py. The `.math_dtypes` attributes of the matrix class based tests only consist of `[np.bool_, np.int_, np.float_, np.complex_]`, so `.test_sum()` never tests for integer upcasting behavior.\n"
    },
    {
      "id": 188494799,
      "user": "cowlicks",
      "body": "@Tiepies looking at my previous PR I think `test_base.py` is okay.\n\nI have not seen `np.integer` and `np.floating` before, so maybe they are new. Which would explain why they are not used in the sparse tests.\n"
    },
    {
      "id": 188911991,
      "user": "Tiepies",
      "body": "@cowlicks your PR indeed tested for this, but PR #5213 reduced the type coverage by replacing `self.checked_dtypes` with `self.math_dtypes`, which means the upcasting behavior is not tested for anymore. I am not comfortable with touching the tests, because I do not fully grasp the reason for this change.\n"
    },
    {
      "id": 189037185,
      "user": "perimosocordiae",
      "body": "Yep, that PR was my doing. The whole dtype testing situation is still a bit of a mess, unfortunately, but [this comment](https://github.com/scipy/scipy/pull/5213#issuecomment-138990519) should hopefully clear up some confusion.\n\nThe takeaway is that we haven't ever been testing for correct upcasting behavior, though we thought that we were before my PR.\n\nPossible fixes include:\n1. adding `np.int8` to `math_dtypes` (will likely require fixing other bugs to make things pass)\n2. changing `test_sum` to use `checked_dtypes` instead of `math_dtypes`\n\nIn the long run, we want to have option (1), but for the scope of this PR, option (2) should be sufficient.\n"
    }
  ],
  "text_context": "# The sparse .sum() method with uint8 dtype does not act like the corresponding numpy method.\n\nWith NumPy calling the `.sum()` method along an axis upcasts the dtype from uint8 to uint64, probably to prevent rolling over back to 0:\n\n```\nIn [9]: np.matrix([[1, 255],\n                   [0, 0]], dtype=np.uint8).sum(1)\nOut[9]: matrix([256,   0], dtype=uint64)\n```\n\nWith the sparse package in SciPy, there is no upcasting, so 255 + 1 rolls over to 0. For the same data we get:\n\n```\n In [11]: sp.csc_matrix(np.array([[1, 255],\n                                  [0, 0]], dtype=np.uint8)).sum(1)\n Out[11]: \n matrix([[0],\n         [0]], dtype=uint8)\n```\n\nThe shapes are different too...\n\nSo should Sparse copy numpy's upcasting behavior? \n\n\nAm I not able to add labels to issues I created? This issue should be labeled with scipy.sparse\n\n\nYes, I think this should be changed to match Numpy behavior. Numpy also IIRC used to work like this, but the accumulator type was bumped up to a larger one at some point. The expected behavior probably is: use platform integer (or, the spmatrix type if it is larger) as the accumulator.\n\nAlso, the reduction methods should gain a dtype argument.\n\nI think there we need mixed input and output type versions of the reduction routines in sparsetools. This again grows the SWIG wrappers...\n\nDeprecation of the old behavior is probably not doable here. Someone relying on the accumulator being of a smaller type is probably not so common occurrence (in contrast, there have been a number of people complaining on stackoverflow etc being surprised about the wraparound), so I think it is possible to change this behavior.\n\n\nSo... The `.mean()` and `.sum()` (and probably other) methods in sparse return results that are the same dtype as the spmatrix. In numpy these methods upcast to the platform default float or integer.\n\n@pv What do you mean by \"reduction methods\"?\n\nI don't think I understand you correctly, you say deprecation is \"not doable\", but then \"it is possible to change this behavior.\"\n\n\n\"Reduction\" is Numpy jargon for sum(), prod(), ...\n\nBy \"not doable\" I mean that it is not possible to make this change in stages, as the change of the accumulator type will cause backward incompatibility in any case, and trying to lessen this impact makes things worse.\n\n\nOkay, I am including a change in the accumulator type in my next PR for bool dtype support.\n\n\n@cowlicks @pv It seems that the `.sum()` method of SciPy sparse matrices is still not in line with the NumPy  `.sum()` method in terms of upcasting behavior. The original example of this issue still results in the same discrepancy (integer overflow for sparse matrices, upcasting for dense matrices) (SciPy 0.18.0.dev0+b2eea7c):\n\n```\nIn [19]: np.matrix([[1, 255],\n                    [0, 0]], dtype=np.uint8).sum(1)\nOut[19]: \nmatrix([[256],\n        [  0]], dtype=uint64)\n\n\nIn [20]: sp.csc_matrix(np.array([[1, 255],\n                                 [0, 0]], dtype=np.uint8)).sum(1)\nOut[20]: \nmatrix([[0],\n        [0]], dtype=uint8)\n\n```\n\n\nFixable via `np.int_ -> np.integral`, `np.float_ -> np.floating` in the lines touched by gh-2549\n\n\nIf I remember it correctly, it should be `np.integer` right ? Please correct me if I am wrong.\n\n\n@maniteja123  `np.integer` seems to be the correct fix, yes. \n\nI can easily submit a PR with the fix, but I am unsure what test to add to sparse/tests/test_base.py. The `.math_dtypes` attributes of the matrix class based tests only consist of `[np.bool_, np.int_, np.float_, np.complex_]`, so `.test_sum()` never tests for integer upcasting behavior.\n\n\n@Tiepies looking at my previous PR I think `test_base.py` is okay.\n\nI have not seen `np.integer` and `np.floating` before, so maybe they are new. Which would explain why they are not used in the sparse tests.\n\n\n@cowlicks your PR indeed tested for this, but PR #5213 reduced the type coverage by replacing `self.checked_dtypes` with `self.math_dtypes`, which means the upcasting behavior is not tested for anymore. I am not comfortable with touching the tests, because I do not fully grasp the reason for this change.\n\n\nYep, that PR was my doing. The whole dtype testing situation is still a bit of a mess, unfortunately, but [this comment](https://github.com/scipy/scipy/pull/5213#issuecomment-138990519) should hopefully clear up some confusion.\n\nThe takeaway is that we haven't ever been testing for correct upcasting behavior, though we thought that we were before my PR.\n\nPossible fixes include:\n1. adding `np.int8` to `math_dtypes` (will likely require fixing other bugs to make things pass)\n2. changing `test_sum` to use `checked_dtypes` instead of `math_dtypes`\n\nIn the long run, we want to have option (1), but for the scope of this PR, option (2) should be sufficient.\n",
  "pr_link": "https://github.com/scipy/scipy/pull/5213",
  "code_context": [
    {
      "filename": "scipy/sparse/bsr.py",
      "content": "\"\"\"Compressed Block Sparse Row matrix format\"\"\"\nfrom __future__ import division, print_function, absolute_import\n\n\n__docformat__ = \"restructuredtext en\"\n\n__all__ = ['bsr_matrix', 'isspmatrix_bsr']\n\nfrom warnings import warn\n\nimport numpy as np\n\nfrom .data import _data_matrix, _minmax_mixin\nfrom .compressed import _cs_matrix\nfrom .base import isspmatrix, _formats\nfrom .sputils import isshape, getdtype, to_native, upcast, get_index_dtype\nfrom . import _sparsetools\nfrom ._sparsetools import (bsr_matvec, bsr_matvecs, csr_matmat_pass1,\n                           bsr_matmat_pass2, bsr_transpose, bsr_sort_indices)\n\n\nclass bsr_matrix(_cs_matrix, _minmax_mixin):\n    \"\"\"Block Sparse Row matrix\n\n    This can be instantiated in several ways:\n        bsr_matrix(D, [blocksize=(R,C)])\n            where D is a dense matrix or 2-D ndarray.\n\n        bsr_matrix(S, [blocksize=(R,C)])\n            with another sparse matrix S (equivalent to S.tobsr())\n\n        bsr_matrix((M, N), [blocksize=(R,C), dtype])\n            to construct an empty matrix with shape (M, N)\n            dtype is optional, defaulting to dtype='d'.\n\n        bsr_matrix((data, ij), [blocksize=(R,C), shape=(M, N)])\n            where ``data`` and ``ij`` satisfy ``a[ij[0, k], ij[1, k]] = data[k]``\n\n        bsr_matrix((data, indices, indptr), [shape=(M, N)])\n            is the standard BSR representation where the block column\n            indices for row i are stored in ``indices[indptr[i]:indptr[i+1]]``\n            and their corresponding block values are stored in\n            ``data[ indptr[i]: indptr[i+1] ]``.  If the shape parameter is not\n            supplied, the matrix dimensions are inferred from the index arrays.\n\n    Attributes\n    ----------\n    dtype : dtype\n        Data type of the matrix\n    shape : 2-tuple\n        Shape of the matrix\n    ndim : int\n        Number of dimensions (this is always 2)\n    nnz\n        Number of nonzero elements\n    data\n        Data array of the matrix\n    indices\n        BSR format index array\n    indptr\n        BSR format index pointer array\n    blocksize\n        Block size of the matrix\n    has_sorted_indices\n        Whether indices are sorted\n\n    Notes\n    -----\n    Sparse matrices can be used in arithmetic operations: they support\n    addition, subtraction, multiplication, division, and matrix power.\n\n    **Summary of BSR format**\n\n    The Block Compressed Row (BSR) format is very similar to the Compressed\n    Sparse Row (CSR) format.  BSR is appropriate for sparse matrices with dense\n    sub matrices like the last example below.  Block matrices often arise in\n    vector-valued finite element discretizations.  In such cases, BSR is\n    considerably more efficient than CSR and CSC for many sparse arithmetic\n    operations.\n\n    **Blocksize**\n\n    The blocksize (R,C) must evenly divide the shape of the matrix (M,N).\n    That is, R and C must satisfy the relationship ``M % R = 0`` and\n    ``N % C = 0``.\n\n    If no blocksize is specified, a simple heuristic is applied to determine\n    an appropriate blocksize.\n\n    Examples\n    --------\n    >>> from scipy.sparse import bsr_matrix\n    >>> bsr_matrix((3, 4), dtype=np.int8).toarray()\n    array([[0, 0, 0, 0],\n           [0, 0, 0, 0],\n           [0, 0, 0, 0]], dtype=int8)\n\n    >>> row = np.array([0, 0, 1, 2, 2, 2])\n    >>> col = np.array([0, 2, 2, 0, 1, 2])\n    >>> data = np.array([1, 2, 3 ,4, 5, 6])\n    >>> bsr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n    array([[1, 0, 2],\n           [0, 0, 3],\n           [4, 5, 6]])\n\n    >>> indptr = np.array([0, 2, 3, 6])\n    >>> indices = np.array([0, 2, 2, 0, 1, 2])\n    >>> data = np.array([1, 2, 3, 4, 5, 6]).repeat(4).reshape(6, 2, 2)\n    >>> bsr_matrix((data,indices,indptr), shape=(6, 6)).toarray()\n    array([[1, 1, 0, 0, 2, 2],\n           [1, 1, 0, 0, 2, 2],\n           [0, 0, 0, 0, 3, 3],\n           [0, 0, 0, 0, 3, 3],\n           [4, 4, 5, 5, 6, 6],\n           [4, 4, 5, 5, 6, 6]])\n\n    \"\"\"\n    def __init__(self, arg1, shape=None, dtype=None, copy=False, blocksize=None):\n        _data_matrix.__init__(self)\n\n        if isspmatrix(arg1):\n            if isspmatrix_bsr(arg1) and copy:\n                arg1 = arg1.copy()\n            else:\n                arg1 = arg1.tobsr(blocksize=blocksize)\n            self._set_self(arg1)\n\n        elif isinstance(arg1,tuple):\n            if isshape(arg1):\n                # it's a tuple of matrix dimensions (M,N)\n                self.shape = arg1\n                M,N = self.shape\n                # process blocksize\n                if blocksize is None:\n                    blocksize = (1,1)\n                else:\n                    if not isshape(blocksize):\n                        raise ValueError('invalid blocksize=%s' % blocksize)\n                    blocksize = tuple(blocksize)\n                self.data = np.zeros((0,) + blocksize, getdtype(dtype, default=float))\n\n                R,C = blocksize\n                if (M % R) != 0 or (N % C) != 0:\n                    raise ValueError('shape must be multiple of blocksize')\n\n                idx_dtype = get_index_dtype(maxval=N//C)\n                self.indices = np.zeros(0, dtype=idx_dtype)\n                self.indptr = np.zeros(M//R + 1, dtype=idx_dtype)\n\n            elif len(arg1) == 2:\n                # (data,(row,col)) format\n                from .coo import coo_matrix\n                self._set_self(coo_matrix(arg1, dtype=dtype).tobsr(blocksize=blocksize))\n\n            elif len(arg1) == 3:\n                # (data,indices,indptr) format\n                (data, indices, indptr) = arg1\n                idx_dtype = get_index_dtype((indices, indptr), check_contents=True)\n                self.indices = np.array(indices, copy=copy, dtype=idx_dtype)\n                self.indptr = np.array(indptr, copy=copy, dtype=idx_dtype)\n                self.data = np.array(data, copy=copy, dtype=getdtype(dtype, data))\n            else:\n                raise ValueError('unrecognized bsr_matrix constructor usage')\n        else:\n            # must be dense\n            try:\n                arg1 = np.asarray(arg1)\n            except:\n                raise ValueError(\"unrecognized form for\"\n                        \" %s_matrix constructor\" % self.format)\n            from .coo import coo_matrix\n            arg1 = coo_matrix(arg1, dtype=dtype).tobsr(blocksize=blocksize)\n            self._set_self(arg1)\n\n        if shape is not None:\n            self.shape = shape   # spmatrix will check for errors\n        else:\n            if self.shape is None:\n                # shape not already set, try to infer dimensions\n                try:\n                    M = len(self.indptr) - 1\n                    N = self.indices.max() + 1\n                except:\n                    raise ValueError('unable to infer matrix dimensions')\n                else:\n                    R,C = self.blocksize\n                    self.shape = (M*R,N*C)\n\n        if self.shape is None:\n            if shape is None:\n                # TODO infer shape here\n                raise ValueError('need to infer shape')\n            else:\n                self.shape = shape\n\n        if dtype is not None:\n            self.data = self.data.astype(dtype)\n\n        self.check_format(full_check=False)\n\n    def check_format(self, full_check=True):\n        \"\"\"check whether the matrix format is valid\n\n            *Parameters*:\n                full_check:\n                    True  - rigorous check, O(N) operations : default\n                    False - basic check, O(1) operations\n\n        \"\"\"\n        M,N = self.shape\n        R,C = self.blocksize\n\n        # index arrays should have integer data types\n        if self.indptr.dtype.kind != 'i':\n            warn(\"indptr array has non-integer dtype (%s)\"\n                    % self.indptr.dtype.name)\n        if self.indices.dtype.kind != 'i':\n            warn(\"indices array has non-integer dtype (%s)\"\n                    % self.indices.dtype.name)\n\n        idx_dtype = get_index_dtype((self.indices, self.indptr))\n        self.indptr = np.asarray(self.indptr, dtype=idx_dtype)\n        self.indices = np.asarray(self.indices, dtype=idx_dtype)\n        self.data = to_native(self.data)\n\n        # check array shapes\n        if self.indices.ndim != 1 or self.indptr.ndim != 1:\n            raise ValueError(\"indices, and indptr should be 1-D\")\n        if self.data.ndim != 3:\n            raise ValueError(\"data should be 3-D\")\n\n        # check index pointer\n        if (len(self.indptr) != M//R + 1):\n            raise ValueError(\"index pointer size (%d) should be (%d)\" %\n                                (len(self.indptr), M//R + 1))\n        if (self.indptr[0] != 0):\n            raise ValueError(\"index pointer should start with 0\")\n\n        # check index and data arrays\n        if (len(self.indices) != len(self.data)):\n            raise ValueError(\"indices and data should have the same size\")\n        if (self.indptr[-1] > len(self.indices)):\n            raise ValueError(\"Last value of index pointer should be less than \"\n                                \"the size of index and data arrays\")\n\n        self.prune()\n\n        if full_check:\n            # check format validity (more expensive)\n            if self.nnz > 0:\n                if self.indices.max() >= N//C:\n                    raise ValueError(\"column index values must be < %d (now max %d)\" % (N//C, self.indices.max()))\n                if self.indices.min() < 0:\n                    raise ValueError(\"column index values must be >= 0\")\n                if np.diff(self.indptr).min() < 0:\n                    raise ValueError(\"index pointer values must form a \"\n                                        \"non-decreasing sequence\")\n\n        # if not self.has_sorted_indices():\n        #    warn('Indices were not in sorted order. Sorting indices.')\n        #    self.sort_indices(check_first=False)\n\n    def _get_blocksize(self):\n        return self.data.shape[1:]\n    blocksize = property(fget=_get_blocksize)\n\n    def getnnz(self):\n        R,C = self.blocksize\n        return int(self.indptr[-1] * R * C)\n    nnz = property(fget=getnnz)\n\n    def __repr__(self):\n        nnz = self.getnnz()\n        format = self.getformat()\n        return \"<%dx%d sparse matrix of type '%s'\\n\" \\\n               \"\\twith %d stored elements (blocksize = %dx%d) in %s format>\" % \\\n               (self.shape + (self.dtype.type, nnz) + self.blocksize +\n                 (_formats[format][1],))\n\n    def diagonal(self):\n        \"\"\"Returns the main diagonal of the matrix\n        \"\"\"\n        M,N = self.shape\n        R,C = self.blocksize\n        y = np.empty(min(M,N), dtype=upcast(self.dtype))\n        _sparsetools.bsr_diagonal(M//R, N//C, R, C,\n                                  self.indptr, self.indices,\n                                  np.ravel(self.data), y)\n        return y\n\n    ##########################\n    # NotImplemented methods #\n    ##########################\n\n    def getdata(self,ind):\n        raise NotImplementedError\n\n    def __getitem__(self,key):\n        raise NotImplementedError\n\n    def __setitem__(self,key,val):\n        raise NotImplementedError\n\n    ######################\n    # Arithmetic methods #\n    ######################\n\n    def matvec(self, other):\n        return self * other\n\n    def matmat(self, other):\n        return self * other\n\n    def _mul_vector(self, other):\n        M,N = self.shape\n        R,C = self.blocksize\n\n        result = np.zeros(self.shape[0], dtype=upcast(self.dtype, other.dtype))\n\n        bsr_matvec(M//R, N//C, R, C,\n            self.indptr, self.indices, self.data.ravel(),\n            other, result)\n\n        return result\n\n    def _mul_multivector(self,other):\n        R,C = self.blocksize\n        M,N = self.shape\n        n_vecs = other.shape[1]  # number of column vectors\n\n        result = np.zeros((M,n_vecs), dtype=upcast(self.dtype,other.dtype))\n\n        bsr_matvecs(M//R, N//C, n_vecs, R, C,\n                self.indptr, self.indices, self.data.ravel(),\n                other.ravel(), result.ravel())\n\n        return result\n\n    def _mul_sparse_matrix(self, other):\n        M, K1 = self.shape\n        K2, N = other.shape\n\n        R,n = self.blocksize\n\n        # convert to this format\n        if isspmatrix_bsr(other):\n            C = other.blocksize[1]\n        else:\n            C = 1\n\n        from .csr import isspmatrix_csr\n\n        if isspmatrix_csr(other) and n == 1:\n            other = other.tobsr(blocksize=(n,C), copy=False)  # lightweight conversion\n        else:\n            other = other.tobsr(blocksize=(n,C))\n\n        idx_dtype = get_index_dtype((self.indptr, self.indices,\n                                     other.indptr, other.indices),\n                                    maxval=(M//R)*(N//C))\n        indptr = np.empty(self.indptr.shape, dtype=idx_dtype)\n\n        csr_matmat_pass1(M//R, N//C,\n                         self.indptr.astype(idx_dtype),\n                         self.indices.astype(idx_dtype),\n                         other.indptr.astype(idx_dtype),\n                         other.indices.astype(idx_dtype),\n                         indptr)\n\n        bnnz = indptr[-1]\n\n        idx_dtype = get_index_dtype((self.indptr, self.indices,\n                                     other.indptr, other.indices),\n                                    maxval=bnnz)\n        indptr = indptr.astype(idx_dtype)\n        indices = np.empty(bnnz, dtype=idx_dtype)\n        data = np.empty(R*C*bnnz, dtype=upcast(self.dtype,other.dtype))\n\n        bsr_matmat_pass2(M//R, N//C, R, C, n,\n                         self.indptr.astype(idx_dtype),\n                         self.indices.astype(idx_dtype),\n                         np.ravel(self.data),\n                         other.indptr.astype(idx_dtype),\n                         other.indices.astype(idx_dtype),\n                         np.ravel(other.data),\n                         indptr,\n                         indices,\n                         data)\n\n        data = data.reshape(-1,R,C)\n\n        # TODO eliminate zeros\n\n        return bsr_matrix((data,indices,indptr),shape=(M,N),blocksize=(R,C))\n\n    ######################\n    # Conversion methods #\n    ######################\n\n    def tobsr(self,blocksize=None,copy=False):\n        if blocksize not in [None, self.blocksize]:\n            return self.tocsr().tobsr(blocksize=blocksize)\n        if copy:\n            return self.copy()\n        else:\n            return self\n\n    def tocsr(self):\n        return self.tocoo(copy=False).tocsr()\n        # TODO make this more efficient\n\n    def tocsc(self):\n        return self.tocoo(copy=False).tocsc()\n\n    def tocoo(self,copy=True):\n        \"\"\"Convert this matrix to COOrdinate format.\n\n        When copy=False the data array will be shared between\n        this matrix and the resultant coo_matrix.\n        \"\"\"\n\n        M,N = self.shape\n        R,C = self.blocksize\n\n        indptr_diff = np.diff(self.indptr)\n        if indptr_diff.dtype.itemsize > np.dtype(np.intp).itemsize:\n            # Check for potential overflow\n            indptr_diff_limited = indptr_diff.astype(np.intp)\n            if np.any(indptr_diff_limited != indptr_diff):\n                raise ValueError(\"Matrix too big to convert\")\n            indptr_diff = indptr_diff_limited\n\n        row = (R * np.arange(M//R)).repeat(indptr_diff)\n        row = row.repeat(R*C).reshape(-1,R,C)\n        row += np.tile(np.arange(R).reshape(-1,1), (1,C))\n        row = row.reshape(-1)\n\n        col = (C * self.indices).repeat(R*C).reshape(-1,R,C)\n        col += np.tile(np.arange(C), (R,1))\n        col = col.reshape(-1)\n\n        data = self.data.reshape(-1)\n\n        if copy:\n            data = data.copy()\n\n        from .coo import coo_matrix\n        return coo_matrix((data,(row,col)), shape=self.shape)\n\n    def transpose(self):\n\n        R,C = self.blocksize\n        M,N = self.shape\n        NBLK = self.nnz//(R*C)\n\n        if self.nnz == 0:\n            return bsr_matrix((N,M), blocksize=(C,R),\n                              dtype=self.dtype)\n\n        indptr = np.empty(N//C + 1, dtype=self.indptr.dtype)\n        indices = np.empty(NBLK, dtype=self.indices.dtype)\n        data = np.empty((NBLK,C,R), dtype=self.data.dtype)\n\n        bsr_transpose(M//R, N//C, R, C,\n                      self.indptr, self.indices, self.data.ravel(),\n                      indptr, indices, data.ravel())\n\n        return bsr_matrix((data,indices,indptr), shape=(N,M))\n\n    ##############################################################\n    # methods that examine or modify the internal data structure #\n    ##############################################################\n\n    def eliminate_zeros(self):\n        R,C = self.blocksize\n        M,N = self.shape\n\n        mask = (self.data != 0).reshape(-1,R*C).sum(axis=1)  # nonzero blocks\n\n        nonzero_blocks = mask.nonzero()[0]\n\n        if len(nonzero_blocks) == 0:\n            return  # nothing to do\n\n        self.data[:len(nonzero_blocks)] = self.data[nonzero_blocks]\n\n        from .csr import csr_matrix\n\n        # modifies self.indptr and self.indices *in place*\n        # since CSR constructor may end up in making copies (in case\n        # our index arrays are invalid in some way), play it safe\n        proxy = csr_matrix((mask,self.indices,self.indptr),shape=(M//R,N//C))\n        proxy.indices = self.indices\n        proxy.indptr = self.indptr\n        proxy.eliminate_zeros()\n\n        self.prune()\n\n    def sum_duplicates(self):\n        raise NotImplementedError\n\n    def sort_indices(self):\n        \"\"\"Sort the indices of this matrix *in place*\n        \"\"\"\n        if self.has_sorted_indices:\n            return\n\n        R,C = self.blocksize\n        M,N = self.shape\n\n        bsr_sort_indices(M//R, N//C, R, C, self.indptr, self.indices, self.data.ravel())\n\n        self.has_sorted_indices = True\n\n    def prune(self):\n        \"\"\" Remove empty space after all non-zero elements.\n        \"\"\"\n\n        R,C = self.blocksize\n        M,N = self.shape\n\n        if len(self.indptr) != M//R + 1:\n            raise ValueError(\"index pointer has invalid length\")\n\n        bnnz = self.indptr[-1]\n\n        if len(self.indices) < bnnz:\n            raise ValueError(\"indices array has too few elements\")\n        if len(self.data) < bnnz:\n            raise ValueError(\"data array has too few elements\")\n\n        self.data = self.data[:bnnz]\n        self.indices = self.indices[:bnnz]\n\n    # utility functions\n    def _binopt(self, other, op, in_shape=None, out_shape=None):\n        \"\"\"Apply the binary operation fn to two sparse matrices.\"\"\"\n\n        # Ideally we'd take the GCDs of the blocksize dimensions\n        # and explode self and other to match.\n        other = self.__class__(other, blocksize=self.blocksize)\n\n        # e.g. bsr_plus_bsr, etc.\n        fn = getattr(_sparsetools, self.format + op + self.format)\n\n        R,C = self.blocksize\n\n        max_bnnz = len(self.data) + len(other.data)\n        idx_dtype = get_index_dtype((self.indptr, self.indices,\n                                     other.indptr, other.indices),\n                                    maxval=max_bnnz)\n        indptr = np.empty(self.indptr.shape, dtype=idx_dtype)\n        indices = np.empty(max_bnnz, dtype=idx_dtype)\n\n        bool_ops = ['_ne_', '_lt_', '_gt_', '_le_', '_ge_']\n        if op in bool_ops:\n            data = np.empty(R*C*max_bnnz, dtype=np.bool_)\n        else:\n            data = np.empty(R*C*max_bnnz, dtype=upcast(self.dtype,other.dtype))\n\n        data_dtype = self.dtype\n        if not np.can_cast(other.dtype, self.dtype):\n            data_dtype = upcast(self.dtype, other.dtype)\n\n        fn(self.shape[0]//R, self.shape[1]//C, R, C,\n           self.indptr.astype(idx_dtype),\n           self.indices.astype(idx_dtype),\n           np.asarray(self.data, dtype=data_dtype).ravel(),\n           other.indptr.astype(idx_dtype),\n           other.indices.astype(idx_dtype),\n           np.ravel(other.data),\n           indptr,\n           indices,\n           data)\n\n        actual_bnnz = indptr[-1]\n        indices = indices[:actual_bnnz]\n        data = data[:R*C*actual_bnnz]\n\n        if actual_bnnz < max_bnnz/2:\n            indices = indices.copy()\n            data = data.copy()\n\n        data = data.reshape(-1,R,C)\n\n        return self.__class__((data, indices, indptr), shape=self.shape)\n\n    # needed by _data_matrix\n    def _with_data(self,data,copy=True):\n        \"\"\"Returns a matrix with the same sparsity structure as self,\n        but with different data.  By default the structure arrays\n        (i.e. .indptr and .indices) are copied.\n        \"\"\"\n        if copy:\n            return self.__class__((data,self.indices.copy(),self.indptr.copy()),\n                                   shape=self.shape,dtype=data.dtype)\n        else:\n            return self.__class__((data,self.indices,self.indptr),\n                                   shape=self.shape,dtype=data.dtype)\n\n#    # these functions are used by the parent class\n#    # to remove redudancy between bsc_matrix and bsr_matrix\n#    def _swap(self,x):\n#        \"\"\"swap the members of x if this is a column-oriented matrix\n#        \"\"\"\n#        return (x[0],x[1])\n\n\ndef isspmatrix_bsr(x):\n    return isinstance(x, bsr_matrix)\n"
    },
    {
      "filename": "scipy/sparse/compressed.py",
      "content": "\"\"\"Base class for sparse matrix formats using compressed storage.\"\"\"\nfrom __future__ import division, print_function, absolute_import\n\n__all__ = []\n\nfrom warnings import warn\nimport operator\n\nimport numpy as np\nfrom scipy._lib.six import xrange, zip as izip\n\nfrom .base import spmatrix, isspmatrix, SparseEfficiencyWarning\nfrom .data import _data_matrix, _minmax_mixin\nfrom .dia import dia_matrix\nfrom . import _sparsetools\nfrom .sputils import upcast, upcast_char, to_native, isdense, isshape, \\\n     getdtype, isscalarlike, isintlike, IndexMixin, get_index_dtype, \\\n     downcast_intp_index, _compat_unique\n\n\nclass _cs_matrix(_data_matrix, _minmax_mixin, IndexMixin):\n    \"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\n\n    def __init__(self, arg1, shape=None, dtype=None, copy=False):\n        _data_matrix.__init__(self)\n\n        if isspmatrix(arg1):\n            if arg1.format == self.format and copy:\n                arg1 = arg1.copy()\n            else:\n                arg1 = arg1.asformat(self.format)\n            self._set_self(arg1)\n\n        elif isinstance(arg1, tuple):\n            if isshape(arg1):\n                # It's a tuple of matrix dimensions (M, N)\n                # create empty matrix\n                self.shape = arg1   # spmatrix checks for errors here\n                M, N = self.shape\n                idx_dtype = get_index_dtype(maxval=self._swap((M,N))[1])\n                self.data = np.zeros(0, getdtype(dtype, default=float))\n                self.indices = np.zeros(0, idx_dtype)\n                self.indptr = np.zeros(self._swap((M,N))[0] + 1, dtype=idx_dtype)\n            else:\n                if len(arg1) == 2:\n                    # (data, ij) format\n                    from .coo import coo_matrix\n                    other = self.__class__(coo_matrix(arg1, shape=shape))\n                    self._set_self(other)\n                elif len(arg1) == 3:\n                    # (data, indices, indptr) format\n                    (data, indices, indptr) = arg1\n                    idx_dtype = get_index_dtype((indices, indptr), check_contents=True)\n                    self.indices = np.array(indices, copy=copy, dtype=idx_dtype)\n                    self.indptr = np.array(indptr, copy=copy, dtype=idx_dtype)\n                    self.data = np.array(data, copy=copy, dtype=getdtype(dtype, data))\n                else:\n                    raise ValueError(\"unrecognized %s_matrix constructor usage\" %\n                            self.format)\n\n        else:\n            # must be dense\n            try:\n                arg1 = np.asarray(arg1)\n            except:\n                raise ValueError(\"unrecognized %s_matrix constructor usage\" %\n                        self.format)\n            from .coo import coo_matrix\n            self._set_self(self.__class__(coo_matrix(arg1, dtype=dtype)))\n\n        # Read matrix dimensions given, if any\n        if shape is not None:\n            self.shape = shape   # spmatrix will check for errors\n        else:\n            if self.shape is None:\n                # shape not already set, try to infer dimensions\n                try:\n                    major_dim = len(self.indptr) - 1\n                    minor_dim = self.indices.max() + 1\n                except:\n                    raise ValueError('unable to infer matrix dimensions')\n                else:\n                    self.shape = self._swap((major_dim,minor_dim))\n\n        if dtype is not None:\n            self.data = np.asarray(self.data, dtype=dtype)\n\n        self.check_format(full_check=False)\n\n    def getnnz(self, axis=None):\n        \"\"\"Get the count of explicitly-stored values (nonzeros)\n\n        Parameters\n        ----------\n        axis : {None, 0, 1}, optional\n            Select between the number of values across the whole matrix, in\n            each column, or in each row.\n        \"\"\"\n        if axis is None:\n            return int(self.indptr[-1])\n        else:\n            if axis < 0:\n                axis += 2\n            axis, _ = self._swap((axis, 1 - axis))\n            _, N = self._swap(self.shape)\n            if axis == 0:\n                return np.bincount(downcast_intp_index(self.indices),\n                                   minlength=N)\n            elif axis == 1:\n                return np.diff(self.indptr)\n            raise ValueError('axis out of bounds')\n\n    nnz = property(fget=getnnz)\n\n    def _set_self(self, other, copy=False):\n        \"\"\"take the member variables of other and assign them to self\"\"\"\n\n        if copy:\n            other = other.copy()\n\n        self.data = other.data\n        self.indices = other.indices\n        self.indptr = other.indptr\n        self.shape = other.shape\n\n    def check_format(self, full_check=True):\n        \"\"\"check whether the matrix format is valid\n\n        Parameters\n        ----------\n        full_check : bool, optional\n            If `True`, rigorous check, O(N) operations. Otherwise\n            basic check, O(1) operations (default True).\n        \"\"\"\n        # use _swap to determine proper bounds\n        major_name,minor_name = self._swap(('row','column'))\n        major_dim,minor_dim = self._swap(self.shape)\n\n        # index arrays should have integer data types\n        if self.indptr.dtype.kind != 'i':\n            warn(\"indptr array has non-integer dtype (%s)\"\n                    % self.indptr.dtype.name)\n        if self.indices.dtype.kind != 'i':\n            warn(\"indices array has non-integer dtype (%s)\"\n                    % self.indices.dtype.name)\n\n        idx_dtype = get_index_dtype((self.indptr, self.indices))\n        self.indptr = np.asarray(self.indptr, dtype=idx_dtype)\n        self.indices = np.asarray(self.indices, dtype=idx_dtype)\n        self.data = to_native(self.data)\n\n        # check array shapes\n        if self.data.ndim != 1 or self.indices.ndim != 1 or self.indptr.ndim != 1:\n            raise ValueError('data, indices, and indptr should be 1-D')\n\n        # check index pointer\n        if (len(self.indptr) != major_dim + 1):\n            raise ValueError(\"index pointer size (%d) should be (%d)\" %\n                                (len(self.indptr), major_dim + 1))\n        if (self.indptr[0] != 0):\n            raise ValueError(\"index pointer should start with 0\")\n\n        # check index and data arrays\n        if (len(self.indices) != len(self.data)):\n            raise ValueError(\"indices and data should have the same size\")\n        if (self.indptr[-1] > len(self.indices)):\n            raise ValueError(\"Last value of index pointer should be less than \"\n                                \"the size of index and data arrays\")\n\n        self.prune()\n\n        if full_check:\n            # check format validity (more expensive)\n            if self.nnz > 0:\n                if self.indices.max() >= minor_dim:\n                    raise ValueError(\"%s index values must be < %d\" %\n                                        (minor_name,minor_dim))\n                if self.indices.min() < 0:\n                    raise ValueError(\"%s index values must be >= 0\" %\n                                        minor_name)\n                if np.diff(self.indptr).min() < 0:\n                    raise ValueError(\"index pointer values must form a \"\n                                        \"non-decreasing sequence\")\n\n        # if not self.has_sorted_indices():\n        #    warn('Indices were not in sorted order.  Sorting indices.')\n        #    self.sort_indices()\n        #    assert(self.has_sorted_indices())\n        # TODO check for duplicates?\n\n    #######################\n    # Boolean comparisons #\n    #######################\n\n    def _scalar_binopt(self, other, op):\n        \"\"\"Scalar version of self._binopt, for cases in which no new nonzeros\n        are added. Produces a new spmatrix in canonical form.\n        \"\"\"\n        try:\n            self.sum_duplicates()\n        except NotImplementedError:\n            pass\n        res = self._with_data(op(self.data, other), copy=True)\n        res.eliminate_zeros()\n        return res\n\n    def __eq__(self, other):\n        # Scalar other.\n        if isscalarlike(other):\n            if np.isnan(other):\n                return self.__class__(self.shape, dtype=np.bool_)\n\n            if other == 0:\n                warn(\"Comparing a sparse matrix with 0 using == is inefficient\"\n                        \", try using != instead.\", SparseEfficiencyWarning)\n                all_true = self.__class__(np.ones(self.shape, dtype=np.bool_))\n                inv = self._scalar_binopt(other, operator.ne)\n                return all_true - inv\n            else:\n                return self._scalar_binopt(other, operator.eq)\n        # Dense other.\n        elif isdense(other):\n            return self.todense() == other\n        # Sparse other.\n        elif isspmatrix(other):\n            warn(\"Comparing sparse matrices using == is inefficient, try using\"\n                    \" != instead.\", SparseEfficiencyWarning)\n            #TODO sparse broadcasting\n            if self.shape != other.shape:\n                return False\n            elif self.format != other.format:\n                other = other.asformat(self.format)\n            res = self._binopt(other,'_ne_')\n            all_true = self.__class__(np.ones(self.shape, dtype=np.bool_))\n            return all_true - res\n        else:\n            return False\n\n    def __ne__(self, other):\n        # Scalar other.\n        if isscalarlike(other):\n            if np.isnan(other):\n                warn(\"Comparing a sparse matrix with nan using != is inefficient\",\n                     SparseEfficiencyWarning)\n                all_true = self.__class__(np.ones(self.shape, dtype=np.bool_))\n                return all_true\n            elif other != 0:\n                warn(\"Comparing a sparse matrix with a nonzero scalar using !=\"\n                     \" is inefficient, try using == instead.\", SparseEfficiencyWarning)\n                all_true = self.__class__(np.ones(self.shape), dtype=np.bool_)\n                inv = self._scalar_binopt(other, operator.eq)\n                return all_true - inv\n            else:\n                return self._scalar_binopt(other, operator.ne)\n        # Dense other.\n        elif isdense(other):\n            return self.todense() != other\n        # Sparse other.\n        elif isspmatrix(other):\n            #TODO sparse broadcasting\n            if self.shape != other.shape:\n                return True\n            elif self.format != other.format:\n                other = other.asformat(self.format)\n            return self._binopt(other,'_ne_')\n        else:\n            return True\n\n    def _inequality(self, other, op, op_name, bad_scalar_msg):\n        # Scalar other.\n        if isscalarlike(other):\n            if 0 == other and op_name in ('_le_', '_ge_'):\n                raise NotImplementedError(\" >= and <= don't work with 0.\")\n            elif op(0, other):\n                warn(bad_scalar_msg, SparseEfficiencyWarning)\n                dtype = upcast(self.dtype, np.result_type(other))\n                other_arr = np.empty(self.shape, dtype=dtype)\n                other_arr.fill(other)\n                other_arr = self.__class__(other_arr)\n                return self._binopt(other_arr, op_name)\n            else:\n                return self._scalar_binopt(other, op)\n        # Dense other.\n        elif isdense(other):\n            return op(self.todense(), other)\n        # Sparse other.\n        elif isspmatrix(other):\n            #TODO sparse broadcasting\n            if self.shape != other.shape:\n                raise ValueError(\"inconsistent shapes\")\n            elif self.format != other.format:\n                other = other.asformat(self.format)\n            if op_name not in ('_ge_', '_le_'):\n                return self._binopt(other, op_name)\n\n            warn(\"Comparing sparse matrices using >= and <= is inefficient, \"\n                 \"using <, >, or !=, instead.\", SparseEfficiencyWarning)\n            all_true = self.__class__(np.ones(self.shape))\n            res = self._binopt(other, '_gt_' if op_name == '_le_' else '_lt_')\n            return all_true - res\n        else:\n            raise ValueError(\"Operands could not be compared.\")\n\n    def __lt__(self, other):\n        return self._inequality(other, operator.lt, '_lt_',\n                                \"Comparing a sparse matrix with a scalar \"\n                                \"greater than zero using < is inefficient, \"\n                                \"try using >= instead.\")\n\n    def __gt__(self, other):\n        return self._inequality(other, operator.gt, '_gt_',\n                                \"Comparing a sparse matrix with a scalar \"\n                                \"less than zero using > is inefficient, \"\n                                \"try using <= instead.\")\n\n    def __le__(self, other):\n        return self._inequality(other, operator.le, '_le_',\n                                \"Comparing a sparse matrix with a scalar \"\n                                \"greater than zero using <= is inefficient, \"\n                                \"try using > instead.\")\n\n    def __ge__(self,other):\n        return self._inequality(other, operator.ge, '_ge_',\n                                \"Comparing a sparse matrix with a scalar \"\n                                \"less than zero using >= is inefficient, \"\n                                \"try using < instead.\")\n\n    #################################\n    # Arithmatic operator overrides #\n    #################################\n\n    def __add__(self,other):\n        # First check if argument is a scalar\n        if isscalarlike(other):\n            if other == 0:\n                return self.copy()\n            else:  # Now we would add this scalar to every element.\n                raise NotImplementedError('adding a nonzero scalar to a '\n                                          'sparse matrix is not supported')\n        elif isspmatrix(other):\n            if (other.shape != self.shape):\n                raise ValueError(\"inconsistent shapes\")\n\n            return self._binopt(other,'_plus_')\n        elif isdense(other):\n            # Convert this matrix to a dense matrix and add them\n            return self.todense() + other\n        else:\n            return NotImplemented\n\n    def __radd__(self,other):\n        return self.__add__(other)\n\n    def __sub__(self,other):\n        # First check if argument is a scalar\n        if isscalarlike(other):\n            if other == 0:\n                return self.copy()\n            else:  # Now we would add this scalar to every element.\n                raise NotImplementedError('adding a nonzero scalar to a '\n                                          'sparse matrix is not supported')\n        elif isspmatrix(other):\n            if (other.shape != self.shape):\n                raise ValueError(\"inconsistent shapes\")\n\n            return self._binopt(other,'_minus_')\n        elif isdense(other):\n            # Convert this matrix to a dense matrix and subtract them\n            return self.todense() - other\n        else:\n            return NotImplemented\n\n    def __rsub__(self,other):  # other - self\n        # note: this can't be replaced by other + (-self) for unsigned types\n        if isscalarlike(other):\n            if other == 0:\n                return -self.copy()\n            else:  # Now we would add this scalar to every element.\n                raise NotImplementedError('adding a nonzero scalar to a '\n                                          'sparse matrix is not supported')\n        elif isdense(other):\n            # Convert this matrix to a dense matrix and subtract them\n            return other - self.todense()\n        else:\n            return NotImplemented\n\n    def multiply(self, other):\n        \"\"\"Point-wise multiplication by another matrix, vector, or\n        scalar.\n        \"\"\"\n        # Scalar multiplication.\n        if isscalarlike(other):\n            return self.__mul__(other)\n        # Sparse matrix or vector.\n        if isspmatrix(other):\n            if self.shape == other.shape:\n                other = self.__class__(other)\n                return self._binopt(other, '_elmul_')\n            # Single element.\n            elif other.shape == (1,1):\n                return self.__mul__(other.tocsc().data[0])\n            elif self.shape == (1,1):\n                return other.__mul__(self.tocsc().data[0])\n            # A row times a column.\n            elif self.shape[1] == other.shape[0] and self.shape[1] == 1:\n                return self._mul_sparse_matrix(other.tocsc())\n            elif self.shape[0] == other.shape[1] and self.shape[0] == 1:\n                return other._mul_sparse_matrix(self.tocsc())\n            # Row vector times matrix. other is a row.\n            elif other.shape[0] == 1 and self.shape[1] == other.shape[1]:\n                other = dia_matrix((other.toarray().ravel(), [0]),\n                                    shape=(other.shape[1], other.shape[1]))\n                return self._mul_sparse_matrix(other)\n            # self is a row.\n            elif self.shape[0] == 1 and self.shape[1] == other.shape[1]:\n                copy = dia_matrix((self.toarray().ravel(), [0]),\n                                    shape=(self.shape[1], self.shape[1]))\n                return other._mul_sparse_matrix(copy)\n            # Column vector times matrix. other is a column.\n            elif other.shape[1] == 1 and self.shape[0] == other.shape[0]:\n                other = dia_matrix((other.toarray().ravel(), [0]),\n                                    shape=(other.shape[0], other.shape[0]))\n                return other._mul_sparse_matrix(self)\n            # self is a column.\n            elif self.shape[1] == 1 and self.shape[0] == other.shape[0]:\n                copy = dia_matrix((self.toarray().ravel(), [0]),\n                                    shape=(self.shape[0], self.shape[0]))\n                return copy._mul_sparse_matrix(other)\n            else:\n                raise ValueError(\"inconsistent shapes\")\n        # Dense matrix.\n        if isdense(other):\n            if self.shape == other.shape:\n                ret = self.tocoo()\n                ret.data = np.multiply(ret.data, other[ret.row, ret.col]\n                                       ).view(np.ndarray).ravel()\n                # Current tests expect dense output.\n                return ret.todense()\n            # Single element.\n            elif other.size == 1:\n                return self.__mul__(other.flat[0])\n        # Anything else.\n        return np.multiply(self.todense(), other)\n\n    ###########################\n    # Multiplication handlers #\n    ###########################\n\n    def _mul_vector(self, other):\n        M,N = self.shape\n\n        # output array\n        result = np.zeros(M, dtype=upcast_char(self.dtype.char,\n                                               other.dtype.char))\n\n        # csr_matvec or csc_matvec\n        fn = getattr(_sparsetools,self.format + '_matvec')\n        fn(M, N, self.indptr, self.indices, self.data, other, result)\n\n        return result\n\n    def _mul_multivector(self, other):\n        M,N = self.shape\n        n_vecs = other.shape[1]  # number of column vectors\n\n        result = np.zeros((M,n_vecs), dtype=upcast_char(self.dtype.char,\n                                                        other.dtype.char))\n\n        # csr_matvecs or csc_matvecs\n        fn = getattr(_sparsetools,self.format + '_matvecs')\n        fn(M, N, n_vecs, self.indptr, self.indices, self.data, other.ravel(), result.ravel())\n\n        return result\n\n    def _mul_sparse_matrix(self, other):\n        M, K1 = self.shape\n        K2, N = other.shape\n\n        major_axis = self._swap((M,N))[0]\n        other = self.__class__(other)  # convert to this format\n\n        idx_dtype = get_index_dtype((self.indptr, self.indices,\n                                     other.indptr, other.indices),\n                                    maxval=M*N)\n        indptr = np.empty(major_axis + 1, dtype=idx_dtype)\n\n        fn = getattr(_sparsetools, self.format + '_matmat_pass1')\n        fn(M, N,\n           np.asarray(self.indptr, dtype=idx_dtype),\n           np.asarray(self.indices, dtype=idx_dtype),\n           np.asarray(other.indptr, dtype=idx_dtype),\n           np.asarray(other.indices, dtype=idx_dtype),\n           indptr)\n\n        nnz = indptr[-1]\n        idx_dtype = get_index_dtype((self.indptr, self.indices,\n                                     other.indptr, other.indices),\n                                    maxval=nnz)\n        indptr = np.asarray(indptr, dtype=idx_dtype)\n        indices = np.empty(nnz, dtype=idx_dtype)\n        data = np.empty(nnz, dtype=upcast(self.dtype, other.dtype))\n\n        fn = getattr(_sparsetools, self.format + '_matmat_pass2')\n        fn(M, N, np.asarray(self.indptr, dtype=idx_dtype),\n           np.asarray(self.indices, dtype=idx_dtype),\n           self.data,\n           np.asarray(other.indptr, dtype=idx_dtype),\n           np.asarray(other.indices, dtype=idx_dtype),\n           other.data,\n           indptr, indices, data)\n\n        return self.__class__((data,indices,indptr),shape=(M,N))\n\n    def diagonal(self):\n        \"\"\"Returns the main diagonal of the matrix\n        \"\"\"\n        # TODO support k-th diagonal\n        fn = getattr(_sparsetools, self.format + \"_diagonal\")\n        y = np.empty(min(self.shape), dtype=upcast(self.dtype))\n        fn(self.shape[0], self.shape[1], self.indptr, self.indices, self.data, y)\n        return y\n\n    #####################\n    # Other binary ops  #\n    #####################\n\n    def _maximum_minimum(self, other, npop, op_name, dense_check):\n        if isscalarlike(other):\n            if dense_check(other):\n                warn(\"Taking maximum (minimum) with > 0 (< 0) number results to \"\n                     \"a dense matrix.\",\n                     SparseEfficiencyWarning)\n                other_arr = np.empty(self.shape, dtype=np.asarray(other).dtype)\n                other_arr.fill(other)\n                other_arr = self.__class__(other_arr)\n                return self._binopt(other_arr, op_name)\n            else:\n                try:\n                    self.sum_duplicates()\n                except NotImplementedError:\n                    pass\n                new_data = npop(self.data, np.asarray(other))\n                mat = self.__class__((new_data, self.indices, self.indptr),\n                                     dtype=new_data.dtype, shape=self.shape)\n                return mat\n        elif isdense(other):\n            return npop(self.todense(), other)\n        elif isspmatrix(other):\n            return self._binopt(other, op_name)\n        else:\n            raise ValueError(\"Operands not compatible.\")\n\n    def maximum(self, other):\n        return self._maximum_minimum(other, np.maximum, '_maximum_', lambda x: np.asarray(x) > 0)\n\n    def minimum(self, other):\n        return self._maximum_minimum(other, np.minimum, '_minimum_', lambda x: np.asarray(x) < 0)\n\n    #####################\n    # Reduce operations #\n    #####################\n\n    def sum(self, axis=None):\n        \"\"\"Sum the matrix over the given axis.  If the axis is None, sum\n        over both rows and columns, returning a scalar.\n        \"\"\"\n        # The spmatrix base class already does axis=0 and axis=1 efficiently\n        # so we only do the case axis=None here\n        if axis is None:\n            return self.data.sum()\n        elif (not hasattr(self, 'blocksize') and\n              axis in self._swap(((1, -1), (0, 2)))[0]):\n            # faster than multiplication for large minor axis in CSC/CSR\n            dtype = self.dtype\n            if np.issubdtype(dtype, np.bool_):\n                dtype = np.int_\n            ret = np.zeros(len(self.indptr) - 1, dtype=dtype)\n            major_index, value = self._minor_reduce(np.add)\n            ret[major_index] = value\n            ret = np.asmatrix(ret)\n            if axis % 2 == 1:\n                ret = ret.T\n            return ret\n        else:\n            return spmatrix.sum(self, axis)\n\n    def _minor_reduce(self, ufunc):\n        \"\"\"Reduce nonzeros with a ufunc over the minor axis when non-empty\n\n        Warning: this does not call sum_duplicates()\n\n        Returns\n        -------\n        major_index : array of ints\n            Major indices where nonzero\n\n        value : array of self.dtype\n            Reduce result for nonzeros in each major_index\n        \"\"\"\n        major_index = np.flatnonzero(np.diff(self.indptr))\n        if self.data.size == 0 and major_index.size == 0:\n            # Numpy < 1.8.0 don't handle empty arrays in reduceat\n            value = np.zeros_like(self.data)\n        else:\n            value = ufunc.reduceat(self.data,\n                                   downcast_intp_index(self.indptr[major_index]))\n        return major_index, value\n\n    #######################\n    # Getting and Setting #\n    #######################\n\n    def __getitem__(self, key):\n        if isinstance(key, tuple):\n            row = key[0]\n            col = key[1]\n\n            # TODO implement CSR[ [1,2,3], X ] with sparse matmat\n            # TODO make use of sorted indices\n\n            if isintlike(row) and isintlike(col):\n                return self._get_single_element(row,col)\n            else:\n                major,minor = self._swap((row,col))\n                if isintlike(major) and isinstance(minor,slice):\n                    minor_shape = self._swap(self.shape)[1]\n                    start, stop, stride = minor.indices(minor_shape)\n                    out_shape = self._swap((1, stop-start))\n                    return self._get_slice(major, start, stop, stride, out_shape)\n                elif isinstance(row, slice) or isinstance(col, slice):\n                    return self._get_submatrix(row, col)\n                else:\n                    raise NotImplementedError\n\n        elif isintlike(key):\n            return self[key, :]\n        else:\n            raise IndexError(\"invalid index\")\n\n    def __setitem__(self, index, x):\n        # Process arrays from IndexMixin\n        i, j = self._unpack_index(index)\n        i, j = self._index_to_arrays(i, j)\n\n        if isspmatrix(x):\n            x = x.toarray()\n\n        # Make x and i into the same shape\n        x = np.asarray(x, dtype=self.dtype)\n        x, _ = np.broadcast_arrays(x, i)\n\n        if x.shape != i.shape:\n            raise ValueError(\"shape mismatch in assignment\")\n\n        if np.size(x) == 0:\n            return\n        i, j = self._swap((i.ravel(), j.ravel()))\n        self._set_many(i, j, x.ravel())\n\n    def _setdiag(self, values, k):\n        if 0 in self.shape:\n            return\n\n        M, N = self.shape\n        broadcast = (values.ndim == 0)\n\n        if k < 0:\n            if broadcast:\n                max_index = min(M + k, N)\n            else:\n                max_index = min(M + k, N, len(values))\n            i = np.arange(max_index, dtype=self.indices.dtype)\n            j = np.arange(max_index, dtype=self.indices.dtype)\n            i -= k\n\n        else:\n            if broadcast:\n                max_index = min(M, N - k)\n            else:\n                max_index = min(M, N - k, len(values))\n            i = np.arange(max_index, dtype=self.indices.dtype)\n            j = np.arange(max_index, dtype=self.indices.dtype)\n            j += k\n\n        if not broadcast:\n            values = values[:len(i)]\n\n        self[i, j] = values\n\n    def _set_many(self, i, j, x):\n        \"\"\"Sets value at each (i, j) to x\n\n        Here (i,j) index major and minor respectively.\n        \"\"\"\n        M, N = self._swap(self.shape)\n\n        def check_bounds(indices, bound):\n            idx = indices.max()\n            if idx >= bound:\n                raise IndexError('index (%d) out of range (>= %d)' %\n                                 (idx, bound))\n            idx = indices.min()\n            if idx < -bound:\n                raise IndexError('index (%d) out of range (< -%d)' %\n                                 (idx, bound))\n\n        check_bounds(i, M)\n        check_bounds(j, N)\n\n        i = np.asarray(i, dtype=self.indices.dtype)\n        j = np.asarray(j, dtype=self.indices.dtype)\n\n        n_samples = len(x)\n        offsets = np.empty(n_samples, dtype=self.indices.dtype)\n        ret = _sparsetools.csr_sample_offsets(M, N, self.indptr, self.indices,\n                                              n_samples, i, j, offsets)\n        if ret == 1:\n            # rinse and repeat\n            self.sum_duplicates()\n            _sparsetools.csr_sample_offsets(M, N, self.indptr,\n                                            self.indices, n_samples, i, j,\n                                            offsets)\n\n        if -1 not in offsets:\n            # only affects existing non-zero cells\n            self.data[offsets] = x\n            return\n\n        else:\n            warn(\"Changing the sparsity structure of a %s_matrix is expensive. \"\n                 \"lil_matrix is more efficient.\" % self.format,\n                 SparseEfficiencyWarning)\n            # replace where possible\n            mask = offsets > -1\n            self.data[offsets[mask]] = x[mask]\n            # only insertions remain\n            mask = ~mask\n            i = i[mask]\n            i[i < 0] += M\n            j = j[mask]\n            j[j < 0] += N\n            self._insert_many(i, j, x[mask])\n\n    def _insert_many(self, i, j, x):\n        \"\"\"Inserts new nonzero at each (i, j) with value x\n\n        Here (i,j) index major and minor respectively.\n        i, j and x must be non-empty, 1d arrays.\n        Inserts each major group (e.g. all entries per row) at a time.\n        Maintains has_sorted_indices property.\n        Modifies i, j, x in place.\n        \"\"\"\n        order = np.argsort(i, kind='mergesort')  # stable for duplicates\n        i = i.take(order, mode='clip')\n        j = j.take(order, mode='clip')\n        x = x.take(order, mode='clip')\n\n        do_sort = self.has_sorted_indices\n\n        # Update index data type\n        idx_dtype = get_index_dtype((self.indices, self.indptr),\n                                    maxval=(self.indptr[-1] + x.size))\n        self.indptr = np.asarray(self.indptr, dtype=idx_dtype)\n        self.indices = np.asarray(self.indices, dtype=idx_dtype)\n        i = np.asarray(i, dtype=idx_dtype)\n        j = np.asarray(j, dtype=idx_dtype)\n\n        # Collate old and new in chunks by major index\n        indices_parts = []\n        data_parts = []\n        ui, ui_indptr = _compat_unique(i, return_index=True)\n        ui_indptr = np.append(ui_indptr, len(j))\n        new_nnzs = np.diff(ui_indptr)\n        prev = 0\n        for c, (ii, js, je) in enumerate(izip(ui, ui_indptr, ui_indptr[1:])):\n            # old entries\n            start = self.indptr[prev]\n            stop = self.indptr[ii]\n            indices_parts.append(self.indices[start:stop])\n            data_parts.append(self.data[start:stop])\n\n            # handle duplicate j: keep last setting\n            uj, uj_indptr = _compat_unique(j[js:je][::-1], return_index=True)\n            if len(uj) == je - js:\n                indices_parts.append(j[js:je])\n                data_parts.append(x[js:je])\n            else:\n                indices_parts.append(j[js:je][::-1][uj_indptr])\n                data_parts.append(x[js:je][::-1][uj_indptr])\n                new_nnzs[c] = len(uj)\n\n            prev = ii\n\n        # remaining old entries\n        start = self.indptr[ii]\n        indices_parts.append(self.indices[start:])\n        data_parts.append(self.data[start:])\n\n        # update attributes\n        self.indices = np.concatenate(indices_parts)\n        self.data = np.concatenate(data_parts)\n        nnzs = np.asarray(np.ediff1d(self.indptr, to_begin=0), dtype=idx_dtype)\n        nnzs[1:][ui] += new_nnzs\n        self.indptr = np.cumsum(nnzs, out=nnzs)\n\n        if do_sort:\n            # TODO: only sort where necessary\n            self.has_sorted_indices = False\n            self.sort_indices()\n\n        self.check_format(full_check=False)\n\n    def _get_single_element(self,row,col):\n        M, N = self.shape\n        if (row < 0):\n            row += M\n        if (col < 0):\n            col += N\n        if not (0 <= row < M) or not (0 <= col < N):\n            raise IndexError(\"index out of bounds\")\n\n        major_index, minor_index = self._swap((row,col))\n\n        # TODO make use of sorted indices (if present)\n\n        start = self.indptr[major_index]\n        end = self.indptr[major_index+1]\n        # can use np.add(..., where) from numpy 1.7\n        return np.compress(minor_index == self.indices[start:end],\n                           self.data[start:end]).sum(dtype=self.dtype)\n\n    def _get_slice(self, i, start, stop, stride, shape):\n        \"\"\"Returns a copy of the elements\n            [i, start:stop:string] for row-oriented matrices\n            [start:stop:string, i] for column-oriented matrices\n        \"\"\"\n        if stride != 1:\n            raise ValueError(\"slicing with step != 1 not supported\")\n        if stop <= start:\n            raise ValueError(\"slice width must be >= 1\")\n\n        # TODO make [i,:] faster\n        # TODO implement [i,x:y:z]\n\n        indices = []\n\n        for ind in xrange(self.indptr[i], self.indptr[i+1]):\n            if self.indices[ind] >= start and self.indices[ind] < stop:\n                indices.append(ind)\n\n        index = self.indices[indices] - start\n        data = self.data[indices]\n        indptr = np.array([0, len(indices)])\n        return self.__class__((data, index, indptr), shape=shape,\n                              dtype=self.dtype)\n\n    def _get_submatrix(self, slice0, slice1):\n        \"\"\"Return a submatrix of this matrix (new matrix is created).\"\"\"\n\n        slice0, slice1 = self._swap((slice0,slice1))\n        shape0, shape1 = self._swap(self.shape)\n\n        def _process_slice(sl, num):\n            if isinstance(sl, slice):\n                i0, i1 = sl.start, sl.stop\n                if i0 is None:\n                    i0 = 0\n                elif i0 < 0:\n                    i0 = num + i0\n\n                if i1 is None:\n                    i1 = num\n                elif i1 < 0:\n                    i1 = num + i1\n\n                return i0, i1\n\n            elif np.isscalar(sl):\n                if sl < 0:\n                    sl += num\n\n                return sl, sl + 1\n\n            else:\n                return sl[0], sl[1]\n\n        def _in_bounds(i0, i1, num):\n            if not (0 <= i0 < num) or not (0 < i1 <= num) or not (i0 < i1):\n                raise IndexError(\"index out of bounds: 0<=%d<%d, 0<=%d<%d, %d<%d\" %\n                                    (i0, num, i1, num, i0, i1))\n\n        i0, i1 = _process_slice(slice0, shape0)\n        j0, j1 = _process_slice(slice1, shape1)\n        _in_bounds(i0, i1, shape0)\n        _in_bounds(j0, j1, shape1)\n\n        aux = _sparsetools.get_csr_submatrix(shape0, shape1,\n                                             self.indptr, self.indices,\n                                             self.data,\n                                             i0, i1, j0, j1)\n\n        data, indices, indptr = aux[2], aux[1], aux[0]\n        shape = self._swap((i1 - i0, j1 - j0))\n\n        return self.__class__((data, indices, indptr), shape=shape)\n\n    ######################\n    # Conversion methods #\n    ######################\n\n    def todia(self):\n        return self.tocoo(copy=False).todia()\n\n    def todok(self):\n        return self.tocoo(copy=False).todok()\n\n    def tocoo(self,copy=True):\n        \"\"\"Return a COOrdinate representation of this matrix\n\n        When copy=False the index and data arrays are not copied.\n        \"\"\"\n        major_dim,minor_dim = self._swap(self.shape)\n\n        data = self.data\n        minor_indices = self.indices\n\n        if copy:\n            data = data.copy()\n            minor_indices = minor_indices.copy()\n\n        major_indices = np.empty(len(minor_indices), dtype=self.indices.dtype)\n\n        _sparsetools.expandptr(major_dim,self.indptr,major_indices)\n\n        row,col = self._swap((major_indices,minor_indices))\n\n        from .coo import coo_matrix\n        return coo_matrix((data,(row,col)), self.shape)\n\n    def toarray(self, order=None, out=None):\n        \"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\n        return self.tocoo(copy=False).toarray(order=order, out=out)\n\n    ##############################################################\n    # methods that examine or modify the internal data structure #\n    ##############################################################\n\n    def eliminate_zeros(self):\n        \"\"\"Remove zero entries from the matrix\n\n        This is an *in place* operation\n        \"\"\"\n        fn = _sparsetools.csr_eliminate_zeros\n        M,N = self._swap(self.shape)\n        fn(M, N, self.indptr, self.indices, self.data)\n\n        self.prune()  # nnz may have changed\n\n    def __get_has_canonical_format(self):\n        \"\"\"Determine whether the matrix has sorted indices and no duplicates\n\n        Returns\n            - True: if the above applies\n            - False: otherwise\n\n        has_canonical_format implies has_sorted_indices, so if the latter flag\n        is False, so will the former be; if the former is found True, the\n        latter flag is also set.\n        \"\"\"\n\n        # first check to see if result was cached\n        if not getattr(self, '_has_sorted_indices', True):\n            # not sorted => not canonical\n            self._has_canonical_format = False\n        elif not hasattr(self, '_has_canonical_format'):\n            fn = _sparsetools.csr_has_canonical_format\n            self.has_canonical_format = \\\n                    fn(len(self.indptr) - 1, self.indptr, self.indices)\n        return self._has_canonical_format\n\n    def __set_has_canonical_format(self, val):\n        self._has_canonical_format = bool(val)\n        if val:\n            self.has_sorted_indices = True\n\n    has_canonical_format = property(fget=__get_has_canonical_format,\n                                    fset=__set_has_canonical_format)\n\n    def sum_duplicates(self):\n        \"\"\"Eliminate duplicate matrix entries by adding them together\n\n        The is an *in place* operation\n        \"\"\"\n        if self.has_canonical_format:\n            return\n        self.sort_indices()\n\n        fn = _sparsetools.csr_sum_duplicates\n        M,N = self._swap(self.shape)\n        fn(M, N, self.indptr, self.indices, self.data)\n\n        self.prune()  # nnz may have changed\n        self.has_canonical_format = True\n\n    def __get_sorted(self):\n        \"\"\"Determine whether the matrix has sorted indices\n\n        Returns\n            - True: if the indices of the matrix are in sorted order\n            - False: otherwise\n\n        \"\"\"\n\n        # first check to see if result was cached\n        if not hasattr(self,'_has_sorted_indices'):\n            fn = _sparsetools.csr_has_sorted_indices\n            self._has_sorted_indices = \\\n                    fn(len(self.indptr) - 1, self.indptr, self.indices)\n        return self._has_sorted_indices\n\n    def __set_sorted(self, val):\n        self._has_sorted_indices = bool(val)\n\n    has_sorted_indices = property(fget=__get_sorted, fset=__set_sorted)\n\n    def sorted_indices(self):\n        \"\"\"Return a copy of this matrix with sorted indices\n        \"\"\"\n        A = self.copy()\n        A.sort_indices()\n        return A\n\n        # an alternative that has linear complexity is the following\n        # although the previous option is typically faster\n        # return self.toother().toother()\n\n    def sort_indices(self):\n        \"\"\"Sort the indices of this matrix *in place*\n        \"\"\"\n\n        if not self.has_sorted_indices:\n            fn = _sparsetools.csr_sort_indices\n            fn(len(self.indptr) - 1, self.indptr, self.indices, self.data)\n            self.has_sorted_indices = True\n\n    def prune(self):\n        \"\"\"Remove empty space after all non-zero elements.\n        \"\"\"\n        major_dim = self._swap(self.shape)[0]\n\n        if len(self.indptr) != major_dim + 1:\n            raise ValueError('index pointer has invalid length')\n        if len(self.indices) < self.nnz:\n            raise ValueError('indices array has fewer than nnz elements')\n        if len(self.data) < self.nnz:\n            raise ValueError('data array has fewer than nnz elements')\n\n        self.data = self.data[:self.nnz]\n        self.indices = self.indices[:self.nnz]\n\n    ###################\n    # utility methods #\n    ###################\n\n    # needed by _data_matrix\n    def _with_data(self,data,copy=True):\n        \"\"\"Returns a matrix with the same sparsity structure as self,\n        but with different data.  By default the structure arrays\n        (i.e. .indptr and .indices) are copied.\n        \"\"\"\n        if copy:\n            return self.__class__((data,self.indices.copy(),self.indptr.copy()),\n                                   shape=self.shape,dtype=data.dtype)\n        else:\n            return self.__class__((data,self.indices,self.indptr),\n                                   shape=self.shape,dtype=data.dtype)\n\n    def _binopt(self, other, op):\n        \"\"\"apply the binary operation fn to two sparse matrices.\"\"\"\n        other = self.__class__(other)\n\n        # e.g. csr_plus_csr, csr_minus_csr, etc.\n        fn = getattr(_sparsetools, self.format + op + self.format)\n\n        maxnnz = self.nnz + other.nnz\n        idx_dtype = get_index_dtype((self.indptr, self.indices,\n                                     other.indptr, other.indices),\n                                    maxval=maxnnz)\n        indptr = np.empty(self.indptr.shape, dtype=idx_dtype)\n        indices = np.empty(maxnnz, dtype=idx_dtype)\n\n        bool_ops = ['_ne_', '_lt_', '_gt_', '_le_', '_ge_']\n        if op in bool_ops:\n            data = np.empty(maxnnz, dtype=np.bool_)\n        else:\n            data = np.empty(maxnnz, dtype=upcast(self.dtype, other.dtype))\n\n        data_dtype = self.dtype\n        if not np.can_cast(other.dtype, self.dtype):\n            data_dtype = upcast(self.dtype, other.dtype)\n\n        fn(self.shape[0], self.shape[1],\n           np.asarray(self.indptr, dtype=idx_dtype),\n           np.asarray(self.indices, dtype=idx_dtype),\n           np.asarray(self.data, dtype=data_dtype),\n           np.asarray(other.indptr, dtype=idx_dtype),\n           np.asarray(other.indices, dtype=idx_dtype),\n           other.data,\n           indptr, indices, data)\n\n        actual_nnz = indptr[-1]\n        indices = indices[:actual_nnz]\n        data = data[:actual_nnz]\n        if actual_nnz < maxnnz // 2:\n            # too much waste, trim arrays\n            indices = indices.copy()\n            data = data.copy()\n\n        A = self.__class__((data, indices, indptr), shape=self.shape)\n\n        return A\n\n    def _divide_sparse(self, other):\n        \"\"\"\n        Divide this matrix by a second sparse matrix.\n        \"\"\"\n        if other.shape != self.shape:\n            raise ValueError('inconsistent shapes')\n\n        r = self._binopt(other, '_eldiv_')\n\n        if np.issubdtype(r.dtype, np.inexact):\n            # Eldiv leaves entries outside the combined sparsity\n            # pattern empty, so they must be filled manually. They are\n            # always nan, so that the matrix is completely full.\n            out = np.empty(self.shape, dtype=self.dtype)\n            out.fill(np.nan)\n            r = r.tocoo()\n            out[r.row, r.col] = r.data\n            out = np.matrix(out)\n        else:\n            # integers types go with nan <-> 0\n            out = r\n\n        return out\n"
    },
    {
      "filename": "scipy/sparse/tests/test_base.py",
      "content": "#\n# Authors: Travis Oliphant, Ed Schofield, Robert Cimrman, Nathan Bell, and others\n\n\"\"\" Test functions for sparse matrices. Each class in the \"Matrix class\nbased tests\" section become subclasses of the classes in the \"Generic\ntests\" section. This is done by the functions in the \"Tailored base\nclass for generic tests\" section.\n\n\"\"\"\n\nfrom __future__ import division, print_function, absolute_import\n\n__usage__ = \"\"\"\nBuild sparse:\n  python setup.py build\nRun tests if scipy is installed:\n  python -c 'import scipy;scipy.sparse.test()'\nRun tests if sparse is not installed:\n  python tests/test_base.py\n\"\"\"\n\nimport warnings\nimport operator\nimport contextlib\n\nimport numpy as np\nfrom scipy._lib.six import xrange, zip as izip\nfrom numpy import (arange, zeros, array, dot, matrix, asmatrix, asarray,\n                   vstack, ndarray, transpose, diag, kron, inf, conjugate,\n                   int8, ComplexWarning, power)\n\nimport random\nfrom numpy.testing import (assert_raises, assert_equal, assert_array_equal,\n        assert_array_almost_equal, assert_almost_equal, assert_,\n        dec, run_module_suite, assert_allclose)\n\nimport scipy.linalg\n\nimport scipy.sparse as sparse\nfrom scipy.sparse import (csc_matrix, csr_matrix, dok_matrix,\n        coo_matrix, lil_matrix, dia_matrix, bsr_matrix,\n        eye, isspmatrix, SparseEfficiencyWarning, issparse)\nfrom scipy.sparse.sputils import supported_dtypes, isscalarlike, get_index_dtype\nfrom scipy.sparse.linalg import splu, expm, inv\n\nfrom scipy._lib._version import NumpyVersion\nfrom scipy._lib.decorator import decorator\n\nimport nose\n\n# Check for __numpy_ufunc__\nclass _UFuncCheck(object):\n    def __array__(self):\n        return np.array([1])\n\n    def __numpy_ufunc__(self, *a, **kwargs):\n        global HAS_NUMPY_UFUNC\n        HAS_NUMPY_UFUNC = True\n\nHAS_NUMPY_UFUNC = False\nnp.add(_UFuncCheck(), np.array([1]))\n\n\nwarnings.simplefilter('ignore', SparseEfficiencyWarning)\nwarnings.simplefilter('ignore', ComplexWarning)\n\n\ndef with_64bit_maxval_limit(maxval_limit=None, random=False, fixed_dtype=None,\n                            downcast_maxval=None, assert_32bit=False):\n    \"\"\"\n    Monkeypatch the maxval threshold at which scipy.sparse switches to\n    64-bit index arrays, or make it (pseudo-)random.\n\n    \"\"\"\n    if maxval_limit is None:\n        maxval_limit = 10\n\n    if assert_32bit:\n        def new_get_index_dtype(arrays=(), maxval=None, check_contents=False):\n            tp = get_index_dtype(arrays, maxval, check_contents)\n            assert_equal(np.iinfo(tp).max, np.iinfo(np.int32).max)\n            assert_(tp == np.int32 or tp == np.intc)\n            return tp\n    elif fixed_dtype is not None:\n        def new_get_index_dtype(arrays=(), maxval=None, check_contents=False):\n            return fixed_dtype\n    elif random:\n        counter = np.random.RandomState(seed=1234)\n\n        def new_get_index_dtype(arrays=(), maxval=None, check_contents=False):\n            return (np.int32, np.int64)[counter.randint(2)]\n    else:\n        def new_get_index_dtype(arrays=(), maxval=None, check_contents=False):\n            dtype = np.int32\n            if maxval is not None:\n                if maxval > maxval_limit:\n                    dtype = np.int64\n            for arr in arrays:\n                arr = np.asarray(arr)\n                if arr.dtype > np.int32:\n                    if check_contents:\n                        if arr.size == 0:\n                            # a bigger type not needed\n                            continue\n                        elif np.issubdtype(arr.dtype, np.integer):\n                            maxval = arr.max()\n                            minval = arr.min()\n                            if minval >= -maxval_limit and maxval <= maxval_limit:\n                                # a bigger type not needed\n                                continue\n                    dtype = np.int64\n            return dtype\n\n    if downcast_maxval is not None:\n        def new_downcast_intp_index(arr):\n            if arr.max() > downcast_maxval:\n                raise AssertionError(\"downcast limited\")\n            return arr.astype(np.intp)\n\n    @decorator\n    def deco(func, *a, **kw):\n        backup = []\n        modules = [scipy.sparse.bsr, scipy.sparse.coo, scipy.sparse.csc,\n                   scipy.sparse.csr, scipy.sparse.dia, scipy.sparse.dok,\n                   scipy.sparse.lil, scipy.sparse.sputils,\n                   scipy.sparse.compressed, scipy.sparse.construct]\n        try:\n            for mod in modules:\n                backup.append((mod, 'get_index_dtype',\n                               getattr(mod, 'get_index_dtype', None)))\n                setattr(mod, 'get_index_dtype', new_get_index_dtype)\n                if downcast_maxval is not None:\n                    backup.append((mod, 'downcast_intp_index',\n                                   getattr(mod, 'downcast_intp_index', None)))\n                    setattr(mod, 'downcast_intp_index', new_downcast_intp_index)\n            return func(*a, **kw)\n        finally:\n            for mod, name, oldfunc in backup:\n                if oldfunc is not None:\n                    setattr(mod, name, oldfunc)\n\n    return deco\n\n\ndef todense(a):\n    if isinstance(a, np.ndarray) or isscalarlike(a):\n        return a\n    return a.todense()\n\n\nclass BinopTester(object):\n    # Custom type to test binary operations on sparse matrices.\n\n    def __add__(self, mat):\n        return \"matrix on the right\"\n\n    def __mul__(self, mat):\n        return \"matrix on the right\"\n\n    def __sub__(self, mat):\n        return \"matrix on the right\"\n\n    def __radd__(self, mat):\n        return \"matrix on the left\"\n\n    def __rmul__(self, mat):\n        return \"matrix on the left\"\n\n    def __rsub__(self, mat):\n        return \"matrix on the left\"\n\n\n#------------------------------------------------------------------------------\n# Generic tests\n#------------------------------------------------------------------------------\n\n\n# TODO check that spmatrix( ... , copy=X ) is respected\n# TODO test prune\n# TODO test has_sorted_indices\nclass _TestCommon:\n    \"\"\"test common functionality shared by all sparse formats\"\"\"\n    math_dtypes = supported_dtypes\n\n    def __init__(self):\n        # Canonical data.\n        self.dat = matrix([[1,0,0,2],[3,0,1,0],[0,2,0,0]],'d')\n        self.datsp = self.spmatrix(self.dat)\n\n        # Some sparse and dense matrices with data for every supported\n        # dtype.\n        # This set union is a workaround for numpy#6295, which means that\n        # two np.int64 dtypes don't hash to the same value.\n        self.checked_dtypes = set(supported_dtypes).union(self.math_dtypes)\n        self.dat_dtypes = {}\n        self.datsp_dtypes = {}\n        for dtype in self.checked_dtypes:\n            self.dat_dtypes[dtype] = self.dat.astype(dtype)\n            self.datsp_dtypes[dtype] = self.spmatrix(self.dat.astype(dtype))\n\n        # Check that the original data is equivalent to the\n        # corresponding dat_dtypes & datsp_dtypes.\n        assert_equal(self.dat, self.dat_dtypes[np.float64])\n        assert_equal(self.datsp.todense(),\n                     self.datsp_dtypes[np.float64].todense())\n\n    def test_bool(self):\n        def check(dtype):\n            datsp = self.datsp_dtypes[dtype]\n\n            assert_raises(ValueError, bool, datsp)\n            assert_(self.spmatrix([1]))\n            assert_(not self.spmatrix([0]))\n        for dtype in self.checked_dtypes:\n            fails = isinstance(self, TestDOK)\n            msg = \"Cannot create a rank <= 2 DOK matrix.\"\n            yield dec.skipif(fails, msg)(check), dtype\n\n    def test_bool_rollover(self):\n        # bool's underlying dtype is 1 byte, check that it does not\n        # rollover True -> False at 256.\n        dat = np.matrix([[True, False]])\n        datsp = self.spmatrix(dat)\n\n        for _ in range(10):\n            datsp = datsp + datsp\n            dat = dat + dat\n        assert_array_equal(dat, datsp.todense())\n\n    def test_eq(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n            dat2 = dat.copy()\n            dat2[:,0] = 0\n            datsp2 = self.spmatrix(dat2)\n            datbsr = bsr_matrix(dat)\n            datcsr = csr_matrix(dat)\n            datcsc = csc_matrix(dat)\n            datlil = lil_matrix(dat)\n\n            # sparse/sparse\n            assert_array_equal(dat == dat2, (datsp == datsp2).todense())\n            # mix sparse types\n            assert_array_equal(dat == dat2, (datbsr == datsp2).todense())\n            assert_array_equal(dat == dat2, (datcsr == datsp2).todense())\n            assert_array_equal(dat == dat2, (datcsc == datsp2).todense())\n            assert_array_equal(dat == dat2, (datlil == datsp2).todense())\n            # sparse/dense\n            assert_array_equal(dat == datsp2, datsp2 == dat)\n            # sparse/scalar\n            assert_array_equal(dat == 0, (datsp == 0).todense())\n            assert_array_equal(dat == 1, (datsp == 1).todense())\n            assert_array_equal(dat == np.nan, (datsp == np.nan).todense())\n\n        msg = \"Bool comparisons only implemented for BSR, CSC, and CSR.\"\n        fails = not isinstance(self, (TestBSR, TestCSC, TestCSR))\n        for dtype in self.checked_dtypes:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=np.ComplexWarning)\n                warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n                yield dec.skipif(fails, msg)(check), dtype\n\n    def test_ne(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n            dat2 = dat.copy()\n            dat2[:,0] = 0\n            datsp2 = self.spmatrix(dat2)\n            datbsr = bsr_matrix(dat)\n            datcsc = csc_matrix(dat)\n            datcsr = csr_matrix(dat)\n            datlil = lil_matrix(dat)\n\n            # sparse/sparse\n            assert_array_equal(dat != dat2, (datsp != datsp2).todense())\n            # mix sparse types\n            assert_array_equal(dat != dat2, (datbsr != datsp2).todense())\n            assert_array_equal(dat != dat2, (datcsc != datsp2).todense())\n            assert_array_equal(dat != dat2, (datcsr != datsp2).todense())\n            assert_array_equal(dat != dat2, (datlil != datsp2).todense())\n            # sparse/dense\n            assert_array_equal(dat != datsp2, datsp2 != dat)\n            # sparse/scalar\n            assert_array_equal(dat != 0, (datsp != 0).todense())\n            assert_array_equal(dat != 1, (datsp != 1).todense())\n            assert_array_equal(0 != dat, (0 != datsp).todense())\n            assert_array_equal(1 != dat, (1 != datsp).todense())\n            assert_array_equal(dat != np.nan, (datsp != np.nan).todense())\n\n        msg = \"Bool comparisons only implemented for BSR, CSC, and CSR.\"\n        fails = not isinstance(self, (TestBSR, TestCSC, TestCSR))\n        for dtype in self.checked_dtypes:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=np.ComplexWarning)\n                warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n                yield dec.skipif(fails, msg)(check), dtype\n\n    def test_lt(self):\n        def check(dtype):\n            # data\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n            dat2 = dat.copy()\n            dat2[:,0] = 0\n            datsp2 = self.spmatrix(dat2)\n            datcomplex = dat.astype(np.complex)\n            datcomplex[:,0] = 1 + 1j\n            datspcomplex = self.spmatrix(datcomplex)\n            datbsr = bsr_matrix(dat)\n            datcsc = csc_matrix(dat)\n            datcsr = csr_matrix(dat)\n            datlil = lil_matrix(dat)\n\n            # sparse/sparse\n            assert_array_equal(dat < dat2, (datsp < datsp2).todense())\n            assert_array_equal(datcomplex < dat2, (datspcomplex < datsp2).todense())\n            # mix sparse types\n            assert_array_equal(dat < dat2, (datbsr < datsp2).todense())\n            assert_array_equal(dat < dat2, (datcsc < datsp2).todense())\n            assert_array_equal(dat < dat2, (datcsr < datsp2).todense())\n            assert_array_equal(dat < dat2, (datlil < datsp2).todense())\n\n            assert_array_equal(dat2 < dat, (datsp2 < datbsr).todense())\n            assert_array_equal(dat2 < dat, (datsp2 < datcsc).todense())\n            assert_array_equal(dat2 < dat, (datsp2 < datcsr).todense())\n            assert_array_equal(dat2 < dat, (datsp2 < datlil).todense())\n            # sparse/dense\n            assert_array_equal(dat < dat2, datsp < dat2)\n            assert_array_equal(datcomplex < dat2, datspcomplex < dat2)\n            # sparse/scalar\n            assert_array_equal((datsp < 2).todense(), dat < 2)\n            assert_array_equal((datsp < 1).todense(), dat < 1)\n            assert_array_equal((datsp < 0).todense(), dat < 0)\n            assert_array_equal((datsp < -1).todense(), dat < -1)\n            assert_array_equal((datsp < -2).todense(), dat < -2)\n            with np.errstate(invalid='ignore'):\n                assert_array_equal((datsp < np.nan).todense(), dat < np.nan)\n\n            assert_array_equal((2 < datsp).todense(), 2 < dat)\n            assert_array_equal((1 < datsp).todense(), 1 < dat)\n            assert_array_equal((0 < datsp).todense(), 0 < dat)\n            assert_array_equal((-1 < datsp).todense(), -1 < dat)\n            assert_array_equal((-2 < datsp).todense(), -2 < dat)\n\n            if NumpyVersion(np.__version__) >= '1.8.0':\n                # data\n                dat = self.dat_dtypes[dtype]\n                datsp = self.datsp_dtypes[dtype]\n                dat2 = dat.copy()\n                dat2[:,0] = 0\n                datsp2 = self.spmatrix(dat2)\n\n                # dense rhs\n                assert_array_equal(dat < datsp2, datsp < dat2)\n\n        msg = \"Bool comparisons only implemented for BSR, CSC, and CSR.\"\n        fails = not isinstance(self, (TestBSR, TestCSC, TestCSR))\n        for dtype in self.checked_dtypes:\n            with warnings.catch_warnings():\n                with np.errstate(invalid='ignore'):\n                    warnings.simplefilter(\"ignore\", category=np.ComplexWarning)\n                    warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n                    yield dec.skipif(fails, msg)(check), dtype\n\n    def test_gt(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n            dat2 = dat.copy()\n            dat2[:,0] = 0\n            datsp2 = self.spmatrix(dat2)\n            datcomplex = dat.astype(np.complex)\n            datcomplex[:,0] = 1 + 1j\n            datspcomplex = self.spmatrix(datcomplex)\n            datbsr = bsr_matrix(dat)\n            datcsc = csc_matrix(dat)\n            datcsr = csr_matrix(dat)\n            datlil = lil_matrix(dat)\n\n            # sparse/sparse\n            assert_array_equal(dat > dat2, (datsp > datsp2).todense())\n            assert_array_equal(datcomplex > dat2, (datspcomplex > datsp2).todense())\n            # mix sparse types\n            assert_array_equal(dat > dat2, (datbsr > datsp2).todense())\n            assert_array_equal(dat > dat2, (datcsc > datsp2).todense())\n            assert_array_equal(dat > dat2, (datcsr > datsp2).todense())\n            assert_array_equal(dat > dat2, (datlil > datsp2).todense())\n\n            assert_array_equal(dat2 > dat, (datsp2 > datbsr).todense())\n            assert_array_equal(dat2 > dat, (datsp2 > datcsc).todense())\n            assert_array_equal(dat2 > dat, (datsp2 > datcsr).todense())\n            assert_array_equal(dat2 > dat, (datsp2 > datlil).todense())\n            # sparse/dense\n            assert_array_equal(dat > dat2, datsp > dat2)\n            assert_array_equal(datcomplex > dat2, datspcomplex > dat2)\n            # sparse/scalar\n            assert_array_equal((datsp > 2).todense(), dat > 2)\n            assert_array_equal((datsp > 1).todense(), dat > 1)\n            assert_array_equal((datsp > 0).todense(), dat > 0)\n            assert_array_equal((datsp > -1).todense(), dat > -1)\n            assert_array_equal((datsp > -2).todense(), dat > -2)\n            with np.errstate(invalid='ignore'):\n                assert_array_equal((datsp > np.nan).todense(), dat > np.nan)\n\n            assert_array_equal((2 > datsp).todense(), 2 > dat)\n            assert_array_equal((1 > datsp).todense(), 1 > dat)\n            assert_array_equal((0 > datsp).todense(), 0 > dat)\n            assert_array_equal((-1 > datsp).todense(), -1 > dat)\n            assert_array_equal((-2 > datsp).todense(), -2 > dat)\n\n            if NumpyVersion(np.__version__) >= '1.8.0':\n                # data\n                dat = self.dat_dtypes[dtype]\n                datsp = self.datsp_dtypes[dtype]\n                dat2 = dat.copy()\n                dat2[:,0] = 0\n                datsp2 = self.spmatrix(dat2)\n\n                # dense rhs\n                assert_array_equal(dat > datsp2, datsp > dat2)\n\n        msg = \"Bool comparisons only implemented for BSR, CSC, and CSR.\"\n        fails = not isinstance(self, (TestBSR, TestCSC, TestCSR))\n        for dtype in self.checked_dtypes:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=np.ComplexWarning)\n                warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n                yield dec.skipif(fails, msg)(check), dtype\n\n    def test_le(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n            dat2 = dat.copy()\n            dat2[:,0] = 0\n            datsp2 = self.spmatrix(dat2)\n            datcomplex = dat.astype(np.complex)\n            datcomplex[:,0] = 1 + 1j\n            datspcomplex = self.spmatrix(datcomplex)\n            datbsr = bsr_matrix(dat)\n            datcsc = csc_matrix(dat)\n            datcsr = csr_matrix(dat)\n            datlil = lil_matrix(dat)\n\n            # sparse/sparse\n            assert_array_equal(dat <= dat2, (datsp <= datsp2).todense())\n            assert_array_equal(datcomplex <= dat2, (datspcomplex <= datsp2).todense())\n            # mix sparse types\n            assert_array_equal((datbsr <= datsp2).todense(), dat <= dat2)\n            assert_array_equal((datcsc <= datsp2).todense(), dat <= dat2)\n            assert_array_equal((datcsr <= datsp2).todense(), dat <= dat2)\n            assert_array_equal((datlil <= datsp2).todense(), dat <= dat2)\n\n            assert_array_equal((datsp2 <= datbsr).todense(), dat2 <= dat)\n            assert_array_equal((datsp2 <= datcsc).todense(), dat2 <= dat)\n            assert_array_equal((datsp2 <= datcsr).todense(), dat2 <= dat)\n            assert_array_equal((datsp2 <= datlil).todense(), dat2 <= dat)\n            # sparse/dense\n            assert_array_equal(datsp <= dat2, dat <= dat2)\n            assert_array_equal(datspcomplex <= dat2, datcomplex <= dat2)\n            # sparse/scalar\n            assert_array_equal((datsp <= 2).todense(), dat <= 2)\n            assert_array_equal((datsp <= 1).todense(), dat <= 1)\n            assert_array_equal((datsp <= -1).todense(), dat <= -1)\n            assert_array_equal((datsp <= -2).todense(), dat <= -2)\n\n            assert_array_equal((2 <= datsp).todense(), 2 <= dat)\n            assert_array_equal((1 <= datsp).todense(), 1 <= dat)\n            assert_array_equal((-1 <= datsp).todense(), -1 <= dat)\n            assert_array_equal((-2 <= datsp).todense(), -2 <= dat)\n\n            if NumpyVersion(np.__version__) >= '1.8.0':\n                # data\n                dat = self.dat_dtypes[dtype]\n                datsp = self.datsp_dtypes[dtype]\n                dat2 = dat.copy()\n                dat2[:,0] = 0\n                datsp2 = self.spmatrix(dat2)\n\n                # dense rhs\n                assert_array_equal(dat <= datsp2, datsp <= dat2)\n\n        msg = \"Bool comparisons only implemented for BSR, CSC, and CSR.\"\n        fails = not isinstance(self, (TestBSR, TestCSC, TestCSR))\n        for dtype in self.checked_dtypes:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=np.ComplexWarning)\n                warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n                yield dec.skipif(fails, msg)(check), dtype\n\n    def test_ge(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n            dat2 = dat.copy()\n            dat2[:,0] = 0\n            datsp2 = self.spmatrix(dat2)\n            datcomplex = dat.astype(np.complex)\n            datcomplex[:,0] = 1 + 1j\n            datspcomplex = self.spmatrix(datcomplex)\n            datbsr = bsr_matrix(dat)\n            datcsc = csc_matrix(dat)\n            datcsr = csr_matrix(dat)\n            datlil = lil_matrix(dat)\n\n            # sparse/sparse\n            assert_array_equal(dat >= dat2, (datsp >= datsp2).todense())\n            assert_array_equal(datcomplex >= dat2, (datspcomplex >= datsp2).todense())\n            # mix sparse types\n            # mix sparse types\n            assert_array_equal((datbsr >= datsp2).todense(), dat >= dat2)\n            assert_array_equal((datcsc >= datsp2).todense(), dat >= dat2)\n            assert_array_equal((datcsr >= datsp2).todense(), dat >= dat2)\n            assert_array_equal((datlil >= datsp2).todense(), dat >= dat2)\n\n            assert_array_equal((datsp2 >= datbsr).todense(), dat2 >= dat)\n            assert_array_equal((datsp2 >= datcsc).todense(), dat2 >= dat)\n            assert_array_equal((datsp2 >= datcsr).todense(), dat2 >= dat)\n            assert_array_equal((datsp2 >= datlil).todense(), dat2 >= dat)\n            # sparse/dense\n            assert_array_equal(datsp >= dat2, dat >= dat2)\n            assert_array_equal(datspcomplex >= dat2, datcomplex >= dat2)\n            # sparse/scalar\n            assert_array_equal((datsp >= 2).todense(), dat >= 2)\n            assert_array_equal((datsp >= 1).todense(), dat >= 1)\n            assert_array_equal((datsp >= -1).todense(), dat >= -1)\n            assert_array_equal((datsp >= -2).todense(), dat >= -2)\n\n            assert_array_equal((2 >= datsp).todense(), 2 >= dat)\n            assert_array_equal((1 >= datsp).todense(), 1 >= dat)\n            assert_array_equal((-1 >= datsp).todense(), -1 >= dat)\n            assert_array_equal((-2 >= datsp).todense(), -2 >= dat)\n\n            if NumpyVersion(np.__version__) >= '1.8.0':\n                # dense data\n                dat = self.dat_dtypes[dtype]\n                datsp = self.datsp_dtypes[dtype]\n                dat2 = dat.copy()\n                dat2[:,0] = 0\n                datsp2 = self.spmatrix(dat2)\n\n                # dense rhs\n                assert_array_equal(dat >= datsp2, datsp >= dat2)\n\n        msg = \"Bool comparisons only implemented for BSR, CSC, and CSR.\"\n        fails = not isinstance(self, (TestBSR, TestCSC, TestCSR))\n        for dtype in self.checked_dtypes:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=np.ComplexWarning)\n                warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n                yield dec.skipif(fails, msg)(check), dtype\n\n    def test_empty(self):\n        # create empty matrices\n        assert_equal(self.spmatrix((3,3)).todense(), np.zeros((3,3)))\n        assert_equal(self.spmatrix((3,3)).nnz, 0)\n\n    def test_invalid_shapes(self):\n        assert_raises(ValueError, self.spmatrix, (-1,3))\n        assert_raises(ValueError, self.spmatrix, (3,-1))\n        assert_raises(ValueError, self.spmatrix, (-1,-1))\n\n    def test_repr(self):\n        repr(self.datsp)\n\n    def test_str(self):\n        str(self.datsp)\n\n    def test_empty_arithmetic(self):\n        # Test manipulating empty matrices. Fails in SciPy SVN <= r1768\n        shape = (5, 5)\n        for mytype in [np.dtype('int32'), np.dtype('float32'),\n                np.dtype('float64'), np.dtype('complex64'),\n                np.dtype('complex128')]:\n            a = self.spmatrix(shape, dtype=mytype)\n            b = a + a\n            c = 2 * a\n            d = a * a.tocsc()\n            e = a * a.tocsr()\n            f = a * a.tocoo()\n            for m in [a,b,c,d,e,f]:\n                assert_equal(m.A, a.A*a.A)\n                # These fail in all revisions <= r1768:\n                assert_equal(m.dtype,mytype)\n                assert_equal(m.A.dtype,mytype)\n\n    def test_abs(self):\n        A = matrix([[-1, 0, 17],[0, -5, 0],[1, -4, 0],[0,0,0]],'d')\n        assert_equal(abs(A),abs(self.spmatrix(A)).todense())\n        \n    def test_elementwise_power(self):\n        A = matrix([[-4, -3, -2],[-1, 0, 1],[2, 3, 4]], 'd')        \n        assert_equal(np.power(A, 2), self.spmatrix(A).power(2).todense())\n                \n        #it's element-wise power function, input has to be a scalar\n        assert_raises(NotImplementedError, self.spmatrix(A).power, A)       \n\n    def test_neg(self):\n        A = matrix([[-1, 0, 17],[0, -5, 0],[1, -4, 0],[0,0,0]],'d')\n        assert_equal(-A,(-self.spmatrix(A)).todense())\n\n    def test_real(self):\n        D = matrix([[1 + 3j, 2 - 4j]])\n        A = self.spmatrix(D)\n        assert_equal(A.real.todense(),D.real)\n\n    def test_imag(self):\n        D = matrix([[1 + 3j, 2 - 4j]])\n        A = self.spmatrix(D)\n        assert_equal(A.imag.todense(),D.imag)\n\n    def test_diagonal(self):\n        # Does the matrix's .diagonal() method work?\n        mats = []\n        mats.append([[1,0,2]])\n        mats.append([[1],[0],[2]])\n        mats.append([[0,1],[0,2],[0,3]])\n        mats.append([[0,0,1],[0,0,2],[0,3,0]])\n\n        mats.append(kron(mats[0],[[1,2]]))\n        mats.append(kron(mats[0],[[1],[2]]))\n        mats.append(kron(mats[1],[[1,2],[3,4]]))\n        mats.append(kron(mats[2],[[1,2],[3,4]]))\n        mats.append(kron(mats[3],[[1,2],[3,4]]))\n        mats.append(kron(mats[3],[[1,2,3,4]]))\n\n        for m in mats:\n            assert_equal(self.spmatrix(m).diagonal(),diag(m))        \n\n    @dec.slow\n    def test_setdiag(self):\n        def dense_setdiag(a, v, k):\n            v = np.asarray(v)\n            if k >= 0:\n                n = min(a.shape[0], a.shape[1] - k)\n                if v.ndim != 0:\n                    n = min(n, len(v))\n                    v = v[:n]\n                i = np.arange(0, n)\n                j = np.arange(k, k + n)\n                a[i,j] = v\n            elif k < 0:\n                dense_setdiag(a.T, v, -k)\n                return\n\n        def check_setdiag(a, b, k):\n            # Check setting diagonal using a scalar, a vector of\n            # correct length, and too short or too long vectors\n            for r in [-1, len(np.diag(a, k)), 2, 30]:\n                if r < 0:\n                    v = int(np.random.randint(1, 20, size=1))\n                else:\n                    v = np.random.randint(1, 20, size=r)\n\n                dense_setdiag(a, v, k)\n                b.setdiag(v, k)\n\n                # check that dense_setdiag worked\n                d = np.diag(a, k)\n                if np.asarray(v).ndim == 0:\n                    assert_array_equal(d, v, err_msg=msg + \" %d\" % (r,))\n                else:\n                    n = min(len(d), len(v))\n                    assert_array_equal(d[:n], v[:n], err_msg=msg + \" %d\" % (r,))\n                # check that sparse setdiag worked\n                assert_array_equal(b.A, a, err_msg=msg + \" %d\" % (r,))\n\n        # comprehensive test\n        np.random.seed(1234)\n        for dtype in [np.int8, np.float64]:\n            for m in [0, 1, 3, 10]:\n                for n in [0, 1, 3, 10]:\n                    for k in range(-m+1, n-1):\n                        msg = repr((dtype, m, n, k))\n                        a = np.zeros((m, n), dtype=dtype)\n                        b = self.spmatrix((m, n), dtype=dtype)\n\n                        check_setdiag(a, b, k)\n\n                        # check overwriting etc\n                        for k2 in np.random.randint(-m+1, n-1, size=12):\n                            check_setdiag(a, b, k2)\n\n        # simpler test case\n        m = self.spmatrix(np.eye(3))\n        values = [3, 2, 1]\n        assert_raises(ValueError, m.setdiag, values, k=4)\n        m.setdiag(values)\n        assert_array_equal(m.diagonal(), values)\n        m.setdiag(values, k=1)\n        assert_array_equal(m.A, np.array([[3, 3, 0],\n                                          [0, 2, 2],\n                                          [0, 0, 1]]))\n        m.setdiag(values, k=-2)\n        assert_array_equal(m.A, np.array([[3, 3, 0],\n                                          [0, 2, 2],\n                                          [3, 0, 1]]))\n        m.setdiag((9,), k=2)\n        assert_array_equal(m.A[0,2], 9)\n        m.setdiag((9,), k=-2)\n        assert_array_equal(m.A[2,0], 9)\n\n    def test_nonzero(self):\n        A = array([[1, 0, 1],[0, 1, 1],[0, 0, 1]])\n        Asp = self.spmatrix(A)\n\n        A_nz = set([tuple(ij) for ij in transpose(A.nonzero())])\n        Asp_nz = set([tuple(ij) for ij in transpose(Asp.nonzero())])\n\n        assert_equal(A_nz, Asp_nz)\n\n    def test_getrow(self):\n        assert_array_equal(self.datsp.getrow(1).todense(), self.dat[1,:])\n        assert_array_equal(self.datsp.getrow(-1).todense(), self.dat[-1,:])\n\n    def test_getcol(self):\n        assert_array_equal(self.datsp.getcol(1).todense(), self.dat[:,1])\n        assert_array_equal(self.datsp.getcol(-1).todense(), self.dat[:,-1])\n\n    def test_sum(self):\n        np.random.seed(1234)\n        dat_1 = np.matrix([[0, 1, 2],\n                           [3, -4, 5],\n                           [-6, 7, 9]])\n        dat_2 = np.random.rand(40, 40)\n        dat_3 = np.array([[]])\n        dat_4 = np.zeros((40, 40))\n        dat_5 = sparse.rand(40, 40, density=1e-2).A\n        matrices = [dat_1, dat_2, dat_3, dat_4, dat_5]\n\n        def check(dtype, j):\n            dat = np.matrix(matrices[j], dtype=dtype)\n            datsp = self.spmatrix(dat, dtype=dtype)\n\n            assert_array_almost_equal(dat.sum(), datsp.sum())\n            assert_equal(dat.sum().dtype, datsp.sum().dtype)\n            assert_array_almost_equal(dat.sum(axis=None), datsp.sum(axis=None))\n            assert_equal(dat.sum(axis=None).dtype, datsp.sum(axis=None).dtype)\n            assert_array_almost_equal(dat.sum(axis=0), datsp.sum(axis=0))\n            assert_equal(dat.sum(axis=0).dtype, datsp.sum(axis=0).dtype)\n            assert_array_almost_equal(dat.sum(axis=1), datsp.sum(axis=1))\n            assert_equal(dat.sum(axis=1).dtype, datsp.sum(axis=1).dtype)\n            if NumpyVersion(np.__version__) >= '1.7.0':\n                # np.matrix.sum with negative axis arg doesn't work for < 1.7\n                assert_array_almost_equal(dat.sum(axis=-2), datsp.sum(axis=-2))\n                assert_equal(dat.sum(axis=-2).dtype, datsp.sum(axis=-2).dtype)\n                assert_array_almost_equal(dat.sum(axis=-1), datsp.sum(axis=-1))\n                assert_equal(dat.sum(axis=-1).dtype, datsp.sum(axis=-1).dtype)\n\n        for dtype in self.math_dtypes:\n            for j in range(len(matrices)):\n                yield check, dtype, j\n\n    def test_mean(self):\n        def check(dtype):\n            dat = np.matrix([[0, 1, 2],\n                            [3, -4, 5],\n                            [-6, 7, 9]], dtype=dtype)\n            datsp = self.spmatrix(dat, dtype=dtype)\n\n            assert_array_almost_equal(dat.mean(), datsp.mean())\n            assert_equal(dat.mean().dtype, datsp.mean().dtype)\n            assert_array_almost_equal(dat.mean(axis=None), datsp.mean(axis=None))\n            assert_equal(dat.mean(axis=None).dtype, datsp.mean(axis=None).dtype)\n            assert_array_almost_equal(dat.mean(axis=0), datsp.mean(axis=0))\n            assert_equal(dat.mean(axis=0).dtype, datsp.mean(axis=0).dtype)\n            assert_array_almost_equal(dat.mean(axis=1), datsp.mean(axis=1))\n            assert_equal(dat.mean(axis=1).dtype, datsp.mean(axis=1).dtype)\n            if NumpyVersion(np.__version__) >= '1.7.0':\n                # np.matrix.sum with negative axis arg doesn't work for < 1.7\n                assert_array_almost_equal(dat.mean(axis=-2), datsp.mean(axis=-2))\n                assert_equal(dat.mean(axis=-2).dtype, datsp.mean(axis=-2).dtype)\n                assert_array_almost_equal(dat.mean(axis=-1), datsp.mean(axis=-1))\n                assert_equal(dat.mean(axis=-1).dtype, datsp.mean(axis=-1).dtype)\n\n        for dtype in self.math_dtypes:\n            yield check, dtype\n\n    def test_expm(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n\n            M = array([[1, 0, 2], [0, 0, 3], [-4, 5, 6]], float)\n            sM = self.spmatrix(M, shape=(3,3), dtype=float)\n            Mexp = scipy.linalg.expm(M)\n            sMexp = expm(sM).todense()\n            assert_array_almost_equal((sMexp - Mexp), zeros((3, 3)))\n\n            N = array([[3., 0., 1.], [0., 2., 0.], [0., 0., 0.]])\n            sN = self.spmatrix(N, shape=(3,3), dtype=float)\n            Nexp = scipy.linalg.expm(N)\n            sNexp = expm(sN).todense()\n            assert_array_almost_equal((sNexp - Nexp), zeros((3, 3)))\n\n    def test_inv(self):\n        def check(dtype):\n            M = array([[1, 0, 2], [0, 0, 3], [-4, 5, 6]], dtype)\n            sM = self.spmatrix(M, shape=(3,3), dtype=dtype)\n            sMinv = inv(sM)\n            assert_array_almost_equal(sMinv.dot(sM).todense(), np.eye(3))\n        for dtype in [float]:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n                yield check, dtype\n\n    def test_from_array(self):\n        A = array([[1,0,0],[2,3,4],[0,5,0],[0,0,0]])\n        assert_array_equal(self.spmatrix(A).toarray(), A)\n\n        A = array([[1.0 + 3j, 0, 0],\n                   [0, 2.0 + 5, 0],\n                   [0, 0, 0]])\n        assert_array_equal(self.spmatrix(A).toarray(), A)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=np.ComplexWarning)\n            assert_array_equal(self.spmatrix(A, dtype='int16').toarray(), A.astype('int16'))\n\n    def test_from_matrix(self):\n        A = matrix([[1,0,0],[2,3,4],[0,5,0],[0,0,0]])\n        assert_array_equal(self.spmatrix(A).todense(), A)\n\n        A = matrix([[1.0 + 3j, 0, 0],\n                    [0, 2.0 + 5, 0],\n                    [0, 0, 0]])\n        assert_array_equal(self.spmatrix(A).toarray(), A)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=np.ComplexWarning)\n            assert_array_equal(self.spmatrix(A, dtype='int16').toarray(), A.astype('int16'))\n\n    def test_from_list(self):\n        A = [[1,0,0],[2,3,4],[0,5,0],[0,0,0]]\n        assert_array_equal(self.spmatrix(A).todense(), A)\n\n        A = [[1.0 + 3j, 0, 0],\n             [0, 2.0 + 5, 0],\n             [0, 0, 0]]\n        assert_array_equal(self.spmatrix(A).toarray(), array(A))\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=np.ComplexWarning)\n            assert_array_equal(self.spmatrix(A, dtype='int16').todense(), array(A).astype('int16'))\n\n    def test_from_sparse(self):\n        D = array([[1,0,0],[2,3,4],[0,5,0],[0,0,0]])\n        S = csr_matrix(D)\n        assert_array_equal(self.spmatrix(S).toarray(), D)\n        S = self.spmatrix(D)\n        assert_array_equal(self.spmatrix(S).toarray(), D)\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=np.ComplexWarning)\n            D = array([[1.0 + 3j, 0, 0],\n                       [0, 2.0 + 5, 0],\n                       [0, 0, 0]])\n            S = csr_matrix(D)\n            assert_array_equal(self.spmatrix(S).toarray(), D)\n            assert_array_equal(self.spmatrix(S, dtype='int16').toarray(), D.astype('int16'))\n            S = self.spmatrix(D)\n            assert_array_equal(self.spmatrix(S).toarray(), D)\n            assert_array_equal(self.spmatrix(S, dtype='int16').toarray(), D.astype('int16'))\n\n    # def test_array(self):\n    #    \"\"\"test array(A) where A is in sparse format\"\"\"\n    #    assert_equal( array(self.datsp), self.dat )\n\n    def test_todense(self):\n        # Check C-contiguous (default).\n        chk = self.datsp.todense()\n        assert_array_equal(chk, self.dat)\n        assert_(chk.flags.c_contiguous)\n        assert_(not chk.flags.f_contiguous)\n        # Check C-contiguous (with arg).\n        chk = self.datsp.todense(order='C')\n        assert_array_equal(chk, self.dat)\n        assert_(chk.flags.c_contiguous)\n        assert_(not chk.flags.f_contiguous)\n        # Check F-contiguous (with arg).\n        chk = self.datsp.todense(order='F')\n        assert_array_equal(chk, self.dat)\n        assert_(not chk.flags.c_contiguous)\n        assert_(chk.flags.f_contiguous)\n        # Check with out argument (array).\n        out = np.zeros(self.datsp.shape, dtype=self.datsp.dtype)\n        chk = self.datsp.todense(out=out)\n        assert_array_equal(self.dat, out)\n        assert_array_equal(self.dat, chk)\n        assert_(chk.base is out)\n        # Check with out array (matrix).\n        out = np.asmatrix(np.zeros(self.datsp.shape, dtype=self.datsp.dtype))\n        chk = self.datsp.todense(out=out)\n        assert_array_equal(self.dat, out)\n        assert_array_equal(self.dat, chk)\n        assert_(chk is out)\n        a = matrix([1.,2.,3.])\n        dense_dot_dense = a * self.dat\n        check = a * self.datsp.todense()\n        assert_array_equal(dense_dot_dense, check)\n        b = matrix([1.,2.,3.,4.]).T\n        dense_dot_dense = self.dat * b\n        check2 = self.datsp.todense() * b\n        assert_array_equal(dense_dot_dense, check2)\n        # Check bool data works.\n        spbool = self.spmatrix(self.dat, dtype=bool)\n        matbool = self.dat.astype(bool)\n        assert_array_equal(spbool.todense(), matbool)\n\n    def test_toarray(self):\n        # Check C-contiguous (default).\n        dat = asarray(self.dat)\n        chk = self.datsp.toarray()\n        assert_array_equal(chk, dat)\n        assert_(chk.flags.c_contiguous)\n        assert_(not chk.flags.f_contiguous)\n        # Check C-contiguous (with arg).\n        chk = self.datsp.toarray(order='C')\n        assert_array_equal(chk, dat)\n        assert_(chk.flags.c_contiguous)\n        assert_(not chk.flags.f_contiguous)\n        # Check F-contiguous (with arg).\n        chk = self.datsp.toarray(order='F')\n        assert_array_equal(chk, dat)\n        assert_(not chk.flags.c_contiguous)\n        assert_(chk.flags.f_contiguous)\n        # Check with output arg.\n        out = np.zeros(self.datsp.shape, dtype=self.datsp.dtype)\n        self.datsp.toarray(out=out)\n        assert_array_equal(chk, dat)\n        # Check that things are fine when we don't initialize with zeros.\n        out[...] = 1.\n        self.datsp.toarray(out=out)\n        assert_array_equal(chk, dat)\n        a = array([1.,2.,3.])\n        dense_dot_dense = dot(a, dat)\n        check = dot(a, self.datsp.toarray())\n        assert_array_equal(dense_dot_dense, check)\n        b = array([1.,2.,3.,4.])\n        dense_dot_dense = dot(dat, b)\n        check2 = dot(self.datsp.toarray(), b)\n        assert_array_equal(dense_dot_dense, check2)\n        # Check bool data works.\n        spbool = self.spmatrix(self.dat, dtype=bool)\n        arrbool = dat.astype(bool)\n        assert_array_equal(spbool.toarray(), arrbool)\n\n    def test_astype(self):\n        D = array([[2.0 + 3j, 0, 0],\n                   [0, 4.0 + 5j, 0],\n                   [0, 0, 0]])\n        S = self.spmatrix(D)\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=np.ComplexWarning)\n\n            for x in supported_dtypes:\n                assert_equal(S.astype(x).dtype, D.astype(x).dtype)  # correct type\n                assert_equal(S.astype(x).toarray(), D.astype(x))        # correct values\n                assert_equal(S.astype(x).format, S.format)           # format preserved\n\n    def test_asfptype(self):\n        A = self.spmatrix(arange(6,dtype='int32').reshape(2,3))\n\n        assert_equal(A.dtype, np.dtype('int32'))\n        assert_equal(A.asfptype().dtype, np.dtype('float64'))\n        assert_equal(A.asfptype().format, A.format)\n        assert_equal(A.astype('int16').asfptype().dtype, np.dtype('float32'))\n        assert_equal(A.astype('complex128').asfptype().dtype, np.dtype('complex128'))\n\n        B = A.asfptype()\n        C = B.asfptype()\n        assert_(B is C)\n\n    def test_mul_scalar(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n\n            assert_array_equal(dat*2,(datsp*2).todense())\n            assert_array_equal(dat*17.3,(datsp*17.3).todense())\n\n        for dtype in self.math_dtypes:\n            yield check, dtype\n\n    def test_rmul_scalar(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n\n            assert_array_equal(2*dat,(2*datsp).todense())\n            assert_array_equal(17.3*dat,(17.3*datsp).todense())\n\n        for dtype in self.math_dtypes:\n            yield check, dtype\n\n    def test_add(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n\n            a = dat.copy()\n            a[0,2] = 2.0\n            b = datsp\n            c = b + a\n            assert_array_equal(c, b.todense() + a)\n\n            c = b + b.tocsr()\n            assert_array_equal(c.todense(),\n                               b.todense() + b.todense())\n\n        for dtype in self.math_dtypes:\n            yield check, dtype\n\n    def test_radd(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n\n            a = dat.copy()\n            a[0,2] = 2.0\n            b = datsp\n            c = a + b\n            assert_array_equal(c, a + b.todense())\n\n        for dtype in self.math_dtypes:\n            yield check, dtype\n\n    def test_sub(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n\n            assert_array_equal((datsp - datsp).todense(),[[0,0,0,0],[0,0,0,0],[0,0,0,0]])\n\n            A = self.spmatrix(matrix([[1,0,0,4],[-1,0,0,0],[0,8,0,-5]],'d'))\n            assert_array_equal((datsp - A).todense(),dat - A.todense())\n            assert_array_equal((A - datsp).todense(),A.todense() - dat)\n\n        for dtype in self.math_dtypes:\n            yield check, dtype\n\n    def test_rsub(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n\n            assert_array_equal((dat - datsp),[[0,0,0,0],[0,0,0,0],[0,0,0,0]])\n            assert_array_equal((datsp - dat),[[0,0,0,0],[0,0,0,0],[0,0,0,0]])\n\n            A = self.spmatrix(matrix([[1,0,0,4],[-1,0,0,0],[0,8,0,-5]],'d'))\n            assert_array_equal((dat - A),dat - A.todense())\n            assert_array_equal((A - dat),A.todense() - dat)\n            assert_array_equal(A.todense() - datsp,A.todense() - dat)\n            assert_array_equal(datsp - A.todense(),dat - A.todense())\n\n        for dtype in self.math_dtypes:\n            if (dtype == np.dtype('bool')) and (\n                    NumpyVersion(np.__version__) >= '1.9.0.dev'):\n                # boolean array subtraction deprecated in 1.9.0\n                continue\n\n            yield check, dtype\n\n    def test_add0(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n\n            # Adding 0 to a sparse matrix\n            assert_array_equal((datsp + 0).todense(), dat)\n            # use sum (which takes 0 as a starting value)\n            sumS = sum([k * datsp for k in range(1, 3)])\n            sumD = sum([k * dat for k in range(1, 3)])\n            assert_almost_equal(sumS.todense(), sumD)\n\n        for dtype in self.math_dtypes:\n            yield check, dtype\n\n    def test_elementwise_multiply(self):\n        # real/real\n        A = array([[4,0,9],[2,-3,5]])\n        B = array([[0,7,0],[0,-4,0]])\n        Asp = self.spmatrix(A)\n        Bsp = self.spmatrix(B)\n        assert_almost_equal(Asp.multiply(Bsp).todense(), A*B)  # sparse/sparse\n        assert_almost_equal(Asp.multiply(B), A*B)  # sparse/dense\n\n        # complex/complex\n        C = array([[1-2j,0+5j,-1+0j],[4-3j,-3+6j,5]])\n        D = array([[5+2j,7-3j,-2+1j],[0-1j,-4+2j,9]])\n        Csp = self.spmatrix(C)\n        Dsp = self.spmatrix(D)\n        assert_almost_equal(Csp.multiply(Dsp).todense(), C*D)  # sparse/sparse\n        assert_almost_equal(Csp.multiply(D), C*D)  # sparse/dense\n\n        # real/complex\n        assert_almost_equal(Asp.multiply(Dsp).todense(), A*D)  # sparse/sparse\n        assert_almost_equal(Asp.multiply(D), A*D)  # sparse/dense\n\n    def test_elementwise_multiply_broadcast(self):\n        A = array([4])\n        B = array([[-9]])\n        C = array([1,-1,0])\n        D = array([[7,9,-9]])\n        E = array([[3],[2],[1]])\n        F = array([[8,6,3],[-4,3,2],[6,6,6]])\n        G = [1, 2, 3]\n        H = np.ones((3, 4))\n        J = H.T\n\n        # Rank 1 arrays can't be cast as spmatrices (A and C) so leave\n        # them out.\n        Bsp = self.spmatrix(B)\n        Dsp = self.spmatrix(D)\n        Esp = self.spmatrix(E)\n        Fsp = self.spmatrix(F)\n        Hsp = self.spmatrix(H)\n        Hspp = self.spmatrix(H[0,None])\n        Jsp = self.spmatrix(J)\n        Jspp = self.spmatrix(J[:,0,None])\n\n        matrices = [A, B, C, D, E, F, G, H, J]\n        spmatrices = [Bsp, Dsp, Esp, Fsp, Hsp, Hspp, Jsp, Jspp]\n\n        # sparse/sparse\n        for i in spmatrices:\n            for j in spmatrices:\n                try:\n                    dense_mult = np.multiply(i.todense(), j.todense())\n                except ValueError:\n                    assert_raises(ValueError, i.multiply, j)\n                    continue\n                sp_mult = i.multiply(j)\n                if isspmatrix(sp_mult):\n                    assert_almost_equal(sp_mult.todense(), dense_mult)\n                else:\n                    assert_almost_equal(sp_mult, dense_mult)\n\n        # sparse/dense\n        for i in spmatrices:\n            for j in matrices:\n                try:\n                    dense_mult = np.multiply(i.todense(), j)\n                except ValueError:\n                    assert_raises(ValueError, i.multiply, j)\n                    continue\n                sp_mult = i.multiply(j)\n                if isspmatrix(sp_mult):\n                    assert_almost_equal(sp_mult.todense(), dense_mult)\n                else:\n                    assert_almost_equal(sp_mult, dense_mult)\n\n    def test_elementwise_divide(self):\n        expected = [[1,np.nan,np.nan,1],[1,np.nan,1,np.nan],[np.nan,1,np.nan,np.nan]]\n        assert_array_equal(todense(self.datsp / self.datsp),expected)\n\n        denom = self.spmatrix(matrix([[1,0,0,4],[-1,0,0,0],[0,8,0,-5]],'d'))\n        res = matrix([[1,np.nan,np.nan,0.5],[-3,np.nan,inf,np.nan],[np.nan,0.25,np.nan,np.nan]],'d')\n        assert_array_equal(todense(self.datsp / denom),res)\n\n        # complex\n        A = array([[1-2j,0+5j,-1+0j],[4-3j,-3+6j,5]])\n        B = array([[5+2j,7-3j,-2+1j],[0-1j,-4+2j,9]])\n        Asp = self.spmatrix(A)\n        Bsp = self.spmatrix(B)\n        assert_almost_equal(todense(Asp / Bsp), A/B)\n\n    def test_pow(self):\n        A = matrix([[1,0,2,0],[0,3,4,0],[0,5,0,0],[0,6,7,8]])\n        B = self.spmatrix(A)\n\n        for exponent in [0,1,2,3]:\n            assert_array_equal((B**exponent).todense(),A**exponent)\n\n        # invalid exponents\n        for exponent in [-1, 2.2, 1 + 3j]:\n            assert_raises(Exception, B.__pow__, exponent)\n\n        # nonsquare matrix\n        B = self.spmatrix(A[:3,:])\n        assert_raises(Exception, B.__pow__, 1)\n\n    def test_rmatvec(self):\n        M = self.spmatrix(matrix([[3,0,0],[0,1,0],[2,0,3.0],[2,3,0]]))\n        assert_array_almost_equal([1,2,3,4]*M, dot([1,2,3,4], M.toarray()))\n        row = matrix([[1,2,3,4]])\n        assert_array_almost_equal(row*M, row*M.todense())\n\n    def test_small_multiplication(self):\n        # test that A*x works for x with shape () (1,) and (1,1)\n        A = self.spmatrix([[1],[2],[3]])\n\n        assert_(isspmatrix(A * array(1)))\n        assert_equal((A * array(1)).todense(), [[1],[2],[3]])\n        assert_equal(A * array([1]), array([1,2,3]))\n        assert_equal(A * array([[1]]), array([[1],[2],[3]]))\n\n    def test_binop_custom_type(self):\n        # Non-regression test: previously, binary operations would raise\n        # NotImplementedError instead of returning NotImplemented\n        # (https://docs.python.org/library/constants.html#NotImplemented)\n        # so overloading Custom + matrix etc. didn't work.\n        A = self.spmatrix([[1], [2], [3]])\n        B = BinopTester()\n        assert_equal(A + B, \"matrix on the left\")\n        assert_equal(A - B, \"matrix on the left\")\n        assert_equal(A * B, \"matrix on the left\")\n        assert_equal(B + A, \"matrix on the right\")\n        assert_equal(B - A, \"matrix on the right\")\n        assert_equal(B * A, \"matrix on the right\")\n\n    def test_matvec(self):\n        M = self.spmatrix(matrix([[3,0,0],[0,1,0],[2,0,3.0],[2,3,0]]))\n        col = matrix([1,2,3]).T\n        assert_array_almost_equal(M * col, M.todense() * col)\n\n        # check result dimensions (ticket #514)\n        assert_equal((M * array([1,2,3])).shape,(4,))\n        assert_equal((M * array([[1],[2],[3]])).shape,(4,1))\n        assert_equal((M * matrix([[1],[2],[3]])).shape,(4,1))\n\n        # check result type\n        assert_(isinstance(M * array([1,2,3]), ndarray))\n        assert_(isinstance(M * matrix([1,2,3]).T, matrix))\n\n        # ensure exception is raised for improper dimensions\n        bad_vecs = [array([1,2]), array([1,2,3,4]), array([[1],[2]]),\n                    matrix([1,2,3]), matrix([[1],[2]])]\n        for x in bad_vecs:\n            assert_raises(ValueError, M.__mul__, x)\n\n        # Should this be supported or not?!\n        # flat = array([1,2,3])\n        # assert_array_almost_equal(M*flat, M.todense()*flat)\n        # Currently numpy dense matrices promote the result to a 1x3 matrix,\n        # whereas sparse matrices leave the result as a rank-1 array.  Which\n        # is preferable?\n\n        # Note: the following command does not work.  Both NumPy matrices\n        # and spmatrices should raise exceptions!\n        # assert_array_almost_equal(M*[1,2,3], M.todense()*[1,2,3])\n\n        # The current relationship between sparse matrix products and array\n        # products is as follows:\n        assert_array_almost_equal(M*array([1,2,3]), dot(M.A,[1,2,3]))\n        assert_array_almost_equal(M*[[1],[2],[3]], asmatrix(dot(M.A,[1,2,3])).T)\n        # Note that the result of M * x is dense if x has a singleton dimension.\n\n        # Currently M.matvec(asarray(col)) is rank-1, whereas M.matvec(col)\n        # is rank-2.  Is this desirable?\n\n    def test_matmat_sparse(self):\n        a = matrix([[3,0,0],[0,1,0],[2,0,3.0],[2,3,0]])\n        a2 = array([[3,0,0],[0,1,0],[2,0,3.0],[2,3,0]])\n        b = matrix([[0,1],[1,0],[0,2]],'d')\n        asp = self.spmatrix(a)\n        bsp = self.spmatrix(b)\n        assert_array_almost_equal((asp*bsp).todense(), a*b)\n        assert_array_almost_equal(asp*b, a*b)\n        assert_array_almost_equal(a*bsp, a*b)\n        assert_array_almost_equal(a2*bsp, a*b)\n\n        # Now try performing cross-type multplication:\n        csp = bsp.tocsc()\n        c = b\n        assert_array_almost_equal((asp*csp).todense(), a*c)\n        assert_array_almost_equal(asp*c, a*c)\n\n        assert_array_almost_equal(a*csp, a*c)\n        assert_array_almost_equal(a2*csp, a*c)\n        csp = bsp.tocsr()\n        assert_array_almost_equal((asp*csp).todense(), a*c)\n        assert_array_almost_equal(asp*c, a*c)\n\n        assert_array_almost_equal(a*csp, a*c)\n        assert_array_almost_equal(a2*csp, a*c)\n        csp = bsp.tocoo()\n        assert_array_almost_equal((asp*csp).todense(), a*c)\n        assert_array_almost_equal(asp*c, a*c)\n\n        assert_array_almost_equal(a*csp, a*c)\n        assert_array_almost_equal(a2*csp, a*c)\n\n        # Test provided by Andy Fraser, 2006-03-26\n        L = 30\n        frac = .3\n        random.seed(0)  # make runs repeatable\n        A = zeros((L,2))\n        for i in xrange(L):\n            for j in xrange(2):\n                r = random.random()\n                if r < frac:\n                    A[i,j] = r/frac\n\n        A = self.spmatrix(A)\n        B = A*A.T\n        assert_array_almost_equal(B.todense(), A.todense() * A.T.todense())\n        assert_array_almost_equal(B.todense(), A.todense() * A.todense().T)\n\n        # check dimension mismatch  2x2 times 3x2\n        A = self.spmatrix([[1,2],[3,4]])\n        B = self.spmatrix([[1,2],[3,4],[5,6]])\n        assert_raises(ValueError, A.__mul__, B)\n\n    def test_matmat_dense(self):\n        a = matrix([[3,0,0],[0,1,0],[2,0,3.0],[2,3,0]])\n        asp = self.spmatrix(a)\n\n        # check both array and matrix types\n        bs = [array([[1,2],[3,4],[5,6]]), matrix([[1,2],[3,4],[5,6]])]\n\n        for b in bs:\n            result = asp*b\n            assert_(isinstance(result, type(b)))\n            assert_equal(result.shape, (4,2))\n            assert_equal(result, dot(a,b))\n\n    def test_sparse_format_conversions(self):\n        A = sparse.kron([[1,0,2],[0,3,4],[5,0,0]], [[1,2],[0,3]])\n        D = A.todense()\n        A = self.spmatrix(A)\n\n        for format in ['bsr','coo','csc','csr','dia','dok','lil']:\n            a = A.asformat(format)\n            assert_equal(a.format,format)\n            assert_array_equal(a.todense(), D)\n\n            b = self.spmatrix(D+3j).asformat(format)\n            assert_equal(b.format,format)\n            assert_array_equal(b.todense(), D+3j)\n\n            c = eval(format + '_matrix')(A)\n            assert_equal(c.format,format)\n            assert_array_equal(c.todense(), D)\n\n    def test_tobsr(self):\n        x = array([[1,0,2,0],[0,0,0,0],[0,0,4,5]])\n        y = array([[0,1,2],[3,0,5]])\n        A = kron(x,y)\n        Asp = self.spmatrix(A)\n        for format in ['bsr']:\n            fn = getattr(Asp, 'to' + format)\n\n            for X in [1, 2, 3, 6]:\n                for Y in [1, 2, 3, 4, 6, 12]:\n                    assert_equal(fn(blocksize=(X,Y)).todense(), A)\n\n    def test_transpose(self):\n        dat_1 = self.dat\n        dat_2 = np.array([[]])\n        matrices = [dat_1, dat_2]\n\n        def check(dtype, j):\n            dat = np.matrix(matrices[j], dtype=dtype)\n            datsp = self.spmatrix(dat)\n\n            a = datsp.transpose()\n            b = dat.transpose()\n            assert_array_equal(a.todense(), b)\n            assert_array_equal(a.transpose().todense(), dat)\n            assert_equal(a.dtype, b.dtype)\n\n            assert_array_equal(self.spmatrix((3,4)).T.todense(), zeros((4,3)))\n\n        for dtype in self.checked_dtypes:\n            for j in range(len(matrices)):\n                yield check, dtype, j\n\n    def test_add_dense(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n\n            # adding a dense matrix to a sparse matrix\n            sum1 = dat + datsp\n            assert_array_equal(sum1, dat + dat)\n            sum2 = datsp + dat\n            assert_array_equal(sum2, dat + dat)\n\n        for dtype in self.math_dtypes:\n            yield check, dtype\n\n    def test_sub_dense(self):\n        # subtracting a dense matrix to/from a sparse matrix\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n\n            # Behavior is different for bool.\n            if dat.dtype == bool:\n                sum1 = dat - datsp\n                assert_array_equal(sum1, dat - dat)\n                sum2 = datsp - dat\n                assert_array_equal(sum2, dat - dat)\n            else:\n                # Manually add to avoid upcasting from scalar\n                # multiplication.\n                sum1 = (dat + dat + dat) - datsp\n                assert_array_equal(sum1, dat + dat)\n                sum2 = (datsp + datsp + datsp) - dat\n                assert_array_equal(sum2, dat + dat)\n\n        for dtype in self.math_dtypes:\n            if (dtype == np.dtype('bool')) and (\n                    NumpyVersion(np.__version__) >= '1.9.0.dev'):\n                # boolean array subtraction deprecated in 1.9.0\n                continue\n\n            yield check, dtype\n\n    def test_maximum_minimum(self):\n        A_dense = np.array([[1, 0, 3], [0, 4, 5], [0, 0, 0]])\n        B_dense = np.array([[1, 1, 2], [0, 3, 6], [1, -1, 0]])\n\n        A_dense_cpx = np.array([[1, 0, 3], [0, 4+2j, 5], [0, 1j, -1j]])\n\n        def check(dtype, dtype2, btype):\n            if np.issubdtype(dtype, np.complexfloating):\n                A = self.spmatrix(A_dense_cpx.astype(dtype))\n            else:\n                A = self.spmatrix(A_dense.astype(dtype))\n            if btype == 'scalar':\n                B = dtype2.type(1)\n            elif btype == 'scalar2':\n                B = dtype2.type(-1)\n            elif btype == 'dense':\n                B = B_dense.astype(dtype2)\n            elif btype == 'sparse':\n                B = self.spmatrix(B_dense.astype(dtype2))\n            else:\n                raise ValueError()\n\n            max_s = A.maximum(B)\n            max_d = np.maximum(todense(A), todense(B))\n            assert_array_equal(todense(max_s), max_d)\n            assert_equal(max_s.dtype, max_d.dtype)\n\n            min_s = A.minimum(B)\n            min_d = np.minimum(todense(A), todense(B))\n            assert_array_equal(todense(min_s), min_d)\n            assert_equal(min_s.dtype, min_d.dtype)\n\n        for dtype in self.math_dtypes:\n            for dtype2 in [np.int8, np.float_, np.complex_]:\n                for btype in ['scalar', 'scalar2', 'dense', 'sparse']:\n                    yield check, np.dtype(dtype), np.dtype(dtype2), btype\n\n    def test_copy(self):\n        # Check whether the copy=True and copy=False keywords work\n        A = self.datsp\n\n        # check that copy preserves format\n        assert_equal(A.copy().format, A.format)\n        assert_equal(A.__class__(A,copy=True).format, A.format)\n        assert_equal(A.__class__(A,copy=False).format, A.format)\n\n        assert_equal(A.copy().todense(), A.todense())\n        assert_equal(A.__class__(A,copy=True).todense(), A.todense())\n        assert_equal(A.__class__(A,copy=False).todense(), A.todense())\n\n        # check that XXX_matrix.toXXX() works\n        toself = getattr(A,'to' + A.format)\n        assert_equal(toself().format, A.format)\n        assert_equal(toself(copy=True).format, A.format)\n        assert_equal(toself(copy=False).format, A.format)\n\n        assert_equal(toself().todense(), A.todense())\n        assert_equal(toself(copy=True).todense(), A.todense())\n        assert_equal(toself(copy=False).todense(), A.todense())\n\n        # check whether the data is copied?\n        # TODO: deal with non-indexable types somehow\n        B = A.copy()\n        try:\n            B[0,0] += 1\n            assert_(B[0,0] != A[0,0])\n        except NotImplementedError:\n            # not all sparse matrices can be indexed\n            pass\n        except TypeError:\n            # not all sparse matrices can be indexed\n            pass\n\n    # test that __iter__ is compatible with NumPy matrix\n    def test_iterator(self):\n        B = np.matrix(np.arange(50).reshape(5, 10))\n        A = self.spmatrix(B)\n\n        for x, y in zip(A, B):\n            assert_equal(x.todense(), y)\n\n    def test_size_zero_matrix_arithmetic(self):\n        # Test basic matrix arithmatic with shapes like (0,0), (10,0),\n        # (0, 3), etc.\n        mat = np.matrix([])\n        a = mat.reshape((0, 0))\n        b = mat.reshape((0, 1))\n        c = mat.reshape((0, 5))\n        d = mat.reshape((1, 0))\n        e = mat.reshape((5, 0))\n        f = np.matrix(np.ones([5, 5]))\n\n        asp = self.spmatrix(a)\n        bsp = self.spmatrix(b)\n        csp = self.spmatrix(c)\n        dsp = self.spmatrix(d)\n        esp = self.spmatrix(e)\n        fsp = self.spmatrix(f)\n\n        # matrix product.\n        assert_array_equal(asp.dot(asp).A, np.dot(a, a).A)\n        assert_array_equal(bsp.dot(dsp).A, np.dot(b, d).A)\n        assert_array_equal(dsp.dot(bsp).A, np.dot(d, b).A)\n        assert_array_equal(csp.dot(esp).A, np.dot(c, e).A)\n        assert_array_equal(csp.dot(fsp).A, np.dot(c, f).A)\n        assert_array_equal(esp.dot(csp).A, np.dot(e, c).A)\n        assert_array_equal(dsp.dot(csp).A, np.dot(d, c).A)\n        assert_array_equal(fsp.dot(esp).A, np.dot(f, e).A)\n\n        # bad matrix products\n        assert_raises(ValueError, dsp.dot, e)\n        assert_raises(ValueError, asp.dot, d)\n\n        # elemente-wise multiplication\n        assert_array_equal(asp.multiply(asp).A, np.multiply(a, a).A)\n        assert_array_equal(bsp.multiply(bsp).A, np.multiply(b, b).A)\n        assert_array_equal(dsp.multiply(dsp).A, np.multiply(d, d).A)\n\n        assert_array_equal(asp.multiply(a).A, np.multiply(a, a).A)\n        assert_array_equal(bsp.multiply(b).A, np.multiply(b, b).A)\n        assert_array_equal(dsp.multiply(d).A, np.multiply(d, d).A)\n\n        assert_array_equal(asp.multiply(6).A, np.multiply(a, 6).A)\n        assert_array_equal(bsp.multiply(6).A, np.multiply(b, 6).A)\n        assert_array_equal(dsp.multiply(6).A, np.multiply(d, 6).A)\n\n        # bad element-wise multiplication\n        assert_raises(ValueError, asp.multiply, c)\n        assert_raises(ValueError, esp.multiply, c)\n\n        # Addition\n        assert_array_equal(asp.__add__(asp).A, a.__add__(a).A)\n        assert_array_equal(bsp.__add__(bsp).A, b.__add__(b).A)\n        assert_array_equal(dsp.__add__(dsp).A, d.__add__(d).A)\n\n        # bad addition\n        assert_raises(ValueError, asp.__add__, dsp)\n        assert_raises(ValueError, bsp.__add__, asp)\n\n    def test_size_zero_conversions(self):\n        mat = np.matrix([])\n        a = mat.reshape((0, 0))\n        b = mat.reshape((0, 5))\n        c = mat.reshape((5, 0))\n\n        for m in [a, b, c]:\n            spm = self.spmatrix(m)\n            assert_array_equal(spm.tocoo().A, m)\n            assert_array_equal(spm.tocsr().A, m)\n            assert_array_equal(spm.tocsc().A, m)\n            assert_array_equal(spm.tolil().A, m)\n            assert_array_equal(spm.todok().A, m)\n            assert_array_equal(spm.tobsr().A, m)\n\n    def test_unary_ufunc_overrides(self):\n        def check(name):\n            if not HAS_NUMPY_UFUNC:\n                if name == \"sign\":\n                    raise nose.SkipTest(\"sign conflicts with comparison op \"\n                                        \"support on Numpy without __numpy_ufunc__\")\n                if self.spmatrix in (dok_matrix, lil_matrix):\n                    raise nose.SkipTest(\"Unary ops not implemented for dok/lil \"\n                                        \"with Numpy without __numpy_ufunc__\")\n            ufunc = getattr(np, name)\n\n            X = self.spmatrix(np.arange(20).reshape(4, 5) / 20.)\n            X0 = ufunc(X.toarray())\n\n            X2 = ufunc(X)\n            assert_array_equal(X2.toarray(), X0)\n\n            if HAS_NUMPY_UFUNC:\n                # the out argument doesn't work on Numpy without __numpy_ufunc__\n                out = np.zeros_like(X0)\n                X3 = ufunc(X, out=out)\n                assert_(X3 is out)\n                assert_array_equal(todense(X3), ufunc(todense(X)))\n\n                out = csc_matrix(out.shape, dtype=out.dtype)\n                out[:,1] = 999\n                X4 = ufunc(X, out=out)\n                assert_(X4 is out)\n                assert_array_equal(todense(X4), ufunc(todense(X)))\n\n        for name in [\"sin\", \"tan\", \"arcsin\", \"arctan\", \"sinh\", \"tanh\",\n                     \"arcsinh\", \"arctanh\", \"rint\", \"sign\", \"expm1\", \"log1p\",\n                     \"deg2rad\", \"rad2deg\", \"floor\", \"ceil\", \"trunc\", \"sqrt\",\n                     \"abs\"]:\n            yield check, name\n\n    def test_binary_ufunc_overrides(self):\n        # data\n        a = np.array([[1, 2, 3],\n                      [4, 5, 0],\n                      [7, 8, 9]])\n        b = np.array([[9, 8, 7],\n                      [6, 0, 0],\n                      [3, 2, 1]])\n        c = 1.0\n        d = 1 + 2j\n        e = 5\n\n        asp = self.spmatrix(a)\n        bsp = self.spmatrix(b)\n\n        a_items = dict(dense=a, scalar=c, cplx_scalar=d, int_scalar=e, sparse=asp)\n        b_items = dict(dense=b, scalar=c, cplx_scalar=d, int_scalar=e, sparse=bsp)\n\n        @dec.skipif(not HAS_NUMPY_UFUNC, \"feature requires Numpy with __numpy_ufunc__\")\n        def check(i, j, dtype):\n            ax = a_items[i]\n            bx = b_items[j]\n\n            if issparse(ax):\n                ax = ax.astype(dtype)\n            if issparse(bx):\n                bx = bx.astype(dtype)\n\n            a = todense(ax)\n            b = todense(bx)\n\n            def check_one(ufunc, allclose=False):\n                # without out argument\n                expected = ufunc(a, b)\n                got = ufunc(ax, bx)\n                if allclose:\n                    assert_allclose(todense(got), expected,\n                                    rtol=5e-15, atol=0)\n                else:\n                    assert_array_equal(todense(got), expected)\n\n                # with out argument\n                out = np.zeros(got.shape, dtype=got.dtype)\n                out.fill(np.nan)\n                got = ufunc(ax, bx, out=out)\n                assert_(got is out)\n                if allclose:\n                    assert_allclose(todense(got), expected,\n                                    rtol=5e-15, atol=0)\n                else:\n                    assert_array_equal(todense(got), expected)\n\n                out = csr_matrix(got.shape, dtype=out.dtype)\n                out[0,:] = 999\n                got = ufunc(ax, bx, out=out)\n                assert_(got is out)\n                if allclose:\n                    assert_allclose(todense(got), expected,\n                                    rtol=5e-15, atol=0)\n                else:\n                    assert_array_equal(todense(got), expected)\n\n            # -- associative\n\n            # multiply\n            check_one(np.multiply)\n\n            # add\n            if isscalarlike(ax) or isscalarlike(bx):\n                try:\n                    check_one(np.add)\n                except NotImplementedError:\n                    # Not implemented for all spmatrix types\n                    pass\n            else:\n                check_one(np.add)\n\n            # maximum\n            check_one(np.maximum)\n\n            # minimum\n            check_one(np.minimum)\n\n            # -- non-associative\n\n            # dot\n            check_one(np.dot)\n\n            # subtract\n            if isscalarlike(ax) or isscalarlike(bx):\n                try:\n                    check_one(np.subtract)\n                except NotImplementedError:\n                    # Not implemented for all spmatrix types\n                    pass\n            else:\n                check_one(np.subtract)\n\n            # divide\n            with np.errstate(divide='ignore', invalid='ignore'):\n                if isscalarlike(bx):\n                    # Rounding error may be different, as the sparse implementation\n                    # computes a/b -> a * (1/b) if b is a scalar\n                    check_one(np.divide, allclose=True)\n                else:\n                    check_one(np.divide)\n\n                # true_divide\n                if isscalarlike(bx):\n                    check_one(np.true_divide, allclose=True)\n                else:\n                    check_one(np.true_divide)\n\n        for i in a_items.keys():\n            for j in b_items.keys():\n                for dtype in [np.int_, np.float_, np.complex_]:\n                    if i == 'sparse' or j == 'sparse':\n                        yield check, i, j, dtype\n\n    @dec.skipif(not HAS_NUMPY_UFUNC, \"feature requires Numpy with __numpy_ufunc__\")\n    def test_ufunc_object_array(self):\n        # This tests compatibility with previous Numpy object array\n        # ufunc behavior. See gh-3345.\n        a = self.spmatrix([[1, 2]])\n        b = self.spmatrix([[3], [4]])\n        c = self.spmatrix([[5], [6]])\n\n        # Should distribute the operation across the object array\n        d = np.multiply(a, np.array([[b], [c]]))\n        assert_(d.dtype == np.object_)\n        assert_(d.shape == (2, 1))\n        assert_allclose(d[0,0].A, (a*b).A)\n        assert_allclose(d[1,0].A, (a*c).A)\n\n        # Lists also get cast to object arrays\n        d = np.multiply(a, [[b], [c]])\n        assert_(d.dtype == np.object_)\n        assert_(d.shape == (2, 1))\n        assert_allclose(d[0,0].A, (a*b).A)\n        assert_allclose(d[1,0].A, (a*c).A)\n\n        # This returned NotImplemented in Numpy < 1.9; do it properly now\n        d = np.multiply(np.array([[b], [c]]), a)\n        assert_(d.dtype == np.object_)\n        assert_(d.shape == (2, 1))\n        assert_allclose(d[0,0].A, (b*a).A)\n        assert_allclose(d[1,0].A, (c*a).A)\n\n        d = np.subtract(np.array(b, dtype=object), c)\n        assert_(isinstance(d, sparse.spmatrix))\n        assert_allclose(d.A, (b - c).A)\n\n\nclass _TestInplaceArithmetic:\n    def test_inplace_dense(self):\n        a = np.ones((3, 4))\n        b = self.spmatrix(a)\n\n        with warnings.catch_warnings():\n            if not HAS_NUMPY_UFUNC:\n                warnings.simplefilter(\"ignore\", DeprecationWarning)\n\n            x = a.copy()\n            y = a.copy()\n            x += a\n            y += b\n            assert_array_equal(x, y)\n\n            x = a.copy()\n            y = a.copy()\n            x -= a\n            y -= b\n            assert_array_equal(x, y)\n\n            # This is matrix product, from __rmul__\n            assert_raises(ValueError, operator.imul, x, b)\n            x = a.copy()\n            y = a.copy()\n            x = x.dot(a.T)\n            y *= b.T\n            assert_array_equal(x, y)\n\n            # Matrix (non-elementwise) floor division is not defined\n            assert_raises(TypeError, operator.ifloordiv, x, b)\n\n    def test_imul_scalar(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n\n            # Avoid implicit casting.\n            if np.can_cast(type(2), dtype, casting='same_kind'):\n                a = datsp.copy()\n                a *= 2\n                b = dat.copy()\n                b *= 2\n                assert_array_equal(b, a.todense())\n\n            if np.can_cast(type(17.3), dtype, casting='same_kind'):\n                a = datsp.copy()\n                a *= 17.3\n                b = dat.copy()\n                b *= 17.3\n                assert_array_equal(b, a.todense())\n\n        for dtype in self.math_dtypes:\n            yield check, dtype\n\n    def test_idiv_scalar(self):\n        def check(dtype):\n            dat = self.dat_dtypes[dtype]\n            datsp = self.datsp_dtypes[dtype]\n\n            if np.can_cast(type(2), dtype, casting='same_kind'):\n                a = datsp.copy()\n                a /= 2\n                b = dat.copy()\n                b /= 2\n                assert_array_equal(b, a.todense())\n\n            if np.can_cast(type(17.3), dtype, casting='same_kind'):\n                a = datsp.copy()\n                a /= 17.3\n                b = dat.copy()\n                b /= 17.3\n                assert_array_equal(b, a.todense())\n\n        for dtype in self.math_dtypes:\n            # /= should only be used with float dtypes to avoid implicit\n            # casting.\n            if not np.can_cast(dtype, np.int_):\n                yield check, dtype\n\n    def test_inplace_success(self):\n        # Inplace ops should work even if a specialized version is not\n        # implemented, falling back to x = x <op> y\n        a = self.spmatrix(np.eye(5))\n        b = self.spmatrix(np.eye(5))\n        bp = self.spmatrix(np.eye(5))\n\n        b += a\n        bp = bp + a\n        assert_allclose(b.A, bp.A)\n\n        b *= a\n        bp = bp * a\n        assert_allclose(b.A, bp.A)\n\n        b -= a\n        bp = bp - a\n        assert_allclose(b.A, bp.A)\n\n        assert_raises(TypeError, operator.ifloordiv, a, b)\n\n\nclass _TestGetSet:\n    def test_getelement(self):\n        def check(dtype):\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n                D = array([[1,0,0],\n                           [4,3,0],\n                           [0,2,0],\n                           [0,0,0]], dtype=dtype)\n                A = self.spmatrix(D)\n\n                M,N = D.shape\n\n                for i in range(-M, M):\n                    for j in range(-N, N):\n                        assert_equal(A[i,j], D[i,j])\n\n                for ij in [(0,3),(-1,3),(4,0),(4,3),(4,-1), (1, 2, 3)]:\n                    assert_raises((IndexError, TypeError), A.__getitem__, ij)\n\n        for dtype in supported_dtypes:\n            yield check, np.dtype(dtype)\n\n    def test_setelement(self):\n        def check(dtype):\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n                A = self.spmatrix((3,4), dtype=dtype)\n                A[0, 0] = dtype.type(0)  # bug 870\n                A[1, 2] = dtype.type(4.0)\n                A[0, 1] = dtype.type(3)\n                A[2, 0] = dtype.type(2.0)\n                A[0,-1] = dtype.type(8)\n                A[-1,-2] = dtype.type(7)\n                A[0, 1] = dtype.type(5)\n\n                if dtype != np.bool_:\n                    assert_array_equal(A.todense(),[[0,5,0,8],[0,0,4,0],[2,0,7,0]])\n\n                for ij in [(0,4),(-1,4),(3,0),(3,4),(3,-1)]:\n                    assert_raises(IndexError, A.__setitem__, ij, 123.0)\n\n                for v in [[1,2,3], array([1,2,3])]:\n                    assert_raises(ValueError, A.__setitem__, (0,0), v)\n\n                if (not np.issubdtype(dtype, np.complexfloating) and\n                        dtype != np.bool_):\n                    for v in [3j]:\n                        assert_raises(TypeError, A.__setitem__, (0,0), v)\n\n        for dtype in supported_dtypes:\n            yield check, np.dtype(dtype)\n\n    def test_negative_index_assignment(self):\n        # Regression test for github issue 4428.\n\n        def check(dtype):\n            A = self.spmatrix((3, 10), dtype=dtype)\n            A[0, -4] = 1\n            assert_equal(A[0, -4], 1)\n\n        for dtype in self.math_dtypes:\n            yield check, np.dtype(dtype)\n\n    def test_scalar_assign_2(self):\n        n, m = (5, 10)\n\n        def _test_set(i, j, nitems):\n            msg = \"%r ; %r ; %r\" % (i, j, nitems)\n            A = self.spmatrix((n, m))\n            A[i, j] = 1\n            assert_almost_equal(A.sum(), nitems, err_msg=msg)\n            assert_almost_equal(A[i, j], 1, err_msg=msg)\n\n        # [i,j]\n        for i, j in [(2, 3), (-1, 8), (-1, -2), (array(-1), -2), (-1, array(-2)),\n                     (array(-1), array(-2))]:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n                _test_set(i, j, 1)\n\n    def test_index_scalar_assign(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n            A = self.spmatrix((5, 5))\n            B = np.zeros((5, 5))\n            for C in [A, B]:\n                C[0,1] = 1\n                C[3,0] = 4\n                C[3,0] = 9\n            assert_array_equal(A.toarray(), B)\n\n\nclass _TestSolve:\n    def test_solve(self):\n        # Test whether the lu_solve command segfaults, as reported by Nils\n        # Wagner for a 64-bit machine, 02 March 2005 (EJS)\n        n = 20\n        np.random.seed(0)  # make tests repeatable\n        A = zeros((n,n), dtype=complex)\n        x = np.random.rand(n)\n        y = np.random.rand(n-1)+1j*np.random.rand(n-1)\n        r = np.random.rand(n)\n        for i in range(len(x)):\n            A[i,i] = x[i]\n        for i in range(len(y)):\n            A[i,i+1] = y[i]\n            A[i+1,i] = conjugate(y[i])\n        A = self.spmatrix(A)\n        x = splu(A).solve(r)\n        assert_almost_equal(A*x,r)\n\n\nclass _TestSlicing:\n    def test_dtype_preservation(self):\n        assert_equal(self.spmatrix((1,10), dtype=np.int16)[0,1:5].dtype, np.int16)\n        assert_equal(self.spmatrix((1,10), dtype=np.int32)[0,1:5].dtype, np.int32)\n        assert_equal(self.spmatrix((1,10), dtype=np.float32)[0,1:5].dtype, np.float32)\n        assert_equal(self.spmatrix((1,10), dtype=np.float64)[0,1:5].dtype, np.float64)\n\n    def test_get_horiz_slice(self):\n        B = asmatrix(arange(50.).reshape(5,10))\n        A = self.spmatrix(B)\n        assert_array_equal(B[1,:], A[1,:].todense())\n        assert_array_equal(B[1,2:5], A[1,2:5].todense())\n\n        C = matrix([[1, 2, 1], [4, 0, 6], [0, 0, 0], [0, 0, 1]])\n        D = self.spmatrix(C)\n        assert_array_equal(C[1, 1:3], D[1, 1:3].todense())\n\n        # Now test slicing when a row contains only zeros\n        E = matrix([[1, 2, 1], [4, 0, 0], [0, 0, 0], [0, 0, 1]])\n        F = self.spmatrix(E)\n        assert_array_equal(E[1, 1:3], F[1, 1:3].todense())\n        assert_array_equal(E[2, -2:], F[2, -2:].A)\n\n        # The following should raise exceptions:\n        assert_raises(IndexError, A.__getitem__, (slice(None), 11))\n        assert_raises(IndexError, A.__getitem__, (6, slice(3, 7)))\n\n    def test_get_vert_slice(self):\n        B = asmatrix(arange(50.).reshape(5,10))\n        A = self.spmatrix(B)\n        assert_array_equal(B[2:5,0], A[2:5,0].todense())\n        assert_array_equal(B[:,1], A[:,1].todense())\n\n        C = matrix([[1, 2, 1], [4, 0, 6], [0, 0, 0], [0, 0, 1]])\n        D = self.spmatrix(C)\n        assert_array_equal(C[1:3, 1], D[1:3, 1].todense())\n        assert_array_equal(C[:, 2], D[:, 2].todense())\n\n        # Now test slicing when a column contains only zeros\n        E = matrix([[1, 0, 1], [4, 0, 0], [0, 0, 0], [0, 0, 1]])\n        F = self.spmatrix(E)\n        assert_array_equal(E[:, 1], F[:, 1].todense())\n        assert_array_equal(E[-2:, 2], F[-2:, 2].todense())\n\n        # The following should raise exceptions:\n        assert_raises(IndexError, A.__getitem__, (slice(None), 11))\n        assert_raises(IndexError, A.__getitem__, (6, slice(3, 7)))\n\n    def test_get_slices(self):\n        B = asmatrix(arange(50.).reshape(5,10))\n        A = self.spmatrix(B)\n        assert_array_equal(A[2:5,0:3].todense(), B[2:5,0:3])\n        assert_array_equal(A[1:,:-1].todense(), B[1:,:-1])\n        assert_array_equal(A[:-1,1:].todense(), B[:-1,1:])\n\n        # Now test slicing when a column contains only zeros\n        E = matrix([[1, 0, 1], [4, 0, 0], [0, 0, 0], [0, 0, 1]])\n        F = self.spmatrix(E)\n        assert_array_equal(E[1:2, 1:2], F[1:2, 1:2].todense())\n        assert_array_equal(E[:, 1:], F[:, 1:].todense())\n\n    def test_non_unit_stride_2d_indexing(self):\n        # Regression test -- used to silently ignore the stride.\n        v0 = np.random.rand(50, 50)\n        try:\n            v = self.spmatrix(v0)[0:25:2, 2:30:3]\n        except ValueError:\n            # if unsupported\n            raise nose.SkipTest(\"feature not implemented\")\n\n        assert_array_equal(v.todense(),\n                           v0[0:25:2, 2:30:3])\n\n    def test_slicing_2(self):\n        B = asmatrix(arange(50).reshape(5,10))\n        A = self.spmatrix(B)\n\n        # [i,j]\n        assert_equal(A[2,3], B[2,3])\n        assert_equal(A[-1,8], B[-1,8])\n        assert_equal(A[-1,-2],B[-1,-2])\n        assert_equal(A[array(-1),-2],B[-1,-2])\n        assert_equal(A[-1,array(-2)],B[-1,-2])\n        assert_equal(A[array(-1),array(-2)],B[-1,-2])\n\n        # [i,1:2]\n        assert_equal(A[2,:].todense(), B[2,:])\n        assert_equal(A[2,5:-2].todense(),B[2,5:-2])\n        assert_equal(A[array(2),5:-2].todense(),B[2,5:-2])\n\n        # [1:2,j]\n        assert_equal(A[:,2].todense(), B[:,2])\n        assert_equal(A[3:4,9].todense(), B[3:4,9])\n        assert_equal(A[1:4,-5].todense(),B[1:4,-5])\n        assert_equal(A[2:-1,3].todense(),B[2:-1,3])\n        assert_equal(A[2:-1,array(3)].todense(),B[2:-1,3])\n\n        # [1:2,1:2]\n        assert_equal(A[1:2,1:2].todense(),B[1:2,1:2])\n        assert_equal(A[4:,3:].todense(), B[4:,3:])\n        assert_equal(A[:4,:5].todense(), B[:4,:5])\n        assert_equal(A[2:-1,:5].todense(),B[2:-1,:5])\n\n        # [i]\n        assert_equal(A[1,:].todense(), B[1,:])\n        assert_equal(A[-2,:].todense(),B[-2,:])\n        assert_equal(A[array(-2),:].todense(),B[-2,:])\n\n        # [1:2]\n        assert_equal(A[1:4].todense(), B[1:4])\n        assert_equal(A[1:-2].todense(),B[1:-2])\n\n        # Check bug reported by Robert Cimrman:\n        # http://thread.gmane.org/gmane.comp.python.scientific.devel/7986\n        s = slice(int8(2),int8(4),None)\n        assert_equal(A[s,:].todense(), B[2:4,:])\n        assert_equal(A[:,s].todense(), B[:,2:4])\n\n    def test_slicing_3(self):\n        B = asmatrix(arange(50).reshape(5,10))\n        A = self.spmatrix(B)\n\n        s_ = np.s_\n        slices = [s_[:2], s_[1:2], s_[3:], s_[3::2],\n                  s_[8:3:-1], s_[4::-2], s_[:5:-1],\n                  0, 1, s_[:], s_[1:5], -1, -2, -5,\n                  array(-1), np.int8(-3)]\n\n        def check_1(a):\n            x = A[a]\n            y = B[a]\n            if y.shape == ():\n                assert_equal(x, y, repr(a))\n            else:\n                if x.size == 0 and y.size == 0:\n                    pass\n                else:\n                    assert_array_equal(x.todense(), y, repr(a))\n\n        for j, a in enumerate(slices):\n            yield check_1, a\n\n        def check_2(a, b):\n            # Indexing np.matrix with 0-d arrays seems to be broken,\n            # as they seem not to be treated as scalars.\n            # https://github.com/numpy/numpy/issues/3110\n            if isinstance(a, np.ndarray):\n                ai = int(a)\n            else:\n                ai = a\n            if isinstance(b, np.ndarray):\n                bi = int(b)\n            else:\n                bi = b\n\n            x = A[a, b]\n            y = B[ai, bi]\n\n            if y.shape == ():\n                assert_equal(x, y, repr((a, b)))\n            else:\n                if x.size == 0 and y.size == 0:\n                    pass\n                else:\n                    assert_array_equal(x.todense(), y, repr((a, b)))\n\n        for i, a in enumerate(slices):\n            for j, b in enumerate(slices):\n                yield check_2, a, b\n\n    def test_ellipsis_slicing(self):\n        b = asmatrix(arange(50).reshape(5,10))\n        a = self.spmatrix(b)\n\n        assert_array_equal(a[...].A, b[...].A)\n        assert_array_equal(a[...,].A, b[...,].A)\n\n        assert_array_equal(a[1, ...].A, b[1, ...].A)\n        assert_array_equal(a[..., 1].A, b[..., 1].A)\n        assert_array_equal(a[1:, ...].A, b[1:, ...].A)\n        assert_array_equal(a[..., 1:].A, b[..., 1:].A)\n\n        assert_array_equal(a[1:, 1, ...].A, b[1:, 1, ...].A)\n        assert_array_equal(a[1, ..., 1:].A, b[1, ..., 1:].A)\n        # These return ints\n        assert_equal(a[1, 1, ...], b[1, 1, ...])\n        assert_equal(a[1, ..., 1], b[1, ..., 1])\n\n    @dec.skipif(NumpyVersion(np.__version__) >= '1.9.0.dev')\n    def test_multiple_ellipsis_slicing(self):\n        b = asmatrix(arange(50).reshape(5,10))\n        a = self.spmatrix(b)\n\n        assert_array_equal(a[..., ...].A, b[..., ...].A)\n        assert_array_equal(a[..., ..., ...].A, b[..., ..., ...].A)\n        assert_array_equal(a[1, ..., ...].A, b[1, ..., ...].A)\n        assert_array_equal(a[1:, ..., ...].A, b[1:, ..., ...].A)\n        assert_array_equal(a[..., ..., 1:].A, b[..., ..., 1:].A)\n\n        # Bug in NumPy's slicing\n        assert_array_equal(a[..., ..., 1].A, b[..., ..., 1].A.reshape((5,1)))\n\n\nclass _TestSlicingAssign:\n    def test_slice_scalar_assign(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n            A = self.spmatrix((5, 5))\n            B = np.zeros((5, 5))\n            for C in [A, B]:\n                C[0:1,1] = 1\n                C[3:0,0] = 4\n                C[3:4,0] = 9\n                C[0,4:] = 1\n                C[3::-1,4:] = 9\n            assert_array_equal(A.toarray(), B)\n\n    def test_slice_assign_2(self):\n        n, m = (5, 10)\n\n        def _test_set(i, j):\n            msg = \"i=%r; j=%r\" % (i, j)\n            A = self.spmatrix((n, m))\n            A[i, j] = 1\n            B = np.zeros((n, m))\n            B[i, j] = 1\n            assert_array_almost_equal(A.todense(), B, err_msg=msg)\n        # [i,1:2]\n        for i, j in [(2, slice(3)), (2, slice(None, 10, 4)), (2, slice(5, -2)),\n                     (array(2), slice(5, -2))]:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n                _test_set(i, j)\n\n    def test_self_self_assignment(self):\n        # Tests whether a row of one lil_matrix can be assigned to\n        # another.\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n            B = self.spmatrix((4,3))\n            B[0,0] = 2\n            B[1,2] = 7\n            B[2,1] = 3\n            B[3,0] = 10\n\n            A = B / 10\n            B[0,:] = A[0,:]\n            assert_array_equal(A[0,:].A, B[0,:].A)\n\n            A = B / 10\n            B[:,:] = A[:1,:1]\n            assert_equal(A[0,0], B[3,2])\n\n            A = B / 10\n            B[:-1,0] = A[0,:].T\n            assert_array_equal(A[0,:].A.T, B[:-1,0].A)\n\n    def test_slice_assignment(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n            B = self.spmatrix((4,3))\n            B[0,0] = 5\n            B[1,2] = 3\n            B[2,1] = 7\n\n            expected = array([[10,0,0],\n                              [0,0,6],\n                              [0,14,0],\n                              [0,0,0]])\n\n            B[:,:] = B+B\n            assert_array_equal(B.todense(),expected)\n\n            block = [[1,0],[0,4]]\n            B[:2,:2] = csc_matrix(array(block))\n            assert_array_equal(B.todense()[:2,:2],block)\n\n    def test_set_slice(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n            A = self.spmatrix((5,10))\n            B = matrix(zeros((5,10), float))\n\n            s_ = np.s_\n            slices = [s_[:2], s_[1:2], s_[3:], s_[3::2],\n                      s_[8:3:-1], s_[4::-2], s_[:5:-1],\n                      0, 1, s_[:], s_[1:5], -1, -2, -5,\n                      array(-1), np.int8(-3)]\n\n            for j, a in enumerate(slices):\n                A[a] = j\n                B[a] = j\n                assert_array_equal(A.todense(), B, repr(a))\n\n            for i, a in enumerate(slices):\n                for j, b in enumerate(slices):\n                    A[a,b] = 10*i + 1000*(j+1)\n                    B[a,b] = 10*i + 1000*(j+1)\n                    assert_array_equal(A.todense(), B, repr((a, b)))\n\n            A[0, 1:10:2] = xrange(1,10,2)\n            B[0, 1:10:2] = xrange(1,10,2)\n            assert_array_equal(A.todense(), B)\n            A[1:5:2,0] = np.array(range(1,5,2))[:,None]\n            B[1:5:2,0] = np.array(range(1,5,2))[:,None]\n            assert_array_equal(A.todense(), B)\n\n            # The next commands should raise exceptions\n            assert_raises(ValueError, A.__setitem__, (0, 0), list(range(100)))\n            assert_raises(ValueError, A.__setitem__, (0, 0), arange(100))\n            assert_raises(ValueError, A.__setitem__, (0, slice(None)),\n                          list(range(100)))\n            assert_raises(ValueError, A.__setitem__, (slice(None), 1),\n                          list(range(100)))\n            assert_raises(ValueError, A.__setitem__, (slice(None), 1), A.copy())\n            assert_raises(ValueError, A.__setitem__,\n                          ([[1, 2, 3], [0, 3, 4]], [1, 2, 3]), [1, 2, 3, 4])\n            assert_raises(ValueError, A.__setitem__,\n                          ([[1, 2, 3], [0, 3, 4], [4, 1, 3]],\n                           [[1, 2, 4], [0, 1, 3]]), [2, 3, 4])\n\n\nclass _TestFancyIndexing:\n    \"\"\"Tests fancy indexing features.  The tests for any matrix formats\n    that implement these features should derive from this class.\n    \"\"\"\n\n    def test_bad_index(self):\n        A = self.spmatrix(np.zeros([5, 5]))\n        assert_raises((IndexError, ValueError, TypeError), A.__getitem__, \"foo\")\n        assert_raises((IndexError, ValueError, TypeError), A.__getitem__, (2, \"foo\"))\n        assert_raises((IndexError, ValueError), A.__getitem__,\n                      ([1, 2, 3], [1, 2, 3, 4]))\n\n    def test_fancy_indexing(self):\n        B = asmatrix(arange(50).reshape(5,10))\n        A = self.spmatrix(B)\n\n        # [i]\n        assert_equal(A[[1,3]].todense(), B[[1,3]])\n\n        # [i,[1,2]]\n        assert_equal(A[3,[1,3]].todense(), B[3,[1,3]])\n        assert_equal(A[-1,[2,-5]].todense(),B[-1,[2,-5]])\n        assert_equal(A[array(-1),[2,-5]].todense(),B[-1,[2,-5]])\n        assert_equal(A[-1,array([2,-5])].todense(),B[-1,[2,-5]])\n        assert_equal(A[array(-1),array([2,-5])].todense(),B[-1,[2,-5]])\n\n        # [1:2,[1,2]]\n        assert_equal(A[:,[2,8,3,-1]].todense(),B[:,[2,8,3,-1]])\n        assert_equal(A[3:4,[9]].todense(), B[3:4,[9]])\n        assert_equal(A[1:4,[-1,-5]].todense(), B[1:4,[-1,-5]])\n        assert_equal(A[1:4,array([-1,-5])].todense(), B[1:4,[-1,-5]])\n\n        # [[1,2],j]\n        assert_equal(A[[1,3],3].todense(), B[[1,3],3])\n        assert_equal(A[[2,-5],-4].todense(), B[[2,-5],-4])\n        assert_equal(A[array([2,-5]),-4].todense(), B[[2,-5],-4])\n        assert_equal(A[[2,-5],array(-4)].todense(), B[[2,-5],-4])\n        assert_equal(A[array([2,-5]),array(-4)].todense(), B[[2,-5],-4])\n\n        # [[1,2],1:2]\n        assert_equal(A[[1,3],:].todense(), B[[1,3],:])\n        assert_equal(A[[2,-5],8:-1].todense(),B[[2,-5],8:-1])\n        assert_equal(A[array([2,-5]),8:-1].todense(),B[[2,-5],8:-1])\n\n        # [[1,2],[1,2]]\n        assert_equal(todense(A[[1,3],[2,4]]), B[[1,3],[2,4]])\n        assert_equal(todense(A[[-1,-3],[2,-4]]), B[[-1,-3],[2,-4]])\n        assert_equal(todense(A[array([-1,-3]),[2,-4]]), B[[-1,-3],[2,-4]])\n        assert_equal(todense(A[[-1,-3],array([2,-4])]), B[[-1,-3],[2,-4]])\n        assert_equal(todense(A[array([-1,-3]),array([2,-4])]), B[[-1,-3],[2,-4]])\n\n        # [[[1],[2]],[1,2]]\n        assert_equal(A[[[1],[3]],[2,4]].todense(), B[[[1],[3]],[2,4]])\n        assert_equal(A[[[-1],[-3],[-2]],[2,-4]].todense(),B[[[-1],[-3],[-2]],[2,-4]])\n        assert_equal(A[array([[-1],[-3],[-2]]),[2,-4]].todense(),B[[[-1],[-3],[-2]],[2,-4]])\n        assert_equal(A[[[-1],[-3],[-2]],array([2,-4])].todense(),B[[[-1],[-3],[-2]],[2,-4]])\n        assert_equal(A[array([[-1],[-3],[-2]]),array([2,-4])].todense(),B[[[-1],[-3],[-2]],[2,-4]])\n\n        # [[1,2]]\n        assert_equal(A[[1,3]].todense(), B[[1,3]])\n        assert_equal(A[[-1,-3]].todense(),B[[-1,-3]])\n        assert_equal(A[array([-1,-3])].todense(),B[[-1,-3]])\n\n        # [[1,2],:][:,[1,2]]\n        assert_equal(A[[1,3],:][:,[2,4]].todense(), B[[1,3],:][:,[2,4]])\n        assert_equal(A[[-1,-3],:][:,[2,-4]].todense(), B[[-1,-3],:][:,[2,-4]])\n        assert_equal(A[array([-1,-3]),:][:,array([2,-4])].todense(), B[[-1,-3],:][:,[2,-4]])\n\n        # [:,[1,2]][[1,2],:]\n        assert_equal(A[:,[1,3]][[2,4],:].todense(), B[:,[1,3]][[2,4],:])\n        assert_equal(A[:,[-1,-3]][[2,-4],:].todense(), B[:,[-1,-3]][[2,-4],:])\n        assert_equal(A[:,array([-1,-3])][array([2,-4]),:].todense(), B[:,[-1,-3]][[2,-4],:])\n\n        # Check bug reported by Robert Cimrman:\n        # http://thread.gmane.org/gmane.comp.python.scientific.devel/7986\n        s = slice(int8(2),int8(4),None)\n        assert_equal(A[s,:].todense(), B[2:4,:])\n        assert_equal(A[:,s].todense(), B[:,2:4])\n\n    def test_fancy_indexing_randomized(self):\n        np.random.seed(1234)  # make runs repeatable\n\n        NUM_SAMPLES = 50\n        M = 6\n        N = 4\n\n        D = np.asmatrix(np.random.rand(M,N))\n        D = np.multiply(D, D > 0.5)\n\n        I = np.random.random_integers(-M + 1, M - 1, size=NUM_SAMPLES)\n        J = np.random.random_integers(-N + 1, N - 1, size=NUM_SAMPLES)\n\n        S = self.spmatrix(D)\n\n        SIJ = S[I,J]\n        if isspmatrix(SIJ):\n            SIJ = SIJ.todense()\n        assert_equal(SIJ, D[I,J])\n\n        I_bad = I + M\n        J_bad = J - N\n\n        assert_raises(IndexError, S.__getitem__, (I_bad,J))\n        assert_raises(IndexError, S.__getitem__, (I,J_bad))\n\n    def test_fancy_indexing_boolean(self):\n        np.random.seed(1234)  # make runs repeatable\n\n        B = asmatrix(arange(50).reshape(5,10))\n        A = self.spmatrix(B)\n\n        I = np.array(np.random.randint(0, 2, size=5), dtype=bool)\n        J = np.array(np.random.randint(0, 2, size=10), dtype=bool)\n        X = np.array(np.random.randint(0, 2, size=(5, 10)), dtype=bool)\n\n        assert_equal(todense(A[I]), B[I])\n        assert_equal(todense(A[:,J]), B[:, J])\n        assert_equal(todense(A[X]), B[X])\n        assert_equal(todense(A[B > 9]), B[B > 9])\n\n        I = np.array([True, False, True, True, False])\n        J = np.array([False, True, True, False, True])\n\n        assert_equal(todense(A[I, J]), B[I, J])\n\n        Z1 = np.zeros((6, 11), dtype=bool)\n        Z2 = np.zeros((6, 11), dtype=bool)\n        Z2[0,-1] = True\n        Z3 = np.zeros((6, 11), dtype=bool)\n        Z3[-1,0] = True\n\n        assert_equal(A[Z1], np.array([]))\n        assert_raises(IndexError, A.__getitem__, Z2)\n        assert_raises(IndexError, A.__getitem__, Z3)\n        assert_raises((IndexError, ValueError), A.__getitem__, (X, 1))\n\n    def test_fancy_indexing_sparse_boolean(self):\n        np.random.seed(1234)  # make runs repeatable\n\n        B = asmatrix(arange(50).reshape(5,10))\n        A = self.spmatrix(B)\n\n        X = np.array(np.random.randint(0, 2, size=(5, 10)), dtype=bool)\n\n        Xsp = csr_matrix(X)\n\n        assert_equal(todense(A[Xsp]), B[X])\n        assert_equal(todense(A[A > 9]), B[B > 9])\n\n        Z = np.array(np.random.randint(0, 2, size=(5, 11)), dtype=bool)\n        Y = np.array(np.random.randint(0, 2, size=(6, 10)), dtype=bool)\n\n        Zsp = csr_matrix(Z)\n        Ysp = csr_matrix(Y)\n\n        assert_raises(IndexError, A.__getitem__, Zsp)\n        assert_raises(IndexError, A.__getitem__, Ysp)\n        assert_raises((IndexError, ValueError), A.__getitem__, (Xsp, 1))\n\n    def test_fancy_indexing_regression_3087(self):\n        mat = self.spmatrix(array([[1, 0, 0], [0,1,0], [1,0,0]]))\n        desired_cols = np.ravel(mat.sum(0)) > 0\n        assert_equal(mat[:, desired_cols].A, [[1, 0], [0, 1], [1, 0]])\n\n    def test_fancy_indexing_seq_assign(self):\n        mat = self.spmatrix(array([[1, 0], [0, 1]]))\n        assert_raises(ValueError, mat.__setitem__, (0, 0), np.array([1,2]))\n\n    def test_fancy_indexing_empty(self):\n        B = asmatrix(arange(50).reshape(5,10))\n        B[1,:] = 0\n        B[:,2] = 0\n        B[3,6] = 0\n        A = self.spmatrix(B)\n\n        K = np.array([False, False, False, False, False])\n        assert_equal(todense(A[K]), B[K])\n        K = np.array([], dtype=int)\n        assert_equal(todense(A[K]), B[K])\n        assert_equal(todense(A[K,K]), B[K,K])\n        J = np.array([0, 1, 2, 3, 4], dtype=int)[:,None]\n        assert_equal(todense(A[K,J]), B[K,J])\n        assert_equal(todense(A[J,K]), B[J,K])\n\n\n@contextlib.contextmanager\ndef check_remains_sorted(X):\n    \"\"\"Checks that sorted indices property is retained through an operation\n    \"\"\"\n    if not hasattr(X, 'has_sorted_indices') or not X.has_sorted_indices:\n        yield\n        return\n    yield\n    indices = X.indices.copy()\n    X.has_sorted_indices = False\n    X.sort_indices()\n    assert_array_equal(indices, X.indices,\n                       'Expected sorted indices, found unsorted')\n\n\nclass _TestFancyIndexingAssign:\n    def test_bad_index_assign(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n            A = self.spmatrix(np.zeros([5, 5]))\n            assert_raises((IndexError, ValueError, TypeError), A.__setitem__, \"foo\", 2)\n            assert_raises((IndexError, ValueError, TypeError), A.__setitem__, (2, \"foo\"), 5)\n\n    def test_fancy_indexing_set(self):\n        n, m = (5, 10)\n\n        def _test_set_slice(i, j):\n            A = self.spmatrix((n, m))\n            with check_remains_sorted(A):\n                A[i, j] = 1\n            B = asmatrix(np.zeros((n, m)))\n            B[i, j] = 1\n            assert_array_almost_equal(A.todense(), B)\n        # [1:2,1:2]\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n            for i, j in [((2, 3, 4), slice(None, 10, 4)),\n                         (np.arange(3), slice(5, -2)),\n                         (slice(2, 5), slice(5, -2))]:\n                _test_set_slice(i, j)\n            for i, j in [(np.arange(3), np.arange(3)), ((0, 3, 4), (1, 2, 4))]:\n                _test_set_slice(i, j)\n\n    def test_fancy_assignment_dtypes(self):\n        def check(dtype):\n            A = self.spmatrix((5, 5), dtype=dtype)\n            A[[0,1],[0,1]] = dtype.type(1)\n            assert_equal(A.sum(), dtype.type(1)*2)\n            A[0:2,0:2] = dtype.type(1.0)\n            assert_equal(A.sum(), dtype.type(1)*4)\n            A[2,2] = dtype.type(1.0)\n            assert_equal(A.sum(), dtype.type(1)*4 + dtype.type(1))\n\n        for dtype in supported_dtypes:\n            yield check, np.dtype(dtype)\n\n    def test_sequence_assignment(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n            A = self.spmatrix((4,3))\n            B = self.spmatrix(eye(3,4))\n\n            i0 = [0,1,2]\n            i1 = (0,1,2)\n            i2 = array(i0)\n\n            with check_remains_sorted(A):\n                A[0,i0] = B[i0,0].T\n                A[1,i1] = B[i1,1].T\n                A[2,i2] = B[i2,2].T\n            assert_array_equal(A.todense(),B.T.todense())\n\n            # column slice\n            A = self.spmatrix((2,3))\n            with check_remains_sorted(A):\n                A[1,1:3] = [10,20]\n            assert_array_equal(A.todense(), [[0,0,0],[0,10,20]])\n\n            # row slice\n            A = self.spmatrix((3,2))\n            with check_remains_sorted(A):\n                A[1:3,1] = [[10],[20]]\n            assert_array_equal(A.todense(), [[0,0],[0,10],[0,20]])\n\n            # both slices\n            A = self.spmatrix((3,3))\n            B = asmatrix(np.zeros((3,3)))\n            with check_remains_sorted(A):\n                for C in [A, B]:\n                    C[[0,1,2], [0,1,2]] = [4,5,6]\n            assert_array_equal(A.toarray(), B)\n\n            # both slices (2)\n            A = self.spmatrix((4, 3))\n            with check_remains_sorted(A):\n                A[(1, 2, 3), (0, 1, 2)] = [1, 2, 3]\n            assert_almost_equal(A.sum(), 6)\n            B = asmatrix(np.zeros((4, 3)))\n            B[(1, 2, 3), (0, 1, 2)] = [1, 2, 3]\n            assert_array_equal(A.todense(), B)\n\n    def test_fancy_assign_empty(self):\n        B = asmatrix(arange(50).reshape(5,10))\n        B[1,:] = 0\n        B[:,2] = 0\n        B[3,6] = 0\n        A = self.spmatrix(B)\n\n        K = np.array([False, False, False, False, False])\n        A[K] = 42\n        assert_equal(todense(A), B)\n\n        K = np.array([], dtype=int)\n        A[K] = 42\n        assert_equal(todense(A), B)\n        A[K,K] = 42\n        assert_equal(todense(A), B)\n\n        J = np.array([0, 1, 2, 3, 4], dtype=int)[:,None]\n        A[K,J] = 42\n        assert_equal(todense(A), B)\n        A[J,K] = 42\n        assert_equal(todense(A), B)\n\n\nclass _TestFancyMultidim:\n    def test_fancy_indexing_ndarray(self):\n        sets = [\n            (np.array([[1], [2], [3]]), np.array([3, 4, 2])),\n            (np.array([[1], [2], [3]]), np.array([[3, 4, 2]])),\n            (np.array([[1, 2, 3]]), np.array([[3], [4], [2]])),\n            (np.array([1, 2, 3]), np.array([[3], [4], [2]])),\n            (np.array([[1, 2, 3], [3, 4, 2]]),\n             np.array([[5, 6, 3], [2, 3, 1]]))\n            ]\n        # These inputs generate 3-D outputs\n        #    (np.array([[[1], [2], [3]], [[3], [4], [2]]]),\n        #     np.array([[[5], [6], [3]], [[2], [3], [1]]])),\n\n        for I, J in sets:\n            np.random.seed(1234)\n            D = np.asmatrix(np.random.rand(5, 7))\n            S = self.spmatrix(D)\n\n            SIJ = S[I,J]\n            if isspmatrix(SIJ):\n                SIJ = SIJ.todense()\n            assert_equal(SIJ, D[I,J])\n\n            I_bad = I + 5\n            J_bad = J + 7\n\n            assert_raises(IndexError, S.__getitem__, (I_bad,J))\n            assert_raises(IndexError, S.__getitem__, (I,J_bad))\n\n            # This would generate 3-D arrays -- not supported\n            assert_raises(IndexError, S.__getitem__, ([I, I], slice(None)))\n            assert_raises(IndexError, S.__getitem__, (slice(None), [J, J]))\n\n\nclass _TestFancyMultidimAssign:\n    def test_fancy_assign_ndarray(self):\n        np.random.seed(1234)\n\n        D = np.asmatrix(np.random.rand(5, 7))\n        S = self.spmatrix(D)\n        X = np.random.rand(2, 3)\n\n        I = np.array([[1, 2, 3], [3, 4, 2]])\n        J = np.array([[5, 6, 3], [2, 3, 1]])\n\n        with check_remains_sorted(S):\n            S[I,J] = X\n        D[I,J] = X\n        assert_equal(S.todense(), D)\n\n        I_bad = I + 5\n        J_bad = J + 7\n\n        C = [1, 2, 3]\n\n        with check_remains_sorted(S):\n            S[I,J] = C\n        D[I,J] = C\n        assert_equal(S.todense(), D)\n\n        with check_remains_sorted(S):\n            S[I,J] = 3\n        D[I,J] = 3\n        assert_equal(S.todense(), D)\n\n        assert_raises(IndexError, S.__setitem__, (I_bad,J), C)\n        assert_raises(IndexError, S.__setitem__, (I,J_bad), C)\n\n    def test_fancy_indexing_multidim_set(self):\n        n, m = (5, 10)\n\n        def _test_set_slice(i, j):\n            A = self.spmatrix((n, m))\n            with check_remains_sorted(A):\n                A[i, j] = 1\n            B = asmatrix(np.zeros((n, m)))\n            B[i, j] = 1\n            assert_array_almost_equal(A.todense(), B)\n        # [[[1, 2], [1, 2]], [1, 2]]\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n            for i, j in [(np.array([[1, 2], [1, 3]]), [1, 3]),\n                            (np.array([0, 4]), [[0, 3], [1, 2]]),\n                            ([[1, 2, 3], [0, 2, 4]], [[0, 4, 3], [4, 1, 2]])]:\n                _test_set_slice(i, j)\n\n    def test_fancy_assign_list(self):\n        np.random.seed(1234)\n\n        D = np.asmatrix(np.random.rand(5, 7))\n        S = self.spmatrix(D)\n        X = np.random.rand(2, 3)\n\n        I = [[1, 2, 3], [3, 4, 2]]\n        J = [[5, 6, 3], [2, 3, 1]]\n\n        S[I,J] = X\n        D[I,J] = X\n        assert_equal(S.todense(), D)\n\n        I_bad = [[ii + 5 for ii in i] for i in I]\n        J_bad = [[jj + 7 for jj in j] for j in J]\n        C = [1, 2, 3]\n\n        S[I,J] = C\n        D[I,J] = C\n        assert_equal(S.todense(), D)\n\n        S[I,J] = 3\n        D[I,J] = 3\n        assert_equal(S.todense(), D)\n\n        assert_raises(IndexError, S.__setitem__, (I_bad,J), C)\n        assert_raises(IndexError, S.__setitem__, (I,J_bad), C)\n\n    def test_fancy_assign_slice(self):\n        np.random.seed(1234)\n\n        D = np.asmatrix(np.random.rand(5, 7))\n        S = self.spmatrix(D)\n\n        I = [[1, 2, 3], [3, 4, 2]]\n        J = [[5, 6, 3], [2, 3, 1]]\n\n        I_bad = [[ii + 5 for ii in i] for i in I]\n        J_bad = [[jj + 7 for jj in j] for j in J]\n\n        C = [1, 2, 3, 4, 5, 6, 7]\n        assert_raises(IndexError, S.__setitem__, (I_bad, slice(None)), C)\n        assert_raises(IndexError, S.__setitem__, (slice(None), J_bad), C)\n\n\nclass _TestArithmetic:\n    \"\"\"\n    Test real/complex arithmetic\n    \"\"\"\n    def __arith_init(self):\n        # these can be represented exactly in FP (so arithmetic should be exact)\n        self.__A = matrix([[-1.5, 6.5, 0, 2.25, 0, 0],\n                         [3.125, -7.875, 0.625, 0, 0, 0],\n                         [0, 0, -0.125, 1.0, 0, 0],\n                         [0, 0, 8.375, 0, 0, 0]],'float64')\n        self.__B = matrix([[0.375, 0, 0, 0, -5, 2.5],\n                         [14.25, -3.75, 0, 0, -0.125, 0],\n                         [0, 7.25, 0, 0, 0, 0],\n                         [18.5, -0.0625, 0, 0, 0, 0]],'complex128')\n        self.__B.imag = matrix([[1.25, 0, 0, 0, 6, -3.875],\n                              [2.25, 4.125, 0, 0, 0, 2.75],\n                              [0, 4.125, 0, 0, 0, 0],\n                              [-0.0625, 0, 0, 0, 0, 0]],'float64')\n\n        # fractions are all x/16ths\n        assert_array_equal((self.__A*16).astype('int32'),16*self.__A)\n        assert_array_equal((self.__B.real*16).astype('int32'),16*self.__B.real)\n        assert_array_equal((self.__B.imag*16).astype('int32'),16*self.__B.imag)\n\n        self.__Asp = self.spmatrix(self.__A)\n        self.__Bsp = self.spmatrix(self.__B)\n\n    def test_add_sub(self):\n        self.__arith_init()\n\n        # basic tests\n        assert_array_equal((self.__Asp+self.__Bsp).todense(),self.__A+self.__B)\n\n        # check conversions\n        for x in supported_dtypes:\n            A = self.__A.astype(x)\n            Asp = self.spmatrix(A)\n            for y in supported_dtypes:\n                if not np.issubdtype(y, np.complexfloating):\n                    B = self.__B.real.astype(y)\n                else:\n                    B = self.__B.astype(y)\n                Bsp = self.spmatrix(B)\n\n                # addition\n                D1 = A + B\n                S1 = Asp + Bsp\n\n                assert_equal(S1.dtype,D1.dtype)\n                assert_array_equal(S1.todense(),D1)\n                assert_array_equal(Asp + B,D1)          # check sparse + dense\n                assert_array_equal(A + Bsp,D1)          # check dense + sparse\n\n                # subtraction\n                if (np.dtype('bool') in [x, y]) and (\n                        NumpyVersion(np.__version__) >= '1.9.0.dev'):\n                    # boolean array subtraction deprecated in 1.9.0\n                    continue\n\n                D1 = A - B\n                S1 = Asp - Bsp\n\n                assert_equal(S1.dtype,D1.dtype)\n                assert_array_equal(S1.todense(),D1)\n                assert_array_equal(Asp - B,D1)          # check sparse - dense\n                assert_array_equal(A - Bsp,D1)          # check dense - sparse\n\n    def test_mu(self):\n        self.__arith_init()\n\n        # basic tests\n        assert_array_equal((self.__Asp*self.__Bsp.T).todense(),self.__A*self.__B.T)\n\n        for x in supported_dtypes:\n            A = self.__A.astype(x)\n            Asp = self.spmatrix(A)\n            for y in supported_dtypes:\n                if np.issubdtype(y, np.complexfloating):\n                    B = self.__B.astype(y)\n                else:\n                    B = self.__B.real.astype(y)\n                Bsp = self.spmatrix(B)\n\n                D1 = A * B.T\n                S1 = Asp * Bsp.T\n\n                assert_allclose(S1.todense(), D1,\n                                atol=1e-14*abs(D1).max())\n                assert_equal(S1.dtype,D1.dtype)\n\n\nclass _TestMinMax(object):\n    def test_minmax(self):\n        for dtype in [np.float32, np.float64, np.int32, np.int64, np.complex128]:\n            D = np.arange(20, dtype=dtype).reshape(5,4)\n\n            X = self.spmatrix(D)\n            assert_equal(X.min(), 0)\n            assert_equal(X.max(), 19)\n            assert_equal(X.min().dtype, dtype)\n            assert_equal(X.max().dtype, dtype)\n\n            D *= -1\n            X = self.spmatrix(D)\n            assert_equal(X.min(), -19)\n            assert_equal(X.max(), 0)\n\n            D += 5\n            X = self.spmatrix(D)\n            assert_equal(X.min(), -14)\n            assert_equal(X.max(), 5)\n\n        # try a fully dense matrix\n        X = self.spmatrix(np.arange(1, 10).reshape(3, 3))\n        assert_equal(X.min(), 1)\n        assert_equal(X.min().dtype, X.dtype)\n\n        X = -X\n        assert_equal(X.max(), -1)\n\n        # and a fully sparse matrix\n        Z = self.spmatrix(np.zeros(1))\n        assert_equal(Z.min(), 0)\n        assert_equal(Z.max(), 0)\n        assert_equal(Z.max().dtype, Z.dtype)\n\n        # another test\n        D = np.arange(20, dtype=float).reshape(5,4)\n        D[0:2, :] = 0\n        X = self.spmatrix(D)\n        assert_equal(X.min(), 0)\n        assert_equal(X.max(), 19)\n\n        # zero-size matrices\n        for D in [np.zeros((0, 0)), np.zeros((0, 10)), np.zeros((10, 0))]:\n            X = self.spmatrix(D)\n            assert_raises(ValueError, X.min)\n            assert_raises(ValueError, X.max)\n\n    def test_minmax_axis(self):\n        D = np.matrix(np.arange(50).reshape(5,10))\n        # completely empty rows, leaving some completely full:\n        D[1, :] = 0\n        # empty at end for reduceat:\n        D[:, 9] = 0\n        # partial rows/cols:\n        D[3, 3] = 0\n        # entries on either side of 0:\n        D[2, 2] = -1\n        X = self.spmatrix(D)\n\n        if NumpyVersion(np.__version__) >= '1.7.0':\n            # np.matrix.sum with negative axis arg doesn't work for < 1.7\n            axes = [-2, -1, 0, 1]\n        else:\n            axes = [0, 1]\n\n        for axis in axes:\n            assert_array_equal(X.max(axis=axis).A, D.max(axis=axis).A)\n            assert_array_equal(X.min(axis=axis).A, D.min(axis=axis).A)\n\n        # full matrix\n        D = np.matrix(np.arange(1, 51).reshape(10, 5))\n        X = self.spmatrix(D)\n        for axis in axes:\n            assert_array_equal(X.max(axis=axis).A, D.max(axis=axis).A)\n            assert_array_equal(X.min(axis=axis).A, D.min(axis=axis).A)\n\n        # empty matrix\n        D = np.matrix(np.zeros((10, 5)))\n        X = self.spmatrix(D)\n        for axis in axes:\n            assert_array_equal(X.max(axis=axis).A, D.max(axis=axis).A)\n            assert_array_equal(X.min(axis=axis).A, D.min(axis=axis).A)\n\n        if NumpyVersion(np.__version__) >= '1.7.0':\n            axes_even = [0, -2]\n            axes_odd = [1, -1]\n        else:\n            axes_even = [0]\n            axes_odd = [1]\n\n        # zero-size matrices\n        D = np.zeros((0, 10))\n        X = self.spmatrix(D)\n        for axis in axes_even:\n            assert_raises(ValueError, X.min, axis=axis)\n            assert_raises(ValueError, X.max, axis=axis)\n        for axis in axes_odd:\n            assert_array_equal(np.zeros((0, 1)), X.min(axis=axis).A)\n            assert_array_equal(np.zeros((0, 1)), X.max(axis=axis).A)\n\n        D = np.zeros((10, 0))\n        X = self.spmatrix(D)\n        for axis in axes_odd:\n            assert_raises(ValueError, X.min, axis=axis)\n            assert_raises(ValueError, X.max, axis=axis)\n        for axis in axes_even:\n            assert_array_equal(np.zeros((1, 0)), X.min(axis=axis).A)\n            assert_array_equal(np.zeros((1, 0)), X.max(axis=axis).A)\n\n\nclass _TestGetNnzAxis(object):\n    def test_getnnz_axis(self):\n        dat = np.matrix([[0, 2],\n                        [3, 5],\n                        [-6, 9]])\n        bool_dat = dat.astype(bool).A\n        datsp = self.spmatrix(dat)\n\n        assert_array_equal(bool_dat.sum(axis=None), datsp.getnnz(axis=None))\n        assert_array_equal(bool_dat.sum(), datsp.getnnz())\n        assert_array_equal(bool_dat.sum(axis=0), datsp.getnnz(axis=0))\n        assert_array_equal(bool_dat.sum(axis=1), datsp.getnnz(axis=1))\n        if NumpyVersion(np.__version__) >= '1.7.0':\n            # np.matrix.sum with negative axis arg doesn't work for < 1.7\n            assert_array_equal(bool_dat.sum(axis=-2), datsp.getnnz(axis=-2))\n            assert_array_equal(bool_dat.sum(axis=-1), datsp.getnnz(axis=-1))\n\n        assert_raises(ValueError, datsp.getnnz, axis=2)\n\n\n#------------------------------------------------------------------------------\n# Tailored base class for generic tests\n#------------------------------------------------------------------------------\n\ndef _possibly_unimplemented(cls, require=True):\n    \"\"\"\n    Construct a class that either runs tests as usual (require=True),\n    or each method raises SkipTest if it encounters a common error.\n    \"\"\"\n    if require:\n        return cls\n    else:\n        def wrap(fc):\n            def wrapper(*a, **kw):\n                try:\n                    return fc(*a, **kw)\n                except (NotImplementedError, TypeError, ValueError,\n                        IndexError, AttributeError):\n                    raise nose.SkipTest(\"feature not implemented\")\n\n            wrapper.__name__ = fc.__name__\n            return wrapper\n\n        new_dict = dict(cls.__dict__)\n        for name, func in cls.__dict__.items():\n            if name.startswith('test_'):\n                new_dict[name] = wrap(func)\n        return type(cls.__name__ + \"NotImplemented\",\n                    cls.__bases__,\n                    new_dict)\n\n\ndef sparse_test_class(getset=True, slicing=True, slicing_assign=True,\n                      fancy_indexing=True, fancy_assign=True,\n                      fancy_multidim_indexing=True, fancy_multidim_assign=True,\n                      minmax=True, nnz_axis=True):\n    \"\"\"\n    Construct a base class, optionally converting some of the tests in\n    the suite to check that the feature is not implemented.\n    \"\"\"\n    bases = (_TestCommon,\n             _possibly_unimplemented(_TestGetSet, getset),\n             _TestSolve,\n             _TestInplaceArithmetic,\n             _TestArithmetic,\n             _possibly_unimplemented(_TestSlicing, slicing),\n             _possibly_unimplemented(_TestSlicingAssign, slicing_assign),\n             _possibly_unimplemented(_TestFancyIndexing, fancy_indexing),\n             _possibly_unimplemented(_TestFancyIndexingAssign,\n                                     fancy_assign),\n             _possibly_unimplemented(_TestFancyMultidim,\n                                     fancy_indexing and fancy_multidim_indexing),\n             _possibly_unimplemented(_TestFancyMultidimAssign,\n                                     fancy_multidim_assign and fancy_assign),\n             _possibly_unimplemented(_TestMinMax, minmax),\n             _possibly_unimplemented(_TestGetNnzAxis, nnz_axis))\n\n    # check that test names do not clash\n    names = {}\n    for cls in bases:\n        for name in cls.__dict__:\n            if not name.startswith('test_'):\n                continue\n            old_cls = names.get(name)\n            if old_cls is not None:\n                raise ValueError(\"Test class %s overloads test %s defined in %s\" % (\n                    cls.__name__, name, old_cls.__name__))\n            names[name] = cls\n\n    return type(\"TestBase\", bases, {})\n\n\n#------------------------------------------------------------------------------\n# Matrix class based tests\n#------------------------------------------------------------------------------\n\nclass TestCSR(sparse_test_class()):\n    spmatrix = csr_matrix\n    math_dtypes = [np.bool_, np.int_, np.float_, np.complex_]\n\n    def test_constructor1(self):\n        b = matrix([[0,4,0],\n                   [3,0,0],\n                   [0,2,0]],'d')\n        bsp = csr_matrix(b)\n        assert_array_almost_equal(bsp.data,[4,3,2])\n        assert_array_equal(bsp.indices,[1,0,1])\n        assert_array_equal(bsp.indptr,[0,1,2,3])\n        assert_equal(bsp.getnnz(),3)\n        assert_equal(bsp.getformat(),'csr')\n        assert_array_equal(bsp.todense(),b)\n\n    def test_constructor2(self):\n        b = zeros((6,6),'d')\n        b[3,4] = 5\n        bsp = csr_matrix(b)\n        assert_array_almost_equal(bsp.data,[5])\n        assert_array_equal(bsp.indices,[4])\n        assert_array_equal(bsp.indptr,[0,0,0,0,1,1,1])\n        assert_array_almost_equal(bsp.todense(),b)\n\n    def test_constructor3(self):\n        b = matrix([[1,0],\n                   [0,2],\n                   [3,0]],'d')\n        bsp = csr_matrix(b)\n        assert_array_almost_equal(bsp.data,[1,2,3])\n        assert_array_equal(bsp.indices,[0,1,0])\n        assert_array_equal(bsp.indptr,[0,1,2,3])\n        assert_array_almost_equal(bsp.todense(),b)\n\n### currently disabled\n##    def test_constructor4(self):\n##        \"\"\"try using int64 indices\"\"\"\n##        data = arange( 6 ) + 1\n##        col = array( [1, 2, 1, 0, 0, 2], dtype='int64' )\n##        ptr = array( [0, 2, 4, 6], dtype='int64' )\n##\n##        a = csr_matrix( (data, col, ptr), shape = (3,3) )\n##\n##        b = matrix([[0,1,2],\n##                    [4,3,0],\n##                    [5,0,6]],'d')\n##\n##        assert_equal(a.indptr.dtype,numpy.dtype('int64'))\n##        assert_equal(a.indices.dtype,numpy.dtype('int64'))\n##        assert_array_equal(a.todense(),b)\n\n    def test_constructor4(self):\n        # using (data, ij) format\n        row = array([2, 3, 1, 3, 0, 1, 3, 0, 2, 1, 2])\n        col = array([0, 1, 0, 0, 1, 1, 2, 2, 2, 2, 1])\n        data = array([6., 10., 3., 9., 1., 4.,\n                              11., 2., 8., 5., 7.])\n\n        ij = vstack((row,col))\n        csr = csr_matrix((data,ij),(4,3))\n        assert_array_equal(arange(12).reshape(4,3),csr.todense())\n\n    def test_constructor5(self):\n        # infer dimensions from arrays\n        indptr = array([0,1,3,3])\n        indices = array([0,5,1,2])\n        data = array([1,2,3,4])\n        csr = csr_matrix((data, indices, indptr))\n        assert_array_equal(csr.shape,(3,6))\n\n    def test_sort_indices(self):\n        data = arange(5)\n        indices = array([7, 2, 1, 5, 4])\n        indptr = array([0, 3, 5])\n        asp = csr_matrix((data, indices, indptr), shape=(2,10))\n        bsp = asp.copy()\n        asp.sort_indices()\n        assert_array_equal(asp.indices,[1, 2, 7, 4, 5])\n        assert_array_equal(asp.todense(),bsp.todense())\n\n    def test_eliminate_zeros(self):\n        data = array([1, 0, 0, 0, 2, 0, 3, 0])\n        indices = array([1, 2, 3, 4, 5, 6, 7, 8])\n        indptr = array([0, 3, 8])\n        asp = csr_matrix((data, indices, indptr), shape=(2,10))\n        bsp = asp.copy()\n        asp.eliminate_zeros()\n        assert_array_equal(asp.nnz, 3)\n        assert_array_equal(asp.data,[1, 2, 3])\n        assert_array_equal(asp.todense(),bsp.todense())\n\n    def test_ufuncs(self):\n        X = csr_matrix(np.arange(20).reshape(4, 5) / 20.)\n        for f in [\"sin\", \"tan\", \"arcsin\", \"arctan\", \"sinh\", \"tanh\",\n                  \"arcsinh\", \"arctanh\", \"rint\", \"sign\", \"expm1\", \"log1p\",\n                  \"deg2rad\", \"rad2deg\", \"floor\", \"ceil\", \"trunc\", \"sqrt\"]:\n            assert_equal(hasattr(csr_matrix, f), True)\n            X2 = getattr(X, f)()\n            assert_equal(X.shape, X2.shape)\n            assert_array_equal(X.indices, X2.indices)\n            assert_array_equal(X.indptr, X2.indptr)\n            assert_array_equal(X2.toarray(), getattr(np, f)(X.toarray()))\n\n    def test_unsorted_arithmetic(self):\n        data = arange(5)\n        indices = array([7, 2, 1, 5, 4])\n        indptr = array([0, 3, 5])\n        asp = csr_matrix((data, indices, indptr), shape=(2,10))\n        data = arange(6)\n        indices = array([8, 1, 5, 7, 2, 4])\n        indptr = array([0, 2, 6])\n        bsp = csr_matrix((data, indices, indptr), shape=(2,10))\n        assert_equal((asp + bsp).todense(), asp.todense() + bsp.todense())\n\n    def test_fancy_indexing_broadcast(self):\n        # broadcasting indexing mode is supported\n        I = np.array([[1], [2], [3]])\n        J = np.array([3, 4, 2])\n\n        np.random.seed(1234)\n        D = np.asmatrix(np.random.rand(5, 7))\n        S = self.spmatrix(D)\n\n        SIJ = S[I,J]\n        if isspmatrix(SIJ):\n            SIJ = SIJ.todense()\n        assert_equal(SIJ, D[I,J])\n\n    def test_has_sorted_indices(self):\n        \"Ensure has_sorted_indices memoizes sorted state for sort_indices\"\n        sorted_inds = np.array([0, 1])\n        unsorted_inds = np.array([1, 0])\n        data = np.array([1, 1])\n        indptr = np.array([0, 2])\n        M = csr_matrix((data, sorted_inds, indptr)).copy()\n        assert_equal(True, M.has_sorted_indices)\n\n        M = csr_matrix((data, unsorted_inds, indptr)).copy()\n        assert_equal(False, M.has_sorted_indices)\n\n        # set by sorting\n        M.sort_indices()\n        assert_equal(True, M.has_sorted_indices)\n        assert_array_equal(M.indices, sorted_inds)\n\n        M = csr_matrix((data, unsorted_inds, indptr)).copy()\n        # set manually (although underlyingly unsorted)\n        M.has_sorted_indices = True\n        assert_equal(True, M.has_sorted_indices)\n        assert_array_equal(M.indices, unsorted_inds)\n\n        # ensure sort bypassed when has_sorted_indices == True\n        M.sort_indices()\n        assert_array_equal(M.indices, unsorted_inds)\n\n    def test_has_canonical_format(self):\n        \"Ensure has_canonical_format memoizes state for sum_duplicates\"\n\n        M = csr_matrix((np.array([2]), np.array([0]), np.array([0, 1])))\n        assert_equal(True, M.has_canonical_format)\n\n        indices = np.array([0, 0])  # contains duplicate\n        data = np.array([1, 1])\n        indptr = np.array([0, 2])\n\n        M = csr_matrix((data, indices, indptr)).copy()\n        assert_equal(False, M.has_canonical_format)\n\n        # set by deduplicating\n        M.sum_duplicates()\n        assert_equal(True, M.has_canonical_format)\n        assert_equal(1, len(M.indices))\n\n        M = csr_matrix((data, indices, indptr)).copy()\n        # set manually (although underlyingly duplicated)\n        M.has_canonical_format = True\n        assert_equal(True, M.has_canonical_format)\n        assert_equal(2, len(M.indices))  # unaffected content\n\n        # ensure deduplication bypassed when has_canonical_format == True\n        M.sum_duplicates()\n        assert_equal(2, len(M.indices))  # unaffected content\n\n\nclass TestCSC(sparse_test_class()):\n    spmatrix = csc_matrix\n    math_dtypes = [np.bool_, np.int_, np.float_, np.complex_]\n\n    def test_constructor1(self):\n        b = matrix([[1,0,0,0],[0,0,1,0],[0,2,0,3]],'d')\n        bsp = csc_matrix(b)\n        assert_array_almost_equal(bsp.data,[1,2,1,3])\n        assert_array_equal(bsp.indices,[0,2,1,2])\n        assert_array_equal(bsp.indptr,[0,1,2,3,4])\n        assert_equal(bsp.getnnz(),4)\n        assert_equal(bsp.shape,b.shape)\n        assert_equal(bsp.getformat(),'csc')\n\n    def test_constructor2(self):\n        b = zeros((6,6),'d')\n        b[2,4] = 5\n        bsp = csc_matrix(b)\n        assert_array_almost_equal(bsp.data,[5])\n        assert_array_equal(bsp.indices,[2])\n        assert_array_equal(bsp.indptr,[0,0,0,0,0,1,1])\n\n    def test_constructor3(self):\n        b = matrix([[1,0],[0,0],[0,2]],'d')\n        bsp = csc_matrix(b)\n        assert_array_almost_equal(bsp.data,[1,2])\n        assert_array_equal(bsp.indices,[0,2])\n        assert_array_equal(bsp.indptr,[0,1,2])\n\n    def test_constructor4(self):\n        # using (data, ij) format\n        row = array([2, 3, 1, 3, 0, 1, 3, 0, 2, 1, 2])\n        col = array([0, 1, 0, 0, 1, 1, 2, 2, 2, 2, 1])\n        data = array([6., 10., 3., 9., 1., 4.,\n                              11., 2., 8., 5., 7.])\n\n        ij = vstack((row,col))\n        csc = csc_matrix((data,ij),(4,3))\n        assert_array_equal(arange(12).reshape(4,3),csc.todense())\n\n    def test_constructor5(self):\n        # infer dimensions from arrays\n        indptr = array([0,1,3,3])\n        indices = array([0,5,1,2])\n        data = array([1,2,3,4])\n        csc = csc_matrix((data, indices, indptr))\n        assert_array_equal(csc.shape,(6,3))\n\n    def test_eliminate_zeros(self):\n        data = array([1, 0, 0, 0, 2, 0, 3, 0])\n        indices = array([1, 2, 3, 4, 5, 6, 7, 8])\n        indptr = array([0, 3, 8])\n        asp = csc_matrix((data, indices, indptr), shape=(10,2))\n        bsp = asp.copy()\n        asp.eliminate_zeros()\n        assert_array_equal(asp.nnz, 3)\n        assert_array_equal(asp.data,[1, 2, 3])\n        assert_array_equal(asp.todense(),bsp.todense())\n\n    def test_sort_indices(self):\n        data = arange(5)\n        row = array([7, 2, 1, 5, 4])\n        ptr = [0, 3, 5]\n        asp = csc_matrix((data, row, ptr), shape=(10,2))\n        bsp = asp.copy()\n        asp.sort_indices()\n        assert_array_equal(asp.indices,[1, 2, 7, 4, 5])\n        assert_array_equal(asp.todense(),bsp.todense())\n\n    def test_ufuncs(self):\n        X = csc_matrix(np.arange(21).reshape(7, 3) / 21.)\n        for f in [\"sin\", \"tan\", \"arcsin\", \"arctan\", \"sinh\", \"tanh\",\n                  \"arcsinh\", \"arctanh\", \"rint\", \"sign\", \"expm1\", \"log1p\",\n                  \"deg2rad\", \"rad2deg\", \"floor\", \"ceil\", \"trunc\", \"sqrt\"]:\n            assert_equal(hasattr(csr_matrix, f), True)\n            X2 = getattr(X, f)()\n            assert_equal(X.shape, X2.shape)\n            assert_array_equal(X.indices, X2.indices)\n            assert_array_equal(X.indptr, X2.indptr)\n            assert_array_equal(X2.toarray(), getattr(np, f)(X.toarray()))\n\n    def test_unsorted_arithmetic(self):\n        data = arange(5)\n        indices = array([7, 2, 1, 5, 4])\n        indptr = array([0, 3, 5])\n        asp = csc_matrix((data, indices, indptr), shape=(10,2))\n        data = arange(6)\n        indices = array([8, 1, 5, 7, 2, 4])\n        indptr = array([0, 2, 6])\n        bsp = csc_matrix((data, indices, indptr), shape=(10,2))\n        assert_equal((asp + bsp).todense(), asp.todense() + bsp.todense())\n\n    def test_fancy_indexing_broadcast(self):\n        # broadcasting indexing mode is supported\n        I = np.array([[1], [2], [3]])\n        J = np.array([3, 4, 2])\n\n        np.random.seed(1234)\n        D = np.asmatrix(np.random.rand(5, 7))\n        S = self.spmatrix(D)\n\n        SIJ = S[I,J]\n        if isspmatrix(SIJ):\n            SIJ = SIJ.todense()\n        assert_equal(SIJ, D[I,J])\n\n\nclass TestDOK(sparse_test_class(minmax=False, nnz_axis=False)):\n    spmatrix = dok_matrix\n    math_dtypes = [np.int_, np.float_, np.complex_]\n\n    def test_mult(self):\n        A = dok_matrix((10,10))\n        A[0,3] = 10\n        A[5,6] = 20\n        D = A*A.T\n        E = A*A.H\n        assert_array_equal(D.A, E.A)\n\n    def test_add_nonzero(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=SparseEfficiencyWarning)\n            A = self.spmatrix((3,2))\n            A[0,1] = -10\n            A[2,0] = 20\n            A = A + 10\n            B = matrix([[10, 0], [10, 10], [30, 10]])\n            assert_array_equal(A.todense(), B)\n\n            A = A + 1j\n            B = B + 1j\n            assert_array_equal(A.todense(), B)\n\n    def test_dok_divide_scalar(self):\n        A = self.spmatrix((3,2))\n        A[0,1] = -10\n        A[2,0] = 20\n\n        assert_array_equal((A/1j).todense(), A.todense()/1j)\n        assert_array_equal((A/9).todense(), A.todense()/9)\n\n    def test_convert(self):\n        # Test provided by Andrew Straw.  Fails in SciPy <= r1477.\n        (m, n) = (6, 7)\n        a = dok_matrix((m, n))\n\n        # set a few elements, but none in the last column\n        a[2,1] = 1\n        a[0,2] = 2\n        a[3,1] = 3\n        a[1,5] = 4\n        a[4,3] = 5\n        a[4,2] = 6\n\n        # assert that the last column is all zeros\n        assert_array_equal(a.toarray()[:,n-1], zeros(m,))\n\n        # make sure it still works for CSC format\n        csc = a.tocsc()\n        assert_array_equal(csc.toarray()[:,n-1], zeros(m,))\n\n        # now test CSR\n        (m, n) = (n, m)\n        b = a.transpose()\n        assert_equal(b.shape, (m, n))\n        # assert that the last row is all zeros\n        assert_array_equal(b.toarray()[m-1,:], zeros(n,))\n\n        # make sure it still works for CSR format\n        csr = b.tocsr()\n        assert_array_equal(csr.toarray()[m-1,:], zeros(n,))\n\n    def test_ctor(self):\n        # Empty ctor\n        assert_raises(TypeError, dok_matrix)\n\n        # Dense ctor\n        b = matrix([[1,0,0,0],[0,0,1,0],[0,2,0,3]],'d')\n        A = dok_matrix(b)\n        assert_equal(b.dtype, A.dtype)\n        assert_equal(A.todense(), b)\n\n        # Sparse ctor\n        c = csr_matrix(b)\n        assert_equal(A.todense(), c.todense())\n\n        data = [[0, 1, 2], [3, 0, 0]]\n        d = dok_matrix(data, dtype=np.float32)\n        assert_equal(d.dtype, np.float32)\n        da = d.toarray()\n        assert_equal(da.dtype, np.float32)\n        assert_array_equal(da, data)\n\n    def test_resize(self):\n        # A couple basic tests of the resize() method.\n        #\n        # resize(shape) resizes the array in-place.\n        a = dok_matrix((5,5))\n        a[:,0] = 1\n        a.resize((2,2))\n        expected1 = array([[1,0],[1,0]])\n        assert_array_equal(a.todense(), expected1)\n        a.resize((3,2))\n        expected2 = array([[1,0],[1,0],[0,0]])\n        assert_array_equal(a.todense(), expected2)\n\n    def test_ticket1160(self):\n        # Regression test for ticket #1160.\n        a = dok_matrix((3,3))\n        a[0,0] = 0\n        # This assert would fail, because the above assignment would\n        # incorrectly call __set_item__ even though the value was 0.\n        assert_((0,0) not in a.keys(), \"Unexpected entry (0,0) in keys\")\n\n        # Slice assignments were also affected.\n        b = dok_matrix((3,3))\n        b[:,0] = 0\n        assert_(len(b.keys()) == 0, \"Unexpected entries in keys\")\n\n    ##\n    ## TODO: The DOK matrix currently returns invalid results rather\n    ##       than raising errors in some indexing operations\n    ##\n\n    @dec.knownfailureif(True, \"known deficiency in DOK\")\n    def test_fancy_indexing(self):\n        pass\n\n    @dec.knownfailureif(True, \"known deficiency in DOK\")\n    def test_add_sub(self):\n        pass\n\n\nclass TestLIL(sparse_test_class(minmax=False)):\n    spmatrix = lil_matrix\n    math_dtypes = [np.int_, np.float_, np.complex_]\n\n    def test_dot(self):\n        A = matrix(zeros((10,10)))\n        A[0,3] = 10\n        A[5,6] = 20\n\n        B = lil_matrix((10,10))\n        B[0,3] = 10\n        B[5,6] = 20\n        assert_array_equal(A * A.T, (B * B.T).todense())\n        assert_array_equal(A * A.H, (B * B.H).todense())\n\n    def test_scalar_mul(self):\n        x = lil_matrix((3,3))\n        x[0,0] = 2\n\n        x = x*2\n        assert_equal(x[0,0],4)\n\n        x = x*0\n        assert_equal(x[0,0],0)\n\n    def test_reshape(self):\n        x = lil_matrix((4,3))\n        x[0,0] = 1\n        x[2,1] = 3\n        x[3,2] = 5\n        x[0,2] = 7\n\n        for s in [(12,1),(1,12)]:\n            assert_array_equal(x.reshape(s).todense(),\n                               x.todense().reshape(s))\n\n    def test_inplace_ops(self):\n        A = lil_matrix([[0,2,3],[4,0,6]])\n        B = lil_matrix([[0,1,0],[0,2,3]])\n\n        data = {'add': (B,A + B),\n                'sub': (B,A - B),\n                'mul': (3,A * 3)}\n\n        for op,(other,expected) in data.items():\n            result = A.copy()\n            getattr(result, '__i%s__' % op)(other)\n\n            assert_array_equal(result.todense(), expected.todense())\n\n        # Ticket 1604.\n        A = lil_matrix((1,3), dtype=np.dtype('float64'))\n        B = array([0.1,0.1,0.1])\n        A[0,:] += B\n        assert_array_equal(A[0,:].toarray().squeeze(), B)\n\n    def test_lil_iteration(self):\n        row_data = [[1,2,3],[4,5,6]]\n        B = lil_matrix(array(row_data))\n        for r,row in enumerate(B):\n            assert_array_equal(row.todense(),array(row_data[r],ndmin=2))\n\n    def test_lil_from_csr(self):\n        # Tests whether a lil_matrix can be constructed from a\n        # csr_matrix.\n        B = lil_matrix((10,10))\n        B[0,3] = 10\n        B[5,6] = 20\n        B[8,3] = 30\n        B[3,8] = 40\n        B[8,9] = 50\n        C = B.tocsr()\n        D = lil_matrix(C)\n        assert_array_equal(C.A, D.A)\n\n    def test_fancy_indexing_lil(self):\n        M = asmatrix(arange(25).reshape(5,5))\n        A = lil_matrix(M)\n\n        assert_equal(A[array([1,2,3]),2:3].todense(), M[array([1,2,3]),2:3])\n\n    def test_point_wise_multiply(self):\n        l = lil_matrix((4,3))\n        l[0,0] = 1\n        l[1,1] = 2\n        l[2,2] = 3\n        l[3,1] = 4\n\n        m = lil_matrix((4,3))\n        m[0,0] = 1\n        m[0,1] = 2\n        m[2,2] = 3\n        m[3,1] = 4\n        m[3,2] = 4\n\n        assert_array_equal(l.multiply(m).todense(),\n                           m.multiply(l).todense())\n\n        assert_array_equal(l.multiply(m).todense(),\n                           [[1,0,0],\n                            [0,0,0],\n                            [0,0,9],\n                            [0,16,0]])\n\n    def test_lil_multiply_removal(self):\n        # Ticket #1427.\n        a = lil_matrix(np.ones((3,3)))\n        a *= 2.\n        a[0, :] = 0\n\n\nclass TestCOO(sparse_test_class(getset=False,\n                                slicing=False, slicing_assign=False,\n                                fancy_indexing=False, fancy_assign=False)):\n    spmatrix = coo_matrix\n    math_dtypes = [np.int_, np.float_, np.complex_]\n\n    def test_constructor1(self):\n        # unsorted triplet format\n        row = array([2, 3, 1, 3, 0, 1, 3, 0, 2, 1, 2])\n        col = array([0, 1, 0, 0, 1, 1, 2, 2, 2, 2, 1])\n        data = array([6., 10., 3., 9., 1., 4.,\n                              11., 2., 8., 5., 7.])\n\n        coo = coo_matrix((data,(row,col)),(4,3))\n\n        assert_array_equal(arange(12).reshape(4,3),coo.todense())\n\n    def test_constructor2(self):\n        # unsorted triplet format with duplicates (which are summed)\n        row = array([0,1,2,2,2,2,0,0,2,2])\n        col = array([0,2,0,2,1,1,1,0,0,2])\n        data = array([2,9,-4,5,7,0,-1,2,1,-5])\n        coo = coo_matrix((data,(row,col)),(3,3))\n\n        mat = matrix([[4,-1,0],[0,0,9],[-3,7,0]])\n\n        assert_array_equal(mat,coo.todense())\n\n    def test_constructor3(self):\n        # empty matrix\n        coo = coo_matrix((4,3))\n\n        assert_array_equal(coo.shape,(4,3))\n        assert_array_equal(coo.row,[])\n        assert_array_equal(coo.col,[])\n        assert_array_equal(coo.data,[])\n        assert_array_equal(coo.todense(),zeros((4,3)))\n\n    def test_constructor4(self):\n        # from dense matrix\n        mat = array([[0,1,0,0],\n                     [7,0,3,0],\n                     [0,4,0,0]])\n        coo = coo_matrix(mat)\n        assert_array_equal(coo.todense(),mat)\n\n        # upgrade rank 1 arrays to row matrix\n        mat = array([0,1,0,0])\n        coo = coo_matrix(mat)\n        assert_array_equal(coo.todense(),mat.reshape(1,-1))\n\n    # COO does not have a __getitem__ to support iteration\n    def test_iterator(self):\n        pass\n\n    def test_todia_all_zeros(self):\n        zeros = [[0, 0]]\n        dia = coo_matrix(zeros).todia()\n        assert_array_equal(dia.A, zeros)\n\n    def test_sum_duplicates(self):\n        coo = coo_matrix((4,3))\n        coo.sum_duplicates()\n        coo = coo_matrix(([1,2], ([1,0], [1,0])))\n        coo.sum_duplicates()\n        assert_array_equal(coo.A, [[2,0],[0,1]])\n        coo = coo_matrix(([1,2], ([1,1], [1,1])))\n        coo.sum_duplicates()\n        assert_array_equal(coo.A, [[0,0],[0,3]])\n        assert_array_equal(coo.row, [1])\n        assert_array_equal(coo.col, [1])\n        assert_array_equal(coo.data, [3])\n\n    def test_todok_duplicates(self):\n        coo = coo_matrix(([1,1,1,1], ([0,2,2,0], [0,1,1,0])))\n        dok = coo.todok()\n        assert_array_equal(dok.A, coo.A)\n\n\nclass TestDIA(sparse_test_class(getset=False, slicing=False, slicing_assign=False,\n                                fancy_indexing=False, fancy_assign=False,\n                                minmax=False, nnz_axis=False)):\n    spmatrix = dia_matrix\n    math_dtypes = [np.int_, np.float_, np.complex_]\n\n    def test_constructor1(self):\n        D = matrix([[1, 0, 3, 0],\n                    [1, 2, 0, 4],\n                    [0, 2, 3, 0],\n                    [0, 0, 3, 4]])\n        data = np.array([[1,2,3,4]]).repeat(3,axis=0)\n        offsets = np.array([0,-1,2])\n        assert_equal(dia_matrix((data,offsets), shape=(4,4)).todense(), D)\n\n    # DIA does not have a __getitem__ to support iteration\n    def test_iterator(self):\n        pass\n\n    @with_64bit_maxval_limit(3)\n    def test_setdiag_dtype(self):\n        m = dia_matrix(np.eye(3))\n        assert_equal(m.offsets.dtype, np.int32)\n        m.setdiag((3,), k=2)\n        assert_equal(m.offsets.dtype, np.int32)\n\n        m = dia_matrix(np.eye(4))\n        assert_equal(m.offsets.dtype, np.int64)\n        m.setdiag((3,), k=3)\n        assert_equal(m.offsets.dtype, np.int64)\n\n\nclass TestBSR(sparse_test_class(getset=False,\n                                slicing=False, slicing_assign=False,\n                                fancy_indexing=False, fancy_assign=False,\n                                nnz_axis=False)):\n    spmatrix = bsr_matrix\n    math_dtypes = [np.int_, np.float_, np.complex_]\n\n    def test_constructor1(self):\n        # check native BSR format constructor\n        indptr = array([0,2,2,4])\n        indices = array([0,2,2,3])\n        data = zeros((4,2,3))\n\n        data[0] = array([[0, 1, 2],\n                         [3, 0, 5]])\n        data[1] = array([[0, 2, 4],\n                         [6, 0, 10]])\n        data[2] = array([[0, 4, 8],\n                         [12, 0, 20]])\n        data[3] = array([[0, 5, 10],\n                         [15, 0, 25]])\n\n        A = kron([[1,0,2,0],[0,0,0,0],[0,0,4,5]], [[0,1,2],[3,0,5]])\n        Asp = bsr_matrix((data,indices,indptr),shape=(6,12))\n        assert_equal(Asp.todense(),A)\n\n        # infer shape from arrays\n        Asp = bsr_matrix((data,indices,indptr))\n        assert_equal(Asp.todense(),A)\n\n    def test_constructor2(self):\n        # construct from dense\n\n        # test zero mats\n        for shape in [(1,1), (5,1), (1,10), (10,4), (3,7), (2,1)]:\n            A = zeros(shape)\n            assert_equal(bsr_matrix(A).todense(),A)\n        A = zeros((4,6))\n        assert_equal(bsr_matrix(A,blocksize=(2,2)).todense(),A)\n        assert_equal(bsr_matrix(A,blocksize=(2,3)).todense(),A)\n\n        A = kron([[1,0,2,0],[0,0,0,0],[0,0,4,5]], [[0,1,2],[3,0,5]])\n        assert_equal(bsr_matrix(A).todense(),A)\n        assert_equal(bsr_matrix(A,shape=(6,12)).todense(),A)\n        assert_equal(bsr_matrix(A,blocksize=(1,1)).todense(),A)\n        assert_equal(bsr_matrix(A,blocksize=(2,3)).todense(),A)\n        assert_equal(bsr_matrix(A,blocksize=(2,6)).todense(),A)\n        assert_equal(bsr_matrix(A,blocksize=(2,12)).todense(),A)\n        assert_equal(bsr_matrix(A,blocksize=(3,12)).todense(),A)\n        assert_equal(bsr_matrix(A,blocksize=(6,12)).todense(),A)\n\n        A = kron([[1,0,2,0],[0,1,0,0],[0,0,0,0]], [[0,1,2],[3,0,5]])\n        assert_equal(bsr_matrix(A,blocksize=(2,3)).todense(),A)\n\n    def test_eliminate_zeros(self):\n        data = kron([1, 0, 0, 0, 2, 0, 3, 0], [[1,1],[1,1]]).T\n        data = data.reshape(-1,2,2)\n        indices = array([1, 2, 3, 4, 5, 6, 7, 8])\n        indptr = array([0, 3, 8])\n        asp = bsr_matrix((data, indices, indptr), shape=(4,20))\n        bsp = asp.copy()\n        asp.eliminate_zeros()\n        assert_array_equal(asp.nnz, 3*4)\n        assert_array_equal(asp.todense(),bsp.todense())\n\n    def test_bsr_matvec(self):\n        A = bsr_matrix(arange(2*3*4*5).reshape(2*4,3*5), blocksize=(4,5))\n        x = arange(A.shape[1]).reshape(-1,1)\n        assert_equal(A*x, A.todense()*x)\n\n    def test_bsr_matvecs(self):\n        A = bsr_matrix(arange(2*3*4*5).reshape(2*4,3*5), blocksize=(4,5))\n        x = arange(A.shape[1]*6).reshape(-1,6)\n        assert_equal(A*x, A.todense()*x)\n\n    @dec.knownfailureif(True, \"BSR not implemented\")\n    def test_iterator(self):\n        pass\n\n    @dec.knownfailureif(True, \"known deficiency in BSR\")\n    def test_setdiag(self):\n        pass\n\n\n#------------------------------------------------------------------------------\n# Tests for non-canonical representations (with duplicates, unsorted indices)\n#------------------------------------------------------------------------------\n\ndef _same_sum_duplicate(data, *inds, **kwargs):\n    \"\"\"Duplicates entries to produce the same matrix\"\"\"\n    indptr = kwargs.pop('indptr', None)\n    if np.issubdtype(data.dtype, np.bool_) or \\\n       np.issubdtype(data.dtype, np.unsignedinteger):\n        if indptr is None:\n            return (data,) + inds\n        else:\n            return (data,) + inds + (indptr,)\n\n    zeros_pos = (data == 0).nonzero()\n\n    # duplicate data\n    data = data.repeat(2, axis=0)\n    data[::2] -= 1\n    data[1::2] = 1\n\n    # don't spoil all explicit zeros\n    if zeros_pos[0].size > 0:\n        pos = tuple(p[0] for p in zeros_pos)\n        pos1 = (2*pos[0],) + pos[1:]\n        pos2 = (2*pos[0]+1,) + pos[1:]\n        data[pos1] = 0\n        data[pos2] = 0\n\n    inds = tuple(indices.repeat(2) for indices in inds)\n\n    if indptr is None:\n        return (data,) + inds\n    else:\n        return (data,) + inds + (indptr * 2,)\n\n\nclass _NonCanonicalMixin(object):\n    def spmatrix(self, D, **kwargs):\n        \"\"\"Replace D with a non-canonical equivalent: containing\n        duplicate elements and explicit zeros\"\"\"\n        construct = super(_NonCanonicalMixin, self).spmatrix\n        M = construct(D, **kwargs)\n\n        zero_pos = (M.A == 0).nonzero()\n        has_zeros = (zero_pos[0].size > 0)\n        if has_zeros:\n            k = zero_pos[0].size//2\n            M = self._insert_explicit_zero(M,\n                                           zero_pos[0][k],\n                                           zero_pos[1][k])\n\n        arg1 = self._arg1_for_noncanonical(M)\n        if 'shape' not in kwargs:\n            kwargs['shape'] = M.shape\n        NC = construct(arg1, **kwargs)\n\n        # check that result is valid\n        assert_allclose(NC.A, M.A)\n\n        # check that at least one explicit zero\n        if has_zeros:\n            assert_((NC.data == 0).any())\n\n        return NC\n\n    @dec.knownfailureif(True, 'abs broken with non-canonical matrix')\n    def test_abs(self):\n        pass\n\n    @dec.knownfailureif(True, 'bool(matrix) broken with non-canonical matrix')\n    def test_bool(self):\n        pass\n\n    @dec.knownfailureif(True, 'min/max broken with non-canonical matrix')\n    def test_minmax(self):\n        pass\n\n    @dec.knownfailureif(True, 'format conversion broken with non-canonical matrix')\n    def test_sparse_format_conversions(self):\n        pass\n\n    @dec.knownfailureif(True, 'unary ufunc overrides broken with non-canonical matrix')\n    def test_unary_ufunc_overrides(self):\n        pass\n\n    @dec.knownfailureif(True, 'some binary ufuncs fail with scalars for noncanonical matrices')\n    def test_binary_ufunc_overrides(self):\n        pass\n\n    @dec.knownfailureif(True, 'getnnz-axis broken with non-canonical matrix')\n    def test_getnnz_axis(self):\n        pass\n\n\nclass _NonCanonicalCompressedMixin(_NonCanonicalMixin):\n    def _arg1_for_noncanonical(self, M):\n        \"\"\"Return non-canonical constructor arg1 equivalent to M\"\"\"\n        data, indices, indptr = _same_sum_duplicate(M.data, M.indices,\n                                                    indptr=M.indptr)\n        # unsorted\n        for start, stop in izip(indptr, indptr[1:]):\n            indices[start:stop] = indices[start:stop][::-1].copy()\n            data[start:stop] = data[start:stop][::-1].copy()\n        return data, indices, indptr\n\n    def _insert_explicit_zero(self, M, i, j):\n        M[i,j] = 0\n        return M\n\n\nclass _NonCanonicalCSMixin(_NonCanonicalCompressedMixin):\n    @dec.knownfailureif(True, '__getitem__ with non-canonical matrix broken for sparse boolean index due to __gt__')\n    def test_fancy_indexing_sparse_boolean(self):\n        pass\n\n    @dec.knownfailureif(True, 'broadcasting element-wise multiply broken with non-canonical matrix')\n    def test_elementwise_multiply_broadcast(self):\n        pass\n\n    @dec.knownfailureif(True, 'inverse broken with non-canonical matrix')\n    def test_inv(self):\n        pass\n\n    @dec.knownfailureif(True, 'solve broken with non-canonical matrix')\n    def test_solve(self):\n        pass\n\n\nclass TestCSRNonCanonical(_NonCanonicalCSMixin, TestCSR):\n    @dec.knownfailureif(True, 'nnz counts explicit zeros')\n    def test_empty(self):\n        pass\n\n\nclass TestCSCNonCanonical(_NonCanonicalCSMixin, TestCSC):\n    @dec.knownfailureif(True, 'nnz counts explicit zeros')\n    def test_empty(self):\n        pass\n\n    @dec.knownfailureif(True, 'nonzero reports explicit zeros')\n    def test_nonzero(self):\n        pass\n\n\nclass TestBSRNonCanonical(_NonCanonicalCompressedMixin, TestBSR):\n    def _insert_explicit_zero(self, M, i, j):\n        x = M.tocsr()\n        x[i,j] = 0\n        return x.tobsr(blocksize=M.blocksize)\n\n    @dec.knownfailureif(True, 'unary ufunc overrides broken with non-canonical BSR')\n    def test_diagonal(self):\n        pass\n\n    @dec.knownfailureif(True, 'unary ufunc overrides broken with non-canonical BSR')\n    def test_expm(self):\n        pass\n\n    @dec.knownfailureif(True, 'inequalities require sum_duplicates, not implemented for BSR')\n    def test_eq(self):\n        pass\n\n    @dec.knownfailureif(True, 'inequalities require sum_duplicates, not implemented for BSR')\n    def test_ne(self):\n        pass\n\n    @dec.knownfailureif(True, 'inequalities require sum_duplicates, not implemented for BSR')\n    def test_gt(self):\n        pass\n\n    @dec.knownfailureif(True, 'inequalities require sum_duplicates, not implemented for BSR')\n    def test_lt(self):\n        pass\n\n    @dec.knownfailureif(True, 'inequalities require sum_duplicates, not implemented for BSR')\n    def test_ge(self):\n        pass\n\n    @dec.knownfailureif(True, 'inequalities require sum_duplicates, not implemented for BSR')\n    def test_le(self):\n        pass\n\n    @dec.knownfailureif(True, 'maximum and minimum fail for non-canonical BSR')\n    def test_maximum_minimum(self):\n        pass\n\n    @dec.knownfailureif(True, 'nnz counts explicit zeros')\n    def test_empty(self):\n        pass\n\n\nclass TestCOONonCanonical(_NonCanonicalMixin, TestCOO):\n    def _arg1_for_noncanonical(self, M):\n        \"\"\"Return non-canonical constructor arg1 equivalent to M\"\"\"\n        data, row, col = _same_sum_duplicate(M.data, M.row, M.col)\n        return data, (row, col)\n\n    def _insert_explicit_zero(self, M, i, j):\n        M.data = np.r_[M.data.dtype.type(0), M.data]\n        M.row = np.r_[M.row.dtype.type(i), M.row]\n        M.col = np.r_[M.col.dtype.type(j), M.col]\n        return M\n\n    def test_setdiag_noncanonical(self):\n        m = self.spmatrix(np.eye(3))\n        m.sum_duplicates()\n        m.setdiag([3, 2], k=1)\n        m.sum_duplicates()\n        assert_(np.all(np.diff(m.col) >= 0))\n\n    @dec.knownfailureif(True, 'nnz counts explicit zeros')\n    def test_empty(self):\n        pass\n\n\nclass Test64Bit(object):\n\n    TEST_CLASSES = [TestBSR, TestCOO, TestCSC, TestCSR, TestDIA,\n                    # lil/dok->other conversion operations have get_index_dtype\n                    TestDOK, TestLIL\n                    ]\n\n    MAT_CLASSES = [bsr_matrix, coo_matrix, csc_matrix, csr_matrix, dia_matrix]\n\n    # The following features are missing, so skip the tests:\n    SKIP_TESTS = {\n        'test_expm': 'expm for 64-bit indices not available',\n        'test_solve': 'linsolve for 64-bit indices not available'\n    }\n\n    def _create_some_matrix(self, mat_cls, m, n):\n        return mat_cls(np.random.rand(m, n))\n\n    def _compare_index_dtype(self, m, dtype):\n        dtype = np.dtype(dtype)\n        if isinstance(m, csc_matrix) or isinstance(m, csr_matrix) \\\n               or isinstance(m, bsr_matrix):\n            return (m.indices.dtype == dtype) and (m.indptr.dtype == dtype)\n        elif isinstance(m, coo_matrix):\n            return (m.row.dtype == dtype) and (m.col.dtype == dtype)\n        elif isinstance(m, dia_matrix):\n            return (m.offsets.dtype == dtype)\n        else:\n            raise ValueError(\"matrix %r has no integer indices\" % (m,))\n\n    def test_decorator_maxval_limit(self):\n        # Test that the with_64bit_maxval_limit decorator works\n\n        @with_64bit_maxval_limit(maxval_limit=10)\n        def check(mat_cls):\n            m = mat_cls(np.random.rand(10, 1))\n            assert_(self._compare_index_dtype(m, np.int32))\n            m = mat_cls(np.random.rand(11, 1))\n            assert_(self._compare_index_dtype(m, np.int64))\n\n        for mat_cls in self.MAT_CLASSES:\n            yield check, mat_cls\n\n    def test_decorator_maxval_random(self):\n        # Test that the with_64bit_maxval_limit decorator works (2)\n\n        @with_64bit_maxval_limit(random=True)\n        def check(mat_cls):\n            seen_32 = False\n            seen_64 = False\n            for k in range(100):\n                m = self._create_some_matrix(mat_cls, 9, 9)\n                seen_32 = seen_32 or self._compare_index_dtype(m, np.int32)\n                seen_64 = seen_64 or self._compare_index_dtype(m, np.int64)\n                if seen_32 and seen_64:\n                    break\n            else:\n                raise AssertionError(\"both 32 and 64 bit indices not seen\")\n\n        for mat_cls in self.MAT_CLASSES:\n            yield check, mat_cls\n\n    def _check_resiliency(self, **kw):\n        # Resiliency test, to check that sparse matrices deal reasonably\n        # with varying index data types.\n\n        skip = kw.pop('skip', ())\n\n        @with_64bit_maxval_limit(**kw)\n        def check(cls, method_name):\n            instance = cls()\n            if hasattr(instance, 'setup'):\n                instance.setup()\n            try:\n                getattr(instance, method_name)()\n            finally:\n                if hasattr(instance, 'teardown'):\n                    instance.teardown()\n\n        for cls in self.TEST_CLASSES:\n            for method_name in dir(cls):\n                method = getattr(cls, method_name)\n                if (method_name.startswith('test_') and\n                        not getattr(method, 'slow', False) and\n                        (cls.__name__ + '.' + method_name) not in skip):\n                    msg = self.SKIP_TESTS.get(method_name)\n                    yield dec.skipif(msg, msg)(check), cls, method_name\n\n    def test_resiliency_limit_10(self):\n        for t in self._check_resiliency(maxval_limit=10):\n            yield t\n\n    def test_resiliency_random(self):\n        # bsr_matrix.eliminate_zeros relies on csr_matrix constructor\n        # not making copies of index arrays --- this is not\n        # necessarily true when we pick the index data type randomly\n        skip = ['TestBSR.test_eliminate_zeros']\n\n        for t in self._check_resiliency(random=True, skip=skip):\n            yield t\n\n    def test_resiliency_all_32(self):\n        for t in self._check_resiliency(fixed_dtype=np.int32):\n            yield t\n\n    def test_resiliency_all_64(self):\n        for t in self._check_resiliency(fixed_dtype=np.int64):\n            yield t\n\n    def test_no_64(self):\n        for t in self._check_resiliency(assert_32bit=True):\n            yield t\n\n    def test_downcast_intp(self):\n        # Check that bincount and ufunc.reduceat intp downcasts are\n        # dealt with. The point here is to trigger points in the code\n        # that can fail on 32-bit systems when using 64-bit indices,\n        # due to use of functions that only work with intp-size\n        # indices.\n\n        @with_64bit_maxval_limit(fixed_dtype=np.int64,\n                                 downcast_maxval=1)\n        def check_limited():\n            # These involve indices larger than `downcast_maxval`\n            a = csc_matrix([[1, 2], [3, 4], [5, 6]])\n            assert_raises(AssertionError, a.getnnz, axis=1)\n            assert_raises(AssertionError, a.sum, axis=0)\n\n            a = csr_matrix([[1, 2, 3], [3, 4, 6]])\n            assert_raises(AssertionError, a.getnnz, axis=0)\n\n            a = coo_matrix([[1, 2, 3], [3, 4, 5]])\n            assert_raises(AssertionError, a.getnnz, axis=0)\n\n        @with_64bit_maxval_limit(fixed_dtype=np.int64)\n        def check_unlimited():\n            # These involve indices larger than `downcast_maxval`\n            a = csc_matrix([[1, 2], [3, 4], [5, 6]])\n            a.getnnz(axis=1)\n            a.sum(axis=0)\n\n            a = csr_matrix([[1, 2, 3], [3, 4, 6]])\n            a.getnnz(axis=0)\n\n            a = coo_matrix([[1, 2, 3], [3, 4, 5]])\n            a.getnnz(axis=0)\n\n        check_limited()\n        check_unlimited()\n\nif __name__ == \"__main__\":\n    run_module_suite()\n"
    }
  ]
}