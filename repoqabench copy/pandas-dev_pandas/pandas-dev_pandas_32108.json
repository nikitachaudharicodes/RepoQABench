{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "32108",
  "issue_description": "# Series with NAMED period index raise error on groupby index.month (pandas 1.0 specific)\n\n*edit from @TomAugspurger*: this is fixed on master, but the example below needs to be added as a unit test. The test can probably go in `groupby/test_groupby.py`.\r\n\r\n#### Description\r\n\r\nWith the pandas 1.0.1 (full version with dependencies at the end), series with NAMED period index  raise error on groupby index.month\r\n\r\nThere is no error if the index is not named.\r\n\r\nThere was no error wit pandas 0.25.3\r\n\r\n#### Code Sample\r\n```python\r\nimport pandas as pd\r\n\r\nindex = pd.period_range(start='2018-01', periods=24, freq='M')\r\nperiodSerie = pd.Series(range(24),index=index)\r\nperiodSerie.index.name = 'Month'\r\nperiodSerie.groupby(periodSerie.index.month).sum()\r\n```\r\n\r\n#### Error\r\nIt seems to me that pandas tries to interpret the index name as if it were part of the index itself.\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_value(self, series, key)\r\n   4410             try:\r\n-> 4411                 return libindex.get_value_at(s, key)\r\n   4412             except IndexError:\r\n\r\npandas/_libs/index.pyx in pandas._libs.index.get_value_at()\r\n\r\npandas/_libs/index.pyx in pandas._libs.index.get_value_at()\r\n\r\npandas/_libs/util.pxd in pandas._libs.util.get_value_at()\r\n\r\npandas/_libs/util.pxd in pandas._libs.util.validate_indexer()\r\n\r\nTypeError: 'str' object cannot be interpreted as an integer\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nKeyError                                  Traceback (most recent call last)\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/period.py in get_value(self, series, key)\r\n    516         try:\r\n--> 517             value = super().get_value(s, key)\r\n    518         except (KeyError, IndexError):\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_value(self, series, key)\r\n   4418                 else:\r\n-> 4419                     raise e1\r\n   4420             except Exception:\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_value(self, series, key)\r\n   4404         try:\r\n-> 4405             return self._engine.get_value(s, k, tz=getattr(series.dtype, \"tz\", None))\r\n   4406         except KeyError as e1:\r\n\r\npandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_value()\r\n\r\npandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_value()\r\n\r\npandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()\r\n\r\npandas/_libs/index_class_helper.pxi in pandas._libs.index.Int64Engine._check_type()\r\n\r\nKeyError: 'Month'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\npandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_datetime_string_with_reso()\r\n\r\npandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.dateutil_parse()\r\n\r\nValueError: Unknown datetime string format, unable to parse: Month\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nDateParseError                            Traceback (most recent call last)\r\n<ipython-input-6-a3e948d22d88> in <module>\r\n      5 periodSerie = pd.Series(range(24),index=index)\r\n      6 periodSerie.index.name = 'Month'\r\n----> 7 periodSerie.groupby(periodSerie.index.month).sum()\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/series.py in groupby(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\r\n   1676         axis = self._get_axis_number(axis)\r\n   1677 \r\n-> 1678         return groupby_generic.SeriesGroupBy(\r\n   1679             obj=self,\r\n   1680             keys=by,\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/groupby/groupby.py in __init__(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\r\n    400             from pandas.core.groupby.grouper import get_grouper\r\n    401 \r\n--> 402             grouper, exclusions, obj = get_grouper(\r\n    403                 obj,\r\n    404                 keys,\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/groupby/grouper.py in get_grouper(obj, key, axis, level, sort, observed, mutated, validate)\r\n    583     for i, (gpr, level) in enumerate(zip(keys, levels)):\r\n    584 \r\n--> 585         if is_in_obj(gpr):  # df.groupby(df['name'])\r\n    586             in_axis, name = True, gpr.name\r\n    587             exclusions.append(name)\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/groupby/grouper.py in is_in_obj(gpr)\r\n    577             return False\r\n    578         try:\r\n--> 579             return gpr is obj[gpr.name]\r\n    580         except (KeyError, IndexError):\r\n    581             return False\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/series.py in __getitem__(self, key)\r\n    869         key = com.apply_if_callable(key, self)\r\n    870         try:\r\n--> 871             result = self.index.get_value(self, key)\r\n    872 \r\n    873             if not is_scalar(result):\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/period.py in get_value(self, series, key)\r\n    518         except (KeyError, IndexError):\r\n    519             if isinstance(key, str):\r\n--> 520                 asdt, parsed, reso = parse_time_string(key, self.freq)\r\n    521                 grp = resolution.Resolution.get_freq_group(reso)\r\n    522                 freqn = resolution.get_freq_group(self.freq)\r\n\r\npandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_time_string()\r\n\r\npandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_datetime_string_with_reso()\r\n\r\nDateParseError: Unknown datetime string format, unable to parse: Month\r\n```\r\n\r\n#### Expected Output\r\nWith pandas 0.25.3, the following expected output is produced :\r\n\r\n```python\r\nMonth\r\n1     12\r\n2     14\r\n3     16\r\n4     18\r\n5     20\r\n6     22\r\n7     24\r\n8     26\r\n9     28\r\n10    30\r\n11    32\r\n12    34\r\ndtype: int64\r\n```\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\npython           : 3.8.1.final.0\r\npython-bits      : 64\r\nOS               : Linux\r\nOS-release       : 5.4.18-1-MANJARO\r\nmachine          : x86_64\r\nprocessor        : \r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : fr_FR.UTF-8\r\nLOCALE           : fr_FR.UTF-8\r\n\r\npandas           : 1.0.1\r\nnumpy            : 1.18.0\r\npytz             : 2019.3\r\ndateutil         : 2.8.1\r\npip              : 20.0.2\r\nsetuptools       : 44.0.0\r\nCython           : 0.29.15\r\npytest           : None\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 2.10.3\r\nIPython          : 7.11.1\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nlxml.etree       : None\r\nmatplotlib       : 3.1.2\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : 3.0.2\r\npandas_gbq       : None\r\npyarrow          : None\r\npytables         : None\r\npytest           : None\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.4.1\r\nsqlalchemy       : None\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : 1.2.0\r\nxlwt             : None\r\nxlsxwriter       : None\r\nnumba            : None\r\n</details>\r\n",
  "issue_comments": [
    {
      "id": 588302753,
      "user": "MarcoGorelli",
      "body": "Thanks @daxid \r\n\r\nCouldn't reproduce this on master, seems it's already been fixed\r\n```\r\nIn [1]: import pandas as pd                                                                                                                                                                                      \r\n\r\nIn [2]: index = pd.period_range(start='2018-01', periods=24, freq='M') \r\n   ...: periodSerie = pd.Series(range(24),index=index) \r\n   ...: periodSerie.index.name = 'Month' \r\n   ...: periodSerie.groupby(periodSerie.index.month).sum()                                                                                                                                                       \r\nOut[2]: \r\nMonth\r\n1     12\r\n2     14\r\n3     16\r\n4     18\r\n5     20\r\n6     22\r\n7     24\r\n8     26\r\n9     28\r\n10    30\r\n11    32\r\n12    34\r\ndtype: int64\r\n```\r\n\r\n(please don't close this yet though, I still haven't checked if there is a test for this)"
    },
    {
      "id": 588335815,
      "user": "daxid",
      "body": "I can confirm it runs OK with the last code on master (pandas-1.1.0.dev0+516.gac3056f2f)\r\n\r\nI'll let it open until you check for related tests.\r\n\r\nBest regards"
    },
    {
      "id": 588442719,
      "user": "jorisvandenbossche",
      "body": "So we need to check if it also already passes on the 1.0.x branch, or if we need to find the commit on master that fixed this to backport."
    },
    {
      "id": 588475281,
      "user": "daxid",
      "body": "I installed the 1.0.x branch and the sample code fails !\r\n\r\nI guess you have to go for a cherry pick :cherries: \r\n\r\nI'll give a shot to test writing. I'll report progress here, probably within a week."
    },
    {
      "id": 588987966,
      "user": "MarcoGorelli",
      "body": "Just checking this but I think it was fixed by #31318\r\n\r\nEDIT\r\n----\r\nyup, seems to be the case - @daxid thanks, tests would be welcome!\r\n\r\n```\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ git checkout 5402ea57a6f0fe606a3de3731dcb903186b1f4c2\r\nHEAD is now at 5402ea57a REF: make PeriodIndex.get_value wrap PeriodIndex.get_loc (#31318)\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ python setup.py build_ext --inplace -j 4\r\nrunning build_ext\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ ipython\r\nPython 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.11.1 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: import pandas as pd \r\n   ...:  \r\n   ...: index = pd.period_range(start='2018-01', periods=24, freq='M') \r\n   ...: periodSerie = pd.Series(range(24),index=index) \r\n   ...: periodSerie.index.name = 'Month' \r\n   ...: periodSerie.groupby(periodSerie.index.month).sum()                                                                                                                                                       \r\nOut[1]: \r\nMonth\r\n1     12\r\n2     14\r\n3     16\r\n4     18\r\n5     20\r\n6     22\r\n7     24\r\n8     26\r\n9     28\r\n10    30\r\n11    32\r\n12    34\r\ndtype: int64\r\n\r\nIn [2]:                                                                                                                                                                                                          \r\nDo you really want to exit ([y]/n)? y\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ git log -n 2\r\ncommit 5402ea57a6f0fe606a3de3731dcb903186b1f4c2 (HEAD, refs/bisect/bad)\r\nAuthor: jbrockmendel <jbrockmendel@gmail.com>\r\nDate:   Mon Jan 27 18:22:55 2020 -0800\r\n\r\n    REF: make PeriodIndex.get_value wrap PeriodIndex.get_loc (#31318)\r\n\r\ncommit 3c763186b81ac61672f7d2e79473f1763b274a80 (refs/bisect/good-3c763186b81ac61672f7d2e79473f1763b274a80)\r\nAuthor: jbrockmendel <jbrockmendel@gmail.com>\r\nDate:   Mon Jan 27 18:22:13 2020 -0800\r\n\r\n    CLN: require extracting .values before expressions calls (#31373)\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ git checkout 3c763186b81ac61672f7d2e79473f1763b274a80\r\nPrevious HEAD position was 5402ea57a REF: make PeriodIndex.get_value wrap PeriodIndex.get_loc (#31318)\r\nHEAD is now at 3c763186b CLN: require extracting .values before expressions calls (#31373)\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ python setup.py build_ext --inplace -j 4\r\nrunning build_ext\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ ipython\r\nPython 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.11.1 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: import pandas as pd \r\n   ...:  \r\n   ...: index = pd.period_range(start='2018-01', periods=24, freq='M') \r\n   ...: periodSerie = pd.Series(range(24),index=index) \r\n   ...: periodSerie.index.name = 'Month' \r\n   ...: periodSerie.groupby(periodSerie.index.month).sum()                                                                                                                                                       \r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n~/pandas/pandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_datetime_string_with_reso()\r\n    308     try:\r\n--> 309         parsed, reso = dateutil_parse(date_string, _DEFAULT_DATETIME,\r\n    310                                       dayfirst=dayfirst, yearfirst=yearfirst,\r\n\r\n~/pandas/pandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.dateutil_parse()\r\n    481     if res is None:\r\n--> 482         raise ValueError(f\"Unknown datetime string format, unable to parse: {timestr}\")\r\n    483 \r\n\r\nValueError: Unknown datetime string format, unable to parse: Month\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nDateParseError                            Traceback (most recent call last)\r\n<ipython-input-1-28f368eeb32c> in <module>\r\n      4 periodSerie = pd.Series(range(24),index=index)\r\n      5 periodSerie.index.name = 'Month'\r\n----> 6 periodSerie.groupby(periodSerie.index.month).sum()\r\n\r\n~/pandas/pandas/core/series.py in groupby(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\r\n   1662             group_keys=group_keys,\r\n   1663             squeeze=squeeze,\r\n-> 1664             observed=observed,\r\n   1665         )\r\n   1666 \r\n\r\n~/pandas/pandas/core/groupby/groupby.py in __init__(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\r\n    407                 sort=sort,\r\n    408                 observed=observed,\r\n--> 409                 mutated=self.mutated,\r\n    410             )\r\n    411 \r\n\r\n~/pandas/pandas/core/groupby/grouper.py in get_grouper(obj, key, axis, level, sort, observed, mutated, validate)\r\n    584     for i, (gpr, level) in enumerate(zip(keys, levels)):\r\n    585 \r\n--> 586         if is_in_obj(gpr):  # df.groupby(df['name'])\r\n    587             in_axis, name = True, gpr.name\r\n    588             exclusions.append(name)\r\n\r\n~/pandas/pandas/core/groupby/grouper.py in is_in_obj(gpr)\r\n    578             return False\r\n    579         try:\r\n--> 580             return gpr is obj[gpr.name]\r\n    581         except (KeyError, IndexError):\r\n    582             return False\r\n\r\n~/pandas/pandas/core/series.py in __getitem__(self, key)\r\n    855 \r\n    856         try:\r\n--> 857             result = self.index.get_value(self, key)\r\n    858 \r\n    859             return result\r\n\r\n~/pandas/pandas/core/indexes/period.py in get_value(self, series, key)\r\n    495                 pass\r\n    496 \r\n--> 497             asdt, reso = parse_time_string(key, self.freq)\r\n    498             grp = resolution.Resolution.get_freq_group(reso)\r\n    499             freqn = resolution.get_freq_group(self.freq)\r\n\r\n~/pandas/pandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_time_string()\r\n    267             yearfirst = get_option(\"display.date_yearfirst\")\r\n    268 \r\n--> 269     res = parse_datetime_string_with_reso(arg, freq=freq,\r\n    270                                           dayfirst=dayfirst,\r\n    271                                           yearfirst=yearfirst)\r\n\r\n~/pandas/pandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_datetime_string_with_reso()\r\n    312     except (ValueError, OverflowError) as err:\r\n    313         # TODO: allow raise of errors within instead\r\n--> 314         raise DateParseError(err)\r\n    315     if parsed is None:\r\n    316         raise DateParseError(f\"Could not parse {date_string}\")\r\n\r\nDateParseError: Unknown datetime string format, unable to parse: Month\r\n```"
    },
    {
      "id": 596613343,
      "user": "TomAugspurger",
      "body": "Backporting https://github.com/pandas-dev/pandas/pull/31318 doesn't look straightforward, so this likely won't be fixed for 1.0.2 unless someone invests some time in the next day or so.\r\n\r\nI'll repurpose this issue to adding a test for the behavior on master."
    },
    {
      "id": 597018969,
      "user": "daxid",
      "body": "Thanks for feedback. \r\nI am still committed to produce tests for this but have been more busy than expected during the last couple of days. "
    },
    {
      "id": 605459768,
      "user": "sumanau7",
      "body": "take"
    },
    {
      "id": 605462184,
      "user": "sumanau7",
      "body": "@MarcoGorelli Request you to review."
    },
    {
      "id": 605488020,
      "user": "daxid",
      "body": "Too bad, my colleague and I had a test ready since Monday.\r\nHe mentioned this thread in his commit (https://github.com/Tetras-Libre/pandas/commit/74e65a8f9372b893a3d228973fdd9472de971ff3) but I forgot to make the pull request :-(\r\n\r\n@MarcoGorelli to review, test should pass on master but fail on 2.0.x branch"
    },
    {
      "id": 605492443,
      "user": "sumanau7",
      "body": "@daxid Missed it, i have closed my pull request please feel free to raise a new pull request, in case the issue is not resolved in few weeks, i will reopen my pull request."
    },
    {
      "id": 605499286,
      "user": "MarcoGorelli",
      "body": "@daxid can you make the pull request and either link to it here, or write \"closes #32108\" in its body?"
    },
    {
      "id": 605876977,
      "user": "sumanau7",
      "body": "@daxid Please run `black pandas` and update the PR."
    },
    {
      "id": 648135531,
      "user": "simonjayhawkins",
      "body": "This is also fixed on 1.0.x branch from backporting #34049 (i.e. 1.0.4)\r\n\r\nb3ebcb03287ed5c0082850b2bde8c7888ce6ac9b is the first new commit\r\ncommit b3ebcb03287ed5c0082850b2bde8c7888ce6ac9b\r\nAuthor: Simon Hawkins <simonjayhawkins@gmail.com>\r\nDate:   Tue May 19 12:39:11 2020 +0100\r\n\r\n    Backport PR #34049 on branch 1.0.x (Bug in Series.groupby would raise ValueError when grouping by PeriodIndex level) (#34247)\r\n"
    }
  ],
  "text_context": "# Series with NAMED period index raise error on groupby index.month (pandas 1.0 specific)\n\n*edit from @TomAugspurger*: this is fixed on master, but the example below needs to be added as a unit test. The test can probably go in `groupby/test_groupby.py`.\r\n\r\n#### Description\r\n\r\nWith the pandas 1.0.1 (full version with dependencies at the end), series with NAMED period index  raise error on groupby index.month\r\n\r\nThere is no error if the index is not named.\r\n\r\nThere was no error wit pandas 0.25.3\r\n\r\n#### Code Sample\r\n```python\r\nimport pandas as pd\r\n\r\nindex = pd.period_range(start='2018-01', periods=24, freq='M')\r\nperiodSerie = pd.Series(range(24),index=index)\r\nperiodSerie.index.name = 'Month'\r\nperiodSerie.groupby(periodSerie.index.month).sum()\r\n```\r\n\r\n#### Error\r\nIt seems to me that pandas tries to interpret the index name as if it were part of the index itself.\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_value(self, series, key)\r\n   4410             try:\r\n-> 4411                 return libindex.get_value_at(s, key)\r\n   4412             except IndexError:\r\n\r\npandas/_libs/index.pyx in pandas._libs.index.get_value_at()\r\n\r\npandas/_libs/index.pyx in pandas._libs.index.get_value_at()\r\n\r\npandas/_libs/util.pxd in pandas._libs.util.get_value_at()\r\n\r\npandas/_libs/util.pxd in pandas._libs.util.validate_indexer()\r\n\r\nTypeError: 'str' object cannot be interpreted as an integer\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nKeyError                                  Traceback (most recent call last)\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/period.py in get_value(self, series, key)\r\n    516         try:\r\n--> 517             value = super().get_value(s, key)\r\n    518         except (KeyError, IndexError):\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_value(self, series, key)\r\n   4418                 else:\r\n-> 4419                     raise e1\r\n   4420             except Exception:\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_value(self, series, key)\r\n   4404         try:\r\n-> 4405             return self._engine.get_value(s, k, tz=getattr(series.dtype, \"tz\", None))\r\n   4406         except KeyError as e1:\r\n\r\npandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_value()\r\n\r\npandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_value()\r\n\r\npandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()\r\n\r\npandas/_libs/index_class_helper.pxi in pandas._libs.index.Int64Engine._check_type()\r\n\r\nKeyError: 'Month'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\npandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_datetime_string_with_reso()\r\n\r\npandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.dateutil_parse()\r\n\r\nValueError: Unknown datetime string format, unable to parse: Month\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nDateParseError                            Traceback (most recent call last)\r\n<ipython-input-6-a3e948d22d88> in <module>\r\n      5 periodSerie = pd.Series(range(24),index=index)\r\n      6 periodSerie.index.name = 'Month'\r\n----> 7 periodSerie.groupby(periodSerie.index.month).sum()\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/series.py in groupby(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\r\n   1676         axis = self._get_axis_number(axis)\r\n   1677 \r\n-> 1678         return groupby_generic.SeriesGroupBy(\r\n   1679             obj=self,\r\n   1680             keys=by,\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/groupby/groupby.py in __init__(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\r\n    400             from pandas.core.groupby.grouper import get_grouper\r\n    401 \r\n--> 402             grouper, exclusions, obj = get_grouper(\r\n    403                 obj,\r\n    404                 keys,\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/groupby/grouper.py in get_grouper(obj, key, axis, level, sort, observed, mutated, validate)\r\n    583     for i, (gpr, level) in enumerate(zip(keys, levels)):\r\n    584 \r\n--> 585         if is_in_obj(gpr):  # df.groupby(df['name'])\r\n    586             in_axis, name = True, gpr.name\r\n    587             exclusions.append(name)\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/groupby/grouper.py in is_in_obj(gpr)\r\n    577             return False\r\n    578         try:\r\n--> 579             return gpr is obj[gpr.name]\r\n    580         except (KeyError, IndexError):\r\n    581             return False\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/series.py in __getitem__(self, key)\r\n    869         key = com.apply_if_callable(key, self)\r\n    870         try:\r\n--> 871             result = self.index.get_value(self, key)\r\n    872 \r\n    873             if not is_scalar(result):\r\n\r\n~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/period.py in get_value(self, series, key)\r\n    518         except (KeyError, IndexError):\r\n    519             if isinstance(key, str):\r\n--> 520                 asdt, parsed, reso = parse_time_string(key, self.freq)\r\n    521                 grp = resolution.Resolution.get_freq_group(reso)\r\n    522                 freqn = resolution.get_freq_group(self.freq)\r\n\r\npandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_time_string()\r\n\r\npandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_datetime_string_with_reso()\r\n\r\nDateParseError: Unknown datetime string format, unable to parse: Month\r\n```\r\n\r\n#### Expected Output\r\nWith pandas 0.25.3, the following expected output is produced :\r\n\r\n```python\r\nMonth\r\n1     12\r\n2     14\r\n3     16\r\n4     18\r\n5     20\r\n6     22\r\n7     24\r\n8     26\r\n9     28\r\n10    30\r\n11    32\r\n12    34\r\ndtype: int64\r\n```\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\npython           : 3.8.1.final.0\r\npython-bits      : 64\r\nOS               : Linux\r\nOS-release       : 5.4.18-1-MANJARO\r\nmachine          : x86_64\r\nprocessor        : \r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : fr_FR.UTF-8\r\nLOCALE           : fr_FR.UTF-8\r\n\r\npandas           : 1.0.1\r\nnumpy            : 1.18.0\r\npytz             : 2019.3\r\ndateutil         : 2.8.1\r\npip              : 20.0.2\r\nsetuptools       : 44.0.0\r\nCython           : 0.29.15\r\npytest           : None\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 2.10.3\r\nIPython          : 7.11.1\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nlxml.etree       : None\r\nmatplotlib       : 3.1.2\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : 3.0.2\r\npandas_gbq       : None\r\npyarrow          : None\r\npytables         : None\r\npytest           : None\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.4.1\r\nsqlalchemy       : None\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : 1.2.0\r\nxlwt             : None\r\nxlsxwriter       : None\r\nnumba            : None\r\n</details>\r\n\n\nThanks @daxid \r\n\r\nCouldn't reproduce this on master, seems it's already been fixed\r\n```\r\nIn [1]: import pandas as pd                                                                                                                                                                                      \r\n\r\nIn [2]: index = pd.period_range(start='2018-01', periods=24, freq='M') \r\n   ...: periodSerie = pd.Series(range(24),index=index) \r\n   ...: periodSerie.index.name = 'Month' \r\n   ...: periodSerie.groupby(periodSerie.index.month).sum()                                                                                                                                                       \r\nOut[2]: \r\nMonth\r\n1     12\r\n2     14\r\n3     16\r\n4     18\r\n5     20\r\n6     22\r\n7     24\r\n8     26\r\n9     28\r\n10    30\r\n11    32\r\n12    34\r\ndtype: int64\r\n```\r\n\r\n(please don't close this yet though, I still haven't checked if there is a test for this)\n\nI can confirm it runs OK with the last code on master (pandas-1.1.0.dev0+516.gac3056f2f)\r\n\r\nI'll let it open until you check for related tests.\r\n\r\nBest regards\n\nSo we need to check if it also already passes on the 1.0.x branch, or if we need to find the commit on master that fixed this to backport.\n\nI installed the 1.0.x branch and the sample code fails !\r\n\r\nI guess you have to go for a cherry pick :cherries: \r\n\r\nI'll give a shot to test writing. I'll report progress here, probably within a week.\n\nJust checking this but I think it was fixed by #31318\r\n\r\nEDIT\r\n----\r\nyup, seems to be the case - @daxid thanks, tests would be welcome!\r\n\r\n```\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ git checkout 5402ea57a6f0fe606a3de3731dcb903186b1f4c2\r\nHEAD is now at 5402ea57a REF: make PeriodIndex.get_value wrap PeriodIndex.get_loc (#31318)\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ python setup.py build_ext --inplace -j 4\r\nrunning build_ext\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ ipython\r\nPython 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.11.1 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: import pandas as pd \r\n   ...:  \r\n   ...: index = pd.period_range(start='2018-01', periods=24, freq='M') \r\n   ...: periodSerie = pd.Series(range(24),index=index) \r\n   ...: periodSerie.index.name = 'Month' \r\n   ...: periodSerie.groupby(periodSerie.index.month).sum()                                                                                                                                                       \r\nOut[1]: \r\nMonth\r\n1     12\r\n2     14\r\n3     16\r\n4     18\r\n5     20\r\n6     22\r\n7     24\r\n8     26\r\n9     28\r\n10    30\r\n11    32\r\n12    34\r\ndtype: int64\r\n\r\nIn [2]:                                                                                                                                                                                                          \r\nDo you really want to exit ([y]/n)? y\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ git log -n 2\r\ncommit 5402ea57a6f0fe606a3de3731dcb903186b1f4c2 (HEAD, refs/bisect/bad)\r\nAuthor: jbrockmendel <jbrockmendel@gmail.com>\r\nDate:   Mon Jan 27 18:22:55 2020 -0800\r\n\r\n    REF: make PeriodIndex.get_value wrap PeriodIndex.get_loc (#31318)\r\n\r\ncommit 3c763186b81ac61672f7d2e79473f1763b274a80 (refs/bisect/good-3c763186b81ac61672f7d2e79473f1763b274a80)\r\nAuthor: jbrockmendel <jbrockmendel@gmail.com>\r\nDate:   Mon Jan 27 18:22:13 2020 -0800\r\n\r\n    CLN: require extracting .values before expressions calls (#31373)\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ git checkout 3c763186b81ac61672f7d2e79473f1763b274a80\r\nPrevious HEAD position was 5402ea57a REF: make PeriodIndex.get_value wrap PeriodIndex.get_loc (#31318)\r\nHEAD is now at 3c763186b CLN: require extracting .values before expressions calls (#31373)\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ python setup.py build_ext --inplace -j 4\r\nrunning build_ext\r\n(pandas-dev) m.gorelli@ws-1808:~/pandas$ ipython\r\nPython 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.11.1 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: import pandas as pd \r\n   ...:  \r\n   ...: index = pd.period_range(start='2018-01', periods=24, freq='M') \r\n   ...: periodSerie = pd.Series(range(24),index=index) \r\n   ...: periodSerie.index.name = 'Month' \r\n   ...: periodSerie.groupby(periodSerie.index.month).sum()                                                                                                                                                       \r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n~/pandas/pandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_datetime_string_with_reso()\r\n    308     try:\r\n--> 309         parsed, reso = dateutil_parse(date_string, _DEFAULT_DATETIME,\r\n    310                                       dayfirst=dayfirst, yearfirst=yearfirst,\r\n\r\n~/pandas/pandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.dateutil_parse()\r\n    481     if res is None:\r\n--> 482         raise ValueError(f\"Unknown datetime string format, unable to parse: {timestr}\")\r\n    483 \r\n\r\nValueError: Unknown datetime string format, unable to parse: Month\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nDateParseError                            Traceback (most recent call last)\r\n<ipython-input-1-28f368eeb32c> in <module>\r\n      4 periodSerie = pd.Series(range(24),index=index)\r\n      5 periodSerie.index.name = 'Month'\r\n----> 6 periodSerie.groupby(periodSerie.index.month).sum()\r\n\r\n~/pandas/pandas/core/series.py in groupby(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\r\n   1662             group_keys=group_keys,\r\n   1663             squeeze=squeeze,\r\n-> 1664             observed=observed,\r\n   1665         )\r\n   1666 \r\n\r\n~/pandas/pandas/core/groupby/groupby.py in __init__(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\r\n    407                 sort=sort,\r\n    408                 observed=observed,\r\n--> 409                 mutated=self.mutated,\r\n    410             )\r\n    411 \r\n\r\n~/pandas/pandas/core/groupby/grouper.py in get_grouper(obj, key, axis, level, sort, observed, mutated, validate)\r\n    584     for i, (gpr, level) in enumerate(zip(keys, levels)):\r\n    585 \r\n--> 586         if is_in_obj(gpr):  # df.groupby(df['name'])\r\n    587             in_axis, name = True, gpr.name\r\n    588             exclusions.append(name)\r\n\r\n~/pandas/pandas/core/groupby/grouper.py in is_in_obj(gpr)\r\n    578             return False\r\n    579         try:\r\n--> 580             return gpr is obj[gpr.name]\r\n    581         except (KeyError, IndexError):\r\n    582             return False\r\n\r\n~/pandas/pandas/core/series.py in __getitem__(self, key)\r\n    855 \r\n    856         try:\r\n--> 857             result = self.index.get_value(self, key)\r\n    858 \r\n    859             return result\r\n\r\n~/pandas/pandas/core/indexes/period.py in get_value(self, series, key)\r\n    495                 pass\r\n    496 \r\n--> 497             asdt, reso = parse_time_string(key, self.freq)\r\n    498             grp = resolution.Resolution.get_freq_group(reso)\r\n    499             freqn = resolution.get_freq_group(self.freq)\r\n\r\n~/pandas/pandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_time_string()\r\n    267             yearfirst = get_option(\"display.date_yearfirst\")\r\n    268 \r\n--> 269     res = parse_datetime_string_with_reso(arg, freq=freq,\r\n    270                                           dayfirst=dayfirst,\r\n    271                                           yearfirst=yearfirst)\r\n\r\n~/pandas/pandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_datetime_string_with_reso()\r\n    312     except (ValueError, OverflowError) as err:\r\n    313         # TODO: allow raise of errors within instead\r\n--> 314         raise DateParseError(err)\r\n    315     if parsed is None:\r\n    316         raise DateParseError(f\"Could not parse {date_string}\")\r\n\r\nDateParseError: Unknown datetime string format, unable to parse: Month\r\n```\n\nBackporting https://github.com/pandas-dev/pandas/pull/31318 doesn't look straightforward, so this likely won't be fixed for 1.0.2 unless someone invests some time in the next day or so.\r\n\r\nI'll repurpose this issue to adding a test for the behavior on master.\n\nThanks for feedback. \r\nI am still committed to produce tests for this but have been more busy than expected during the last couple of days. \n\ntake\n\n@MarcoGorelli Request you to review.\n\nToo bad, my colleague and I had a test ready since Monday.\r\nHe mentioned this thread in his commit (https://github.com/Tetras-Libre/pandas/commit/74e65a8f9372b893a3d228973fdd9472de971ff3) but I forgot to make the pull request :-(\r\n\r\n@MarcoGorelli to review, test should pass on master but fail on 2.0.x branch\n\n@daxid Missed it, i have closed my pull request please feel free to raise a new pull request, in case the issue is not resolved in few weeks, i will reopen my pull request.\n\n@daxid can you make the pull request and either link to it here, or write \"closes #32108\" in its body?\n\n@daxid Please run `black pandas` and update the PR.\n\nThis is also fixed on 1.0.x branch from backporting #34049 (i.e. 1.0.4)\r\n\r\nb3ebcb03287ed5c0082850b2bde8c7888ce6ac9b is the first new commit\r\ncommit b3ebcb03287ed5c0082850b2bde8c7888ce6ac9b\r\nAuthor: Simon Hawkins <simonjayhawkins@gmail.com>\r\nDate:   Tue May 19 12:39:11 2020 +0100\r\n\r\n    Backport PR #34049 on branch 1.0.x (Bug in Series.groupby would raise ValueError when grouping by PeriodIndex level) (#34247)\r\n",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/31318",
  "code_context": [
    {
      "filename": "pandas/core/indexes/period.py",
      "content": "from datetime import datetime, timedelta\nfrom typing import TYPE_CHECKING, Any\nimport weakref\n\nimport numpy as np\n\nfrom pandas._libs import index as libindex\nfrom pandas._libs.tslibs import NaT, frequencies as libfrequencies, resolution\nfrom pandas._libs.tslibs.parsing import parse_time_string\nfrom pandas._libs.tslibs.period import Period\nfrom pandas.util._decorators import Appender, cache_readonly\n\nfrom pandas.core.dtypes.common import (\n    ensure_platform_int,\n    is_bool_dtype,\n    is_datetime64_any_dtype,\n    is_dtype_equal,\n    is_float,\n    is_integer,\n    is_integer_dtype,\n    is_list_like,\n    is_object_dtype,\n    is_scalar,\n    pandas_dtype,\n)\n\nfrom pandas.core.accessor import delegate_names\nfrom pandas.core.arrays.period import (\n    PeriodArray,\n    period_array,\n    raise_on_incompatible,\n    validate_dtype_freq,\n)\nimport pandas.core.common as com\nimport pandas.core.indexes.base as ibase\nfrom pandas.core.indexes.base import (\n    InvalidIndexError,\n    _index_shared_docs,\n    ensure_index,\n    maybe_extract_name,\n)\nfrom pandas.core.indexes.datetimelike import (\n    DatetimeIndexOpsMixin,\n    DatetimelikeDelegateMixin,\n)\nfrom pandas.core.indexes.datetimes import DatetimeIndex, Index\nfrom pandas.core.indexes.numeric import Int64Index\nfrom pandas.core.ops import get_op_result_name\nfrom pandas.core.tools.datetimes import DateParseError\n\nfrom pandas.tseries import frequencies\nfrom pandas.tseries.offsets import DateOffset, Tick\n\n_index_doc_kwargs = dict(ibase._index_doc_kwargs)\n_index_doc_kwargs.update(dict(target_klass=\"PeriodIndex or list of Periods\"))\n\nif TYPE_CHECKING:\n    from pandas import Series\n\n# --- Period index sketch\n\n\ndef _new_PeriodIndex(cls, **d):\n    # GH13277 for unpickling\n    values = d.pop(\"data\")\n    if values.dtype == \"int64\":\n        freq = d.pop(\"freq\", None)\n        values = PeriodArray(values, freq=freq)\n        return cls._simple_new(values, **d)\n    else:\n        return cls(values, **d)\n\n\nclass PeriodDelegateMixin(DatetimelikeDelegateMixin):\n    \"\"\"\n    Delegate from PeriodIndex to PeriodArray.\n    \"\"\"\n\n    _raw_methods = {\"_format_native_types\"}\n    _raw_properties = {\"is_leap_year\", \"freq\"}\n\n    _delegated_properties = PeriodArray._datetimelike_ops + list(_raw_properties)\n    _delegated_methods = set(PeriodArray._datetimelike_methods) | _raw_methods\n\n\n@delegate_names(PeriodArray, PeriodDelegateMixin._delegated_properties, typ=\"property\")\n@delegate_names(\n    PeriodArray, PeriodDelegateMixin._delegated_methods, typ=\"method\", overwrite=True\n)\nclass PeriodIndex(DatetimeIndexOpsMixin, Int64Index, PeriodDelegateMixin):\n    \"\"\"\n    Immutable ndarray holding ordinal values indicating regular periods in time.\n\n    Index keys are boxed to Period objects which carries the metadata (eg,\n    frequency information).\n\n    Parameters\n    ----------\n    data : array-like (1d int np.ndarray or PeriodArray), optional\n        Optional period-like data to construct index with.\n    copy : bool\n        Make a copy of input ndarray.\n    freq : str or period object, optional\n        One of pandas period strings or corresponding objects\n    year : int, array, or Series, default None\n    month : int, array, or Series, default None\n    quarter : int, array, or Series, default None\n    day : int, array, or Series, default None\n    hour : int, array, or Series, default None\n    minute : int, array, or Series, default None\n    second : int, array, or Series, default None\n    tz : object, default None\n        Timezone for converting datetime64 data to Periods.\n    dtype : str or PeriodDtype, default None\n\n    Attributes\n    ----------\n    day\n    dayofweek\n    dayofyear\n    days_in_month\n    daysinmonth\n    end_time\n    freq\n    freqstr\n    hour\n    is_leap_year\n    minute\n    month\n    quarter\n    qyear\n    second\n    start_time\n    week\n    weekday\n    weekofyear\n    year\n\n    Methods\n    -------\n    asfreq\n    strftime\n    to_timestamp\n\n    See Also\n    --------\n    Index : The base pandas Index type.\n    Period : Represents a period of time.\n    DatetimeIndex : Index with datetime64 data.\n    TimedeltaIndex : Index of timedelta64 data.\n    period_range : Create a fixed-frequency PeriodIndex.\n\n    Examples\n    --------\n    >>> idx = pd.PeriodIndex(year=year_arr, quarter=q_arr)\n    \"\"\"\n\n    _typ = \"periodindex\"\n    _attributes = [\"name\", \"freq\"]\n\n    # define my properties & methods for delegation\n    _is_numeric_dtype = False\n    _infer_as_myclass = True\n\n    _data: PeriodArray\n\n    _engine_type = libindex.PeriodEngine\n    _supports_partial_string_indexing = True\n\n    # ------------------------------------------------------------------------\n    # Index Constructors\n\n    def __new__(\n        cls,\n        data=None,\n        ordinal=None,\n        freq=None,\n        tz=None,\n        dtype=None,\n        copy=False,\n        name=None,\n        **fields,\n    ):\n\n        valid_field_set = {\n            \"year\",\n            \"month\",\n            \"day\",\n            \"quarter\",\n            \"hour\",\n            \"minute\",\n            \"second\",\n        }\n\n        if not set(fields).issubset(valid_field_set):\n            argument = list(set(fields) - valid_field_set)[0]\n            raise TypeError(f\"__new__() got an unexpected keyword argument {argument}\")\n\n        name = maybe_extract_name(name, data, cls)\n\n        if data is None and ordinal is None:\n            # range-based.\n            data, freq2 = PeriodArray._generate_range(None, None, None, freq, fields)\n            # PeriodArray._generate range does validation that fields is\n            # empty when really using the range-based constructor.\n            freq = freq2\n\n            data = PeriodArray(data, freq=freq)\n        else:\n            freq = validate_dtype_freq(dtype, freq)\n\n            # PeriodIndex allow PeriodIndex(period_index, freq=different)\n            # Let's not encourage that kind of behavior in PeriodArray.\n\n            if freq and isinstance(data, cls) and data.freq != freq:\n                # TODO: We can do some of these with no-copy / coercion?\n                # e.g. D -> 2D seems to be OK\n                data = data.asfreq(freq)\n\n            if data is None and ordinal is not None:\n                # we strangely ignore `ordinal` if data is passed.\n                ordinal = np.asarray(ordinal, dtype=np.int64)\n                data = PeriodArray(ordinal, freq)\n            else:\n                # don't pass copy here, since we copy later.\n                data = period_array(data=data, freq=freq)\n\n        if copy:\n            data = data.copy()\n\n        return cls._simple_new(data, name=name)\n\n    @classmethod\n    def _simple_new(cls, values, name=None, freq=None, **kwargs):\n        \"\"\"\n        Create a new PeriodIndex.\n\n        Parameters\n        ----------\n        values : PeriodArray\n            Values that can be converted to a PeriodArray without inference\n            or coercion.\n        \"\"\"\n        assert isinstance(values, PeriodArray), type(values)\n        assert freq is None or freq == values.freq, (freq, values.freq)\n\n        result = object.__new__(cls)\n        result._data = values\n        # For groupby perf. See note in indexes/base about _index_data\n        result._index_data = values._data\n        result.name = name\n        result._reset_identity()\n        return result\n\n    # ------------------------------------------------------------------------\n    # Data\n\n    @property\n    def values(self):\n        return np.asarray(self)\n\n    def _shallow_copy(self, values=None, **kwargs):\n        # TODO: simplify, figure out type of values\n        if values is None:\n            values = self._data\n\n        if isinstance(values, type(self)):\n            values = values._data\n\n        if not isinstance(values, PeriodArray):\n            if isinstance(values, np.ndarray) and values.dtype == \"i8\":\n                values = PeriodArray(values, freq=self.freq)\n            else:\n                # GH#30713 this should never be reached\n                raise TypeError(type(values), getattr(values, \"dtype\", None))\n\n        # We don't allow changing `freq` in _shallow_copy.\n        validate_dtype_freq(self.dtype, kwargs.get(\"freq\"))\n        attributes = self._get_attributes_dict()\n\n        attributes.update(kwargs)\n        if not len(values) and \"dtype\" not in kwargs:\n            attributes[\"dtype\"] = self.dtype\n        return self._simple_new(values, **attributes)\n\n    def _shallow_copy_with_infer(self, values=None, **kwargs):\n        \"\"\" we always want to return a PeriodIndex \"\"\"\n        return self._shallow_copy(values=values, **kwargs)\n\n    @property\n    def _box_func(self):\n        \"\"\"Maybe box an ordinal or Period\"\"\"\n        # TODO(DatetimeArray): Avoid double-boxing\n        # PeriodArray takes care of boxing already, so we need to check\n        # whether we're given an ordinal or a Period. It seems like some\n        # places outside of indexes/period.py are calling this _box_func,\n        # but passing data that's already boxed.\n        def func(x):\n            if isinstance(x, Period) or x is NaT:\n                return x\n            else:\n                return Period._from_ordinal(ordinal=x, freq=self.freq)\n\n        return func\n\n    def _maybe_convert_timedelta(self, other):\n        \"\"\"\n        Convert timedelta-like input to an integer multiple of self.freq\n\n        Parameters\n        ----------\n        other : timedelta, np.timedelta64, DateOffset, int, np.ndarray\n\n        Returns\n        -------\n        converted : int, np.ndarray[int64]\n\n        Raises\n        ------\n        IncompatibleFrequency : if the input cannot be written as a multiple\n            of self.freq.  Note IncompatibleFrequency subclasses ValueError.\n        \"\"\"\n        if isinstance(other, (timedelta, np.timedelta64, Tick, np.ndarray)):\n            offset = frequencies.to_offset(self.freq.rule_code)\n            if isinstance(offset, Tick):\n                # _check_timedeltalike_freq_compat will raise if incompatible\n                delta = self._data._check_timedeltalike_freq_compat(other)\n                return delta\n        elif isinstance(other, DateOffset):\n            freqstr = other.rule_code\n            base = libfrequencies.get_base_alias(freqstr)\n            if base == self.freq.rule_code:\n                return other.n\n\n            raise raise_on_incompatible(self, other)\n        elif is_integer(other):\n            # integer is passed to .shift via\n            # _add_datetimelike_methods basically\n            # but ufunc may pass integer to _add_delta\n            return other\n\n        # raise when input doesn't have freq\n        raise raise_on_incompatible(self, None)\n\n    # ------------------------------------------------------------------------\n    # Rendering Methods\n\n    def _mpl_repr(self):\n        # how to represent ourselves to matplotlib\n        return self.astype(object).values\n\n    @property\n    def _formatter_func(self):\n        return self.array._formatter(boxed=False)\n\n    # ------------------------------------------------------------------------\n    # Indexing\n\n    @cache_readonly\n    def _engine(self):\n        # To avoid a reference cycle, pass a weakref of self to _engine_type.\n        period = weakref.ref(self)\n        return self._engine_type(period, len(self))\n\n    @Appender(_index_shared_docs[\"contains\"])\n    def __contains__(self, key: Any) -> bool:\n        if isinstance(key, Period):\n            if key.freq != self.freq:\n                return False\n            else:\n                return key.ordinal in self._engine\n        else:\n            hash(key)\n            try:\n                self.get_loc(key)\n                return True\n            except KeyError:\n                return False\n\n    @cache_readonly\n    def _int64index(self):\n        return Int64Index._simple_new(self.asi8, name=self.name)\n\n    # ------------------------------------------------------------------------\n    # Index Methods\n\n    def __array__(self, dtype=None) -> np.ndarray:\n        if is_integer_dtype(dtype):\n            return self.asi8\n        else:\n            return self.astype(object).values\n\n    def __array_wrap__(self, result, context=None):\n        \"\"\"\n        Gets called after a ufunc. Needs additional handling as\n        PeriodIndex stores internal data as int dtype\n\n        Replace this to __numpy_ufunc__ in future version\n        \"\"\"\n        if isinstance(context, tuple) and len(context) > 0:\n            func = context[0]\n            if func is np.add:\n                pass\n            elif func is np.subtract:\n                name = self.name\n                left = context[1][0]\n                right = context[1][1]\n                if isinstance(left, PeriodIndex) and isinstance(right, PeriodIndex):\n                    name = left.name if left.name == right.name else None\n                    return Index(result, name=name)\n                elif isinstance(left, Period) or isinstance(right, Period):\n                    return Index(result, name=name)\n            elif isinstance(func, np.ufunc):\n                if \"M->M\" not in func.types:\n                    msg = f\"ufunc '{func.__name__}' not supported for the PeriodIndex\"\n                    # This should be TypeError, but TypeError cannot be raised\n                    # from here because numpy catches.\n                    raise ValueError(msg)\n\n        if is_bool_dtype(result):\n            return result\n        # the result is object dtype array of Period\n        # cannot pass _simple_new as it is\n        return type(self)(result, freq=self.freq, name=self.name)\n\n    def asof_locs(self, where, mask):\n        \"\"\"\n        where : array of timestamps\n        mask : array of booleans where data is not NA\n\n        \"\"\"\n        where_idx = where\n        if isinstance(where_idx, DatetimeIndex):\n            where_idx = PeriodIndex(where_idx.values, freq=self.freq)\n\n        locs = self._ndarray_values[mask].searchsorted(\n            where_idx._ndarray_values, side=\"right\"\n        )\n\n        locs = np.where(locs > 0, locs - 1, 0)\n        result = np.arange(len(self))[mask].take(locs)\n\n        first = mask.argmax()\n        result[\n            (locs == 0) & (where_idx._ndarray_values < self._ndarray_values[first])\n        ] = -1\n\n        return result\n\n    @Appender(_index_shared_docs[\"astype\"])\n    def astype(self, dtype, copy=True, how=\"start\"):\n        dtype = pandas_dtype(dtype)\n\n        if is_datetime64_any_dtype(dtype):\n            # 'how' is index-specific, isn't part of the EA interface.\n            tz = getattr(dtype, \"tz\", None)\n            return self.to_timestamp(how=how).tz_localize(tz)\n\n        # TODO: should probably raise on `how` here, so we don't ignore it.\n        return super().astype(dtype, copy=copy)\n\n    @property\n    def is_full(self) -> bool:\n        \"\"\"\n        Returns True if this PeriodIndex is range-like in that all Periods\n        between start and end are present, in order.\n        \"\"\"\n        if len(self) == 0:\n            return True\n        if not self.is_monotonic:\n            raise ValueError(\"Index is not monotonic\")\n        values = self.asi8\n        return ((values[1:] - values[:-1]) < 2).all()\n\n    @property\n    def inferred_type(self) -> str:\n        # b/c data is represented as ints make sure we can't have ambiguous\n        # indexing\n        return \"period\"\n\n    def get_value(self, series: \"Series\", key):\n        \"\"\"\n        Fast lookup of value from 1-dimensional ndarray. Only use this if you\n        know what you're doing\n        \"\"\"\n        if is_integer(key):\n            loc = key\n        else:\n            loc = self.get_loc(key)\n        return self._get_values_for_loc(series, loc)\n\n    @Appender(_index_shared_docs[\"get_indexer\"] % _index_doc_kwargs)\n    def get_indexer(self, target, method=None, limit=None, tolerance=None):\n        target = ensure_index(target)\n\n        if isinstance(target, PeriodIndex):\n            if target.freq != self.freq:\n                # No matches\n                no_matches = -1 * np.ones(self.shape, dtype=np.intp)\n                return no_matches\n\n            target = target.asi8\n            self_index = self._int64index\n        else:\n            self_index = self\n\n        if tolerance is not None:\n            tolerance = self._convert_tolerance(tolerance, target)\n        return Index.get_indexer(self_index, target, method, limit, tolerance)\n\n    @Appender(_index_shared_docs[\"get_indexer_non_unique\"] % _index_doc_kwargs)\n    def get_indexer_non_unique(self, target):\n        target = ensure_index(target)\n\n        if isinstance(target, PeriodIndex):\n            if target.freq != self.freq:\n                no_matches = -1 * np.ones(self.shape, dtype=np.intp)\n                return no_matches, no_matches\n\n            target = target.asi8\n\n        indexer, missing = self._int64index.get_indexer_non_unique(target)\n        return ensure_platform_int(indexer), missing\n\n    def get_loc(self, key, method=None, tolerance=None):\n        \"\"\"\n        Get integer location for requested label.\n\n        Parameters\n        ----------\n        key : Period, NaT, str, or datetime\n            String or datetime key must be parseable as Period.\n\n        Returns\n        -------\n        loc : int or ndarray[int64]\n\n        Raises\n        ------\n        KeyError\n            Key is not present in the index.\n        TypeError\n            If key is listlike or otherwise not hashable.\n        \"\"\"\n\n        if not is_scalar(key):\n            raise InvalidIndexError(key)\n\n        if isinstance(key, str):\n\n            try:\n                loc = self._get_string_slice(key)\n                return loc\n            except (TypeError, ValueError):\n                pass\n\n            try:\n                asdt, reso = parse_time_string(key, self.freq)\n            except DateParseError:\n                # A string with invalid format\n                raise KeyError(f\"Cannot interpret '{key}' as period\")\n\n            grp = resolution.Resolution.get_freq_group(reso)\n            freqn = resolution.get_freq_group(self.freq)\n\n            # _get_string_slice will handle cases where grp < freqn\n            assert grp >= freqn\n\n            if grp == freqn:\n                key = Period(asdt, freq=self.freq)\n                loc = self.get_loc(key, method=method, tolerance=tolerance)\n                return loc\n            elif method is None:\n                raise KeyError(key)\n            else:\n                key = asdt\n\n        elif is_integer(key):\n            # Period constructor will cast to string, which we dont want\n            raise KeyError(key)\n\n        try:\n            key = Period(key, freq=self.freq)\n        except ValueError:\n            # we cannot construct the Period\n            # as we have an invalid type\n            if is_list_like(key):\n                raise TypeError(f\"'{key}' is an invalid key\")\n            raise KeyError(key)\n\n        ordinal = key.ordinal if key is not NaT else key.value\n        try:\n            return self._engine.get_loc(ordinal)\n        except KeyError:\n\n            try:\n                if tolerance is not None:\n                    tolerance = self._convert_tolerance(tolerance, np.asarray(key))\n                return self._int64index.get_loc(ordinal, method, tolerance)\n\n            except KeyError:\n                raise KeyError(key)\n\n    def _maybe_cast_slice_bound(self, label, side, kind):\n        \"\"\"\n        If label is a string or a datetime, cast it to Period.ordinal according\n        to resolution.\n\n        Parameters\n        ----------\n        label : object\n        side : {'left', 'right'}\n        kind : {'loc', 'getitem'}\n\n        Returns\n        -------\n        bound : Period or object\n\n        Notes\n        -----\n        Value of `side` parameter should be validated in caller.\n\n        \"\"\"\n        assert kind in [\"loc\", \"getitem\"]\n\n        if isinstance(label, datetime):\n            return Period(label, freq=self.freq)\n        elif isinstance(label, str):\n            try:\n                parsed, reso = parse_time_string(label, self.freq)\n                bounds = self._parsed_string_to_bounds(reso, parsed)\n                return bounds[0 if side == \"left\" else 1]\n            except ValueError:\n                # string cannot be parsed as datetime-like\n                # TODO: we need tests for this case\n                raise KeyError(label)\n        elif is_integer(label) or is_float(label):\n            self._invalid_indexer(\"slice\", label)\n\n        return label\n\n    def _parsed_string_to_bounds(self, reso: str, parsed: datetime):\n        if reso not in [\"year\", \"month\", \"quarter\", \"day\", \"hour\", \"minute\", \"second\"]:\n            raise KeyError(reso)\n\n        grp = resolution.Resolution.get_freq_group(reso)\n        iv = Period(parsed, freq=(grp, 1))\n        return (iv.asfreq(self.freq, how=\"start\"), iv.asfreq(self.freq, how=\"end\"))\n\n    def _get_string_slice(self, key: str, use_lhs: bool = True, use_rhs: bool = True):\n        # TODO: Check for non-True use_lhs/use_rhs\n        parsed, reso = parse_time_string(key, self.freq)\n        grp = resolution.Resolution.get_freq_group(reso)\n        freqn = resolution.get_freq_group(self.freq)\n\n        if not grp < freqn:\n            # TODO: we used to also check for\n            #  reso in [\"day\", \"hour\", \"minute\", \"second\"]\n            #  why is that check not needed?\n            raise ValueError(key)\n\n        t1, t2 = self._parsed_string_to_bounds(reso, parsed)\n        i8vals = self.asi8\n\n        if self.is_monotonic:\n\n            # we are out of range\n            if len(self) and (\n                (use_lhs and t1 < self[0] and t2 < self[0])\n                or ((use_rhs and t1 > self[-1] and t2 > self[-1]))\n            ):\n                raise KeyError(key)\n\n            # TODO: does this depend on being monotonic _increasing_?\n            #  If so, DTI will also be affected.\n\n            # a monotonic (sorted) series can be sliced\n            # Use asi8.searchsorted to avoid re-validating Periods\n            left = i8vals.searchsorted(t1.ordinal, side=\"left\") if use_lhs else None\n            right = i8vals.searchsorted(t2.ordinal, side=\"right\") if use_rhs else None\n            return slice(left, right)\n\n        else:\n            lhs_mask = (i8vals >= t1.ordinal) if use_lhs else True\n            rhs_mask = (i8vals <= t2.ordinal) if use_rhs else True\n\n            # try to find a the dates\n            return (lhs_mask & rhs_mask).nonzero()[0]\n\n    def _convert_tolerance(self, tolerance, target):\n        tolerance = DatetimeIndexOpsMixin._convert_tolerance(self, tolerance, target)\n        if target.size != tolerance.size and tolerance.size > 1:\n            raise ValueError(\"list-like tolerance size must match target index size\")\n        return self._maybe_convert_timedelta(tolerance)\n\n    def insert(self, loc, item):\n        if not isinstance(item, Period) or self.freq != item.freq:\n            return self.astype(object).insert(loc, item)\n\n        idx = np.concatenate(\n            (self[:loc].asi8, np.array([item.ordinal]), self[loc:].asi8)\n        )\n        return self._shallow_copy(idx)\n\n    def join(self, other, how=\"left\", level=None, return_indexers=False, sort=False):\n        \"\"\"\n        See Index.join\n        \"\"\"\n        self._assert_can_do_setop(other)\n\n        if not isinstance(other, PeriodIndex):\n            return self.astype(object).join(\n                other, how=how, level=level, return_indexers=return_indexers, sort=sort\n            )\n\n        result = Int64Index.join(\n            self,\n            other,\n            how=how,\n            level=level,\n            return_indexers=return_indexers,\n            sort=sort,\n        )\n\n        if return_indexers:\n            result, lidx, ridx = result\n            return self._apply_meta(result), lidx, ridx\n        return self._apply_meta(result)\n\n    # ------------------------------------------------------------------------\n    # Set Operation Methods\n\n    def _assert_can_do_setop(self, other):\n        super()._assert_can_do_setop(other)\n\n        # *Can't* use PeriodIndexes of different freqs\n        # *Can* use PeriodIndex/DatetimeIndex\n        if isinstance(other, PeriodIndex) and self.freq != other.freq:\n            raise raise_on_incompatible(self, other)\n\n    def intersection(self, other, sort=False):\n        self._validate_sort_keyword(sort)\n        self._assert_can_do_setop(other)\n        res_name = get_op_result_name(self, other)\n        other = ensure_index(other)\n\n        if self.equals(other):\n            return self._get_reconciled_name_object(other)\n\n        if not is_dtype_equal(self.dtype, other.dtype):\n            # TODO: fastpath for if we have a different PeriodDtype\n            this = self.astype(\"O\")\n            other = other.astype(\"O\")\n            return this.intersection(other, sort=sort)\n\n        i8self = Int64Index._simple_new(self.asi8)\n        i8other = Int64Index._simple_new(other.asi8)\n        i8result = i8self.intersection(i8other, sort=sort)\n\n        result = self._shallow_copy(np.asarray(i8result, dtype=np.int64), name=res_name)\n        return result\n\n    def difference(self, other, sort=None):\n        self._validate_sort_keyword(sort)\n        self._assert_can_do_setop(other)\n        res_name = get_op_result_name(self, other)\n        other = ensure_index(other)\n\n        if self.equals(other):\n            # pass an empty PeriodArray with the appropriate dtype\n            return self._shallow_copy(self._data[:0])\n\n        if is_object_dtype(other):\n            return self.astype(object).difference(other).astype(self.dtype)\n\n        elif not is_dtype_equal(self.dtype, other.dtype):\n            return self\n\n        i8self = Int64Index._simple_new(self.asi8)\n        i8other = Int64Index._simple_new(other.asi8)\n        i8result = i8self.difference(i8other, sort=sort)\n\n        result = self._shallow_copy(np.asarray(i8result, dtype=np.int64), name=res_name)\n        return result\n\n    def _union(self, other, sort):\n        if not len(other) or self.equals(other) or not len(self):\n            return super()._union(other, sort=sort)\n\n        # We are called by `union`, which is responsible for this validation\n        assert isinstance(other, type(self))\n\n        if not is_dtype_equal(self.dtype, other.dtype):\n            this = self.astype(\"O\")\n            other = other.astype(\"O\")\n            return this._union(other, sort=sort)\n\n        i8self = Int64Index._simple_new(self.asi8)\n        i8other = Int64Index._simple_new(other.asi8)\n        i8result = i8self._union(i8other, sort=sort)\n\n        res_name = get_op_result_name(self, other)\n        result = self._shallow_copy(np.asarray(i8result, dtype=np.int64), name=res_name)\n        return result\n\n    # ------------------------------------------------------------------------\n\n    def _apply_meta(self, rawarr):\n        if not isinstance(rawarr, PeriodIndex):\n            if not isinstance(rawarr, PeriodArray):\n                rawarr = PeriodArray(rawarr, freq=self.freq)\n            rawarr = PeriodIndex._simple_new(rawarr, name=self.name)\n        return rawarr\n\n    def memory_usage(self, deep=False):\n        result = super().memory_usage(deep=deep)\n        if hasattr(self, \"_cache\") and \"_int64index\" in self._cache:\n            result += self._int64index.memory_usage(deep=deep)\n        return result\n\n\nPeriodIndex._add_numeric_methods_disabled()\nPeriodIndex._add_logical_methods_disabled()\n\n\ndef period_range(\n    start=None, end=None, periods=None, freq=None, name=None\n) -> PeriodIndex:\n    \"\"\"\n    Return a fixed frequency PeriodIndex.\n\n    The day (calendar) is the default frequency.\n\n    Parameters\n    ----------\n    start : str or period-like, default None\n        Left bound for generating periods.\n    end : str or period-like, default None\n        Right bound for generating periods.\n    periods : int, default None\n        Number of periods to generate.\n    freq : str or DateOffset, optional\n        Frequency alias. By default the freq is taken from `start` or `end`\n        if those are Period objects. Otherwise, the default is ``\"D\"`` for\n        daily frequency.\n    name : str, default None\n        Name of the resulting PeriodIndex.\n\n    Returns\n    -------\n    PeriodIndex\n\n    Notes\n    -----\n    Of the three parameters: ``start``, ``end``, and ``periods``, exactly two\n    must be specified.\n\n    To learn more about the frequency strings, please see `this link\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n\n    Examples\n    --------\n\n    >>> pd.period_range(start='2017-01-01', end='2018-01-01', freq='M')\n    PeriodIndex(['2017-01', '2017-02', '2017-03', '2017-04', '2017-05',\n                 '2017-06', '2017-06', '2017-07', '2017-08', '2017-09',\n                 '2017-10', '2017-11', '2017-12', '2018-01'],\n                dtype='period[M]', freq='M')\n\n    If ``start`` or ``end`` are ``Period`` objects, they will be used as anchor\n    endpoints for a ``PeriodIndex`` with frequency matching that of the\n    ``period_range`` constructor.\n\n    >>> pd.period_range(start=pd.Period('2017Q1', freq='Q'),\n    ...                 end=pd.Period('2017Q2', freq='Q'), freq='M')\n    PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'],\n                dtype='period[M]', freq='M')\n    \"\"\"\n    if com.count_not_none(start, end, periods) != 2:\n        raise ValueError(\n            \"Of the three parameters: start, end, and periods, \"\n            \"exactly two must be specified\"\n        )\n    if freq is None and (not isinstance(start, Period) and not isinstance(end, Period)):\n        freq = \"D\"\n\n    data, freq = PeriodArray._generate_range(start, end, periods, freq, fields={})\n    data = PeriodArray(data, freq=freq)\n    return PeriodIndex(data, name=name)\n"
    },
    {
      "filename": "pandas/tests/indexes/period/test_indexing.py",
      "content": "from datetime import datetime, timedelta\nimport re\n\nimport numpy as np\nimport pytest\n\nfrom pandas._libs.tslibs import period as libperiod\n\nimport pandas as pd\nfrom pandas import DatetimeIndex, Period, PeriodIndex, Series, notna, period_range\nimport pandas._testing as tm\nfrom pandas.core.indexes.base import InvalidIndexError\n\n\nclass TestGetItem:\n    def test_ellipsis(self):\n        # GH#21282\n        idx = period_range(\"2011-01-01\", \"2011-01-31\", freq=\"D\", name=\"idx\")\n\n        result = idx[...]\n        assert result.equals(idx)\n        assert result is not idx\n\n    def test_getitem(self):\n        idx1 = pd.period_range(\"2011-01-01\", \"2011-01-31\", freq=\"D\", name=\"idx\")\n\n        for idx in [idx1]:\n            result = idx[0]\n            assert result == pd.Period(\"2011-01-01\", freq=\"D\")\n\n            result = idx[-1]\n            assert result == pd.Period(\"2011-01-31\", freq=\"D\")\n\n            result = idx[0:5]\n            expected = pd.period_range(\"2011-01-01\", \"2011-01-05\", freq=\"D\", name=\"idx\")\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx[0:10:2]\n            expected = pd.PeriodIndex(\n                [\"2011-01-01\", \"2011-01-03\", \"2011-01-05\", \"2011-01-07\", \"2011-01-09\"],\n                freq=\"D\",\n                name=\"idx\",\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx[-20:-5:3]\n            expected = pd.PeriodIndex(\n                [\"2011-01-12\", \"2011-01-15\", \"2011-01-18\", \"2011-01-21\", \"2011-01-24\"],\n                freq=\"D\",\n                name=\"idx\",\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx[4::-1]\n            expected = PeriodIndex(\n                [\"2011-01-05\", \"2011-01-04\", \"2011-01-03\", \"2011-01-02\", \"2011-01-01\"],\n                freq=\"D\",\n                name=\"idx\",\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n    def test_getitem_index(self):\n        idx = period_range(\"2007-01\", periods=10, freq=\"M\", name=\"x\")\n\n        result = idx[[1, 3, 5]]\n        exp = pd.PeriodIndex([\"2007-02\", \"2007-04\", \"2007-06\"], freq=\"M\", name=\"x\")\n        tm.assert_index_equal(result, exp)\n\n        result = idx[[True, True, False, False, False, True, True, False, False, False]]\n        exp = pd.PeriodIndex(\n            [\"2007-01\", \"2007-02\", \"2007-06\", \"2007-07\"], freq=\"M\", name=\"x\"\n        )\n        tm.assert_index_equal(result, exp)\n\n    def test_getitem_partial(self):\n        rng = period_range(\"2007-01\", periods=50, freq=\"M\")\n        ts = Series(np.random.randn(len(rng)), rng)\n\n        with pytest.raises(KeyError, match=r\"^'2006'$\"):\n            ts[\"2006\"]\n\n        result = ts[\"2008\"]\n        assert (result.index.year == 2008).all()\n\n        result = ts[\"2008\":\"2009\"]\n        assert len(result) == 24\n\n        result = ts[\"2008-1\":\"2009-12\"]\n        assert len(result) == 24\n\n        result = ts[\"2008Q1\":\"2009Q4\"]\n        assert len(result) == 24\n\n        result = ts[:\"2009\"]\n        assert len(result) == 36\n\n        result = ts[\"2009\":]\n        assert len(result) == 50 - 24\n\n        exp = result\n        result = ts[24:]\n        tm.assert_series_equal(exp, result)\n\n        ts = ts[10:].append(ts[10:])\n        msg = \"left slice bound for non-unique label: '2008'\"\n        with pytest.raises(KeyError, match=msg):\n            ts[slice(\"2008\", \"2009\")]\n\n    def test_getitem_datetime(self):\n        rng = period_range(start=\"2012-01-01\", periods=10, freq=\"W-MON\")\n        ts = Series(range(len(rng)), index=rng)\n\n        dt1 = datetime(2011, 10, 2)\n        dt4 = datetime(2012, 4, 20)\n\n        rs = ts[dt1:dt4]\n        tm.assert_series_equal(rs, ts)\n\n    def test_getitem_nat(self):\n        idx = pd.PeriodIndex([\"2011-01\", \"NaT\", \"2011-02\"], freq=\"M\")\n        assert idx[0] == pd.Period(\"2011-01\", freq=\"M\")\n        assert idx[1] is pd.NaT\n\n        s = pd.Series([0, 1, 2], index=idx)\n        assert s[pd.NaT] == 1\n\n        s = pd.Series(idx, index=idx)\n        assert s[pd.Period(\"2011-01\", freq=\"M\")] == pd.Period(\"2011-01\", freq=\"M\")\n        assert s[pd.NaT] is pd.NaT\n\n    def test_getitem_list_periods(self):\n        # GH 7710\n        rng = period_range(start=\"2012-01-01\", periods=10, freq=\"D\")\n        ts = Series(range(len(rng)), index=rng)\n        exp = ts.iloc[[1]]\n        tm.assert_series_equal(ts[[Period(\"2012-01-02\", freq=\"D\")]], exp)\n\n    def test_getitem_seconds(self):\n        # GH#6716\n        didx = pd.date_range(start=\"2013/01/01 09:00:00\", freq=\"S\", periods=4000)\n        pidx = period_range(start=\"2013/01/01 09:00:00\", freq=\"S\", periods=4000)\n\n        for idx in [didx, pidx]:\n            # getitem against index should raise ValueError\n            values = [\n                \"2014\",\n                \"2013/02\",\n                \"2013/01/02\",\n                \"2013/02/01 9H\",\n                \"2013/02/01 09:00\",\n            ]\n            for v in values:\n                # GH7116\n                # these show deprecations as we are trying\n                # to slice with non-integer indexers\n                # with pytest.raises(IndexError):\n                #    idx[v]\n                continue\n\n            s = Series(np.random.rand(len(idx)), index=idx)\n            tm.assert_series_equal(s[\"2013/01/01 10:00\"], s[3600:3660])\n            tm.assert_series_equal(s[\"2013/01/01 9H\"], s[:3600])\n            for d in [\"2013/01/01\", \"2013/01\", \"2013\"]:\n                tm.assert_series_equal(s[d], s)\n\n    def test_getitem_day(self):\n        # GH#6716\n        # Confirm DatetimeIndex and PeriodIndex works identically\n        didx = pd.date_range(start=\"2013/01/01\", freq=\"D\", periods=400)\n        pidx = period_range(start=\"2013/01/01\", freq=\"D\", periods=400)\n\n        for idx in [didx, pidx]:\n            # getitem against index should raise ValueError\n            values = [\n                \"2014\",\n                \"2013/02\",\n                \"2013/01/02\",\n                \"2013/02/01 9H\",\n                \"2013/02/01 09:00\",\n            ]\n            for v in values:\n\n                # GH7116\n                # these show deprecations as we are trying\n                # to slice with non-integer indexers\n                # with pytest.raises(IndexError):\n                #    idx[v]\n                continue\n\n            s = Series(np.random.rand(len(idx)), index=idx)\n            tm.assert_series_equal(s[\"2013/01\"], s[0:31])\n            tm.assert_series_equal(s[\"2013/02\"], s[31:59])\n            tm.assert_series_equal(s[\"2014\"], s[365:])\n\n            invalid = [\"2013/02/01 9H\", \"2013/02/01 09:00\"]\n            for v in invalid:\n                with pytest.raises(KeyError, match=v):\n                    s[v]\n\n\nclass TestWhere:\n    @pytest.mark.parametrize(\"klass\", [list, tuple, np.array, Series])\n    def test_where(self, klass):\n        i = period_range(\"20130101\", periods=5, freq=\"D\")\n        cond = [True] * len(i)\n        expected = i\n        result = i.where(klass(cond))\n        tm.assert_index_equal(result, expected)\n\n        cond = [False] + [True] * (len(i) - 1)\n        expected = PeriodIndex([pd.NaT] + i[1:].tolist(), freq=\"D\")\n        result = i.where(klass(cond))\n        tm.assert_index_equal(result, expected)\n\n    def test_where_other(self):\n        i = period_range(\"20130101\", periods=5, freq=\"D\")\n        for arr in [np.nan, pd.NaT]:\n            result = i.where(notna(i), other=np.nan)\n            expected = i\n            tm.assert_index_equal(result, expected)\n\n        i2 = i.copy()\n        i2 = pd.PeriodIndex([pd.NaT, pd.NaT] + i[2:].tolist(), freq=\"D\")\n        result = i.where(notna(i2), i2)\n        tm.assert_index_equal(result, i2)\n\n        i2 = i.copy()\n        i2 = pd.PeriodIndex([pd.NaT, pd.NaT] + i[2:].tolist(), freq=\"D\")\n        result = i.where(notna(i2), i2.values)\n        tm.assert_index_equal(result, i2)\n\n    def test_where_invalid_dtypes(self):\n        pi = period_range(\"20130101\", periods=5, freq=\"D\")\n\n        i2 = pi.copy()\n        i2 = pd.PeriodIndex([pd.NaT, pd.NaT] + pi[2:].tolist(), freq=\"D\")\n\n        with pytest.raises(TypeError, match=\"Where requires matching dtype\"):\n            pi.where(notna(i2), i2.asi8)\n\n        with pytest.raises(TypeError, match=\"Where requires matching dtype\"):\n            pi.where(notna(i2), i2.asi8.view(\"timedelta64[ns]\"))\n\n        with pytest.raises(TypeError, match=\"Where requires matching dtype\"):\n            pi.where(notna(i2), i2.to_timestamp(\"S\"))\n\n\nclass TestTake:\n    def test_take(self):\n        # GH#10295\n        idx1 = pd.period_range(\"2011-01-01\", \"2011-01-31\", freq=\"D\", name=\"idx\")\n\n        for idx in [idx1]:\n            result = idx.take([0])\n            assert result == pd.Period(\"2011-01-01\", freq=\"D\")\n\n            result = idx.take([5])\n            assert result == pd.Period(\"2011-01-06\", freq=\"D\")\n\n            result = idx.take([0, 1, 2])\n            expected = pd.period_range(\"2011-01-01\", \"2011-01-03\", freq=\"D\", name=\"idx\")\n            tm.assert_index_equal(result, expected)\n            assert result.freq == \"D\"\n            assert result.freq == expected.freq\n\n            result = idx.take([0, 2, 4])\n            expected = pd.PeriodIndex(\n                [\"2011-01-01\", \"2011-01-03\", \"2011-01-05\"], freq=\"D\", name=\"idx\"\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx.take([7, 4, 1])\n            expected = pd.PeriodIndex(\n                [\"2011-01-08\", \"2011-01-05\", \"2011-01-02\"], freq=\"D\", name=\"idx\"\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx.take([3, 2, 5])\n            expected = PeriodIndex(\n                [\"2011-01-04\", \"2011-01-03\", \"2011-01-06\"], freq=\"D\", name=\"idx\"\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx.take([-3, 2, 5])\n            expected = PeriodIndex(\n                [\"2011-01-29\", \"2011-01-03\", \"2011-01-06\"], freq=\"D\", name=\"idx\"\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n    def test_take_misc(self):\n        index = period_range(start=\"1/1/10\", end=\"12/31/12\", freq=\"D\", name=\"idx\")\n        expected = PeriodIndex(\n            [\n                datetime(2010, 1, 6),\n                datetime(2010, 1, 7),\n                datetime(2010, 1, 9),\n                datetime(2010, 1, 13),\n            ],\n            freq=\"D\",\n            name=\"idx\",\n        )\n\n        taken1 = index.take([5, 6, 8, 12])\n        taken2 = index[[5, 6, 8, 12]]\n\n        for taken in [taken1, taken2]:\n            tm.assert_index_equal(taken, expected)\n            assert isinstance(taken, PeriodIndex)\n            assert taken.freq == index.freq\n            assert taken.name == expected.name\n\n    def test_take_fill_value(self):\n        # GH#12631\n        idx = pd.PeriodIndex(\n            [\"2011-01-01\", \"2011-02-01\", \"2011-03-01\"], name=\"xxx\", freq=\"D\"\n        )\n        result = idx.take(np.array([1, 0, -1]))\n        expected = pd.PeriodIndex(\n            [\"2011-02-01\", \"2011-01-01\", \"2011-03-01\"], name=\"xxx\", freq=\"D\"\n        )\n        tm.assert_index_equal(result, expected)\n\n        # fill_value\n        result = idx.take(np.array([1, 0, -1]), fill_value=True)\n        expected = pd.PeriodIndex(\n            [\"2011-02-01\", \"2011-01-01\", \"NaT\"], name=\"xxx\", freq=\"D\"\n        )\n        tm.assert_index_equal(result, expected)\n\n        # allow_fill=False\n        result = idx.take(np.array([1, 0, -1]), allow_fill=False, fill_value=True)\n        expected = pd.PeriodIndex(\n            [\"2011-02-01\", \"2011-01-01\", \"2011-03-01\"], name=\"xxx\", freq=\"D\"\n        )\n        tm.assert_index_equal(result, expected)\n\n        msg = (\n            \"When allow_fill=True and fill_value is not None, \"\n            \"all indices must be >= -1\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            idx.take(np.array([1, 0, -2]), fill_value=True)\n        with pytest.raises(ValueError, match=msg):\n            idx.take(np.array([1, 0, -5]), fill_value=True)\n\n        msg = \"index -5 is out of bounds for( axis 0 with)? size 3\"\n        with pytest.raises(IndexError, match=msg):\n            idx.take(np.array([1, -5]))\n\n\nclass TestIndexing:\n    def test_get_loc_msg(self):\n        idx = period_range(\"2000-1-1\", freq=\"A\", periods=10)\n        bad_period = Period(\"2012\", \"A\")\n        with pytest.raises(KeyError, match=r\"^Period\\('2012', 'A-DEC'\\)$\"):\n            idx.get_loc(bad_period)\n\n        try:\n            idx.get_loc(bad_period)\n        except KeyError as inst:\n            assert inst.args[0] == bad_period\n\n    def test_get_loc_nat(self):\n        didx = DatetimeIndex([\"2011-01-01\", \"NaT\", \"2011-01-03\"])\n        pidx = PeriodIndex([\"2011-01-01\", \"NaT\", \"2011-01-03\"], freq=\"M\")\n\n        # check DatetimeIndex compat\n        for idx in [didx, pidx]:\n            assert idx.get_loc(pd.NaT) == 1\n            assert idx.get_loc(None) == 1\n            assert idx.get_loc(float(\"nan\")) == 1\n            assert idx.get_loc(np.nan) == 1\n\n    def test_get_loc(self):\n        # GH 17717\n        p0 = pd.Period(\"2017-09-01\")\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n\n        # get the location of p1/p2 from\n        # monotonic increasing PeriodIndex with non-duplicate\n        idx0 = pd.PeriodIndex([p0, p1, p2])\n        expected_idx1_p1 = 1\n        expected_idx1_p2 = 2\n\n        assert idx0.get_loc(p1) == expected_idx1_p1\n        assert idx0.get_loc(str(p1)) == expected_idx1_p1\n        assert idx0.get_loc(p2) == expected_idx1_p2\n        assert idx0.get_loc(str(p2)) == expected_idx1_p2\n\n        msg = \"Cannot interpret 'foo' as period\"\n        with pytest.raises(KeyError, match=msg):\n            idx0.get_loc(\"foo\")\n        with pytest.raises(KeyError, match=r\"^1\\.1$\"):\n            idx0.get_loc(1.1)\n\n        with pytest.raises(InvalidIndexError, match=re.escape(str(idx0))):\n            idx0.get_loc(idx0)\n\n        # get the location of p1/p2 from\n        # monotonic increasing PeriodIndex with duplicate\n        idx1 = pd.PeriodIndex([p1, p1, p2])\n        expected_idx1_p1 = slice(0, 2)\n        expected_idx1_p2 = 2\n\n        assert idx1.get_loc(p1) == expected_idx1_p1\n        assert idx1.get_loc(str(p1)) == expected_idx1_p1\n        assert idx1.get_loc(p2) == expected_idx1_p2\n        assert idx1.get_loc(str(p2)) == expected_idx1_p2\n\n        msg = \"Cannot interpret 'foo' as period\"\n        with pytest.raises(KeyError, match=msg):\n            idx1.get_loc(\"foo\")\n\n        with pytest.raises(KeyError, match=r\"^1\\.1$\"):\n            idx1.get_loc(1.1)\n\n        with pytest.raises(InvalidIndexError, match=re.escape(str(idx1))):\n            idx1.get_loc(idx1)\n\n        # get the location of p1/p2 from\n        # non-monotonic increasing/decreasing PeriodIndex with duplicate\n        idx2 = pd.PeriodIndex([p2, p1, p2])\n        expected_idx2_p1 = 1\n        expected_idx2_p2 = np.array([True, False, True])\n\n        assert idx2.get_loc(p1) == expected_idx2_p1\n        assert idx2.get_loc(str(p1)) == expected_idx2_p1\n        tm.assert_numpy_array_equal(idx2.get_loc(p2), expected_idx2_p2)\n        tm.assert_numpy_array_equal(idx2.get_loc(str(p2)), expected_idx2_p2)\n\n    def test_get_loc_integer(self):\n        dti = pd.date_range(\"2016-01-01\", periods=3)\n        pi = dti.to_period(\"D\")\n        with pytest.raises(KeyError, match=\"16801\"):\n            pi.get_loc(16801)\n\n        pi2 = dti.to_period(\"Y\")  # duplicates, ordinals are all 46\n        with pytest.raises(KeyError, match=\"46\"):\n            pi2.get_loc(46)\n\n    @pytest.mark.parametrize(\"freq\", [\"H\", \"D\"])\n    def test_get_value_datetime_hourly(self, freq):\n        # get_loc and get_value should treat datetime objects symmetrically\n        dti = pd.date_range(\"2016-01-01\", periods=3, freq=\"MS\")\n        pi = dti.to_period(freq)\n        ser = pd.Series(range(7, 10), index=pi)\n\n        ts = dti[0]\n\n        assert pi.get_loc(ts) == 0\n        assert pi.get_value(ser, ts) == 7\n        assert ser[ts] == 7\n        assert ser.loc[ts] == 7\n\n        ts2 = ts + pd.Timedelta(hours=3)\n        if freq == \"H\":\n            with pytest.raises(KeyError, match=\"2016-01-01 03:00\"):\n                pi.get_loc(ts2)\n            with pytest.raises(KeyError, match=\"2016-01-01 03:00\"):\n                pi.get_value(ser, ts2)\n            with pytest.raises(KeyError, match=\"2016-01-01 03:00\"):\n                ser[ts2]\n            with pytest.raises(KeyError, match=\"2016-01-01 03:00\"):\n                ser.loc[ts2]\n        else:\n            assert pi.get_loc(ts2) == 0\n            assert pi.get_value(ser, ts2) == 7\n            assert ser[ts2] == 7\n            assert ser.loc[ts2] == 7\n\n    def test_get_value_integer(self):\n        dti = pd.date_range(\"2016-01-01\", periods=3)\n        pi = dti.to_period(\"D\")\n        ser = pd.Series(range(3), index=pi)\n        with pytest.raises(IndexError, match=\"index out of bounds\"):\n            pi.get_value(ser, 16801)\n\n        pi2 = dti.to_period(\"Y\")  # duplicates, ordinals are all 46\n        ser2 = pd.Series(range(3), index=pi2)\n        with pytest.raises(IndexError, match=\"index out of bounds\"):\n            pi2.get_value(ser2, 46)\n\n    def test_is_monotonic_increasing(self):\n        # GH 17717\n        p0 = pd.Period(\"2017-09-01\")\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n\n        idx_inc0 = pd.PeriodIndex([p0, p1, p2])\n        idx_inc1 = pd.PeriodIndex([p0, p1, p1])\n        idx_dec0 = pd.PeriodIndex([p2, p1, p0])\n        idx_dec1 = pd.PeriodIndex([p2, p1, p1])\n        idx = pd.PeriodIndex([p1, p2, p0])\n\n        assert idx_inc0.is_monotonic_increasing is True\n        assert idx_inc1.is_monotonic_increasing is True\n        assert idx_dec0.is_monotonic_increasing is False\n        assert idx_dec1.is_monotonic_increasing is False\n        assert idx.is_monotonic_increasing is False\n\n    def test_is_monotonic_decreasing(self):\n        # GH 17717\n        p0 = pd.Period(\"2017-09-01\")\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n\n        idx_inc0 = pd.PeriodIndex([p0, p1, p2])\n        idx_inc1 = pd.PeriodIndex([p0, p1, p1])\n        idx_dec0 = pd.PeriodIndex([p2, p1, p0])\n        idx_dec1 = pd.PeriodIndex([p2, p1, p1])\n        idx = pd.PeriodIndex([p1, p2, p0])\n\n        assert idx_inc0.is_monotonic_decreasing is False\n        assert idx_inc1.is_monotonic_decreasing is False\n        assert idx_dec0.is_monotonic_decreasing is True\n        assert idx_dec1.is_monotonic_decreasing is True\n        assert idx.is_monotonic_decreasing is False\n\n    def test_contains(self):\n        # GH 17717\n        p0 = pd.Period(\"2017-09-01\")\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n        p3 = pd.Period(\"2017-09-04\")\n\n        ps0 = [p0, p1, p2]\n        idx0 = pd.PeriodIndex(ps0)\n        ser = pd.Series(range(6, 9), index=idx0)\n\n        for p in ps0:\n            assert p in idx0\n            assert str(p) in idx0\n\n        # GH#31172\n        # Higher-resolution period-like are _not_ considered as contained\n        key = \"2017-09-01 00:00:01\"\n        assert key not in idx0\n        with pytest.raises(KeyError, match=key):\n            idx0.get_loc(key)\n        with pytest.raises(KeyError, match=key):\n            idx0.get_value(ser, key)\n\n        assert \"2017-09\" in idx0\n\n        assert p3 not in idx0\n\n    def test_get_value(self):\n        # GH 17717\n        p0 = pd.Period(\"2017-09-01\")\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n\n        idx0 = pd.PeriodIndex([p0, p1, p2])\n        input0 = pd.Series(np.array([1, 2, 3]), index=idx0)\n        expected0 = 2\n\n        result0 = idx0.get_value(input0, p1)\n        assert result0 == expected0\n\n        idx1 = pd.PeriodIndex([p1, p1, p2])\n        input1 = pd.Series(np.array([1, 2, 3]), index=idx1)\n        expected1 = input1.iloc[[0, 1]]\n\n        result1 = idx1.get_value(input1, p1)\n        tm.assert_series_equal(result1, expected1)\n\n        idx2 = pd.PeriodIndex([p1, p2, p1])\n        input2 = pd.Series(np.array([1, 2, 3]), index=idx2)\n        expected2 = input2.iloc[[0, 2]]\n\n        result2 = idx2.get_value(input2, p1)\n        tm.assert_series_equal(result2, expected2)\n\n    def test_get_indexer(self):\n        # GH 17717\n        p1 = pd.Period(\"2017-09-01\")\n        p2 = pd.Period(\"2017-09-04\")\n        p3 = pd.Period(\"2017-09-07\")\n\n        tp0 = pd.Period(\"2017-08-31\")\n        tp1 = pd.Period(\"2017-09-02\")\n        tp2 = pd.Period(\"2017-09-05\")\n        tp3 = pd.Period(\"2017-09-09\")\n\n        idx = pd.PeriodIndex([p1, p2, p3])\n\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(idx), np.array([0, 1, 2], dtype=np.intp)\n        )\n\n        target = pd.PeriodIndex([tp0, tp1, tp2, tp3])\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"pad\"), np.array([-1, 0, 1, 2], dtype=np.intp)\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"backfill\"), np.array([0, 1, 2, -1], dtype=np.intp)\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"nearest\"), np.array([0, 0, 1, 2], dtype=np.intp)\n        )\n\n        res = idx.get_indexer(target, \"nearest\", tolerance=pd.Timedelta(\"1 day\"))\n        tm.assert_numpy_array_equal(res, np.array([0, 0, 1, -1], dtype=np.intp))\n\n    def test_get_indexer_mismatched_dtype(self):\n        # Check that we return all -1s and do not raise or cast incorrectly\n\n        dti = pd.date_range(\"2016-01-01\", periods=3)\n        pi = dti.to_period(\"D\")\n        pi2 = dti.to_period(\"W\")\n\n        expected = np.array([-1, -1, -1], dtype=np.intp)\n\n        result = pi.get_indexer(dti)\n        tm.assert_numpy_array_equal(result, expected)\n\n        # This should work in both directions\n        result = dti.get_indexer(pi)\n        tm.assert_numpy_array_equal(result, expected)\n\n        result = pi.get_indexer(pi2)\n        tm.assert_numpy_array_equal(result, expected)\n\n        # We expect the same from get_indexer_non_unique\n        result = pi.get_indexer_non_unique(dti)[0]\n        tm.assert_numpy_array_equal(result, expected)\n\n        result = dti.get_indexer_non_unique(pi)[0]\n        tm.assert_numpy_array_equal(result, expected)\n\n        result = pi.get_indexer_non_unique(pi2)[0]\n        tm.assert_numpy_array_equal(result, expected)\n\n    def test_get_indexer_non_unique(self):\n        # GH 17717\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n        p3 = pd.Period(\"2017-09-04\")\n        p4 = pd.Period(\"2017-09-05\")\n\n        idx1 = pd.PeriodIndex([p1, p2, p1])\n        idx2 = pd.PeriodIndex([p2, p1, p3, p4])\n\n        result = idx1.get_indexer_non_unique(idx2)\n        expected_indexer = np.array([1, 0, 2, -1, -1], dtype=np.intp)\n        expected_missing = np.array([2, 3], dtype=np.int64)\n\n        tm.assert_numpy_array_equal(result[0], expected_indexer)\n        tm.assert_numpy_array_equal(result[1], expected_missing)\n\n    # TODO: This method came from test_period; de-dup with version above\n    def test_get_loc2(self):\n        idx = pd.period_range(\"2000-01-01\", periods=3)\n\n        for method in [None, \"pad\", \"backfill\", \"nearest\"]:\n            assert idx.get_loc(idx[1], method) == 1\n            assert idx.get_loc(idx[1].asfreq(\"H\", how=\"start\"), method) == 1\n            assert idx.get_loc(idx[1].to_timestamp(), method) == 1\n            assert idx.get_loc(idx[1].to_timestamp().to_pydatetime(), method) == 1\n            assert idx.get_loc(str(idx[1]), method) == 1\n\n        idx = pd.period_range(\"2000-01-01\", periods=5)[::2]\n        assert idx.get_loc(\"2000-01-02T12\", method=\"nearest\", tolerance=\"1 day\") == 1\n        assert (\n            idx.get_loc(\"2000-01-02T12\", method=\"nearest\", tolerance=pd.Timedelta(\"1D\"))\n            == 1\n        )\n        assert (\n            idx.get_loc(\n                \"2000-01-02T12\", method=\"nearest\", tolerance=np.timedelta64(1, \"D\")\n            )\n            == 1\n        )\n        assert (\n            idx.get_loc(\"2000-01-02T12\", method=\"nearest\", tolerance=timedelta(1)) == 1\n        )\n\n        msg = \"unit abbreviation w/o a number\"\n        with pytest.raises(ValueError, match=msg):\n            idx.get_loc(\"2000-01-10\", method=\"nearest\", tolerance=\"foo\")\n\n        msg = \"Input has different freq=None from PeriodArray\\\\(freq=D\\\\)\"\n        with pytest.raises(ValueError, match=msg):\n            idx.get_loc(\"2000-01-10\", method=\"nearest\", tolerance=\"1 hour\")\n        with pytest.raises(KeyError, match=r\"^Period\\('2000-01-10', 'D'\\)$\"):\n            idx.get_loc(\"2000-01-10\", method=\"nearest\", tolerance=\"1 day\")\n        with pytest.raises(\n            ValueError, match=\"list-like tolerance size must match target index size\"\n        ):\n            idx.get_loc(\n                \"2000-01-10\",\n                method=\"nearest\",\n                tolerance=[\n                    pd.Timedelta(\"1 day\").to_timedelta64(),\n                    pd.Timedelta(\"1 day\").to_timedelta64(),\n                ],\n            )\n\n    # TODO: This method came from test_period; de-dup with version above\n    def test_get_indexer2(self):\n        idx = pd.period_range(\"2000-01-01\", periods=3).asfreq(\"H\", how=\"start\")\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(idx), np.array([0, 1, 2], dtype=np.intp)\n        )\n\n        target = pd.PeriodIndex(\n            [\"1999-12-31T23\", \"2000-01-01T12\", \"2000-01-02T01\"], freq=\"H\"\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"pad\"), np.array([-1, 0, 1], dtype=np.intp)\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"backfill\"), np.array([0, 1, 2], dtype=np.intp)\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"nearest\"), np.array([0, 1, 1], dtype=np.intp)\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"nearest\", tolerance=\"1 hour\"),\n            np.array([0, -1, 1], dtype=np.intp),\n        )\n\n        msg = \"Input has different freq=None from PeriodArray\\\\(freq=H\\\\)\"\n        with pytest.raises(ValueError, match=msg):\n            idx.get_indexer(target, \"nearest\", tolerance=\"1 minute\")\n\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"nearest\", tolerance=\"1 day\"),\n            np.array([0, 1, 1], dtype=np.intp),\n        )\n        tol_raw = [\n            pd.Timedelta(\"1 hour\"),\n            pd.Timedelta(\"1 hour\"),\n            np.timedelta64(1, \"D\"),\n        ]\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(\n                target, \"nearest\", tolerance=[np.timedelta64(x) for x in tol_raw]\n            ),\n            np.array([0, -1, 1], dtype=np.intp),\n        )\n        tol_bad = [\n            pd.Timedelta(\"2 hour\").to_timedelta64(),\n            pd.Timedelta(\"1 hour\").to_timedelta64(),\n            np.timedelta64(1, \"M\"),\n        ]\n        with pytest.raises(\n            libperiod.IncompatibleFrequency, match=\"Input has different freq=None from\"\n        ):\n            idx.get_indexer(target, \"nearest\", tolerance=tol_bad)\n\n    def test_indexing(self):\n        # GH 4390, iat incorrectly indexing\n        index = period_range(\"1/1/2001\", periods=10)\n        s = Series(np.random.randn(10), index=index)\n        expected = s[index[0]]\n        result = s.iat[0]\n        assert expected == result\n\n    def test_period_index_indexer(self):\n        # GH4125\n        idx = pd.period_range(\"2002-01\", \"2003-12\", freq=\"M\")\n        df = pd.DataFrame(np.random.randn(24, 10), index=idx)\n        tm.assert_frame_equal(df, df.loc[idx])\n        tm.assert_frame_equal(df, df.loc[list(idx)])\n        tm.assert_frame_equal(df, df.loc[list(idx)])\n        tm.assert_frame_equal(df.iloc[0:5], df.loc[idx[0:5]])\n        tm.assert_frame_equal(df, df.loc[list(idx)])\n"
    }
  ]
}