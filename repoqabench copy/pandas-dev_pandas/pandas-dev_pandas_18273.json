{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "18273",
  "issue_description": "# read_excel return empty dataframe when using usecols\n\n\r\n```python\r\nIn [3]: data = pd.read_excel(\"A.xlsx\")\r\n\r\nIn [4]: data\r\nOut[4]:\r\n   A  B\r\n0  1  2\r\n1  3  4\r\n\r\nIn [5]: data1 = pd.read_excel(\"A.xlsx\",usecols=['B'])\r\n\r\nIn [6]: data1\r\nOut[6]:\r\nEmpty DataFrame\r\nColumns: []\r\nIndex: []\r\n\r\nIn [7]: pd.__version__\r\nOut[7]: '0.21.0'\r\n\r\n```\r\n#### Problem description\r\nHaving a excel file name A.xlsx(or A.xls) with column A,B\r\nread_excel return empty dataframe if usecols used ",
  "issue_comments": [
    {
      "id": 344332372,
      "user": "chris-b1",
      "body": "Guessing this is due to a conflict in the two different kind of specs we accept for usecols - columns labels, or Excel column letters (A, B, C, ...).  A workaround is to select the Excel column completely (`'B:B'`) but this should work.\r\n\r\n```python\r\ndf = pd.DataFrame({'A': [1, 3], 'B': [3, 4]})\r\ndf.to_excel('tmp.xlsx', index=False)\r\n\r\npd.read_excel('tmp.xlsx', usecols=['B'])\r\nOut[86]: \r\nEmpty DataFrame\r\nColumns: []\r\nIndex: []\r\n\r\n\r\npd.read_excel('tmp.xlsx', usecols='B:B')\r\nOut[88]: \r\n   B\r\n0  3\r\n1  4\r\n```"
    },
    {
      "id": 345583066,
      "user": "jhall6226",
      "body": "I'm interested in contributing and thought this looked like a good place to take a first step.\r\n\r\nReviewing pandas/io/excel.py, it looks like the change needs to be made in the _should_parse function of the ExcelFile class. Specifically, here: https://github.com/pandas-dev/pandas/blob/1915ffc53ea60494f24d83844bbff00efa392c82/pandas/io/excel.py#L355-L360\r\n\r\nIt looks like the current implementation checks for an integer first (i.e. a max number of columns to use), a string second (i.e. assuming a comma separated list of column names in a single string), and assumes a list (technically any container that implements the \"in\" operator) otherwise. When a list is assumed for usecols, the check for the column index (i) assumes that it is a list of integers.\r\n\r\nThe simplest way to implement the requested functionality would be to add a new conditional to check whether the first element is a string and, if so, concatenate the list into a single string like case 2 and re-use the _range2cols function to convert to numeric values before returning the comparison:\r\n```python\r\nif isinstance(usecols, list) and isinstance(usecols[0], compat.string_types):\r\n    return i in _range2cols(', '.join(usecols))\r\n```\r\nAdditionally, there would probably need to be another check (if there isn't already?) to handle the behavior for an empty list. Should this be assumed to mean the same thing as None? It doesn't make sense to read a sheet and not return any data.\r\n\r\nIf we take this a little further, we could add support for mixed lists of integers and strings (if desired) by doing something like:\r\n```python\r\ndef _list2cols(area_list):\r\n    parsed_list = list()\r\n    for e in area_list:\r\n        if isinstance(e, int):\r\n            parsed_list.append(e)\r\n        elif isinstance(e, compat.string_types):\r\n            parsed_list.extend(_range2cols(e))\r\n        else:\r\n            pass # Assuming other types should not be considered\r\n\r\n    return parsed_list\r\n\r\nif isinstance(usecols, list):\r\n    return i in _list2cols(usecols)\r\n```\r\n\r\nInterested in feedback on which direction should be taken.\r\n\r\n"
    },
    {
      "id": 345759560,
      "user": "chris-b1",
      "body": "What I think would be easiest here would be to only have `_should_parse` handle the case when `usecols` is an Excel column specification (e.g. `'A,B,D:E'`), and in all other cases pass through `usecols` to `TextParser` here.\r\nhttps://github.com/pandas-dev/pandas/blob/1915ffc53ea60494f24d83844bbff00efa392c82/pandas/io/excel.py#L529\r\n\r\nIt already has logic to handle column names/locations, and will raise in the mixed case.\r\n\r\n```python\r\nfrom pandas.io.parsers import TextParser\r\nTextParser([['a', 'b', 'c'],\r\n            [1, 2, 3]], usecols=['b']).read()\r\n\r\nOut[81]: \r\n   b\r\n0  2\r\n```"
    },
    {
      "id": 345791675,
      "user": "jhall6226",
      "body": "Ok. So in that case, you would remove the preprocessing steps here.\r\nhttps://github.com/pandas-dev/pandas/blob/1915ffc53ea60494f24d83844bbff00efa392c82/pandas/io/excel.py#L478\r\n\r\nThen, you would call a function like the current _should_parse to convert the usecols value (which would only have to be done once vice the rows x columns amount of times that it is currently done) into something readable by TextParser and pass that new value where you referenced.\r\n\r\nIs that the correct interpretation?"
    },
    {
      "id": 345837214,
      "user": "chris-b1",
      "body": "Yes, I'm thinking that will most straightforward, rather than\nre-implementing what TextParser does.  Feel free to put up a\nwork-in-progress pull request and ping me, it is often easier to answer\nquestions looking at the actual changes.\n\nOn Mon, Nov 20, 2017 at 12:53 PM, Jordan Hall <notifications@github.com>\nwrote:\n\n> Ok. So in that case, you would remove the preprocessing steps here.\n> https://github.com/pandas-dev/pandas/blob/1915ffc53ea60494f24d83844bbff0\n> 0efa392c82/pandas/io/excel.py#L478 <http://url>\n>\n> Then, you would call a function like the current _should_parse to convert\n> the usecols value (which would only have to be done once vice the rows x\n> columns amount of times that it is currently done) into something readable\n> by TextParser and pass that new value where you referenced.\n>\n> Is that the correct interpretation?\n>\n> 窶能n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/issues/18273#issuecomment-345791675>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AB1b_K69yoT3EOyfp3ALntzCjc8BZ9dHks5s4cq3gaJpZM4Qcs_f>\n> .\n>\n"
    },
    {
      "id": 348183986,
      "user": "JeroenDelcour",
      "body": "Any progress on this? I couldn't find the mentioned pull request."
    },
    {
      "id": 356224056,
      "user": "Vonatzki",
      "body": "Wow, after 2 years of using this, I stumbled upon this after I updated my pandas.\r\n\r\nThis is scary since most of my scripts use the usecol parameter heavily. I guess I have to downgrade for now."
    },
    {
      "id": 357540816,
      "user": "kuraga",
      "body": "Yeah, the same issue with 0.21.0 and 0.22.0. No issues with 0.20.3.\r\n\r\nAll columns' names are cyrillic complex (not `A`, `B`, etc.)"
    },
    {
      "id": 357632881,
      "user": "linlinzhao",
      "body": "I have a set of excel files, all of which have a few same columns I need to read, but other columns are different. The old usecols with specified column names works nicely. \r\n\r\nDo I have to downgrade Pandas? Currently I have 0.22.0"
    },
    {
      "id": 360252882,
      "user": "ldacey",
      "body": "Same issue here. usecols is returning an empty dataframe after upgrading."
    },
    {
      "id": 362176766,
      "user": "weifei0228",
      "body": "Same issue here.usecols is returning an empty dataframe with 0.22.0"
    },
    {
      "id": 374084557,
      "user": "Bravico",
      "body": "Same issue in empty dataframe returning with 0.22.0"
    },
    {
      "id": 375544785,
      "user": "LISHITING",
      "body": "For me\r\nInstead of typing `usecols=['B']`, try `usecols='B'`\r\n"
    },
    {
      "id": 375934696,
      "user": "jacksonjos",
      "body": "I'm going to work on this issue to solve it.\r\n\r\nIf anyone is already working on it, please, tell me."
    },
    {
      "id": 376164277,
      "user": "Cristianasp",
      "body": "Same issue here. I have a file with 100 columns and I want to select 20 by their colum label, but I cannot do that. I get an empty dataframe. My workaround is to save the excel as csv... and then read it."
    },
    {
      "id": 376167605,
      "user": "chris-b1",
      "body": "Copying my comment from #20480, welcome any feedback on how this api should work\r\n\r\n\r\n#18273 is actually two somewhat separate problems and we have a bit of an API tangle here\r\n\r\n1.  passing a list of Excel column _letters_ doesn't work (this fixes that)\r\n2.  passing a list column _names_ (e.g. column title `'foo'` in the spreadsheet) to `usecols` doesn't work anymore\r\n\r\nNumber 2 wasn't part of the `read_excel` documented args, but once worked, because this param used to be called `parse_cols` (#17774), and if you passed something to `usecols` it would get passed down to the TextParser logic and do the right thing\r\nhttps://github.com/pandas-dev/pandas/blob/1915ffc53ea60494f24d83844bbff00efa392c82/pandas/io/excel.py#L529\r\n\r\nNot sure what the solution is, there could be ambiguous cases (column titled`'A'` in spreadsheet column `B`), that would be easiest to handle with separate kwargs.  Or could just have usecols do everything and warn in cases of ambiguity."
    },
    {
      "id": 376169612,
      "user": "chris-b1",
      "body": "Also for people needing a work-around, it works, and is essentially as efficient to do `pd.read_excel(...)[usecols].`  The entire Excel file has to parsed no matter what because of the row oriented xml layout."
    },
    {
      "id": 376370676,
      "user": "TomAugspurger",
      "body": "What do people think about a new keyword vs. guessing (well, warning if there's ambiguity)? I suppose the third option is deprecate the current behavior of `usecols` meaning the Excel ranges in favor of a new keyword, but I suppose we shouldn't break the one thing that works consistently across pandas versions.\r\n\r\nIt's unfortunate, but I think best to introduce a new keyword here for named columns. Or just recommend subsetting after reading, if we don't want to add a new keyword."
    },
    {
      "id": 376374546,
      "user": "jacksonjos",
      "body": "I prefer a new keyword too because is less confusing and error prone than making the same keyword having multiple behaviors.\r\n\r\nWhen a decisions is made I can implement it. "
    },
    {
      "id": 381405460,
      "user": "mrcodetastic",
      "body": "Hi,\r\n\r\nHas a decision been made on what the new argument will be yet? This is a very useful part of the pandas to no longer work."
    },
    {
      "id": 381406141,
      "user": "jacksonjos",
      "body": "Hi,\n\nI was already working on this issue and finally the reviewers have decided\nwhat will be the named arguments, so I'll implement this today.\n\nBest regards,\n\n2018-04-15 10:11 GMT-03:00 mrfaptastic <notifications@github.com>:\n\n> Hi,\n>\n> Has a decision been made on what the new argument will be yet? This is a\n> pretty key part of the pandas to be kept broken.\n>\n> 窶能n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/issues/18273#issuecomment-381405460>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AANuQqMyO8ArxXexm0fEGWA8XL3uzoXEks5to0b8gaJpZM4Qcs_f>\n> .\n>\n"
    },
    {
      "id": 381414724,
      "user": "Cristianasp",
      "body": "Great news! Thank you!\n\n\nEm dom, 15 de abr de 2018 10:21, Jackson Souza <notifications@github.com>\nescreveu:\n\n> Hi,\n>\n> I was already working on this issue and finally the reviewers have decided\n> what will be the named arguments, so I'll implement this today.\n>\n> Best regards,\n>\n> 2018-04-15 10:11 GMT-03:00 mrfaptastic <notifications@github.com>:\n>\n> > Hi,\n> >\n> > Has a decision been made on what the new argument will be yet? This is a\n> > pretty key part of the pandas to be kept broken.\n> >\n> > 窶能n> > You are receiving this because you are subscribed to this thread.\n> > Reply to this email directly, view it on GitHub\n> > <\n> https://github.com/pandas-dev/pandas/issues/18273#issuecomment-381405460>,\n> > or mute the thread\n> > <\n> https://github.com/notifications/unsubscribe-auth/AANuQqMyO8ArxXexm0fEGWA8XL3uzoXEks5to0b8gaJpZM4Qcs_f\n> >\n> > .\n> >\n>\n> 窶能n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/issues/18273#issuecomment-381406141>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AcYZgpsXKscM85210AtjA5wEH_MVsZSaks5to0lzgaJpZM4Qcs_f>\n> .\n>\n"
    },
    {
      "id": 382341293,
      "user": "franktoffel",
      "body": "I was having the same issue and had to use pd.read_csv() instead. \r\n\r\nGood to know that there is a solution coming up."
    },
    {
      "id": 388645215,
      "user": "jacksonjos",
      "body": "Hi everyone, I'm having trouble to have this fix added to Pandas.\r\n\r\nI'm updating the commit for the pull request for almost 2 months as you can see in the conversation at https://github.com/pandas-dev/pandas/pull/20480/ and after every update one of the reviewers point changes that were already in the commit and should be pointed out before. What I mean is that I'm trying hard to have this issue solved but because of the lack of standard to review the changes every time there is something else to change in the commit making contributing to Pandas really awful and demotivating.\r\n\r\nDoes someone have a suggestion of what should I do about it? May anyone from Pandas core team  help me to find out what is the problem with the contribution I'm making?\r\n\r\nAlso, the behavior of `usecols` was redefined and it was created another keyword argument called `usecols_excel` to handle exclusively excel columns indexes as a string. So, the request to handle excel columns as a list of strings was revoked as you can see at the documentation of `usecols` and `usecols_excel` at https://github.com/pandas-dev/pandas/pull/20480/files#diff-0153a977179cfc73a2645cf0b7cd1f7f"
    },
    {
      "id": 388899885,
      "user": "chris-b1",
      "body": "Hi @jacksonjos - I'm getting back to your change now - thank you for the patience, my apologies that I haven't been very responsive, I haven't been putting much time towards pandas lately.\r\n\r\nOur review model is pretty informal and iterative, I get that it can be frustrating to address all the comments and not have a PR approved, but that's largely how it works, so I've found it helpful to have that as an expectation going in."
    },
    {
      "id": 395036796,
      "user": "jacksonjos",
      "body": "@chris-b1, may you take a look at issue https://github.com/pandas-dev/pandas/pull/20480, please?\r\n\r\n@jreback requested your review there again and without you it can't be closed.\r\nThank you for your attention."
    },
    {
      "id": 401994245,
      "user": "Teckloon",
      "body": "Thanks for resolving the read_excel return empty dataframe."
    },
    {
      "id": 433751677,
      "user": "gfyoung",
      "body": "Throwing my two cents in:\r\n\r\nhttps://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html\r\n\r\nSupporting lists of strings is not technically addressed in the documentation, so I'm a little hesitant to call this a bug as of the current version of `pandas` (`0.23.4`).\r\n\r\nThat being said, this issue does bring up a lot of questions re: how to handle `usecols` for `read_excel`, in particular, why its handling is so different from `usecols` for CSV:\r\n\r\n* Column ranges (e.g. `A:C`) - that's totally fine with me.  That's special to Excel.\r\n* \"If int then indicates last column to be parsed\" - We don't support this for CSV.  I don't see why we support this for Excel?\r\n* List-like support for Excel is pretty bad.  We don't support values like `usecols=[0, 1, 2]` or `usecols=['A', 'B', 'C']`, which I think we should.\r\n* We don't support callables for `usecols`, though I don't see why we shouldn't.\r\n\r\nWhat do you guys think?"
    },
    {
      "id": 433752172,
      "user": "WillAyd",
      "body": "My personal belief is that usecols should operate the same way that it does in read_csv and excel-specific behavior should be handled in a separate parameter (something to the effect of `use_range`). \r\n\r\nIt would require some deprecations from the current state but I think that logical separation would clarify any ambiguity between range \"A:A\" in Excel and a column named \"A\". "
    },
    {
      "id": 433752484,
      "user": "gfyoung",
      "body": "> My personal belief is that usecols should operate the same way that it does in read_csv and excel-specific behavior should be handled in a separate parameter (something to the effect of use_range).\r\n\r\n@WillAyd : Not sure I fully agree with adding a new parameter, but at least we have consensus that `usecols` should be widely consistent across the board. 汨 \r\n\r\n@jreback @chris-b1 : Thoughts?"
    }
  ],
  "text_context": "# read_excel return empty dataframe when using usecols\n\n\r\n```python\r\nIn [3]: data = pd.read_excel(\"A.xlsx\")\r\n\r\nIn [4]: data\r\nOut[4]:\r\n   A  B\r\n0  1  2\r\n1  3  4\r\n\r\nIn [5]: data1 = pd.read_excel(\"A.xlsx\",usecols=['B'])\r\n\r\nIn [6]: data1\r\nOut[6]:\r\nEmpty DataFrame\r\nColumns: []\r\nIndex: []\r\n\r\nIn [7]: pd.__version__\r\nOut[7]: '0.21.0'\r\n\r\n```\r\n#### Problem description\r\nHaving a excel file name A.xlsx(or A.xls) with column A,B\r\nread_excel return empty dataframe if usecols used \n\nGuessing this is due to a conflict in the two different kind of specs we accept for usecols - columns labels, or Excel column letters (A, B, C, ...).  A workaround is to select the Excel column completely (`'B:B'`) but this should work.\r\n\r\n```python\r\ndf = pd.DataFrame({'A': [1, 3], 'B': [3, 4]})\r\ndf.to_excel('tmp.xlsx', index=False)\r\n\r\npd.read_excel('tmp.xlsx', usecols=['B'])\r\nOut[86]: \r\nEmpty DataFrame\r\nColumns: []\r\nIndex: []\r\n\r\n\r\npd.read_excel('tmp.xlsx', usecols='B:B')\r\nOut[88]: \r\n   B\r\n0  3\r\n1  4\r\n```\n\nI'm interested in contributing and thought this looked like a good place to take a first step.\r\n\r\nReviewing pandas/io/excel.py, it looks like the change needs to be made in the _should_parse function of the ExcelFile class. Specifically, here: https://github.com/pandas-dev/pandas/blob/1915ffc53ea60494f24d83844bbff00efa392c82/pandas/io/excel.py#L355-L360\r\n\r\nIt looks like the current implementation checks for an integer first (i.e. a max number of columns to use), a string second (i.e. assuming a comma separated list of column names in a single string), and assumes a list (technically any container that implements the \"in\" operator) otherwise. When a list is assumed for usecols, the check for the column index (i) assumes that it is a list of integers.\r\n\r\nThe simplest way to implement the requested functionality would be to add a new conditional to check whether the first element is a string and, if so, concatenate the list into a single string like case 2 and re-use the _range2cols function to convert to numeric values before returning the comparison:\r\n```python\r\nif isinstance(usecols, list) and isinstance(usecols[0], compat.string_types):\r\n    return i in _range2cols(', '.join(usecols))\r\n```\r\nAdditionally, there would probably need to be another check (if there isn't already?) to handle the behavior for an empty list. Should this be assumed to mean the same thing as None? It doesn't make sense to read a sheet and not return any data.\r\n\r\nIf we take this a little further, we could add support for mixed lists of integers and strings (if desired) by doing something like:\r\n```python\r\ndef _list2cols(area_list):\r\n    parsed_list = list()\r\n    for e in area_list:\r\n        if isinstance(e, int):\r\n            parsed_list.append(e)\r\n        elif isinstance(e, compat.string_types):\r\n            parsed_list.extend(_range2cols(e))\r\n        else:\r\n            pass # Assuming other types should not be considered\r\n\r\n    return parsed_list\r\n\r\nif isinstance(usecols, list):\r\n    return i in _list2cols(usecols)\r\n```\r\n\r\nInterested in feedback on which direction should be taken.\r\n\r\n\n\nWhat I think would be easiest here would be to only have `_should_parse` handle the case when `usecols` is an Excel column specification (e.g. `'A,B,D:E'`), and in all other cases pass through `usecols` to `TextParser` here.\r\nhttps://github.com/pandas-dev/pandas/blob/1915ffc53ea60494f24d83844bbff00efa392c82/pandas/io/excel.py#L529\r\n\r\nIt already has logic to handle column names/locations, and will raise in the mixed case.\r\n\r\n```python\r\nfrom pandas.io.parsers import TextParser\r\nTextParser([['a', 'b', 'c'],\r\n            [1, 2, 3]], usecols=['b']).read()\r\n\r\nOut[81]: \r\n   b\r\n0  2\r\n```\n\nOk. So in that case, you would remove the preprocessing steps here.\r\nhttps://github.com/pandas-dev/pandas/blob/1915ffc53ea60494f24d83844bbff00efa392c82/pandas/io/excel.py#L478\r\n\r\nThen, you would call a function like the current _should_parse to convert the usecols value (which would only have to be done once vice the rows x columns amount of times that it is currently done) into something readable by TextParser and pass that new value where you referenced.\r\n\r\nIs that the correct interpretation?\n\nYes, I'm thinking that will most straightforward, rather than\nre-implementing what TextParser does.  Feel free to put up a\nwork-in-progress pull request and ping me, it is often easier to answer\nquestions looking at the actual changes.\n\nOn Mon, Nov 20, 2017 at 12:53 PM, Jordan Hall <notifications@github.com>\nwrote:\n\n> Ok. So in that case, you would remove the preprocessing steps here.\n> https://github.com/pandas-dev/pandas/blob/1915ffc53ea60494f24d83844bbff0\n> 0efa392c82/pandas/io/excel.py#L478 <http://url>\n>\n> Then, you would call a function like the current _should_parse to convert\n> the usecols value (which would only have to be done once vice the rows x\n> columns amount of times that it is currently done) into something readable\n> by TextParser and pass that new value where you referenced.\n>\n> Is that the correct interpretation?\n>\n> 窶能n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/issues/18273#issuecomment-345791675>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AB1b_K69yoT3EOyfp3ALntzCjc8BZ9dHks5s4cq3gaJpZM4Qcs_f>\n> .\n>\n\n\nAny progress on this? I couldn't find the mentioned pull request.\n\nWow, after 2 years of using this, I stumbled upon this after I updated my pandas.\r\n\r\nThis is scary since most of my scripts use the usecol parameter heavily. I guess I have to downgrade for now.\n\nYeah, the same issue with 0.21.0 and 0.22.0. No issues with 0.20.3.\r\n\r\nAll columns' names are cyrillic complex (not `A`, `B`, etc.)\n\nI have a set of excel files, all of which have a few same columns I need to read, but other columns are different. The old usecols with specified column names works nicely. \r\n\r\nDo I have to downgrade Pandas? Currently I have 0.22.0\n\nSame issue here. usecols is returning an empty dataframe after upgrading.\n\nSame issue here.usecols is returning an empty dataframe with 0.22.0\n\nSame issue in empty dataframe returning with 0.22.0\n\nFor me\r\nInstead of typing `usecols=['B']`, try `usecols='B'`\r\n\n\nI'm going to work on this issue to solve it.\r\n\r\nIf anyone is already working on it, please, tell me.\n\nSame issue here. I have a file with 100 columns and I want to select 20 by their colum label, but I cannot do that. I get an empty dataframe. My workaround is to save the excel as csv... and then read it.\n\nCopying my comment from #20480, welcome any feedback on how this api should work\r\n\r\n\r\n#18273 is actually two somewhat separate problems and we have a bit of an API tangle here\r\n\r\n1.  passing a list of Excel column _letters_ doesn't work (this fixes that)\r\n2.  passing a list column _names_ (e.g. column title `'foo'` in the spreadsheet) to `usecols` doesn't work anymore\r\n\r\nNumber 2 wasn't part of the `read_excel` documented args, but once worked, because this param used to be called `parse_cols` (#17774), and if you passed something to `usecols` it would get passed down to the TextParser logic and do the right thing\r\nhttps://github.com/pandas-dev/pandas/blob/1915ffc53ea60494f24d83844bbff00efa392c82/pandas/io/excel.py#L529\r\n\r\nNot sure what the solution is, there could be ambiguous cases (column titled`'A'` in spreadsheet column `B`), that would be easiest to handle with separate kwargs.  Or could just have usecols do everything and warn in cases of ambiguity.\n\nAlso for people needing a work-around, it works, and is essentially as efficient to do `pd.read_excel(...)[usecols].`  The entire Excel file has to parsed no matter what because of the row oriented xml layout.\n\nWhat do people think about a new keyword vs. guessing (well, warning if there's ambiguity)? I suppose the third option is deprecate the current behavior of `usecols` meaning the Excel ranges in favor of a new keyword, but I suppose we shouldn't break the one thing that works consistently across pandas versions.\r\n\r\nIt's unfortunate, but I think best to introduce a new keyword here for named columns. Or just recommend subsetting after reading, if we don't want to add a new keyword.\n\nI prefer a new keyword too because is less confusing and error prone than making the same keyword having multiple behaviors.\r\n\r\nWhen a decisions is made I can implement it. \n\nHi,\r\n\r\nHas a decision been made on what the new argument will be yet? This is a very useful part of the pandas to no longer work.\n\nHi,\n\nI was already working on this issue and finally the reviewers have decided\nwhat will be the named arguments, so I'll implement this today.\n\nBest regards,\n\n2018-04-15 10:11 GMT-03:00 mrfaptastic <notifications@github.com>:\n\n> Hi,\n>\n> Has a decision been made on what the new argument will be yet? This is a\n> pretty key part of the pandas to be kept broken.\n>\n> 窶能n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/issues/18273#issuecomment-381405460>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AANuQqMyO8ArxXexm0fEGWA8XL3uzoXEks5to0b8gaJpZM4Qcs_f>\n> .\n>\n\n\nGreat news! Thank you!\n\n\nEm dom, 15 de abr de 2018 10:21, Jackson Souza <notifications@github.com>\nescreveu:\n\n> Hi,\n>\n> I was already working on this issue and finally the reviewers have decided\n> what will be the named arguments, so I'll implement this today.\n>\n> Best regards,\n>\n> 2018-04-15 10:11 GMT-03:00 mrfaptastic <notifications@github.com>:\n>\n> > Hi,\n> >\n> > Has a decision been made on what the new argument will be yet? This is a\n> > pretty key part of the pandas to be kept broken.\n> >\n> > 窶能n> > You are receiving this because you are subscribed to this thread.\n> > Reply to this email directly, view it on GitHub\n> > <\n> https://github.com/pandas-dev/pandas/issues/18273#issuecomment-381405460>,\n> > or mute the thread\n> > <\n> https://github.com/notifications/unsubscribe-auth/AANuQqMyO8ArxXexm0fEGWA8XL3uzoXEks5to0b8gaJpZM4Qcs_f\n> >\n> > .\n> >\n>\n> 窶能n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/issues/18273#issuecomment-381406141>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AcYZgpsXKscM85210AtjA5wEH_MVsZSaks5to0lzgaJpZM4Qcs_f>\n> .\n>\n\n\nI was having the same issue and had to use pd.read_csv() instead. \r\n\r\nGood to know that there is a solution coming up.\n\nHi everyone, I'm having trouble to have this fix added to Pandas.\r\n\r\nI'm updating the commit for the pull request for almost 2 months as you can see in the conversation at https://github.com/pandas-dev/pandas/pull/20480/ and after every update one of the reviewers point changes that were already in the commit and should be pointed out before. What I mean is that I'm trying hard to have this issue solved but because of the lack of standard to review the changes every time there is something else to change in the commit making contributing to Pandas really awful and demotivating.\r\n\r\nDoes someone have a suggestion of what should I do about it? May anyone from Pandas core team  help me to find out what is the problem with the contribution I'm making?\r\n\r\nAlso, the behavior of `usecols` was redefined and it was created another keyword argument called `usecols_excel` to handle exclusively excel columns indexes as a string. So, the request to handle excel columns as a list of strings was revoked as you can see at the documentation of `usecols` and `usecols_excel` at https://github.com/pandas-dev/pandas/pull/20480/files#diff-0153a977179cfc73a2645cf0b7cd1f7f\n\nHi @jacksonjos - I'm getting back to your change now - thank you for the patience, my apologies that I haven't been very responsive, I haven't been putting much time towards pandas lately.\r\n\r\nOur review model is pretty informal and iterative, I get that it can be frustrating to address all the comments and not have a PR approved, but that's largely how it works, so I've found it helpful to have that as an expectation going in.\n\n@chris-b1, may you take a look at issue https://github.com/pandas-dev/pandas/pull/20480, please?\r\n\r\n@jreback requested your review there again and without you it can't be closed.\r\nThank you for your attention.\n\nThanks for resolving the read_excel return empty dataframe.\n\nThrowing my two cents in:\r\n\r\nhttps://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html\r\n\r\nSupporting lists of strings is not technically addressed in the documentation, so I'm a little hesitant to call this a bug as of the current version of `pandas` (`0.23.4`).\r\n\r\nThat being said, this issue does bring up a lot of questions re: how to handle `usecols` for `read_excel`, in particular, why its handling is so different from `usecols` for CSV:\r\n\r\n* Column ranges (e.g. `A:C`) - that's totally fine with me.  That's special to Excel.\r\n* \"If int then indicates last column to be parsed\" - We don't support this for CSV.  I don't see why we support this for Excel?\r\n* List-like support for Excel is pretty bad.  We don't support values like `usecols=[0, 1, 2]` or `usecols=['A', 'B', 'C']`, which I think we should.\r\n* We don't support callables for `usecols`, though I don't see why we shouldn't.\r\n\r\nWhat do you guys think?\n\nMy personal belief is that usecols should operate the same way that it does in read_csv and excel-specific behavior should be handled in a separate parameter (something to the effect of `use_range`). \r\n\r\nIt would require some deprecations from the current state but I think that logical separation would clarify any ambiguity between range \"A:A\" in Excel and a column named \"A\". \n\n> My personal belief is that usecols should operate the same way that it does in read_csv and excel-specific behavior should be handled in a separate parameter (something to the effect of use_range).\r\n\r\n@WillAyd : Not sure I fully agree with adding a new parameter, but at least we have consensus that `usecols` should be widely consistent across the board. 汨 \r\n\r\n@jreback @chris-b1 : Thoughts?",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/20480",
  "code_context": [
    {
      "filename": "pandas/io/excel.py",
      "content": "\"\"\"\nModule parse to/from Excel\n\"\"\"\n\n# ---------------------------------------------------------------------\n# ExcelFile class\nfrom datetime import datetime, date, time, MINYEAR, timedelta\n\nimport os\nimport abc\nimport warnings\nimport numpy as np\nimport string\nimport re\nfrom io import UnsupportedOperation\n\nfrom pandas.core.dtypes.common import (\n    is_integer, is_float,\n    is_bool, is_list_like)\n\nfrom pandas.core.frame import DataFrame\nfrom pandas.io.parsers import TextParser\nfrom pandas.errors import EmptyDataError\nfrom pandas.io.common import (_is_url, _urlopen, _validate_header_arg,\n                              get_filepath_or_buffer, _NA_VALUES,\n                              _stringify_path)\nimport pandas._libs.json as json\nfrom pandas.compat import (map, zip, reduce, range, lrange, u, add_metaclass,\n                           string_types, OrderedDict)\nfrom pandas.core import config\nfrom pandas.io.formats.printing import pprint_thing\nimport pandas.compat as compat\nfrom warnings import warn\nfrom distutils.version import LooseVersion\nfrom pandas.util._decorators import Appender, deprecate_kwarg\nfrom textwrap import fill\n\n__all__ = [\"read_excel\", \"ExcelWriter\", \"ExcelFile\"]\n\n_writer_extensions = [\"xlsx\", \"xls\", \"xlsm\"]\n_writers = {}\n\n_read_excel_doc = \"\"\"\nRead an Excel table into a pandas DataFrame\n\nParameters\n----------\nio : string, path object (pathlib.Path or py._path.local.LocalPath),\n    file-like object, pandas ExcelFile, or xlrd workbook.\n    The string could be a URL. Valid URL schemes include http, ftp, s3,\n    and file. For file URLs, a host is expected. For instance, a local\n    file could be file://localhost/path/to/workbook.xlsx\nsheet_name : string, int, mixed list of strings/ints, or None, default 0\n\n    Strings are used for sheet names, Integers are used in zero-indexed\n    sheet positions.\n\n    Lists of strings/integers are used to request multiple sheets.\n\n    Specify None to get all sheets.\n\n    str|int -> DataFrame is returned.\n    list|None -> Dict of DataFrames is returned, with keys representing\n    sheets.\n\n    Available Cases\n\n    * Defaults to 0 -> 1st sheet as a DataFrame\n    * 1 -> 2nd sheet as a DataFrame\n    * \"Sheet1\" -> 1st sheet as a DataFrame\n    * [0,1,\"Sheet5\"] -> 1st, 2nd & 5th sheet as a dictionary of DataFrames\n    * None -> All sheets as a dictionary of DataFrames\n\nsheetname : string, int, mixed list of strings/ints, or None, default 0\n\n    .. deprecated:: 0.21.0\n       Use `sheet_name` instead\n\nheader : int, list of ints, default 0\n    Row (0-indexed) to use for the column labels of the parsed\n    DataFrame. If a list of integers is passed those row positions will\n    be combined into a ``MultiIndex``. Use None if there is no header.\nnames : array-like, default None\n    List of column names to use. If file contains no header row,\n    then you should explicitly pass header=None\nindex_col : int, list of ints, default None\n    Column (0-indexed) to use as the row labels of the DataFrame.\n    Pass None if there is no such column.  If a list is passed,\n    those columns will be combined into a ``MultiIndex``.  If a\n    subset of data is selected with ``usecols_excel`` or ``usecols``,\n    index_col is based on the subset.\nparse_cols : int or list, default None\n\n    .. deprecated:: 0.21.0\n       Pass in `usecols` instead.\n\nusecols : list-like or callable, default None\n    Return a subset of the columns. If list-like, all elements must either\n    be positional (i.e. integer indices into the document columns) or string\n    that correspond to column names provided either by the user in `names` or\n    inferred from the document header row(s). For example, a valid list-like\n    `usecols` parameter would be [0, 1, 2] or ['foo', 'bar', 'baz']. Note that\n    you can not give both ``usecols`` and ``usecols_excel`` keyword arguments\n    at the same time.\n\n    If callable, the callable function will be evaluated against the column\n    names, returning names where the callable function evaluates to True. An\n    example of a valid callable argument would be ``lambda x: x.upper() in\n    ['AAA', 'BBB', 'DDD']``.\n\n    .. versionadded:: 0.24.0\n    Added support to column labels and now `usecols_excel` is the keyword that\n    receives separated comma list of excel columns and ranges.\nusecols_excel : string, default None\n    Return a subset of the columns from a spreadsheet specified as Excel column\n    ranges and columns. Note that you can not use both ``usecols`` and\n    ``usecols_excel`` keyword arguments at the same time.\n\n    * If None then parse all columns,\n    * If string then indicates comma separated list of Excel column letters and\n      column ranges (e.g. \"A:E\" or \"A,C,E:F\") to be parsed. Ranges are\n      inclusive of both sides.\n\n    .. versionadded:: 0.24.0\n\nsqueeze : boolean, default False\n    If the parsed data only contains one column then return a Series\ndtype : Type name or dict of column -> type, default None\n    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n    Use `object` to preserve data as stored in Excel and not interpret dtype.\n    If converters are specified, they will be applied INSTEAD\n    of dtype conversion.\n\n    .. versionadded:: 0.20.0\n\nengine: string, default None\n    If io is not a buffer or path, this must be set to identify io.\n    Acceptable values are None or xlrd\nconverters : dict, default None\n    Dict of functions for converting values in certain columns. Keys can\n    either be integers or column labels, values are functions that take one\n    input argument, the Excel cell content, and return the transformed\n    content.\ntrue_values : list, default None\n    Values to consider as True\n\n    .. versionadded:: 0.19.0\n\nfalse_values : list, default None\n    Values to consider as False\n\n    .. versionadded:: 0.19.0\n\nskiprows : list-like\n    Rows to skip at the beginning (0-indexed)\nnrows : int, default None\n    Number of rows to parse\n\n    .. versionadded:: 0.23.0\n\nna_values : scalar, str, list-like, or dict, default None\n    Additional strings to recognize as NA/NaN. If dict passed, specific\n    per-column NA values. By default the following values are interpreted\n    as NaN: '\"\"\" + fill(\"', '\".join(sorted(_NA_VALUES)), 70, subsequent_indent=\"    \") + \"\"\"'.\nkeep_default_na : bool, default True\n    If na_values are specified and keep_default_na is False the default NaN\n    values are overridden, otherwise they're appended to.\nverbose : boolean, default False\n    Indicate number of NA values placed in non-numeric columns\nthousands : str, default None\n    Thousands separator for parsing string columns to numeric.  Note that\n    this parameter is only necessary for columns stored as TEXT in Excel,\n    any numeric columns will automatically be parsed, regardless of display\n    format.\ncomment : str, default None\n    Comments out remainder of line. Pass a character or characters to this\n    argument to indicate comments in the input file. Any data between the\n    comment string and the end of the current line is ignored.\nskip_footer : int, default 0\n\n    .. deprecated:: 0.23.0\n       Pass in `skipfooter` instead.\nskipfooter : int, default 0\n    Rows at the end to skip (0-indexed)\nconvert_float : boolean, default True\n    convert integral floats to int (i.e., 1.0 --> 1). If False, all numeric\n    data will be read in as floats: Excel stores all numbers as floats\n    internally\n\nReturns\n-------\nparsed : DataFrame or Dict of DataFrames\n    DataFrame from the passed in Excel file.  See notes in sheet_name\n    argument for more information on when a Dict of Dataframes is returned.\n\nExamples\n--------\n\nAn example DataFrame written to a local file\n\n>>> df_out = pd.DataFrame([('string1', 1),\n...                        ('string2', 2),\n...                        ('string3', 3)],\n...                       columns=['Name', 'Value'])\n>>> df_out\n      Name  Value\n0  string1      1\n1  string2      2\n2  string3      3\n>>> df_out.to_excel('tmp.xlsx')\n\nThe file can be read using the file name as string or an open file object:\n\n>>> pd.read_excel('tmp.xlsx')\n      Name  Value\n0  string1      1\n1  string2      2\n2  string3      3\n\n>>> pd.read_excel(open('tmp.xlsx','rb'))\n      Name  Value\n0  string1      1\n1  string2      2\n2  string3      3\n\nIndex and header can be specified via the `index_col` and `header` arguments\n\n>>> pd.read_excel('tmp.xlsx', index_col=None, header=None)\n     0        1      2\n0  NaN     Name  Value\n1  0.0  string1      1\n2  1.0  string2      2\n3  2.0  string3      3\n\nColumn types are inferred but can be explicitly specified\n\n>>> pd.read_excel('tmp.xlsx', dtype={'Name':str, 'Value':float})\n      Name  Value\n0  string1    1.0\n1  string2    2.0\n2  string3    3.0\n\nTrue, False, and NA values, and thousands separators have defaults,\nbut can be explicitly specified, too. Supply the values you would like\nas strings or lists of strings!\n\n>>> pd.read_excel('tmp.xlsx',\n...               na_values=['string1', 'string2'])\n      Name  Value\n0      NaN      1\n1      NaN      2\n2  string3      3\n\nComment lines in the excel input file can be skipped using the `comment` kwarg\n\n>>> df = pd.DataFrame({'a': ['1', '#2'], 'b': ['2', '3']})\n>>> df.to_excel('tmp.xlsx', index=False)\n>>> pd.read_excel('tmp.xlsx')\n    a  b\n0   1  2\n1  #2  3\n\n>>> pd.read_excel('tmp.xlsx', comment='#')\n   a  b\n0  1  2\n\"\"\"\n\n\ndef register_writer(klass):\n    \"\"\"Adds engine to the excel writer registry. You must use this method to\n    integrate with ``to_excel``. Also adds config options for any new\n    ``supported_extensions`` defined on the writer.\"\"\"\n    if not compat.callable(klass):\n        raise ValueError(\"Can only register callables as engines\")\n    engine_name = klass.engine\n    _writers[engine_name] = klass\n    for ext in klass.supported_extensions:\n        if ext.startswith('.'):\n            ext = ext[1:]\n        if ext not in _writer_extensions:\n            config.register_option(\"io.excel.{ext}.writer\".format(ext=ext),\n                                   engine_name, validator=str)\n            _writer_extensions.append(ext)\n\n\ndef _get_default_writer(ext):\n    _default_writers = {'xlsx': 'openpyxl', 'xlsm': 'openpyxl', 'xls': 'xlwt'}\n    try:\n        import xlsxwriter  # noqa\n        _default_writers['xlsx'] = 'xlsxwriter'\n    except ImportError:\n        pass\n    return _default_writers[ext]\n\n\ndef _is_excel_columns_notation(columns):\n    \"\"\"\n    Receives a string and check if the string is a comma separated list of\n    Excel index columns and index ranges. An Excel range is a string with two\n    column indexes separated by ':').\n    \"\"\"\n    if isinstance(columns, compat.string_types) and all(\n       (x in string.ascii_letters) for x in re.split(r',|:', columns)):\n        return True\n\n    return False\n\n\ndef get_writer(engine_name):\n    try:\n        return _writers[engine_name]\n    except KeyError:\n        raise ValueError(\"No Excel writer '{engine}'\"\n                         .format(engine=engine_name))\n\n\n@Appender(_read_excel_doc)\n@deprecate_kwarg(\"parse_cols\", \"usecols\")\n@deprecate_kwarg(\"skip_footer\", \"skipfooter\")\ndef read_excel(io,\n               sheet_name=0,\n               header=0,\n               names=None,\n               index_col=None,\n               usecols=None,\n               usecols_excel=None,\n               squeeze=False,\n               dtype=None,\n               engine=None,\n               converters=None,\n               true_values=None,\n               false_values=None,\n               skiprows=None,\n               nrows=None,\n               na_values=None,\n               parse_dates=False,\n               date_parser=None,\n               thousands=None,\n               comment=None,\n               skipfooter=0,\n               convert_float=True,\n               **kwds):\n\n    if not isinstance(io, ExcelFile):\n        io = ExcelFile(io, engine=engine)\n\n    return io.parse(\n        sheet_name=sheet_name,\n        header=header,\n        names=names,\n        index_col=index_col,\n        usecols_excel=usecols_excel,\n        usecols=usecols,\n        squeeze=squeeze,\n        dtype=dtype,\n        converters=converters,\n        true_values=true_values,\n        false_values=false_values,\n        skiprows=skiprows,\n        nrows=nrows,\n        na_values=na_values,\n        parse_dates=parse_dates,\n        date_parser=date_parser,\n        thousands=thousands,\n        comment=comment,\n        skipfooter=skipfooter,\n        convert_float=convert_float,\n        **kwds)\n\n\nclass ExcelFile(object):\n    \"\"\"\n    Class for parsing tabular excel sheets into DataFrame objects.\n    Uses xlrd. See read_excel for more documentation\n\n    Parameters\n    ----------\n    io : string, path object (pathlib.Path or py._path.local.LocalPath),\n        file-like object or xlrd workbook\n        If a string or path object, expected to be a path to xls or xlsx file\n    engine: string, default None\n        If io is not a buffer or path, this must be set to identify io.\n        Acceptable values are None or xlrd\n    \"\"\"\n\n    def __init__(self, io, **kwds):\n\n        err_msg = \"Install xlrd >= 0.9.0 for Excel support\"\n\n        try:\n            import xlrd\n        except ImportError:\n            raise ImportError(err_msg)\n        else:\n            ver = tuple(map(int, xlrd.__VERSION__.split(\".\")[:2]))\n            if ver < (0, 9):  # pragma: no cover\n                raise ImportError(err_msg +\n                                  \". Current version \" + xlrd.__VERSION__)\n\n        # could be a str, ExcelFile, Book, etc.\n        self.io = io\n        # Always a string\n        self._io = _stringify_path(io)\n\n        engine = kwds.pop('engine', None)\n\n        if engine is not None and engine != 'xlrd':\n            raise ValueError(\"Unknown engine: {engine}\".format(engine=engine))\n\n        # If io is a url, want to keep the data as bytes so can't pass\n        # to get_filepath_or_buffer()\n        if _is_url(self._io):\n            io = _urlopen(self._io)\n        elif not isinstance(self.io, (ExcelFile, xlrd.Book)):\n            io, _, _, _ = get_filepath_or_buffer(self._io)\n\n        if engine == 'xlrd' and isinstance(io, xlrd.Book):\n            self.book = io\n        elif not isinstance(io, xlrd.Book) and hasattr(io, \"read\"):\n            # N.B. xlrd.Book has a read attribute too\n            if hasattr(io, 'seek'):\n                try:\n                    # GH 19779\n                    io.seek(0)\n                except UnsupportedOperation:\n                    # HTTPResponse does not support seek()\n                    # GH 20434\n                    pass\n\n            data = io.read()\n            self.book = xlrd.open_workbook(file_contents=data)\n        elif isinstance(self._io, compat.string_types):\n            self.book = xlrd.open_workbook(self._io)\n        else:\n            raise ValueError('Must explicitly set engine if not passing in'\n                             ' buffer or path for io.')\n\n    def __fspath__(self):\n        return self._io\n\n    def parse(self,\n              sheet_name=0,\n              header=0,\n              names=None,\n              index_col=None,\n              usecols=None,\n              usecols_excel=None,\n              squeeze=False,\n              converters=None,\n              true_values=None,\n              false_values=None,\n              skiprows=None,\n              nrows=None,\n              na_values=None,\n              parse_dates=False,\n              date_parser=None,\n              thousands=None,\n              comment=None,\n              skipfooter=0,\n              convert_float=True,\n              **kwds):\n        \"\"\"\n        Parse specified sheet(s) into a DataFrame\n\n        Equivalent to read_excel(ExcelFile, ...)  See the read_excel\n        docstring for more info on accepted parameters\n        \"\"\"\n\n        # Can't use _deprecate_kwarg since sheetname=None has a special meaning\n        if is_integer(sheet_name) and sheet_name == 0 and 'sheetname' in kwds:\n            warnings.warn(\"The `sheetname` keyword is deprecated, use \"\n                          \"`sheet_name` instead\", FutureWarning, stacklevel=2)\n            sheet_name = kwds.pop(\"sheetname\")\n        elif 'sheetname' in kwds:\n            raise TypeError(\"Cannot specify both `sheet_name` \"\n                            \"and `sheetname`. Use just `sheet_name`\")\n\n        return self._parse_excel(sheet_name=sheet_name,\n                                 header=header,\n                                 names=names,\n                                 index_col=index_col,\n                                 usecols_excel=usecols_excel,\n                                 usecols=usecols,\n                                 squeeze=squeeze,\n                                 converters=converters,\n                                 true_values=true_values,\n                                 false_values=false_values,\n                                 skiprows=skiprows,\n                                 nrows=nrows,\n                                 na_values=na_values,\n                                 parse_dates=parse_dates,\n                                 date_parser=date_parser,\n                                 thousands=thousands,\n                                 comment=comment,\n                                 skipfooter=skipfooter,\n                                 convert_float=convert_float,\n                                 **kwds)\n\n    def _should_parse(self, i, usecols_excel, usecols):\n\n        def _range2cols(areas):\n            \"\"\"\n            Convert comma separated list of column names and column ranges to a\n            list of 0-based column indexes.\n\n            >>> _range2cols('A:E')\n            [0, 1, 2, 3, 4]\n            >>> _range2cols('A,C,Z:AB')\n            [0, 2, 25, 26, 27]\n            \"\"\"\n            def _excel2num(x):\n                \"Convert Excel column name like 'AB' to 0-based column index\"\n                return reduce(lambda s, a: s * 26 + ord(a) - ord('A') + 1,\n                              x.upper().strip(), 0) - 1\n\n            cols = []\n            for rng in areas.split(','):\n                if ':' in rng:\n                    rng = rng.split(':')\n                    cols += lrange(_excel2num(rng[0]), _excel2num(rng[1]) + 1)\n                else:\n                    cols.append(_excel2num(rng))\n            return cols\n\n        # check if usecols_excel is a string that indicates a comma separated\n        # list of Excel column letters and column ranges\n        if isinstance(usecols_excel, compat.string_types):\n            return i in _range2cols(usecols_excel)\n\n        return True\n\n    def _parse_excel(self,\n                     sheet_name=0,\n                     header=0,\n                     names=None,\n                     index_col=None,\n                     usecols=None,\n                     usecols_excel=None,\n                     squeeze=False,\n                     dtype=None,\n                     true_values=None,\n                     false_values=None,\n                     skiprows=None,\n                     nrows=None,\n                     na_values=None,\n                     verbose=False,\n                     parse_dates=False,\n                     date_parser=None,\n                     thousands=None,\n                     comment=None,\n                     skipfooter=0,\n                     convert_float=True,\n                     **kwds):\n\n        _validate_header_arg(header)\n\n        if (usecols is not None) and (usecols_excel is not None):\n            raise ValueError(\"Cannot specify both `usecols` and \"\n                             \"`usecols_excel`. Choose one of them.\")\n\n        # Check if some string in usecols may be interpreted as a Excel\n        # range or positional column\n        elif _is_excel_columns_notation(usecols):\n            warnings.warn(\"The `usecols` keyword argument used to refer to \"\n                          \"Excel ranges and columns as strings was \"\n                          \"renamed to `usecols_excel`.\", UserWarning,\n                          stacklevel=3)\n            usecols_excel = usecols\n            usecols = None\n\n        elif (usecols_excel is not None) and not _is_excel_columns_notation(\n                usecols_excel):\n            raise TypeError(\"`usecols_excel` must be None or a string as a \"\n                            \"comma separeted Excel ranges and columns.\")\n\n        if 'chunksize' in kwds:\n            raise NotImplementedError(\"chunksize keyword of read_excel \"\n                                      \"is not implemented\")\n\n        if parse_dates is True and index_col is None:\n            warn(\"The 'parse_dates=True' keyword of read_excel was provided\"\n                 \" without an 'index_col' keyword value.\")\n\n        import xlrd\n        from xlrd import (xldate, XL_CELL_DATE,\n                          XL_CELL_ERROR, XL_CELL_BOOLEAN,\n                          XL_CELL_NUMBER)\n\n        epoch1904 = self.book.datemode\n\n        def _parse_cell(cell_contents, cell_typ):\n            \"\"\"converts the contents of the cell into a pandas\n               appropriate object\"\"\"\n\n            if cell_typ == XL_CELL_DATE:\n\n                if xlrd_0_9_3:\n                    # Use the newer xlrd datetime handling.\n                    try:\n                        cell_contents = \\\n                            xldate.xldate_as_datetime(cell_contents,\n                                                      epoch1904)\n                    except OverflowError:\n                        return cell_contents\n                    # Excel doesn't distinguish between dates and time,\n                    # so we treat dates on the epoch as times only.\n                    # Also, Excel supports 1900 and 1904 epochs.\n                    year = (cell_contents.timetuple())[0:3]\n                    if ((not epoch1904 and year == (1899, 12, 31)) or\n                            (epoch1904 and year == (1904, 1, 1))):\n                        cell_contents = time(cell_contents.hour,\n                                             cell_contents.minute,\n                                             cell_contents.second,\n                                             cell_contents.microsecond)\n                else:\n                    # Use the xlrd <= 0.9.2 date handling.\n                    try:\n                        dt = xldate.xldate_as_tuple(cell_contents, epoch1904)\n\n                    except xldate.XLDateTooLarge:\n                        return cell_contents\n\n                    if dt[0] < MINYEAR:\n                        cell_contents = time(*dt[3:])\n                    else:\n                        cell_contents = datetime(*dt)\n\n            elif cell_typ == XL_CELL_ERROR:\n                cell_contents = np.nan\n            elif cell_typ == XL_CELL_BOOLEAN:\n                cell_contents = bool(cell_contents)\n            elif convert_float and cell_typ == XL_CELL_NUMBER:\n                # GH5394 - Excel 'numbers' are always floats\n                # it's a minimal perf hit and less surprising\n                val = int(cell_contents)\n                if val == cell_contents:\n                    cell_contents = val\n            return cell_contents\n\n        # xlrd >= 0.9.3 can return datetime objects directly.\n        if LooseVersion(xlrd.__VERSION__) >= LooseVersion(\"0.9.3\"):\n            xlrd_0_9_3 = True\n        else:\n            xlrd_0_9_3 = False\n\n        ret_dict = False\n\n        # Keep sheetname to maintain backwards compatibility.\n        if isinstance(sheet_name, list):\n            sheets = sheet_name\n            ret_dict = True\n        elif sheet_name is None:\n            sheets = self.sheet_names\n            ret_dict = True\n        else:\n            sheets = [sheet_name]\n\n        # handle same-type duplicates.\n        sheets = list(OrderedDict.fromkeys(sheets).keys())\n\n        output = OrderedDict()\n\n        for asheetname in sheets:\n            if verbose:\n                print(\"Reading sheet {sheet}\".format(sheet=asheetname))\n\n            if isinstance(asheetname, compat.string_types):\n                sheet = self.book.sheet_by_name(asheetname)\n            else:  # assume an integer if not a string\n                sheet = self.book.sheet_by_index(asheetname)\n\n            data = []\n            should_parse = {}\n\n            for i in range(sheet.nrows):\n                row = []\n                for j, (value, typ) in enumerate(zip(sheet.row_values(i),\n                                                     sheet.row_types(i))):\n                    if ((usecols is not None) or (usecols_excel is not None) or\n                            (j not in should_parse)):\n                        should_parse[j] = self._should_parse(j, usecols_excel,\n                                                             usecols)\n\n                    if (((usecols_excel is None) and (usecols is None)) or\n                            should_parse[j]):\n                        row.append(_parse_cell(value, typ))\n                data.append(row)\n\n            if sheet.nrows == 0:\n                output[asheetname] = DataFrame()\n                continue\n\n            if is_list_like(header) and len(header) == 1:\n                header = header[0]\n\n            # forward fill and pull out names for MultiIndex column\n            header_names = None\n            if header is not None:\n                if is_list_like(header):\n                    header_names = []\n                    control_row = [True for x in data[0]]\n                    for row in header:\n                        if is_integer(skiprows):\n                            row += skiprows\n\n                        data[row], control_row = _fill_mi_header(\n                            data[row], control_row)\n                        header_name, data[row] = _pop_header_name(\n                            data[row], index_col)\n                        header_names.append(header_name)\n                else:\n                    data[header] = _trim_excel_header(data[header])\n\n            if is_list_like(index_col):\n                # forward fill values for MultiIndex index\n                if not is_list_like(header):\n                    offset = 1 + header\n                else:\n                    offset = 1 + max(header)\n\n                for col in index_col:\n                    last = data[offset][col]\n                    for row in range(offset + 1, len(data)):\n                        if data[row][col] == '' or data[row][col] is None:\n                            data[row][col] = last\n                        else:\n                            last = data[row][col]\n\n            has_index_names = is_list_like(header) and len(header) > 1\n\n            # GH 12292 : error when read one empty column from excel file\n            try:\n                parser = TextParser(data,\n                                    header=header,\n                                    index_col=index_col,\n                                    has_index_names=has_index_names,\n                                    squeeze=squeeze,\n                                    dtype=dtype,\n                                    true_values=true_values,\n                                    false_values=false_values,\n                                    usecols=usecols,\n                                    skiprows=skiprows,\n                                    nrows=nrows,\n                                    na_values=na_values,\n                                    parse_dates=parse_dates,\n                                    date_parser=date_parser,\n                                    thousands=thousands,\n                                    comment=comment,\n                                    skipfooter=skipfooter,\n                                    **kwds)\n\n                output[asheetname] = parser.read(nrows=nrows)\n                if names is not None:\n                    output[asheetname].columns = names\n                if not squeeze or isinstance(output[asheetname], DataFrame):\n                    output[asheetname].columns = output[\n                        asheetname].columns.set_names(header_names)\n            except EmptyDataError:\n                # No Data, return an empty DataFrame\n                output[asheetname] = DataFrame()\n\n        if ret_dict:\n            return output\n        else:\n            return output[asheetname]\n\n    @property\n    def sheet_names(self):\n        return self.book.sheet_names()\n\n    def close(self):\n        \"\"\"close io if necessary\"\"\"\n        if hasattr(self.io, 'close'):\n            self.io.close()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.close()\n\n\ndef _validate_freeze_panes(freeze_panes):\n    if freeze_panes is not None:\n        if (\n            len(freeze_panes) == 2 and\n            all(isinstance(item, int) for item in freeze_panes)\n        ):\n            return True\n\n        raise ValueError(\"freeze_panes must be of form (row, column)\"\n                         \" where row and column are integers\")\n\n    # freeze_panes wasn't specified, return False so it won't be applied\n    # to output sheet\n    return False\n\n\ndef _trim_excel_header(row):\n    # trim header row so auto-index inference works\n    # xlrd uses '' , openpyxl None\n    while len(row) > 0 and (row[0] == '' or row[0] is None):\n        row = row[1:]\n    return row\n\n\ndef _fill_mi_header(row, control_row):\n    \"\"\"Forward fills blank entries in row, but only inside the same parent index\n\n    Used for creating headers in Multiindex.\n    Parameters\n    ----------\n    row : list\n        List of items in a single row.\n    control_row : list of boolean\n        Helps to determine if particular column is in same parent index as the\n        previous value. Used to stop propagation of empty cells between\n        different indexes.\n\n    Returns\n    ----------\n    Returns changed row and control_row\n    \"\"\"\n    last = row[0]\n    for i in range(1, len(row)):\n        if not control_row[i]:\n            last = row[i]\n\n        if row[i] == '' or row[i] is None:\n            row[i] = last\n        else:\n            control_row[i] = False\n            last = row[i]\n\n    return row, control_row\n\n# fill blank if index_col not None\n\n\ndef _pop_header_name(row, index_col):\n    \"\"\" (header, new_data) for header rows in MultiIndex parsing\"\"\"\n    none_fill = lambda x: None if x == '' else x\n\n    if index_col is None:\n        # no index col specified, trim data for inference path\n        return none_fill(row[0]), row[1:]\n    else:\n        # pop out header name and fill w/ blank\n        i = index_col if not is_list_like(index_col) else max(index_col)\n        return none_fill(row[i]), row[:i] + [''] + row[i + 1:]\n\n\n@add_metaclass(abc.ABCMeta)\nclass ExcelWriter(object):\n    \"\"\"\n    Class for writing DataFrame objects into excel sheets, default is to use\n    xlwt for xls, openpyxl for xlsx.  See DataFrame.to_excel for typical usage.\n\n    Parameters\n    ----------\n    path : string\n        Path to xls or xlsx file.\n    engine : string (optional)\n        Engine to use for writing. If None, defaults to\n        ``io.excel.<extension>.writer``.  NOTE: can only be passed as a keyword\n        argument.\n    date_format : string, default None\n        Format string for dates written into Excel files (e.g. 'YYYY-MM-DD')\n    datetime_format : string, default None\n        Format string for datetime objects written into Excel files\n        (e.g. 'YYYY-MM-DD HH:MM:SS')\n\n    Notes\n    -----\n    For compatibility with CSV writers, ExcelWriter serializes lists\n    and dicts to strings before writing.\n    \"\"\"\n    # Defining an ExcelWriter implementation (see abstract methods for more...)\n\n    # - Mandatory\n    #   - ``write_cells(self, cells, sheet_name=None, startrow=0, startcol=0)``\n    #     --> called to write additional DataFrames to disk\n    #   - ``supported_extensions`` (tuple of supported extensions), used to\n    #      check that engine supports the given extension.\n    #   - ``engine`` - string that gives the engine name. Necessary to\n    #     instantiate class directly and bypass ``ExcelWriterMeta`` engine\n    #     lookup.\n    #   - ``save(self)`` --> called to save file to disk\n    # - Mostly mandatory (i.e. should at least exist)\n    #   - book, cur_sheet, path\n\n    # - Optional:\n    #   - ``__init__(self, path, engine=None, **kwargs)`` --> always called\n    #     with path as first argument.\n\n    # You also need to register the class with ``register_writer()``.\n    # Technically, ExcelWriter implementations don't need to subclass\n    # ExcelWriter.\n    def __new__(cls, path, engine=None, **kwargs):\n        # only switch class if generic(ExcelWriter)\n\n        if issubclass(cls, ExcelWriter):\n            if engine is None or (isinstance(engine, string_types) and\n                                  engine == 'auto'):\n                if isinstance(path, string_types):\n                    ext = os.path.splitext(path)[-1][1:]\n                else:\n                    ext = 'xlsx'\n\n                try:\n                    engine = config.get_option('io.excel.{ext}.writer'\n                                               .format(ext=ext))\n                    if engine == 'auto':\n                        engine = _get_default_writer(ext)\n                except KeyError:\n                    error = ValueError(\"No engine for filetype: '{ext}'\"\n                                       .format(ext=ext))\n                    raise error\n            cls = get_writer(engine)\n\n        return object.__new__(cls)\n\n    # declare external properties you can count on\n    book = None\n    curr_sheet = None\n    path = None\n\n    @abc.abstractproperty\n    def supported_extensions(self):\n        \"extensions that writer engine supports\"\n        pass\n\n    @abc.abstractproperty\n    def engine(self):\n        \"name of engine\"\n        pass\n\n    @abc.abstractmethod\n    def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0,\n                    freeze_panes=None):\n        \"\"\"\n        Write given formatted cells into Excel an excel sheet\n\n        Parameters\n        ----------\n        cells : generator\n            cell of formatted data to save to Excel sheet\n        sheet_name : string, default None\n            Name of Excel sheet, if None, then use self.cur_sheet\n        startrow: upper left cell row to dump data frame\n        startcol: upper left cell column to dump data frame\n        freeze_panes: integer tuple of length 2\n            contains the bottom-most row and right-most column to freeze\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def save(self):\n        \"\"\"\n        Save workbook to disk.\n        \"\"\"\n        pass\n\n    def __init__(self, path, engine=None,\n                 date_format=None, datetime_format=None, **engine_kwargs):\n        # validate that this engine can handle the extension\n        if isinstance(path, string_types):\n            ext = os.path.splitext(path)[-1]\n        else:\n            ext = 'xls' if engine == 'xlwt' else 'xlsx'\n\n        self.check_extension(ext)\n\n        self.path = path\n        self.sheets = {}\n        self.cur_sheet = None\n\n        if date_format is None:\n            self.date_format = 'YYYY-MM-DD'\n        else:\n            self.date_format = date_format\n        if datetime_format is None:\n            self.datetime_format = 'YYYY-MM-DD HH:MM:SS'\n        else:\n            self.datetime_format = datetime_format\n\n    def __fspath__(self):\n        return _stringify_path(self.path)\n\n    def _get_sheet_name(self, sheet_name):\n        if sheet_name is None:\n            sheet_name = self.cur_sheet\n        if sheet_name is None:  # pragma: no cover\n            raise ValueError('Must pass explicit sheet_name or set '\n                             'cur_sheet property')\n        return sheet_name\n\n    def _value_with_fmt(self, val):\n        \"\"\"Convert numpy types to Python types for the Excel writers.\n\n        Parameters\n        ----------\n        val : object\n            Value to be written into cells\n\n        Returns\n        -------\n        Tuple with the first element being the converted value and the second\n            being an optional format\n        \"\"\"\n        fmt = None\n\n        if is_integer(val):\n            val = int(val)\n        elif is_float(val):\n            val = float(val)\n        elif is_bool(val):\n            val = bool(val)\n        elif isinstance(val, datetime):\n            fmt = self.datetime_format\n        elif isinstance(val, date):\n            fmt = self.date_format\n        elif isinstance(val, timedelta):\n            val = val.total_seconds() / float(86400)\n            fmt = '0'\n        else:\n            val = compat.to_str(val)\n\n        return val, fmt\n\n    @classmethod\n    def check_extension(cls, ext):\n        \"\"\"checks that path's extension against the Writer's supported\n        extensions.  If it isn't supported, raises UnsupportedFiletypeError.\"\"\"\n        if ext.startswith('.'):\n            ext = ext[1:]\n        if not any(ext in extension for extension in cls.supported_extensions):\n            msg = (u(\"Invalid extension for engine '{engine}': '{ext}'\")\n                   .format(engine=pprint_thing(cls.engine),\n                           ext=pprint_thing(ext)))\n            raise ValueError(msg)\n        else:\n            return True\n\n    # Allow use as a contextmanager\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.close()\n\n    def close(self):\n        \"\"\"synonym for save, to make it more file-like\"\"\"\n        return self.save()\n\n\nclass _OpenpyxlWriter(ExcelWriter):\n    engine = 'openpyxl'\n    supported_extensions = ('.xlsx', '.xlsm')\n\n    def __init__(self, path, engine=None, **engine_kwargs):\n        # Use the openpyxl module as the Excel writer.\n        from openpyxl.workbook import Workbook\n\n        super(_OpenpyxlWriter, self).__init__(path, **engine_kwargs)\n\n        # Create workbook object with default optimized_write=True.\n        self.book = Workbook()\n\n        # Openpyxl 1.6.1 adds a dummy sheet. We remove it.\n        if self.book.worksheets:\n            try:\n                self.book.remove(self.book.worksheets[0])\n            except AttributeError:\n\n                # compat\n                self.book.remove_sheet(self.book.worksheets[0])\n\n    def save(self):\n        \"\"\"\n        Save workbook to disk.\n        \"\"\"\n        return self.book.save(self.path)\n\n    @classmethod\n    def _convert_to_style(cls, style_dict):\n        \"\"\"\n        converts a style_dict to an openpyxl style object\n        Parameters\n        ----------\n        style_dict: style dictionary to convert\n        \"\"\"\n\n        from openpyxl.style import Style\n        xls_style = Style()\n        for key, value in style_dict.items():\n            for nk, nv in value.items():\n                if key == \"borders\":\n                    (xls_style.borders.__getattribute__(nk)\n                     .__setattr__('border_style', nv))\n                else:\n                    xls_style.__getattribute__(key).__setattr__(nk, nv)\n\n        return xls_style\n\n    @classmethod\n    def _convert_to_style_kwargs(cls, style_dict):\n        \"\"\"\n        Convert a style_dict to a set of kwargs suitable for initializing\n        or updating-on-copy an openpyxl v2 style object\n        Parameters\n        ----------\n        style_dict : dict\n            A dict with zero or more of the following keys (or their synonyms).\n                'font'\n                'fill'\n                'border' ('borders')\n                'alignment'\n                'number_format'\n                'protection'\n        Returns\n        -------\n        style_kwargs : dict\n            A dict with the same, normalized keys as ``style_dict`` but each\n            value has been replaced with a native openpyxl style object of the\n            appropriate class.\n        \"\"\"\n\n        _style_key_map = {\n            'borders': 'border',\n        }\n\n        style_kwargs = {}\n        for k, v in style_dict.items():\n            if k in _style_key_map:\n                k = _style_key_map[k]\n            _conv_to_x = getattr(cls, '_convert_to_{k}'.format(k=k),\n                                 lambda x: None)\n            new_v = _conv_to_x(v)\n            if new_v:\n                style_kwargs[k] = new_v\n\n        return style_kwargs\n\n    @classmethod\n    def _convert_to_color(cls, color_spec):\n        \"\"\"\n        Convert ``color_spec`` to an openpyxl v2 Color object\n        Parameters\n        ----------\n        color_spec : str, dict\n            A 32-bit ARGB hex string, or a dict with zero or more of the\n            following keys.\n                'rgb'\n                'indexed'\n                'auto'\n                'theme'\n                'tint'\n                'index'\n                'type'\n        Returns\n        -------\n        color : openpyxl.styles.Color\n        \"\"\"\n\n        from openpyxl.styles import Color\n\n        if isinstance(color_spec, str):\n            return Color(color_spec)\n        else:\n            return Color(**color_spec)\n\n    @classmethod\n    def _convert_to_font(cls, font_dict):\n        \"\"\"\n        Convert ``font_dict`` to an openpyxl v2 Font object\n        Parameters\n        ----------\n        font_dict : dict\n            A dict with zero or more of the following keys (or their synonyms).\n                'name'\n                'size' ('sz')\n                'bold' ('b')\n                'italic' ('i')\n                'underline' ('u')\n                'strikethrough' ('strike')\n                'color'\n                'vertAlign' ('vertalign')\n                'charset'\n                'scheme'\n                'family'\n                'outline'\n                'shadow'\n                'condense'\n        Returns\n        -------\n        font : openpyxl.styles.Font\n        \"\"\"\n\n        from openpyxl.styles import Font\n\n        _font_key_map = {\n            'sz': 'size',\n            'b': 'bold',\n            'i': 'italic',\n            'u': 'underline',\n            'strike': 'strikethrough',\n            'vertalign': 'vertAlign',\n        }\n\n        font_kwargs = {}\n        for k, v in font_dict.items():\n            if k in _font_key_map:\n                k = _font_key_map[k]\n            if k == 'color':\n                v = cls._convert_to_color(v)\n            font_kwargs[k] = v\n\n        return Font(**font_kwargs)\n\n    @classmethod\n    def _convert_to_stop(cls, stop_seq):\n        \"\"\"\n        Convert ``stop_seq`` to a list of openpyxl v2 Color objects,\n        suitable for initializing the ``GradientFill`` ``stop`` parameter.\n        Parameters\n        ----------\n        stop_seq : iterable\n            An iterable that yields objects suitable for consumption by\n            ``_convert_to_color``.\n        Returns\n        -------\n        stop : list of openpyxl.styles.Color\n        \"\"\"\n\n        return map(cls._convert_to_color, stop_seq)\n\n    @classmethod\n    def _convert_to_fill(cls, fill_dict):\n        \"\"\"\n        Convert ``fill_dict`` to an openpyxl v2 Fill object\n        Parameters\n        ----------\n        fill_dict : dict\n            A dict with one or more of the following keys (or their synonyms),\n                'fill_type' ('patternType', 'patterntype')\n                'start_color' ('fgColor', 'fgcolor')\n                'end_color' ('bgColor', 'bgcolor')\n            or one or more of the following keys (or their synonyms).\n                'type' ('fill_type')\n                'degree'\n                'left'\n                'right'\n                'top'\n                'bottom'\n                'stop'\n        Returns\n        -------\n        fill : openpyxl.styles.Fill\n        \"\"\"\n\n        from openpyxl.styles import PatternFill, GradientFill\n\n        _pattern_fill_key_map = {\n            'patternType': 'fill_type',\n            'patterntype': 'fill_type',\n            'fgColor': 'start_color',\n            'fgcolor': 'start_color',\n            'bgColor': 'end_color',\n            'bgcolor': 'end_color',\n        }\n\n        _gradient_fill_key_map = {\n            'fill_type': 'type',\n        }\n\n        pfill_kwargs = {}\n        gfill_kwargs = {}\n        for k, v in fill_dict.items():\n            pk = gk = None\n            if k in _pattern_fill_key_map:\n                pk = _pattern_fill_key_map[k]\n            if k in _gradient_fill_key_map:\n                gk = _gradient_fill_key_map[k]\n            if pk in ['start_color', 'end_color']:\n                v = cls._convert_to_color(v)\n            if gk == 'stop':\n                v = cls._convert_to_stop(v)\n            if pk:\n                pfill_kwargs[pk] = v\n            elif gk:\n                gfill_kwargs[gk] = v\n            else:\n                pfill_kwargs[k] = v\n                gfill_kwargs[k] = v\n\n        try:\n            return PatternFill(**pfill_kwargs)\n        except TypeError:\n            return GradientFill(**gfill_kwargs)\n\n    @classmethod\n    def _convert_to_side(cls, side_spec):\n        \"\"\"\n        Convert ``side_spec`` to an openpyxl v2 Side object\n        Parameters\n        ----------\n        side_spec : str, dict\n            A string specifying the border style, or a dict with zero or more\n            of the following keys (or their synonyms).\n                'style' ('border_style')\n                'color'\n        Returns\n        -------\n        side : openpyxl.styles.Side\n        \"\"\"\n\n        from openpyxl.styles import Side\n\n        _side_key_map = {\n            'border_style': 'style',\n        }\n\n        if isinstance(side_spec, str):\n            return Side(style=side_spec)\n\n        side_kwargs = {}\n        for k, v in side_spec.items():\n            if k in _side_key_map:\n                k = _side_key_map[k]\n            if k == 'color':\n                v = cls._convert_to_color(v)\n            side_kwargs[k] = v\n\n        return Side(**side_kwargs)\n\n    @classmethod\n    def _convert_to_border(cls, border_dict):\n        \"\"\"\n        Convert ``border_dict`` to an openpyxl v2 Border object\n        Parameters\n        ----------\n        border_dict : dict\n            A dict with zero or more of the following keys (or their synonyms).\n                'left'\n                'right'\n                'top'\n                'bottom'\n                'diagonal'\n                'diagonal_direction'\n                'vertical'\n                'horizontal'\n                'diagonalUp' ('diagonalup')\n                'diagonalDown' ('diagonaldown')\n                'outline'\n        Returns\n        -------\n        border : openpyxl.styles.Border\n        \"\"\"\n\n        from openpyxl.styles import Border\n\n        _border_key_map = {\n            'diagonalup': 'diagonalUp',\n            'diagonaldown': 'diagonalDown',\n        }\n\n        border_kwargs = {}\n        for k, v in border_dict.items():\n            if k in _border_key_map:\n                k = _border_key_map[k]\n            if k == 'color':\n                v = cls._convert_to_color(v)\n            if k in ['left', 'right', 'top', 'bottom', 'diagonal']:\n                v = cls._convert_to_side(v)\n            border_kwargs[k] = v\n\n        return Border(**border_kwargs)\n\n    @classmethod\n    def _convert_to_alignment(cls, alignment_dict):\n        \"\"\"\n        Convert ``alignment_dict`` to an openpyxl v2 Alignment object\n        Parameters\n        ----------\n        alignment_dict : dict\n            A dict with zero or more of the following keys (or their synonyms).\n                'horizontal'\n                'vertical'\n                'text_rotation'\n                'wrap_text'\n                'shrink_to_fit'\n                'indent'\n        Returns\n        -------\n        alignment : openpyxl.styles.Alignment\n        \"\"\"\n\n        from openpyxl.styles import Alignment\n\n        return Alignment(**alignment_dict)\n\n    @classmethod\n    def _convert_to_number_format(cls, number_format_dict):\n        \"\"\"\n        Convert ``number_format_dict`` to an openpyxl v2.1.0 number format\n        initializer.\n        Parameters\n        ----------\n        number_format_dict : dict\n            A dict with zero or more of the following keys.\n                'format_code' : str\n        Returns\n        -------\n        number_format : str\n        \"\"\"\n        return number_format_dict['format_code']\n\n    @classmethod\n    def _convert_to_protection(cls, protection_dict):\n        \"\"\"\n        Convert ``protection_dict`` to an openpyxl v2 Protection object.\n        Parameters\n        ----------\n        protection_dict : dict\n            A dict with zero or more of the following keys.\n                'locked'\n                'hidden'\n        Returns\n        -------\n        \"\"\"\n\n        from openpyxl.styles import Protection\n\n        return Protection(**protection_dict)\n\n    def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0,\n                    freeze_panes=None):\n        # Write the frame cells using openpyxl.\n        sheet_name = self._get_sheet_name(sheet_name)\n\n        _style_cache = {}\n\n        if sheet_name in self.sheets:\n            wks = self.sheets[sheet_name]\n        else:\n            wks = self.book.create_sheet()\n            wks.title = sheet_name\n            self.sheets[sheet_name] = wks\n\n        if _validate_freeze_panes(freeze_panes):\n            wks.freeze_panes = wks.cell(row=freeze_panes[0] + 1,\n                                        column=freeze_panes[1] + 1)\n\n        for cell in cells:\n            xcell = wks.cell(\n                row=startrow + cell.row + 1,\n                column=startcol + cell.col + 1\n            )\n            xcell.value, fmt = self._value_with_fmt(cell.val)\n            if fmt:\n                xcell.number_format = fmt\n\n            style_kwargs = {}\n            if cell.style:\n                key = str(cell.style)\n                style_kwargs = _style_cache.get(key)\n                if style_kwargs is None:\n                    style_kwargs = self._convert_to_style_kwargs(cell.style)\n                    _style_cache[key] = style_kwargs\n\n            if style_kwargs:\n                for k, v in style_kwargs.items():\n                    setattr(xcell, k, v)\n\n            if cell.mergestart is not None and cell.mergeend is not None:\n\n                wks.merge_cells(\n                    start_row=startrow + cell.row + 1,\n                    start_column=startcol + cell.col + 1,\n                    end_column=startcol + cell.mergeend + 1,\n                    end_row=startrow + cell.mergestart + 1\n                )\n\n                # When cells are merged only the top-left cell is preserved\n                # The behaviour of the other cells in a merged range is\n                # undefined\n                if style_kwargs:\n                    first_row = startrow + cell.row + 1\n                    last_row = startrow + cell.mergestart + 1\n                    first_col = startcol + cell.col + 1\n                    last_col = startcol + cell.mergeend + 1\n\n                    for row in range(first_row, last_row + 1):\n                        for col in range(first_col, last_col + 1):\n                            if row == first_row and col == first_col:\n                                # Ignore first cell. It is already handled.\n                                continue\n                            xcell = wks.cell(column=col, row=row)\n                            for k, v in style_kwargs.items():\n                                setattr(xcell, k, v)\n\n\nregister_writer(_OpenpyxlWriter)\n\n\nclass _XlwtWriter(ExcelWriter):\n    engine = 'xlwt'\n    supported_extensions = ('.xls',)\n\n    def __init__(self, path, engine=None, encoding=None, **engine_kwargs):\n        # Use the xlwt module as the Excel writer.\n        import xlwt\n        engine_kwargs['engine'] = engine\n        super(_XlwtWriter, self).__init__(path, **engine_kwargs)\n\n        if encoding is None:\n            encoding = 'ascii'\n        self.book = xlwt.Workbook(encoding=encoding)\n        self.fm_datetime = xlwt.easyxf(num_format_str=self.datetime_format)\n        self.fm_date = xlwt.easyxf(num_format_str=self.date_format)\n\n    def save(self):\n        \"\"\"\n        Save workbook to disk.\n        \"\"\"\n        return self.book.save(self.path)\n\n    def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0,\n                    freeze_panes=None):\n        # Write the frame cells using xlwt.\n\n        sheet_name = self._get_sheet_name(sheet_name)\n\n        if sheet_name in self.sheets:\n            wks = self.sheets[sheet_name]\n        else:\n            wks = self.book.add_sheet(sheet_name)\n            self.sheets[sheet_name] = wks\n\n        if _validate_freeze_panes(freeze_panes):\n            wks.set_panes_frozen(True)\n            wks.set_horz_split_pos(freeze_panes[0])\n            wks.set_vert_split_pos(freeze_panes[1])\n\n        style_dict = {}\n\n        for cell in cells:\n            val, fmt = self._value_with_fmt(cell.val)\n\n            stylekey = json.dumps(cell.style)\n            if fmt:\n                stylekey += fmt\n\n            if stylekey in style_dict:\n                style = style_dict[stylekey]\n            else:\n                style = self._convert_to_style(cell.style, fmt)\n                style_dict[stylekey] = style\n\n            if cell.mergestart is not None and cell.mergeend is not None:\n                wks.write_merge(startrow + cell.row,\n                                startrow + cell.mergestart,\n                                startcol + cell.col,\n                                startcol + cell.mergeend,\n                                val, style)\n            else:\n                wks.write(startrow + cell.row,\n                          startcol + cell.col,\n                          val, style)\n\n    @classmethod\n    def _style_to_xlwt(cls, item, firstlevel=True, field_sep=',',\n                       line_sep=';'):\n        \"\"\"helper which recursively generate an xlwt easy style string\n        for example:\n\n            hstyle = {\"font\": {\"bold\": True},\n            \"border\": {\"top\": \"thin\",\n                    \"right\": \"thin\",\n                    \"bottom\": \"thin\",\n                    \"left\": \"thin\"},\n            \"align\": {\"horiz\": \"center\"}}\n            will be converted to\n            font: bold on; \\\n                    border: top thin, right thin, bottom thin, left thin; \\\n                    align: horiz center;\n        \"\"\"\n        if hasattr(item, 'items'):\n            if firstlevel:\n                it = [\"{key}: {val}\"\n                      .format(key=key, val=cls._style_to_xlwt(value, False))\n                      for key, value in item.items()]\n                out = \"{sep} \".format(sep=(line_sep).join(it))\n                return out\n            else:\n                it = [\"{key} {val}\"\n                      .format(key=key, val=cls._style_to_xlwt(value, False))\n                      for key, value in item.items()]\n                out = \"{sep} \".format(sep=(field_sep).join(it))\n                return out\n        else:\n            item = \"{item}\".format(item=item)\n            item = item.replace(\"True\", \"on\")\n            item = item.replace(\"False\", \"off\")\n            return item\n\n    @classmethod\n    def _convert_to_style(cls, style_dict, num_format_str=None):\n        \"\"\"\n        converts a style_dict to an xlwt style object\n        Parameters\n        ----------\n        style_dict: style dictionary to convert\n        num_format_str: optional number format string\n        \"\"\"\n        import xlwt\n\n        if style_dict:\n            xlwt_stylestr = cls._style_to_xlwt(style_dict)\n            style = xlwt.easyxf(xlwt_stylestr, field_sep=',', line_sep=';')\n        else:\n            style = xlwt.XFStyle()\n        if num_format_str is not None:\n            style.num_format_str = num_format_str\n\n        return style\n\n\nregister_writer(_XlwtWriter)\n\n\nclass _XlsxStyler(object):\n    # Map from openpyxl-oriented styles to flatter xlsxwriter representation\n    # Ordering necessary for both determinism and because some are keyed by\n    # prefixes of others.\n    STYLE_MAPPING = {\n        'font': [\n            (('name',), 'font_name'),\n            (('sz',), 'font_size'),\n            (('size',), 'font_size'),\n            (('color', 'rgb',), 'font_color'),\n            (('color',), 'font_color'),\n            (('b',), 'bold'),\n            (('bold',), 'bold'),\n            (('i',), 'italic'),\n            (('italic',), 'italic'),\n            (('u',), 'underline'),\n            (('underline',), 'underline'),\n            (('strike',), 'font_strikeout'),\n            (('vertAlign',), 'font_script'),\n            (('vertalign',), 'font_script'),\n        ],\n        'number_format': [\n            (('format_code',), 'num_format'),\n            ((), 'num_format',),\n        ],\n        'protection': [\n            (('locked',), 'locked'),\n            (('hidden',), 'hidden'),\n        ],\n        'alignment': [\n            (('horizontal',), 'align'),\n            (('vertical',), 'valign'),\n            (('text_rotation',), 'rotation'),\n            (('wrap_text',), 'text_wrap'),\n            (('indent',), 'indent'),\n            (('shrink_to_fit',), 'shrink'),\n        ],\n        'fill': [\n            (('patternType',), 'pattern'),\n            (('patterntype',), 'pattern'),\n            (('fill_type',), 'pattern'),\n            (('start_color', 'rgb',), 'fg_color'),\n            (('fgColor', 'rgb',), 'fg_color'),\n            (('fgcolor', 'rgb',), 'fg_color'),\n            (('start_color',), 'fg_color'),\n            (('fgColor',), 'fg_color'),\n            (('fgcolor',), 'fg_color'),\n            (('end_color', 'rgb',), 'bg_color'),\n            (('bgColor', 'rgb',), 'bg_color'),\n            (('bgcolor', 'rgb',), 'bg_color'),\n            (('end_color',), 'bg_color'),\n            (('bgColor',), 'bg_color'),\n            (('bgcolor',), 'bg_color'),\n        ],\n        'border': [\n            (('color', 'rgb',), 'border_color'),\n            (('color',), 'border_color'),\n            (('style',), 'border'),\n            (('top', 'color', 'rgb',), 'top_color'),\n            (('top', 'color',), 'top_color'),\n            (('top', 'style',), 'top'),\n            (('top',), 'top'),\n            (('right', 'color', 'rgb',), 'right_color'),\n            (('right', 'color',), 'right_color'),\n            (('right', 'style',), 'right'),\n            (('right',), 'right'),\n            (('bottom', 'color', 'rgb',), 'bottom_color'),\n            (('bottom', 'color',), 'bottom_color'),\n            (('bottom', 'style',), 'bottom'),\n            (('bottom',), 'bottom'),\n            (('left', 'color', 'rgb',), 'left_color'),\n            (('left', 'color',), 'left_color'),\n            (('left', 'style',), 'left'),\n            (('left',), 'left'),\n        ],\n    }\n\n    @classmethod\n    def convert(cls, style_dict, num_format_str=None):\n        \"\"\"\n        converts a style_dict to an xlsxwriter format dict\n\n        Parameters\n        ----------\n        style_dict: style dictionary to convert\n        num_format_str: optional number format string\n        \"\"\"\n\n        # Create a XlsxWriter format object.\n        props = {}\n\n        if num_format_str is not None:\n            props['num_format'] = num_format_str\n\n        if style_dict is None:\n            return props\n\n        if 'borders' in style_dict:\n            style_dict = style_dict.copy()\n            style_dict['border'] = style_dict.pop('borders')\n\n        for style_group_key, style_group in style_dict.items():\n            for src, dst in cls.STYLE_MAPPING.get(style_group_key, []):\n                # src is a sequence of keys into a nested dict\n                # dst is a flat key\n                if dst in props:\n                    continue\n                v = style_group\n                for k in src:\n                    try:\n                        v = v[k]\n                    except (KeyError, TypeError):\n                        break\n                else:\n                    props[dst] = v\n\n        if isinstance(props.get('pattern'), string_types):\n            # TODO: support other fill patterns\n            props['pattern'] = 0 if props['pattern'] == 'none' else 1\n\n        for k in ['border', 'top', 'right', 'bottom', 'left']:\n            if isinstance(props.get(k), string_types):\n                try:\n                    props[k] = ['none', 'thin', 'medium', 'dashed', 'dotted',\n                                'thick', 'double', 'hair', 'mediumDashed',\n                                'dashDot', 'mediumDashDot', 'dashDotDot',\n                                'mediumDashDotDot', 'slantDashDot'].\\\n                        index(props[k])\n                except ValueError:\n                    props[k] = 2\n\n        if isinstance(props.get('font_script'), string_types):\n            props['font_script'] = ['baseline', 'superscript', 'subscript'].\\\n                index(props['font_script'])\n\n        if isinstance(props.get('underline'), string_types):\n            props['underline'] = {'none': 0, 'single': 1, 'double': 2,\n                                  'singleAccounting': 33,\n                                  'doubleAccounting': 34}[props['underline']]\n\n        return props\n\n\nclass _XlsxWriter(ExcelWriter):\n    engine = 'xlsxwriter'\n    supported_extensions = ('.xlsx',)\n\n    def __init__(self, path, engine=None,\n                 date_format=None, datetime_format=None, **engine_kwargs):\n        # Use the xlsxwriter module as the Excel writer.\n        import xlsxwriter\n\n        super(_XlsxWriter, self).__init__(path, engine=engine,\n                                          date_format=date_format,\n                                          datetime_format=datetime_format,\n                                          **engine_kwargs)\n\n        self.book = xlsxwriter.Workbook(path, **engine_kwargs)\n\n    def save(self):\n        \"\"\"\n        Save workbook to disk.\n        \"\"\"\n\n        return self.book.close()\n\n    def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0,\n                    freeze_panes=None):\n        # Write the frame cells using xlsxwriter.\n        sheet_name = self._get_sheet_name(sheet_name)\n\n        if sheet_name in self.sheets:\n            wks = self.sheets[sheet_name]\n        else:\n            wks = self.book.add_worksheet(sheet_name)\n            self.sheets[sheet_name] = wks\n\n        style_dict = {'null': None}\n\n        if _validate_freeze_panes(freeze_panes):\n            wks.freeze_panes(*(freeze_panes))\n\n        for cell in cells:\n            val, fmt = self._value_with_fmt(cell.val)\n\n            stylekey = json.dumps(cell.style)\n            if fmt:\n                stylekey += fmt\n\n            if stylekey in style_dict:\n                style = style_dict[stylekey]\n            else:\n                style = self.book.add_format(\n                    _XlsxStyler.convert(cell.style, fmt))\n                style_dict[stylekey] = style\n\n            if cell.mergestart is not None and cell.mergeend is not None:\n                wks.merge_range(startrow + cell.row,\n                                startcol + cell.col,\n                                startrow + cell.mergestart,\n                                startcol + cell.mergeend,\n                                cell.val, style)\n            else:\n                wks.write(startrow + cell.row,\n                          startcol + cell.col,\n                          val, style)\n\n\nregister_writer(_XlsxWriter)\n"
    },
    {
      "filename": "pandas/tests/io/test_excel.py",
      "content": "# pylint: disable=E1101\nimport os\nimport warnings\nfrom datetime import datetime, date, time, timedelta\nfrom distutils.version import LooseVersion\nfrom functools import partial\nfrom warnings import catch_warnings\nfrom collections import OrderedDict\n\nimport numpy as np\nimport pytest\nfrom numpy import nan\n\nimport pandas as pd\nimport pandas.util.testing as tm\nimport pandas.util._test_decorators as td\nfrom pandas import DataFrame, Index, MultiIndex\nfrom pandas.compat import u, range, map, BytesIO, iteritems, PY36\nfrom pandas.core.config import set_option, get_option\nfrom pandas.io.common import URLError\nfrom pandas.io.excel import (\n    ExcelFile, ExcelWriter, read_excel, _XlwtWriter, _OpenpyxlWriter,\n    register_writer, _XlsxWriter\n)\nfrom pandas.io.formats.excel import ExcelFormatter\nfrom pandas.io.parsers import read_csv\nfrom pandas.util.testing import ensure_clean, makeCustomDataframe as mkdf\n\n\n_seriesd = tm.getSeriesData()\n_tsd = tm.getTimeSeriesData()\n_frame = DataFrame(_seriesd)[:10]\n_frame2 = DataFrame(_seriesd, columns=['D', 'C', 'B', 'A'])[:10]\n_tsframe = tm.makeTimeDataFrame()[:5]\n_mixed_frame = _frame.copy()\n_mixed_frame['foo'] = 'bar'\n\n\n@td.skip_if_no('xlrd', '0.9')\nclass SharedItems(object):\n\n    def setup_method(self, method):\n        self.dirpath = tm.get_data_path()\n        self.frame = _frame.copy()\n        self.frame2 = _frame2.copy()\n        self.tsframe = _tsframe.copy()\n        self.mixed_frame = _mixed_frame.copy()\n\n    def get_csv_refdf(self, basename):\n        \"\"\"\n        Obtain the reference data from read_csv with the Python engine.\n        Test data path is defined by pandas.util.testing.get_data_path()\n\n        Parameters\n        ----------\n\n        basename : str\n            File base name, excluding file extension.\n\n        Returns\n        -------\n\n        dfref : DataFrame\n        \"\"\"\n        pref = os.path.join(self.dirpath, basename + '.csv')\n        dfref = read_csv(pref, index_col=0, parse_dates=True, engine='python')\n        return dfref\n\n    def get_excelfile(self, basename, ext):\n        \"\"\"\n        Return test data ExcelFile instance. Test data path is defined by\n        pandas.util.testing.get_data_path()\n\n        Parameters\n        ----------\n\n        basename : str\n            File base name, excluding file extension.\n\n        Returns\n        -------\n\n        excel : io.excel.ExcelFile\n        \"\"\"\n        return ExcelFile(os.path.join(self.dirpath, basename + ext))\n\n    def get_exceldf(self, basename, ext, *args, **kwds):\n        \"\"\"\n        Return test data DataFrame. Test data path is defined by\n        pandas.util.testing.get_data_path()\n\n        Parameters\n        ----------\n\n        basename : str\n            File base name, excluding file extension.\n\n        Returns\n        -------\n\n        df : DataFrame\n        \"\"\"\n        pth = os.path.join(self.dirpath, basename + ext)\n        return read_excel(pth, *args, **kwds)\n\n\nclass ReadingTestsBase(SharedItems):\n    # This is based on ExcelWriterBase\n\n    def test_usecols_list(self, ext):\n\n        dfref = self.get_csv_refdf('test1')\n        dfref = dfref.reindex(columns=['B', 'C'])\n        df1 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0,\n                               usecols=[1, 2])\n        df2 = self.get_exceldf('test1', ext, 'Sheet2', skiprows=[1],\n                               index_col=0, usecols=[1, 2])\n\n        with tm.assert_produces_warning(FutureWarning):\n            df3 = self.get_exceldf('test1', ext, 'Sheet2', skiprows=[1],\n                                   index_col=0, parse_cols=[1, 2])\n\n        # TODO add index to xls file)\n        tm.assert_frame_equal(df1, dfref, check_names=False)\n        tm.assert_frame_equal(df2, dfref, check_names=False)\n        tm.assert_frame_equal(df3, dfref, check_names=False)\n\n    def test_usecols_excel_str(self, ext):\n\n        dfref = self.get_csv_refdf('test1')\n\n        df1 = dfref.reindex(columns=['A', 'B', 'C'])\n        df2 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0,\n                               usecols_excel='A:D')\n        df3 = self.get_exceldf('test1', ext, 'Sheet2', skiprows=[1],\n                               index_col=0, usecols_excel='A:D')\n\n        # The following code receives two warnings because FutureWarning is\n        # thrown when parse_cols is passed in read_excel and UserWarning is\n        # thrown when parse_cols (usecols) receives an comma separated list of\n        # Excel indexes and ranges\n        with tm.assert_produces_warning() as w:\n            df4 = self.get_exceldf('test1', ext, 'Sheet2', skiprows=[1],\n                                   index_col=0, parse_cols='A:D')\n            assert issubclass(w[0].category, FutureWarning)\n            assert issubclass(w[1].category, UserWarning)\n\n        # TODO add index to xls, read xls ignores index name ?\n        tm.assert_frame_equal(df2, df1, check_names=False)\n        tm.assert_frame_equal(df3, df1, check_names=False)\n        tm.assert_frame_equal(df4, df1, check_names=False)\n\n        df1 = dfref.reindex(columns=['B', 'C'])\n        df2 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0,\n                               usecols_excel='A,C,D')\n        df3 = self.get_exceldf('test1', ext, 'Sheet2', skiprows=[1],\n                               index_col=0, usecols_excel='A,C,D')\n        # TODO add index to xls file\n        tm.assert_frame_equal(df2, df1, check_names=False)\n        tm.assert_frame_equal(df3, df1, check_names=False)\n\n        df1 = dfref.reindex(columns=['B', 'C'])\n        df2 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0,\n                               usecols_excel='A,C:D')\n        df3 = self.get_exceldf('test1', ext, 'Sheet2', skiprows=[1],\n                               index_col=0, usecols_excel='A,C:D')\n        tm.assert_frame_equal(df2, df1, check_names=False)\n        tm.assert_frame_equal(df3, df1, check_names=False)\n\n    def test_usecols_diff_positional_int_columns_order(self, ext):\n\n        df1 = self.get_csv_refdf('test1')[['A', 'C']]\n\n        df2 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0,\n                               usecols=[0, 2])\n        df3 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0,\n                               usecols=[2, 0])\n\n        tm.assert_frame_equal(df2, df1, check_names=False)\n        tm.assert_frame_equal(df3, df2, check_names=False)\n\n    def test_usecols_diff_positional_str_columns_order(self, ext):\n\n        df1 = self.get_csv_refdf('test1')[['B', 'D']]\n\n        df2 = self.get_exceldf('test1', ext, 'Sheet1', usecols=['B', 'D'])\n        df3 = self.get_exceldf('test1', ext, 'Sheet1', usecols=['D', 'B'])\n\n        tm.assert_frame_equal(df2, df1, check_names=False)\n        tm.assert_frame_equal(df3, df1, check_names=False)\n\n    def test_read_excel_without_slicing(self, ext):\n\n        df1 = self.get_csv_refdf('test1')\n        df2 = self.get_exceldf('test1', ext, 'Sheet1')\n\n        tm.assert_frame_equal(df2, df1, check_names=False)\n\n    def test_pass_callable_argument(self, ext):\n\n        dfref = self.get_csv_refdf('test1')[['C', 'D']]\n\n        df1 = dfref.reindex(columns=['C', 'D'])\n        df2 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0,\n                               usecols=lambda x: x > 'B')\n        df3 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0,\n                               usecols_excel='A,D:E')\n\n        tm.assert_frame_equal(df2, df1, check_names=False)\n        tm.assert_frame_equal(df3, df1, check_names=False)\n\n    def test_usecols_deprecated_excel_range_str(self, ext):\n\n        dfref = self.get_csv_refdf('test1')[['B', 'C', 'D']]\n\n        df1 = dfref.reindex(columns=['C', 'D'])\n        df2 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0,\n                               usecols=['C', 'D'])\n        with tm.assert_produces_warning(UserWarning):\n            df3 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0,\n                                   usecols='A,D:E')\n\n        tm.assert_frame_equal(df2, df1, check_names=False)\n        tm.assert_frame_equal(df3, df1, check_names=False)\n\n    def test_index_col_label_error(self, ext):\n        msg = \"list indices must be integers.*, not str\"\n        with tm.assert_raises_regex(TypeError, msg):\n            self.get_exceldf('test1', ext, 'Sheet1', index_col=[\"A\"],\n                             usecols=[\"\", \"A\", \"C\"])\n\n    def test_pass_non_existent_column(self, ext):\n        msg = \"Usecols do not match columns, columns expected but not found: \"\n        \"['E']\"\n        with tm.assert_raises_regex(ValueError, msg):\n            self.get_exceldf('test1', ext, usecols=['E'])\n\n    def test_usecols_excel_wrong_type(self, ext):\n        msg = \"`usecols_excel` must be None or a string as a comma separeted \"\n        \" Excel ranges and columns.\"\n        with tm.assert_raises_regex(TypeError, msg):\n            self.get_exceldf('test1', ext, usecols_excel=1)\n\n    def test_usecols_wrong_type(self, ext):\n        msg = \"'usecols' must either be list-like of all strings, all unicode,\"\n        \" all integers or a callable.\"\n        with tm.assert_raises_regex(ValueError, msg):\n            self.get_exceldf('test1', ext, usecols='E1')\n\n    def test_usecols_and_usecols_excel_error(self, ext):\n        msg = \"Cannot specify both `usecols` and `usecols_excel`. Choose one\"\n        \" of them.\"\n        with tm.assert_raises_regex(ValueError, msg):\n            self.get_exceldf('test1', ext, usecols=[0, 2], usecols_excel=\"A:C\")\n\n    def test_excel_stop_iterator(self, ext):\n\n        parsed = self.get_exceldf('test2', ext, 'Sheet1')\n        expected = DataFrame([['aaaa', 'bbbbb']], columns=['Test', 'Test1'])\n        tm.assert_frame_equal(parsed, expected)\n\n    def test_excel_cell_error_na(self, ext):\n\n        parsed = self.get_exceldf('test3', ext, 'Sheet1')\n        expected = DataFrame([[np.nan]], columns=['Test'])\n        tm.assert_frame_equal(parsed, expected)\n\n    def test_excel_passes_na(self, ext):\n\n        excel = self.get_excelfile('test4', ext)\n\n        parsed = read_excel(excel, 'Sheet1', keep_default_na=False,\n                            na_values=['apple'])\n        expected = DataFrame([['NA'], [1], ['NA'], [np.nan], ['rabbit']],\n                             columns=['Test'])\n        tm.assert_frame_equal(parsed, expected)\n\n        parsed = read_excel(excel, 'Sheet1', keep_default_na=True,\n                            na_values=['apple'])\n        expected = DataFrame([[np.nan], [1], [np.nan], [np.nan], ['rabbit']],\n                             columns=['Test'])\n        tm.assert_frame_equal(parsed, expected)\n\n        # 13967\n        excel = self.get_excelfile('test5', ext)\n\n        parsed = read_excel(excel, 'Sheet1', keep_default_na=False,\n                            na_values=['apple'])\n        expected = DataFrame([['1.#QNAN'], [1], ['nan'], [np.nan], ['rabbit']],\n                             columns=['Test'])\n        tm.assert_frame_equal(parsed, expected)\n\n        parsed = read_excel(excel, 'Sheet1', keep_default_na=True,\n                            na_values=['apple'])\n        expected = DataFrame([[np.nan], [1], [np.nan], [np.nan], ['rabbit']],\n                             columns=['Test'])\n        tm.assert_frame_equal(parsed, expected)\n\n    def test_excel_table_sheet_by_index(self, ext):\n\n        excel = self.get_excelfile('test1', ext)\n        dfref = self.get_csv_refdf('test1')\n\n        df1 = read_excel(excel, 0, index_col=0)\n        df2 = read_excel(excel, 1, skiprows=[1], index_col=0)\n        tm.assert_frame_equal(df1, dfref, check_names=False)\n        tm.assert_frame_equal(df2, dfref, check_names=False)\n\n        df1 = excel.parse(0, index_col=0)\n        df2 = excel.parse(1, skiprows=[1], index_col=0)\n        tm.assert_frame_equal(df1, dfref, check_names=False)\n        tm.assert_frame_equal(df2, dfref, check_names=False)\n\n        df3 = read_excel(excel, 0, index_col=0, skipfooter=1)\n        tm.assert_frame_equal(df3, df1.iloc[:-1])\n\n        with tm.assert_produces_warning(FutureWarning, check_stacklevel=False):\n            df4 = read_excel(excel, 0, index_col=0, skip_footer=1)\n            tm.assert_frame_equal(df3, df4)\n\n        df3 = excel.parse(0, index_col=0, skipfooter=1)\n        tm.assert_frame_equal(df3, df1.iloc[:-1])\n\n        import xlrd\n        with pytest.raises(xlrd.XLRDError):\n            read_excel(excel, 'asdf')\n\n    def test_excel_table(self, ext):\n\n        dfref = self.get_csv_refdf('test1')\n\n        df1 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0)\n        df2 = self.get_exceldf('test1', ext, 'Sheet2', skiprows=[1],\n                               index_col=0)\n        # TODO add index to file\n        tm.assert_frame_equal(df1, dfref, check_names=False)\n        tm.assert_frame_equal(df2, dfref, check_names=False)\n\n        df3 = self.get_exceldf('test1', ext, 'Sheet1', index_col=0,\n                               skipfooter=1)\n        tm.assert_frame_equal(df3, df1.iloc[:-1])\n\n    def test_reader_special_dtypes(self, ext):\n\n        expected = DataFrame.from_dict(OrderedDict([\n            (\"IntCol\", [1, 2, -3, 4, 0]),\n            (\"FloatCol\", [1.25, 2.25, 1.83, 1.92, 0.0000000005]),\n            (\"BoolCol\", [True, False, True, True, False]),\n            (\"StrCol\", [1, 2, 3, 4, 5]),\n            # GH5394 - this is why convert_float isn't vectorized\n            (\"Str2Col\", [\"a\", 3, \"c\", \"d\", \"e\"]),\n            (\"DateCol\", [datetime(2013, 10, 30), datetime(2013, 10, 31),\n                         datetime(1905, 1, 1), datetime(2013, 12, 14),\n                         datetime(2015, 3, 14)])\n        ]))\n        basename = 'test_types'\n\n        # should read in correctly and infer types\n        actual = self.get_exceldf(basename, ext, 'Sheet1')\n        tm.assert_frame_equal(actual, expected)\n\n        # if not coercing number, then int comes in as float\n        float_expected = expected.copy()\n        float_expected[\"IntCol\"] = float_expected[\"IntCol\"].astype(float)\n        float_expected.loc[float_expected.index[1], \"Str2Col\"] = 3.0\n        actual = self.get_exceldf(basename, ext, 'Sheet1', convert_float=False)\n        tm.assert_frame_equal(actual, float_expected)\n\n        # check setting Index (assuming xls and xlsx are the same here)\n        for icol, name in enumerate(expected.columns):\n            actual = self.get_exceldf(basename, ext, 'Sheet1', index_col=icol)\n            exp = expected.set_index(name)\n            tm.assert_frame_equal(actual, exp)\n\n        # convert_float and converters should be different but both accepted\n        expected[\"StrCol\"] = expected[\"StrCol\"].apply(str)\n        actual = self.get_exceldf(\n            basename, ext, 'Sheet1', converters={\"StrCol\": str})\n        tm.assert_frame_equal(actual, expected)\n\n        no_convert_float = float_expected.copy()\n        no_convert_float[\"StrCol\"] = no_convert_float[\"StrCol\"].apply(str)\n        actual = self.get_exceldf(basename, ext, 'Sheet1', convert_float=False,\n                                  converters={\"StrCol\": str})\n        tm.assert_frame_equal(actual, no_convert_float)\n\n    # GH8212 - support for converters and missing values\n    def test_reader_converters(self, ext):\n\n        basename = 'test_converters'\n\n        expected = DataFrame.from_dict(OrderedDict([\n            (\"IntCol\", [1, 2, -3, -1000, 0]),\n            (\"FloatCol\", [12.5, np.nan, 18.3, 19.2, 0.000000005]),\n            (\"BoolCol\", ['Found', 'Found', 'Found', 'Not found', 'Found']),\n            (\"StrCol\", ['1', np.nan, '3', '4', '5']),\n        ]))\n\n        converters = {'IntCol': lambda x: int(x) if x != '' else -1000,\n                      'FloatCol': lambda x: 10 * x if x else np.nan,\n                      2: lambda x: 'Found' if x != '' else 'Not found',\n                      3: lambda x: str(x) if x else '',\n                      }\n\n        # should read in correctly and set types of single cells (not array\n        # dtypes)\n        actual = self.get_exceldf(basename, ext, 'Sheet1',\n                                  converters=converters)\n        tm.assert_frame_equal(actual, expected)\n\n    def test_reader_dtype(self, ext):\n        # GH 8212\n        basename = 'testdtype'\n        actual = self.get_exceldf(basename, ext)\n\n        expected = DataFrame({\n            'a': [1, 2, 3, 4],\n            'b': [2.5, 3.5, 4.5, 5.5],\n            'c': [1, 2, 3, 4],\n            'd': [1.0, 2.0, np.nan, 4.0]}).reindex(\n                columns=['a', 'b', 'c', 'd'])\n\n        tm.assert_frame_equal(actual, expected)\n\n        actual = self.get_exceldf(basename, ext,\n                                  dtype={'a': 'float64',\n                                         'b': 'float32',\n                                         'c': str})\n\n        expected['a'] = expected['a'].astype('float64')\n        expected['b'] = expected['b'].astype('float32')\n        expected['c'] = ['001', '002', '003', '004']\n        tm.assert_frame_equal(actual, expected)\n\n        with pytest.raises(ValueError):\n            actual = self.get_exceldf(basename, ext, dtype={'d': 'int64'})\n\n    def test_reading_all_sheets(self, ext):\n        # Test reading all sheetnames by setting sheetname to None,\n        # Ensure a dict is returned.\n        # See PR #9450\n        basename = 'test_multisheet'\n        dfs = self.get_exceldf(basename, ext, sheet_name=None)\n        # ensure this is not alphabetical to test order preservation\n        expected_keys = ['Charlie', 'Alpha', 'Beta']\n        tm.assert_contains_all(expected_keys, dfs.keys())\n        # Issue 9930\n        # Ensure sheet order is preserved\n        assert expected_keys == list(dfs.keys())\n\n    def test_reading_multiple_specific_sheets(self, ext):\n        # Test reading specific sheetnames by specifying a mixed list\n        # of integers and strings, and confirm that duplicated sheet\n        # references (positions/names) are removed properly.\n        # Ensure a dict is returned\n        # See PR #9450\n        basename = 'test_multisheet'\n        # Explicitly request duplicates. Only the set should be returned.\n        expected_keys = [2, 'Charlie', 'Charlie']\n        dfs = self.get_exceldf(basename, ext, sheet_name=expected_keys)\n        expected_keys = list(set(expected_keys))\n        tm.assert_contains_all(expected_keys, dfs.keys())\n        assert len(expected_keys) == len(dfs.keys())\n\n    def test_reading_all_sheets_with_blank(self, ext):\n        # Test reading all sheetnames by setting sheetname to None,\n        # In the case where some sheets are blank.\n        # Issue #11711\n        basename = 'blank_with_header'\n        dfs = self.get_exceldf(basename, ext, sheet_name=None)\n        expected_keys = ['Sheet1', 'Sheet2', 'Sheet3']\n        tm.assert_contains_all(expected_keys, dfs.keys())\n\n    # GH6403\n    def test_read_excel_blank(self, ext):\n        actual = self.get_exceldf('blank', ext, 'Sheet1')\n        tm.assert_frame_equal(actual, DataFrame())\n\n    def test_read_excel_blank_with_header(self, ext):\n        expected = DataFrame(columns=['col_1', 'col_2'])\n        actual = self.get_exceldf('blank_with_header', ext, 'Sheet1')\n        tm.assert_frame_equal(actual, expected)\n\n    @td.skip_if_no('openpyxl')\n    @td.skip_if_no('xlwt')\n    # GH 12292 : error when read one empty column from excel file\n    def test_read_one_empty_col_no_header(self, ext):\n        df = pd.DataFrame(\n            [[\"\", 1, 100],\n             [\"\", 2, 200],\n             [\"\", 3, 300],\n             [\"\", 4, 400]]\n        )\n        with ensure_clean(ext) as path:\n            df.to_excel(path, 'no_header', index=False, header=False)\n            actual_header_none = read_excel(\n                path,\n                'no_header',\n                usecols=[0],\n                header=None,\n                nrows=0\n            )\n\n            actual_header_zero = read_excel(\n                path,\n                'no_header',\n                usecols=[0],\n                header=0\n            )\n        expected_header_none = DataFrame(columns=[0])\n        tm.assert_frame_equal(actual_header_none, expected_header_none)\n        expected_header_zero = DataFrame({1: [2, 3, 4]}, index=3 * [np.nan])\n        tm.assert_frame_equal(actual_header_zero, expected_header_zero)\n\n    @td.skip_if_no('openpyxl')\n    @td.skip_if_no('xlwt')\n    def test_read_one_empty_col_with_header(self, ext):\n        df = pd.DataFrame(\n            [[\"\", 1, 100],\n             [\"\", 2, 200],\n             [\"\", 3, 300],\n             [\"\", 4, 400]]\n        )\n        with ensure_clean(ext) as path:\n            df.to_excel(path, 'with_header', index=False, header=True)\n            actual_header_none = read_excel(\n                path,\n                'with_header',\n                usecols=[0],\n                header=None,\n                nrows=1\n            )\n\n            actual_header_zero = read_excel(\n                path,\n                'with_header',\n                usecols=[0],\n                header=0\n            )\n        expected_header_none = DataFrame(pd.Series([0], dtype='int64'))\n        tm.assert_frame_equal(actual_header_none, expected_header_none)\n        expected_header_zero = DataFrame(pd.Series(4 * [np.nan]))\n        tm.assert_frame_equal(actual_header_zero, expected_header_zero)\n\n    @td.skip_if_no('openpyxl')\n    @td.skip_if_no('xlwt')\n    def test_set_column_names_in_parameter(self, ext):\n        # GH 12870 : pass down column names associated with\n        # keyword argument names\n        refdf = pd.DataFrame([[1, 'foo'], [2, 'bar'],\n                              [3, 'baz']], columns=['a', 'b'])\n\n        with ensure_clean(ext) as pth:\n            with ExcelWriter(pth) as writer:\n                refdf.to_excel(writer, 'Data_no_head',\n                               header=False, index=False)\n                refdf.to_excel(writer, 'Data_with_head', index=False)\n\n            refdf.columns = ['A', 'B']\n\n            with ExcelFile(pth) as reader:\n                xlsdf_no_head = read_excel(reader, 'Data_no_head',\n                                           header=None, names=['A', 'B'])\n                xlsdf_with_head = read_excel(reader, 'Data_with_head',\n                                             index_col=None, names=['A', 'B'])\n\n            tm.assert_frame_equal(xlsdf_no_head, refdf)\n            tm.assert_frame_equal(xlsdf_with_head, refdf)\n\n    def test_date_conversion_overflow(self, ext):\n        # GH 10001 : pandas.ExcelFile ignore parse_dates=False\n        expected = pd.DataFrame([[pd.Timestamp('2016-03-12'), 'Marc Johnson'],\n                                 [pd.Timestamp('2016-03-16'), 'Jack Black'],\n                                 [1e+20, 'Timothy Brown']],\n                                columns=['DateColWithBigInt', 'StringCol'])\n\n        result = self.get_exceldf('testdateoverflow', ext)\n        tm.assert_frame_equal(result, expected)\n\n    def test_sheet_name_and_sheetname(self, ext):\n        # GH10559: Minor improvement: Change \"sheet_name\" to \"sheetname\"\n        # GH10969: DOC: Consistent var names (sheetname vs sheet_name)\n        # GH12604: CLN GH10559 Rename sheetname variable to sheet_name\n        dfref = self.get_csv_refdf('test1')\n        df1 = self.get_exceldf('test1', ext, sheet_name='Sheet1')    # doc\n        with tm.assert_produces_warning(FutureWarning, check_stacklevel=False):\n            df2 = self.get_exceldf('test1', ext,\n                                   sheetname='Sheet1')  # bkwrd compat\n\n        tm.assert_frame_equal(df1, dfref, check_names=False)\n        tm.assert_frame_equal(df2, dfref, check_names=False)\n\n    def test_sheet_name_both_raises(self, ext):\n        with tm.assert_raises_regex(TypeError, \"Cannot specify both\"):\n            self.get_exceldf('test1', ext, sheetname='Sheet1',\n                             sheet_name='Sheet1')\n\n\n@pytest.mark.parametrize(\"ext\", ['.xls', '.xlsx', '.xlsm'])\nclass TestXlrdReader(ReadingTestsBase):\n    \"\"\"\n    This is the base class for the xlrd tests, and 3 different file formats\n    are supported: xls, xlsx, xlsm\n    \"\"\"\n\n    def test_excel_read_buffer(self, ext):\n\n        pth = os.path.join(self.dirpath, 'test1' + ext)\n        expected = read_excel(pth, 'Sheet1', index_col=0)\n        with open(pth, 'rb') as f:\n            actual = read_excel(f, 'Sheet1', index_col=0)\n            tm.assert_frame_equal(expected, actual)\n\n        with open(pth, 'rb') as f:\n            xls = ExcelFile(f)\n            actual = read_excel(xls, 'Sheet1', index_col=0)\n            tm.assert_frame_equal(expected, actual)\n\n    @td.skip_if_no('xlwt')\n    def test_read_xlrd_Book(self, ext):\n        import xlrd\n\n        df = self.frame\n        with ensure_clean('.xls') as pth:\n            df.to_excel(pth, \"SheetA\")\n            book = xlrd.open_workbook(pth)\n\n            with ExcelFile(book, engine=\"xlrd\") as xl:\n                result = read_excel(xl, \"SheetA\")\n                tm.assert_frame_equal(df, result)\n\n            result = read_excel(book, sheet_name=\"SheetA\", engine=\"xlrd\")\n            tm.assert_frame_equal(df, result)\n\n    @tm.network\n    def test_read_from_http_url(self, ext):\n        url = ('https://raw.github.com/pandas-dev/pandas/master/'\n               'pandas/tests/io/data/test1' + ext)\n        url_table = read_excel(url)\n        local_table = self.get_exceldf('test1', ext)\n        tm.assert_frame_equal(url_table, local_table)\n\n    @td.skip_if_no('s3fs')\n    def test_read_from_s3_url(self, ext):\n        boto3 = pytest.importorskip('boto3')\n        moto = pytest.importorskip('moto')\n\n        with moto.mock_s3():\n            conn = boto3.resource(\"s3\", region_name=\"us-east-1\")\n            conn.create_bucket(Bucket=\"pandas-test\")\n            file_name = os.path.join(self.dirpath, 'test1' + ext)\n            with open(file_name, 'rb') as f:\n                conn.Bucket(\"pandas-test\").put_object(Key=\"test1\" + ext,\n                                                      Body=f)\n\n            url = ('s3://pandas-test/test1' + ext)\n            url_table = read_excel(url)\n            local_table = self.get_exceldf('test1', ext)\n            tm.assert_frame_equal(url_table, local_table)\n\n    @pytest.mark.slow\n    def test_read_from_file_url(self, ext):\n\n        # FILE\n        localtable = os.path.join(self.dirpath, 'test1' + ext)\n        local_table = read_excel(localtable)\n\n        try:\n            url_table = read_excel('file://localhost/' + localtable)\n        except URLError:\n            # fails on some systems\n            import platform\n            pytest.skip(\"failing on %s\" %\n                        ' '.join(platform.uname()).strip())\n\n        tm.assert_frame_equal(url_table, local_table)\n\n    @td.skip_if_no('pathlib')\n    def test_read_from_pathlib_path(self, ext):\n\n        # GH12655\n        from pathlib import Path\n\n        str_path = os.path.join(self.dirpath, 'test1' + ext)\n        expected = read_excel(str_path, 'Sheet1', index_col=0)\n\n        path_obj = Path(self.dirpath, 'test1' + ext)\n        actual = read_excel(path_obj, 'Sheet1', index_col=0)\n\n        tm.assert_frame_equal(expected, actual)\n\n    @td.skip_if_no('py.path')\n    def test_read_from_py_localpath(self, ext):\n\n        # GH12655\n        from py.path import local as LocalPath\n\n        str_path = os.path.join(self.dirpath, 'test1' + ext)\n        expected = read_excel(str_path, 'Sheet1', index_col=0)\n\n        abs_dir = os.path.abspath(self.dirpath)\n        path_obj = LocalPath(abs_dir).join('test1' + ext)\n        actual = read_excel(path_obj, 'Sheet1', index_col=0)\n\n        tm.assert_frame_equal(expected, actual)\n\n    def test_reader_closes_file(self, ext):\n\n        pth = os.path.join(self.dirpath, 'test1' + ext)\n        f = open(pth, 'rb')\n        with ExcelFile(f) as xlsx:\n            # parses okay\n            read_excel(xlsx, 'Sheet1', index_col=0)\n\n        assert f.closed\n\n    @td.skip_if_no('openpyxl')\n    @td.skip_if_no('xlwt')\n    def test_creating_and_reading_multiple_sheets(self, ext):\n        # Test reading multiple sheets, from a runtime created excel file\n        # with multiple sheets.\n        # See PR #9450\n        def tdf(sheetname):\n            d, i = [11, 22, 33], [1, 2, 3]\n            return DataFrame(d, i, columns=[sheetname])\n\n        sheets = ['AAA', 'BBB', 'CCC']\n\n        dfs = [tdf(s) for s in sheets]\n        dfs = dict(zip(sheets, dfs))\n\n        with ensure_clean(ext) as pth:\n            with ExcelWriter(pth) as ew:\n                for sheetname, df in iteritems(dfs):\n                    df.to_excel(ew, sheetname)\n            dfs_returned = read_excel(pth, sheet_name=sheets)\n            for s in sheets:\n                tm.assert_frame_equal(dfs[s], dfs_returned[s])\n\n    def test_reader_seconds(self, ext):\n        import xlrd\n\n        # Test reading times with and without milliseconds. GH5945.\n        if LooseVersion(xlrd.__VERSION__) >= LooseVersion(\"0.9.3\"):\n            # Xlrd >= 0.9.3 can handle Excel milliseconds.\n            expected = DataFrame.from_dict({\"Time\": [time(1, 2, 3),\n                                            time(2, 45, 56, 100000),\n                                            time(4, 29, 49, 200000),\n                                            time(6, 13, 42, 300000),\n                                            time(7, 57, 35, 400000),\n                                            time(9, 41, 28, 500000),\n                                            time(11, 25, 21, 600000),\n                                            time(13, 9, 14, 700000),\n                                            time(14, 53, 7, 800000),\n                                            time(16, 37, 0, 900000),\n                                            time(18, 20, 54)]})\n        else:\n            # Xlrd < 0.9.3 rounds Excel milliseconds.\n            expected = DataFrame.from_dict({\"Time\": [time(1, 2, 3),\n                                            time(2, 45, 56),\n                                            time(4, 29, 49),\n                                            time(6, 13, 42),\n                                            time(7, 57, 35),\n                                            time(9, 41, 29),\n                                            time(11, 25, 22),\n                                            time(13, 9, 15),\n                                            time(14, 53, 8),\n                                            time(16, 37, 1),\n                                            time(18, 20, 54)]})\n\n        actual = self.get_exceldf('times_1900', ext, 'Sheet1')\n        tm.assert_frame_equal(actual, expected)\n\n        actual = self.get_exceldf('times_1904', ext, 'Sheet1')\n        tm.assert_frame_equal(actual, expected)\n\n    def test_read_excel_multiindex(self, ext):\n        # GH 4679\n        mi = MultiIndex.from_product([['foo', 'bar'], ['a', 'b']])\n        mi_file = os.path.join(self.dirpath, 'testmultiindex' + ext)\n\n        expected = DataFrame([[1, 2.5, pd.Timestamp('2015-01-01'), True],\n                              [2, 3.5, pd.Timestamp('2015-01-02'), False],\n                              [3, 4.5, pd.Timestamp('2015-01-03'), False],\n                              [4, 5.5, pd.Timestamp('2015-01-04'), True]],\n                             columns=mi)\n\n        actual = read_excel(mi_file, 'mi_column', header=[0, 1])\n        tm.assert_frame_equal(actual, expected)\n        actual = read_excel(mi_file, 'mi_column', header=[0, 1], index_col=0)\n        tm.assert_frame_equal(actual, expected)\n\n        expected.columns = ['a', 'b', 'c', 'd']\n        expected.index = mi\n        actual = read_excel(mi_file, 'mi_index', index_col=[0, 1])\n        tm.assert_frame_equal(actual, expected, check_names=False)\n\n        expected.columns = mi\n        actual = read_excel(mi_file, 'both', index_col=[0, 1], header=[0, 1])\n        tm.assert_frame_equal(actual, expected, check_names=False)\n\n        expected.index = mi.set_names(['ilvl1', 'ilvl2'])\n        expected.columns = ['a', 'b', 'c', 'd']\n        actual = read_excel(mi_file, 'mi_index_name', index_col=[0, 1])\n        tm.assert_frame_equal(actual, expected)\n\n        expected.index = list(range(4))\n        expected.columns = mi.set_names(['c1', 'c2'])\n        actual = read_excel(mi_file, 'mi_column_name',\n                            header=[0, 1], index_col=0)\n        tm.assert_frame_equal(actual, expected)\n\n        # Issue #11317\n        expected.columns = mi.set_levels(\n            [1, 2], level=1).set_names(['c1', 'c2'])\n        actual = read_excel(mi_file, 'name_with_int',\n                            index_col=0, header=[0, 1])\n        tm.assert_frame_equal(actual, expected)\n\n        expected.columns = mi.set_names(['c1', 'c2'])\n        expected.index = mi.set_names(['ilvl1', 'ilvl2'])\n        actual = read_excel(mi_file, 'both_name',\n                            index_col=[0, 1], header=[0, 1])\n        tm.assert_frame_equal(actual, expected)\n\n        actual = read_excel(mi_file, 'both_name',\n                            index_col=[0, 1], header=[0, 1])\n        tm.assert_frame_equal(actual, expected)\n\n        actual = read_excel(mi_file, 'both_name_skiprows', index_col=[0, 1],\n                            header=[0, 1], skiprows=2)\n        tm.assert_frame_equal(actual, expected)\n\n    @td.skip_if_no('xlsxwriter')\n    def test_read_excel_multiindex_empty_level(self, ext):\n        # GH 12453\n        with ensure_clean('.xlsx') as path:\n            df = DataFrame({\n                ('One', 'x'): {0: 1},\n                ('Two', 'X'): {0: 3},\n                ('Two', 'Y'): {0: 7},\n                ('Zero', ''): {0: 0}\n            })\n\n            expected = DataFrame({\n                ('One', u'x'): {0: 1},\n                ('Two', u'X'): {0: 3},\n                ('Two', u'Y'): {0: 7},\n                ('Zero', 'Unnamed: 3_level_1'): {0: 0}\n            })\n\n            df.to_excel(path)\n            actual = pd.read_excel(path, header=[0, 1])\n            tm.assert_frame_equal(actual, expected)\n\n            df = pd.DataFrame({\n                ('Beg', ''): {0: 0},\n                ('Middle', 'x'): {0: 1},\n                ('Tail', 'X'): {0: 3},\n                ('Tail', 'Y'): {0: 7}\n            })\n\n            expected = pd.DataFrame({\n                ('Beg', 'Unnamed: 0_level_1'): {0: 0},\n                ('Middle', u'x'): {0: 1},\n                ('Tail', u'X'): {0: 3},\n                ('Tail', u'Y'): {0: 7}\n            })\n\n            df.to_excel(path)\n            actual = pd.read_excel(path, header=[0, 1])\n            tm.assert_frame_equal(actual, expected)\n\n    @td.skip_if_no('xlsxwriter')\n    def test_excel_multindex_roundtrip(self, ext):\n        # GH 4679\n        with ensure_clean('.xlsx') as pth:\n            for c_idx_names in [True, False]:\n                for r_idx_names in [True, False]:\n                    for c_idx_levels in [1, 3]:\n                        for r_idx_levels in [1, 3]:\n                            # column index name can't be serialized unless\n                            # MultiIndex\n                            if (c_idx_levels == 1 and c_idx_names):\n                                continue\n\n                            # empty name case current read in as unnamed\n                            # levels, not Nones\n                            check_names = True\n                            if not r_idx_names and r_idx_levels > 1:\n                                check_names = False\n\n                            df = mkdf(5, 5, c_idx_names,\n                                      r_idx_names, c_idx_levels,\n                                      r_idx_levels)\n                            df.to_excel(pth)\n                            act = pd.read_excel(\n                                pth, index_col=list(range(r_idx_levels)),\n                                header=list(range(c_idx_levels)))\n                            tm.assert_frame_equal(\n                                df, act, check_names=check_names)\n\n                            df.iloc[0, :] = np.nan\n                            df.to_excel(pth)\n                            act = pd.read_excel(\n                                pth, index_col=list(range(r_idx_levels)),\n                                header=list(range(c_idx_levels)))\n                            tm.assert_frame_equal(\n                                df, act, check_names=check_names)\n\n                            df.iloc[-1, :] = np.nan\n                            df.to_excel(pth)\n                            act = pd.read_excel(\n                                pth, index_col=list(range(r_idx_levels)),\n                                header=list(range(c_idx_levels)))\n                            tm.assert_frame_equal(\n                                df, act, check_names=check_names)\n\n    def test_excel_old_index_format(self, ext):\n        # see gh-4679\n        filename = 'test_index_name_pre17' + ext\n        in_file = os.path.join(self.dirpath, filename)\n\n        # We detect headers to determine if index names exist, so\n        # that \"index\" name in the \"names\" version of the data will\n        # now be interpreted as rows that include null data.\n        data = np.array([[None, None, None, None, None],\n                         ['R0C0', 'R0C1', 'R0C2', 'R0C3', 'R0C4'],\n                         ['R1C0', 'R1C1', 'R1C2', 'R1C3', 'R1C4'],\n                         ['R2C0', 'R2C1', 'R2C2', 'R2C3', 'R2C4'],\n                         ['R3C0', 'R3C1', 'R3C2', 'R3C3', 'R3C4'],\n                         ['R4C0', 'R4C1', 'R4C2', 'R4C3', 'R4C4']])\n        columns = ['C_l0_g0', 'C_l0_g1', 'C_l0_g2', 'C_l0_g3', 'C_l0_g4']\n        mi = MultiIndex(levels=[['R0', 'R_l0_g0', 'R_l0_g1',\n                                 'R_l0_g2', 'R_l0_g3', 'R_l0_g4'],\n                                ['R1', 'R_l1_g0', 'R_l1_g1',\n                                 'R_l1_g2', 'R_l1_g3', 'R_l1_g4']],\n                        labels=[[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]],\n                        names=[None, None])\n        si = Index(['R0', 'R_l0_g0', 'R_l0_g1', 'R_l0_g2',\n                    'R_l0_g3', 'R_l0_g4'], name=None)\n\n        expected = pd.DataFrame(data, index=si, columns=columns)\n\n        actual = pd.read_excel(in_file, 'single_names')\n        tm.assert_frame_equal(actual, expected)\n\n        expected.index = mi\n\n        actual = pd.read_excel(in_file, 'multi_names')\n        tm.assert_frame_equal(actual, expected)\n\n        # The analogous versions of the \"names\" version data\n        # where there are explicitly no names for the indices.\n        data = np.array([['R0C0', 'R0C1', 'R0C2', 'R0C3', 'R0C4'],\n                         ['R1C0', 'R1C1', 'R1C2', 'R1C3', 'R1C4'],\n                         ['R2C0', 'R2C1', 'R2C2', 'R2C3', 'R2C4'],\n                         ['R3C0', 'R3C1', 'R3C2', 'R3C3', 'R3C4'],\n                         ['R4C0', 'R4C1', 'R4C2', 'R4C3', 'R4C4']])\n        columns = ['C_l0_g0', 'C_l0_g1', 'C_l0_g2', 'C_l0_g3', 'C_l0_g4']\n        mi = MultiIndex(levels=[['R_l0_g0', 'R_l0_g1', 'R_l0_g2',\n                                 'R_l0_g3', 'R_l0_g4'],\n                                ['R_l1_g0', 'R_l1_g1', 'R_l1_g2',\n                                 'R_l1_g3', 'R_l1_g4']],\n                        labels=[[0, 1, 2, 3, 4], [0, 1, 2, 3, 4]],\n                        names=[None, None])\n        si = Index(['R_l0_g0', 'R_l0_g1', 'R_l0_g2',\n                    'R_l0_g3', 'R_l0_g4'], name=None)\n\n        expected = pd.DataFrame(data, index=si, columns=columns)\n\n        actual = pd.read_excel(in_file, 'single_no_names')\n        tm.assert_frame_equal(actual, expected)\n\n        expected.index = mi\n\n        actual = pd.read_excel(in_file, 'multi_no_names', index_col=[0, 1])\n        tm.assert_frame_equal(actual, expected, check_names=False)\n\n    def test_read_excel_bool_header_arg(self, ext):\n        # GH 6114\n        for arg in [True, False]:\n            with pytest.raises(TypeError):\n                pd.read_excel(os.path.join(self.dirpath, 'test1' + ext),\n                              header=arg)\n\n    def test_read_excel_chunksize(self, ext):\n        # GH 8011\n        with pytest.raises(NotImplementedError):\n            pd.read_excel(os.path.join(self.dirpath, 'test1' + ext),\n                          chunksize=100)\n\n    @td.skip_if_no('openpyxl')\n    @td.skip_if_no('xlwt')\n    def test_read_excel_parse_dates(self, ext):\n        # GH 11544, 12051\n        df = DataFrame(\n            {'col': [1, 2, 3],\n             'date_strings': pd.date_range('2012-01-01', periods=3)})\n        df2 = df.copy()\n        df2['date_strings'] = df2['date_strings'].dt.strftime('%m/%d/%Y')\n\n        with ensure_clean(ext) as pth:\n            df2.to_excel(pth)\n\n            res = read_excel(pth)\n            tm.assert_frame_equal(df2, res)\n\n            # no index_col specified when parse_dates is True\n            with tm.assert_produces_warning():\n                res = read_excel(pth, parse_dates=True)\n                tm.assert_frame_equal(df2, res)\n\n            res = read_excel(pth, parse_dates=['date_strings'], index_col=0)\n            tm.assert_frame_equal(df, res)\n\n            dateparser = lambda x: pd.datetime.strptime(x, '%m/%d/%Y')\n            res = read_excel(pth, parse_dates=['date_strings'],\n                             date_parser=dateparser, index_col=0)\n            tm.assert_frame_equal(df, res)\n\n    def test_read_excel_skiprows_list(self, ext):\n        # GH 4903\n        actual = pd.read_excel(os.path.join(self.dirpath,\n                                            'testskiprows' + ext),\n                               'skiprows_list', skiprows=[0, 2])\n        expected = DataFrame([[1, 2.5, pd.Timestamp('2015-01-01'), True],\n                              [2, 3.5, pd.Timestamp('2015-01-02'), False],\n                              [3, 4.5, pd.Timestamp('2015-01-03'), False],\n                              [4, 5.5, pd.Timestamp('2015-01-04'), True]],\n                             columns=['a', 'b', 'c', 'd'])\n        tm.assert_frame_equal(actual, expected)\n\n        actual = pd.read_excel(os.path.join(self.dirpath,\n                                            'testskiprows' + ext),\n                               'skiprows_list', skiprows=np.array([0, 2]))\n        tm.assert_frame_equal(actual, expected)\n\n    def test_read_excel_nrows(self, ext):\n        # GH 16645\n        num_rows_to_pull = 5\n        actual = pd.read_excel(os.path.join(self.dirpath, 'test1' + ext),\n                               nrows=num_rows_to_pull)\n        expected = pd.read_excel(os.path.join(self.dirpath,\n                                              'test1' + ext))\n        expected = expected[:num_rows_to_pull]\n        tm.assert_frame_equal(actual, expected)\n\n    def test_read_excel_nrows_greater_than_nrows_in_file(self, ext):\n        # GH 16645\n        expected = pd.read_excel(os.path.join(self.dirpath,\n                                              'test1' + ext))\n        num_records_in_file = len(expected)\n        num_rows_to_pull = num_records_in_file + 10\n        actual = pd.read_excel(os.path.join(self.dirpath, 'test1' + ext),\n                               nrows=num_rows_to_pull)\n        tm.assert_frame_equal(actual, expected)\n\n    def test_read_excel_nrows_non_integer_parameter(self, ext):\n        # GH 16645\n        msg = \"'nrows' must be an integer >=0\"\n        with tm.assert_raises_regex(ValueError, msg):\n            pd.read_excel(os.path.join(self.dirpath, 'test1' + ext),\n                          nrows='5')\n\n    def test_read_excel_squeeze(self, ext):\n        # GH 12157\n        f = os.path.join(self.dirpath, 'test_squeeze' + ext)\n\n        actual = pd.read_excel(f, 'two_columns', index_col=0, squeeze=True)\n        expected = pd.Series([2, 3, 4], [4, 5, 6], name='b')\n        expected.index.name = 'a'\n        tm.assert_series_equal(actual, expected)\n\n        actual = pd.read_excel(f, 'two_columns', squeeze=True)\n        expected = pd.DataFrame({'a': [4, 5, 6],\n                                 'b': [2, 3, 4]})\n        tm.assert_frame_equal(actual, expected)\n\n        actual = pd.read_excel(f, 'one_column', squeeze=True)\n        expected = pd.Series([1, 2, 3], name='a')\n        tm.assert_series_equal(actual, expected)\n\n\nclass _WriterBase(SharedItems):\n\n    @pytest.fixture(autouse=True)\n    def set_engine_and_path(self, request, merge_cells, engine, ext):\n        \"\"\"Fixture to set engine and open file for use in each test case\n\n        Rather than requiring `engine=...` to be provided explicitly as an\n        argument in each test, this fixture sets a global option to dictate\n        which engine should be used to write Excel files. After executing\n        the test it rolls back said change to the global option.\n\n        It also uses a context manager to open a temporary excel file for\n        the function to write to, accessible via `self.path`\n\n        Notes\n        -----\n        This fixture will run as part of each test method defined in the\n        class and any subclasses, on account of the `autouse=True`\n        argument\n        \"\"\"\n        option_name = 'io.excel.{ext}.writer'.format(ext=ext.strip('.'))\n        prev_engine = get_option(option_name)\n        set_option(option_name, engine)\n        with ensure_clean(ext) as path:\n            self.path = path\n            yield\n        set_option(option_name, prev_engine)  # Roll back option change\n\n\n@pytest.mark.parametrize(\"merge_cells\", [True, False])\n@pytest.mark.parametrize(\"engine,ext\", [\n    pytest.param('openpyxl', '.xlsx', marks=pytest.mark.skipif(\n        not td.safe_import('openpyxl'), reason='No openpyxl')),\n    pytest.param('openpyxl', '.xlsm', marks=pytest.mark.skipif(\n        not td.safe_import('openpyxl'), reason='No openpyxl')),\n    pytest.param('xlwt', '.xls', marks=pytest.mark.skipif(\n        not td.safe_import('xlwt'), reason='No xlwt')),\n    pytest.param('xlsxwriter', '.xlsx', marks=pytest.mark.skipif(\n        not td.safe_import('xlsxwriter'), reason='No xlsxwriter'))\n])\nclass TestExcelWriter(_WriterBase):\n    # Base class for test cases to run with different Excel writers.\n\n    def test_excel_sheet_by_name_raise(self, merge_cells, engine, ext):\n        import xlrd\n\n        gt = DataFrame(np.random.randn(10, 2))\n        gt.to_excel(self.path)\n        xl = ExcelFile(self.path)\n        df = read_excel(xl, 0)\n        tm.assert_frame_equal(gt, df)\n\n        with pytest.raises(xlrd.XLRDError):\n            read_excel(xl, '0')\n\n    def test_excelwriter_contextmanager(self, merge_cells, engine, ext):\n        with ExcelWriter(self.path) as writer:\n            self.frame.to_excel(writer, 'Data1')\n            self.frame2.to_excel(writer, 'Data2')\n\n        with ExcelFile(self.path) as reader:\n            found_df = read_excel(reader, 'Data1')\n            found_df2 = read_excel(reader, 'Data2')\n            tm.assert_frame_equal(found_df, self.frame)\n            tm.assert_frame_equal(found_df2, self.frame2)\n\n    def test_roundtrip(self, merge_cells, engine, ext):\n        self.frame['A'][:5] = nan\n\n        self.frame.to_excel(self.path, 'test1')\n        self.frame.to_excel(self.path, 'test1', columns=['A', 'B'])\n        self.frame.to_excel(self.path, 'test1', header=False)\n        self.frame.to_excel(self.path, 'test1', index=False)\n\n        # test roundtrip\n        self.frame.to_excel(self.path, 'test1')\n        recons = read_excel(self.path, 'test1', index_col=0)\n        tm.assert_frame_equal(self.frame, recons)\n\n        self.frame.to_excel(self.path, 'test1', index=False)\n        recons = read_excel(self.path, 'test1', index_col=None)\n        recons.index = self.frame.index\n        tm.assert_frame_equal(self.frame, recons)\n\n        self.frame.to_excel(self.path, 'test1', na_rep='NA')\n        recons = read_excel(self.path, 'test1', index_col=0, na_values=['NA'])\n        tm.assert_frame_equal(self.frame, recons)\n\n        # GH 3611\n        self.frame.to_excel(self.path, 'test1', na_rep='88')\n        recons = read_excel(self.path, 'test1', index_col=0, na_values=['88'])\n        tm.assert_frame_equal(self.frame, recons)\n\n        self.frame.to_excel(self.path, 'test1', na_rep='88')\n        recons = read_excel(self.path, 'test1', index_col=0,\n                            na_values=[88, 88.0])\n        tm.assert_frame_equal(self.frame, recons)\n\n        # GH 6573\n        self.frame.to_excel(self.path, 'Sheet1')\n        recons = read_excel(self.path, index_col=0)\n        tm.assert_frame_equal(self.frame, recons)\n\n        self.frame.to_excel(self.path, '0')\n        recons = read_excel(self.path, index_col=0)\n        tm.assert_frame_equal(self.frame, recons)\n\n        # GH 8825 Pandas Series should provide to_excel method\n        s = self.frame[\"A\"]\n        s.to_excel(self.path)\n        recons = read_excel(self.path, index_col=0)\n        tm.assert_frame_equal(s.to_frame(), recons)\n\n    def test_mixed(self, merge_cells, engine, ext):\n        self.mixed_frame.to_excel(self.path, 'test1')\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1', index_col=0)\n        tm.assert_frame_equal(self.mixed_frame, recons)\n\n    def test_tsframe(self, merge_cells, engine, ext):\n        df = tm.makeTimeDataFrame()[:5]\n\n        df.to_excel(self.path, 'test1')\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1')\n        tm.assert_frame_equal(df, recons)\n\n    def test_basics_with_nan(self, merge_cells, engine, ext):\n        self.frame['A'][:5] = nan\n        self.frame.to_excel(self.path, 'test1')\n        self.frame.to_excel(self.path, 'test1', columns=['A', 'B'])\n        self.frame.to_excel(self.path, 'test1', header=False)\n        self.frame.to_excel(self.path, 'test1', index=False)\n\n    @pytest.mark.parametrize(\"np_type\", [\n        np.int8, np.int16, np.int32, np.int64])\n    def test_int_types(self, merge_cells, engine, ext, np_type):\n        # Test np.int values read come back as int (rather than float\n        # which is Excel's format).\n        frame = DataFrame(np.random.randint(-10, 10, size=(10, 2)),\n                          dtype=np_type)\n        frame.to_excel(self.path, 'test1')\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1')\n        int_frame = frame.astype(np.int64)\n        tm.assert_frame_equal(int_frame, recons)\n        recons2 = read_excel(self.path, 'test1')\n        tm.assert_frame_equal(int_frame, recons2)\n\n        # test with convert_float=False comes back as float\n        float_frame = frame.astype(float)\n        recons = read_excel(self.path, 'test1', convert_float=False)\n        tm.assert_frame_equal(recons, float_frame,\n                              check_index_type=False,\n                              check_column_type=False)\n\n    @pytest.mark.parametrize(\"np_type\", [\n        np.float16, np.float32, np.float64])\n    def test_float_types(self, merge_cells, engine, ext, np_type):\n        # Test np.float values read come back as float.\n        frame = DataFrame(np.random.random_sample(10), dtype=np_type)\n        frame.to_excel(self.path, 'test1')\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1').astype(np_type)\n        tm.assert_frame_equal(frame, recons, check_dtype=False)\n\n    @pytest.mark.parametrize(\"np_type\", [np.bool8, np.bool_])\n    def test_bool_types(self, merge_cells, engine, ext, np_type):\n        # Test np.bool values read come back as float.\n        frame = (DataFrame([1, 0, True, False], dtype=np_type))\n        frame.to_excel(self.path, 'test1')\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1').astype(np_type)\n        tm.assert_frame_equal(frame, recons)\n\n    def test_inf_roundtrip(self, merge_cells, engine, ext):\n        frame = DataFrame([(1, np.inf), (2, 3), (5, -np.inf)])\n        frame.to_excel(self.path, 'test1')\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1')\n        tm.assert_frame_equal(frame, recons)\n\n    def test_sheets(self, merge_cells, engine, ext):\n        self.frame['A'][:5] = nan\n\n        self.frame.to_excel(self.path, 'test1')\n        self.frame.to_excel(self.path, 'test1', columns=['A', 'B'])\n        self.frame.to_excel(self.path, 'test1', header=False)\n        self.frame.to_excel(self.path, 'test1', index=False)\n\n        # Test writing to separate sheets\n        writer = ExcelWriter(self.path)\n        self.frame.to_excel(writer, 'test1')\n        self.tsframe.to_excel(writer, 'test2')\n        writer.save()\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1', index_col=0)\n        tm.assert_frame_equal(self.frame, recons)\n        recons = read_excel(reader, 'test2', index_col=0)\n        tm.assert_frame_equal(self.tsframe, recons)\n        assert 2 == len(reader.sheet_names)\n        assert 'test1' == reader.sheet_names[0]\n        assert 'test2' == reader.sheet_names[1]\n\n    def test_colaliases(self, merge_cells, engine, ext):\n        self.frame['A'][:5] = nan\n\n        self.frame.to_excel(self.path, 'test1')\n        self.frame.to_excel(self.path, 'test1', columns=['A', 'B'])\n        self.frame.to_excel(self.path, 'test1', header=False)\n        self.frame.to_excel(self.path, 'test1', index=False)\n\n        # column aliases\n        col_aliases = Index(['AA', 'X', 'Y', 'Z'])\n        self.frame2.to_excel(self.path, 'test1', header=col_aliases)\n        reader = ExcelFile(self.path)\n        rs = read_excel(reader, 'test1', index_col=0)\n        xp = self.frame2.copy()\n        xp.columns = col_aliases\n        tm.assert_frame_equal(xp, rs)\n\n    def test_roundtrip_indexlabels(self, merge_cells, engine, ext):\n        self.frame['A'][:5] = nan\n\n        self.frame.to_excel(self.path, 'test1')\n        self.frame.to_excel(self.path, 'test1', columns=['A', 'B'])\n        self.frame.to_excel(self.path, 'test1', header=False)\n        self.frame.to_excel(self.path, 'test1', index=False)\n\n        # test index_label\n        frame = (DataFrame(np.random.randn(10, 2)) >= 0)\n        frame.to_excel(self.path, 'test1',\n                       index_label=['test'],\n                       merge_cells=merge_cells)\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1',\n                            index_col=0,\n                            ).astype(np.int64)\n        frame.index.names = ['test']\n        assert frame.index.names == recons.index.names\n\n        frame = (DataFrame(np.random.randn(10, 2)) >= 0)\n        frame.to_excel(self.path,\n                       'test1',\n                       index_label=['test', 'dummy', 'dummy2'],\n                       merge_cells=merge_cells)\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1',\n                            index_col=0,\n                            ).astype(np.int64)\n        frame.index.names = ['test']\n        assert frame.index.names == recons.index.names\n\n        frame = (DataFrame(np.random.randn(10, 2)) >= 0)\n        frame.to_excel(self.path,\n                       'test1',\n                       index_label='test',\n                       merge_cells=merge_cells)\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1',\n                            index_col=0,\n                            ).astype(np.int64)\n        frame.index.names = ['test']\n        tm.assert_frame_equal(frame, recons.astype(bool))\n\n        self.frame.to_excel(self.path,\n                            'test1',\n                            columns=['A', 'B', 'C', 'D'],\n                            index=False, merge_cells=merge_cells)\n        # take 'A' and 'B' as indexes (same row as cols 'C', 'D')\n        df = self.frame.copy()\n        df = df.set_index(['A', 'B'])\n\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1', index_col=[0, 1])\n        tm.assert_frame_equal(df, recons, check_less_precise=True)\n\n    def test_excel_roundtrip_indexname(self, merge_cells, engine, ext):\n        df = DataFrame(np.random.randn(10, 4))\n        df.index.name = 'foo'\n\n        df.to_excel(self.path, merge_cells=merge_cells)\n\n        xf = ExcelFile(self.path)\n        result = read_excel(xf, xf.sheet_names[0],\n                            index_col=0)\n\n        tm.assert_frame_equal(result, df)\n        assert result.index.name == 'foo'\n\n    def test_excel_roundtrip_datetime(self, merge_cells, engine, ext):\n        # datetime.date, not sure what to test here exactly\n        tsf = self.tsframe.copy()\n\n        tsf.index = [x.date() for x in self.tsframe.index]\n        tsf.to_excel(self.path, 'test1', merge_cells=merge_cells)\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1')\n        tm.assert_frame_equal(self.tsframe, recons)\n\n    # GH4133 - excel output format strings\n    def test_excel_date_datetime_format(self, merge_cells, engine, ext):\n        df = DataFrame([[date(2014, 1, 31),\n                         date(1999, 9, 24)],\n                        [datetime(1998, 5, 26, 23, 33, 4),\n                         datetime(2014, 2, 28, 13, 5, 13)]],\n                       index=['DATE', 'DATETIME'], columns=['X', 'Y'])\n        df_expected = DataFrame([[datetime(2014, 1, 31),\n                                  datetime(1999, 9, 24)],\n                                 [datetime(1998, 5, 26, 23, 33, 4),\n                                  datetime(2014, 2, 28, 13, 5, 13)]],\n                                index=['DATE', 'DATETIME'], columns=['X', 'Y'])\n\n        with ensure_clean(ext) as filename2:\n            writer1 = ExcelWriter(self.path)\n            writer2 = ExcelWriter(filename2,\n                                  date_format='DD.MM.YYYY',\n                                  datetime_format='DD.MM.YYYY HH-MM-SS')\n\n            df.to_excel(writer1, 'test1')\n            df.to_excel(writer2, 'test1')\n\n            writer1.close()\n            writer2.close()\n\n            reader1 = ExcelFile(self.path)\n            reader2 = ExcelFile(filename2)\n\n            rs1 = read_excel(reader1, 'test1', index_col=None)\n            rs2 = read_excel(reader2, 'test1', index_col=None)\n\n            tm.assert_frame_equal(rs1, rs2)\n\n            # since the reader returns a datetime object for dates, we need\n            # to use df_expected to check the result\n            tm.assert_frame_equal(rs2, df_expected)\n\n    def test_to_excel_interval_no_labels(self, merge_cells, engine, ext):\n        # GH19242 - test writing Interval without labels\n        frame = DataFrame(np.random.randint(-10, 10, size=(20, 1)),\n                          dtype=np.int64)\n        expected = frame.copy()\n        frame['new'] = pd.cut(frame[0], 10)\n        expected['new'] = pd.cut(expected[0], 10).astype(str)\n        frame.to_excel(self.path, 'test1')\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1')\n        tm.assert_frame_equal(expected, recons)\n\n    def test_to_excel_interval_labels(self, merge_cells, engine, ext):\n        # GH19242 - test writing Interval with labels\n        frame = DataFrame(np.random.randint(-10, 10, size=(20, 1)),\n                          dtype=np.int64)\n        expected = frame.copy()\n        intervals = pd.cut(frame[0], 10, labels=['A', 'B', 'C', 'D', 'E',\n                                                 'F', 'G', 'H', 'I', 'J'])\n        frame['new'] = intervals\n        expected['new'] = pd.Series(list(intervals))\n        frame.to_excel(self.path, 'test1')\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1')\n        tm.assert_frame_equal(expected, recons)\n\n    def test_to_excel_timedelta(self, merge_cells, engine, ext):\n        # GH 19242, GH9155 - test writing timedelta to xls\n        frame = DataFrame(np.random.randint(-10, 10, size=(20, 1)),\n                          columns=['A'],\n                          dtype=np.int64\n                          )\n        expected = frame.copy()\n        frame['new'] = frame['A'].apply(lambda x: timedelta(seconds=x))\n        expected['new'] = expected['A'].apply(\n            lambda x: timedelta(seconds=x).total_seconds() / float(86400))\n        frame.to_excel(self.path, 'test1')\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1')\n        tm.assert_frame_equal(expected, recons)\n\n    def test_to_excel_periodindex(self, merge_cells, engine, ext):\n        frame = self.tsframe\n        xp = frame.resample('M', kind='period').mean()\n\n        xp.to_excel(self.path, 'sht1')\n\n        reader = ExcelFile(self.path)\n        rs = read_excel(reader, 'sht1', index_col=0)\n        tm.assert_frame_equal(xp, rs.to_period('M'))\n\n    def test_to_excel_multiindex(self, merge_cells, engine, ext):\n        frame = self.frame\n        arrays = np.arange(len(frame.index) * 2).reshape(2, -1)\n        new_index = MultiIndex.from_arrays(arrays,\n                                           names=['first', 'second'])\n        frame.index = new_index\n\n        frame.to_excel(self.path, 'test1', header=False)\n        frame.to_excel(self.path, 'test1', columns=['A', 'B'])\n\n        # round trip\n        frame.to_excel(self.path, 'test1', merge_cells=merge_cells)\n        reader = ExcelFile(self.path)\n        df = read_excel(reader, 'test1', index_col=[0, 1])\n        tm.assert_frame_equal(frame, df)\n\n    # GH13511\n    def test_to_excel_multiindex_nan_label(self, merge_cells, engine, ext):\n        frame = pd.DataFrame({'A': [None, 2, 3],\n                              'B': [10, 20, 30],\n                              'C': np.random.sample(3)})\n        frame = frame.set_index(['A', 'B'])\n\n        frame.to_excel(self.path, merge_cells=merge_cells)\n        df = read_excel(self.path, index_col=[0, 1])\n        tm.assert_frame_equal(frame, df)\n\n    # Test for Issue 11328. If column indices are integers, make\n    # sure they are handled correctly for either setting of\n    # merge_cells\n    def test_to_excel_multiindex_cols(self, merge_cells, engine, ext):\n        frame = self.frame\n        arrays = np.arange(len(frame.index) * 2).reshape(2, -1)\n        new_index = MultiIndex.from_arrays(arrays,\n                                           names=['first', 'second'])\n        frame.index = new_index\n\n        new_cols_index = MultiIndex.from_tuples([(40, 1), (40, 2),\n                                                 (50, 1), (50, 2)])\n        frame.columns = new_cols_index\n        header = [0, 1]\n        if not merge_cells:\n            header = 0\n\n        # round trip\n        frame.to_excel(self.path, 'test1', merge_cells=merge_cells)\n        reader = ExcelFile(self.path)\n        df = read_excel(reader, 'test1', header=header,\n                        index_col=[0, 1])\n        if not merge_cells:\n            fm = frame.columns.format(sparsify=False,\n                                      adjoin=False, names=False)\n            frame.columns = [\".\".join(map(str, q)) for q in zip(*fm)]\n        tm.assert_frame_equal(frame, df)\n\n    def test_to_excel_multiindex_dates(self, merge_cells, engine, ext):\n        # try multiindex with dates\n        tsframe = self.tsframe.copy()\n        new_index = [tsframe.index, np.arange(len(tsframe.index))]\n        tsframe.index = MultiIndex.from_arrays(new_index)\n\n        tsframe.index.names = ['time', 'foo']\n        tsframe.to_excel(self.path, 'test1', merge_cells=merge_cells)\n        reader = ExcelFile(self.path)\n        recons = read_excel(reader, 'test1',\n                            index_col=[0, 1])\n\n        tm.assert_frame_equal(tsframe, recons)\n        assert recons.index.names == ('time', 'foo')\n\n    def test_to_excel_multiindex_no_write_index(self, merge_cells, engine,\n                                                ext):\n        # Test writing and re-reading a MI witout the index. GH 5616.\n\n        # Initial non-MI frame.\n        frame1 = DataFrame({'a': [10, 20], 'b': [30, 40], 'c': [50, 60]})\n\n        # Add a MI.\n        frame2 = frame1.copy()\n        multi_index = MultiIndex.from_tuples([(70, 80), (90, 100)])\n        frame2.index = multi_index\n\n        # Write out to Excel without the index.\n        frame2.to_excel(self.path, 'test1', index=False)\n\n        # Read it back in.\n        reader = ExcelFile(self.path)\n        frame3 = read_excel(reader, 'test1')\n\n        # Test that it is the same as the initial frame.\n        tm.assert_frame_equal(frame1, frame3)\n\n    def test_to_excel_float_format(self, merge_cells, engine, ext):\n        df = DataFrame([[0.123456, 0.234567, 0.567567],\n                        [12.32112, 123123.2, 321321.2]],\n                       index=['A', 'B'], columns=['X', 'Y', 'Z'])\n\n        df.to_excel(self.path, 'test1', float_format='%.2f')\n\n        reader = ExcelFile(self.path)\n        rs = read_excel(reader, 'test1', index_col=None)\n        xp = DataFrame([[0.12, 0.23, 0.57],\n                        [12.32, 123123.20, 321321.20]],\n                       index=['A', 'B'], columns=['X', 'Y', 'Z'])\n        tm.assert_frame_equal(rs, xp)\n\n    def test_to_excel_output_encoding(self, merge_cells, engine, ext):\n        # avoid mixed inferred_type\n        df = DataFrame([[u'\\u0192', u'\\u0193', u'\\u0194'],\n                        [u'\\u0195', u'\\u0196', u'\\u0197']],\n                       index=[u'A\\u0192', u'B'],\n                       columns=[u'X\\u0193', u'Y', u'Z'])\n\n        with ensure_clean('__tmp_to_excel_float_format__.' + ext) as filename:\n            df.to_excel(filename, sheet_name='TestSheet', encoding='utf8')\n            result = read_excel(filename, 'TestSheet', encoding='utf8')\n            tm.assert_frame_equal(result, df)\n\n    def test_to_excel_unicode_filename(self, merge_cells, engine, ext):\n        with ensure_clean(u('\\u0192u.') + ext) as filename:\n            try:\n                f = open(filename, 'wb')\n            except UnicodeEncodeError:\n                pytest.skip('no unicode file names on this system')\n            else:\n                f.close()\n\n            df = DataFrame([[0.123456, 0.234567, 0.567567],\n                            [12.32112, 123123.2, 321321.2]],\n                           index=['A', 'B'], columns=['X', 'Y', 'Z'])\n\n            df.to_excel(filename, 'test1', float_format='%.2f')\n\n            reader = ExcelFile(filename)\n            rs = read_excel(reader, 'test1', index_col=None)\n            xp = DataFrame([[0.12, 0.23, 0.57],\n                            [12.32, 123123.20, 321321.20]],\n                           index=['A', 'B'], columns=['X', 'Y', 'Z'])\n            tm.assert_frame_equal(rs, xp)\n\n    # def test_to_excel_header_styling_xls(self, merge_cells, engine, ext):\n\n    #     import StringIO\n    #     s = StringIO(\n    #     \"\"\"Date,ticker,type,value\n    #     2001-01-01,x,close,12.2\n    #     2001-01-01,x,open ,12.1\n    #     2001-01-01,y,close,12.2\n    #     2001-01-01,y,open ,12.1\n    #     2001-02-01,x,close,12.2\n    #     2001-02-01,x,open ,12.1\n    #     2001-02-01,y,close,12.2\n    #     2001-02-01,y,open ,12.1\n    #     2001-03-01,x,close,12.2\n    #     2001-03-01,x,open ,12.1\n    #     2001-03-01,y,close,12.2\n    #     2001-03-01,y,open ,12.1\"\"\")\n    #     df = read_csv(s, parse_dates=[\"Date\"])\n    #     pdf = df.pivot_table(values=\"value\", rows=[\"ticker\"],\n    #                                          cols=[\"Date\", \"type\"])\n\n    #     try:\n    #         import xlwt\n    #         import xlrd\n    #     except ImportError:\n    #         pytest.skip\n\n    #     filename = '__tmp_to_excel_header_styling_xls__.xls'\n    #     pdf.to_excel(filename, 'test1')\n\n    #     wbk = xlrd.open_workbook(filename,\n    #                              formatting_info=True)\n    #     assert [\"test1\"] == wbk.sheet_names()\n    #     ws = wbk.sheet_by_name('test1')\n    #     assert [(0, 1, 5, 7), (0, 1, 3, 5), (0, 1, 1, 3)] == ws.merged_cells\n    #     for i in range(0, 2):\n    #         for j in range(0, 7):\n    #             xfx = ws.cell_xf_index(0, 0)\n    #             cell_xf = wbk.xf_list[xfx]\n    #             font = wbk.font_list\n    #             assert 1 == font[cell_xf.font_index].bold\n    #             assert 1 == cell_xf.border.top_line_style\n    #             assert 1 == cell_xf.border.right_line_style\n    #             assert 1 == cell_xf.border.bottom_line_style\n    #             assert 1 == cell_xf.border.left_line_style\n    #             assert 2 == cell_xf.alignment.hor_align\n    #     os.remove(filename)\n    # def test_to_excel_header_styling_xlsx(self, merge_cells, engine, ext):\n    #     import StringIO\n    #     s = StringIO(\n    #     \"\"\"Date,ticker,type,value\n    #     2001-01-01,x,close,12.2\n    #     2001-01-01,x,open ,12.1\n    #     2001-01-01,y,close,12.2\n    #     2001-01-01,y,open ,12.1\n    #     2001-02-01,x,close,12.2\n    #     2001-02-01,x,open ,12.1\n    #     2001-02-01,y,close,12.2\n    #     2001-02-01,y,open ,12.1\n    #     2001-03-01,x,close,12.2\n    #     2001-03-01,x,open ,12.1\n    #     2001-03-01,y,close,12.2\n    #     2001-03-01,y,open ,12.1\"\"\")\n    #     df = read_csv(s, parse_dates=[\"Date\"])\n    #     pdf = df.pivot_table(values=\"value\", rows=[\"ticker\"],\n    #                                          cols=[\"Date\", \"type\"])\n    #     try:\n    #         import openpyxl\n    #         from openpyxl.cell import get_column_letter\n    #     except ImportError:\n    #         pytest.skip\n    #     if openpyxl.__version__ < '1.6.1':\n    #         pytest.skip\n    #     # test xlsx_styling\n    #     filename = '__tmp_to_excel_header_styling_xlsx__.xlsx'\n    #     pdf.to_excel(filename, 'test1')\n    #     wbk = openpyxl.load_workbook(filename)\n    #     assert [\"test1\"] == wbk.get_sheet_names()\n    #     ws = wbk.get_sheet_by_name('test1')\n    #     xlsaddrs = [\"%s2\" % chr(i) for i in range(ord('A'), ord('H'))]\n    #     xlsaddrs += [\"A%s\" % i for i in range(1, 6)]\n    #     xlsaddrs += [\"B1\", \"D1\", \"F1\"]\n    #     for xlsaddr in xlsaddrs:\n    #         cell = ws.cell(xlsaddr)\n    #         assert cell.style.font.bold\n    #         assert (openpyxl.style.Border.BORDER_THIN ==\n    #                 cell.style.borders.top.border_style)\n    #         assert (openpyxl.style.Border.BORDER_THIN ==\n    #                 cell.style.borders.right.border_style)\n    #         assert (openpyxl.style.Border.BORDER_THIN ==\n    #                 cell.style.borders.bottom.border_style)\n    #         assert (openpyxl.style.Border.BORDER_THIN ==\n    #                 cell.style.borders.left.border_style)\n    #         assert (openpyxl.style.Alignment.HORIZONTAL_CENTER ==\n    #                 cell.style.alignment.horizontal)\n    #     mergedcells_addrs = [\"C1\", \"E1\", \"G1\"]\n    #     for maddr in mergedcells_addrs:\n    #         assert ws.cell(maddr).merged\n    #     os.remove(filename)\n\n    def test_excel_010_hemstring(self, merge_cells, engine, ext):\n        if merge_cells:\n            pytest.skip('Skip tests for merged MI format.')\n\n        from pandas.util.testing import makeCustomDataframe as mkdf\n        # ensure limited functionality in 0.10\n        # override of #2370 until sorted out in 0.11\n\n        def roundtrip(df, header=True, parser_hdr=0, index=True):\n\n            df.to_excel(self.path, header=header,\n                        merge_cells=merge_cells, index=index)\n            xf = ExcelFile(self.path)\n            res = read_excel(xf, xf.sheet_names[0], header=parser_hdr)\n            return res\n\n        nrows = 5\n        ncols = 3\n        for use_headers in (True, False):\n            for i in range(1, 4):  # row multindex up to nlevel=3\n                for j in range(1, 4):  # col \"\"\n                    df = mkdf(nrows, ncols, r_idx_nlevels=i, c_idx_nlevels=j)\n\n                    # this if will be removed once multi column excel writing\n                    # is implemented for now fixing #9794\n                    if j > 1:\n                        with pytest.raises(NotImplementedError):\n                            res = roundtrip(df, use_headers, index=False)\n                    else:\n                        res = roundtrip(df, use_headers)\n\n                    if use_headers:\n                        assert res.shape == (nrows, ncols + i)\n                    else:\n                        # first row taken as columns\n                        assert res.shape == (nrows - 1, ncols + i)\n\n                    # no nans\n                    for r in range(len(res.index)):\n                        for c in range(len(res.columns)):\n                            assert res.iloc[r, c] is not np.nan\n\n        res = roundtrip(DataFrame([0]))\n        assert res.shape == (1, 1)\n        assert res.iloc[0, 0] is not np.nan\n\n        res = roundtrip(DataFrame([0]), False, None)\n        assert res.shape == (1, 2)\n        assert res.iloc[0, 0] is not np.nan\n\n    def test_excel_010_hemstring_raises_NotImplementedError(self, merge_cells,\n                                                            engine, ext):\n        # This test was failing only for j>1 and header=False,\n        # So I reproduced a simple test.\n        if merge_cells:\n            pytest.skip('Skip tests for merged MI format.')\n\n        from pandas.util.testing import makeCustomDataframe as mkdf\n        # ensure limited functionality in 0.10\n        # override of #2370 until sorted out in 0.11\n\n        def roundtrip2(df, header=True, parser_hdr=0, index=True):\n\n            df.to_excel(self.path, header=header,\n                        merge_cells=merge_cells, index=index)\n            xf = ExcelFile(self.path)\n            res = read_excel(xf, xf.sheet_names[0], header=parser_hdr)\n            return res\n\n        nrows = 5\n        ncols = 3\n        j = 2\n        i = 1\n        df = mkdf(nrows, ncols, r_idx_nlevels=i, c_idx_nlevels=j)\n        with pytest.raises(NotImplementedError):\n            roundtrip2(df, header=False, index=False)\n\n    def test_duplicated_columns(self, merge_cells, engine, ext):\n        # Test for issue #5235\n        write_frame = DataFrame([[1, 2, 3], [1, 2, 3], [1, 2, 3]])\n        colnames = ['A', 'B', 'B']\n\n        write_frame.columns = colnames\n        write_frame.to_excel(self.path, 'test1')\n\n        read_frame = read_excel(self.path, 'test1')\n        read_frame.columns = colnames\n        tm.assert_frame_equal(write_frame, read_frame)\n\n        # 11007 / #10970\n        write_frame = DataFrame([[1, 2, 3, 4], [5, 6, 7, 8]],\n                                columns=['A', 'B', 'A', 'B'])\n        write_frame.to_excel(self.path, 'test1')\n        read_frame = read_excel(self.path, 'test1')\n        read_frame.columns = ['A', 'B', 'A', 'B']\n        tm.assert_frame_equal(write_frame, read_frame)\n\n        # 10982\n        write_frame.to_excel(self.path, 'test1', index=False, header=False)\n        read_frame = read_excel(self.path, 'test1', header=None)\n        write_frame.columns = [0, 1, 2, 3]\n        tm.assert_frame_equal(write_frame, read_frame)\n\n    def test_swapped_columns(self, merge_cells, engine, ext):\n        # Test for issue #5427.\n        write_frame = DataFrame({'A': [1, 1, 1],\n                                 'B': [2, 2, 2]})\n        write_frame.to_excel(self.path, 'test1', columns=['B', 'A'])\n\n        read_frame = read_excel(self.path, 'test1', header=0)\n\n        tm.assert_series_equal(write_frame['A'], read_frame['A'])\n        tm.assert_series_equal(write_frame['B'], read_frame['B'])\n\n    def test_invalid_columns(self, merge_cells, engine, ext):\n        # 10982\n        write_frame = DataFrame({'A': [1, 1, 1],\n                                 'B': [2, 2, 2]})\n\n        with tm.assert_produces_warning(FutureWarning,\n                                        check_stacklevel=False):\n            write_frame.to_excel(self.path, 'test1', columns=['B', 'C'])\n        expected = write_frame.reindex(columns=['B', 'C'])\n        read_frame = read_excel(self.path, 'test1')\n        tm.assert_frame_equal(expected, read_frame)\n\n        with pytest.raises(KeyError):\n            write_frame.to_excel(self.path, 'test1', columns=['C', 'D'])\n\n    def test_comment_arg(self, merge_cells, engine, ext):\n        # Re issue #18735\n        # Test the comment argument functionality to read_excel\n\n        # Create file to read in\n        df = DataFrame({'A': ['one', '#one', 'one'],\n                        'B': ['two', 'two', '#two']})\n        df.to_excel(self.path, 'test_c')\n\n        # Read file without comment arg\n        result1 = read_excel(self.path, 'test_c')\n        result1.iloc[1, 0] = None\n        result1.iloc[1, 1] = None\n        result1.iloc[2, 1] = None\n        result2 = read_excel(self.path, 'test_c', comment='#')\n        tm.assert_frame_equal(result1, result2)\n\n    def test_comment_default(self, merge_cells, engine, ext):\n        # Re issue #18735\n        # Test the comment argument default to read_excel\n\n        # Create file to read in\n        df = DataFrame({'A': ['one', '#one', 'one'],\n                        'B': ['two', 'two', '#two']})\n        df.to_excel(self.path, 'test_c')\n\n        # Read file with default and explicit comment=None\n        result1 = read_excel(self.path, 'test_c')\n        result2 = read_excel(self.path, 'test_c', comment=None)\n        tm.assert_frame_equal(result1, result2)\n\n    def test_comment_used(self, merge_cells, engine, ext):\n        # Re issue #18735\n        # Test the comment argument is working as expected when used\n\n        # Create file to read in\n        df = DataFrame({'A': ['one', '#one', 'one'],\n                        'B': ['two', 'two', '#two']})\n        df.to_excel(self.path, 'test_c')\n\n        # Test read_frame_comment against manually produced expected output\n        expected = DataFrame({'A': ['one', None, 'one'],\n                              'B': ['two', None, None]})\n        result = read_excel(self.path, 'test_c', comment='#')\n        tm.assert_frame_equal(result, expected)\n\n    def test_comment_emptyline(self, merge_cells, engine, ext):\n        # Re issue #18735\n        # Test that read_excel ignores commented lines at the end of file\n\n        df = DataFrame({'a': ['1', '#2'], 'b': ['2', '3']})\n        df.to_excel(self.path, index=False)\n\n        # Test that all-comment lines at EoF are ignored\n        expected = DataFrame({'a': [1], 'b': [2]})\n        result = read_excel(self.path, comment='#')\n        tm.assert_frame_equal(result, expected)\n\n    def test_datetimes(self, merge_cells, engine, ext):\n\n        # Test writing and reading datetimes. For issue #9139. (xref #9185)\n        datetimes = [datetime(2013, 1, 13, 1, 2, 3),\n                     datetime(2013, 1, 13, 2, 45, 56),\n                     datetime(2013, 1, 13, 4, 29, 49),\n                     datetime(2013, 1, 13, 6, 13, 42),\n                     datetime(2013, 1, 13, 7, 57, 35),\n                     datetime(2013, 1, 13, 9, 41, 28),\n                     datetime(2013, 1, 13, 11, 25, 21),\n                     datetime(2013, 1, 13, 13, 9, 14),\n                     datetime(2013, 1, 13, 14, 53, 7),\n                     datetime(2013, 1, 13, 16, 37, 0),\n                     datetime(2013, 1, 13, 18, 20, 52)]\n\n        write_frame = DataFrame({'A': datetimes})\n        write_frame.to_excel(self.path, 'Sheet1')\n        read_frame = read_excel(self.path, 'Sheet1', header=0)\n\n        tm.assert_series_equal(write_frame['A'], read_frame['A'])\n\n    # GH7074\n    def test_bytes_io(self, merge_cells, engine, ext):\n        bio = BytesIO()\n        df = DataFrame(np.random.randn(10, 2))\n        # pass engine explicitly as there is no file path to infer from\n        writer = ExcelWriter(bio, engine=engine)\n        df.to_excel(writer)\n        writer.save()\n        bio.seek(0)\n        reread_df = read_excel(bio)\n        tm.assert_frame_equal(df, reread_df)\n\n    # GH8188\n    def test_write_lists_dict(self, merge_cells, engine, ext):\n        df = DataFrame({'mixed': ['a', ['b', 'c'], {'d': 'e', 'f': 2}],\n                        'numeric': [1, 2, 3.0],\n                        'str': ['apple', 'banana', 'cherry']})\n        expected = df.copy()\n        expected.mixed = expected.mixed.apply(str)\n        expected.numeric = expected.numeric.astype('int64')\n\n        df.to_excel(self.path, 'Sheet1')\n        read = read_excel(self.path, 'Sheet1', header=0)\n        tm.assert_frame_equal(read, expected)\n\n    # GH13347\n    def test_true_and_false_value_options(self, merge_cells, engine, ext):\n        df = pd.DataFrame([['foo', 'bar']], columns=['col1', 'col2'])\n        expected = df.replace({'foo': True,\n                               'bar': False})\n\n        df.to_excel(self.path)\n        read_frame = read_excel(self.path, true_values=['foo'],\n                                false_values=['bar'])\n        tm.assert_frame_equal(read_frame, expected)\n\n    def test_freeze_panes(self, merge_cells, engine, ext):\n        # GH15160\n        expected = DataFrame([[1, 2], [3, 4]], columns=['col1', 'col2'])\n        expected.to_excel(self.path, \"Sheet1\", freeze_panes=(1, 1))\n        result = read_excel(self.path)\n        tm.assert_frame_equal(expected, result)\n\n    def test_path_pathlib(self, merge_cells, engine, ext):\n        df = tm.makeDataFrame()\n        writer = partial(df.to_excel, engine=engine)\n        reader = partial(pd.read_excel)\n        result = tm.round_trip_pathlib(writer, reader,\n                                       path=\"foo.{}\".format(ext))\n        tm.assert_frame_equal(df, result)\n\n    def test_path_localpath(self, merge_cells, engine, ext):\n        df = tm.makeDataFrame()\n        writer = partial(df.to_excel, engine=engine)\n        reader = partial(pd.read_excel)\n        result = tm.round_trip_pathlib(writer, reader,\n                                       path=\"foo.{}\".format(ext))\n        tm.assert_frame_equal(df, result)\n\n\n@td.skip_if_no('openpyxl')\n@pytest.mark.parametrize(\"merge_cells,ext,engine\", [\n    (None, '.xlsx', 'openpyxl')])\nclass TestOpenpyxlTests(_WriterBase):\n\n    def test_to_excel_styleconverter(self, merge_cells, ext, engine):\n        from openpyxl import styles\n\n        hstyle = {\n            \"font\": {\n                \"color\": '00FF0000',\n                \"bold\": True,\n            },\n            \"borders\": {\n                \"top\": \"thin\",\n                \"right\": \"thin\",\n                \"bottom\": \"thin\",\n                \"left\": \"thin\",\n            },\n            \"alignment\": {\n                \"horizontal\": \"center\",\n                \"vertical\": \"top\",\n            },\n            \"fill\": {\n                \"patternType\": 'solid',\n                'fgColor': {\n                    'rgb': '006666FF',\n                    'tint': 0.3,\n                },\n            },\n            \"number_format\": {\n                \"format_code\": \"0.00\"\n            },\n            \"protection\": {\n                \"locked\": True,\n                \"hidden\": False,\n            },\n        }\n\n        font_color = styles.Color('00FF0000')\n        font = styles.Font(bold=True, color=font_color)\n        side = styles.Side(style=styles.borders.BORDER_THIN)\n        border = styles.Border(top=side, right=side, bottom=side, left=side)\n        alignment = styles.Alignment(horizontal='center', vertical='top')\n        fill_color = styles.Color(rgb='006666FF', tint=0.3)\n        fill = styles.PatternFill(patternType='solid', fgColor=fill_color)\n\n        number_format = '0.00'\n\n        protection = styles.Protection(locked=True, hidden=False)\n\n        kw = _OpenpyxlWriter._convert_to_style_kwargs(hstyle)\n        assert kw['font'] == font\n        assert kw['border'] == border\n        assert kw['alignment'] == alignment\n        assert kw['fill'] == fill\n        assert kw['number_format'] == number_format\n        assert kw['protection'] == protection\n\n    def test_write_cells_merge_styled(self, merge_cells, ext, engine):\n        from pandas.io.formats.excel import ExcelCell\n\n        sheet_name = 'merge_styled'\n\n        sty_b1 = {'font': {'color': '00FF0000'}}\n        sty_a2 = {'font': {'color': '0000FF00'}}\n\n        initial_cells = [\n            ExcelCell(col=1, row=0, val=42, style=sty_b1),\n            ExcelCell(col=0, row=1, val=99, style=sty_a2),\n        ]\n\n        sty_merged = {'font': {'color': '000000FF', 'bold': True}}\n        sty_kwargs = _OpenpyxlWriter._convert_to_style_kwargs(sty_merged)\n        openpyxl_sty_merged = sty_kwargs['font']\n        merge_cells = [\n            ExcelCell(col=0, row=0, val='pandas',\n                      mergestart=1, mergeend=1, style=sty_merged),\n        ]\n\n        with ensure_clean(ext) as path:\n            writer = _OpenpyxlWriter(path)\n            writer.write_cells(initial_cells, sheet_name=sheet_name)\n            writer.write_cells(merge_cells, sheet_name=sheet_name)\n\n            wks = writer.sheets[sheet_name]\n            xcell_b1 = wks['B1']\n            xcell_a2 = wks['A2']\n            assert xcell_b1.font == openpyxl_sty_merged\n            assert xcell_a2.font == openpyxl_sty_merged\n\n\n@td.skip_if_no('xlwt')\n@pytest.mark.parametrize(\"merge_cells,ext,engine\", [\n    (None, '.xls', 'xlwt')])\nclass TestXlwtTests(_WriterBase):\n\n    def test_excel_raise_error_on_multiindex_columns_and_no_index(\n            self, merge_cells, ext, engine):\n        # MultiIndex as columns is not yet implemented 9794\n        cols = MultiIndex.from_tuples([('site', ''),\n                                       ('2014', 'height'),\n                                       ('2014', 'weight')])\n        df = DataFrame(np.random.randn(10, 3), columns=cols)\n        with pytest.raises(NotImplementedError):\n            with ensure_clean(ext) as path:\n                df.to_excel(path, index=False)\n\n    def test_excel_multiindex_columns_and_index_true(self, merge_cells, ext,\n                                                     engine):\n        cols = MultiIndex.from_tuples([('site', ''),\n                                       ('2014', 'height'),\n                                       ('2014', 'weight')])\n        df = pd.DataFrame(np.random.randn(10, 3), columns=cols)\n        with ensure_clean(ext) as path:\n            df.to_excel(path, index=True)\n\n    def test_excel_multiindex_index(self, merge_cells, ext, engine):\n        # MultiIndex as index works so assert no error #9794\n        cols = MultiIndex.from_tuples([('site', ''),\n                                       ('2014', 'height'),\n                                       ('2014', 'weight')])\n        df = DataFrame(np.random.randn(3, 10), index=cols)\n        with ensure_clean(ext) as path:\n            df.to_excel(path, index=False)\n\n    def test_to_excel_styleconverter(self, merge_cells, ext, engine):\n        import xlwt\n\n        hstyle = {\"font\": {\"bold\": True},\n                  \"borders\": {\"top\": \"thin\",\n                              \"right\": \"thin\",\n                              \"bottom\": \"thin\",\n                              \"left\": \"thin\"},\n                  \"alignment\": {\"horizontal\": \"center\", \"vertical\": \"top\"}}\n\n        xls_style = _XlwtWriter._convert_to_style(hstyle)\n        assert xls_style.font.bold\n        assert xlwt.Borders.THIN == xls_style.borders.top\n        assert xlwt.Borders.THIN == xls_style.borders.right\n        assert xlwt.Borders.THIN == xls_style.borders.bottom\n        assert xlwt.Borders.THIN == xls_style.borders.left\n        assert xlwt.Alignment.HORZ_CENTER == xls_style.alignment.horz\n        assert xlwt.Alignment.VERT_TOP == xls_style.alignment.vert\n\n\n@td.skip_if_no('xlsxwriter')\n@pytest.mark.parametrize(\"merge_cells,ext,engine\", [\n    (None, '.xlsx', 'xlsxwriter')])\nclass TestXlsxWriterTests(_WriterBase):\n\n    @td.skip_if_no('openpyxl')\n    def test_column_format(self, merge_cells, ext, engine):\n        # Test that column formats are applied to cells. Test for issue #9167.\n        # Applicable to xlsxwriter only.\n        with warnings.catch_warnings():\n            # Ignore the openpyxl lxml warning.\n            warnings.simplefilter(\"ignore\")\n            import openpyxl\n\n        with ensure_clean(ext) as path:\n            frame = DataFrame({'A': [123456, 123456],\n                               'B': [123456, 123456]})\n\n            writer = ExcelWriter(path)\n            frame.to_excel(writer)\n\n            # Add a number format to col B and ensure it is applied to cells.\n            num_format = '#,##0'\n            write_workbook = writer.book\n            write_worksheet = write_workbook.worksheets()[0]\n            col_format = write_workbook.add_format({'num_format': num_format})\n            write_worksheet.set_column('B:B', None, col_format)\n            writer.save()\n\n            read_workbook = openpyxl.load_workbook(path)\n            try:\n                read_worksheet = read_workbook['Sheet1']\n            except TypeError:\n                # compat\n                read_worksheet = read_workbook.get_sheet_by_name(name='Sheet1')\n\n            # Get the number format from the cell.\n            try:\n                cell = read_worksheet['B2']\n            except TypeError:\n                # compat\n                cell = read_worksheet.cell('B2')\n\n            try:\n                read_num_format = cell.number_format\n            except Exception:\n                read_num_format = cell.style.number_format._format_code\n\n            assert read_num_format == num_format\n\n\nclass TestExcelWriterEngineTests(object):\n\n    @pytest.mark.parametrize('klass,ext', [\n        pytest.param(_XlsxWriter, '.xlsx', marks=pytest.mark.skipif(\n            not td.safe_import('xlsxwriter'), reason='No xlsxwriter')),\n        pytest.param(_OpenpyxlWriter, '.xlsx', marks=pytest.mark.skipif(\n            not td.safe_import('openpyxl'), reason='No openpyxl')),\n        pytest.param(_XlwtWriter, '.xls', marks=pytest.mark.skipif(\n            not td.safe_import('xlwt'), reason='No xlwt'))\n    ])\n    def test_ExcelWriter_dispatch(self, klass, ext):\n        with ensure_clean(ext) as path:\n            writer = ExcelWriter(path)\n            if ext == '.xlsx' and td.safe_import('xlsxwriter'):\n                # xlsxwriter has preference over openpyxl if both installed\n                assert isinstance(writer, _XlsxWriter)\n            else:\n                assert isinstance(writer, klass)\n\n    def test_ExcelWriter_dispatch_raises(self):\n        with tm.assert_raises_regex(ValueError, 'No engine'):\n            ExcelWriter('nothing')\n\n    def test_register_writer(self):\n        # some awkward mocking to test out dispatch and such actually works\n        called_save = []\n        called_write_cells = []\n\n        class DummyClass(ExcelWriter):\n            called_save = False\n            called_write_cells = False\n            supported_extensions = ['test', 'xlsx', 'xls']\n            engine = 'dummy'\n\n            def save(self):\n                called_save.append(True)\n\n            def write_cells(self, *args, **kwargs):\n                called_write_cells.append(True)\n\n        def check_called(func):\n            func()\n            assert len(called_save) >= 1\n            assert len(called_write_cells) >= 1\n            del called_save[:]\n            del called_write_cells[:]\n\n        with pd.option_context('io.excel.xlsx.writer', 'dummy'):\n            register_writer(DummyClass)\n            writer = ExcelWriter('something.test')\n            assert isinstance(writer, DummyClass)\n            df = tm.makeCustomDataframe(1, 1)\n\n            with catch_warnings(record=True):\n                panel = tm.makePanel()\n                func = lambda: df.to_excel('something.test')\n                check_called(func)\n                check_called(lambda: panel.to_excel('something.test'))\n                check_called(lambda: df.to_excel('something.xlsx'))\n                check_called(\n                    lambda: df.to_excel(\n                        'something.xls', engine='dummy'))\n\n\n@pytest.mark.parametrize('engine', [\n    pytest.param('xlwt',\n                 marks=pytest.mark.xfail(reason='xlwt does not support '\n                                                'openpyxl-compatible '\n                                                'style dicts')),\n    'xlsxwriter',\n    'openpyxl',\n])\ndef test_styler_to_excel(engine):\n    def style(df):\n        # XXX: RGB colors not supported in xlwt\n        return DataFrame([['font-weight: bold', '', ''],\n                          ['', 'color: blue', ''],\n                          ['', '', 'text-decoration: underline'],\n                          ['border-style: solid', '', ''],\n                          ['', 'font-style: italic', ''],\n                          ['', '', 'text-align: right'],\n                          ['background-color: red', '', ''],\n                          ['', '', ''],\n                          ['', '', ''],\n                          ['', '', '']],\n                         index=df.index, columns=df.columns)\n\n    def assert_equal_style(cell1, cell2):\n        # XXX: should find a better way to check equality\n        assert cell1.alignment.__dict__ == cell2.alignment.__dict__\n        assert cell1.border.__dict__ == cell2.border.__dict__\n        assert cell1.fill.__dict__ == cell2.fill.__dict__\n        assert cell1.font.__dict__ == cell2.font.__dict__\n        assert cell1.number_format == cell2.number_format\n        assert cell1.protection.__dict__ == cell2.protection.__dict__\n\n    def custom_converter(css):\n        # use bold iff there is custom style attached to the cell\n        if css.strip(' \\n;'):\n            return {'font': {'bold': True}}\n        return {}\n\n    pytest.importorskip('jinja2')\n    pytest.importorskip(engine)\n\n    # Prepare spreadsheets\n\n    df = DataFrame(np.random.randn(10, 3))\n    with ensure_clean('.xlsx' if engine != 'xlwt' else '.xls') as path:\n        writer = ExcelWriter(path, engine=engine)\n        df.to_excel(writer, sheet_name='frame')\n        df.style.to_excel(writer, sheet_name='unstyled')\n        styled = df.style.apply(style, axis=None)\n        styled.to_excel(writer, sheet_name='styled')\n        ExcelFormatter(styled, style_converter=custom_converter).write(\n            writer, sheet_name='custom')\n        writer.save()\n\n        if engine not in ('openpyxl', 'xlsxwriter'):\n            # For other engines, we only smoke test\n            return\n        openpyxl = pytest.importorskip('openpyxl')\n        wb = openpyxl.load_workbook(path)\n\n        # (1) compare DataFrame.to_excel and Styler.to_excel when unstyled\n        n_cells = 0\n        for col1, col2 in zip(wb['frame'].columns,\n                              wb['unstyled'].columns):\n            assert len(col1) == len(col2)\n            for cell1, cell2 in zip(col1, col2):\n                assert cell1.value == cell2.value\n                assert_equal_style(cell1, cell2)\n                n_cells += 1\n\n        # ensure iteration actually happened:\n        assert n_cells == (10 + 1) * (3 + 1)\n\n        # (2) check styling with default converter\n\n        # XXX: openpyxl (as at 2.4) prefixes colors with 00, xlsxwriter with FF\n        alpha = '00' if engine == 'openpyxl' else 'FF'\n\n        n_cells = 0\n        for col1, col2 in zip(wb['frame'].columns,\n                              wb['styled'].columns):\n            assert len(col1) == len(col2)\n            for cell1, cell2 in zip(col1, col2):\n                ref = '%s%d' % (cell2.column, cell2.row)\n                # XXX: this isn't as strong a test as ideal; we should\n                #      confirm that differences are exclusive\n                if ref == 'B2':\n                    assert not cell1.font.bold\n                    assert cell2.font.bold\n                elif ref == 'C3':\n                    assert cell1.font.color.rgb != cell2.font.color.rgb\n                    assert cell2.font.color.rgb == alpha + '0000FF'\n                elif ref == 'D4':\n                    # This fails with engine=xlsxwriter due to\n                    # https://bitbucket.org/openpyxl/openpyxl/issues/800\n                    if engine == 'xlsxwriter' \\\n                       and (LooseVersion(openpyxl.__version__) <\n                            LooseVersion('2.4.6')):\n                        pass\n                    else:\n                        assert cell1.font.underline != cell2.font.underline\n                        assert cell2.font.underline == 'single'\n                elif ref == 'B5':\n                    assert not cell1.border.left.style\n                    assert (cell2.border.top.style ==\n                            cell2.border.right.style ==\n                            cell2.border.bottom.style ==\n                            cell2.border.left.style ==\n                            'medium')\n                elif ref == 'C6':\n                    assert not cell1.font.italic\n                    assert cell2.font.italic\n                elif ref == 'D7':\n                    assert (cell1.alignment.horizontal !=\n                            cell2.alignment.horizontal)\n                    assert cell2.alignment.horizontal == 'right'\n                elif ref == 'B8':\n                    assert cell1.fill.fgColor.rgb != cell2.fill.fgColor.rgb\n                    assert cell1.fill.patternType != cell2.fill.patternType\n                    assert cell2.fill.fgColor.rgb == alpha + 'FF0000'\n                    assert cell2.fill.patternType == 'solid'\n                else:\n                    assert_equal_style(cell1, cell2)\n\n                assert cell1.value == cell2.value\n                n_cells += 1\n\n        assert n_cells == (10 + 1) * (3 + 1)\n\n        # (3) check styling with custom converter\n        n_cells = 0\n        for col1, col2 in zip(wb['frame'].columns,\n                              wb['custom'].columns):\n            assert len(col1) == len(col2)\n            for cell1, cell2 in zip(col1, col2):\n                ref = '%s%d' % (cell2.column, cell2.row)\n                if ref in ('B2', 'C3', 'D4', 'B5', 'C6', 'D7', 'B8'):\n                    assert not cell1.font.bold\n                    assert cell2.font.bold\n                else:\n                    assert_equal_style(cell1, cell2)\n\n                assert cell1.value == cell2.value\n                n_cells += 1\n\n        assert n_cells == (10 + 1) * (3 + 1)\n\n\n@td.skip_if_no('openpyxl')\n@pytest.mark.skipif(not PY36, reason='requires fspath')\nclass TestFSPath(object):\n\n    def test_excelfile_fspath(self):\n        with tm.ensure_clean('foo.xlsx') as path:\n            df = DataFrame({\"A\": [1, 2]})\n            df.to_excel(path)\n            xl = ExcelFile(path)\n            result = os.fspath(xl)\n            assert result == path\n\n    def test_excelwriter_fspath(self):\n        with tm.ensure_clean('foo.xlsx') as path:\n            writer = ExcelWriter(path)\n            assert os.fspath(writer) == str(path)\n"
    }
  ]
}