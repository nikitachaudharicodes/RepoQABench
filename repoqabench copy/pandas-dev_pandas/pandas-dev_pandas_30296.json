{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "30296",
  "issue_description": "# DEPR: Remove pandas.np\n\nNot sure if it was added intentionally, but it's possible to call numpy with the `np` attribute of the pandas module:\r\n```python\r\nimport pandas\r\nx = pandas.np.array([1, 2, 3])\r\n```\r\nWhile this is not documented, I've seen couple of places suggesting this as a \"trick\" to avoid importing numpy directly.\r\n\r\nI personally find this hacky, and I think should be removed. ",
  "issue_comments": [
    {
      "id": 566410831,
      "user": "AlexKirko",
      "body": "There is a chance removing this will break something, in case adding it wasn't random, but I believe it should still be removed. It's ugly and the issues that might arise are easily fixable.\r\nAs far as I can see, all this would entail is a one-line edit to `__init__.py` I found no explanation why `np` was added in the code or in the API reference.\r\nEdit: I did find a colleague who relied on this, so even if our code doesn't break anything in the library (or if we fix it), this change will still break backward compatibility for some users."
    },
    {
      "id": 566417179,
      "user": "datapythonista",
      "body": "We remove everything gradually, by first raising warnings.\r\n\r\nI think there are other things we may also want to check if we should remove, I saw a `pandas.array` that I guess is an alias for `numpy.array`."
    },
    {
      "id": 566417382,
      "user": "mroeschke",
      "body": "Similar but more minor, looks like users will also import `datetime.datetime` with `import pandas` which I find odd.\r\n\r\n```\r\nIn [1]: import pandas\r\n\r\nIn [2]: pandas.datetime\r\nOut[2]: datetime.datetime\r\n```"
    },
    {
      "id": 566418786,
      "user": "AlexKirko",
      "body": "Fair point about the deprecation warning.\r\n\r\n`pd.array`, however, isn't just an alias. It allows to make arrays of pandas-specific datatypes.\r\n\r\nThis works:\r\n```\r\npd.array([1,2,3], dtype=pd.Int64Dtype())\r\n\r\n<IntegerArray>\r\n[1, 2, 3]\r\nLength: 3, dtype: Int64\r\n```\r\nThis doesn't:\r\n```\r\nnp.array([1,2,3], dtype=pd.Int64Dtype())\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-7-6ae38424b9f7> in <module>\r\n----> 1 np.array([1,2,3], dtype=pd.Int64Dtype())\r\n\r\nTypeError: data type not understood\r\n```"
    },
    {
      "id": 566427199,
      "user": "xhochy",
      "body": "The numpy import is actually explicit: https://github.com/pandas-dev/pandas/blob/37dfcc1acf3b37a1ff5251fee3380a179da1f2ed/pandas/__init__.py#L108 but is simply a redirect to normal `numpy`: https://github.com/pandas-dev/pandas/blob/37dfcc1acf3b37a1ff5251fee3380a179da1f2ed/pandas/core/api.py#L3 Still, I have often met users that swear that `pandas.np` is different from `np` as it provides a compatability layer between NumPy and pandas. Removing this alias would also wipe out this myth. As it is just an alias, the breaking change is really easy to resolve.\r\n\r\nThe `datetime` import is also https://github.com/pandas-dev/pandas/blob/37dfcc1acf3b37a1ff5251fee3380a179da1f2ed/pandas/__init__.py#L42 only there for importing it via `pandas.datetime`. There is no usage of it in the `__init__.py`."
    },
    {
      "id": 566429369,
      "user": "jorisvandenbossche",
      "body": "For python 3.7+, we can actually deprecate this with the module getattr trick (the same we use for Panel dummy class right now). So I think we can go through a deprecation cycle instead of directly removing (for python 3.6, this is more difficult though)."
    },
    {
      "id": 566429590,
      "user": "datapythonista",
      "body": "> `pd.array`, however, isn't just an alias.\r\n\r\nYep, I got confused, it's obviously our own array. "
    },
    {
      "id": 567725576,
      "user": "lithomas1",
      "body": "take"
    },
    {
      "id": 568023149,
      "user": "TomAugspurger",
      "body": "Are we wanting to do this for 1.0, or should it wait, or does it not matter?"
    },
    {
      "id": 568026357,
      "user": "datapythonista",
      "body": "Would be nice, but I don't think it's important, since it won't be removed until 2.0 I guess."
    },
    {
      "id": 568143058,
      "user": "jbrockmendel",
      "body": "`datetime` was also suggested for this treatment.  what else doesn't belong in the top-level namespace?  Some candidates:\r\n\r\n- `__docformat__`  (is this a legacy thing or is it actually used by sphinx or something?)\r\n- `_hashtable`, `_lib`, `_tslib`\r\n- `datetime`\r\n- `isnull`, `notnull` (weren't these deprecated a while back?)\r\n- `_np_version_under1p*`\r\n- `_version`\r\n"
    },
    {
      "id": 568143364,
      "user": "jreback",
      "body": "the private modules don’t show up anyhow so reallly nbd in those\r\n\r\nwe didn’t actually depreciate isnull/notnull"
    },
    {
      "id": 568207386,
      "user": "ryankarlos",
      "body": "Can i have a go at datetime or  isnull/notnull ? "
    },
    {
      "id": 568207996,
      "user": "jorisvandenbossche",
      "body": "I think it is better to first finalize the open PR: https://github.com/pandas-dev/pandas/pull/30386. \r\n\r\nAlso, if we want to deprecate isnull/notnull, let's first discuss that in a separate issue, as this is a quite different thing. Here we are discussing shortcuts for external packages."
    },
    {
      "id": 568930146,
      "user": "ryankarlos",
      "body": "ok will wait for this PR to be merged - if datetime still requires treatment in this issue then happy to work on that. "
    },
    {
      "id": 568930711,
      "user": "datapythonista",
      "body": "I think we want to get rid of `pandas.datetime`, and I don't think there shouldn't be important conflicts with #30386 if you open the PR in parallel."
    },
    {
      "id": 568933977,
      "user": "ryankarlos",
      "body": "ok will do, thanks @datapythonista "
    },
    {
      "id": 607907420,
      "user": "CharlyWargnier",
      "body": "Hi guys,\r\n\r\nI've got this code:\r\n\r\n`df['SEBotClass'] = pd.np.where(df.userAgent.str.contains(\"YandexBot\"), \"YandexBot\",\r\n  pd.np.where(df.userAgent.str.contains(\"bingbot\"), \"BingBot\",\r\n    pd.np.where(df.userAgent.str.contains(\"DuckDuckBot\"), \"DuckDuckGo\",\r\n      pd.np.where(df.userAgent.str.contains(\"Baiduspider\"), \"Baidu\",\r\n        pd.np.where(df.userAgent.str.contains(\"Googlebot/2.1\"), \"GoogleBot\", \"Else\")))))\r\nnan=pd.np.nan`\r\n\r\nWhich now gives this warning message:\r\n\r\n> FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\r\n\r\nWhat do I need to do to avoid that warning?\r\n\r\nThanks! :)\r\n\r\n"
    },
    {
      "id": 607910923,
      "user": "jorisvandenbossche",
      "body": "Replace `pd.np` with `np` in your code above (after doing `import numpy as np`)"
    },
    {
      "id": 607913152,
      "user": "CharlyWargnier",
      "body": "Thanks Joris!"
    }
  ],
  "text_context": "# DEPR: Remove pandas.np\n\nNot sure if it was added intentionally, but it's possible to call numpy with the `np` attribute of the pandas module:\r\n```python\r\nimport pandas\r\nx = pandas.np.array([1, 2, 3])\r\n```\r\nWhile this is not documented, I've seen couple of places suggesting this as a \"trick\" to avoid importing numpy directly.\r\n\r\nI personally find this hacky, and I think should be removed. \n\nThere is a chance removing this will break something, in case adding it wasn't random, but I believe it should still be removed. It's ugly and the issues that might arise are easily fixable.\r\nAs far as I can see, all this would entail is a one-line edit to `__init__.py` I found no explanation why `np` was added in the code or in the API reference.\r\nEdit: I did find a colleague who relied on this, so even if our code doesn't break anything in the library (or if we fix it), this change will still break backward compatibility for some users.\n\nWe remove everything gradually, by first raising warnings.\r\n\r\nI think there are other things we may also want to check if we should remove, I saw a `pandas.array` that I guess is an alias for `numpy.array`.\n\nSimilar but more minor, looks like users will also import `datetime.datetime` with `import pandas` which I find odd.\r\n\r\n```\r\nIn [1]: import pandas\r\n\r\nIn [2]: pandas.datetime\r\nOut[2]: datetime.datetime\r\n```\n\nFair point about the deprecation warning.\r\n\r\n`pd.array`, however, isn't just an alias. It allows to make arrays of pandas-specific datatypes.\r\n\r\nThis works:\r\n```\r\npd.array([1,2,3], dtype=pd.Int64Dtype())\r\n\r\n<IntegerArray>\r\n[1, 2, 3]\r\nLength: 3, dtype: Int64\r\n```\r\nThis doesn't:\r\n```\r\nnp.array([1,2,3], dtype=pd.Int64Dtype())\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-7-6ae38424b9f7> in <module>\r\n----> 1 np.array([1,2,3], dtype=pd.Int64Dtype())\r\n\r\nTypeError: data type not understood\r\n```\n\nThe numpy import is actually explicit: https://github.com/pandas-dev/pandas/blob/37dfcc1acf3b37a1ff5251fee3380a179da1f2ed/pandas/__init__.py#L108 but is simply a redirect to normal `numpy`: https://github.com/pandas-dev/pandas/blob/37dfcc1acf3b37a1ff5251fee3380a179da1f2ed/pandas/core/api.py#L3 Still, I have often met users that swear that `pandas.np` is different from `np` as it provides a compatability layer between NumPy and pandas. Removing this alias would also wipe out this myth. As it is just an alias, the breaking change is really easy to resolve.\r\n\r\nThe `datetime` import is also https://github.com/pandas-dev/pandas/blob/37dfcc1acf3b37a1ff5251fee3380a179da1f2ed/pandas/__init__.py#L42 only there for importing it via `pandas.datetime`. There is no usage of it in the `__init__.py`.\n\nFor python 3.7+, we can actually deprecate this with the module getattr trick (the same we use for Panel dummy class right now). So I think we can go through a deprecation cycle instead of directly removing (for python 3.6, this is more difficult though).\n\n> `pd.array`, however, isn't just an alias.\r\n\r\nYep, I got confused, it's obviously our own array. \n\ntake\n\nAre we wanting to do this for 1.0, or should it wait, or does it not matter?\n\nWould be nice, but I don't think it's important, since it won't be removed until 2.0 I guess.\n\n`datetime` was also suggested for this treatment.  what else doesn't belong in the top-level namespace?  Some candidates:\r\n\r\n- `__docformat__`  (is this a legacy thing or is it actually used by sphinx or something?)\r\n- `_hashtable`, `_lib`, `_tslib`\r\n- `datetime`\r\n- `isnull`, `notnull` (weren't these deprecated a while back?)\r\n- `_np_version_under1p*`\r\n- `_version`\r\n\n\nthe private modules don’t show up anyhow so reallly nbd in those\r\n\r\nwe didn’t actually depreciate isnull/notnull\n\nCan i have a go at datetime or  isnull/notnull ? \n\nI think it is better to first finalize the open PR: https://github.com/pandas-dev/pandas/pull/30386. \r\n\r\nAlso, if we want to deprecate isnull/notnull, let's first discuss that in a separate issue, as this is a quite different thing. Here we are discussing shortcuts for external packages.\n\nok will wait for this PR to be merged - if datetime still requires treatment in this issue then happy to work on that. \n\nI think we want to get rid of `pandas.datetime`, and I don't think there shouldn't be important conflicts with #30386 if you open the PR in parallel.\n\nok will do, thanks @datapythonista \n\nHi guys,\r\n\r\nI've got this code:\r\n\r\n`df['SEBotClass'] = pd.np.where(df.userAgent.str.contains(\"YandexBot\"), \"YandexBot\",\r\n  pd.np.where(df.userAgent.str.contains(\"bingbot\"), \"BingBot\",\r\n    pd.np.where(df.userAgent.str.contains(\"DuckDuckBot\"), \"DuckDuckGo\",\r\n      pd.np.where(df.userAgent.str.contains(\"Baiduspider\"), \"Baidu\",\r\n        pd.np.where(df.userAgent.str.contains(\"Googlebot/2.1\"), \"GoogleBot\", \"Else\")))))\r\nnan=pd.np.nan`\r\n\r\nWhich now gives this warning message:\r\n\r\n> FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\r\n\r\nWhat do I need to do to avoid that warning?\r\n\r\nThanks! :)\r\n\r\n\n\nReplace `pd.np` with `np` in your code above (after doing `import numpy as np`)\n\nThanks Joris!",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/30386",
  "code_context": [
    {
      "filename": "pandas/__init__.py",
      "content": "# flake8: noqa\n\n__docformat__ = \"restructuredtext\"\n\n# Let users know if they're missing any of our hard dependencies\nhard_dependencies = (\"numpy\", \"pytz\", \"dateutil\")\nmissing_dependencies = []\n\nfor dependency in hard_dependencies:\n    try:\n        __import__(dependency)\n    except ImportError as e:\n        missing_dependencies.append(\"{0}: {1}\".format(dependency, str(e)))\n\nif missing_dependencies:\n    raise ImportError(\n        \"Unable to import required dependencies:\\n\" + \"\\n\".join(missing_dependencies)\n    )\ndel hard_dependencies, dependency, missing_dependencies\n\n# numpy compat\nfrom pandas.compat.numpy import (\n    _np_version_under1p14,\n    _np_version_under1p15,\n    _np_version_under1p16,\n    _np_version_under1p17,\n    _np_version_under1p18,\n)\n\ntry:\n    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib\nexcept ImportError as e:  # pragma: no cover\n    # hack but overkill to use re\n    module = str(e).replace(\"cannot import name \", \"\")\n    raise ImportError(\n        \"C extension: {0} not built. If you want to import \"\n        \"pandas from the source directory, you may need to run \"\n        \"'python setup.py build_ext --inplace --force' to build \"\n        \"the C extensions first.\".format(module)\n    )\n\nfrom datetime import datetime\n\nfrom pandas._config import (\n    get_option,\n    set_option,\n    reset_option,\n    describe_option,\n    option_context,\n    options,\n)\n\n# let init-time option registration happen\nimport pandas.core.config_init\n\nfrom pandas.core.api import (\n    # dtype\n    Int8Dtype,\n    Int16Dtype,\n    Int32Dtype,\n    Int64Dtype,\n    UInt8Dtype,\n    UInt16Dtype,\n    UInt32Dtype,\n    UInt64Dtype,\n    CategoricalDtype,\n    PeriodDtype,\n    IntervalDtype,\n    DatetimeTZDtype,\n    StringDtype,\n    BooleanDtype,\n    # missing\n    NA,\n    isna,\n    isnull,\n    notna,\n    notnull,\n    # indexes\n    Index,\n    CategoricalIndex,\n    Int64Index,\n    UInt64Index,\n    RangeIndex,\n    Float64Index,\n    MultiIndex,\n    IntervalIndex,\n    TimedeltaIndex,\n    DatetimeIndex,\n    PeriodIndex,\n    IndexSlice,\n    # tseries\n    NaT,\n    Period,\n    period_range,\n    Timedelta,\n    timedelta_range,\n    Timestamp,\n    date_range,\n    bdate_range,\n    Interval,\n    interval_range,\n    DateOffset,\n    # conversion\n    to_numeric,\n    to_datetime,\n    to_timedelta,\n    # misc\n    Grouper,\n    factorize,\n    unique,\n    value_counts,\n    NamedAgg,\n    array,\n    Categorical,\n    set_eng_float_format,\n    Series,\n    DataFrame,\n)\n\nfrom pandas.core.arrays.sparse import SparseArray, SparseDtype\n\nfrom pandas.tseries.api import infer_freq\nfrom pandas.tseries import offsets\n\nfrom pandas.core.computation.api import eval\n\nfrom pandas.core.reshape.api import (\n    concat,\n    lreshape,\n    melt,\n    wide_to_long,\n    merge,\n    merge_asof,\n    merge_ordered,\n    crosstab,\n    pivot,\n    pivot_table,\n    get_dummies,\n    cut,\n    qcut,\n)\n\nfrom pandas.util._print_versions import show_versions\n\nfrom pandas.io.api import (\n    # excel\n    ExcelFile,\n    ExcelWriter,\n    read_excel,\n    # parsers\n    read_csv,\n    read_fwf,\n    read_table,\n    # pickle\n    read_pickle,\n    to_pickle,\n    # pytables\n    HDFStore,\n    read_hdf,\n    # sql\n    read_sql,\n    read_sql_query,\n    read_sql_table,\n    # misc\n    read_clipboard,\n    read_parquet,\n    read_orc,\n    read_feather,\n    read_gbq,\n    read_html,\n    read_json,\n    read_stata,\n    read_sas,\n    read_spss,\n)\n\nfrom pandas.io.json import _json_normalize as json_normalize\n\nfrom pandas.util._tester import test\nimport pandas.testing\nimport pandas.arrays\n\n# use the closest tagged version if possible\nfrom ._version import get_versions\n\nv = get_versions()\n__version__ = v.get(\"closest-tag\", v[\"version\"])\n__git_version__ = v.get(\"full-revisionid\")\ndel get_versions, v\n\n# GH 27101\n# TODO: remove Panel compat in 1.0\nif pandas.compat.PY37:\n\n    def __getattr__(name):\n        import warnings\n\n        if name == \"Panel\":\n\n            warnings.warn(\n                \"The Panel class is removed from pandas. Accessing it \"\n                \"from the top-level namespace will also be removed in \"\n                \"the next version\",\n                FutureWarning,\n                stacklevel=2,\n            )\n\n            class Panel:\n                pass\n\n            return Panel\n\n        elif name == \"np\":\n\n            warnings.warn(\n                \"The pandas.np module is deprecated \"\n                \"and will be removed from pandas in a future version. \"\n                \"Import numpy directly instead\",\n                FutureWarning,\n                stacklevel=2,\n            )\n            import numpy as np\n\n            return np\n\n        elif name in {\"SparseSeries\", \"SparseDataFrame\"}:\n            warnings.warn(\n                \"The {} class is removed from pandas. Accessing it from \"\n                \"the top-level namespace will also be removed in the next \"\n                \"version\".format(name),\n                FutureWarning,\n                stacklevel=2,\n            )\n\n            return type(name, (), {})\n\n        raise AttributeError(\"module 'pandas' has no attribute '{}'\".format(name))\n\n\nelse:\n\n    class Panel:\n        pass\n\n    class SparseDataFrame:\n        pass\n\n    class SparseSeries:\n        pass\n\n    class __numpy:\n        def __init__(self):\n            import numpy as np\n            import warnings\n\n            self.np = np\n            self.warnings = warnings\n\n        def __getattr__(self, item):\n            self.warnings.warn(\n                \"The pandas.np module is deprecated \"\n                \"and will be removed from pandas in a future version. \"\n                \"Import numpy directly instead\",\n                FutureWarning,\n                stacklevel=2,\n            )\n            try:\n                return getattr(self.np, item)\n            except AttributeError:\n                raise AttributeError(f\"module numpy has no attribute {item}\")\n\n    np = __numpy()\n\n# module level doc-string\n__doc__ = \"\"\"\npandas - a powerful data analysis and manipulation library for Python\n=====================================================================\n\n**pandas** is a Python package providing fast, flexible, and expressive data\nstructures designed to make working with \"relational\" or \"labeled\" data both\neasy and intuitive. It aims to be the fundamental high-level building block for\ndoing practical, **real world** data analysis in Python. Additionally, it has\nthe broader goal of becoming **the most powerful and flexible open source data\nanalysis / manipulation tool available in any language**. It is already well on\nits way toward this goal.\n\nMain Features\n-------------\nHere are just a few of the things that pandas does well:\n\n  - Easy handling of missing data in floating point as well as non-floating\n    point data.\n  - Size mutability: columns can be inserted and deleted from DataFrame and\n    higher dimensional objects\n  - Automatic and explicit data alignment: objects can be explicitly aligned\n    to a set of labels, or the user can simply ignore the labels and let\n    `Series`, `DataFrame`, etc. automatically align the data for you in\n    computations.\n  - Powerful, flexible group by functionality to perform split-apply-combine\n    operations on data sets, for both aggregating and transforming data.\n  - Make it easy to convert ragged, differently-indexed data in other Python\n    and NumPy data structures into DataFrame objects.\n  - Intelligent label-based slicing, fancy indexing, and subsetting of large\n    data sets.\n  - Intuitive merging and joining data sets.\n  - Flexible reshaping and pivoting of data sets.\n  - Hierarchical labeling of axes (possible to have multiple labels per tick).\n  - Robust IO tools for loading data from flat files (CSV and delimited),\n    Excel files, databases, and saving/loading data from the ultrafast HDF5\n    format.\n  - Time series-specific functionality: date range generation and frequency\n    conversion, moving window statistics, date shifting and lagging.\n\"\"\"\n"
    },
    {
      "filename": "pandas/core/api.py",
      "content": "# flake8: noqa\n\nfrom pandas._libs import NaT, Period, Timedelta, Timestamp\nfrom pandas._libs.missing import NA\n\nfrom pandas.core.dtypes.dtypes import (\n    CategoricalDtype,\n    DatetimeTZDtype,\n    IntervalDtype,\n    PeriodDtype,\n)\nfrom pandas.core.dtypes.missing import isna, isnull, notna, notnull\n\nfrom pandas.core.algorithms import factorize, unique, value_counts\nfrom pandas.core.arrays import Categorical\nfrom pandas.core.arrays.boolean import BooleanDtype\nfrom pandas.core.arrays.integer import (\n    Int8Dtype,\n    Int16Dtype,\n    Int32Dtype,\n    Int64Dtype,\n    UInt8Dtype,\n    UInt16Dtype,\n    UInt32Dtype,\n    UInt64Dtype,\n)\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.construction import array\nfrom pandas.core.groupby import Grouper, NamedAgg\nfrom pandas.core.indexes.api import (\n    CategoricalIndex,\n    DatetimeIndex,\n    Float64Index,\n    Index,\n    Int64Index,\n    IntervalIndex,\n    MultiIndex,\n    PeriodIndex,\n    RangeIndex,\n    TimedeltaIndex,\n    UInt64Index,\n)\nfrom pandas.core.indexes.datetimes import bdate_range, date_range\nfrom pandas.core.indexes.interval import Interval, interval_range\nfrom pandas.core.indexes.period import period_range\nfrom pandas.core.indexes.timedeltas import timedelta_range\nfrom pandas.core.indexing import IndexSlice\nfrom pandas.core.series import Series\nfrom pandas.core.tools.datetimes import to_datetime\nfrom pandas.core.tools.numeric import to_numeric\nfrom pandas.core.tools.timedeltas import to_timedelta\n\nfrom pandas.io.formats.format import set_eng_float_format\nfrom pandas.tseries.offsets import DateOffset\n\n# DataFrame needs to be imported after NamedAgg to avoid a circular import\nfrom pandas.core.frame import DataFrame  # isort:skip\n"
    },
    {
      "filename": "pandas/tests/api/test_api.py",
      "content": "from typing import List\n\nimport pandas as pd\nfrom pandas import api, compat\nimport pandas.util.testing as tm\n\n\nclass Base:\n    def check(self, namespace, expected, ignored=None):\n        # see which names are in the namespace, minus optional\n        # ignored ones\n        # compare vs the expected\n\n        result = sorted(f for f in dir(namespace) if not f.startswith(\"__\"))\n        if ignored is not None:\n            result = sorted(set(result) - set(ignored))\n\n        expected = sorted(expected)\n        tm.assert_almost_equal(result, expected)\n\n\nclass TestPDApi(Base):\n    # these are optionally imported based on testing\n    # & need to be ignored\n    ignored = [\"tests\", \"locale\", \"conftest\"]\n\n    # top-level sub-packages\n    lib = [\n        \"api\",\n        \"arrays\",\n        \"compat\",\n        \"core\",\n        \"errors\",\n        \"pandas\",\n        \"plotting\",\n        \"test\",\n        \"testing\",\n        \"tseries\",\n        \"util\",\n        \"options\",\n        \"io\",\n    ]\n\n    # these are already deprecated; awaiting removal\n    deprecated_modules: List[str] = []\n\n    # misc\n    misc = [\"IndexSlice\", \"NaT\", \"NA\"]\n\n    # top-level classes\n    classes = [\n        \"Categorical\",\n        \"CategoricalIndex\",\n        \"DataFrame\",\n        \"DateOffset\",\n        \"DatetimeIndex\",\n        \"ExcelFile\",\n        \"ExcelWriter\",\n        \"Float64Index\",\n        \"Grouper\",\n        \"HDFStore\",\n        \"Index\",\n        \"Int64Index\",\n        \"MultiIndex\",\n        \"Period\",\n        \"PeriodIndex\",\n        \"RangeIndex\",\n        \"UInt64Index\",\n        \"Series\",\n        \"SparseArray\",\n        \"SparseDtype\",\n        \"StringDtype\",\n        \"Timedelta\",\n        \"TimedeltaIndex\",\n        \"Timestamp\",\n        \"Interval\",\n        \"IntervalIndex\",\n        \"CategoricalDtype\",\n        \"PeriodDtype\",\n        \"IntervalDtype\",\n        \"DatetimeTZDtype\",\n        \"BooleanDtype\",\n        \"Int8Dtype\",\n        \"Int16Dtype\",\n        \"Int32Dtype\",\n        \"Int64Dtype\",\n        \"UInt8Dtype\",\n        \"UInt16Dtype\",\n        \"UInt32Dtype\",\n        \"UInt64Dtype\",\n        \"NamedAgg\",\n    ]\n    if not compat.PY37:\n        classes.extend([\"Panel\", \"SparseSeries\", \"SparseDataFrame\"])\n        deprecated_modules.append(\"np\")\n\n    # these are already deprecated; awaiting removal\n    deprecated_classes: List[str] = []\n\n    # these should be deprecated in the future\n    deprecated_classes_in_future: List[str] = []\n\n    # external modules exposed in pandas namespace\n    modules = [\"datetime\"]\n\n    # top-level functions\n    funcs = [\n        \"array\",\n        \"bdate_range\",\n        \"concat\",\n        \"crosstab\",\n        \"cut\",\n        \"date_range\",\n        \"interval_range\",\n        \"eval\",\n        \"factorize\",\n        \"get_dummies\",\n        \"infer_freq\",\n        \"isna\",\n        \"isnull\",\n        \"lreshape\",\n        \"melt\",\n        \"notna\",\n        \"notnull\",\n        \"offsets\",\n        \"merge\",\n        \"merge_ordered\",\n        \"merge_asof\",\n        \"period_range\",\n        \"pivot\",\n        \"pivot_table\",\n        \"qcut\",\n        \"show_versions\",\n        \"timedelta_range\",\n        \"unique\",\n        \"value_counts\",\n        \"wide_to_long\",\n    ]\n\n    # top-level option funcs\n    funcs_option = [\n        \"reset_option\",\n        \"describe_option\",\n        \"get_option\",\n        \"option_context\",\n        \"set_option\",\n        \"set_eng_float_format\",\n    ]\n\n    # top-level read_* funcs\n    funcs_read = [\n        \"read_clipboard\",\n        \"read_csv\",\n        \"read_excel\",\n        \"read_fwf\",\n        \"read_gbq\",\n        \"read_hdf\",\n        \"read_html\",\n        \"read_json\",\n        \"read_pickle\",\n        \"read_sas\",\n        \"read_sql\",\n        \"read_sql_query\",\n        \"read_sql_table\",\n        \"read_stata\",\n        \"read_table\",\n        \"read_feather\",\n        \"read_parquet\",\n        \"read_orc\",\n        \"read_spss\",\n    ]\n\n    # top-level json funcs\n    funcs_json = [\"json_normalize\"]\n\n    # top-level to_* funcs\n    funcs_to = [\"to_datetime\", \"to_numeric\", \"to_pickle\", \"to_timedelta\"]\n\n    # top-level to deprecate in the future\n    deprecated_funcs_in_future: List[str] = []\n\n    # these are already deprecated; awaiting removal\n    deprecated_funcs: List[str] = []\n\n    # private modules in pandas namespace\n    private_modules = [\n        \"_config\",\n        \"_hashtable\",\n        \"_lib\",\n        \"_libs\",\n        \"_np_version_under1p14\",\n        \"_np_version_under1p15\",\n        \"_np_version_under1p16\",\n        \"_np_version_under1p17\",\n        \"_np_version_under1p18\",\n        \"_tslib\",\n        \"_typing\",\n        \"_version\",\n    ]\n\n    def test_api(self):\n\n        self.check(\n            pd,\n            self.lib\n            + self.misc\n            + self.modules\n            + self.deprecated_modules\n            + self.classes\n            + self.deprecated_classes\n            + self.deprecated_classes_in_future\n            + self.funcs\n            + self.funcs_option\n            + self.funcs_read\n            + self.funcs_json\n            + self.funcs_to\n            + self.deprecated_funcs_in_future\n            + self.deprecated_funcs\n            + self.private_modules,\n            self.ignored,\n        )\n\n    def test_depr(self):\n        deprecated = (\n            self.deprecated_modules\n            + self.deprecated_classes\n            + self.deprecated_classes_in_future\n            + self.deprecated_funcs\n            + self.deprecated_funcs_in_future\n        )\n        for depr in deprecated:\n            with tm.assert_produces_warning(FutureWarning):\n                if compat.PY37:\n                    getattr(pd, depr)\n                else:\n                    deprecated = getattr(pd, depr)\n                    deprecated.__getattr__(dir(deprecated)[-1])\n\n\ndef test_np():\n    import numpy as np\n    import warnings\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", FutureWarning)\n        assert (pd.np.arange(0, 10) == np.arange(0, 10)).all()\n\n\nclass TestApi(Base):\n    allowed = [\"types\", \"extensions\", \"indexers\"]\n\n    def test_api(self):\n        self.check(api, self.allowed)\n\n\nclass TestTesting(Base):\n    funcs = [\"assert_frame_equal\", \"assert_series_equal\", \"assert_index_equal\"]\n\n    def test_testing(self):\n        from pandas import testing\n\n        self.check(testing, self.funcs)\n"
    },
    {
      "filename": "pandas/tests/indexes/period/test_indexing.py",
      "content": "from datetime import datetime, timedelta\n\nimport numpy as np\nimport pytest\n\nfrom pandas._libs.tslibs import period as libperiod\n\nimport pandas as pd\nfrom pandas import DatetimeIndex, Period, PeriodIndex, Series, notna, period_range\nimport pandas.util.testing as tm\n\n\nclass TestGetItem:\n    def test_ellipsis(self):\n        # GH#21282\n        idx = period_range(\"2011-01-01\", \"2011-01-31\", freq=\"D\", name=\"idx\")\n\n        result = idx[...]\n        assert result.equals(idx)\n        assert result is not idx\n\n    def test_getitem(self):\n        idx1 = pd.period_range(\"2011-01-01\", \"2011-01-31\", freq=\"D\", name=\"idx\")\n\n        for idx in [idx1]:\n            result = idx[0]\n            assert result == pd.Period(\"2011-01-01\", freq=\"D\")\n\n            result = idx[-1]\n            assert result == pd.Period(\"2011-01-31\", freq=\"D\")\n\n            result = idx[0:5]\n            expected = pd.period_range(\"2011-01-01\", \"2011-01-05\", freq=\"D\", name=\"idx\")\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx[0:10:2]\n            expected = pd.PeriodIndex(\n                [\"2011-01-01\", \"2011-01-03\", \"2011-01-05\", \"2011-01-07\", \"2011-01-09\"],\n                freq=\"D\",\n                name=\"idx\",\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx[-20:-5:3]\n            expected = pd.PeriodIndex(\n                [\"2011-01-12\", \"2011-01-15\", \"2011-01-18\", \"2011-01-21\", \"2011-01-24\"],\n                freq=\"D\",\n                name=\"idx\",\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx[4::-1]\n            expected = PeriodIndex(\n                [\"2011-01-05\", \"2011-01-04\", \"2011-01-03\", \"2011-01-02\", \"2011-01-01\"],\n                freq=\"D\",\n                name=\"idx\",\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n    def test_getitem_index(self):\n        idx = period_range(\"2007-01\", periods=10, freq=\"M\", name=\"x\")\n\n        result = idx[[1, 3, 5]]\n        exp = pd.PeriodIndex([\"2007-02\", \"2007-04\", \"2007-06\"], freq=\"M\", name=\"x\")\n        tm.assert_index_equal(result, exp)\n\n        result = idx[[True, True, False, False, False, True, True, False, False, False]]\n        exp = pd.PeriodIndex(\n            [\"2007-01\", \"2007-02\", \"2007-06\", \"2007-07\"], freq=\"M\", name=\"x\"\n        )\n        tm.assert_index_equal(result, exp)\n\n    def test_getitem_partial(self):\n        rng = period_range(\"2007-01\", periods=50, freq=\"M\")\n        ts = Series(np.random.randn(len(rng)), rng)\n\n        with pytest.raises(KeyError, match=r\"^'2006'$\"):\n            ts[\"2006\"]\n\n        result = ts[\"2008\"]\n        assert (result.index.year == 2008).all()\n\n        result = ts[\"2008\":\"2009\"]\n        assert len(result) == 24\n\n        result = ts[\"2008-1\":\"2009-12\"]\n        assert len(result) == 24\n\n        result = ts[\"2008Q1\":\"2009Q4\"]\n        assert len(result) == 24\n\n        result = ts[:\"2009\"]\n        assert len(result) == 36\n\n        result = ts[\"2009\":]\n        assert len(result) == 50 - 24\n\n        exp = result\n        result = ts[24:]\n        tm.assert_series_equal(exp, result)\n\n        ts = ts[10:].append(ts[10:])\n        msg = \"left slice bound for non-unique label: '2008'\"\n        with pytest.raises(KeyError, match=msg):\n            ts[slice(\"2008\", \"2009\")]\n\n    def test_getitem_datetime(self):\n        rng = period_range(start=\"2012-01-01\", periods=10, freq=\"W-MON\")\n        ts = Series(range(len(rng)), index=rng)\n\n        dt1 = datetime(2011, 10, 2)\n        dt4 = datetime(2012, 4, 20)\n\n        rs = ts[dt1:dt4]\n        tm.assert_series_equal(rs, ts)\n\n    def test_getitem_nat(self):\n        idx = pd.PeriodIndex([\"2011-01\", \"NaT\", \"2011-02\"], freq=\"M\")\n        assert idx[0] == pd.Period(\"2011-01\", freq=\"M\")\n        assert idx[1] is pd.NaT\n\n        s = pd.Series([0, 1, 2], index=idx)\n        assert s[pd.NaT] == 1\n\n        s = pd.Series(idx, index=idx)\n        assert s[pd.Period(\"2011-01\", freq=\"M\")] == pd.Period(\"2011-01\", freq=\"M\")\n        assert s[pd.NaT] is pd.NaT\n\n    def test_getitem_list_periods(self):\n        # GH 7710\n        rng = period_range(start=\"2012-01-01\", periods=10, freq=\"D\")\n        ts = Series(range(len(rng)), index=rng)\n        exp = ts.iloc[[1]]\n        tm.assert_series_equal(ts[[Period(\"2012-01-02\", freq=\"D\")]], exp)\n\n    def test_getitem_seconds(self):\n        # GH#6716\n        didx = pd.date_range(start=\"2013/01/01 09:00:00\", freq=\"S\", periods=4000)\n        pidx = period_range(start=\"2013/01/01 09:00:00\", freq=\"S\", periods=4000)\n\n        for idx in [didx, pidx]:\n            # getitem against index should raise ValueError\n            values = [\n                \"2014\",\n                \"2013/02\",\n                \"2013/01/02\",\n                \"2013/02/01 9H\",\n                \"2013/02/01 09:00\",\n            ]\n            for v in values:\n                # GH7116\n                # these show deprecations as we are trying\n                # to slice with non-integer indexers\n                # with pytest.raises(IndexError):\n                #    idx[v]\n                continue\n\n            s = Series(np.random.rand(len(idx)), index=idx)\n            tm.assert_series_equal(s[\"2013/01/01 10:00\"], s[3600:3660])\n            tm.assert_series_equal(s[\"2013/01/01 9H\"], s[:3600])\n            for d in [\"2013/01/01\", \"2013/01\", \"2013\"]:\n                tm.assert_series_equal(s[d], s)\n\n    def test_getitem_day(self):\n        # GH#6716\n        # Confirm DatetimeIndex and PeriodIndex works identically\n        didx = pd.date_range(start=\"2013/01/01\", freq=\"D\", periods=400)\n        pidx = period_range(start=\"2013/01/01\", freq=\"D\", periods=400)\n\n        for idx in [didx, pidx]:\n            # getitem against index should raise ValueError\n            values = [\n                \"2014\",\n                \"2013/02\",\n                \"2013/01/02\",\n                \"2013/02/01 9H\",\n                \"2013/02/01 09:00\",\n            ]\n            for v in values:\n\n                # GH7116\n                # these show deprecations as we are trying\n                # to slice with non-integer indexers\n                # with pytest.raises(IndexError):\n                #    idx[v]\n                continue\n\n            s = Series(np.random.rand(len(idx)), index=idx)\n            tm.assert_series_equal(s[\"2013/01\"], s[0:31])\n            tm.assert_series_equal(s[\"2013/02\"], s[31:59])\n            tm.assert_series_equal(s[\"2014\"], s[365:])\n\n            invalid = [\"2013/02/01 9H\", \"2013/02/01 09:00\"]\n            for v in invalid:\n                with pytest.raises(KeyError, match=v):\n                    s[v]\n\n\nclass TestWhere:\n    @pytest.mark.parametrize(\"klass\", [list, tuple, np.array, Series])\n    def test_where(self, klass):\n        i = period_range(\"20130101\", periods=5, freq=\"D\")\n        cond = [True] * len(i)\n        expected = i\n        result = i.where(klass(cond))\n        tm.assert_index_equal(result, expected)\n\n        cond = [False] + [True] * (len(i) - 1)\n        expected = PeriodIndex([pd.NaT] + i[1:].tolist(), freq=\"D\")\n        result = i.where(klass(cond))\n        tm.assert_index_equal(result, expected)\n\n    def test_where_other(self):\n        i = period_range(\"20130101\", periods=5, freq=\"D\")\n        for arr in [np.nan, pd.NaT]:\n            result = i.where(notna(i), other=np.nan)\n            expected = i\n            tm.assert_index_equal(result, expected)\n\n        i2 = i.copy()\n        i2 = pd.PeriodIndex([pd.NaT, pd.NaT] + i[2:].tolist(), freq=\"D\")\n        result = i.where(notna(i2), i2)\n        tm.assert_index_equal(result, i2)\n\n        i2 = i.copy()\n        i2 = pd.PeriodIndex([pd.NaT, pd.NaT] + i[2:].tolist(), freq=\"D\")\n        result = i.where(notna(i2), i2.values)\n        tm.assert_index_equal(result, i2)\n\n\nclass TestTake:\n    def test_take(self):\n        # GH#10295\n        idx1 = pd.period_range(\"2011-01-01\", \"2011-01-31\", freq=\"D\", name=\"idx\")\n\n        for idx in [idx1]:\n            result = idx.take([0])\n            assert result == pd.Period(\"2011-01-01\", freq=\"D\")\n\n            result = idx.take([5])\n            assert result == pd.Period(\"2011-01-06\", freq=\"D\")\n\n            result = idx.take([0, 1, 2])\n            expected = pd.period_range(\"2011-01-01\", \"2011-01-03\", freq=\"D\", name=\"idx\")\n            tm.assert_index_equal(result, expected)\n            assert result.freq == \"D\"\n            assert result.freq == expected.freq\n\n            result = idx.take([0, 2, 4])\n            expected = pd.PeriodIndex(\n                [\"2011-01-01\", \"2011-01-03\", \"2011-01-05\"], freq=\"D\", name=\"idx\"\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx.take([7, 4, 1])\n            expected = pd.PeriodIndex(\n                [\"2011-01-08\", \"2011-01-05\", \"2011-01-02\"], freq=\"D\", name=\"idx\"\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx.take([3, 2, 5])\n            expected = PeriodIndex(\n                [\"2011-01-04\", \"2011-01-03\", \"2011-01-06\"], freq=\"D\", name=\"idx\"\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n            result = idx.take([-3, 2, 5])\n            expected = PeriodIndex(\n                [\"2011-01-29\", \"2011-01-03\", \"2011-01-06\"], freq=\"D\", name=\"idx\"\n            )\n            tm.assert_index_equal(result, expected)\n            assert result.freq == expected.freq\n            assert result.freq == \"D\"\n\n    def test_take_misc(self):\n        index = period_range(start=\"1/1/10\", end=\"12/31/12\", freq=\"D\", name=\"idx\")\n        expected = PeriodIndex(\n            [\n                datetime(2010, 1, 6),\n                datetime(2010, 1, 7),\n                datetime(2010, 1, 9),\n                datetime(2010, 1, 13),\n            ],\n            freq=\"D\",\n            name=\"idx\",\n        )\n\n        taken1 = index.take([5, 6, 8, 12])\n        taken2 = index[[5, 6, 8, 12]]\n\n        for taken in [taken1, taken2]:\n            tm.assert_index_equal(taken, expected)\n            assert isinstance(taken, PeriodIndex)\n            assert taken.freq == index.freq\n            assert taken.name == expected.name\n\n    def test_take_fill_value(self):\n        # GH#12631\n        idx = pd.PeriodIndex(\n            [\"2011-01-01\", \"2011-02-01\", \"2011-03-01\"], name=\"xxx\", freq=\"D\"\n        )\n        result = idx.take(np.array([1, 0, -1]))\n        expected = pd.PeriodIndex(\n            [\"2011-02-01\", \"2011-01-01\", \"2011-03-01\"], name=\"xxx\", freq=\"D\"\n        )\n        tm.assert_index_equal(result, expected)\n\n        # fill_value\n        result = idx.take(np.array([1, 0, -1]), fill_value=True)\n        expected = pd.PeriodIndex(\n            [\"2011-02-01\", \"2011-01-01\", \"NaT\"], name=\"xxx\", freq=\"D\"\n        )\n        tm.assert_index_equal(result, expected)\n\n        # allow_fill=False\n        result = idx.take(np.array([1, 0, -1]), allow_fill=False, fill_value=True)\n        expected = pd.PeriodIndex(\n            [\"2011-02-01\", \"2011-01-01\", \"2011-03-01\"], name=\"xxx\", freq=\"D\"\n        )\n        tm.assert_index_equal(result, expected)\n\n        msg = (\n            \"When allow_fill=True and fill_value is not None, \"\n            \"all indices must be >= -1\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            idx.take(np.array([1, 0, -2]), fill_value=True)\n        with pytest.raises(ValueError, match=msg):\n            idx.take(np.array([1, 0, -5]), fill_value=True)\n\n        msg = \"index -5 is out of bounds for size 3\"\n        with pytest.raises(IndexError, match=msg):\n            idx.take(np.array([1, -5]))\n\n\nclass TestIndexing:\n    def test_get_loc_msg(self):\n        idx = period_range(\"2000-1-1\", freq=\"A\", periods=10)\n        bad_period = Period(\"2012\", \"A\")\n        with pytest.raises(KeyError, match=r\"^Period\\('2012', 'A-DEC'\\)$\"):\n            idx.get_loc(bad_period)\n\n        try:\n            idx.get_loc(bad_period)\n        except KeyError as inst:\n            assert inst.args[0] == bad_period\n\n    def test_get_loc_nat(self):\n        didx = DatetimeIndex([\"2011-01-01\", \"NaT\", \"2011-01-03\"])\n        pidx = PeriodIndex([\"2011-01-01\", \"NaT\", \"2011-01-03\"], freq=\"M\")\n\n        # check DatetimeIndex compat\n        for idx in [didx, pidx]:\n            assert idx.get_loc(pd.NaT) == 1\n            assert idx.get_loc(None) == 1\n            assert idx.get_loc(float(\"nan\")) == 1\n            assert idx.get_loc(np.nan) == 1\n\n    def test_get_loc(self):\n        # GH 17717\n        p0 = pd.Period(\"2017-09-01\")\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n\n        # get the location of p1/p2 from\n        # monotonic increasing PeriodIndex with non-duplicate\n        idx0 = pd.PeriodIndex([p0, p1, p2])\n        expected_idx1_p1 = 1\n        expected_idx1_p2 = 2\n\n        assert idx0.get_loc(p1) == expected_idx1_p1\n        assert idx0.get_loc(str(p1)) == expected_idx1_p1\n        assert idx0.get_loc(p2) == expected_idx1_p2\n        assert idx0.get_loc(str(p2)) == expected_idx1_p2\n\n        msg = \"Cannot interpret 'foo' as period\"\n        with pytest.raises(KeyError, match=msg):\n            idx0.get_loc(\"foo\")\n        with pytest.raises(KeyError, match=r\"^1\\.1$\"):\n            idx0.get_loc(1.1)\n\n        msg = (\n            r\"'PeriodIndex\\(\\['2017-09-01', '2017-09-02', '2017-09-03'\\],\"\n            r\" dtype='period\\[D\\]', freq='D'\\)' is an invalid key\"\n        )\n        with pytest.raises(TypeError, match=msg):\n            idx0.get_loc(idx0)\n\n        # get the location of p1/p2 from\n        # monotonic increasing PeriodIndex with duplicate\n        idx1 = pd.PeriodIndex([p1, p1, p2])\n        expected_idx1_p1 = slice(0, 2)\n        expected_idx1_p2 = 2\n\n        assert idx1.get_loc(p1) == expected_idx1_p1\n        assert idx1.get_loc(str(p1)) == expected_idx1_p1\n        assert idx1.get_loc(p2) == expected_idx1_p2\n        assert idx1.get_loc(str(p2)) == expected_idx1_p2\n\n        msg = \"Cannot interpret 'foo' as period\"\n        with pytest.raises(KeyError, match=msg):\n            idx1.get_loc(\"foo\")\n\n        with pytest.raises(KeyError, match=r\"^1\\.1$\"):\n            idx1.get_loc(1.1)\n\n        msg = (\n            r\"'PeriodIndex\\(\\['2017-09-02', '2017-09-02', '2017-09-03'\\],\"\n            r\" dtype='period\\[D\\]', freq='D'\\)' is an invalid key\"\n        )\n        with pytest.raises(TypeError, match=msg):\n            idx1.get_loc(idx1)\n\n        # get the location of p1/p2 from\n        # non-monotonic increasing/decreasing PeriodIndex with duplicate\n        idx2 = pd.PeriodIndex([p2, p1, p2])\n        expected_idx2_p1 = 1\n        expected_idx2_p2 = np.array([True, False, True])\n\n        assert idx2.get_loc(p1) == expected_idx2_p1\n        assert idx2.get_loc(str(p1)) == expected_idx2_p1\n        tm.assert_numpy_array_equal(idx2.get_loc(p2), expected_idx2_p2)\n        tm.assert_numpy_array_equal(idx2.get_loc(str(p2)), expected_idx2_p2)\n\n    def test_is_monotonic_increasing(self):\n        # GH 17717\n        p0 = pd.Period(\"2017-09-01\")\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n\n        idx_inc0 = pd.PeriodIndex([p0, p1, p2])\n        idx_inc1 = pd.PeriodIndex([p0, p1, p1])\n        idx_dec0 = pd.PeriodIndex([p2, p1, p0])\n        idx_dec1 = pd.PeriodIndex([p2, p1, p1])\n        idx = pd.PeriodIndex([p1, p2, p0])\n\n        assert idx_inc0.is_monotonic_increasing is True\n        assert idx_inc1.is_monotonic_increasing is True\n        assert idx_dec0.is_monotonic_increasing is False\n        assert idx_dec1.is_monotonic_increasing is False\n        assert idx.is_monotonic_increasing is False\n\n    def test_is_monotonic_decreasing(self):\n        # GH 17717\n        p0 = pd.Period(\"2017-09-01\")\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n\n        idx_inc0 = pd.PeriodIndex([p0, p1, p2])\n        idx_inc1 = pd.PeriodIndex([p0, p1, p1])\n        idx_dec0 = pd.PeriodIndex([p2, p1, p0])\n        idx_dec1 = pd.PeriodIndex([p2, p1, p1])\n        idx = pd.PeriodIndex([p1, p2, p0])\n\n        assert idx_inc0.is_monotonic_decreasing is False\n        assert idx_inc1.is_monotonic_decreasing is False\n        assert idx_dec0.is_monotonic_decreasing is True\n        assert idx_dec1.is_monotonic_decreasing is True\n        assert idx.is_monotonic_decreasing is False\n\n    def test_contains(self):\n        # GH 17717\n        p0 = pd.Period(\"2017-09-01\")\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n        p3 = pd.Period(\"2017-09-04\")\n\n        ps0 = [p0, p1, p2]\n        idx0 = pd.PeriodIndex(ps0)\n\n        for p in ps0:\n            assert p in idx0\n            assert str(p) in idx0\n\n        assert \"2017-09-01 00:00:01\" in idx0\n\n        assert \"2017-09\" in idx0\n\n        assert p3 not in idx0\n\n    def test_get_value(self):\n        # GH 17717\n        p0 = pd.Period(\"2017-09-01\")\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n\n        idx0 = pd.PeriodIndex([p0, p1, p2])\n        input0 = np.array([1, 2, 3])\n        expected0 = 2\n\n        result0 = idx0.get_value(input0, p1)\n        assert result0 == expected0\n\n        idx1 = pd.PeriodIndex([p1, p1, p2])\n        input1 = np.array([1, 2, 3])\n        expected1 = np.array([1, 2])\n\n        result1 = idx1.get_value(input1, p1)\n        tm.assert_numpy_array_equal(result1, expected1)\n\n        idx2 = pd.PeriodIndex([p1, p2, p1])\n        input2 = np.array([1, 2, 3])\n        expected2 = np.array([1, 3])\n\n        result2 = idx2.get_value(input2, p1)\n        tm.assert_numpy_array_equal(result2, expected2)\n\n    def test_get_indexer(self):\n        # GH 17717\n        p1 = pd.Period(\"2017-09-01\")\n        p2 = pd.Period(\"2017-09-04\")\n        p3 = pd.Period(\"2017-09-07\")\n\n        tp0 = pd.Period(\"2017-08-31\")\n        tp1 = pd.Period(\"2017-09-02\")\n        tp2 = pd.Period(\"2017-09-05\")\n        tp3 = pd.Period(\"2017-09-09\")\n\n        idx = pd.PeriodIndex([p1, p2, p3])\n\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(idx), np.array([0, 1, 2], dtype=np.intp)\n        )\n\n        target = pd.PeriodIndex([tp0, tp1, tp2, tp3])\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"pad\"), np.array([-1, 0, 1, 2], dtype=np.intp)\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"backfill\"), np.array([0, 1, 2, -1], dtype=np.intp)\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"nearest\"), np.array([0, 0, 1, 2], dtype=np.intp)\n        )\n\n        res = idx.get_indexer(target, \"nearest\", tolerance=pd.Timedelta(\"1 day\"))\n        tm.assert_numpy_array_equal(res, np.array([0, 0, 1, -1], dtype=np.intp))\n\n    def test_get_indexer_non_unique(self):\n        # GH 17717\n        p1 = pd.Period(\"2017-09-02\")\n        p2 = pd.Period(\"2017-09-03\")\n        p3 = pd.Period(\"2017-09-04\")\n        p4 = pd.Period(\"2017-09-05\")\n\n        idx1 = pd.PeriodIndex([p1, p2, p1])\n        idx2 = pd.PeriodIndex([p2, p1, p3, p4])\n\n        result = idx1.get_indexer_non_unique(idx2)\n        expected_indexer = np.array([1, 0, 2, -1, -1], dtype=np.intp)\n        expected_missing = np.array([2, 3], dtype=np.int64)\n\n        tm.assert_numpy_array_equal(result[0], expected_indexer)\n        tm.assert_numpy_array_equal(result[1], expected_missing)\n\n    # TODO: This method came from test_period; de-dup with version above\n    def test_get_loc2(self):\n        idx = pd.period_range(\"2000-01-01\", periods=3)\n\n        for method in [None, \"pad\", \"backfill\", \"nearest\"]:\n            assert idx.get_loc(idx[1], method) == 1\n            assert idx.get_loc(idx[1].asfreq(\"H\", how=\"start\"), method) == 1\n            assert idx.get_loc(idx[1].to_timestamp(), method) == 1\n            assert idx.get_loc(idx[1].to_timestamp().to_pydatetime(), method) == 1\n            assert idx.get_loc(str(idx[1]), method) == 1\n\n        idx = pd.period_range(\"2000-01-01\", periods=5)[::2]\n        assert idx.get_loc(\"2000-01-02T12\", method=\"nearest\", tolerance=\"1 day\") == 1\n        assert (\n            idx.get_loc(\"2000-01-02T12\", method=\"nearest\", tolerance=pd.Timedelta(\"1D\"))\n            == 1\n        )\n        assert (\n            idx.get_loc(\n                \"2000-01-02T12\", method=\"nearest\", tolerance=np.timedelta64(1, \"D\")\n            )\n            == 1\n        )\n        assert (\n            idx.get_loc(\"2000-01-02T12\", method=\"nearest\", tolerance=timedelta(1)) == 1\n        )\n\n        msg = \"unit abbreviation w/o a number\"\n        with pytest.raises(ValueError, match=msg):\n            idx.get_loc(\"2000-01-10\", method=\"nearest\", tolerance=\"foo\")\n\n        msg = \"Input has different freq=None from PeriodArray\\\\(freq=D\\\\)\"\n        with pytest.raises(ValueError, match=msg):\n            idx.get_loc(\"2000-01-10\", method=\"nearest\", tolerance=\"1 hour\")\n        with pytest.raises(KeyError, match=r\"^Period\\('2000-01-10', 'D'\\)$\"):\n            idx.get_loc(\"2000-01-10\", method=\"nearest\", tolerance=\"1 day\")\n        with pytest.raises(\n            ValueError, match=\"list-like tolerance size must match target index size\"\n        ):\n            idx.get_loc(\n                \"2000-01-10\",\n                method=\"nearest\",\n                tolerance=[\n                    pd.Timedelta(\"1 day\").to_timedelta64(),\n                    pd.Timedelta(\"1 day\").to_timedelta64(),\n                ],\n            )\n\n    # TODO: This method came from test_period; de-dup with version above\n    def test_get_indexer2(self):\n        idx = pd.period_range(\"2000-01-01\", periods=3).asfreq(\"H\", how=\"start\")\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(idx), np.array([0, 1, 2], dtype=np.intp)\n        )\n\n        target = pd.PeriodIndex(\n            [\"1999-12-31T23\", \"2000-01-01T12\", \"2000-01-02T01\"], freq=\"H\"\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"pad\"), np.array([-1, 0, 1], dtype=np.intp)\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"backfill\"), np.array([0, 1, 2], dtype=np.intp)\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"nearest\"), np.array([0, 1, 1], dtype=np.intp)\n        )\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"nearest\", tolerance=\"1 hour\"),\n            np.array([0, -1, 1], dtype=np.intp),\n        )\n\n        msg = \"Input has different freq=None from PeriodArray\\\\(freq=H\\\\)\"\n        with pytest.raises(ValueError, match=msg):\n            idx.get_indexer(target, \"nearest\", tolerance=\"1 minute\")\n\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(target, \"nearest\", tolerance=\"1 day\"),\n            np.array([0, 1, 1], dtype=np.intp),\n        )\n        tol_raw = [\n            pd.Timedelta(\"1 hour\"),\n            pd.Timedelta(\"1 hour\"),\n            np.timedelta64(1, \"D\"),\n        ]\n        tm.assert_numpy_array_equal(\n            idx.get_indexer(\n                target, \"nearest\", tolerance=[np.timedelta64(x) for x in tol_raw]\n            ),\n            np.array([0, -1, 1], dtype=np.intp),\n        )\n        tol_bad = [\n            pd.Timedelta(\"2 hour\").to_timedelta64(),\n            pd.Timedelta(\"1 hour\").to_timedelta64(),\n            np.timedelta64(1, \"M\"),\n        ]\n        with pytest.raises(\n            libperiod.IncompatibleFrequency, match=\"Input has different freq=None from\"\n        ):\n            idx.get_indexer(target, \"nearest\", tolerance=tol_bad)\n\n    def test_indexing(self):\n        # GH 4390, iat incorrectly indexing\n        index = period_range(\"1/1/2001\", periods=10)\n        s = Series(np.random.randn(10), index=index)\n        expected = s[index[0]]\n        result = s.iat[0]\n        assert expected == result\n\n    def test_period_index_indexer(self):\n        # GH4125\n        idx = pd.period_range(\"2002-01\", \"2003-12\", freq=\"M\")\n        df = pd.DataFrame(np.random.randn(24, 10), index=idx)\n        tm.assert_frame_equal(df, df.loc[idx])\n        tm.assert_frame_equal(df, df.loc[list(idx)])\n        tm.assert_frame_equal(df, df.loc[list(idx)])\n        tm.assert_frame_equal(df.iloc[0:5], df.loc[idx[0:5]])\n        tm.assert_frame_equal(df, df.loc[list(idx)])\n"
    }
  ]
}