{
  "repo_name": "oppia_oppia",
  "issue_id": "20908",
  "issue_description": "# [BUG]: Voiceover progress not synchronized\n\n### Describe the bug\r\n\r\nDuring voiceover play from the exploration player page, the voiceover progress indicator does not show the actual representation of voiceover at that time. For e.g. When the voiceover is completed the still shows that some of the voiceover is still remaining.\r\n\r\n \r\n\r\n### URL of the page where the issue is observed.\r\n\r\nN/A\r\n\r\n### Steps To Reproduce\r\n\r\n1. Create and publish an exploration\r\n2. Add voiceovers to the exploration\r\n    - Enable ENABLE_VOICEOVER_CONTRIBUTION feature flag\r\n    - Enable ADD_VOICEOVER_WITH_ACCENT feature flag\r\n    - Get the voiceover admin rights from the admin roles tab.\r\n    - Visit to /voiceover-admin page\r\n    - Add language accents support\r\n4. Visit the exploration player page.\r\n5. Play the voiceover and observe that even after completing the voiceover there is some part left in the progress indicator\r\n\r\n### Expected Behavior\r\n\r\nThe progress indicator should synchronize with the voiceover play status, otherwise this will confuse students.\r\n\r\n### Screenshots/Videos\r\n\r\n![image](https://github.com/user-attachments/assets/40f12425-0941-46ac-9017-22c15b4517a8)\r\n\r\n\r\n### What device are you using?\r\n\r\nDesktop\r\n\r\n### Operating System\r\n\r\nLinux\r\n\r\n### What browsers are you seeing the problem on?\r\n\r\n_No response_\r\n\r\n### Browser version\r\n\r\n_No response_\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Tips for developers\r\n\r\nBefore addressing the bug, please identify which PR caused the issue (you can follow the steps [here](https://github.com/oppia/oppia/wiki/How-to-find-the-commit-which-introduced-a-bug)). If you identify the PR, comment on the issue with a link to it. If not, mention the commit hash of the oldest commit you saw the bug on (and the month and year it was made in).\r\n\r\nThen, please leave a comment with details of the approach that you plan to take to fix the issue (see [example](https://github.com/oppia/oppia/issues/19157#issuecomment-1858788463)).\r\n\r\n**Note:** If this is your first Oppia issue, please make sure to follow our guidelines for [choosing an issue](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#choosing-a-good-first-issue) and [setting things up](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#setting-things-up). You will also need to show a demo of the fix working correctly on your local machine. Thanks!\r\n",
  "issue_comments": [
    {
      "id": 2346510975,
      "user": "pritam2317",
      "body": "Hi @Nik-09, As per my finding, it appears that while playing the audio, the [currentVoiceoverTime](https://github.com/oppia/oppia/blob/666c45a1a59269f559ba02b0381c960c0b5d0a4d/core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.ts#L154) variable counts the seconds relative to the audio played. As a result, this variable’s total count is one less than the actual length of the audio. Because of this, the audio slider doesn’t quite reach the end since it follows [currentVoiceoverTime](https://github.com/oppia/oppia/blob/666c45a1a59269f559ba02b0381c960c0b5d0a4d/core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.ts#L154). To address this issue, we add +1 to currentVoiceoverTime in the HTML [file](https://github.com/oppia/oppia/blob/666c45a1a59269f559ba02b0381c960c0b5d0a4d/core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.html#L32C11-L39C17), as shown here.\r\n          <div *ngIf=\"!audioLoadingIndicatorIsShown\">\r\n            <oppia-audio-slider [value]=\"this.currentVoiceoverTime+1\"\r\n                                [dir]=\"isLanguageRTL() ? 'rtl' : 'ltr'\"\r\n                                [max]=\"audioPlayerService.getAudioDuration()\"\r\n                                (valueChange)=\"setProgress($event)\"\r\n                                aria-label=\"audio-slider\">\r\n            </oppia-audio-slider>\r\n          </div>\r\n\r\nVideo proof:\r\n[Screencast from 12-09-24 08:15:42 PM IST.webm](https://github.com/user-attachments/assets/6f7da46b-6f0d-4775-89f6-0e912dcb652a)\r\n"
    },
    {
      "id": 2353223520,
      "user": "Nik-09",
      "body": "Hi @pritam2317 I appreciate the findings, but regarding the 1-sec rule, I am not very confident, because it may take some time to load voiceovers and ultimately this will reflect in progress.\r\n\r\nOne question, why the difference between currentVoiceoverTime and progress occur in the first place?\r\n\r\nFor video:\r\nDoes the voiceover progress move back to zero progress after completing the voiceover play?\r\n\r\nThank you\r\n\r\n\r\n "
    },
    {
      "id": 2622502341,
      "user": "dakshmehta007",
      "body": "@seanlip , is this issue still open? I am ready to solve it."
    },
    {
      "id": 2626176646,
      "user": "seanlip",
      "body": "@dakshmehta007 Per the guidance at https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#choosing-a-good-first-issue, please provide an explanation of what your PR will do (with names of files you're changing, what you plan to change in each file, etc.), as well as a video showing that the changes work correctly on your local machine. If it looks good, we can assign you to this issue.\n\nNote that any unassigned issue is open for contributors to take up, but we discourage taking up any issues marked \"low impact\" or prioritized as \"backlog\".\n\nPlease also follow the other instructions on that wiki page if you have not yet done so. Thanks!"
    },
    {
      "id": 2627996682,
      "user": "shashank0470",
      "body": "Can I work on this?"
    },
    {
      "id": 2639424500,
      "user": "himkar-cmd",
      "body": "Hi @seanlip @Nik-09,\n\nI tried to resolve the issue, and the problem is as follows:\nIn the file core/templates/services/audio-player.service.ts, the function getCurrentTime() returns Math.floor, which causes the progress bar to lag behind. This happens because this._currentTrack.seek() starts unexpectedly for 0-1 seconds, preventing the function from returning a time equal to this._currentTrack.duration().And also Play button fetch time every 500 ms.\n\n![Image](https://github.com/user-attachments/assets/a6edc94b-3d1b-41f6-ba66-bd0c1f2f72c6) \n\nIn the HTML file (core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.html), the maximum range of the progress bar is set to this._currentTrack.duration(). Due to the lag, the progress bar never fills completely and doesn’t reset to zero.\n\n![Image](https://github.com/user-attachments/assets/4aabbb3e-b2b4-4378-a59b-c51331ef61cf)\n\n\nTo address this, I modified the logic by replacing Math.floor with Math.round in the file core/templates/services/audio-player.service.ts.\n![Image](https://github.com/user-attachments/assets/29784eee-43f8-4d7e-ad2b-08c6f9a6de97)\n\n\nAdditionally, in the file core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.html, I adjusted the slider's maximum range to 100.\n\n![Image](https://github.com/user-attachments/assets/2271a1ae-7e09-40e3-a389-e18d1ca1a09b)\n\nIn order to make the slider get time in percent the changes made in logic of\nfile -----> core\\templates\\pages\\exploration-player-page\\layout-directives\\audio-bar.component.ts\n\n![Image](https://github.com/user-attachments/assets/6ed17f47-d043-4ae5-9ba7-4bbbe2414ddf)\n\nThe proof of solution is ---> \n\nhttps://github.com/user-attachments/assets/eee9a40e-1800-411e-a103-dcc461c6e9ea\n\nThese are the error which i found\n\nPTAL When you get the time and also suggest if changes needed."
    },
    {
      "id": 2641872098,
      "user": "seanlip",
      "body": "@himkar-cmd Interesting, thanks -- I think you have found the root cause of the issue, though I'm not sure about the solution. \n\nJust to clarify, there are two issues, right:\n- Use of \"floor\" means that, when starting the voiceover, it looks like there's no progress for a while\n- The voiceover progress indicator never reaches full completion\n\nA few things to investigate:\n\n- Can you make getCurrentTime() return the time to 1 d.p. or 2 d.p. (still using 'floor')? Does making that change, alone, help at all? \n- Instead of using a range of 100 can you use a range of \"duration in secs * 10\" instead -- would that give enough granularity?\n\nNot sure about using \"round()\" since that introduces some uncertainty in the timestamps (basically, 0:04 should mean the interval from 0:04 to 0:05, not from 0:03.5 to 0:04.5).\n\nThanks!"
    },
    {
      "id": 2641978112,
      "user": "himkar-cmd",
      "body": "Hi @seanlip , i tried to implement those suggestion--->\n\n![Image](https://github.com/user-attachments/assets/8f8649fb-57a0-42c1-9f97-58d4cd59b4b3)\n\n![Image](https://github.com/user-attachments/assets/6050b380-cbbd-42f8-b5d4-4c3b2c80eca9)\n\n![Image](https://github.com/user-attachments/assets/1f3f2dd6-fe94-477e-a8d2-99341cde60a9)\n\nthe working video is---->\n\nhttps://github.com/user-attachments/assets/2713a4f4-0971-41ba-aa5d-98045aa32490"
    },
    {
      "id": 2647429142,
      "user": "seanlip",
      "body": "Thanks @himkar-cmd. The UI seems fine, but a few notes on implementation:\n\n- Please change getCurrentTime to getCurrentTimeInSecs and have it actually return the current time in seconds, to 1 decimal place.\n- Similarly, change totalVoiceoverTime to totalVoiceoverDurationSecs.\n\nDoes that work, or does the slider component need to use integers? If the latter then you can use Msecs instead in the above names and return whole numbers of milliseconds. But see if you can try seconds first (up to 1 dp) since that is how duration of audio files is usually measured."
    },
    {
      "id": 2649652205,
      "user": "himkar-cmd",
      "body": "Hi @seanlip, I’ve made the changes.\n\n![Image](https://github.com/user-attachments/assets/286cf888-42d6-418a-9794-1db9be4193df)\n\n![Image](https://github.com/user-attachments/assets/db1f887d-75c1-4774-9aa0-cf104f756b0d)\n\nThe slider works with both integer and decimal values. However, for stability, we are limiting decimal precision to 1 or 2 decimal places.\n\n![Image](https://github.com/user-attachments/assets/d0a25dfa-969f-44f3-848d-9cd860d7cb0a)\n Also changes a little bit in above pic interval from 500 to 250 but if it not a problem.\nIf this approach is not appropriate, please let me know, and I will make the necessary changes.\n"
    },
    {
      "id": 2649889203,
      "user": "seanlip",
      "body": "Hi @himkar-cmd -- thanks for the updates. There are some other small issues (e.g. the explanation for why '?' is needed needs to be clearer) but we can probably discuss them in a PR. I'm assigning you to this issue for now, feel free to create a PR -- thanks!\n\nAlso, one note: this.currentVoiceoverTime should be changed to this.currentVoiceoverTimeInSecs. (In general when you get feedback from a reviewer, try to apply it everywhere it's needed, without further prompting. Thanks.)"
    },
    {
      "id": 2668011802,
      "user": "HardikGoyal2003",
      "body": "Closing this issue as fixed by https://github.com/oppia/oppia/pull/21902"
    }
  ],
  "text_context": "# [BUG]: Voiceover progress not synchronized\n\n### Describe the bug\r\n\r\nDuring voiceover play from the exploration player page, the voiceover progress indicator does not show the actual representation of voiceover at that time. For e.g. When the voiceover is completed the still shows that some of the voiceover is still remaining.\r\n\r\n \r\n\r\n### URL of the page where the issue is observed.\r\n\r\nN/A\r\n\r\n### Steps To Reproduce\r\n\r\n1. Create and publish an exploration\r\n2. Add voiceovers to the exploration\r\n    - Enable ENABLE_VOICEOVER_CONTRIBUTION feature flag\r\n    - Enable ADD_VOICEOVER_WITH_ACCENT feature flag\r\n    - Get the voiceover admin rights from the admin roles tab.\r\n    - Visit to /voiceover-admin page\r\n    - Add language accents support\r\n4. Visit the exploration player page.\r\n5. Play the voiceover and observe that even after completing the voiceover there is some part left in the progress indicator\r\n\r\n### Expected Behavior\r\n\r\nThe progress indicator should synchronize with the voiceover play status, otherwise this will confuse students.\r\n\r\n### Screenshots/Videos\r\n\r\n![image](https://github.com/user-attachments/assets/40f12425-0941-46ac-9017-22c15b4517a8)\r\n\r\n\r\n### What device are you using?\r\n\r\nDesktop\r\n\r\n### Operating System\r\n\r\nLinux\r\n\r\n### What browsers are you seeing the problem on?\r\n\r\n_No response_\r\n\r\n### Browser version\r\n\r\n_No response_\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Tips for developers\r\n\r\nBefore addressing the bug, please identify which PR caused the issue (you can follow the steps [here](https://github.com/oppia/oppia/wiki/How-to-find-the-commit-which-introduced-a-bug)). If you identify the PR, comment on the issue with a link to it. If not, mention the commit hash of the oldest commit you saw the bug on (and the month and year it was made in).\r\n\r\nThen, please leave a comment with details of the approach that you plan to take to fix the issue (see [example](https://github.com/oppia/oppia/issues/19157#issuecomment-1858788463)).\r\n\r\n**Note:** If this is your first Oppia issue, please make sure to follow our guidelines for [choosing an issue](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#choosing-a-good-first-issue) and [setting things up](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#setting-things-up). You will also need to show a demo of the fix working correctly on your local machine. Thanks!\r\n\n\nHi @Nik-09, As per my finding, it appears that while playing the audio, the [currentVoiceoverTime](https://github.com/oppia/oppia/blob/666c45a1a59269f559ba02b0381c960c0b5d0a4d/core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.ts#L154) variable counts the seconds relative to the audio played. As a result, this variable’s total count is one less than the actual length of the audio. Because of this, the audio slider doesn’t quite reach the end since it follows [currentVoiceoverTime](https://github.com/oppia/oppia/blob/666c45a1a59269f559ba02b0381c960c0b5d0a4d/core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.ts#L154). To address this issue, we add +1 to currentVoiceoverTime in the HTML [file](https://github.com/oppia/oppia/blob/666c45a1a59269f559ba02b0381c960c0b5d0a4d/core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.html#L32C11-L39C17), as shown here.\r\n          <div *ngIf=\"!audioLoadingIndicatorIsShown\">\r\n            <oppia-audio-slider [value]=\"this.currentVoiceoverTime+1\"\r\n                                [dir]=\"isLanguageRTL() ? 'rtl' : 'ltr'\"\r\n                                [max]=\"audioPlayerService.getAudioDuration()\"\r\n                                (valueChange)=\"setProgress($event)\"\r\n                                aria-label=\"audio-slider\">\r\n            </oppia-audio-slider>\r\n          </div>\r\n\r\nVideo proof:\r\n[Screencast from 12-09-24 08:15:42 PM IST.webm](https://github.com/user-attachments/assets/6f7da46b-6f0d-4775-89f6-0e912dcb652a)\r\n\n\nHi @pritam2317 I appreciate the findings, but regarding the 1-sec rule, I am not very confident, because it may take some time to load voiceovers and ultimately this will reflect in progress.\r\n\r\nOne question, why the difference between currentVoiceoverTime and progress occur in the first place?\r\n\r\nFor video:\r\nDoes the voiceover progress move back to zero progress after completing the voiceover play?\r\n\r\nThank you\r\n\r\n\r\n \n\n@seanlip , is this issue still open? I am ready to solve it.\n\n@dakshmehta007 Per the guidance at https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#choosing-a-good-first-issue, please provide an explanation of what your PR will do (with names of files you're changing, what you plan to change in each file, etc.), as well as a video showing that the changes work correctly on your local machine. If it looks good, we can assign you to this issue.\n\nNote that any unassigned issue is open for contributors to take up, but we discourage taking up any issues marked \"low impact\" or prioritized as \"backlog\".\n\nPlease also follow the other instructions on that wiki page if you have not yet done so. Thanks!\n\nCan I work on this?\n\nHi @seanlip @Nik-09,\n\nI tried to resolve the issue, and the problem is as follows:\nIn the file core/templates/services/audio-player.service.ts, the function getCurrentTime() returns Math.floor, which causes the progress bar to lag behind. This happens because this._currentTrack.seek() starts unexpectedly for 0-1 seconds, preventing the function from returning a time equal to this._currentTrack.duration().And also Play button fetch time every 500 ms.\n\n![Image](https://github.com/user-attachments/assets/a6edc94b-3d1b-41f6-ba66-bd0c1f2f72c6) \n\nIn the HTML file (core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.html), the maximum range of the progress bar is set to this._currentTrack.duration(). Due to the lag, the progress bar never fills completely and doesn’t reset to zero.\n\n![Image](https://github.com/user-attachments/assets/4aabbb3e-b2b4-4378-a59b-c51331ef61cf)\n\n\nTo address this, I modified the logic by replacing Math.floor with Math.round in the file core/templates/services/audio-player.service.ts.\n![Image](https://github.com/user-attachments/assets/29784eee-43f8-4d7e-ad2b-08c6f9a6de97)\n\n\nAdditionally, in the file core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.html, I adjusted the slider's maximum range to 100.\n\n![Image](https://github.com/user-attachments/assets/2271a1ae-7e09-40e3-a389-e18d1ca1a09b)\n\nIn order to make the slider get time in percent the changes made in logic of\nfile -----> core\\templates\\pages\\exploration-player-page\\layout-directives\\audio-bar.component.ts\n\n![Image](https://github.com/user-attachments/assets/6ed17f47-d043-4ae5-9ba7-4bbbe2414ddf)\n\nThe proof of solution is ---> \n\nhttps://github.com/user-attachments/assets/eee9a40e-1800-411e-a103-dcc461c6e9ea\n\nThese are the error which i found\n\nPTAL When you get the time and also suggest if changes needed.\n\n@himkar-cmd Interesting, thanks -- I think you have found the root cause of the issue, though I'm not sure about the solution. \n\nJust to clarify, there are two issues, right:\n- Use of \"floor\" means that, when starting the voiceover, it looks like there's no progress for a while\n- The voiceover progress indicator never reaches full completion\n\nA few things to investigate:\n\n- Can you make getCurrentTime() return the time to 1 d.p. or 2 d.p. (still using 'floor')? Does making that change, alone, help at all? \n- Instead of using a range of 100 can you use a range of \"duration in secs * 10\" instead -- would that give enough granularity?\n\nNot sure about using \"round()\" since that introduces some uncertainty in the timestamps (basically, 0:04 should mean the interval from 0:04 to 0:05, not from 0:03.5 to 0:04.5).\n\nThanks!\n\nHi @seanlip , i tried to implement those suggestion--->\n\n![Image](https://github.com/user-attachments/assets/8f8649fb-57a0-42c1-9f97-58d4cd59b4b3)\n\n![Image](https://github.com/user-attachments/assets/6050b380-cbbd-42f8-b5d4-4c3b2c80eca9)\n\n![Image](https://github.com/user-attachments/assets/1f3f2dd6-fe94-477e-a8d2-99341cde60a9)\n\nthe working video is---->\n\nhttps://github.com/user-attachments/assets/2713a4f4-0971-41ba-aa5d-98045aa32490\n\nThanks @himkar-cmd. The UI seems fine, but a few notes on implementation:\n\n- Please change getCurrentTime to getCurrentTimeInSecs and have it actually return the current time in seconds, to 1 decimal place.\n- Similarly, change totalVoiceoverTime to totalVoiceoverDurationSecs.\n\nDoes that work, or does the slider component need to use integers? If the latter then you can use Msecs instead in the above names and return whole numbers of milliseconds. But see if you can try seconds first (up to 1 dp) since that is how duration of audio files is usually measured.\n\nHi @seanlip, I’ve made the changes.\n\n![Image](https://github.com/user-attachments/assets/286cf888-42d6-418a-9794-1db9be4193df)\n\n![Image](https://github.com/user-attachments/assets/db1f887d-75c1-4774-9aa0-cf104f756b0d)\n\nThe slider works with both integer and decimal values. However, for stability, we are limiting decimal precision to 1 or 2 decimal places.\n\n![Image](https://github.com/user-attachments/assets/d0a25dfa-969f-44f3-848d-9cd860d7cb0a)\n Also changes a little bit in above pic interval from 500 to 250 but if it not a problem.\nIf this approach is not appropriate, please let me know, and I will make the necessary changes.\n\n\nHi @himkar-cmd -- thanks for the updates. There are some other small issues (e.g. the explanation for why '?' is needed needs to be clearer) but we can probably discuss them in a PR. I'm assigning you to this issue for now, feel free to create a PR -- thanks!\n\nAlso, one note: this.currentVoiceoverTime should be changed to this.currentVoiceoverTimeInSecs. (In general when you get feedback from a reviewer, try to apply it everywhere it's needed, without further prompting. Thanks.)\n\nClosing this issue as fixed by https://github.com/oppia/oppia/pull/21902",
  "pr_link": "https://github.com/oppia/oppia/pull/21902",
  "code_context": [
    {
      "filename": "core/templates/pages/exploration-editor-page/translation-tab/audio-translation-bar/audio-translation-bar.component.html",
      "content": "<div  class=\"oppia-drop-area\" *ngIf=\"dropAreaIsAccessible\">\n  <div class=\"oppia-blur-background\"></div>\n  <div class=\"oppia-drop-area-message\" >Drop your file here!</div>\n</div>\n<div  class=\"oppia-drop-area\" *ngIf=\"userIsGuest\">\n  <div class=\"oppia-blur-background\"></div>\n  <div class=\"oppia-drop-area-message-for-guest-users\">Please log in to upload audio files.</div>\n</div>\n<div class=\"oppia-audio-recording-bar\" [hidden]=\"!((!isAudioAvailable || audioIsUpdating) && !selectedRecording)\">\n  <div class=\"oppia-content-wrapper\">\n    <button class=\"btn oppia-audio-button oppia-audio-bar-button-transition\" disabled>\n      <i class=\"fas fa-play oppia-play-icon\"></i>\n    </button>\n  </div>\n  <div class=\"d-block d-xl-none oppia-content-wrapper oppia-audio-bar-info\">\n    <div class=\"padding-small-screen\">\n      <div *ngIf=\"!cannotRecord && !checkingMicrophonePermission\">\n        <span *ngIf=\"canVoiceover\"> Press <i class=\"fas fa-microphone\"></i>  to record.</span>\n      </div>\n      <div *ngIf=\"checkingMicrophonePermission\">\n        Loading microphone.<loading-dots></loading-dots>\n      </div>\n      <div *ngIf=\"recordingPermissionDenied && cannotRecord\">\n        Permission needed for recording.\n      </div>\n      <div *ngIf=\"unsupportedBrowser && cannotRecord\">\n        Microphone is not supported.\n      </div>\n    </div>\n  </div>\n  <div class=\"d-none d-xl-block oppia-content-wrapper oppia-audio-bar-info\">\n    <div class=\"padding-large-screen\">\n      <div *ngIf=\"!cannotRecord && !checkingMicrophonePermission\">\n        No audio recorded.<span *ngIf=\"canVoiceover\"> Press <i class=\"fas fa-microphone\"></i>  to start recording.</span>\n      </div>\n      <div *ngIf=\"checkingMicrophonePermission\">\n        Loading microphone.<loading-dots></loading-dots>\n      </div>\n      <div *ngIf=\"recordingPermissionDenied && cannotRecord\">\n        You need to grant permission for this application to use your microphone.\n      </div>\n      <div *ngIf=\"unsupportedBrowser && cannotRecord\">\n        Sorry, your browser does not support recording feature.\n      </div>\n    </div>\n  </div>\n  <div class=\"oppia-content-wrapper\">\n    <button class=\"btn oppia-audio-button oppia-audio-bar-button-transition e2e-test-accessibility-translation-start-record\"\n            [ngbTooltip]=\"'Record'\"\n            placement=\"bottom\"\n            (click)=\"checkAndStartRecording()\"\n            [hidden]=\"!canVoiceover || cannotRecord\"\n            aria-label=\"Start recording\"\n            for=\"Recording\">\n      <i class=\"fas fa-microphone oppia-microphone-icon\"></i>\n    </button>\n  </div>\n  <div class=\"oppia-content-wrapper\">\n    <button class=\"btn oppia-audio-button oppia-audio-bar-button-transition e2e-test-upload-audio-button e2e-test-accessibility-translation-upload-audio\"\n            [ngbTooltip]=\"'Upload'\"\n            placement=\"bottom\"\n            (click)=\"openAddAudioTranslationModal(null)\"\n            [hidden]=\"!canVoiceover\"\n            aria-label=\"Upload voiceovered file\">\n      <i class=\"fas fa-upload\"></i>\n    </button>\n  </div>\n</div>\n<div class=\"oppia-audio-recording-bar\" [hidden]=\"!(selectedRecording  && !audioIsCurrentlyBeingSaved)\">\n  <div class=\"oppia-content-wrapper\">\n    <button class=\"btn oppia-audio-button oppia-audio-bar-button-transition e2e-test-accessibility-translation-play-recorded-audio\"\n            (click)=\"playAndPauseUnsavedAudio()\"\n            [disabled]=\"voiceoverRecorder.status().isRecording\"\n            aria-label=\"Play recorded audio\">\n      <div *ngIf=\"unsavedAudioIsPlaying\">\n        <i class=\"fas fa-pause\"></i>\n      </div>\n      <div *ngIf=\"!unsavedAudioIsPlaying\">\n        <i class=\"fas fa-play oppia-play-icon\"></i>\n      </div>\n    </button>\n  </div>\n  <div class=\"oppia-content-wrapper oppia-flex-1-wrapper\">\n    <div class=\"oppia-audio-visualiser\">\n      <div class=\"oppia-mp3-converting\" *ngIf=\"voiceoverRecorder.status().isRecording\" tabindex=\"0\">\n        Recording audio<loading-dots></loading-dots>\n      </div>\n      <div id=\"visualized\" #visualized class=\"oppia-audio-wave-view\" *ngIf=\"!voiceoverRecorder.status().isRecording && !audioIsCurrentlyBeingSaved\">\n      </div>\n    </div>\n  </div>\n  <div class=\"oppia-content-wrapper\" *ngIf=\"voiceoverRecorder.status().isRecording\">\n    <div class=\"oppia-recording-timer\" tabindex=\"0\">\n      {{ recordingDate | formatTime }} / {{ recordingTimeLimit | formatTime }}\n    </div>\n  </div>\n  <div class=\"oppia-content-wrapper\" *ngIf=\"voiceoverRecorder.status().isRecording\">\n    <button class=\"btn oppia-audio-button oppia-audio-bar-button-transition e2e-test-stop-record-button\"\n            [ngbTooltip]=\"'Stop'\"\n            placement=\"bottom\"\n            (click)=\"stopRecording()\"\n            aria-label=\"Stop recording\">\n      <i class=\"fas fa-stop\"></i>\n    </button>\n  </div>\n  <div class=\"oppia-content-wrapper\">\n    <button class=\"btn oppia-audio-action-button oppia-audio-bar-button-transition\"\n            *ngIf=\"!voiceoverRecorder.status().isRecording && audioBlob\"\n            (click)=\"reRecord()\"\n            aria-label=\"Record again\">\n      Re-take\n    </button>\n  </div>\n  <div class=\"oppia-content-wrapper\" *ngIf=\"!voiceoverRecorder.status().isRecording && audioBlob\">\n    <button class=\"btn oppia-audio-action-button oppia-audio-bar-button-transition e2e-test-confirm-record\"\n            (click)=\"saveRecordedAudio()\"\n            aria-label=\"Save the recorded audio\">\n      Confirm\n    </button>\n  </div>\n  <div class=\"oppia-content-wrapper\" *ngIf=\"!voiceoverRecorder.status().isRecording && audioBlob\">\n    <button class=\"btn oppia-cancel-button oppia-audio-bar-button-transition\"\n            (click)=\"cancelRecording()\"\n            aria-label=\"Cancel the recorded audio\">\n      Cancel\n    </button>\n  </div>\n</div>\n<div class=\"oppia-audio-recording-bar\" *ngIf=\"audioIsCurrentlyBeingSaved\">\n  <div class=\"oppia-content-wrapper\">\n    <button class=\"btn oppia-audio-button oppia-audio-bar-button-transition\" disabled>\n      <i class=\"fas fa-play oppia-play-icon\"></i>\n    </button>\n  </div>\n  <div class=\"oppia-content-wrapper oppia-flex-1-wrapper\">\n    <div class=\"oppia-audio-bar-info\">\n      <div>Saving<loading-dots></loading-dots></div>\n    </div>\n  </div>\n</div>\n<div *ngIf=\"isAudioAvailable && !audioIsUpdating\" class=\"oppia-audio-recording-bar\">\n  <div class=\"oppia-content-wrapper\">\n    <button class=\"btn oppia-audio-button oppia-audio-bar-button-transition e2e-test-play-pause-audio-button\"\n            (click)=\"playPauseUploadedAudioTranslation()\">\n      <div *ngIf=\"!isPlayingUploadedAudio()\">\n        <i class=\"fas fa-play oppia-play-icon\"></i>\n      </div>\n      <div *ngIf=\"isPlayingUploadedAudio()\">\n        <i class=\"fas fa-pause\"></i>\n      </div>\n    </button>\n  </div>\n  <div class=\"oppia-slider-section oppia-content-wrapper fx-main-center fx-cross-center full-height\">\n    <div *ngIf=\"audioLoadingIndicatorIsShown\">\n      <mat-progress-bar mode=\"indeterminate\"></mat-progress-bar>\n    </div>\n    <div *ngIf=\"!audioLoadingIndicatorIsShown\" class=\"fx-row fx-main-center fx-cross-center\">\n      <oppia-audio-slider class=\"full-width\"\n                          [value]=\"audioPlayerService.getCurrentTimeInSecs()\"\n                          [max]=\"durationSecs\"\n                          (valueChange)=\"setProgress($event)\"\n                          [thumbLabel]=\"true\"\n                          aria-label=\"audio-slider\">\n      </oppia-audio-slider>\n    </div>\n  </div>\n  <div class=\"oppia-content-wrapper oppia-recording-timer\" tabindex=\"0\">\n    <div *ngIf=\"isAudioAvailable && audioIsLoading\">\n      {{ startingDuration | formatTime }} / {{ durationSecs | formatTime }}\n    </div>\n    <div *ngIf=\"audioTimerIsShown && !audioIsLoading\">\n      {{ audioPlayerService.getCurrentTimeInSecs() | formatTime }} / {{ durationSecs | formatTime }}\n    </div>\n    <div *ngIf=\"!audioTimerIsShown && !audioIsLoading\">\n       -- / --\n    </div>\n  </div>\n  <div class=\"oppia-content-wrapper\">\n    <button class=\"btn oppia-audio-button oppia-audio-bar-button-transition e2e-test-upload-audio-button\"\n            [ngbTooltip]=\"'Upload audio'\"\n            placement=\"bottom\"\n            [hidden]=\"!canVoiceover\"\n            (click)=\"openAddAudioTranslationModal()\">\n      <i class=\"fas fa-upload oppia-upload-icon\"></i>\n    </button>\n  </div>\n  <div class=\"oppia-content-wrapper\">\n    <button class=\"btn oppia-audio-button oppia-audio-bar-button-transition e2e-test-delete-record\"\n            [ngbTooltip]=\"'Delete'\"\n            placement=\"bottom\"\n            [hidden]=\"!canVoiceover\"\n            (click)=\"openDeleteAudioTranslationModal()\">\n      <i class=\"fas fa-trash oppia-delete-icon\"></i>\n    </button>\n  </div>\n  <div class=\"oppia-content-wrapper\" *ngIf=\"!audioNeedsUpdate\">\n    <button class=\"btn oppia-audio-button oppia-audio-bar-button-transition\"\n            [ngbTooltip]=\"'Audio needs update'\"\n            placement=\"bottom\"\n            [hidden]=\"!canVoiceover\"\n            (click)=\"toggleAudioNeedsUpdate()\">\n      <i class=\"fas fa-exclamation-triangle\"></i>\n    </button>\n  </div>\n  <div class=\"oppia-content-wrapper\" *ngIf=\"audioNeedsUpdate\">\n    <button class=\"btn oppia-audio-button audio-update-needed-button oppia-audio-bar-button-transition\"\n            [ngbTooltip]=\"'Audio does not need update'\"\n            placement=\"bottom\"\n            [hidden]=\"!canVoiceover\"\n            (click)=\"toggleAudioNeedsUpdate()\">\n      <i class=\"fas fa-exclamation-triangle\"></i>\n    </button>\n  </div>\n</div>\n<div class=\"oppia-translation-bottom-right-container\" *ngIf=\"showRecorderWarning\" tabindex=\"0\">\n  <span>\n    <strong>Warning: </strong>Don't navigate to other tabs of this page before saving recorded audio, otherwise the recorded audio will be lost.\n  </span>\n</div>\n<div class=\"oppia-translation-bottom-proTip\" *ngIf=\"canVoiceover && !showRecorderWarning && !audioBlob && !isAudioAvailable\">\n  <div class=\"alert alert-secondary\" tabindex=\"0\">\n    <strong>ProTips</strong>\n    <div>Use the \"R\" key to start/stop recording.</div>\n    <div>Use a dedicated microphone for best results.</div>\n  </div>\n</div>\n\n<style>\n  .oppia-drop-area {\n    border: 3px dashed #aaa;\n    height: 80%;\n    position: absolute;\n    top: 10%;\n    width: 100%;\n    z-index: 100;\n  }\n  .oppia-blur-background {\n    background-color: #fff;\n    height: 100%;\n    opacity: 0.8;\n    position: absolute;\n    width: 100%;\n  }\n  .oppia-drop-area-message {\n    font-size: 36px;\n    height: 100%;\n    padding: 20%;\n    position: absolute;\n    text-align: center;\n    width: 100%;\n  }\n  .oppia-drop-area-message-for-guest-users {\n    color: #aaa;\n    font-size: 36px;\n    height: 100%;\n    padding: 20%;\n    position: absolute;\n    text-align: center;\n    width: 100%;\n  }\n  .oppia-audio-recording-bar {\n    align-items: center;\n    background-color: #f7f7f7;\n    display: flex;\n    height: 100%;\n    padding: 0 10px;\n    width: 100%;\n  }\n  .audioRecorder {\n    align-items: center;\n    display: flex;\n  }\n  .audioRecorder > div:first-child {\n    width: 0 !important;\n  }\n  .oppia-content-wrapper {\n    margin: 0 5px;\n  }\n  .oppia-audio-bar-info {\n    background-color: #009688;\n    border-radius: 3px;\n    color: white;\n    flex: 1;\n    font-size: 12px;\n    height: 38px;\n    line-height: 27px;\n    text-align: center;\n  }\n  .oppia-audio-bar-info .padding-small-screen {\n    font-size: 11px;\n    padding: 5px 2px;\n  }\n  .oppia-audio-bar-info .padding-large-screen {\n    padding: 5px 20px;\n  }\n  .oppia-audio-button {\n    background-color: #009688;\n    border-radius: 20px;\n    color: white;\n    padding-left: 10px;\n    width: 36px;\n  }\n  .oppia-audio-bar-button-transition {\n    -webkit-transition: background-color .2s cubic-bezier(.35,0,.25,1);\n    -moz-transition: background-color .2s cubic-bezier(.35,0,.25,1);\n    -o-transition: background-color .2s cubic-bezier(.35,0,.25,1);\n    transition: background-color .2s cubic-bezier(.35,0,.25,1);\n  }\n  .oppia-audio-action-button {\n    background-color: #009688;\n    border-radius: 3px;\n    color: white;\n    padding-left: 6px;\n    width: 68px;\n  }\n  .oppia-cancel-button {\n    background-color: #009688;\n    border-radius: 3px;\n    color: white;\n    padding-left: 6px;\n    width: 57px;\n  }\n  .oppia-audio-button:hover, .oppia-audio-action-button:hover, .oppia-cancel-button:hover {\n    background-color: #01675d;\n    color: white;\n  }\n  .oppia-audio-button[disabled] {\n    background-color: #009688;\n    pointer-events: auto;\n  }\n  .oppia-audio-button:focus {\n    color: white;\n  }\n  .oppia-audio-visualiser {\n    flex: 1;\n    height: 38px;\n  }\n  .oppia-flex-1-wrapper {\n    flex: 1;\n  }\n  .oppia-mp3-converting {\n    background-color: #009688;\n    border-radius: 3px;\n    color: white;\n    flex: 1;\n    font-size: 12px;\n    height: 38px;\n    line-height: 27px;\n    padding: 5px 40px;\n    text-align: center;\n  }\n  .oppia-recording-timer {\n    font-size: 14px;\n    text-align: center;\n    width: 83px;\n  }\n  .oppia-slider-section {\n    background-color: #009688;\n    border-radius: 3px;\n    color: white;\n    flex: 1;\n    font-size: 12px;\n    height: 38px;\n    padding: 0 15px;\n    text-align: center;\n  }\n  .oppia-translation-bottom-right-container {\n    color: #ce133b;\n    font-size: 12px;\n    letter-spacing: 0.5px;\n    position: relative;\n    text-align: center;\n    top: 10px;\n  }\n  .oppia-translation-bottom-proTip {\n    color: #000;\n    font-size: 12px;\n    letter-spacing: 0.5px;\n    position: relative;\n    text-align: center;\n    top: 10px;\n  }\n  .oppia-microphone-icon {\n    padding-left: 1px;\n  }\n  .oppia-play-icon {\n    padding-left: 2px;\n  }\n  .oppia-delete-icon {\n    padding-left: 1px;\n  }\n  audio-translation-bar .audio-update-needed-button {\n    background-color: red;\n  }\n  audio-translation-bar .tooltip-inner {\n  max-width: none;\n  white-space: nowrap;\n  }\n  audio-translation-bar md-progress-linear {\n    height: 38px;\n    padding-top: 12px;\n  }\n  audio-translation-bar md-progress-linear.md-default-theme .md-container {\n    background-color: #f8f8f8;\n  }\n  audio-translation-bar md-progress-linear.md-default-theme .md-bar {\n    background-color: #009688;\n  }\n  audio-translation-bar md-slider {\n    height: 38px;\n  }\n  audio-translation-bar md-slider .md-track-container {\n    height: 1px;\n    top: 18px !important;\n  }\n  audio-translation-bar md-slider .md-track {\n    background-color: #f8f8f8;\n  }\n  audio-translation-bar md-slider.md-default-theme .md-track-fill {\n    background-color: #009688;\n  }\n  audio-translation-bar .md-thumb-container {\n    left: 4px;\n    top: -5px;\n  }\n  audio-translation-bar md-slider.md-default-theme .md-thumb:after {\n    background-color: #009688;\n    border-color: #ccc;\n  }\n  audio-translation-bar canvas {\n    background: #e4e1d1;\n    border-radius: 3px;\n    max-width: unset;\n  }\n  .full-width {\n    width: 100%;\n  }\n  .full-height {\n    height: 100%;\n  }\n</style>\n"
    },
    {
      "filename": "core/templates/pages/exploration-editor-page/translation-tab/voiceover-card/voiceover-card.component.spec.ts",
      "content": "// Copyright 2024 The Oppia Authors. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS-IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Unit tests for VoiceoverCardComponent.\n */\n\nimport {\n  ComponentFixture,\n  fakeAsync,\n  flush,\n  tick,\n  TestBed,\n  discardPeriodicTasks,\n  waitForAsync,\n} from '@angular/core/testing';\nimport {NO_ERRORS_SCHEMA, Pipe, EventEmitter} from '@angular/core';\nimport {HttpClientTestingModule} from '@angular/common/http/testing';\nimport {AudioPlayerService} from 'services/audio-player.service';\nimport {ContextService} from 'services/context.service';\nimport {TranslationLanguageService} from '../services/translation-language.service';\nimport {NgbModal, NgbModalRef} from '@ng-bootstrap/ng-bootstrap';\nimport {TranslationTabActiveContentIdService} from '../services/translation-tab-active-content-id.service';\nimport {Voiceover} from 'domain/exploration/voiceover.model';\nimport {ChangeListService} from 'pages/exploration-editor-page/services/change-list.service';\nimport {LocalStorageService} from 'services/local-storage.service';\nimport {EntityVoiceoversService} from 'services/entity-voiceovers.services';\nimport {EntityVoiceovers} from 'domain/voiceover/entity-voiceovers.model';\nimport {VoiceoverCardComponent} from './voiceover-card.component';\nimport {FormatTimePipe} from 'filters/format-timer.pipe';\nimport {VoiceoverBackendDict} from 'domain/exploration/voiceover.model';\n\n@Pipe({name: 'formatTime'})\nclass MockFormatTimePipe {\n  transform(value: number): string {\n    return String(value);\n  }\n}\n\nclass MockNgbModal {\n  open() {\n    return {\n      result: Promise.resolve(),\n    };\n  }\n}\n\ndescribe('Voiceover card component', () => {\n  let component: VoiceoverCardComponent;\n  let fixture: ComponentFixture<VoiceoverCardComponent>;\n  let ngbModal: NgbModal;\n  let contextService: ContextService;\n  let audioPlayerService: AudioPlayerService;\n  let translationLanguageService: TranslationLanguageService;\n  let translationTabActiveContentIdService: TranslationTabActiveContentIdService;\n  let changeListService: ChangeListService;\n  let localStorageService: LocalStorageService;\n  let entityVoiceoversService: EntityVoiceoversService;\n\n  beforeEach(waitForAsync(() => {\n    TestBed.configureTestingModule({\n      imports: [HttpClientTestingModule],\n      declarations: [VoiceoverCardComponent, MockFormatTimePipe],\n      providers: [\n        {\n          provide: FormatTimePipe,\n          useClass: MockFormatTimePipe,\n        },\n        {\n          provide: NgbModal,\n          useClass: MockNgbModal,\n        },\n        TranslationLanguageService,\n      ],\n      schemas: [NO_ERRORS_SCHEMA],\n    }).compileComponents();\n  }));\n\n  beforeEach(() => {\n    fixture = TestBed.createComponent(VoiceoverCardComponent);\n    component = fixture.componentInstance;\n    contextService = TestBed.inject(ContextService);\n    ngbModal = TestBed.inject(NgbModal);\n    audioPlayerService = TestBed.inject(AudioPlayerService);\n    translationLanguageService = TestBed.inject(TranslationLanguageService);\n    translationTabActiveContentIdService = TestBed.inject(\n      TranslationTabActiveContentIdService\n    );\n    changeListService = TestBed.inject(ChangeListService);\n    localStorageService = TestBed.inject(LocalStorageService);\n    changeListService = TestBed.inject(ChangeListService);\n    entityVoiceoversService = TestBed.inject(EntityVoiceoversService);\n\n    spyOn(\n      translationLanguageService,\n      'onActiveLanguageChanged'\n    ).and.returnValue(new EventEmitter<void>());\n    spyOn(\n      translationTabActiveContentIdService,\n      'onActiveContentIdChanged'\n    ).and.returnValue(new EventEmitter<string>());\n    spyOn(\n      translationLanguageService,\n      'onActiveLanguageAccentChanged'\n    ).and.returnValue(new EventEmitter<void>());\n    spyOn(entityVoiceoversService, 'onVoiceoverLoad').and.returnValue(\n      new EventEmitter<void>()\n    );\n  });\n\n  it('should be able to initialize the voiceover card component', fakeAsync(() => {\n    spyOn(\n      localStorageService,\n      'getLastSelectedLanguageAccentCode'\n    ).and.returnValue('en-US');\n    spyOn(component, 'updateLanguageCode');\n    spyOn(component, 'updateActiveContent');\n    spyOn(component, 'updateLanguageAccentCode');\n    let questionSummariesInitializedEmitter = new EventEmitter();\n    spyOn(\n      translationLanguageService,\n      'onActiveLanguageChanged'\n    ).and.returnValue(questionSummariesInitializedEmitter);\n\n    spyOn(audioPlayerService, 'isTrackLoaded').and.returnValue(true);\n    spyOn(audioPlayerService, 'isPlaying').and.returnValue(true);\n    spyOn(audioPlayerService, 'getCurrentTimeInSecs').and.returnValue(10);\n\n    component.manualVoiceoverDuration = 10;\n    component.voiceoverProgress = 0;\n    component.pageIsLoaded = false;\n\n    component.ngOnInit();\n    translationLanguageService.onActiveLanguageAccentChanged.emit();\n    translationLanguageService.onActiveLanguageChanged.emit();\n    translationTabActiveContentIdService.onActiveContentIdChanged.emit();\n    entityVoiceoversService.onVoiceoverLoad.emit();\n\n    flush();\n    tick(5000);\n    tick();\n    discardPeriodicTasks();\n\n    expect(component.pageIsLoaded).toBeTrue();\n\n    expect(component.voiceoverProgress).toEqual(100);\n  }));\n\n  it('should be able to initialize the voiceover card component when audio is not loaded', fakeAsync(() => {\n    spyOn(\n      localStorageService,\n      'getLastSelectedLanguageAccentCode'\n    ).and.returnValue('en-US');\n    spyOn(component, 'updateLanguageCode');\n    spyOn(component, 'updateActiveContent');\n    spyOn(component, 'updateLanguageAccentCode');\n\n    spyOn(audioPlayerService, 'isTrackLoaded').and.returnValue(false);\n\n    component.pageIsLoaded = false;\n    component.voiceoverProgress = 80;\n\n    component.ngOnInit();\n    flush();\n    tick(5000);\n    tick();\n    discardPeriodicTasks();\n\n    expect(component.pageIsLoaded).toBeTrue();\n    expect(component.voiceoverProgress).toEqual(0);\n  }));\n\n  it('should be able to update voiceover with the active change list', fakeAsync(() => {\n    let voiceover1: VoiceoverBackendDict = {\n      filename: 'b.mp3',\n      file_size_bytes: 100000,\n      needs_update: false,\n      duration_secs: 12.0,\n    };\n\n    let changeDicts = [\n      {\n        cmd: 'update_voiceovers',\n        language_accent_code: 'en-US',\n        content_id: 'content_id_1',\n        voiceovers: {\n          manual: voiceover1,\n        },\n      },\n      {\n        cmd: 'update_voiceovers',\n        language_accent_code: 'en-US',\n        content_id: 'content_id_2',\n        voiceovers: {},\n      },\n    ];\n\n    spyOn(changeListService, 'getVoiceoverChangeList').and.returnValue(\n      changeDicts\n    );\n\n    spyOn(\n      entityVoiceoversService,\n      'getEntityVoiceoversByLanguageAccentCode'\n    ).and.returnValue(undefined);\n\n    spyOn(entityVoiceoversService, 'addEntityVoiceovers');\n\n    component.updateVoiceoverWithChangeList();\n    flush();\n    discardPeriodicTasks();\n\n    expect(entityVoiceoversService.addEntityVoiceovers).toHaveBeenCalled();\n  }));\n\n  it('should be able to update active content', fakeAsync(() => {\n    component.activeContentId = 'content_0';\n\n    spyOn(\n      translationTabActiveContentIdService,\n      'getActiveContentId'\n    ).and.returnValue('content_1');\n    spyOn(\n      localStorageService,\n      'getLastSelectedLanguageAccentCode'\n    ).and.returnValue('en-US');\n\n    component.updateActiveContent();\n    flush();\n    discardPeriodicTasks();\n    expect(component.activeContentId).toEqual('content_1');\n  }));\n\n  it('should be able to update language code', fakeAsync(() => {\n    spyOn(\n      localStorageService,\n      'getLastSelectedLanguageAccentCode'\n    ).and.returnValue('en-US');\n    spyOn(entityVoiceoversService, 'fetchEntityVoiceovers').and.returnValue(\n      Promise.resolve()\n    );\n    let activeLanguageCodeSpy = spyOn(\n      translationLanguageService,\n      'getActiveLanguageCode'\n    );\n\n    activeLanguageCodeSpy.and.returnValue('en');\n\n    expect(component.languageCode).toBeUndefined();\n\n    component.updateLanguageCode();\n    flush();\n    discardPeriodicTasks();\n    expect(component.languageCode).toEqual('en');\n\n    activeLanguageCodeSpy.and.returnValue('hi');\n    component.updateLanguageCode();\n    flush();\n    discardPeriodicTasks();\n    expect(component.languageCode).toEqual('hi');\n  }));\n\n  it('should be able to set active manual voiceover', fakeAsync(() => {\n    let manualVoiceoverBackendDict: VoiceoverBackendDict = {\n      filename: 'a.mp3',\n      file_size_bytes: 200000,\n      needs_update: false,\n      duration_secs: 10.0,\n    };\n    let contentIdToVoiceoversMappingBackendDict = {\n      content0: {\n        manual: manualVoiceoverBackendDict,\n      },\n    };\n    let entityId = 'exploration_1';\n    let entityType = 'exploration';\n    let entityVersion = 1;\n    let languageAccentCode = 'en-US';\n\n    let entityVoiceoversBackendDict = {\n      entity_id: entityId,\n      entity_type: entityType,\n      entity_version: entityVersion,\n      language_accent_code: languageAccentCode,\n      voiceovers_mapping: contentIdToVoiceoversMappingBackendDict,\n    };\n    let entityVoiceovers = EntityVoiceovers.createFromBackendDict(\n      entityVoiceoversBackendDict\n    );\n\n    entityVoiceoversService.init(entityId, entityType, entityVersion, 'en');\n    entityVoiceoversService.addEntityVoiceovers('en-US', entityVoiceovers);\n    component.languageAccentCode = 'en-US';\n    component.activeContentId = 'content1';\n\n    component.setActiveContentManualVoiceover();\n    flush();\n    discardPeriodicTasks();\n\n    component.activeContentId = 'content0';\n    component.setActiveContentManualVoiceover();\n    flush();\n    discardPeriodicTasks();\n\n    expect(component.manualVoiceover.filename).toEqual('a.mp3');\n  }));\n\n  it('should be able to update language accent code', fakeAsync(() => {\n    component.languageAccentCode = 'en-US';\n    component.unsupportedLanguageCode = true;\n\n    component.updateLanguageAccentCode('en-IN');\n    flush();\n    discardPeriodicTasks();\n\n    expect(component.languageAccentCode).toEqual('en-IN');\n    expect(component.unsupportedLanguageCode).toBeFalse();\n\n    component.updateLanguageAccentCode('');\n    flush();\n    discardPeriodicTasks();\n\n    expect(component.unsupportedLanguageCode).toBeTrue();\n    expect(component.languageAccentCode).toEqual('');\n  }));\n\n  it('should be able to load and play voiceover', fakeAsync(() => {\n    audioPlayerService.pause();\n    spyOn(audioPlayerService, 'isTrackLoaded').and.returnValue(false);\n    component.audioIsLoaded = false;\n    spyOn(audioPlayerService, 'loadAsync').and.returnValue(Promise.resolve());\n\n    component.playAndPauseVoiceover('a.mp3');\n    flush();\n    discardPeriodicTasks();\n    expect(audioPlayerService.loadAsync).toHaveBeenCalled();\n  }));\n\n  it('should be able to play loaded voiceover', fakeAsync(() => {\n    audioPlayerService.pause();\n    spyOn(audioPlayerService, 'play');\n\n    spyOn(audioPlayerService, 'isPlaying').and.returnValue(false);\n    spyOn(audioPlayerService, 'isTrackLoaded').and.returnValue(true);\n    component.playAndPauseVoiceover('a.mp3');\n\n    expect(audioPlayerService.play).toHaveBeenCalled();\n  }));\n\n  it('should be able to play and pause loaded voiceover', fakeAsync(() => {\n    spyOn(audioPlayerService, 'isPlaying').and.returnValue(true);\n    audioPlayerService.play();\n    component.playAndPauseVoiceover('a.mp3');\n    flush();\n    discardPeriodicTasks();\n    expect(audioPlayerService.isPlaying()).toBeTrue();\n  }));\n\n  it('should be able to delete manual voiceover', fakeAsync(() => {\n    spyOn(ngbModal, 'open').and.returnValue({\n      componentInstance: {},\n      result: Promise.resolve(),\n    } as NgbModalRef);\n\n    let manualVoiceoverBackendDict: VoiceoverBackendDict = {\n      filename: 'a.mp3',\n      file_size_bytes: 200000,\n      needs_update: false,\n      duration_secs: 10.0,\n    };\n    component.manualVoiceover = Voiceover.createFromBackendDict(\n      manualVoiceoverBackendDict\n    );\n\n    let entityId = 'exploration_1';\n    let entityType = 'exploration';\n    let entityVersion = 1;\n    let languageAccentCode = 'en-US';\n    let contentIdToVoiceoversMappingBackendDict = {\n      content0: {\n        manual: manualVoiceoverBackendDict,\n      },\n    };\n    let entityVoiceoversBackendDict = {\n      entity_id: entityId,\n      entity_type: entityType,\n      entity_version: entityVersion,\n      language_accent_code: languageAccentCode,\n      voiceovers_mapping: contentIdToVoiceoversMappingBackendDict,\n    };\n    component.activeEntityVoiceoversInstance =\n      EntityVoiceovers.createFromBackendDict(entityVoiceoversBackendDict);\n\n    component.deleteManualVoiceover();\n    flush();\n    discardPeriodicTasks();\n\n    expect(component.manualVoiceover).toBeUndefined();\n  }));\n\n  it('should not be able to delete manual voiceover for rejection handler', fakeAsync(() => {\n    spyOn(ngbModal, 'open').and.returnValue({\n      componentInstance: {},\n      result: Promise.reject(),\n    } as NgbModalRef);\n\n    let manualVoiceoverBackendDict: VoiceoverBackendDict = {\n      filename: 'a.mp3',\n      file_size_bytes: 200000,\n      needs_update: false,\n      duration_secs: 10.0,\n    };\n    component.manualVoiceover = Voiceover.createFromBackendDict(\n      manualVoiceoverBackendDict\n    );\n\n    component.deleteManualVoiceover();\n    flush();\n    discardPeriodicTasks();\n\n    expect(component.manualVoiceover.filename).toEqual('a.mp3');\n  }));\n\n  it('should be able to toggle manual voiceover status', fakeAsync(() => {\n    let manualVoiceoverBackendDict: VoiceoverBackendDict = {\n      filename: 'a.mp3',\n      file_size_bytes: 200000,\n      needs_update: false,\n      duration_secs: 10.0,\n    };\n    component.manualVoiceover = Voiceover.createFromBackendDict(\n      manualVoiceoverBackendDict\n    );\n    let entityId = 'exploration_1';\n    let entityType = 'exploration';\n    let entityVersion = 1;\n    let languageAccentCode = 'en-US';\n    let contentIdToVoiceoversMappingBackendDict = {\n      content0: {\n        manual: manualVoiceoverBackendDict,\n      },\n    };\n    let entityVoiceoversBackendDict = {\n      entity_id: entityId,\n      entity_type: entityType,\n      entity_version: entityVersion,\n      language_accent_code: languageAccentCode,\n      voiceovers_mapping: contentIdToVoiceoversMappingBackendDict,\n    };\n    let entityVoiceovers = EntityVoiceovers.createFromBackendDict(\n      entityVoiceoversBackendDict\n    );\n\n    component.languageAccentCode = 'en-US';\n    component.activeContentId = 'content0';\n\n    entityVoiceoversService.init(entityId, entityType, entityVersion, 'en');\n    entityVoiceoversService.addEntityVoiceovers('en-US', entityVoiceovers);\n\n    expect(component.manualVoiceover.needsUpdate).toBeFalse();\n    component.toggleAudioNeedsUpdate();\n    flush();\n    discardPeriodicTasks();\n\n    expect(component.manualVoiceover.needsUpdate).toBeTrue();\n  }));\n\n  it('should be able to add manual voiceovers', fakeAsync(() => {\n    spyOn(contextService, 'getExplorationId').and.returnValue('exp_1');\n    spyOn(contextService, 'getExplorationVersion').and.returnValue(1);\n\n    let result = {\n      filename: 'a.mp3',\n      fileSizeBytes: 200000,\n      durationSecs: 10.0,\n    };\n\n    spyOn(ngbModal, 'open').and.returnValue({\n      componentInstance: {},\n      result: Promise.resolve(result),\n    } as NgbModalRef);\n\n    expect(component.manualVoiceover).toBeUndefined();\n\n    component.addManualVoiceover();\n    flush();\n    discardPeriodicTasks();\n\n    expect(component.manualVoiceover.filename).toEqual('a.mp3');\n    expect(component.manualVoiceover.durationSecs).toEqual(10.0);\n  }));\n\n  it('should not add manual voiceovers for reject handler', fakeAsync(() => {\n    spyOn(contextService, 'getExplorationId').and.returnValue('exp_1');\n    spyOn(contextService, 'getExplorationVersion').and.returnValue(1);\n\n    spyOn(ngbModal, 'open').and.returnValue({\n      componentInstance: {},\n      result: Promise.reject(),\n    } as NgbModalRef);\n\n    expect(component.manualVoiceover).toBeUndefined();\n\n    component.addManualVoiceover();\n    flush();\n    discardPeriodicTasks();\n\n    expect(component.manualVoiceover).toBeUndefined();\n  }));\n});\n"
    },
    {
      "filename": "core/templates/pages/exploration-editor-page/translation-tab/voiceover-card/voiceover-card.component.ts",
      "content": "// Copyright 2024 The Oppia Authors. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS-IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Component for the voiceovers in the Exploration editor page.\n */\n\nimport {Component, ElementRef, OnInit, ViewChild} from '@angular/core';\nimport {NgbModal} from '@ng-bootstrap/ng-bootstrap';\nimport {Subscription} from 'rxjs';\nimport {AddAudioTranslationModalComponent} from '../modal-templates/add-audio-translation-modal.component';\nimport {AlertsService} from 'services/alerts.service';\nimport {AudioPlayerService} from 'services/audio-player.service';\nimport {ContextService} from 'services/context.service';\nimport {IdGenerationService} from 'services/id-generation.service';\nimport {TranslationLanguageService} from '../services/translation-language.service';\nimport {TranslationTabActiveContentIdService} from '../services/translation-tab-active-content-id.service';\nimport {Voiceover} from 'domain/exploration/voiceover.model';\nimport {ChangeListService} from 'pages/exploration-editor-page/services/change-list.service';\nimport {VoiceoverRemovalConfirmModalComponent} from './modals/voiceover-removal-confirm-modal.component';\nimport {LocalStorageService} from 'services/local-storage.service';\nimport {EntityVoiceoversService} from 'services/entity-voiceovers.services';\nimport {EntityVoiceovers} from 'domain/voiceover/entity-voiceovers.model';\nimport {TranslationStatusService} from '../services/translation-status.service';\nimport {GraphDataService} from 'pages/exploration-editor-page/services/graph-data.service';\nimport {LanguageAccentToDescription} from 'domain/voiceover/voiceover-backend-api.service';\nimport {ExplorationChangeEditVoiceovers} from 'domain/exploration/exploration-draft.model';\n\n@Component({\n  selector: 'oppia-voiceover-card',\n  templateUrl: './voiceover-card.component.html',\n})\nexport class VoiceoverCardComponent implements OnInit {\n  @ViewChild('visualized') visualized!: ElementRef<Element>;\n  directiveSubscriptions = new Subscription();\n\n  pageIsLoaded: boolean = false;\n  audioIsLoaded: boolean = false;\n  languageAccentCodesAreLoaded: boolean = false;\n  isAudioAvailable: boolean = false;\n  voiceoversAreLoaded: boolean = false;\n  languageAccentCodeIsSelected: boolean = false;\n  unsupportedLanguageCode = false;\n\n  manualVoiceover!: Voiceover | undefined;\n  manualVoiceoverDuration: number = 0;\n  currentVoiceoverDuration: number = 0;\n  voiceoverProgress: number = 0;\n\n  activeContentId!: string;\n  languageCode!: string;\n  languageAccentCode!: string;\n\n  availableLanguageAccentCodesToDescriptions: LanguageAccentToDescription = {};\n  supportedLanguageAccentCodesToDescriptions: LanguageAccentToDescription = {};\n  supportedLanguageAccentCodesLength: number = 0;\n\n  languageAccentDescription!: string;\n  activeEntityVoiceoversInstance!: EntityVoiceovers;\n\n  constructor(\n    private audioPlayerService: AudioPlayerService,\n    private contextService: ContextService,\n    private translationLanguageService: TranslationLanguageService,\n    private translationTabActiveContentIdService: TranslationTabActiveContentIdService,\n    private ngbModal: NgbModal,\n    private idGenerationService: IdGenerationService,\n    private alertsService: AlertsService,\n    private changeListService: ChangeListService,\n    private localStorageService: LocalStorageService,\n    private entityVoiceoversService: EntityVoiceoversService,\n    private translationStatusService: TranslationStatusService,\n    private graphDataService: GraphDataService\n  ) {}\n\n  ngOnInit(): void {\n    this.pageIsLoaded = true;\n    this.languageAccentCodesAreLoaded = true;\n    this.languageAccentCode =\n      this.localStorageService.getLastSelectedLanguageAccentCode() as string;\n    this.languageAccentCodeIsSelected = this.languageAccentCode !== 'undefined';\n\n    this.directiveSubscriptions.add(\n      this.translationLanguageService.onActiveLanguageChanged.subscribe(() => {\n        this.updateLanguageCode();\n      })\n    );\n\n    this.directiveSubscriptions.add(\n      this.translationTabActiveContentIdService.onActiveContentIdChanged.subscribe(\n        () => {\n          this.updateActiveContent();\n        }\n      )\n    );\n\n    this.directiveSubscriptions.add(\n      this.translationLanguageService.onActiveLanguageAccentChanged.subscribe(\n        () => {\n          let newLanguageAccentCode =\n            this.localStorageService.getLastSelectedLanguageAccentCode() as string;\n          this.updateLanguageAccentCode(newLanguageAccentCode);\n        }\n      )\n    );\n    this.voiceoversAreLoaded =\n      Object.keys(\n        this.entityVoiceoversService.languageAccentCodeToEntityVoiceovers\n      ).length !== 0;\n    this.directiveSubscriptions.add(\n      this.entityVoiceoversService.onVoiceoverLoad.subscribe(() => {\n        this.voiceoversAreLoaded = true;\n      })\n    );\n\n    setInterval(() => {\n      if (\n        this.audioPlayerService.isTrackLoaded() &&\n        this.audioPlayerService.isPlaying()\n      ) {\n        this.currentVoiceoverDuration = Math.floor(\n          this.audioPlayerService.getCurrentTimeInSecs()\n        );\n        this.voiceoverProgress = Math.round(\n          (this.currentVoiceoverDuration / this.manualVoiceoverDuration) * 100\n        );\n      } else if (!this.audioPlayerService.isTrackLoaded()) {\n        this.voiceoverProgress = 0;\n        this.currentVoiceoverDuration = 0;\n      }\n    }, 1000);\n    this.updateActiveContent();\n  }\n\n  updateVoiceoverWithChangeList(): void {\n    this.changeListService.getVoiceoverChangeList().forEach(changeDict => {\n      changeDict = changeDict as ExplorationChangeEditVoiceovers;\n      let contentId = changeDict.content_id;\n      let voiceovers = changeDict.voiceovers;\n      let languageAccentCode = changeDict.language_accent_code;\n\n      let entityVoiceovers =\n        this.entityVoiceoversService.getEntityVoiceoversByLanguageAccentCode(\n          languageAccentCode\n        );\n      if (entityVoiceovers === undefined) {\n        entityVoiceovers = new EntityVoiceovers(\n          this.entityVoiceoversService.entityId,\n          this.entityVoiceoversService.entityType,\n          this.entityVoiceoversService.entityVersion,\n          languageAccentCode,\n          {}\n        );\n      }\n      if (Object.keys(voiceovers).length > 0) {\n        let manualVoiceover = Voiceover.createFromBackendDict(\n          voiceovers.manual\n        );\n        entityVoiceovers.voiceoversMapping[contentId] = {\n          manual: manualVoiceover,\n        };\n      } else {\n        delete entityVoiceovers.voiceoversMapping[contentId];\n      }\n\n      this.entityVoiceoversService.addEntityVoiceovers(\n        languageAccentCode,\n        entityVoiceovers\n      );\n    });\n  }\n\n  updateActiveContent(): void {\n    this.activeContentId =\n      this.translationTabActiveContentIdService.getActiveContentId() as string;\n\n    let languageAccentCode =\n      this.localStorageService.getLastSelectedLanguageAccentCode() as string;\n\n    this.languageAccentCodeIsSelected = languageAccentCode !== 'undefined';\n\n    if (this.languageAccentCodeIsSelected) {\n      this.languageAccentCode = languageAccentCode;\n      this.setActiveContentManualVoiceover();\n      this.entityVoiceoversService.setActiveLanguageAccentCode(\n        languageAccentCode\n      );\n    }\n  }\n\n  updateLanguageCode(): void {\n    let newLanguageCode =\n      this.translationLanguageService.getActiveLanguageCode();\n\n    if (this.languageCode === undefined) {\n      this.entityVoiceoversService.fetchEntityVoiceovers().then(() => {\n        this.languageAccentCode =\n          this.localStorageService.getLastSelectedLanguageAccentCode() as string;\n\n        this.languageAccentCodeIsSelected =\n          this.languageAccentCode !== 'undefined';\n\n        if (this.languageAccentCodeIsSelected) {\n          this.entityVoiceoversService.setActiveLanguageAccentCode(\n            this.languageAccentCode\n          );\n          this.updateVoiceoverWithChangeList();\n          this.setActiveContentManualVoiceover();\n          this.updateStatusGraph();\n        }\n      });\n    }\n\n    this.languageCode = newLanguageCode;\n    this.entityVoiceoversService.setLanguageCode(this.languageCode);\n  }\n\n  setActiveContentManualVoiceover(): void {\n    this.activeEntityVoiceoversInstance =\n      this.entityVoiceoversService.getEntityVoiceoversByLanguageAccentCode(\n        this.languageAccentCode\n      ) as EntityVoiceovers;\n\n    this.currentVoiceoverDuration = 0;\n    this.voiceoverProgress = 0;\n    this.audioIsLoaded = false;\n    this.audioPlayerService.clear();\n    this.manualVoiceover = undefined;\n\n    if (this.activeEntityVoiceoversInstance === undefined) {\n      return;\n    }\n\n    let voiceoverTypeToVoiceovers =\n      this.activeEntityVoiceoversInstance.voiceoversMapping[\n        this.activeContentId\n      ];\n\n    if (voiceoverTypeToVoiceovers === undefined) {\n      return;\n    }\n\n    this.manualVoiceover = voiceoverTypeToVoiceovers.manual;\n    this.manualVoiceoverDuration = Math.round(\n      this.manualVoiceover.durationSecs\n    );\n  }\n\n  updateLanguageAccentCode(languageAccentCode: string): void {\n    this.languageAccentCodeIsSelected = false;\n\n    if (languageAccentCode === '') {\n      this.unsupportedLanguageCode = true;\n    } else {\n      this.unsupportedLanguageCode = false;\n      this.languageAccentCodeIsSelected = true;\n    }\n    this.languageAccentCode = languageAccentCode;\n    this.entityVoiceoversService.setActiveLanguageAccentCode(\n      languageAccentCode\n    );\n    this.localStorageService.setLastSelectedLanguageAccentCode(\n      languageAccentCode\n    );\n\n    this.setActiveContentManualVoiceover();\n    this.updateStatusGraph();\n  }\n\n  updateStatusGraph(): void {\n    this.translationStatusService.refresh();\n    setTimeout(() => {\n      this.graphDataService.recompute();\n    });\n  }\n\n  playAndPauseVoiceover(filename: string): void {\n    if (this.audioPlayerService.isPlaying()) {\n      this.audioPlayerService.pause();\n      return;\n    }\n    if (this.audioPlayerService.isTrackLoaded()) {\n      this.audioPlayerService.play();\n    } else {\n      this.audioPlayerService.loadAsync(filename).then(() => {\n        this.audioIsLoaded = true;\n        this.audioPlayerService.play();\n      });\n    }\n  }\n\n  deleteManualVoiceover(): void {\n    const modalRef = this.ngbModal.open(VoiceoverRemovalConfirmModalComponent, {\n      backdrop: 'static',\n    });\n    modalRef.result.then(\n      () => {\n        this.manualVoiceover = undefined;\n        this.changeListService.editVoiceovers(\n          this.activeContentId,\n          this.languageAccentCode,\n          {}\n        );\n\n        delete this.activeEntityVoiceoversInstance.voiceoversMapping[\n          this.activeContentId\n        ];\n        this.updateStatusGraph();\n      },\n      () => {\n        // Note to developers:\n        // This callback is triggered when the Cancel button is\n        // clicked. No further action is needed.\n      }\n    );\n  }\n\n  toggleAudioNeedsUpdate(): void {\n    (this.manualVoiceover as Voiceover).needsUpdate = !(\n      this.manualVoiceover as Voiceover\n    ).needsUpdate;\n    this.changeListService.editVoiceovers(\n      this.activeContentId,\n      this.languageAccentCode,\n      {\n        manual: (this.manualVoiceover as Voiceover).toBackendDict(),\n      }\n    );\n\n    let entityVoiceovers =\n      this.entityVoiceoversService.getEntityVoiceoversByLanguageAccentCode(\n        this.languageAccentCode\n      ) as EntityVoiceovers;\n    entityVoiceovers.voiceoversMapping[\n      this.activeContentId\n    ].manual.needsUpdate = (this.manualVoiceover as Voiceover).needsUpdate;\n\n    this.entityVoiceoversService.removeEntityVoiceovers(\n      this.languageAccentCode\n    );\n    this.entityVoiceoversService.addEntityVoiceovers(\n      this.languageAccentCode,\n      entityVoiceovers\n    );\n\n    this.updateStatusGraph();\n  }\n\n  addManualVoiceover(): void {\n    const modalRef = this.ngbModal.open(AddAudioTranslationModalComponent, {\n      backdrop: 'static',\n    });\n\n    modalRef.componentInstance.audioFile = undefined;\n    modalRef.componentInstance.generatedFilename = this.generateNewFilename();\n    modalRef.componentInstance.languageCode = this.languageCode;\n    modalRef.componentInstance.isAudioAvailable = this.isAudioAvailable;\n    modalRef.result.then(\n      result => {\n        this.manualVoiceover = new Voiceover(\n          result.filename,\n          result.fileSizeBytes,\n          false,\n          result.durationSecs\n        );\n\n        this.changeListService.editVoiceovers(\n          this.activeContentId,\n          this.languageAccentCode,\n          {\n            manual: this.manualVoiceover.toBackendDict(),\n          }\n        );\n        this.manualVoiceoverDuration = Math.round(\n          this.manualVoiceover.durationSecs\n        );\n\n        if (this.activeEntityVoiceoversInstance === undefined) {\n          this.activeEntityVoiceoversInstance = new EntityVoiceovers(\n            this.contextService.getExplorationId(),\n            'exploration',\n            this.contextService.getExplorationVersion() as number,\n            this.languageAccentCode,\n            {}\n          );\n        }\n\n        this.activeEntityVoiceoversInstance.voiceoversMapping[\n          this.activeContentId\n        ] = {\n          manual: this.manualVoiceover,\n        };\n        this.entityVoiceoversService.addEntityVoiceovers(\n          this.languageAccentCode,\n          this.activeEntityVoiceoversInstance\n        );\n        this.updateStatusGraph();\n      },\n      () => {\n        this.alertsService.clearWarnings();\n      }\n    );\n  }\n\n  generateNewFilename(): string {\n    return (\n      this.activeContentId +\n      '-' +\n      this.languageAccentCode +\n      '-' +\n      this.idGenerationService.generateNewId() +\n      '.mp3'\n    );\n  }\n}\n"
    },
    {
      "filename": "core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.html",
      "content": "<div aria-label=\"audio menu\" class=\"audio-header\" *ngIf=\"isAudioBarAvailable()\"\n     [ngClass]=\"{'audio-header-margin': explorationPlayerModeIsActive}\" headroom>\n\n  <div *ngIf=\"audioBarIsExpanded\" class=\"audio-bar-expanded\" headroom>\n    <div #audioControls tabindex=\"0\" class=\"audio-controls\" [ngClass]=\"{'audio-controls-margin': progressBarIsShown}\">\n      <div class=\"oppia-audio-header-control-buttons fx-row fx-main-center fx-cross-center\">\n        <div class=\"audio-header-control-icons\">\n          <a (click)=\"onBackwardButtonClicked()\">\n            <span class=\"oppia-replay-white-circle\" *ngIf=\"progressBarIsShown\">\n              <i class=\"fas fa-undo audio-undo-icon\"></i>\n              <span class=\"oppia-five-icon\">5</span>\n            </span>\n          </a>\n          <a (click)=\"onPlayButtonClicked()\" (keydown.enter)=\"onPlayButtonClicked()\"\n             [ngbTooltip]=\"!isAudioAvailableInCurrentLanguage() ? ('I18N_PLAYER_AUDIO_NOT_AVAILABLE_IN' | translate:{languageDescription:getCurrentAudioLanguageDescription()}) : ''\"\n             placement=\"right\">\n            <i class=\"fas oppia-audio-controls-button-icon\" tabindex=\"0\" aria-label=\"Press enter to Listen to the Lesson\"\n               [ngClass]=\"{'fa-ellipsis-h': audioLoadingIndicatorIsShown, 'fa-play-circle e2e-test-play-circle': !isAudioPlaying(), 'fa-pause-circle e2e-test-pause-circle': isAudioPlaying(), 'audio-controls-audio-not-available': !isAudioAvailableInCurrentLanguage() || audioIsLoading}\">\n            </i>\n          </a>\n          <a (click)=\"onForwardButtonClicked()\">\n            <span class=\"oppia-replay-white-circle oppia-replay-white-circle-forward\" *ngIf=\"progressBarIsShown\">\n              <i class=\"fas fa-undo audio-undo-icon audio-undo-icon-forward\"></i>\n              <span class=\"oppia-five-icon oppia-five-icon-forward\">5</span>\n            </span>\n          </a>\n        </div>\n        <div class=\"slider-section\" *ngIf=\"progressBarIsShown\">\n          <div *ngIf=\"audioLoadingIndicatorIsShown\">\n            <mat-progress-bar mode=\"indeterminate\"></mat-progress-bar>\n          </div>\n          <div *ngIf=\"!audioLoadingIndicatorIsShown\">\n            <oppia-audio-slider [value]=\"this.currentVoiceoverTime\"\n                                [dir]=\"isLanguageRTL() ? 'rtl' : 'ltr'\"\n                                [max]=\"this.totalVoiceoverDurationSecs\"\n                                (valueChange)=\"setProgress($event)\"\n                                aria-label=\"audio-slider\">\n            </oppia-audio-slider>\n          </div>\n          <span *ngIf=\"audioLoadingIndicatorIsShown && !doesCurrentAudioTranslationNeedUpdate()\"\n                class=\"audio-controls-message\">\n            {{ 'I18N_PLAYER_AUDIO_LOADING_AUDIO' | translate }}\n          </span>\n          <span *ngIf=\"isAudioAvailableInCurrentLanguage() && doesCurrentAudioTranslationNeedUpdate()\"\n                class=\"audio-controls-message\">\n            {{ 'I18N_PLAYER_AUDIO_MIGHT_NOT_MATCH_TEXT' | translate }}\n          </span>\n          <!--Filler space for message-->\n          <span class=\"audio-controls-message\">&zwnj;</span>\n        </div>\n        <div class=\"oppia-audio-header-select\"\n             *ngIf=\"!isVoiceoverContributionWithAccentEnabled()\">\n          <select class=\"audio-language-select e2e-test-audio-lang-select\"\n                  [(ngModel)]=\"selectedLanguage.value\"\n                  (change)=\"onNewLanguageSelected()\">\n            <option *ngFor=\"let opt of languagesInExploration\" [value]=\"opt.value\">{{ opt.displayed }}</option>\n          </select>\n        </div>\n        <div class=\"oppia-audio-header-select\"\n             *ngIf=\"isVoiceoverContributionWithAccentEnabled() && languageAccentDecriptions.length > 0\">\n          <select class=\"audio-language-select e2e-test-audio-lang-select\"\n                  [(ngModel)]=\"selectedLanguageAccentDescription\"\n                  (change)=\"updateSelectedLanguageAccent()\">\n            <option *ngFor=\"let opt of languageAccentDecriptions\" [value]=\"opt\">{{ opt }}</option>\n          </select>\n        </div>\n      </div>\n    </div>\n    <div class=\"audio-collapse-button audio-toggle-button\"\n         *ngIf=\"audioBarIsExpanded\"\n         (click)=\"collapseAudioBar()\"\n         aria-label=\"Audio menu collapse\"\n         [ngClass]=\"{'audio-controls-margin': progressBarIsShown}\">\n      <i class=\"fas fa-sort-up\"></i>\n    </div>\n  </div>\n  <div class=\"audio-expand-button audio-toggle-button\"\n       *ngIf=\"!audioBarIsExpanded\"\n       (click)=\"expandAudioBar()\"\n       (keydown.enter)=\"expandAudioBar()\"\n       aria-label=\"Audio menu expand\">\n    <div class=\"container e2e-test-audio-bar\">\n      <div class=\"row\">\n        <div class=\"col-lg-6 px-0 mt-1 ml-2\">\n          <span class=\"audio-expand-button-text\">\n            {{ 'I18N_PLAYER_AUDIO_EXPAND_TEXT' | translate }}\n          </span>\n        </div>\n        <div class=\"col-lg-3 col-6 px-0 mt-lg-2\">\n          <i tabindex=\"0\" aria-label=\"headphone icon\" class=\"audio-expand-icon fas fa-headphones-alt\"></i>\n        </div>\n        <div class=\"col-lg-2 col-6 px-0 mt-lg-1\">\n          <i tabindex=\"0\" aria-label=\"Press Enter to expand the audio menu\" class=\"audio-expand-icon fas fa-sort-down\"></i>\n        </div>\n      </div>\n    </div>\n  </div>\n</div>\n\n<style>\n  .fa-play-circle:before {\n    font-size: 1.7em;\n  }\n\n  .fa-pause-circle:before {\n    font-size: 1.7em;\n  }\n\n  .mat-progress-bar {\n    height: 5px;\n  }\n\n  .mat-progress-bar .mat-progress-bar-fill {\n    background-color: #009688;\n  }\n\n  .mat-progress-bar-primary:after {\n    background-color: #009688;\n    border-color: #009688;\n  }\n\n  .audio-header .fa-sort-up, .audio-header .fa-sort-down {\n    transform: translateY(-2px);\n  }\n\n  .audio-expand-button {\n    height: 45px;\n    width: 150px;\n  }\n\n  @media screen and (max-width: 991px) {\n    .audio-expand-button {\n      height: 32px;\n      width: 90px;\n    }\n    .audio-expand-button-text {\n      display: none;\n    }\n  }\n\n  .audio-expand-icon {\n    font-size: 25px;\n  }\n\n  .audio-collapse-button {\n    height: 10px;\n    position: absolute;\n    top: 44px;\n    transition: top 200ms linear;\n    width: 30px;\n  }\n\n  .audio-toggle-button {\n    background-color: #0d48a1;\n    border-bottom-left-radius: 15px;\n    border-bottom-right-radius: 15px;\n    color: white;\n    display: block;\n    font-size: 12px;\n    margin: 0 auto;\n    position: sticky;\n    text-align: center;\n  }\n\n  .oppia-audio-controls-button-icon {\n    color: white;\n    font-size: 1.4em;\n    min-width: 6%;\n    text-align: right;\n    vertical-align: middle;\n  }\n  .oppia-audio-header-control-buttons {\n    display: flex;\n    flex-wrap: wrap;\n    justify-content: center;\n    width: 700px;\n  }\n  .oppia-replay-white-circle {\n    display: inline-block;\n    font-size: 1.4em;\n    height: 36px;\n    padding: 5px;\n    position: relative;\n    vertical-align: middle;\n    width: 36px;\n  }\n  .audio-undo-icon {\n    color: #fff;\n    left: 50%;\n    padding: 0;\n    position: absolute;\n    top: 7px;\n    transform: translateX(-43%);\n  }\n  .audio-undo-icon-forward {\n    transform: scaleX(-1) translateX(43%);\n  }\n  .oppia-audio-header-select {\n    transform: translateY(5px);\n  }\n  .oppia-five-icon {\n    bottom: 7px;\n    color: #fff;\n    font-size: 10px;\n    font-weight: 800;\n    left: 3px;\n    position: relative;\n  }\n  .oppia-five-icon-forward {\n    left: 0;\n  }\n  .audio-controls-button-image {\n    height: 21px;\n    width: 21px;\n  }\n\n  .audio-controls-audio-not-available {\n    color: gray;\n  }\n\n  .audio-controls {\n    align-items: center;\n    background-color: #0d48a1;\n    display: flex;\n    flex-direction: row;\n    flex-wrap: nowrap;\n    height: 70px;\n    justify-content: center;\n    padding: 0 4px;\n    transition: margin-top 200ms linear;\n    width: 100%;\n  }\n\n  .audio-controls.ng-enter,\n  .audio-controls.ng-leave {\n    position: absolute;\n    -webkit-transition: 300ms cubic-bezier(0.250, 0.250, 0.750, 0.750) all;\n    -moz-transition: 300ms cubic-bezier(0.250, 0.250, 0.750, 0.750) all;\n    -ms-transition: 300ms cubic-bezier(0.250, 0.250, 0.750, 0.750) all;\n    -o-transition: 300ms cubic-bezier(0.250, 0.250, 0.750, 0.750) all;\n    transition: 300ms cubic-bezier(0.250, 0.250, 0.750, 0.750) all;\n  }\n\n  .audio-controls.ng-enter {\n    top: -44px;\n  }\n\n  .audio-controls.ng-enter.audio-controls.ng-enter-active {\n    top: 0;\n  }\n\n  .audio-controls.ng-leave {\n    top: 0;\n  }\n\n  .audio-controls.ng-leave.audio-controls.ng-leave-active {\n    top: -44px;\n  }\n\n  .audio-controls-message {\n    color: white;\n    font-size: 10px;\n    font-style: italic;\n    vertical-align: 29px;\n  }\n\n  .audio-header {\n    left: 0;\n    position: fixed;\n    text-align: center;\n    top: 126px;\n    width: 100%;\n    z-index: 100;\n  }\n\n  .audio-header-margin {\n    top: 3.5em;\n  }\n\n  @media(max-width: 768px) {\n    .audio-header {\n      top: 3.5em;\n      transition: top 200ms linear;\n    }\n\n    .audio-header.headroom--unpinned {\n      top: 0;\n    }\n  }\n  .audio-language-select {\n    border-radius: 9px;\n    font-size: 15px;\n    margin-bottom: 15px;\n    margin-left: 5px;\n    padding-left: 2px;\n    padding-top: 2px;\n  }\n\n  .slider-section {\n    line-height: 0px;\n    transform: translateY(10px);\n  }\n\n  .audio-bar-nav-up {\n    margin-top: -186px;\n  }\n\n  .audio-bar-nav-hidden {\n    margin-top: -270px;\n  }\n\n  @media screen and (max-width: 370px) {\n    .oppia-audio-header-control-buttons {\n      justify-content: space-evenly;\n    }\n    .oppia-replay-white-circle {\n      padding: 5px;\n      width: 26px;\n    }\n    .oppia-audio-header-select select {\n      width: 100%;\n    }\n    .audio-header-control-icons {\n      order: 2;\n    }\n    .slider-section {\n      order: 1;\n      width: 90%;\n    }\n    .oppia-audio-header-select {\n      order: 3;\n      width: 50%;\n    }\n    .audio-collapse-button {\n      top: 80px;\n    }\n    .audio-controls {\n      height: 80px;\n    }\n  }\n\n  @media screen and (max-width: 550px) {\n    .audio-controls {\n      height: auto;\n      margin-top: -1px;\n      padding: 20px 0;\n      padding-right: 20px;\n    }\n    .slider-section {\n      transform: translateY(4px);\n    }\n    .audio-collapse-button {\n      top: 98px;\n    }\n    .audio-header-control-icons {\n      display: flex;\n      flex-wrap: wrap;\n      justify-content: space-between;\n    }\n    .oppia-audio-controls-button-icon {\n      font-size: 1.1em;\n      margin: 0 20px;\n      position: relative;\n      top: 4px;\n    }\n  }\n</style>\n"
    },
    {
      "filename": "core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.spec.ts",
      "content": "// Copyright 2021 The Oppia Authors. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the 'License');\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an 'AS-IS' BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Unit tests for the AudioBarComponent.\n */\n\nimport {EventEmitter, NO_ERRORS_SCHEMA} from '@angular/core';\nimport {HttpClientTestingModule} from '@angular/common/http/testing';\nimport {\n  ComponentFixture,\n  discardPeriodicTasks,\n  fakeAsync,\n  flush,\n  TestBed,\n  tick,\n  waitForAsync,\n} from '@angular/core/testing';\nimport {MockTranslatePipe} from 'tests/unit-test-utils';\n\nimport {AudioBarComponent} from 'pages/exploration-player-page/layout-directives/audio-bar.component';\nimport {Voiceover} from 'domain/exploration/voiceover.model';\nimport {AssetsBackendApiService} from 'services/assets-backend-api.service';\nimport {AudioBarStatusService} from 'services/audio-bar-status.service';\nimport {AudioPlayerService} from 'services/audio-player.service';\nimport {AutogeneratedAudioPlayerService} from 'services/autogenerated-audio-player.service';\nimport {AudioPreloaderService} from '../services/audio-preloader.service';\nimport {AudioTranslationLanguageService} from '../services/audio-translation-language.service';\nimport {AudioTranslationManagerService} from '../services/audio-translation-manager.service';\nimport {PlayerPositionService} from '../services/player-position.service';\nimport {ContextService} from 'services/context.service';\nimport {I18nLanguageCodeService} from 'services/i18n-language-code.service';\nimport {PlatformFeatureService} from 'services/platform-feature.service';\nimport {VoiceoverPlayerService} from '../services/voiceover-player.service';\nimport {EntityVoiceoversService} from 'services/entity-voiceovers.services';\nimport {EntityVoiceovers} from 'domain/voiceover/entity-voiceovers.model';\nimport {VoiceoverBackendDict} from 'domain/exploration/voiceover.model';\n\nclass MockPlatformFeatureService {\n  get status(): object {\n    return {\n      EnableVoiceoverContribution: {\n        isEnabled: false,\n      },\n      AddVoiceoverWithAccent: {\n        isEnabled: false,\n      },\n    };\n  }\n}\n\ndescribe('Audio Bar Component', () => {\n  let component: AudioBarComponent;\n  let fixture: ComponentFixture<AudioBarComponent>;\n\n  let assetsBackendApiService: AssetsBackendApiService;\n  let audioBarStatusService: AudioBarStatusService;\n  let audioPlayerService: AudioPlayerService;\n  let audioPreloaderService: AudioPreloaderService;\n  let audioTranslationLanguageService: AudioTranslationLanguageService;\n  let audioTranslationManagerService: AudioTranslationManagerService;\n  let autogeneratedAudioPlayerService: AutogeneratedAudioPlayerService;\n  let playerPositionService: PlayerPositionService;\n  let contextService: ContextService;\n  let i18nLanguageCodeService: I18nLanguageCodeService;\n  let voiceoverPlayerService: VoiceoverPlayerService;\n  let entityVoiceoversService: EntityVoiceoversService;\n\n  beforeEach(waitForAsync(() => {\n    TestBed.configureTestingModule({\n      imports: [HttpClientTestingModule],\n      declarations: [AudioBarComponent, MockTranslatePipe],\n      providers: [\n        {\n          provide: PlatformFeatureService,\n          useClass: MockPlatformFeatureService,\n        },\n      ],\n      schemas: [NO_ERRORS_SCHEMA],\n    }).compileComponents();\n  }));\n\n  beforeEach(() => {\n    fixture = TestBed.createComponent(AudioBarComponent);\n    component = fixture.componentInstance;\n    audioPlayerService = TestBed.inject(AudioPlayerService);\n    audioBarStatusService = TestBed.inject(AudioBarStatusService);\n    audioTranslationLanguageService = TestBed.inject(\n      AudioTranslationLanguageService\n    );\n    audioPreloaderService = TestBed.inject(AudioPreloaderService);\n    assetsBackendApiService = TestBed.inject(AssetsBackendApiService);\n    audioTranslationManagerService = TestBed.inject(\n      AudioTranslationManagerService\n    );\n    autogeneratedAudioPlayerService = TestBed.inject(\n      AutogeneratedAudioPlayerService\n    );\n    playerPositionService = TestBed.inject(PlayerPositionService);\n    contextService = TestBed.inject(ContextService);\n    i18nLanguageCodeService = TestBed.inject(I18nLanguageCodeService);\n    voiceoverPlayerService = TestBed.inject(VoiceoverPlayerService);\n    entityVoiceoversService = TestBed.inject(EntityVoiceoversService);\n    fixture.detectChanges();\n\n    spyOn(voiceoverPlayerService, 'onActiveVoiceoverChanged').and.returnValue(\n      new EventEmitter<void>()\n    );\n    spyOn(\n      voiceoverPlayerService,\n      'onTranslationLanguageChanged'\n    ).and.returnValue(new EventEmitter<void>());\n  });\n  beforeEach(() => {\n    spyOn(audioBarStatusService, 'markAudioBarExpanded').and.callThrough();\n    spyOn(audioBarStatusService, 'markAudioBarCollapsed').and.callThrough();\n    spyOn(contextService, 'getExplorationId').and.returnValue('exp1');\n  });\n\n  afterEach(() => {\n    component.ngOnDestroy();\n  });\n\n  it(\n    'should set secondary audio translations when audio bar ' +\n      'is opened and audio is playing',\n    fakeAsync(() => {\n      let params = {\n        audioTranslations: {},\n        componentName: 'feedback',\n        html: '',\n      };\n      let mockOnAutoplayAudioEventEmitter = new EventEmitter();\n      spyOnProperty(audioPlayerService, 'onAutoplayAudio').and.returnValue(\n        mockOnAutoplayAudioEventEmitter\n      );\n      let secondaryTranslaionsSpy = spyOn(\n        audioTranslationManagerService,\n        'setSecondaryAudioTranslations'\n      ).and.callThrough();\n\n      component.ngOnInit();\n      component.expandAudioBar();\n      component.isPaused = false;\n      fixture.detectChanges();\n\n      mockOnAutoplayAudioEventEmitter.emit(params);\n      voiceoverPlayerService.onActiveVoiceoverChanged.emit();\n      voiceoverPlayerService.onTranslationLanguageChanged.emit();\n\n      flush();\n      discardPeriodicTasks();\n      fixture.detectChanges();\n\n      expect(secondaryTranslaionsSpy).toHaveBeenCalledWith(\n        params.audioTranslations,\n        params.html,\n        params.componentName\n      );\n    })\n  );\n\n  it(\"should set current time when calling 'setProgress'\", () => {\n    // This time period is used to set progress\n    // when user pulls the drag button in audio bar.\n    let param = {\n      value: 100,\n    };\n    let currentTimeSpy = spyOn(\n      audioPlayerService,\n      'setCurrentTime'\n    ).and.callThrough();\n\n    component.setProgress(param);\n\n    expect(currentTimeSpy).toHaveBeenCalledWith(100);\n  });\n\n  it('should set current voiceover time after the view has changed', () => {\n    spyOn(audioPlayerService, 'isTrackLoaded').and.returnValue(true);\n    spyOn(audioPlayerService, 'isPlaying').and.returnValue(true);\n    spyOn(audioPlayerService, 'getCurrentTimeInSecs').and.returnValue(5);\n\n    component.currentVoiceoverTime = 0;\n    component.ngAfterContentChecked();\n\n    expect(component.currentVoiceoverTime).toEqual(5);\n  });\n  it(\n    'should check whether the auto generated language ' + 'code is selected',\n    () => {\n      let autoGeneratedLanguageSpy = spyOn(\n        audioTranslationLanguageService,\n        'isAutogeneratedLanguageCodeSelected'\n      ).and.returnValue(false);\n      let result = component.isAutogeneratedLanguageCodeSelected();\n\n      expect(result).toBe(false);\n      expect(autoGeneratedLanguageSpy).toHaveBeenCalled();\n    }\n  );\n\n  it('should check if the audio bar is available', () => {\n    // Audio bar is only accessible if the number of\n    // available languages are greater than one.\n    component.languagesInExploration = [\n      {\n        value: 'en',\n        displayed: 'english',\n      },\n      {\n        value: 'es',\n        displayed: 'spanish',\n      },\n    ];\n\n    let result = component.isAudioBarAvailable();\n    expect(result).toBe(true);\n\n    component.languagesInExploration = [];\n    result = component.isAudioBarAvailable();\n    expect(result).toBe(false);\n  });\n\n  it('should call focusOnAudioControls when expanding the audio bar', () => {\n    spyOn(component, 'focusOnAudioControls');\n    component.expandAudioBar();\n    expect(component.focusOnAudioControls).toHaveBeenCalled();\n  });\n\n  it('should focus on audio controls element when focusOnAudioControls is called', () => {\n    const mockElementRef = {\n      nativeElement: {\n        focus: jasmine.createSpy('focus'),\n      },\n    };\n    component.audioControlsRef = mockElementRef as ElementRef;\n\n    component.focusOnAudioControls();\n\n    expect(mockElementRef.nativeElement.focus).toHaveBeenCalled();\n  });\n\n  it('should check if the audio bar is available with enabled accent', () => {\n    component.languageAccentDecriptions = ['English (India)', 'English (US)'];\n    spyOn(\n      component,\n      'isVoiceoverContributionWithAccentEnabled'\n    ).and.returnValue(true);\n\n    let result = component.isAudioBarAvailable();\n    expect(result).toBe(true);\n\n    component.languageAccentDecriptions = [];\n    result = component.isAudioBarAvailable();\n    expect(result).toBe(false);\n  });\n\n  it('should return true if the selected language is RTL', () => {\n    spyOn(i18nLanguageCodeService, 'isCurrentLanguageRTL').and.returnValue(\n      true\n    );\n\n    expect(component.isLanguageRTL()).toBe(true);\n  });\n\n  it('should return false if the selected language is not RTL', () => {\n    spyOn(i18nLanguageCodeService, 'isCurrentLanguageRTL').and.returnValue(\n      false\n    );\n\n    expect(component.isLanguageRTL()).toBe(false);\n  });\n\n  it(\n    'should forward audio with time interval of five seconds ' +\n      'when audio forward button is clicked',\n    () => {\n      let forwardSpy = spyOn(audioPlayerService, 'forward').and.callThrough();\n\n      component.onForwardButtonClicked();\n\n      expect(forwardSpy).toHaveBeenCalledWith(5);\n    }\n  );\n\n  it(\n    'should rewind audio with time interval of five seconds ' +\n      'when audio rewind button is clicked',\n    () => {\n      let rewindSpy = spyOn(audioPlayerService, 'rewind').and.callThrough();\n\n      component.onBackwardButtonClicked();\n\n      expect(rewindSpy).toHaveBeenCalledWith(5);\n    }\n  );\n\n  it('should expand audio bar when clicking expand button', () => {\n    // Setting audio bar in collapsed view.\n    component.audioBarIsExpanded = false;\n    component.expandAudioBar();\n    expect(component.audioBarIsExpanded).toBe(true);\n  });\n\n  it('should collapse audio bar when clicking expand button', () => {\n    // Setting audio bar in expanded view.\n    component.audioBarIsExpanded = true;\n    component.collapseAudioBar();\n    expect(component.audioBarIsExpanded).toBe(false);\n  });\n\n  it('should return selected audio language code', () => {\n    spyOn(\n      audioTranslationLanguageService,\n      'getCurrentAudioLanguageCode'\n    ).and.returnValue('en');\n    let result = component.getCurrentAudioLanguageCode();\n    expect(result).toBe('en');\n  });\n\n  it('should return selected audio language description', () => {\n    spyOn(\n      audioTranslationLanguageService,\n      'getCurrentAudioLanguageDescription'\n    ).and.returnValue('description');\n    let result = component.getCurrentAudioLanguageDescription();\n    expect(result).toBe('description');\n  });\n\n  it('should return voiceovers in selected language', () => {\n    let audioTranslation = {\n      en: Voiceover.createFromBackendDict({\n        filename: 'audio-en.mp3',\n        file_size_bytes: 0.5,\n        needs_update: false,\n        duration_secs: 0.5,\n      }),\n      es: Voiceover.createFromBackendDict({\n        filename: 'audio-es.mp3',\n        file_size_bytes: 0.5,\n        needs_update: false,\n        duration_secs: 0.5,\n      }),\n    };\n    spyOn(\n      audioTranslationManagerService,\n      'getCurrentAudioTranslations'\n    ).and.returnValue(audioTranslation);\n    // Setting selected language to be 'en'.\n    spyOn(\n      audioTranslationLanguageService,\n      'getCurrentAudioLanguageCode'\n    ).and.returnValue('en');\n\n    let result = component.getVoiceoverInCurrentLanguage();\n    expect(result).toBe(audioTranslation.en);\n  });\n\n  it('should check whether the audio is playing currently', () => {\n    let isPlayingSpy = spyOn(audioPlayerService, 'isPlaying').and.returnValue(\n      false\n    );\n    let result = component.isAudioPlaying();\n\n    expect(result).toBe(false);\n    expect(isPlayingSpy).toHaveBeenCalled();\n  });\n\n  it(\n    'should check whether the audio is selected by ' +\n      'auto generated language code',\n    () => {\n      let autogeneratedLanguageSpy = spyOn(\n        audioTranslationLanguageService,\n        'isAutogeneratedLanguageCodeSelected'\n      ).and.returnValue(false);\n      let result = component.isAutogeneratedLanguageCodeSelected();\n\n      expect(result).toBe(false);\n      expect(autogeneratedLanguageSpy).toHaveBeenCalled();\n    }\n  );\n\n  it('should check if the audio is available in selected language', () => {\n    let audioTranslation = {\n      en: Voiceover.createFromBackendDict({\n        filename: 'audio-en.mp3',\n        file_size_bytes: 0.5,\n        needs_update: false,\n        duration_secs: 0.5,\n      }),\n      es: Voiceover.createFromBackendDict({\n        filename: 'audio-es.mp3',\n        file_size_bytes: 0.5,\n        needs_update: false,\n        duration_secs: 0.5,\n      }),\n    };\n    spyOn(\n      audioTranslationManagerService,\n      'getCurrentAudioTranslations'\n    ).and.returnValue(audioTranslation);\n    // Setting selected language to be 'en'.\n    spyOn(\n      audioTranslationLanguageService,\n      'getCurrentAudioLanguageCode'\n    ).and.returnValue('en');\n\n    let result = component.isAudioAvailableInCurrentLanguage();\n    expect(result).toBe(true);\n  });\n\n  it('should check if the audio is available in selected language with accent feature flag enabled', () => {\n    component.voiceoverToBePlayed = undefined;\n\n    spyOn(\n      component,\n      'isVoiceoverContributionWithAccentEnabled'\n    ).and.returnValue(true);\n\n    let result = component.isAudioAvailableInCurrentLanguage();\n    expect(result).toBe(false);\n\n    component.voiceoverToBePlayed = Voiceover.createFromBackendDict({\n      filename: 'audio-en.mp3',\n      file_size_bytes: 0.5,\n      needs_update: true,\n      duration_secs: 0.5,\n    });\n\n    result = component.isAudioAvailableInCurrentLanguage();\n    expect(result).toBe(true);\n  });\n\n  it(\n    'should return true if the selected audio translation ' +\n      'needs to be updated which is not auto generated language code',\n    () => {\n      let audioTranslation = {\n        en: Voiceover.createFromBackendDict({\n          filename: 'audio-en.mp3',\n          file_size_bytes: 0.5,\n          needs_update: true,\n          duration_secs: 0.5,\n        }),\n        es: Voiceover.createFromBackendDict({\n          filename: 'audio-es.mp3',\n          file_size_bytes: 0.5,\n          needs_update: true,\n          duration_secs: 0.5,\n        }),\n      };\n      spyOn(\n        audioTranslationManagerService,\n        'getCurrentAudioTranslations'\n      ).and.returnValue(audioTranslation);\n      // Setting selected language to be 'en'.\n      spyOn(\n        audioTranslationLanguageService,\n        'getCurrentAudioLanguageCode'\n      ).and.returnValue('en');\n\n      let result = component.doesCurrentAudioTranslationNeedUpdate();\n\n      expect(result).toBe(true);\n    }\n  );\n\n  it(\n    'should not check whether the auto generated audio ' +\n      'language code is upto to date',\n    () => {\n      spyOn(\n        audioTranslationLanguageService,\n        'isAutogeneratedLanguageCodeSelected'\n      ).and.returnValue(true);\n\n      let result = component.doesCurrentAudioTranslationNeedUpdate();\n\n      expect(result).toBe(false);\n    }\n  );\n\n  describe('on clicking play pause button ', () => {\n    it(\n      'should play auto generated audio translation when ' +\n        'play button is clicked',\n      () => {\n        // Setting auto generated langugae to be true.\n        spyOn(\n          audioTranslationLanguageService,\n          'isAutogeneratedLanguageCodeSelected'\n        ).and.returnValue(true);\n        // Setting audio is playing to be false.\n        spyOn(autogeneratedAudioPlayerService, 'isPlaying').and.returnValue(\n          false\n        );\n        spyOn(\n          audioTranslationLanguageService,\n          'getSpeechSynthesisLanguageCode'\n        ).and.returnValue('');\n        spyOn(\n          audioTranslationManagerService,\n          'getCurrentHtmlForAutogeneratedSequentialAudio'\n        ).and.returnValue('<p>test</p>');\n        let playSpy = spyOn(\n          autogeneratedAudioPlayerService,\n          'play'\n        ).and.callFake((html, language, cb) => {\n          cb();\n        });\n\n        component.onPlayButtonClicked();\n        expect(playSpy).toHaveBeenCalled();\n      }\n    );\n\n    it(\n      'should throw error if speech synthesis language code ' + 'is null',\n      () => {\n        // Setting auto generated langugae to be true.\n        spyOn(\n          audioTranslationLanguageService,\n          'isAutogeneratedLanguageCodeSelected'\n        ).and.returnValue(true);\n        // Setting audio is playing to be false.\n        spyOn(autogeneratedAudioPlayerService, 'isPlaying').and.returnValue(\n          false\n        );\n        spyOn(\n          audioTranslationLanguageService,\n          'getSpeechSynthesisLanguageCode'\n        ).and.returnValue(null);\n        spyOn(autogeneratedAudioPlayerService, 'play').and.callFake(\n          (html, language, cb) => {\n            cb();\n          }\n        );\n\n        expect(() => {\n          component.onPlayButtonClicked();\n        }).toThrowError(\n          'speechSynthesisLanguageCode cannot be null at this point.'\n        );\n      }\n    );\n\n    it(\n      'should pause auto generated audio translation when ' +\n        'pause button is clicked',\n      () => {\n        // Setting auto generated langugae to be true.\n        spyOn(\n          audioTranslationLanguageService,\n          'isAutogeneratedLanguageCodeSelected'\n        ).and.returnValue(true);\n        // Setting audio is playing to be true.\n        spyOn(autogeneratedAudioPlayerService, 'isPlaying').and.returnValue(\n          true\n        );\n        let pauseSpy = spyOn(\n          autogeneratedAudioPlayerService,\n          'cancel'\n        ).and.callThrough();\n\n        component.onPlayButtonClicked();\n        expect(pauseSpy).toHaveBeenCalled();\n      }\n    );\n\n    it(\n      'should play uploaded audio translation when ' +\n        'play button is clicked and when tracks are loaded',\n      () => {\n        let audioTranslation = {\n          en: Voiceover.createFromBackendDict({\n            filename: 'audio-en.mp3',\n            file_size_bytes: 0.5,\n            needs_update: false,\n            duration_secs: 0.5,\n          }),\n          es: Voiceover.createFromBackendDict({\n            filename: 'audio-es.mp3',\n            file_size_bytes: 0.5,\n            needs_update: false,\n            duration_secs: 0.5,\n          }),\n        };\n        spyOn(\n          audioTranslationManagerService,\n          'getCurrentAudioTranslations'\n        ).and.returnValue(audioTranslation);\n        // Setting selected language to be 'en'.\n        spyOn(\n          audioTranslationLanguageService,\n          'getCurrentAudioLanguageCode'\n        ).and.returnValue('en');\n        // Setting auto generated langugae to be false.\n        spyOn(\n          audioTranslationLanguageService,\n          'isAutogeneratedLanguageCodeSelected'\n        ).and.returnValue(false);\n        // Setting audio is playing to be true.\n        spyOn(audioPlayerService, 'isPlaying').and.returnValue(false);\n        // Settings audio tracks loaded to be true.\n        spyOn(audioPlayerService, 'isTrackLoaded').and.returnValue(true);\n        let playSpy = spyOn(audioPlayerService, 'play').and.callThrough();\n\n        component.onPlayButtonClicked();\n        expect(playSpy).toHaveBeenCalled();\n      }\n    );\n\n    it(\n      'should load audio track and play audio when ' + 'play button is clicked',\n      () => {\n        let audioTranslation = {\n          en: Voiceover.createFromBackendDict({\n            filename: 'audio-en.mp3',\n            file_size_bytes: 0.5,\n            needs_update: false,\n            duration_secs: 0.5,\n          }),\n          es: Voiceover.createFromBackendDict({\n            filename: 'audio-es.mp3',\n            file_size_bytes: 0.5,\n            needs_update: false,\n            duration_secs: 0.5,\n          }),\n        };\n        spyOn(\n          audioTranslationManagerService,\n          'getCurrentAudioTranslations'\n        ).and.returnValue(audioTranslation);\n        // Setting selected language to be 'en'.\n        spyOn(\n          audioTranslationLanguageService,\n          'getCurrentAudioLanguageCode'\n        ).and.returnValue('en');\n        // Setting auto generated langugae to be false.\n        spyOn(\n          audioTranslationLanguageService,\n          'isAutogeneratedLanguageCodeSelected'\n        ).and.returnValue(false);\n        // Setting audio is playing to be true.\n        spyOn(audioPlayerService, 'isPlaying').and.returnValue(false);\n        // Settings audio tracks loaded to be false.\n        spyOn(audioPlayerService, 'isTrackLoaded').and.returnValue(false);\n        let loadAndPlaySpy = spyOn(\n          component,\n          'loadAndPlayAudioTranslation'\n        ).and.returnValue();\n        spyOn(playerPositionService, 'getCurrentStateName').and.returnValue(\n          'Start'\n        );\n        spyOn(audioPreloaderService, 'restartAudioPreloader').and.returnValue();\n\n        component.onPlayButtonClicked();\n        expect(loadAndPlaySpy).toHaveBeenCalled();\n      }\n    );\n\n    it('should load audio track and play audio when play button is clicked', () => {\n      let audioTranslation = {\n        en: Voiceover.createFromBackendDict({\n          filename: 'audio-en.mp3',\n          file_size_bytes: 0.5,\n          needs_update: false,\n          duration_secs: 0.5,\n        }),\n        es: Voiceover.createFromBackendDict({\n          filename: 'audio-es.mp3',\n          file_size_bytes: 0.5,\n          needs_update: false,\n          duration_secs: 0.5,\n        }),\n      };\n      spyOn(\n        component,\n        'isVoiceoverContributionWithAccentEnabled'\n      ).and.returnValue(true);\n\n      component.voiceoverToBePlayed = Voiceover.createFromBackendDict({\n        filename: 'audio-en.mp3',\n        file_size_bytes: 0.5,\n        needs_update: true,\n        duration_secs: 0.5,\n      });\n\n      spyOn(\n        audioTranslationManagerService,\n        'getCurrentAudioTranslations'\n      ).and.returnValue(audioTranslation);\n      // Setting selected language to be 'en'.\n      spyOn(\n        audioTranslationLanguageService,\n        'getCurrentAudioLanguageCode'\n      ).and.returnValue('en');\n      // Setting auto generated langugae to be false.\n      spyOn(\n        audioTranslationLanguageService,\n        'isAutogeneratedLanguageCodeSelected'\n      ).and.returnValue(false);\n      // Setting audio is playing to be true.\n      spyOn(audioPlayerService, 'isPlaying').and.returnValue(false);\n      // Settings audio tracks loaded to be false.\n      spyOn(audioPlayerService, 'isTrackLoaded').and.returnValue(false);\n      let loadAndPlaySpy = spyOn(\n        component,\n        'loadAndPlayAudioTranslation'\n      ).and.returnValue();\n      spyOn(playerPositionService, 'getCurrentStateName').and.returnValue(\n        'Start'\n      );\n      spyOn(audioPreloaderService, 'restartAudioPreloader').and.returnValue();\n\n      component.onPlayButtonClicked();\n      expect(loadAndPlaySpy).toHaveBeenCalled();\n    });\n\n    it('should be able update diplayable language accent code', () => {\n      let manualVoiceoverBackendDict: VoiceoverBackendDict = {\n        filename: 'a.mp3',\n        file_size_bytes: 200000,\n        needs_update: false,\n        duration_secs: 10.0,\n      };\n      let contentIdToVoiceoversMappingBackendDict = {\n        content0: {\n          manual: manualVoiceoverBackendDict,\n        },\n      };\n      let entityId = 'exploration_1';\n      let entityType = 'exploration';\n      let entityVersion = 1;\n      let languageAccentCode = 'en-US';\n      let entityVoiceoversBackendDict = {\n        entity_id: entityId,\n        entity_type: entityType,\n        entity_version: entityVersion,\n        language_accent_code: languageAccentCode,\n        voiceovers_mapping: contentIdToVoiceoversMappingBackendDict,\n      };\n      let entityVoiceovers = EntityVoiceovers.createFromBackendDict(\n        entityVoiceoversBackendDict\n      );\n      let languageAccentDecriptions = ['en-US', 'en-IN'];\n\n      spyOn(\n        voiceoverPlayerService,\n        'getLanguageAccentDescriptions'\n      ).and.returnValue(languageAccentDecriptions);\n      spyOn(\n        entityVoiceoversService,\n        'getActiveEntityVoiceovers'\n      ).and.returnValue(entityVoiceovers);\n      spyOn(playerPositionService, 'getCurrentStateName');\n      voiceoverPlayerService.activeContentId = 'content0';\n\n      component.voiceoverToBePlayed = undefined;\n      component.updateDisplayableLanguageAccentDescription();\n\n      expect(component.voiceoverToBePlayed.filename).toEqual('a.mp3');\n    });\n\n    it(\n      'should pause uploaded audio translation when ' +\n        'pause button is clicked',\n      () => {\n        let audioTranslation = {\n          en: Voiceover.createFromBackendDict({\n            filename: 'audio-en.mp3',\n            file_size_bytes: 0.5,\n            needs_update: false,\n            duration_secs: 0.5,\n          }),\n          es: Voiceover.createFromBackendDict({\n            filename: 'audio-es.mp3',\n            file_size_bytes: 0.5,\n            needs_update: false,\n            duration_secs: 0.5,\n          }),\n        };\n        spyOn(\n          audioTranslationManagerService,\n          'getCurrentAudioTranslations'\n        ).and.returnValue(audioTranslation);\n        // Setting selected language to be 'en'.\n        spyOn(\n          audioTranslationLanguageService,\n          'getCurrentAudioLanguageCode'\n        ).and.returnValue('en');\n        // Setting auto generated langugae to be false.\n        spyOn(\n          audioTranslationLanguageService,\n          'isAutogeneratedLanguageCodeSelected'\n        ).and.returnValue(false);\n        // Setting audio is playing to be true.\n        spyOn(audioPlayerService, 'isPlaying').and.returnValue(true);\n        let pauseSpy = spyOn(audioPlayerService, 'pause').and.callThrough();\n\n        component.onPlayButtonClicked();\n        expect(pauseSpy).toHaveBeenCalled();\n      }\n    );\n\n    it(\n      'should load audio track and play audio ' + 'which are stored in cache',\n      fakeAsync(() => {\n        let audioTranslation = {\n          en: Voiceover.createFromBackendDict({\n            filename: 'audio-en.mp3',\n            file_size_bytes: 0.5,\n            needs_update: false,\n            duration_secs: 0.5,\n          }),\n          es: Voiceover.createFromBackendDict({\n            filename: 'audio-es.mp3',\n            file_size_bytes: 0.5,\n            needs_update: false,\n            duration_secs: 0.5,\n          }),\n        };\n        spyOn(\n          audioTranslationManagerService,\n          'getCurrentAudioTranslations'\n        ).and.returnValue(audioTranslation);\n        // Setting selected language to be 'en'.\n        spyOn(\n          audioTranslationLanguageService,\n          'getCurrentAudioLanguageCode'\n        ).and.returnValue('en');\n        spyOn(\n          audioPreloaderService,\n          'setMostRecentlyRequestedAudioFilename'\n        ).and.callThrough();\n        // Setting cached value to be true.\n        spyOn(assetsBackendApiService, 'isCached').and.returnValue(true);\n        spyOn(audioPlayerService, 'loadAsync').and.returnValue(\n          Promise.resolve()\n        );\n        let playCacheAudioSpy = spyOn(\n          component,\n          'playCachedAudioTranslation'\n        ).and.callThrough();\n        let playSpy = spyOn(audioPlayerService, 'play').and.callThrough();\n\n        component.loadAndPlayAudioTranslation();\n        tick();\n        discardPeriodicTasks();\n\n        expect(playCacheAudioSpy).toHaveBeenCalled();\n        expect(playSpy).toHaveBeenCalled();\n      })\n    );\n\n    it('should load audio track and play audio with accent', fakeAsync(() => {\n      component.voiceoverToBePlayed = Voiceover.createFromBackendDict({\n        filename: 'audio-en.mp3',\n        file_size_bytes: 0.5,\n        needs_update: false,\n        duration_secs: 0.5,\n      });\n      spyOn(component, 'getVoiceoverInCurrentLanguage');\n      spyOn(\n        component,\n        'isVoiceoverContributionWithAccentEnabled'\n      ).and.returnValue(true);\n      spyOn(audioTranslationManagerService, 'getCurrentAudioTranslations');\n      // Setting selected language to be 'en'.\n      spyOn(audioTranslationLanguageService, 'getCurrentAudioLanguageCode');\n      spyOn(\n        audioPreloaderService,\n        'setMostRecentlyRequestedAudioFilename'\n      ).and.callThrough();\n      // Setting cached value to be true.\n      spyOn(assetsBackendApiService, 'isCached').and.returnValue(true);\n      spyOn(audioPlayerService, 'loadAsync').and.returnValue(Promise.resolve());\n      let playCacheAudioSpy = spyOn(\n        component,\n        'playCachedAudioTranslation'\n      ).and.callThrough();\n      let playSpy = spyOn(audioPlayerService, 'play').and.callThrough();\n\n      component.loadAndPlayAudioTranslation();\n      tick();\n      discardPeriodicTasks();\n\n      expect(playCacheAudioSpy).toHaveBeenCalled();\n      expect(playSpy).toHaveBeenCalled();\n    }));\n\n    it(\n      'should restart audio track if audio is not' + 'stored in cache',\n      fakeAsync(() => {\n        let audioTranslation = {\n          en: Voiceover.createFromBackendDict({\n            filename: 'audio-en.mp3',\n            file_size_bytes: 0.5,\n            needs_update: false,\n            duration_secs: 0.5,\n          }),\n          es: Voiceover.createFromBackendDict({\n            filename: 'audio-es.mp3',\n            file_size_bytes: 0.5,\n            needs_update: false,\n            duration_secs: 0.5,\n          }),\n        };\n        spyOn(\n          audioTranslationManagerService,\n          'getCurrentAudioTranslations'\n        ).and.returnValue(audioTranslation);\n        // Setting selected language to be 'en'.\n        spyOn(\n          audioTranslationLanguageService,\n          'getCurrentAudioLanguageCode'\n        ).and.returnValue('en');\n        spyOn(\n          audioPreloaderService,\n          'setMostRecentlyRequestedAudioFilename'\n        ).and.callThrough();\n        // Setting cached value to be true.\n        spyOn(assetsBackendApiService, 'isCached').and.returnValue(false);\n        spyOn(playerPositionService, 'getCurrentStateName').and.returnValue(\n          'Start'\n        );\n        let restartAudioSpy = spyOn(\n          audioPreloaderService,\n          'restartAudioPreloader'\n        ).and.returnValue();\n\n        component.loadAndPlayAudioTranslation();\n        tick();\n\n        expect(restartAudioSpy).toHaveBeenCalled();\n      })\n    );\n  });\n\n  it('should play audio from cache after finishing loading', () => {\n    spyOn(\n      audioPreloaderService,\n      'getMostRecentlyRequestedAudioFilename'\n    ).and.returnValue('audio-en.mp3');\n    component.audioLoadingIndicatorIsShown = true;\n    let playCacheAudioSpy = spyOn(component, 'playCachedAudioTranslation');\n\n    component.onFinishedLoadingAudio('audio-en.mp3');\n    expect(playCacheAudioSpy).toHaveBeenCalled();\n  });\n\n  it('should restart audio bar after selecting a new language', () => {\n    component.languagesInExploration = [\n      {\n        value: 'en',\n        displayed: 'english',\n      },\n      {\n        value: 'es',\n        displayed: 'spanish',\n      },\n    ];\n    component.selectedLanguage.value = 'en';\n    let audioTranslation = {\n      en: Voiceover.createFromBackendDict({\n        filename: 'audio-en.mp3',\n        file_size_bytes: 0.5,\n        needs_update: false,\n        duration_secs: 0.5,\n      }),\n      es: Voiceover.createFromBackendDict({\n        filename: 'audio-es.mp3',\n        file_size_bytes: 0.5,\n        needs_update: false,\n        duration_secs: 0.5,\n      }),\n    };\n\n    spyOn(playerPositionService, 'getCurrentStateName').and.returnValue(\n      'Start'\n    );\n    spyOn(\n      audioTranslationLanguageService,\n      'isAutogeneratedLanguageCodeSelected'\n    ).and.returnValue(false);\n    spyOn(\n      audioTranslationLanguageService,\n      'setCurrentAudioLanguageCode'\n    ).and.callThrough();\n    spyOn(\n      audioTranslationManagerService,\n      'getCurrentAudioTranslations'\n    ).and.returnValue(audioTranslation);\n    // Setting selected language to be 'en'.\n    spyOn(\n      audioTranslationLanguageService,\n      'getCurrentAudioLanguageCode'\n    ).and.returnValue('en');\n    let languageSetSpy = spyOn(\n      audioPreloaderService,\n      'setMostRecentlyRequestedAudioFilename'\n    ).and.callThrough();\n    let restartAudioBarSpy = spyOn(\n      audioPreloaderService,\n      'restartAudioPreloader'\n    ).and.returnValue();\n\n    component.onNewLanguageSelected();\n    expect(languageSetSpy).toHaveBeenCalledWith('audio-en.mp3');\n    expect(restartAudioBarSpy).toHaveBeenCalled();\n  });\n\n  it('should throw error if language code is invalid', () => {\n    component.selectedLanguage.value = null;\n\n    expect(() => {\n      component.onNewLanguageSelected();\n    }).toThrowError('Expected a valid language code.');\n  });\n});\n"
    },
    {
      "filename": "core/templates/pages/exploration-player-page/layout-directives/audio-bar.component.ts",
      "content": "// Copyright 2021 The Oppia Authors. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS-IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Component for a set of audio controls for a specific\n * audio translation in the learner view.\n */\n\nimport {\n  Component,\n  ViewChild,\n  ElementRef,\n  ChangeDetectorRef,\n} from '@angular/core';\nimport {Voiceover} from 'domain/exploration/voiceover.model';\nimport {Subscription} from 'rxjs';\nimport {AssetsBackendApiService} from 'services/assets-backend-api.service';\nimport {AudioBarStatusService} from 'services/audio-bar-status.service';\nimport {\n  AudioPlayerService,\n  AutoPlayAudioEvent,\n} from 'services/audio-player.service';\nimport {AutogeneratedAudioPlayerService} from 'services/autogenerated-audio-player.service';\nimport {ContextService} from 'services/context.service';\nimport {SiteAnalyticsService} from 'services/site-analytics.service';\nimport {AudioPreloaderService} from '../services/audio-preloader.service';\nimport {\n  AudioTranslationLanguageService,\n  ExplorationLanguageInfo,\n} from '../services/audio-translation-language.service';\nimport {AudioTranslationManagerService} from '../services/audio-translation-manager.service';\nimport {PlayerPositionService} from '../services/player-position.service';\nimport {I18nLanguageCodeService} from 'services/i18n-language-code.service';\nimport {EntityVoiceoversService} from 'services/entity-voiceovers.services';\nimport {PlatformFeatureService} from 'services/platform-feature.service';\nimport {VoiceoverPlayerService} from '../services/voiceover-player.service';\nimport {LanguageAccentToDescription} from 'domain/voiceover/voiceover-backend-api.service';\nimport {LocalStorageService} from 'services/local-storage.service';\n\n@Component({\n  selector: 'oppia-audio-bar',\n  templateUrl: './audio-bar.component.html',\n})\nexport class AudioBarComponent {\n  @ViewChild('audioControls', {static: false}) audioControlsRef!: ElementRef;\n  lastScrollTop: number = 0;\n  isPaused: boolean = true;\n  directiveSubscriptions: Subscription = new Subscription();\n  languagesInExploration: ExplorationLanguageInfo[];\n  audioBarIsExpanded: boolean = false;\n  progressBarIsShown: boolean = false;\n  audioLoadingIndicatorIsShown: boolean = false;\n  explorationPlayerModeIsActive: boolean;\n  // Value may be null if the language is not available.\n  selectedLanguage: {value: string | null};\n  languageAccentCodesToDescriptions!: LanguageAccentToDescription;\n  languageAccentDecriptions: string[] = [];\n  selectedLanguageAccentDescription!: string;\n  voiceoverToBePlayed!: Voiceover | undefined;\n  currentVoiceoverTime: number = 0;\n  totalVoiceoverDurationSecs: number = 0;\n\n  constructor(\n    private assetsBackendApiService: AssetsBackendApiService,\n    private audioBarStatusService: AudioBarStatusService,\n    private audioPlayerService: AudioPlayerService,\n    private audioPreloaderService: AudioPreloaderService,\n    private audioTranslationLanguageService: AudioTranslationLanguageService,\n    private audioTranslationManagerService: AudioTranslationManagerService,\n    private autogeneratedAudioPlayerService: AutogeneratedAudioPlayerService,\n    private contextService: ContextService,\n    private playerPositionService: PlayerPositionService,\n    private I18nLanguageCodeService: I18nLanguageCodeService,\n    private siteAnalyticsService: SiteAnalyticsService,\n    private entityVoiceoversService: EntityVoiceoversService,\n    private platformFeatureService: PlatformFeatureService,\n    private voiceoverPlayerService: VoiceoverPlayerService,\n    private localStorageService: LocalStorageService,\n    private cdRef: ChangeDetectorRef\n  ) {\n    this.explorationPlayerModeIsActive =\n      this.contextService.isInExplorationPlayerPage();\n    this.languagesInExploration =\n      this.audioTranslationLanguageService.getLanguageOptionsForDropdown();\n    this.selectedLanguage = {\n      value: this.getCurrentAudioLanguageCode(),\n    };\n  }\n\n  ngOnInit(): void {\n    this.directiveSubscriptions.add(\n      this.voiceoverPlayerService.onTranslationLanguageChanged.subscribe(() => {\n        this.audioPlayerService.stop();\n        this.audioPlayerService.clear();\n        this.voiceoverToBePlayed = undefined;\n        this.setProgress({value: 0});\n        this.updateDisplayableLanguageAccentDescription();\n      })\n    );\n\n    this.directiveSubscriptions.add(\n      this.voiceoverPlayerService.onActiveVoiceoverChanged.subscribe(() => {\n        this.voiceoverToBePlayed =\n          this.voiceoverPlayerService.getActiveVoiceover() as Voiceover;\n      })\n    );\n\n    this.directiveSubscriptions.add(\n      this.audioPlayerService.onAutoplayAudio.subscribe(\n        (params: AutoPlayAudioEvent) => {\n          if (this.audioBarIsExpanded) {\n            this.audioPlayerService.stop();\n            this.autogeneratedAudioPlayerService.cancel();\n\n            // We use a timeout to allow for any previous audio to have\n            // their 'onend' callback called. This is primarily used to\n            // address delays with autogenerated audio callbacks.\n            setTimeout(() => {\n              if (params) {\n                this.audioTranslationManagerService.setSecondaryAudioTranslations(\n                  params.audioTranslations,\n                  params.html,\n                  params.componentName\n                );\n                if (!this.isPaused) {\n                  this.onPlayButtonClicked();\n                }\n              }\n            }, 100);\n          }\n        }\n      )\n    );\n    this.audioBarIsExpanded = false;\n    this.progressBarIsShown = false;\n    this.audioLoadingIndicatorIsShown = false;\n    this.audioPreloaderService.setAudioLoadedCallback(\n      this.onFinishedLoadingAudio.bind(this)\n    );\n\n    this.languageAccentDecriptions =\n      this.voiceoverPlayerService.getLanguageAccentDescriptions();\n  }\n\n  ngOnDestroy(): void {\n    this.directiveSubscriptions.unsubscribe();\n  }\n\n  ngAfterContentChecked(): void {\n    if (\n      this.audioPlayerService.isTrackLoaded() &&\n      this.audioPlayerService.isPlaying()\n    ) {\n      this.currentVoiceoverTime =\n        this.audioPlayerService.getCurrentTimeInSecs();\n      this.totalVoiceoverDurationSecs = Math.floor(\n        this.audioPlayerService.getAudioDuration()\n      );\n    }\n    if (!this.audioPlayerService.isTrackLoaded()) {\n      this.currentVoiceoverTime = 0;\n    }\n  }\n\n  setProgress(val: {value: number}): void {\n    this.audioPlayerService.setCurrentTime(val.value);\n  }\n\n  isAudioBarAvailable(): boolean {\n    if (this.isVoiceoverContributionWithAccentEnabled()) {\n      return this.languageAccentDecriptions.length > 0;\n    }\n    return this.languagesInExploration.length > 0;\n  }\n\n  isLanguageRTL(): boolean {\n    return this.I18nLanguageCodeService.isCurrentLanguageRTL();\n  }\n\n  onNewLanguageSelected(): void {\n    if (this.selectedLanguage.value === null) {\n      throw new Error('Expected a valid language code.');\n    }\n    this.audioTranslationLanguageService.setCurrentAudioLanguageCode(\n      this.selectedLanguage.value\n    );\n    this.audioPlayerService.stop();\n    this.audioPlayerService.clear();\n    this.autogeneratedAudioPlayerService.cancel();\n    const voiceoverInCurrentLanguage = this.getVoiceoverInCurrentLanguage();\n    if (\n      this.isAudioBarAvailable() &&\n      !this.isAutogeneratedLanguageCodeSelected() &&\n      voiceoverInCurrentLanguage\n    ) {\n      let audioTranslation: Voiceover = voiceoverInCurrentLanguage;\n      this.audioPreloaderService.setMostRecentlyRequestedAudioFilename(\n        audioTranslation.filename\n      );\n      this.audioPreloaderService.restartAudioPreloader(\n        this.playerPositionService.getCurrentStateName()\n      );\n    }\n  }\n\n  focusOnAudioControls(): void {\n    this.audioControlsRef?.nativeElement.focus();\n  }\n\n  expandAudioBar(): void {\n    this.audioBarIsExpanded = true;\n    this.audioBarStatusService.markAudioBarExpanded();\n    this.cdRef.detectChanges();\n    this.focusOnAudioControls();\n  }\n\n  collapseAudioBar(): void {\n    this.audioBarStatusService.markAudioBarCollapsed();\n    this.audioBarIsExpanded = false;\n    this.audioPlayerService.stop();\n    this.audioPlayerService.clear();\n    this.autogeneratedAudioPlayerService.cancel();\n  }\n\n  // Returns null if the audio is not available in the current language.\n  getCurrentAudioLanguageCode(): string | null {\n    return this.audioTranslationLanguageService.getCurrentAudioLanguageCode();\n  }\n\n  // Returns null if the audio is not available in the current language.\n  getCurrentAudioLanguageDescription(): string | null {\n    return this.audioTranslationLanguageService.getCurrentAudioLanguageDescription();\n  }\n\n  isVoiceoverContributionWithAccentEnabled(): boolean {\n    return this.platformFeatureService.status.AddVoiceoverWithAccent.isEnabled;\n  }\n\n  // Returns null if the audio is not available in the current language.\n  getVoiceoverInCurrentLanguage(): Voiceover | null {\n    const currentAudioLanguageCode = this.getCurrentAudioLanguageCode();\n    if (currentAudioLanguageCode !== null) {\n      return this.audioTranslationManagerService.getCurrentAudioTranslations()[\n        currentAudioLanguageCode\n      ];\n    }\n    return null;\n  }\n\n  isAudioPlaying(): boolean {\n    return (\n      this.audioPlayerService.isPlaying() ||\n      this.autogeneratedAudioPlayerService.isPlaying()\n    );\n  }\n\n  isAudioAvailableInCurrentLanguage(): boolean {\n    if (this.isVoiceoverContributionWithAccentEnabled()) {\n      return this.voiceoverToBePlayed !== undefined;\n    }\n    return (\n      Boolean(this.getVoiceoverInCurrentLanguage()) ||\n      this.isAutogeneratedLanguageCodeSelected()\n    );\n  }\n\n  doesCurrentAudioTranslationNeedUpdate(): boolean {\n    const voiceoverInCurrentLanguage = this.getVoiceoverInCurrentLanguage();\n    if (\n      !this.isAutogeneratedLanguageCodeSelected() &&\n      voiceoverInCurrentLanguage\n    ) {\n      let audioTranslation: Voiceover = voiceoverInCurrentLanguage;\n      return audioTranslation && audioTranslation.needsUpdate;\n    } else {\n      return false;\n    }\n  }\n\n  isAutogeneratedLanguageCodeSelected(): boolean {\n    return this.audioTranslationLanguageService.isAutogeneratedLanguageCodeSelected();\n  }\n\n  onBackwardButtonClicked(): void {\n    this.audioPlayerService.rewind(5);\n  }\n\n  onForwardButtonClicked(): void {\n    this.audioPlayerService.forward(5);\n  }\n\n  updateDisplayableLanguageAccentDescription(): void {\n    this.languageAccentDecriptions =\n      this.voiceoverPlayerService.getLanguageAccentDescriptions();\n\n    if (this.languageAccentDecriptions.length > 0) {\n      this.selectedLanguageAccentDescription =\n        this.languageAccentDecriptions[0];\n      this.updateSelectedLanguageAccent();\n    }\n  }\n\n  updateSelectedLanguageAccent(): void {\n    this.audioPlayerService.stop();\n    this.audioPlayerService.clear();\n    this.setProgress({value: 0});\n    let languageAccentCode =\n      this.voiceoverPlayerService.languageAccentDescriptionsToCodes[\n        this.selectedLanguageAccentDescription as string\n      ];\n    this.entityVoiceoversService.setActiveLanguageAccentCode(\n      languageAccentCode\n    );\n    let entityVoiceover =\n      this.entityVoiceoversService.getActiveEntityVoiceovers();\n\n    let contentId = this.voiceoverPlayerService.activeContentId;\n\n    this.voiceoverToBePlayed = entityVoiceover.getManualVoiceover(\n      contentId\n    ) as Voiceover;\n\n    this.audioPreloaderService.restartAudioPreloader(\n      this.playerPositionService.getCurrentStateName()\n    );\n  }\n\n  onPlayButtonClicked(): void {\n    this.isPaused = !this.isPaused;\n\n    if (this.isVoiceoverContributionWithAccentEnabled()) {\n      this.progressBarIsShown = true;\n      if (this.voiceoverToBePlayed) {\n        this.playPauseUploadedAudioTranslation();\n      }\n    } else {\n      this.progressBarIsShown = !this.isAutogeneratedLanguageCodeSelected();\n      if (this.isAutogeneratedLanguageCodeSelected()) {\n        this.playPauseAutogeneratedAudioTranslation();\n      } else {\n        let audioTranslation = this.getVoiceoverInCurrentLanguage();\n        if (audioTranslation) {\n          this.playPauseUploadedAudioTranslation();\n        }\n      }\n    }\n    this.siteAnalyticsService.registerStartAudioPlayedEvent(\n      this.contextService.getExplorationId(),\n      this.playerPositionService.getDisplayedCardIndex()\n    );\n  }\n\n  isCached(audioTranslation: Voiceover): boolean {\n    return this.assetsBackendApiService.isCached(audioTranslation.filename);\n  }\n\n  playPauseAutogeneratedAudioTranslation(): void {\n    // SpeechSynthesis in Chrome seems to have a bug\n    // where if you pause the utterance, wait for around\n    // 15 or more seconds, then try resuming, nothing\n    // will sound. As a temporary fix, just restart the\n    // utterance from the beginning instead of resuming.\n    if (this.autogeneratedAudioPlayerService.isPlaying()) {\n      this.autogeneratedAudioPlayerService.cancel();\n    } else {\n      const speechSynthesisLanguageCode =\n        this.audioTranslationLanguageService.getSpeechSynthesisLanguageCode();\n      if (speechSynthesisLanguageCode === null) {\n        throw new Error(\n          'speechSynthesisLanguageCode cannot be null at this point.'\n        );\n      }\n      this.autogeneratedAudioPlayerService.play(\n        this.audioTranslationManagerService.getCurrentHtmlForAutogeneratedAudio(),\n        speechSynthesisLanguageCode,\n        () => {\n          // Used to update bindings to show a silent speaker after\n          // autogenerated audio has finished playing.\n          this.audioTranslationManagerService.clearSecondaryAudioTranslations();\n          let sequentialAudio =\n            this.audioTranslationManagerService.getCurrentHtmlForAutogeneratedSequentialAudio();\n          if (sequentialAudio) {\n            this.autogeneratedAudioPlayerService.play(\n              sequentialAudio,\n              speechSynthesisLanguageCode,\n              () => {}\n            );\n          }\n        }\n      );\n    }\n  }\n\n  playPauseUploadedAudioTranslation(): void {\n    if (!this.audioPlayerService.isPlaying()) {\n      if (this.audioPlayerService.isTrackLoaded()) {\n        this.audioPlayerService.play();\n      } else {\n        this.loadAndPlayAudioTranslation();\n      }\n    } else {\n      this.audioPlayerService.pause();\n    }\n  }\n\n  playCachedAudioTranslation(audioFilename: string): void {\n    this.audioPlayerService.loadAsync(audioFilename).then(() => {\n      this.audioLoadingIndicatorIsShown = false;\n      this.audioPlayerService.play();\n    });\n  }\n\n  /**\n   * Called when an audio file finishes loading.\n   * @param {string} audioFilename - Filename of the audio file that\n   *                                 finished loading.\n   */\n  onFinishedLoadingAudio(audioFilename: string): void {\n    let mostRecentlyRequestedAudioFilename =\n      this.audioPreloaderService.getMostRecentlyRequestedAudioFilename();\n    if (\n      this.audioLoadingIndicatorIsShown &&\n      audioFilename === mostRecentlyRequestedAudioFilename\n    ) {\n      this.playCachedAudioTranslation(audioFilename);\n    }\n  }\n\n  loadAndPlayAudioTranslation(): void {\n    this.audioLoadingIndicatorIsShown = true;\n    let audioTranslation = this.getVoiceoverInCurrentLanguage() as Voiceover;\n\n    if (this.isVoiceoverContributionWithAccentEnabled()) {\n      audioTranslation = this.voiceoverToBePlayed as Voiceover;\n    }\n\n    if (audioTranslation) {\n      this.audioPreloaderService.setMostRecentlyRequestedAudioFilename(\n        audioTranslation.filename\n      );\n      if (this.isCached(audioTranslation)) {\n        this.playCachedAudioTranslation(audioTranslation.filename);\n      } else if (\n        !this.audioPreloaderService.isLoadingAudioFile(\n          audioTranslation.filename\n        )\n      ) {\n        this.audioPreloaderService.restartAudioPreloader(\n          this.playerPositionService.getCurrentStateName()\n        );\n      }\n    }\n  }\n}\n"
    },
    {
      "filename": "core/templates/services/audio-player.service.spec.ts",
      "content": "// Copyright 2021 The Oppia Authors. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS-IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Unit tests to operate the playback of audio.\n */\n\nimport {\n  discardPeriodicTasks,\n  fakeAsync,\n  flushMicrotasks,\n  TestBed,\n  tick,\n  waitForAsync,\n} from '@angular/core/testing';\nimport {AudioPlayerService} from './audio-player.service';\nimport {AssetsBackendApiService} from './assets-backend-api.service';\nimport {ContextService} from './context.service';\nimport {EventEmitter, NO_ERRORS_SCHEMA} from '@angular/core';\nimport {HttpClientTestingModule} from '@angular/common/http/testing';\nimport * as howler from 'howler';\nimport {AudioTranslationManagerService} from 'pages/exploration-player-page/services/audio-translation-manager.service';\nimport {Subject} from 'rxjs';\nimport {Howl} from 'howler';\n\ndescribe('AudioPlayerService', () => {\n  let audioPlayerService: AudioPlayerService;\n  let contextService: ContextService;\n  let assetsBackendApiService: AssetsBackendApiService;\n  let audioTranslationManagerService: AudioTranslationManagerService;\n  let successHandler: jasmine.Spy;\n  let failHandler: jasmine.Spy;\n\n  beforeEach(waitForAsync(() => {\n    TestBed.configureTestingModule({\n      imports: [HttpClientTestingModule],\n      providers: [AudioPlayerService, ContextService, AssetsBackendApiService],\n      schemas: [NO_ERRORS_SCHEMA],\n    });\n  }));\n\n  beforeEach(() => {\n    audioTranslationManagerService = TestBed.inject(\n      AudioTranslationManagerService\n    );\n    audioPlayerService = TestBed.inject(AudioPlayerService);\n    contextService = TestBed.inject(ContextService);\n    assetsBackendApiService = TestBed.inject(AssetsBackendApiService);\n    spyOn(contextService, 'getExplorationId').and.returnValue('1');\n    successHandler = jasmine.createSpy('success');\n    failHandler = jasmine.createSpy('fail');\n  });\n\n  describe('when audio loads successfully', () => {\n    beforeEach(() => {\n      spyOn(howler, 'Howl').and.returnValue({\n        on: (evt: string, func: () => void) => {\n          if (evt === 'load') {\n            func();\n          }\n        },\n        stop: () => {\n          console.error('Howl.stop');\n        },\n        pause: () => {\n          console.error('Howl.pause');\n        },\n        playing: () => {\n          return false;\n        },\n        play: () => {\n          console.error('Howl.play');\n          return 2;\n        },\n        seek: (num?: number) => {\n          if (typeof num !== 'undefined') {\n            console.error('Howl.seek ', num);\n            return num;\n          }\n          return 10;\n        },\n        duration: () => {\n          return 30;\n        },\n      } as Howl);\n      spyOn(assetsBackendApiService, 'loadAudio').and.returnValue(\n        Promise.resolve({\n          data: new Blob(),\n          filename: 'test.mp3',\n        })\n      );\n    });\n\n    it('should load track when user plays audio', fakeAsync(async () => {\n      audioPlayerService\n        .loadAsync('test.mp3')\n        .then(successHandler, failHandler);\n      flushMicrotasks();\n\n      expect(successHandler).toHaveBeenCalled();\n      expect(failHandler).not.toHaveBeenCalled();\n    }));\n\n    it('should not load track when a track has already been loaded', fakeAsync(() => {\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      expect(assetsBackendApiService.loadAudio).toHaveBeenCalledTimes(1);\n    }));\n\n    it('should play audio when user clicks the play button', fakeAsync(() => {\n      spyOn(console, 'error');\n\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      audioPlayerService.play();\n      tick(501);\n      discardPeriodicTasks();\n\n      // The play function of the Howl calss is called when the user clicks\n      // the  play button. Since the Howl class is mocked, a cosole.error stmt\n      // is placed inside the play function and is tested if the console.error\n      // stmt inside it triggered.\n      expect(console.error).toHaveBeenCalledWith('Howl.play');\n    }));\n\n    it('should not play audio again when audio is already being played', fakeAsync(() => {\n      spyOn(console, 'error');\n      spyOn(audioPlayerService, 'isPlaying').and.returnValue(true);\n\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      audioPlayerService.play();\n      discardPeriodicTasks();\n\n      // The play function of the Howl calss is called when the user clicks\n      // the  play button. Since the Howl class is mocked, a cosole.error stmt\n      // is placed inside the play function and is tested if the console.error\n      // stmt inside it triggered.\n      expect(console.error).not.toHaveBeenCalledWith('Howl.play');\n    }));\n\n    it('should not pause track when audio is not being played', fakeAsync(() => {\n      spyOn(audioPlayerService, 'isPlaying').and.returnValue(false);\n      spyOn(audioPlayerService, 'getCurrentTimeInSecs');\n      let subjectNext = spyOn(Subject.prototype, 'next');\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      audioPlayerService.pause();\n\n      expect(audioPlayerService.getCurrentTimeInSecs).not.toHaveBeenCalled();\n      expect(subjectNext).toHaveBeenCalledTimes(1);\n    }));\n\n    it(\n      \"should pause track when user clicks the 'Pause' \" + 'button',\n      fakeAsync(() => {\n        spyOn(audioPlayerService, 'isPlaying').and.returnValue(true);\n        let subjectNext = spyOn(Subject.prototype, 'next');\n        spyOn(audioPlayerService, 'getCurrentTimeInSecs');\n        audioPlayerService.loadAsync('test.mp3');\n        flushMicrotasks();\n\n        audioPlayerService.pause();\n\n        expect(audioPlayerService.getCurrentTimeInSecs).toHaveBeenCalled();\n        expect(subjectNext).toHaveBeenCalled();\n      })\n    );\n\n    it('should stop playing track when called', fakeAsync(() => {\n      spyOn(audioPlayerService, 'setCurrentTime');\n      spyOn(console, 'error');\n      spyOn(audioTranslationManagerService, 'clearSecondaryAudioTranslations');\n      let subjectNext = spyOn(Subject.prototype, 'next');\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      audioPlayerService.stop();\n\n      expect(console.error).toHaveBeenCalledWith('Howl.stop');\n      expect(subjectNext).toHaveBeenCalledTimes(2);\n      expect(\n        audioTranslationManagerService.clearSecondaryAudioTranslations\n      ).toHaveBeenCalled();\n    }));\n\n    it(\n      \"should rewind the track when user clicks the 'Rewind' \" + 'button',\n      fakeAsync(() => {\n        spyOn(console, 'error');\n        audioPlayerService.loadAsync('test.mp3');\n        flushMicrotasks();\n\n        audioPlayerService.rewind(5);\n\n        expect(console.error).toHaveBeenCalledWith('Howl.seek ', 5);\n      })\n    );\n\n    it(\n      \"should forward the track when user clicks the 'forward'\" + ' button',\n      fakeAsync(() => {\n        spyOn(console, 'error');\n        audioPlayerService.loadAsync('test.mp3');\n        flushMicrotasks();\n\n        audioPlayerService.forward(5);\n\n        expect(console.error).toHaveBeenCalledWith('Howl.seek ', 15);\n      })\n    );\n\n    it('should get the current time of the track when it is being played', fakeAsync(() => {\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      expect(audioPlayerService.getCurrentTimeInSecs()).toBe(10);\n    }));\n\n    it('should set the time when user clicks on the track', fakeAsync(() => {\n      spyOn(console, 'error');\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      audioPlayerService.setCurrentTime(15);\n\n      expect(console.error).toHaveBeenCalledWith('Howl.seek ', 15);\n    }));\n\n    it(\n      'should set the time as track duration when user clicks on end ' +\n        'of the track',\n      fakeAsync(() => {\n        spyOn(console, 'error');\n        audioPlayerService.loadAsync('test.mp3');\n        flushMicrotasks();\n\n        audioPlayerService.setCurrentTime(31);\n\n        expect(console.error).toHaveBeenCalledWith('Howl.seek ', 30);\n      })\n    );\n\n    it(\n      'should set the time as 0 when user clicks on beginning ' +\n        'of the track',\n      fakeAsync(() => {\n        spyOn(console, 'error');\n        audioPlayerService.loadAsync('test.mp3');\n        flushMicrotasks();\n\n        audioPlayerService.setCurrentTime(-1);\n\n        expect(console.error).toHaveBeenCalledWith('Howl.seek ', 0);\n      })\n    );\n\n    it('should return duration of the track when called', fakeAsync(() => {\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      expect(audioPlayerService.getAudioDuration()).toBe(30);\n    }));\n\n    it('should return false when audio is not being played', fakeAsync(() => {\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      expect(audioPlayerService.isPlaying()).toBe(false);\n    }));\n\n    it('should return whether track is loaded', fakeAsync(() => {\n      expect(audioPlayerService.isTrackLoaded()).toBe(false);\n\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      expect(audioPlayerService.isTrackLoaded()).toBe(true);\n\n      audioPlayerService.clear();\n\n      expect(audioPlayerService.isTrackLoaded()).toBe(false);\n    }));\n\n    it('should clear track when called', fakeAsync(() => {\n      spyOn(audioPlayerService, 'isPlaying').and.callThrough();\n      spyOn(audioPlayerService, 'stop');\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      expect(audioPlayerService.isTrackLoaded()).toBe(true);\n\n      audioPlayerService.clear();\n\n      expect(audioPlayerService.stop).not.toHaveBeenCalled();\n      expect(audioPlayerService.isTrackLoaded()).toBe(false);\n    }));\n\n    it('should stop and clear track when called', fakeAsync(() => {\n      spyOn(audioPlayerService, 'isPlaying').and.returnValue(true);\n      spyOn(audioPlayerService, 'stop');\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      expect(audioPlayerService.isTrackLoaded()).toBe(true);\n\n      audioPlayerService.clear();\n\n      expect(audioPlayerService.stop).toHaveBeenCalled();\n      expect(audioPlayerService.isTrackLoaded()).toBe(false);\n    }));\n  });\n\n  describe('when track is not loaded', () => {\n    beforeEach(() => {\n      spyOn(howler, 'Howl').and.returnValue({\n        on: (evt: string, func: () => void) => {\n          if (evt === 'load') {\n            func();\n          }\n        },\n        seek: (num: number) => {\n          if (typeof num !== 'undefined') {\n            console.error('Howl.seek ', num);\n            return num;\n          }\n          console.error('Howl.seek');\n          return {};\n        },\n        stop: () => {\n          console.error('Howl.stop');\n        },\n        playing: () => {\n          return true;\n        },\n      } as Howl);\n      spyOn(assetsBackendApiService, 'loadAudio').and.returnValue(\n        Promise.resolve({\n          data: new Blob(),\n          filename: 'test.mp3',\n        })\n      );\n      spyOn(console, 'error');\n    });\n\n    it('should not call Howl.stop when no audio is loaded', fakeAsync(() => {\n      spyOn(audioPlayerService, 'setCurrentTime');\n      let subjectNext = spyOn(Subject.prototype, 'next');\n\n      audioPlayerService.stop();\n\n      expect(console.error).not.toHaveBeenCalledWith('Howl.stop');\n      expect(subjectNext).not.toHaveBeenCalledTimes(2);\n    }));\n\n    it('should not rewind track when no audio is loaded', fakeAsync(() => {\n      audioPlayerService.rewind(5);\n\n      expect(console.error).not.toHaveBeenCalled();\n    }));\n\n    it('should not rewind track when seek does not return an number', fakeAsync(() => {\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      audioPlayerService.rewind(5);\n\n      expect(console.error).toHaveBeenCalledTimes(1);\n      expect(console.error).toHaveBeenCalledWith('Howl.seek');\n    }));\n\n    it('should not forward track when no audio is loaded', fakeAsync(() => {\n      audioPlayerService.forward(5);\n\n      expect(console.error).not.toHaveBeenCalled();\n    }));\n\n    it('should not foward track when seek does not return an number', fakeAsync(() => {\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      audioPlayerService.forward(5);\n\n      expect(console.error).toHaveBeenCalledTimes(1);\n      expect(console.error).toHaveBeenCalledWith('Howl.seek');\n    }));\n\n    it(\n      'should not get the current time of track when no audio is' + ' loaded',\n      () => {\n        expect(audioPlayerService.getCurrentTimeInSecs()).toBe(0);\n      }\n    );\n\n    it(\n      'should not get the current time of track when seek does not ' +\n        'return an number',\n      fakeAsync(() => {\n        audioPlayerService.loadAsync('test.mp3');\n        flushMicrotasks();\n\n        expect(audioPlayerService.getCurrentTimeInSecs()).toBe(0);\n      })\n    );\n\n    it('should not forward track when no audio is loaded', fakeAsync(() => {\n      audioPlayerService.forward(5);\n\n      expect(console.error).not.toHaveBeenCalled();\n    }));\n\n    it('should not set time of the track when audio is not loaded', () => {\n      audioPlayerService.setCurrentTime(5);\n\n      expect(console.error).not.toHaveBeenCalled();\n    });\n\n    it('should return 0 duration when no audio is loaded', fakeAsync(() => {\n      expect(audioPlayerService.getAudioDuration()).toBe(0);\n    }));\n\n    it('should return whether audio is playing', fakeAsync(() => {\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      expect(audioPlayerService.isPlaying()).toBe(true);\n    }));\n  });\n\n  it(\n    'should clear secondary audio translations when audio ' + 'ends',\n    fakeAsync(async () => {\n      spyOn(howler, 'Howl').and.returnValue({\n        on: (evt: string, func: () => void) => {\n          if (evt === 'end') {\n            func();\n          }\n        },\n      } as Howl);\n      spyOn(assetsBackendApiService, 'loadAudio').and.returnValue(\n        Promise.resolve({\n          data: new Blob(),\n          filename: 'test',\n        })\n      );\n      spyOn(audioTranslationManagerService, 'clearSecondaryAudioTranslations');\n\n      audioPlayerService.loadAsync('test.mp3');\n      flushMicrotasks();\n\n      expect(\n        audioTranslationManagerService.clearSecondaryAudioTranslations\n      ).toHaveBeenCalled();\n    })\n  );\n\n  it('should display error when audio fails to load', fakeAsync(() => {\n    spyOn(assetsBackendApiService, 'loadAudio').and.returnValue(\n      Promise.reject('Error')\n    );\n    spyOn(audioTranslationManagerService, 'clearSecondaryAudioTranslations');\n\n    audioPlayerService.loadAsync('test.mp3').then(successHandler, failHandler);\n    flushMicrotasks();\n\n    expect(successHandler).not.toHaveBeenCalled();\n    expect(failHandler).toHaveBeenCalledWith('Error');\n  }));\n\n  it('should fetch event emitter for update in view', () => {\n    let mockEventEmitter = new EventEmitter();\n    expect(audioPlayerService.viewUpdate).toEqual(mockEventEmitter);\n  });\n\n  it('should fetch event emitter for auto play audio', () => {\n    let mockEventEmitter = new EventEmitter();\n    expect(audioPlayerService.onAutoplayAudio).toEqual(mockEventEmitter);\n  });\n\n  it('should return subject when audio stops playing', () => {\n    let mockSubject = new Subject<void>();\n    expect(audioPlayerService.onAudioStop).toEqual(mockSubject);\n  });\n});\n"
    },
    {
      "filename": "core/templates/services/audio-player.service.ts",
      "content": "// Copyright 2017 The Oppia Authors. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS-IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Service to operate the playback of audio.\n */\n\nimport {EventEmitter, Injectable, NgZone} from '@angular/core';\nimport {AudioFile} from 'domain/utilities/audio-file.model';\nimport {\n  AudioTranslationManagerService,\n  AudioTranslations,\n} from 'pages/exploration-player-page/services/audio-translation-manager.service';\nimport {AssetsBackendApiService} from './assets-backend-api.service';\nimport {ContextService} from './context.service';\nimport {Howl} from 'howler';\nimport {downgradeInjectable} from '@angular/upgrade/static';\nimport {interval, Subject} from 'rxjs';\nimport {takeUntil} from 'rxjs/operators';\n\nexport interface AutoPlayAudioEvent {\n  audioTranslations: AudioTranslations;\n  html: string;\n  componentName: string;\n}\n\n@Injectable({\n  providedIn: 'root',\n})\nexport class AudioPlayerService {\n  // 'currentTrackFilename','currentTrack' and 'lastPauseOrSeekPos'\n  // will be 'null' when the track is not selected or ended.\n  private _currentTrackFilename: string | null = null;\n  private _currentTrack: Howl | null = null;\n  private _lastPauseOrSeekPos: number | null = null;\n  private _updateViewEventEmitter = new EventEmitter<void>();\n  private _autoplayAudioEventEmitter =\n    new EventEmitter<void | AutoPlayAudioEvent>();\n\n  private _stopIntervalSubject = new Subject<void>();\n  constructor(\n    private assetsBackendApiService: AssetsBackendApiService,\n    private audioTranslationManagerService: AudioTranslationManagerService,\n    private contextService: ContextService,\n    private ngZone: NgZone\n  ) {}\n\n  private async _loadAsync(\n    filename: string,\n    successCallback: () => void,\n    errorCallback: (reason?: string[]) => void\n  ) {\n    if (this._currentTrackFilename === filename) {\n      return;\n    }\n    this.assetsBackendApiService\n      .loadAudio(this.contextService.getExplorationId(), filename)\n      .then(\n        (loadedAudioFile: AudioFile) => {\n          this._currentTrack = new Howl({\n            src: [URL.createObjectURL(loadedAudioFile.data)],\n            format: ['mp3'],\n          });\n          this._currentTrack.on('load', () => {\n            this._stopIntervalSubject.next();\n            this._currentTrackFilename = loadedAudioFile.filename;\n            this._lastPauseOrSeekPos = 0;\n            successCallback();\n          });\n          this._currentTrack.on('end', () => {\n            this._stopIntervalSubject.next();\n            this._currentTrack = null;\n            this._currentTrackFilename = null;\n            this._lastPauseOrSeekPos = null;\n            this.audioTranslationManagerService.clearSecondaryAudioTranslations();\n          });\n        },\n        e => errorCallback(e)\n      );\n  }\n\n  async loadAsync(filename: string): Promise<void> {\n    return new Promise((resolve, reject) => {\n      this._loadAsync(filename, resolve, reject);\n    });\n  }\n\n  play(): void {\n    if (this.isPlaying()) {\n      return;\n    }\n\n    this.ngZone.runOutsideAngular(() => {\n      if (this._currentTrack !== null) {\n        // 'lastPauseOrSeekPos' will not be null since currentTrack exists.\n        // We can safely typecast it to 'number'.\n        this._currentTrack.seek(this._lastPauseOrSeekPos as number);\n      }\n      interval(500)\n        .pipe(takeUntil(this._stopIntervalSubject))\n        .subscribe(() => {\n          this.ngZone.run(() => {\n            this._updateViewEventEmitter.emit();\n          });\n        });\n      // 'currentTrack' is not null since the audio event has been emitted\n      // and that is why we use '?'.\n      this._currentTrack?.play();\n    });\n  }\n\n  pause(): void {\n    if (!this.isPlaying()) {\n      return;\n    }\n    this._lastPauseOrSeekPos = Math.floor(this.getCurrentTimeInSecs());\n    // 'currentTrack' is not null since the track is playing\n    // and that is why we use '?'.\n    this._currentTrack?.pause();\n    this._stopIntervalSubject.next();\n  }\n\n  stop(): void {\n    if (!this._currentTrack) {\n      return;\n    }\n    this._currentTrack.stop();\n    this._stopIntervalSubject.next();\n    this._currentTrack = null;\n    this._currentTrackFilename = null;\n    this._lastPauseOrSeekPos = null;\n    this.audioTranslationManagerService.clearSecondaryAudioTranslations();\n  }\n\n  rewind(seconds: number): void {\n    if (!this._currentTrack) {\n      return;\n    }\n    const currentSeconds = this._currentTrack.seek();\n    if (typeof currentSeconds !== 'number') {\n      return;\n    }\n    const rewindTo = currentSeconds - seconds;\n    this._currentTrack.seek(rewindTo > 0 ? rewindTo : 0);\n  }\n\n  forward(seconds: number): void {\n    if (!this._currentTrack) {\n      return;\n    }\n    const currentSeconds = this._currentTrack.seek();\n    if (typeof currentSeconds !== 'number') {\n      return;\n    }\n    if (currentSeconds + seconds < this._currentTrack.duration()) {\n      this._currentTrack.seek(currentSeconds + seconds);\n    }\n  }\n\n  getCurrentTimeInSecs(): number {\n    if (!this._currentTrack) {\n      return 0;\n    }\n    const currentTime = this._currentTrack.seek();\n    if (typeof currentTime !== 'number') {\n      return 0;\n    }\n    return Math.floor(currentTime * 10) / 10;\n  }\n\n  setCurrentTime(val: number): void {\n    if (!this._currentTrack) {\n      return;\n    }\n    if (val < 0) {\n      this._currentTrack.seek(0);\n      return;\n    }\n    if (val > this._currentTrack.duration()) {\n      this._currentTrack.seek(this._currentTrack.duration());\n      return;\n    }\n    this._lastPauseOrSeekPos = val;\n    this._currentTrack.seek(Math.floor(val));\n  }\n\n  getAudioDuration(): number {\n    if (this._currentTrack) {\n      return this._currentTrack.duration();\n    } else {\n      return 0;\n    }\n  }\n\n  isPlaying(): boolean {\n    return this._currentTrack !== null && this._currentTrack.playing();\n  }\n\n  isTrackLoaded(): boolean {\n    return this._currentTrack !== null;\n  }\n\n  clear(): void {\n    if (this.isPlaying()) {\n      this.stop();\n    }\n    this._currentTrackFilename = null;\n    this._currentTrack = null;\n  }\n\n  get viewUpdate(): EventEmitter<void> {\n    return this._updateViewEventEmitter;\n  }\n\n  get onAutoplayAudio(): EventEmitter<void | AutoPlayAudioEvent> {\n    return this._autoplayAudioEventEmitter;\n  }\n\n  get onAudioStop(): Subject<void> {\n    return this._stopIntervalSubject;\n  }\n}\n\nangular\n  .module('oppia')\n  .factory('AudioPlayerService', downgradeInjectable(AudioPlayerService));\n"
    }
  ]
}