{
  "repo_name": "oppia_oppia",
  "issue_id": "5145",
  "issue_description": "# Modify the from_backend_dict method\n\nRight now, the following classes have two separate methods called `from_backend_dict()` and `from_dict()`:\r\n- [ ] `core.domain.stats_domain.Playthrough`\r\n- [ ] `core.domain.stats_domain.ExplorationIssue`\r\n\r\n`from_dict()` takes a dictionary and creates an instance based on its values.  \r\n`from_backend_dict()` takes a dictionary and validates it before creating an instance based on its values and an automatically generated ID.\r\n\r\nPut simply, `from_backend_dict()` does not require an actual ID, whereas `from_dict()` does.\r\n\r\nWe should consolidate this into one `from_dict()` method with a flag `id_required=True`",
  "issue_comments": [
    {
      "id": 399645404,
      "user": "seanlip",
      "body": "I don't like the use of a dummy ID. Can you add links to cases when it is actually needed?\r\n\r\nIn general we should never be using \"fake\" data in the main code."
    },
    {
      "id": 399645809,
      "user": "pranavsid98",
      "body": "@seanlip \r\n\r\nSo this is the case:\r\n\r\nWhen there is incoming playthrough data from the front end, it is in a dict form, and since the playthrough doesnt exist in the datastore yet, it does not have an ID. In our controller, before the playthrough is stored, a lot of operations are performed (finding the issue for the playthrough to be inserted, if it already exists) and the like. Going by our practice of not using dicts directly while performing operations, I converted it to a temporary instance that doesnt have any significance.\r\n\r\nIs that bad?"
    },
    {
      "id": 399701084,
      "user": "seanlip",
      "body": "It's good to use domain objects, but not great to use a temporary/fake ID. Some alternatives:\r\n\r\n- Does your domain object actually need an ID field? If not, remove it from there and have it only be a storage model property.\r\n- Use an ID value of None while the playthrough still does not have an ID assigned. In the domain object, document the significance of this value."
    },
    {
      "id": 403812849,
      "user": "jacobdavis11",
      "body": "@brianrodri are you still working on this?"
    },
    {
      "id": 406281506,
      "user": "anmolshkl",
      "body": "@brianrodri ping!"
    },
    {
      "id": 411167096,
      "user": "apb7",
      "body": "Hi @brianrodri, are you still working on this? Thanks! "
    },
    {
      "id": 411168104,
      "user": "brianrodri",
      "body": "Heya, not for a while since I'm currently on vacation. I'll take a look\r\nagain in about a week, so feel free to reassign if that's too late."
    },
    {
      "id": 411171941,
      "user": "apb7",
      "body": "No problem, sounds good! Thanks for the update."
    },
    {
      "id": 413300424,
      "user": "tjiang11",
      "body": "Hey @brianrodri any updates on this?"
    },
    {
      "id": 420373792,
      "user": "jacobdavis11",
      "body": "De-assigning for now. Please re-assign if you'd like to continue work."
    },
    {
      "id": 553332226,
      "user": "ghost",
      "body": "I'll take this issue"
    },
    {
      "id": 553402451,
      "user": "ghost",
      "body": "added a PR\r\nhttps://github.com/oppia/oppia/pull/7992"
    }
  ],
  "text_context": "# Modify the from_backend_dict method\n\nRight now, the following classes have two separate methods called `from_backend_dict()` and `from_dict()`:\r\n- [ ] `core.domain.stats_domain.Playthrough`\r\n- [ ] `core.domain.stats_domain.ExplorationIssue`\r\n\r\n`from_dict()` takes a dictionary and creates an instance based on its values.  \r\n`from_backend_dict()` takes a dictionary and validates it before creating an instance based on its values and an automatically generated ID.\r\n\r\nPut simply, `from_backend_dict()` does not require an actual ID, whereas `from_dict()` does.\r\n\r\nWe should consolidate this into one `from_dict()` method with a flag `id_required=True`\n\nI don't like the use of a dummy ID. Can you add links to cases when it is actually needed?\r\n\r\nIn general we should never be using \"fake\" data in the main code.\n\n@seanlip \r\n\r\nSo this is the case:\r\n\r\nWhen there is incoming playthrough data from the front end, it is in a dict form, and since the playthrough doesnt exist in the datastore yet, it does not have an ID. In our controller, before the playthrough is stored, a lot of operations are performed (finding the issue for the playthrough to be inserted, if it already exists) and the like. Going by our practice of not using dicts directly while performing operations, I converted it to a temporary instance that doesnt have any significance.\r\n\r\nIs that bad?\n\nIt's good to use domain objects, but not great to use a temporary/fake ID. Some alternatives:\r\n\r\n- Does your domain object actually need an ID field? If not, remove it from there and have it only be a storage model property.\r\n- Use an ID value of None while the playthrough still does not have an ID assigned. In the domain object, document the significance of this value.\n\n@brianrodri are you still working on this?\n\n@brianrodri ping!\n\nHi @brianrodri, are you still working on this? Thanks! \n\nHeya, not for a while since I'm currently on vacation. I'll take a look\r\nagain in about a week, so feel free to reassign if that's too late.\n\nNo problem, sounds good! Thanks for the update.\n\nHey @brianrodri any updates on this?\n\nDe-assigning for now. Please re-assign if you'd like to continue work.\n\nI'll take this issue\n\nadded a PR\r\nhttps://github.com/oppia/oppia/pull/7992",
  "pr_link": "https://github.com/oppia/oppia/pull/7992",
  "code_context": [
    {
      "filename": "core/controllers/editor.py",
      "content": "# coding: utf-8\n\n# Copyright 2014 The Oppia Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Controllers for the editor view.\"\"\"\nfrom __future__ import absolute_import  # pylint: disable=import-only-modules\nfrom __future__ import unicode_literals  # pylint: disable=import-only-modules\n\nimport datetime\nimport imghdr\nimport logging\n\nfrom constants import constants\nfrom core.controllers import acl_decorators\nfrom core.controllers import base\nfrom core.domain import email_manager\nfrom core.domain import exp_domain\nfrom core.domain import exp_fetchers\nfrom core.domain import exp_services\nfrom core.domain import fs_domain\nfrom core.domain import fs_services\nfrom core.domain import question_services\nfrom core.domain import rights_manager\nfrom core.domain import search_services\nfrom core.domain import state_domain\nfrom core.domain import stats_domain\nfrom core.domain import stats_services\nfrom core.domain import user_services\nfrom core.platform import models\nimport feconf\nimport utils\n\napp_identity_services = models.Registry.import_app_identity_services()\ncurrent_user_services = models.Registry.import_current_user_services()\n(stats_models, user_models) = models.Registry.import_models(\n    [models.NAMES.statistics, models.NAMES.user])\n\n\ndef _require_valid_version(version_from_payload, exploration_version):\n    \"\"\"Check that the payload version matches the given exploration version.\"\"\"\n    if version_from_payload is None:\n        raise base.BaseHandler.InvalidInputException(\n            'Invalid POST request: a version must be specified.')\n\n    if version_from_payload != exploration_version:\n        raise base.BaseHandler.InvalidInputException(\n            'Trying to update version %s of exploration from version %s, '\n            'which is too old. Please reload the page and try again.'\n            % (exploration_version, version_from_payload))\n\n\nclass EditorHandler(base.BaseHandler):\n    \"\"\"Base class for all handlers for the editor page.\"\"\"\n    pass\n\n\nclass ExplorationPage(EditorHandler):\n    \"\"\"The editor page for a single exploration.\"\"\"\n\n\n    @acl_decorators.can_play_exploration\n    def get(self, unused_exploration_id):\n        \"\"\"Handles GET requests.\"\"\"\n\n        self.render_template('exploration-editor-page.mainpage.html')\n\n\nclass ExplorationHandler(EditorHandler):\n    \"\"\"Page with editor data for a single exploration.\"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_play_exploration\n    def get(self, exploration_id):\n        \"\"\"Gets the data for the exploration overview page.\"\"\"\n        # 'apply_draft' and 'v'(version) are optional parameters because the\n        # exploration history tab also uses this handler, and these parameters\n        # are not used by that tab.\n        version = self.request.get('v', default_value=None)\n        apply_draft = self.request.get('apply_draft', default_value=False)\n\n        user_settings = user_services.get_user_settings(self.user_id)\n        has_seen_editor_tutorial = False\n        has_seen_translation_tutorial = False\n        if user_settings is not None:\n            if user_settings.last_started_state_editor_tutorial:\n                has_seen_editor_tutorial = True\n            if user_settings.last_started_state_translation_tutorial:\n                has_seen_translation_tutorial = True\n\n        try:\n            exploration_data = exp_services.get_user_exploration_data(\n                self.user_id, exploration_id, apply_draft=apply_draft,\n                version=version)\n            exploration_data['show_state_editor_tutorial_on_load'] = (\n                self.user_id and not has_seen_editor_tutorial)\n            exploration_data['show_state_translation_tutorial_on_load'] = (\n                self.user_id and not has_seen_translation_tutorial)\n        except:\n            raise self.PageNotFoundException\n\n        self.values.update(exploration_data)\n        self.render_json(self.values)\n\n    @acl_decorators.can_save_exploration\n    def put(self, exploration_id):\n        \"\"\"Updates properties of the given exploration.\"\"\"\n        exploration = exp_fetchers.get_exploration_by_id(exploration_id)\n        version = self.payload.get('version')\n        _require_valid_version(version, exploration.version)\n\n        commit_message = self.payload.get('commit_message')\n        change_list_dict = self.payload.get('change_list')\n        change_list = [\n            exp_domain.ExplorationChange(change) for change in change_list_dict]\n        try:\n            exploration_rights = rights_manager.get_exploration_rights(\n                exploration_id)\n            can_edit = rights_manager.check_can_edit_activity(\n                self.user, exploration_rights)\n            can_voiceover = rights_manager.check_can_voiceover_activity(\n                self.user, exploration_rights)\n            if can_edit:\n                exp_services.update_exploration(\n                    self.user_id, exploration_id, change_list, commit_message)\n            elif can_voiceover:\n                exp_services.update_exploration(\n                    self.user_id, exploration_id, change_list, commit_message,\n                    is_by_voice_artist=True)\n        except utils.ValidationError as e:\n            raise self.InvalidInputException(e)\n\n        exploration_data = exp_services.get_user_exploration_data(\n            self.user_id, exploration_id)\n\n        self.values.update(exploration_data)\n        self.render_json(self.values)\n\n    @acl_decorators.can_delete_exploration\n    def delete(self, exploration_id):\n        \"\"\"Deletes the given exploration.\"\"\"\n\n        log_debug_string = '(%s) %s tried to delete exploration %s' % (\n            self.role, self.user_id, exploration_id)\n        logging.debug(log_debug_string)\n\n        is_exploration_cloned = rights_manager.is_exploration_cloned(\n            exploration_id)\n        exp_services.delete_exploration(\n            self.user_id, exploration_id, force_deletion=is_exploration_cloned)\n\n        log_info_string = '(%s) %s deleted exploration %s' % (\n            self.role, self.user_id, exploration_id)\n        logging.info(log_info_string)\n        self.render_json(self.values)\n\n\nclass UserExplorationPermissionsHandler(EditorHandler):\n    \"\"\"Handles user permissions for a particular exploration.\"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_play_exploration\n    def get(self, exploration_id):\n        \"\"\"Gets the user permissions for an exploration.\"\"\"\n        exploration_rights = rights_manager.get_exploration_rights(\n            exploration_id)\n        self.values.update({\n            'can_delete': rights_manager.check_can_delete_activity(\n                self.user, exploration_rights),\n            'can_edit': rights_manager.check_can_edit_activity(\n                self.user, exploration_rights),\n            'can_modify_roles': (\n                rights_manager.check_can_modify_activity_roles(\n                    self.user, exploration_rights)),\n            'can_publish': rights_manager.check_can_publish_activity(\n                self.user, exploration_rights),\n            'can_release_ownership': (\n                rights_manager.check_can_release_ownership(\n                    self.user, exploration_rights)),\n            'can_voiceover': (\n                rights_manager.check_can_voiceover_activity(\n                    self.user, exploration_rights)),\n            'can_unpublish': rights_manager.check_can_unpublish_activity(\n                self.user, exploration_rights),\n        })\n        self.render_json(self.values)\n\n\nclass ExplorationRightsHandler(EditorHandler):\n    \"\"\"Handles management of exploration editing rights.\"\"\"\n\n    @acl_decorators.can_modify_exploration_roles\n    def put(self, exploration_id):\n        \"\"\"Updates the editing rights for the given exploration.\"\"\"\n        exploration = exp_fetchers.get_exploration_by_id(exploration_id)\n        version = self.payload.get('version')\n        _require_valid_version(version, exploration.version)\n\n        make_community_owned = self.payload.get('make_community_owned')\n        new_member_username = self.payload.get('new_member_username')\n        new_member_role = self.payload.get('new_member_role')\n        viewable_if_private = self.payload.get('viewable_if_private')\n\n        if new_member_username:\n            new_member_id = user_services.get_user_id_from_username(\n                new_member_username)\n            if new_member_id is None:\n                raise self.InvalidInputException(\n                    'Sorry, we could not find the specified user.')\n\n            rights_manager.assign_role_for_exploration(\n                self.user, exploration_id, new_member_id, new_member_role)\n            email_manager.send_role_notification_email(\n                self.user_id, new_member_id, new_member_role, exploration_id,\n                exploration.title)\n\n        elif make_community_owned:\n            exploration = exp_fetchers.get_exploration_by_id(exploration_id)\n            try:\n                exploration.validate(strict=True)\n            except utils.ValidationError as e:\n                raise self.InvalidInputException(e)\n\n            rights_manager.release_ownership_of_exploration(\n                self.user, exploration_id)\n\n        elif viewable_if_private is not None:\n            rights_manager.set_private_viewability_of_exploration(\n                self.user, exploration_id, viewable_if_private)\n\n        else:\n            raise self.InvalidInputException(\n                'No change was made to this exploration.')\n\n        self.render_json({\n            'rights': rights_manager.get_exploration_rights(\n                exploration_id).to_dict()\n        })\n\n\nclass ExplorationStatusHandler(EditorHandler):\n    \"\"\"Handles publishing of an exploration.\"\"\"\n\n    def _publish_exploration(self, exploration_id):\n        \"\"\"Publish an exploration.\n\n        Args:\n            exploration_id: str. Id of the exploration.\n\n        Raises:\n            InvalidInputException: Given exploration is invalid.\n        \"\"\"\n        exploration = exp_fetchers.get_exploration_by_id(exploration_id)\n        try:\n            exploration.validate(strict=True)\n        except utils.ValidationError as e:\n            raise self.InvalidInputException(e)\n\n        exp_services.publish_exploration_and_update_user_profiles(\n            self.user, exploration_id)\n        exp_services.index_explorations_given_ids([exploration_id])\n\n    @acl_decorators.can_publish_exploration\n    def put(self, exploration_id):\n        make_public = self.payload.get('make_public')\n\n        if make_public is not None:\n            self._publish_exploration(exploration_id)\n\n        self.render_json({\n            'rights': rights_manager.get_exploration_rights(\n                exploration_id).to_dict()\n        })\n\n\nclass ExplorationModeratorRightsHandler(EditorHandler):\n    \"\"\"Handles management of exploration rights by moderators.\"\"\"\n\n    @acl_decorators.can_access_moderator_page\n    def put(self, exploration_id):\n        \"\"\"Unpublishes the given exploration, and sends an email to all its\n        owners.\n        \"\"\"\n        exploration = exp_fetchers.get_exploration_by_id(exploration_id)\n        email_body = self.payload.get('email_body')\n        version = self.payload.get('version')\n        _require_valid_version(version, exploration.version)\n\n        # If moderator emails can be sent, check that all the prerequisites are\n        # satisfied, otherwise do nothing.\n        if feconf.REQUIRE_EMAIL_ON_MODERATOR_ACTION:\n            if not email_body:\n                raise self.InvalidInputException(\n                    'Moderator actions should include an email to the '\n                    'recipient.')\n            email_manager.require_moderator_email_prereqs_are_satisfied()\n\n        # Unpublish exploration.\n        rights_manager.unpublish_exploration(self.user, exploration_id)\n        search_services.delete_explorations_from_search_index([exploration_id])\n        exp_rights = rights_manager.get_exploration_rights(exploration_id)\n\n        # If moderator emails can be sent, send an email to the all owners of\n        # the exploration notifying them of the change.\n        if feconf.REQUIRE_EMAIL_ON_MODERATOR_ACTION:\n            for owner_id in exp_rights.owner_ids:\n                email_manager.send_moderator_action_email(\n                    self.user_id, owner_id, 'unpublish_exploration',\n                    exploration.title, email_body)\n\n        self.render_json({\n            'rights': exp_rights.to_dict(),\n        })\n\n\nclass UserExplorationEmailsHandler(EditorHandler):\n    \"\"\"Handles management of user email notification preferences for this\n    exploration.\n    \"\"\"\n\n    @acl_decorators.can_edit_exploration\n    def put(self, exploration_id):\n        \"\"\"Updates the email notification preferences for the given exploration.\n\n        Args:\n            exploration_id: str. The exploration id.\n\n        Raises:\n            InvalidInputException: Invalid message type.\n        \"\"\"\n\n        mute = self.payload.get('mute')\n        message_type = self.payload.get('message_type')\n\n        if message_type == feconf.MESSAGE_TYPE_FEEDBACK:\n            user_services.set_email_preferences_for_exploration(\n                self.user_id, exploration_id, mute_feedback_notifications=mute)\n        elif message_type == feconf.MESSAGE_TYPE_SUGGESTION:\n            user_services.set_email_preferences_for_exploration(\n                self.user_id, exploration_id,\n                mute_suggestion_notifications=mute)\n        else:\n            raise self.InvalidInputException(\n                'Invalid message type.')\n\n        exploration_email_preferences = (\n            user_services.get_email_preferences_for_exploration(\n                self.user_id, exploration_id))\n        self.render_json({\n            'email_preferences': exploration_email_preferences.to_dict()\n        })\n\n\nclass ExplorationFileDownloader(EditorHandler):\n    \"\"\"Downloads an exploration as a zip file, or dict of YAML strings\n    representing states.\n    \"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_DOWNLOADABLE\n\n    @acl_decorators.can_download_exploration\n    def get(self, exploration_id):\n        \"\"\"Handles GET requests.\"\"\"\n        exploration = exp_fetchers.get_exploration_by_id(exploration_id)\n\n        version_str = self.request.get('v', default_value=exploration.version)\n        output_format = self.request.get('output_format', default_value='zip')\n\n        try:\n            version = int(version_str)\n        except ValueError:\n            version = exploration.version\n\n        # If the title of the exploration has changed, we use the new title.\n        filename = utils.to_ascii(\n            'oppia-%s-v%s.zip'\n            % (exploration.title.replace(' ', ''), version)).decode('utf-8')\n\n        if output_format == feconf.OUTPUT_FORMAT_ZIP:\n            self.render_downloadable_file(\n                exp_services.export_to_zip_file(\n                    exploration_id, version=version),\n                filename, 'text/plain')\n        elif output_format == feconf.OUTPUT_FORMAT_JSON:\n            self.render_json(exp_services.export_states_to_yaml(\n                exploration_id, version=version))\n        else:\n            raise self.InvalidInputException(\n                'Unrecognized output format %s' % output_format)\n\n\nclass StateYamlHandler(EditorHandler):\n    \"\"\"Given a representation of a state, converts it to a YAML string.\n\n    Note that this handler is stateless; it does not make use of the storage\n    layer.\n    \"\"\"\n\n    @acl_decorators.can_play_exploration\n    def post(self, unused_exploration_id):\n        \"\"\"Handles POST requests.\"\"\"\n        state_dict = self.payload.get('state_dict')\n        width = self.payload.get('width')\n\n        if not width or not state_dict:\n            raise self.PageNotFoundException\n\n        self.render_json({\n            'yaml': state_domain.State.convert_state_dict_to_yaml(\n                state_dict, width),\n        })\n\n\nclass ExplorationSnapshotsHandler(EditorHandler):\n    \"\"\"Returns the exploration snapshot history.\"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_play_exploration\n    def get(self, exploration_id):\n        \"\"\"Handles GET requests.\"\"\"\n\n        snapshots = exp_services.get_exploration_snapshots_metadata(\n            exploration_id)\n\n        # Patch `snapshots` to use the editor's display name.\n        snapshots_committer_ids = [\n            snapshot['committer_id'] for snapshot in snapshots]\n        committer_usernames = user_services.get_usernames(\n            snapshots_committer_ids)\n        for index, snapshot in enumerate(snapshots):\n            snapshot['committer_id'] = committer_usernames[index]\n\n        self.render_json({\n            'snapshots': snapshots,\n        })\n\n\nclass ExplorationRevertHandler(EditorHandler):\n    \"\"\"Reverts an exploration to an older version.\"\"\"\n\n    @acl_decorators.can_edit_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\"\"\"\n        current_version = self.payload.get('current_version')\n        revert_to_version = self.payload.get('revert_to_version')\n\n        if not isinstance(revert_to_version, int):\n            raise self.InvalidInputException(\n                'Expected an integer version to revert to; received %s.' %\n                revert_to_version)\n        if not isinstance(current_version, int):\n            raise self.InvalidInputException(\n                'Expected an integer current version; received %s.' %\n                current_version)\n\n        if revert_to_version < 1 or revert_to_version >= current_version:\n            raise self.InvalidInputException(\n                'Cannot revert to version %s from version %s.' %\n                (revert_to_version, current_version))\n\n        exp_services.discard_draft(exploration_id, self.user_id)\n        exp_services.revert_exploration(\n            self.user_id, exploration_id, current_version, revert_to_version)\n        self.render_json({})\n\n\nclass ExplorationStatisticsHandler(EditorHandler):\n    \"\"\"Returns statistics for an exploration. This is the handler for the new\n    statistics framework.\n    \"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_view_exploration_stats\n    def get(self, exploration_id):\n        \"\"\"Handles GET requests.\"\"\"\n        current_exploration = exp_fetchers.get_exploration_by_id(\n            exploration_id)\n\n        self.render_json(stats_services.get_exploration_stats(\n            exploration_id, current_exploration.version).to_frontend_dict())\n\n\nclass StateRulesStatsHandler(EditorHandler):\n    \"\"\"Returns detailed learner answer statistics for a state.\"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_view_exploration_stats\n    def get(self, exploration_id, escaped_state_name):\n        \"\"\"Handles GET requests.\"\"\"\n        current_exploration = exp_fetchers.get_exploration_by_id(\n            exploration_id)\n\n        state_name = utils.unescape_encoded_uri_component(escaped_state_name)\n        if state_name not in current_exploration.states:\n            logging.error('Could not find state: %s' % state_name)\n            logging.error('Available states: %s' % (\n                list(current_exploration.states.keys())))\n            raise self.PageNotFoundException\n\n        self.render_json({\n            'visualizations_info': stats_services.get_visualizations_info(\n                current_exploration.id, state_name,\n                current_exploration.states[state_name].interaction.id),\n        })\n\n\nclass FetchIssuesHandler(EditorHandler):\n    \"\"\"Handler used for retrieving the list of unresolved issues in an\n    exploration. This removes the invalid issues and returns the remaining\n    unresolved ones.\n    \"\"\"\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_view_exploration_stats\n    def get(self, exp_id):\n        \"\"\"Handles GET requests.\"\"\"\n        exp_version = self.request.get('exp_version')\n        exp_issues = stats_services.get_exp_issues(exp_id, exp_version)\n        if exp_issues is None:\n            raise self.PageNotFoundException(\n                'Invalid version %s for exploration ID %s'\n                % (exp_version, exp_id))\n        unresolved_issues = []\n        for issue in exp_issues.unresolved_issues:\n            if issue.is_valid:\n                unresolved_issues.append(issue)\n        exp_issues.unresolved_issues = unresolved_issues\n        exp_issues_dict = exp_issues.to_dict()\n        self.render_json(exp_issues_dict['unresolved_issues'])\n\n\nclass FetchPlaythroughHandler(EditorHandler):\n    \"\"\"Handler used for retrieving a playthrough.\"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_view_exploration_stats\n    def get(self, unused_exploration_id, playthrough_id):\n        \"\"\"Handles GET requests.\"\"\"\n        playthrough = stats_services.get_playthrough_by_id(playthrough_id)\n        if playthrough is None:\n            raise self.PageNotFoundException(\n                'Invalid playthrough ID %s' % (playthrough_id))\n        self.render_json(playthrough.to_dict())\n\n\nclass ResolveIssueHandler(EditorHandler):\n    \"\"\"Handler used for resolving an issue. Currently, when an issue is\n    resolved, the issue is removed from the unresolved issues list in the\n    ExplorationIssuesModel instance, and all corresponding playthrough\n    instances are deleted.\n    \"\"\"\n\n    @acl_decorators.can_edit_exploration\n    def post(self, exp_id):\n        \"\"\"Handles POST requests.\"\"\"\n        exp_issue_dict = self.payload.get('exp_issue_dict')\n        try:\n            unused_exp_issue = stats_domain.ExplorationIssue.from_dict(\n                exp_issue_dict)\n        except utils.ValidationError as e:\n            raise self.PageNotFoundException(e)\n\n        exp_version = self.payload.get('exp_version')\n\n        exp_issues = stats_services.get_exp_issues(exp_id, exp_version)\n        if exp_issues is None:\n            raise self.PageNotFoundException(\n                'Invalid exploration ID %s' % (exp_id))\n\n        # Check that the passed in issue actually exists in the exploration\n        # issues instance.\n        issue_to_remove = None\n        for issue in exp_issues.unresolved_issues:\n            if issue.to_dict() == exp_issue_dict:\n                issue_to_remove = issue\n                break\n\n        if not issue_to_remove:\n            raise self.PageNotFoundException(\n                'Exploration issue does not exist in the list of issues for '\n                'the exploration with ID %s' % exp_id)\n\n        # Remove the issue from the unresolved issues list.\n        exp_issues.unresolved_issues.remove(issue_to_remove)\n\n        # Update the exploration issues instance and delete the playthrough\n        # instances.\n        stats_services.delete_playthroughs_multi(\n            issue_to_remove.playthrough_ids)\n        stats_services.save_exp_issues_model_transactional(exp_issues)\n\n        self.render_json({})\n\n\nclass ImageUploadHandler(EditorHandler):\n    \"\"\"Handles image uploads.\"\"\"\n\n    # The string to prefix to the filename (before tacking the whole thing on\n    # to the end of 'assets/').\n    _FILENAME_PREFIX = 'image'\n    _decorator = None\n\n    @acl_decorators.can_edit_entity\n    def post(self, entity_type, entity_id):\n        \"\"\"Saves an image uploaded by a content creator.\"\"\"\n\n        raw = self.request.get('image')\n        filename = self.payload.get('filename')\n        if not raw:\n            raise self.InvalidInputException('No image supplied')\n\n        allowed_formats = ', '.join(\n            list(feconf.ACCEPTED_IMAGE_FORMATS_AND_EXTENSIONS.keys()))\n\n        # Verify that the data is recognized as an image.\n        file_format = imghdr.what(None, h=raw)\n        if file_format not in feconf.ACCEPTED_IMAGE_FORMATS_AND_EXTENSIONS:\n            raise self.InvalidInputException('Image not recognized')\n\n        # Verify that the file type matches the supplied extension.\n        if not filename:\n            raise self.InvalidInputException('No filename supplied')\n        if filename.rfind('.') == 0:\n            raise self.InvalidInputException('Invalid filename')\n        if '/' in filename or '..' in filename:\n            raise self.InvalidInputException(\n                'Filenames should not include slashes (/) or consecutive '\n                'dot characters.')\n        if '.' not in filename:\n            raise self.InvalidInputException(\n                'Image filename with no extension: it should have '\n                'one of the following extensions: %s.' % allowed_formats)\n\n        dot_index = filename.rfind('.')\n        extension = filename[dot_index + 1:].lower()\n        if (extension not in\n                feconf.ACCEPTED_IMAGE_FORMATS_AND_EXTENSIONS[file_format]):\n            raise self.InvalidInputException(\n                'Expected a filename ending in .%s, received %s' %\n                (file_format, filename))\n\n        file_system_class = fs_services.get_entity_file_system_class()\n        fs = fs_domain.AbstractFileSystem(file_system_class(\n            entity_type, entity_id))\n        filepath = '%s/%s' % (self._FILENAME_PREFIX, filename)\n\n        if fs.isfile(filepath):\n            raise self.InvalidInputException(\n                'A file with the name %s already exists. Please choose a '\n                'different name.' % filename)\n\n        fs_services.save_original_and_compressed_versions_of_image(\n            self.user_id, filename, entity_type, entity_id, raw)\n\n        self.render_json({'filename': filename})\n\n\nclass StartedTutorialEventHandler(EditorHandler):\n    \"\"\"Records that this user has started the state editor tutorial.\"\"\"\n\n    @acl_decorators.can_play_exploration\n    def post(self, unused_exploration_id):\n        \"\"\"Handles GET requests.\"\"\"\n        user_services.record_user_started_state_editor_tutorial(self.user_id)\n        self.render_json({})\n\n\nclass EditorAutosaveHandler(ExplorationHandler):\n    \"\"\"Handles requests from the editor for draft autosave.\"\"\"\n\n    @acl_decorators.can_save_exploration\n    def put(self, exploration_id):\n        \"\"\"Handles PUT requests for draft updation.\"\"\"\n        # Raise an Exception if the draft change list fails non-strict\n        # validation.\n        try:\n            change_list_dict = self.payload.get('change_list')\n            change_list = [\n                exp_domain.ExplorationChange(change)\n                for change in change_list_dict]\n            version = self.payload.get('version')\n\n            exploration_rights = rights_manager.get_exploration_rights(\n                exploration_id)\n            can_edit = rights_manager.check_can_edit_activity(\n                self.user, exploration_rights)\n            can_voiceover = rights_manager.check_can_voiceover_activity(\n                self.user, exploration_rights)\n            if can_edit:\n                exp_services.create_or_update_draft(\n                    exploration_id, self.user_id, change_list, version,\n                    datetime.datetime.utcnow())\n            elif can_voiceover:\n                exp_services.create_or_update_draft(\n                    exploration_id, self.user_id, change_list, version,\n                    datetime.datetime.utcnow(), is_by_voice_artist=True)\n\n        except utils.ValidationError as e:\n            # We leave any pre-existing draft changes in the datastore.\n            raise self.InvalidInputException(e)\n        exp_user_data = user_models.ExplorationUserDataModel.get(\n            self.user_id, exploration_id)\n        draft_change_list_id = exp_user_data.draft_change_list_id\n        # If the draft_change_list_id is False, have the user discard the draft\n        # changes. We save the draft to the datastore even if the version is\n        # invalid, so that it is available for recovery later.\n        self.render_json({\n            'draft_change_list_id': draft_change_list_id,\n            'is_version_of_draft_valid': exp_services.is_version_of_draft_valid(\n                exploration_id, version)})\n\n    @acl_decorators.can_save_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST request for discarding draft changes.\"\"\"\n        exp_services.discard_draft(exploration_id, self.user_id)\n        self.render_json({})\n\n\nclass StateAnswerStatisticsHandler(EditorHandler):\n    \"\"\"Returns basic learner answer statistics for a state.\"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_view_exploration_stats\n    def get(self, exploration_id):\n        \"\"\"Handles GET requests.\"\"\"\n        current_exploration = exp_fetchers.get_exploration_by_id(exploration_id)\n\n        top_state_answers = stats_services.get_top_state_answer_stats_multi(\n            exploration_id, current_exploration.states)\n        top_state_interaction_ids = {\n            state_name: current_exploration.states[state_name].interaction.id\n            for state_name in top_state_answers\n        }\n        self.render_json({\n            'answers': top_state_answers,\n            'interaction_ids': top_state_interaction_ids,\n        })\n\n\nclass TopUnresolvedAnswersHandler(EditorHandler):\n    \"\"\"Returns a list of top N unresolved answers.\"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_edit_exploration\n    def get(self, exploration_id):\n        \"\"\"Handles GET requests for unresolved answers.\"\"\"\n        state_name = self.request.get('state_name')\n        if not state_name:\n            raise self.PageNotFoundException\n\n        unresolved_answers_with_frequency = (\n            stats_services.get_top_state_unresolved_answers(\n                exploration_id, state_name))\n\n        self.render_json({\n            'unresolved_answers': unresolved_answers_with_frequency\n        })\n\n\nclass LearnerAnswerInfoHandler(EditorHandler):\n    \"\"\"Handles the learner answer info for an exploration state.\"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_play_entity\n    def get(self, entity_type, entity_id):\n        \"\"\"Handles the GET requests for learner answer info for an\n        exploration state.\n        \"\"\"\n        if not constants.ENABLE_SOLICIT_ANSWER_DETAILS_FEATURE:\n            raise self.PageNotFoundException\n\n        learner_answer_info_data = []\n\n        if entity_type == feconf.ENTITY_TYPE_EXPLORATION:\n            exp = exp_fetchers.get_exploration_by_id(entity_id)\n            for state_name in exp.states:\n                state_reference = (\n                    stats_services.get_state_reference_for_exploration(\n                        entity_id, state_name))\n                learner_answer_details = (\n                    stats_services.get_learner_answer_details(\n                        feconf.ENTITY_TYPE_EXPLORATION, state_reference))\n                if learner_answer_details is not None:\n                    learner_answer_info_data.append({\n                        'state_name': state_name,\n                        'interaction_id': learner_answer_details.interaction_id,\n                        'customization_args': exp.states[state_name].interaction\n                                              .to_dict()['customization_args'],\n                        'learner_answer_info_dicts': [\n                            learner_answer_info.to_dict() for\n                            learner_answer_info in\n                            learner_answer_details.learner_answer_info_list]\n                    })\n        elif entity_type == feconf.ENTITY_TYPE_QUESTION:\n            question = question_services.get_question_by_id(entity_id)\n            state_reference = stats_services.get_state_reference_for_question(\n                entity_id)\n            learner_answer_details = stats_services.get_learner_answer_details(\n                feconf.ENTITY_TYPE_QUESTION, state_reference)\n            if learner_answer_details is not None:\n                learner_answer_info_dicts = [\n                    learner_answer_info.to_dict() for learner_answer_info in\n                    learner_answer_details.learner_answer_info_list]\n            learner_answer_info_data = {\n                'interaction_id': learner_answer_details.interaction_id,\n                'customization_args': question.question_state_data.interaction\n                                      .to_dict()['customization_args'],\n                'learner_answer_info_dicts': learner_answer_info_dicts\n            }\n\n        self.render_json({\n            'learner_answer_info_data': learner_answer_info_data\n        })\n\n    @acl_decorators.can_edit_entity\n    def delete(self, entity_type, entity_id):\n        \"\"\"Deletes the learner answer info by the given id.\"\"\"\n\n        if not constants.ENABLE_SOLICIT_ANSWER_DETAILS_FEATURE:\n            raise self.PageNotFoundException\n\n        if entity_type == feconf.ENTITY_TYPE_EXPLORATION:\n            state_name = self.request.get('state_name')\n            if not state_name:\n                raise self.InvalidInputException\n            state_reference = (\n                stats_services.get_state_reference_for_exploration(\n                    entity_id, state_name))\n        elif entity_type == feconf.ENTITY_TYPE_QUESTION:\n            state_reference = (\n                stats_services.get_state_reference_for_question(\n                    entity_id))\n        learner_answer_info_id = self.request.get('learner_answer_info_id')\n        if not learner_answer_info_id:\n            raise self.PageNotFoundException\n        stats_services.delete_learner_answer_info(\n            entity_type, state_reference, learner_answer_info_id)\n        self.render_json({})\n"
    },
    {
      "filename": "core/controllers/reader.py",
      "content": "# Copyright 2014 The Oppia Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Controllers for the Oppia exploration learner view.\"\"\"\nfrom __future__ import absolute_import  # pylint: disable=import-only-modules\nfrom __future__ import unicode_literals  # pylint: disable=import-only-modules\n\nimport json\nimport logging\nimport random\n\nfrom constants import constants\nfrom core.controllers import acl_decorators\nfrom core.controllers import base\nfrom core.domain import classifier_services\nfrom core.domain import collection_services\nfrom core.domain import config_domain\nfrom core.domain import event_services\nfrom core.domain import exp_fetchers\nfrom core.domain import exp_services\nfrom core.domain import feedback_services\nfrom core.domain import interaction_registry\nfrom core.domain import learner_progress_services\nfrom core.domain import moderator_services\nfrom core.domain import question_fetchers\nfrom core.domain import question_services\nfrom core.domain import rating_services\nfrom core.domain import recommendations_services\nfrom core.domain import rights_manager\nfrom core.domain import stats_domain\nfrom core.domain import stats_services\nfrom core.domain import story_fetchers\nfrom core.domain import summary_services\nfrom core.domain import user_services\nfrom core.platform import models\nimport feconf\nimport utils\n\n(stats_models,) = models.Registry.import_models([models.NAMES.statistics])\n\nMAX_SYSTEM_RECOMMENDATIONS = 4\n\n\ndef _get_exploration_player_data(\n        exploration_id, version, collection_id, can_edit):\n    \"\"\"Returns a dict of exploration player data.\n\n    Args:\n        exploration_id: str. The ID of the exploration.\n        version: int or None. The version of the exploration.\n        collection_id: str. ID of the collection.\n        can_edit: bool. Whether the given user can edit this activity.\n\n    Returns:\n        dict. A dict of exploration player data.\n        The keys and values of the dict are as follows:\n        - 'can_edit': bool. Whether the given user can edit this activity.\n        - 'exploration_title': str. Title of exploration.\n        - 'exploration_version': int. The version of the exploration.\n        - 'collection_id': str. ID of the collection.\n        - 'collection_title': str. Title of collection.\n            required by the given exploration ID.\n        - 'is_private': bool. Whether the exploration is private or not.\n        - 'meta_name': str. Title of exploration.\n        - 'meta_description': str. Objective of exploration.\n    \"\"\"\n    try:\n        exploration = exp_fetchers.get_exploration_by_id(\n            exploration_id, version=version)\n    except Exception:\n        raise Exception\n\n    collection_title = None\n    if collection_id:\n        try:\n            collection = collection_services.get_collection_by_id(\n                collection_id)\n            collection_title = collection.title\n        except Exception:\n            raise Exception\n\n    version = exploration.version\n\n    return {\n        'can_edit': can_edit,\n        'exploration_title': exploration.title,\n        'exploration_version': version,\n        'collection_id': collection_id,\n        'collection_title': collection_title,\n        'is_private': rights_manager.is_exploration_private(\n            exploration_id),\n        # Note that this overwrites the value in base.py.\n        'meta_name': exploration.title,\n        # Note that this overwrites the value in base.py.\n        'meta_description': utils.capitalize_string(exploration.objective),\n    }\n\n\nclass ExplorationEmbedPage(base.BaseHandler):\n    \"\"\"Page describing a single embedded exploration.\"\"\"\n\n    @acl_decorators.can_play_exploration\n    def get(self, exploration_id):\n        \"\"\"Handles GET requests.\n\n        Args:\n            exploration_id: str. The ID of the exploration.\n        \"\"\"\n        version_str = self.request.get('v')\n        version = int(version_str) if version_str else None\n        exploration_rights = rights_manager.get_exploration_rights(\n            exploration_id, strict=False)\n\n        # Note: this is an optional argument and will be None when the\n        # exploration is being played outside the context of a collection.\n        collection_id = self.request.get('collection_id')\n        can_edit = rights_manager.check_can_edit_activity(\n            self.user, exploration_rights)\n\n        # This check is needed in order to show the correct page when a 404\n        # error is raised. The self.request.get('iframed') part of the check is\n        # needed for backwards compatibility with older versions of the\n        # embedding script.\n        if (feconf.EXPLORATION_URL_EMBED_PREFIX in self.request.uri or\n                self.request.get('iframed')):\n            self.values['iframed'] = True\n        try:\n            # If the exploration does not exist, a 404 error is raised.\n            exploration_data_values = _get_exploration_player_data(\n                exploration_id, version, collection_id, can_edit)\n        except Exception:\n            raise self.PageNotFoundException\n\n        self.values.update(exploration_data_values)\n        self.values['iframed'] = True\n        self.render_template(\n            'exploration-player-page.mainpage.html',\n            iframe_restriction=None)\n\n\nclass ExplorationPage(base.BaseHandler):\n    \"\"\"Page describing a single exploration.\"\"\"\n\n    @acl_decorators.can_play_exploration\n    def get(self, exploration_id):\n        \"\"\"Handles GET requests.\n\n        Args:\n            exploration_id: str. The ID of the exploration.\n        \"\"\"\n        version_str = self.request.get('v')\n        version = int(version_str) if version_str else None\n        exploration_rights = rights_manager.get_exploration_rights(\n            exploration_id, strict=False)\n\n        if self.request.get('iframed'):\n            redirect_url = '/embed/exploration/%s' % exploration_id\n            if version_str:\n                redirect_url += '?v=%s' % version_str\n            self.redirect(redirect_url)\n            return\n\n        # Note: this is an optional argument and will be None when the\n        # exploration is being played outside the context of a collection or if\n        # the 'parent' parameter is present.\n        if self.request.get('parent'):\n            collection_id = None\n        else:\n            collection_id = self.request.get('collection_id')\n        can_edit = rights_manager.check_can_edit_activity(\n            self.user, exploration_rights)\n\n        try:\n            # If the exploration does not exist, a 404 error is raised.\n            exploration_data_values = _get_exploration_player_data(\n                exploration_id, version, collection_id, can_edit)\n        except Exception:\n            raise self.PageNotFoundException\n\n        self.values.update(exploration_data_values)\n        self.values['iframed'] = False\n        self.render_template(\n            'exploration-player-page.mainpage.html')\n\n\nclass ExplorationHandler(base.BaseHandler):\n    \"\"\"Provides the initial data for a single exploration.\"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_play_exploration\n    def get(self, exploration_id):\n        \"\"\"Populates the data on the individual exploration page.\n\n        Args:\n            exploration_id: str. The ID of the exploration.\n        \"\"\"\n        version = self.request.get('v')\n        version = int(version) if version else None\n\n        try:\n            exploration = exp_fetchers.get_exploration_by_id(\n                exploration_id, version=version)\n        except Exception as e:\n            raise self.PageNotFoundException(e)\n\n        exploration_rights = rights_manager.get_exploration_rights(\n            exploration_id, strict=False)\n        user_settings = user_services.get_user_settings(self.user_id)\n\n        preferred_audio_language_code = None\n        if user_settings is not None:\n            preferred_audio_language_code = (\n                user_settings.preferred_audio_language_code)\n\n        # Retrieve all classifiers for the exploration.\n        state_classifier_mapping = {}\n        classifier_training_jobs = (\n            classifier_services.get_classifier_training_jobs(\n                exploration_id, exploration.version,\n                list(exploration.states.keys())))\n        for index, state_name in enumerate(exploration.states.keys()):\n            if classifier_training_jobs[index] is not None:\n                classifier_data = classifier_training_jobs[\n                    index].classifier_data\n                algorithm_id = classifier_training_jobs[index].algorithm_id\n                data_schema_version = (\n                    classifier_training_jobs[index].data_schema_version)\n                state_classifier_mapping[state_name] = {\n                    'algorithm_id': algorithm_id,\n                    'classifier_data': classifier_data,\n                    'data_schema_version': data_schema_version\n                }\n\n        self.values.update({\n            'can_edit': (\n                rights_manager.check_can_edit_activity(\n                    self.user, exploration_rights)),\n            'exploration': exploration.to_player_dict(),\n            'exploration_id': exploration_id,\n            'is_logged_in': bool(self.user_id),\n            'session_id': utils.generate_new_session_id(),\n            'version': exploration.version,\n            'preferred_audio_language_code': preferred_audio_language_code,\n            'state_classifier_mapping': state_classifier_mapping,\n            'auto_tts_enabled': exploration.auto_tts_enabled,\n            'correctness_feedback_enabled': (\n                exploration.correctness_feedback_enabled),\n            'record_playthrough_probability': (\n                config_domain.RECORD_PLAYTHROUGH_PROBABILITY.value),\n        })\n        self.render_json(self.values)\n\n\nclass PretestHandler(base.BaseHandler):\n    \"\"\"Provides subsequent pretest questions after initial batch.\"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_play_exploration\n    def get(self, exploration_id):\n        \"\"\"Handles GET request.\"\"\"\n        start_cursor = self.request.get('cursor')\n        story_id = self.request.get('story_id')\n        story = story_fetchers.get_story_by_id(story_id, strict=False)\n        if story is None:\n            raise self.InvalidInputException\n        if not story.has_exploration(exploration_id):\n            raise self.InvalidInputException\n        pretest_questions, _, next_start_cursor = (\n            question_fetchers.get_questions_and_skill_descriptions_by_skill_ids(\n                feconf.NUM_PRETEST_QUESTIONS,\n                story.get_prerequisite_skill_ids_for_exp_id(exploration_id),\n                start_cursor)\n        )\n        question_dicts = [question.to_dict() for question in pretest_questions]\n\n        self.values.update({\n            'pretest_question_dicts': question_dicts,\n            'next_start_cursor': next_start_cursor\n        })\n        self.render_json(self.values)\n\n\nclass StorePlaythroughHandler(base.BaseHandler):\n    \"\"\"Handles a useful playthrough coming in from the frontend to store it. If\n    the playthrough already exists, it is updated in the datastore.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"Method that initializes member variables for the handler.\n\n        Attributes:\n            current_exp_issues: ExplorationIssues. The exploration issues domain\n                object.\n            current_issue_schema_version: int. The issue schema version.\n            current_playthrough_id: str|None. The Playthrough ID or None.\n        \"\"\"\n        super(StorePlaythroughHandler, self).__init__(*args, **kwargs)\n        self.current_exp_issues = None\n        self.current_issue_schema_version = None\n        self.current_playthrough_id = None\n\n    def _find_matching_issue_in_exp_issues(self, playthrough):\n        \"\"\"Finds an issue with the equivalent issue_type and associated states\n        as the given playthrough in the unresolved issues list of the\n        exploration issues model.\n\n        Args:\n            playthrough: Playthrough. The playthrough domain object.\n\n        Returns:\n            int|None. The index at which the issue was found, None otherwise.\n        \"\"\"\n        for index, issue in enumerate(\n                self.current_exp_issues.unresolved_issues):\n            if issue.issue_type == playthrough.issue_type:\n                issue_customization_args = issue.issue_customization_args\n                # In case issue_keyname is 'state_names', the ordering of the\n                # list is important i.e. [a,b,c] is different from [b,c,a].\n                issue_keyname = stats_models.ISSUE_TYPE_KEYNAME_MAPPING[\n                    issue.issue_type]\n                if (issue_customization_args[issue_keyname] ==\n                        playthrough.issue_customization_args[issue_keyname]):\n                    return index\n        return None\n\n    def _move_playthrough_to_correct_issue(self, playthrough, orig_playthrough):\n        \"\"\"Moves the updated playthrough to its correct issue in the unresolved\n        issues list.\n\n        Args:\n            playthrough: Playthrough. The updated playthrough domain object.\n            orig_playthrough: Playthrough. The original playthrough domain\n                object which is in the now-incorrect issue list.\n        \"\"\"\n        did_move_playthrough_to_new_issue = False\n        issue_index = self._find_matching_issue_in_exp_issues(playthrough)\n        # Check whether the playthrough can be added to its new issue,\n        # if not, it stays in its old issue.\n        if issue_index is not None:\n            issue = self.current_exp_issues.unresolved_issues[issue_index]\n            if len(issue.playthrough_ids) < feconf.MAX_PLAYTHROUGHS_FOR_ISSUE:\n                issue.playthrough_ids.append(self.current_playthrough_id)\n                did_move_playthrough_to_new_issue = True\n        else:\n            issue = stats_domain.ExplorationIssue(\n                playthrough.issue_type,\n                playthrough.issue_customization_args,\n                [self.current_playthrough_id],\n                self.current_issue_schema_version, is_valid=True)\n            self.current_exp_issues.unresolved_issues.append(issue)\n            did_move_playthrough_to_new_issue = True\n\n        # Now, remove the playthrough from its old issue.\n        if did_move_playthrough_to_new_issue:\n            orig_issue_index = self._find_matching_issue_in_exp_issues(\n                orig_playthrough)\n            if orig_issue_index is not None:\n                self.current_exp_issues.unresolved_issues[\n                    orig_issue_index].playthrough_ids.remove(\n                        self.current_playthrough_id)\n\n    def _assign_playthrough_to_issue(self, playthrough):\n        \"\"\"Assigns newly created playthrough to its correct issue or makes a new\n        issue.\n\n        Args:\n            playthrough: Playthrough. The playthrough domain object.\n\n        Raises:\n            Exception. Maximum playthroughs per issue reached.\n\n        Returns:\n            playthrough_id: int. The playthrough ID.\n        \"\"\"\n        # Find whether an issue already exists for the new playthrough.\n        issue_index = self._find_matching_issue_in_exp_issues(playthrough)\n        if issue_index is not None:\n            issue = self.current_exp_issues.unresolved_issues[issue_index]\n            if len(issue.playthrough_ids) < feconf.MAX_PLAYTHROUGHS_FOR_ISSUE:\n                actions = [action.to_dict() for action in playthrough.actions]\n                playthrough_id = stats_models.PlaythroughModel.create(\n                    playthrough.exp_id, playthrough.exp_version,\n                    playthrough.issue_type,\n                    playthrough.issue_customization_args, actions)\n                issue.playthrough_ids.append(playthrough_id)\n            else:\n                raise Exception('Maximum playthroughs per issue reached.')\n        else:\n            actions = [action.to_dict() for action in playthrough.actions]\n            playthrough_id = stats_models.PlaythroughModel.create(\n                playthrough.exp_id, playthrough.exp_version,\n                playthrough.issue_type,\n                playthrough.issue_customization_args, actions)\n            issue = stats_domain.ExplorationIssue(\n                playthrough.issue_type,\n                playthrough.issue_customization_args,\n                [playthrough_id], self.current_issue_schema_version,\n                is_valid=True)\n\n            self.current_exp_issues.unresolved_issues.append(issue)\n\n        return playthrough_id\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests. Appends to existing list of playthroughs or\n        deletes it if already full.\n\n        Args:\n            exploration_id: str. The ID of the exploration.\n        \"\"\"\n        playthrough_data = self.payload.get('playthrough_data')\n        try:\n            unused_playthrough = stats_domain.Playthrough.from_dict(\n                playthrough_data)\n        except utils.ValidationError as e:\n            raise self.InvalidInputException(e)\n\n        try:\n            self.current_issue_schema_version = self.payload[\n                'issue_schema_version']\n        except KeyError as e:\n            raise self.InvalidInputException(e)\n\n        try:\n            self.current_playthrough_id = self.payload['playthrough_id']\n        except KeyError as e:\n            raise self.InvalidInputException(e)\n\n        exp_version = playthrough_data['exp_version']\n\n        exp_issues_model = stats_models.ExplorationIssuesModel.get_model(\n            exploration_id, exp_version)\n        self.current_exp_issues = stats_services.get_exp_issues_from_model(\n            exp_issues_model)\n\n        playthrough = stats_domain.Playthrough.from_dict(playthrough_data)\n\n        # If playthrough already exists, update it in the datastore.\n        if self.current_playthrough_id is not None:\n            orig_playthrough = stats_services.get_playthrough_by_id(\n                self.current_playthrough_id)\n            if orig_playthrough.issue_type != playthrough.issue_type:\n                self._move_playthrough_to_correct_issue(\n                    playthrough, orig_playthrough)\n\n            stats_services.update_playthroughs_multi(\n                [self.current_playthrough_id], [playthrough])\n            stats_services.save_exp_issues_model_transactional(\n                self.current_exp_issues)\n            self.render_json({})\n            return\n\n        payload_return = {'playthrough_stored': True}\n\n        playthrough_id = None\n        try:\n            playthrough_id = self._assign_playthrough_to_issue(playthrough)\n        except Exception:\n            payload_return['playthrough_stored'] = False\n\n        stats_services.save_exp_issues_model_transactional(\n            self.current_exp_issues)\n        payload_return['playthrough_id'] = playthrough_id\n        self.render_json(payload_return)\n\n\nclass StatsEventsHandler(base.BaseHandler):\n    \"\"\"Handles a batch of events coming in from the frontend.\"\"\"\n\n    REQUIRE_PAYLOAD_CSRF_CHECK = False\n\n    def _require_aggregated_stats_are_valid(self, aggregated_stats):\n        \"\"\"Checks whether the aggregated stats dict has the correct keys.\n\n        Args:\n            aggregated_stats: dict. Dict comprising of aggregated stats.\n        \"\"\"\n        exploration_stats_properties = [\n            'num_starts',\n            'num_actual_starts',\n            'num_completions'\n        ]\n        state_stats_properties = [\n            'total_answers_count',\n            'useful_feedback_count',\n            'total_hit_count',\n            'first_hit_count',\n            'num_times_solution_viewed',\n            'num_completions'\n        ]\n\n        for exp_stats_property in exploration_stats_properties:\n            if exp_stats_property not in aggregated_stats:\n                raise self.InvalidInputException(\n                    '%s not in aggregated stats dict.' % (exp_stats_property))\n        for state_name in aggregated_stats['state_stats_mapping']:\n            for state_stats_property in state_stats_properties:\n                if state_stats_property not in aggregated_stats[\n                        'state_stats_mapping'][state_name]:\n                    raise self.InvalidInputException(\n                        '%s not in state stats mapping of %s in aggregated '\n                        'stats dict.' % (state_stats_property, state_name))\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        aggregated_stats = self.payload.get('aggregated_stats')\n        exp_version = self.payload.get('exp_version')\n        if exp_version is None:\n            raise self.InvalidInputException(\n                'NONE EXP VERSION: Stats aggregation')\n        try:\n            self._require_aggregated_stats_are_valid(aggregated_stats)\n        except self.InvalidInputException as e:\n            logging.error(e)\n        event_services.StatsEventsHandler.record(\n            exploration_id, exp_version, aggregated_stats)\n        self.render_json({})\n\n\nclass AnswerSubmittedEventHandler(base.BaseHandler):\n    \"\"\"Tracks a learner submitting an answer.\"\"\"\n\n    REQUIRE_PAYLOAD_CSRF_CHECK = False\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\n\n        Args:\n            exploration_id: str. The ID of the exploration.\n        \"\"\"\n        old_state_name = self.payload.get('old_state_name')\n        # The reader's answer.\n        answer = self.payload.get('answer')\n        # Parameters associated with the learner.\n        params = self.payload.get('params', {})\n        # The version of the exploration.\n        version = self.payload.get('version')\n        if version is None:\n            raise self.InvalidInputException(\n                'NONE EXP VERSION: Answer Submit')\n        session_id = self.payload.get('session_id')\n        client_time_spent_in_secs = self.payload.get(\n            'client_time_spent_in_secs')\n        # The answer group and rule spec indexes, which will be used to get\n        # the rule spec string.\n        answer_group_index = self.payload.get('answer_group_index')\n        rule_spec_index = self.payload.get('rule_spec_index')\n        classification_categorization = self.payload.get(\n            'classification_categorization')\n\n        exploration = exp_fetchers.get_exploration_by_id(\n            exploration_id, version=version)\n\n        old_interaction = exploration.states[old_state_name].interaction\n\n        old_interaction_instance = (\n            interaction_registry.Registry.get_interaction_by_id(\n                old_interaction.id))\n\n        normalized_answer = old_interaction_instance.normalize_answer(answer)\n\n        event_services.AnswerSubmissionEventHandler.record(\n            exploration_id, version, old_state_name,\n            exploration.states[old_state_name].interaction.id,\n            answer_group_index, rule_spec_index, classification_categorization,\n            session_id, client_time_spent_in_secs, params, normalized_answer)\n        self.render_json({})\n\n\nclass StateHitEventHandler(base.BaseHandler):\n    \"\"\"Tracks a learner hitting a new state.\"\"\"\n\n    REQUIRE_PAYLOAD_CSRF_CHECK = False\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\n\n        Args:\n            exploration_id: str. The ID of the exploration.\n        \"\"\"\n        new_state_name = self.payload.get('new_state_name')\n        exploration_version = self.payload.get('exploration_version')\n        if exploration_version is None:\n            raise self.InvalidInputException(\n                'NONE EXP VERSION: State hit')\n        session_id = self.payload.get('session_id')\n        # TODO(sll): why do we not record the value of this anywhere?\n        client_time_spent_in_secs = self.payload.get(  # pylint: disable=unused-variable\n            'client_time_spent_in_secs')\n        old_params = self.payload.get('old_params')\n\n        # Record the state hit, if it is not the END state.\n        if new_state_name is not None:\n            event_services.StateHitEventHandler.record(\n                exploration_id, exploration_version, new_state_name,\n                session_id, old_params, feconf.PLAY_TYPE_NORMAL)\n        else:\n            logging.error('Unexpected StateHit event for the END state.')\n        self.render_json({})\n\n\nclass StateCompleteEventHandler(base.BaseHandler):\n    \"\"\"Tracks a learner complete a state. Here, 'completing' means answering\n    the state and progressing to a new state.\n    \"\"\"\n\n    REQUIRE_PAYLOAD_CSRF_CHECK = False\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\"\"\"\n        if self.payload.get('exp_version') is None:\n            raise self.InvalidInputException(\n                'NONE EXP VERSION: State Complete')\n        event_services.StateCompleteEventHandler.record(\n            exploration_id, self.payload.get('exp_version'),\n            self.payload.get('state_name'), self.payload.get('session_id'),\n            self.payload.get('time_spent_in_state_secs'))\n        self.render_json({})\n\n\nclass LeaveForRefresherExpEventHandler(base.BaseHandler):\n    \"\"\"Tracks a learner leaving an exploration for a refresher exploration.\"\"\"\n\n    REQUIRE_PAYLOAD_CSRF_CHECK = False\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\"\"\"\n        event_services.LeaveForRefresherExpEventHandler.record(\n            exploration_id, self.payload.get('refresher_exp_id'),\n            self.payload.get('exp_version'), self.payload.get('state_name'),\n            self.payload.get('session_id'),\n            self.payload.get('time_spent_in_state_secs'))\n        self.render_json({})\n\n\nclass ReaderFeedbackHandler(base.BaseHandler):\n    \"\"\"Submits feedback from the reader.\"\"\"\n\n    REQUIRE_PAYLOAD_CSRF_CHECK = False\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\n\n        Args:\n            exploration_id: str. The ID of the exploration.\n        \"\"\"\n        subject = self.payload.get('subject', 'Feedback from a learner')\n        feedback = self.payload.get('feedback')\n        include_author = self.payload.get('include_author')\n\n        feedback_services.create_thread(\n            feconf.ENTITY_TYPE_EXPLORATION,\n            exploration_id,\n            self.user_id if include_author else None,\n            subject,\n            feedback)\n        self.render_json(self.values)\n\n\nclass ExplorationStartEventHandler(base.BaseHandler):\n    \"\"\"Tracks a learner starting an exploration.\"\"\"\n\n    REQUIRE_PAYLOAD_CSRF_CHECK = False\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\n\n        Args:\n            exploration_id: str. The ID of the exploration.\n        \"\"\"\n        if self.payload.get('version') is None:\n            raise self.InvalidInputException(\n                'NONE EXP VERSION: Exploration start')\n        event_services.StartExplorationEventHandler.record(\n            exploration_id, self.payload.get('version'),\n            self.payload.get('state_name'),\n            self.payload.get('session_id'),\n            self.payload.get('params'),\n            feconf.PLAY_TYPE_NORMAL)\n        self.render_json({})\n\n\nclass ExplorationActualStartEventHandler(base.BaseHandler):\n    \"\"\"Tracks a learner actually starting an exploration. These are the learners\n    who traverse past the initial state.\n    \"\"\"\n\n    REQUIRE_PAYLOAD_CSRF_CHECK = False\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\"\"\"\n        if self.payload.get('exploration_version') is None:\n            raise self.InvalidInputException(\n                'NONE EXP VERSION: Actual Start')\n        event_services.ExplorationActualStartEventHandler.record(\n            exploration_id, self.payload.get('exploration_version'),\n            self.payload.get('state_name'), self.payload.get('session_id'))\n        self.render_json({})\n\n\nclass SolutionHitEventHandler(base.BaseHandler):\n    \"\"\"Tracks a learner clicking on the 'View Solution' button.\"\"\"\n\n    REQUIRE_PAYLOAD_CSRF_CHECK = False\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\"\"\"\n        if self.payload.get('exploration_version') is None:\n            raise self.InvalidInputException(\n                'NONE EXP VERSION: Solution hit')\n        event_services.SolutionHitEventHandler.record(\n            exploration_id, self.payload.get('exploration_version'),\n            self.payload.get('state_name'), self.payload.get('session_id'),\n            self.payload.get('time_spent_in_state_secs'))\n        self.render_json({})\n\n\nclass ExplorationCompleteEventHandler(base.BaseHandler):\n    \"\"\"Tracks a learner completing an exploration.\n\n    The state name recorded should be a state with a terminal interaction.\n    \"\"\"\n\n    REQUIRE_PAYLOAD_CSRF_CHECK = False\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\n\n        Args:\n            exploration_id: str. The ID of the exploration.\n        \"\"\"\n\n        # This will be None if the exploration is not being played within the\n        # context of a collection.\n        collection_id = self.payload.get('collection_id')\n        user_id = self.user_id\n\n        if self.payload.get('version') is None:\n            raise self.InvalidInputException(\n                'NONE EXP VERSION: Exploration complete')\n        event_services.CompleteExplorationEventHandler.record(\n            exploration_id,\n            self.payload.get('version'),\n            self.payload.get('state_name'),\n            self.payload.get('session_id'),\n            self.payload.get('client_time_spent_in_secs'),\n            self.payload.get('params'),\n            feconf.PLAY_TYPE_NORMAL)\n\n        if user_id:\n            learner_progress_services.mark_exploration_as_completed(\n                user_id, exploration_id)\n\n        if user_id and collection_id:\n            collection_services.record_played_exploration_in_collection_context(\n                user_id, collection_id, exploration_id)\n            next_exp_id_to_complete = (\n                collection_services.get_next_exploration_id_to_complete_by_user( # pylint: disable=line-too-long\n                    user_id, collection_id))\n\n            if not next_exp_id_to_complete:\n                learner_progress_services.mark_collection_as_completed(\n                    user_id, collection_id)\n            else:\n                learner_progress_services.mark_collection_as_incomplete(\n                    user_id, collection_id)\n\n        self.render_json(self.values)\n\n\nclass ExplorationMaybeLeaveHandler(base.BaseHandler):\n    \"\"\"Tracks a learner leaving an exploration without completing it.\n\n    The state name recorded should be a state with a non-terminal interaction.\n    \"\"\"\n\n    REQUIRE_PAYLOAD_CSRF_CHECK = False\n\n    @acl_decorators.can_play_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\n\n        Args:\n            exploration_id: str. The ID of the exploration.\n        \"\"\"\n        version = self.payload.get('version')\n        if version is None:\n            raise self.InvalidInputException(\n                'NONE EXP VERSION: Maybe quit')\n        state_name = self.payload.get('state_name')\n        user_id = self.user_id\n        collection_id = self.payload.get('collection_id')\n\n        if user_id:\n            learner_progress_services.mark_exploration_as_incomplete(\n                user_id, exploration_id, state_name, version)\n\n        if user_id and collection_id:\n            learner_progress_services.mark_collection_as_incomplete(\n                user_id, collection_id)\n\n        event_services.MaybeLeaveExplorationEventHandler.record(\n            exploration_id,\n            version,\n            state_name,\n            self.payload.get('session_id'),\n            self.payload.get('client_time_spent_in_secs'),\n            self.payload.get('params'),\n            feconf.PLAY_TYPE_NORMAL)\n        self.render_json(self.values)\n\n\nclass LearnerIncompleteActivityHandler(base.BaseHandler):\n    \"\"\"Handles operations related to the activities in the incomplete list of\n    the user.\n    \"\"\"\n    @acl_decorators.can_access_learner_dashboard\n    def delete(self, activity_type, activity_id):\n        \"\"\"Removes exploration or collection from incomplete list.\n\n        Args:\n            activity_type: str. The activity type. Currently, it can take values\n                \"exploration\" or \"collection\".\n            activity_id: str. The ID of the activity to be deleted.\n        \"\"\"\n        if activity_type == constants.ACTIVITY_TYPE_EXPLORATION:\n            learner_progress_services.remove_exp_from_incomplete_list(\n                self.user_id, activity_id)\n        elif activity_type == constants.ACTIVITY_TYPE_COLLECTION:\n            learner_progress_services.remove_collection_from_incomplete_list(\n                self.user_id, activity_id)\n\n        self.render_json(self.values)\n\n\nclass RatingHandler(base.BaseHandler):\n    \"\"\"Records the rating of an exploration submitted by a user.\n\n    Note that this represents ratings submitted on completion of the\n    exploration.\n    \"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_play_exploration\n    def get(self, exploration_id):\n        \"\"\"Handles GET requests.\"\"\"\n        self.values.update({\n            'overall_ratings':\n                rating_services.get_overall_ratings_for_exploration(\n                    exploration_id),\n            'user_rating': (\n                rating_services.get_user_specific_rating_for_exploration(\n                    self.user_id, exploration_id) if self.user_id else None)\n        })\n        self.render_json(self.values)\n\n    @acl_decorators.can_rate_exploration\n    def put(self, exploration_id):\n        \"\"\"Handles PUT requests for submitting ratings at the end of an\n        exploration.\n        \"\"\"\n        user_rating = self.payload.get('user_rating')\n        rating_services.assign_rating_to_exploration(\n            self.user_id, exploration_id, user_rating)\n        self.render_json({})\n\n\nclass RecommendationsHandler(base.BaseHandler):\n    \"\"\"Provides recommendations to be displayed at the end of explorations.\n    Which explorations are provided depends on whether the exploration was\n    played within the context of a collection and whether the user is logged in.\n    If both are true, then the explorations are suggested from the collection,\n    if there are upcoming explorations for the learner to complete.\n    \"\"\"\n\n    # TODO(bhenning): Move the recommendation selection logic & related tests\n    # to the domain layer as service methods or to the frontend to reduce the\n    # amount of logic needed in this handler.\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.can_play_exploration\n    def get(self, exploration_id):\n        \"\"\"Handles GET requests.\"\"\"\n        collection_id = self.request.get('collection_id')\n        include_system_recommendations = self.request.get(\n            'include_system_recommendations')\n        try:\n            author_recommended_exp_ids = json.loads(self.request.get(\n                'stringified_author_recommended_ids'))\n        except Exception:\n            raise self.PageNotFoundException\n\n        system_recommended_exp_ids = []\n        next_exp_id = None\n\n        if collection_id:\n            if self.user_id:\n                next_exp_id = (\n                    collection_services.get_next_exploration_id_to_complete_by_user(  # pylint: disable=line-too-long\n                        self.user_id, collection_id))\n            else:\n                collection = collection_services.get_collection_by_id(\n                    collection_id)\n                next_exp_id = (\n                    collection.get_next_exploration_id_in_sequence(\n                        exploration_id))\n        elif include_system_recommendations:\n            system_chosen_exp_ids = (\n                recommendations_services.get_exploration_recommendations(\n                    exploration_id))\n            filtered_exp_ids = list(\n                set(system_chosen_exp_ids) - set(author_recommended_exp_ids))\n            system_recommended_exp_ids = random.sample(\n                filtered_exp_ids,\n                min(MAX_SYSTEM_RECOMMENDATIONS, len(filtered_exp_ids)))\n\n        recommended_exp_ids = set(\n            author_recommended_exp_ids + system_recommended_exp_ids)\n        if next_exp_id is not None:\n            recommended_exp_ids.add(next_exp_id)\n\n        self.values.update({\n            'summaries': (\n                summary_services.get_displayable_exp_summary_dicts_matching_ids(\n                    recommended_exp_ids)),\n        })\n        self.render_json(self.values)\n\n\nclass FlagExplorationHandler(base.BaseHandler):\n    \"\"\"Handles operations relating to learner flagging of explorations.\"\"\"\n\n    @acl_decorators.can_flag_exploration\n    def post(self, exploration_id):\n        \"\"\"Handles POST requests.\n\n        Args:\n            exploration_id: str. The ID of the exploration.\n        \"\"\"\n        moderator_services.enqueue_flag_exploration_email_task(\n            exploration_id,\n            self.payload.get('report_text'),\n            self.user_id)\n        self.render_json(self.values)\n\n\nclass QuestionPlayerHandler(base.BaseHandler):\n    \"\"\"Provides questions with given skill ids.\"\"\"\n\n    GET_HANDLER_ERROR_RETURN_TYPE = feconf.HANDLER_TYPE_JSON\n\n    @acl_decorators.open_access\n    def get(self):\n        \"\"\"Handles GET request.\"\"\"\n        # Skill ids are given as a comma separated list because this is\n        # a GET request.\n\n        skill_ids = self.request.get('skill_ids').split(',')\n        question_count = self.request.get('question_count')\n        fetch_by_difficulty_value = self.request.get('fetch_by_difficulty')\n\n        if not question_count.isdigit() or int(question_count) <= 0:\n            raise self.InvalidInputException(\n                'Question count has to be greater than 0')\n\n        if not (fetch_by_difficulty_value == 'true' or\n                fetch_by_difficulty_value == 'false'):\n            raise self.InvalidInputException(\n                'fetch_by_difficulty must be true or false')\n        fetch_by_difficulty = (fetch_by_difficulty_value == 'true')\n\n        questions = (\n            question_services.get_questions_by_skill_ids(\n                int(question_count), skill_ids, fetch_by_difficulty)\n        )\n\n        question_dicts = [question.to_dict() for question in questions]\n        self.values.update({\n            'question_dicts': question_dicts\n        })\n        self.render_json(self.values)\n\n\nclass LearnerAnswerDetailsSubmissionHandler(base.BaseHandler):\n    \"\"\"Handles the learner answer details submission.\"\"\"\n\n    @acl_decorators.can_play_entity\n    def put(self, entity_type, entity_id):\n        \"\"\"\"Handles the PUT requests. Stores the answer details submitted\n        by the learner.\n        \"\"\"\n        if not constants.ENABLE_SOLICIT_ANSWER_DETAILS_FEATURE:\n            raise self.PageNotFoundException\n\n        interaction_id = self.payload.get('interaction_id')\n        if entity_type == feconf.ENTITY_TYPE_EXPLORATION:\n            state_name = self.payload.get('state_name')\n            state_reference = (\n                stats_services.get_state_reference_for_exploration(\n                    entity_id, state_name))\n            if interaction_id != exp_services.get_interaction_id_for_state(\n                    entity_id, state_name):\n                raise utils.InvalidInputException(\n                    'Interaction id given does not match with the '\n                    'interaction id of the state')\n        elif entity_type == feconf.ENTITY_TYPE_QUESTION:\n            state_reference = (\n                stats_services.get_state_reference_for_question(entity_id))\n            if interaction_id != (\n                    question_services.get_interaction_id_for_question(\n                        entity_id)):\n                raise utils.InvalidInputException(\n                    'Interaction id given does not match with the '\n                    'interaction id of the question')\n\n        answer = self.payload.get('answer')\n        answer_details = self.payload.get('answer_details')\n        stats_services.record_learner_answer_info(\n            entity_type, state_reference,\n            interaction_id, answer, answer_details)\n        self.render_json({})\n"
    },
    {
      "filename": "core/domain/stats_domain.py",
      "content": "# coding: utf-8\n#\n# Copyright 2014 The Oppia Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Domain object for statistics models.\"\"\"\nfrom __future__ import absolute_import  # pylint: disable=import-only-modules\nfrom __future__ import unicode_literals  # pylint: disable=import-only-modules\n\nimport datetime\nimport json\nimport numbers\nimport sys\n\nfrom constants import constants\nfrom core.domain import action_registry\nfrom core.domain import customization_args_util\nfrom core.domain import exp_domain\nfrom core.domain import interaction_registry\nfrom core.domain import playthrough_issue_registry\nfrom core.platform import models\nimport feconf\nimport python_utils\nimport utils\n\n(stats_models,) = models.Registry.import_models([models.NAMES.statistics])\n\n\n# These are special sentinel values attributed to answers migrated from the old\n# answer storage model. Those answers could not have session IDs or time spent\n# values inferred or reconstituted perfectly, so they are assigned these\n# values, instead. Logic and jobs which use these values are expected to skip\n# over the migrated answers to avoid tainted results. Furthermore, all migrated\n# answers are easy to retrieve by reducing session value on this session ID.\n# NOTE TO DEVELOPERS: All other state answer data model entities must not ever\n# store this session ID unless it was created by the 2017 answer migration job\n# (see #1205). Also, this string must never change.\nMIGRATED_STATE_ANSWER_SESSION_ID_2017 = 'migrated_state_answer_session_id_2017'\nMIGRATED_STATE_ANSWER_TIME_SPENT_IN_SEC = 0.0\n\n# These values dictate the types of calculation objects stored in\n# StateAnswersCalcOutput.\nCALC_OUTPUT_TYPE_ANSWER_FREQUENCY_LIST = 'AnswerFrequencyList'\nCALC_OUTPUT_TYPE_CATEGORIZED_ANSWER_FREQUENCY_LISTS = (\n    'CategorizedAnswerFrequencyLists')\n\n# The maximum size in bytes the learner_answer_info_list can take\n# in LearnerAnswerDetails.\nMAX_LEARNER_ANSWER_INFO_LIST_BYTE_SIZE = 900000\n\n# The maximum size in bytes the answer_details can take in\n# LearnerAnswerInfo.\nMAX_ANSWER_DETAILS_BYTE_SIZE = 10000\n\n\nclass ExplorationStats(python_utils.OBJECT):\n    \"\"\"Domain object representing analytics data for an exploration.\"\"\"\n\n    def __init__(\n            self, exp_id, exp_version, num_starts_v1, num_starts_v2,\n            num_actual_starts_v1, num_actual_starts_v2, num_completions_v1,\n            num_completions_v2, state_stats_mapping):\n        \"\"\"Constructs an ExplorationStats domain object.\n\n        Args:\n            exp_id: str. ID of the exploration.\n            exp_version: int. Version of the exploration.\n            num_starts_v1: int. Number of learners who started the exploration.\n            num_starts_v2: int. As above, but for events with version 2.\n            num_actual_starts_v1: int. Number of learners who actually attempted\n                the exploration. These are the learners who have completed the\n                initial state of the exploration and traversed to the next\n                state.\n            num_actual_starts_v2: int. As above, but for events with version 2.\n            num_completions_v1: int. Number of learners who completed the\n                exploration.\n            num_completions_v2: int. As above, but for events with version 2.\n            state_stats_mapping: dict. A dictionary mapping the state names of\n                an exploration to the corresponding StateStats domain object.\n        \"\"\"\n        self.exp_id = exp_id\n        self.exp_version = exp_version\n        self.num_starts_v1 = num_starts_v1\n        self.num_starts_v2 = num_starts_v2\n        self.num_actual_starts_v1 = num_actual_starts_v1\n        self.num_actual_starts_v2 = num_actual_starts_v2\n        self.num_completions_v1 = num_completions_v1\n        self.num_completions_v2 = num_completions_v2\n        self.state_stats_mapping = state_stats_mapping\n\n    @property\n    def num_starts(self):\n        \"\"\"Returns the number of learners who started the exploration.\n\n        Returns:\n            int. The number of learners who started the exploration.\n        \"\"\"\n        return self.num_starts_v1 + self.num_starts_v2\n\n    @property\n    def num_actual_starts(self):\n        \"\"\"Returns the number of learners who actually attempted the\n        exploration. These are the learners who have completed the initial\n        state of the exploration and traversed to the next state.\n\n        Returns:\n            int. The number of learners who actually attempted\n                the exploration.\n        \"\"\"\n        return self.num_actual_starts_v1 + self.num_actual_starts_v2\n\n    @property\n    def num_completions(self):\n        \"\"\"Returns the number of learners who completed the exploration.\n\n        Returns:\n            int. The number of learners who completed the exploration.\n        \"\"\"\n        return self.num_completions_v1 + self.num_completions_v2\n\n    def to_dict(self):\n        \"\"\"Returns a dict representation of the domain object.\"\"\"\n        state_stats_mapping_dict = {}\n        for state_name in self.state_stats_mapping:\n            state_stats_mapping_dict[state_name] = self.state_stats_mapping[\n                state_name].to_dict()\n\n        exploration_stats_dict = {\n            'exp_id': self.exp_id,\n            'exp_version': self.exp_version,\n            'num_starts_v1': self.num_starts_v1,\n            'num_starts_v2': self.num_starts_v2,\n            'num_actual_starts_v1': self.num_actual_starts_v1,\n            'num_actual_starts_v2': self.num_actual_starts_v2,\n            'num_completions_v1': self.num_completions_v1,\n            'num_completions_v2': self.num_completions_v2,\n            'state_stats_mapping': state_stats_mapping_dict\n        }\n        return exploration_stats_dict\n\n    def to_frontend_dict(self):\n        \"\"\"Returns a dict representation of the domain object for use in the\n        frontend.\n        \"\"\"\n        state_stats_mapping_dict = {}\n        for state_name in self.state_stats_mapping:\n            state_stats_mapping_dict[state_name] = self.state_stats_mapping[\n                state_name].to_frontend_dict()\n\n        exploration_stats_dict = {\n            'exp_id': self.exp_id,\n            'exp_version': self.exp_version,\n            'num_starts': self.num_starts,\n            'num_actual_starts': self.num_actual_starts,\n            'num_completions': self.num_completions,\n            'state_stats_mapping': state_stats_mapping_dict\n        }\n        return exploration_stats_dict\n\n    @classmethod\n    def create_default(cls, exp_id, exp_version, state_stats_mapping):\n        \"\"\"Creates a ExplorationStats domain object and sets all properties to\n        0.\n\n        Args:\n            exp_id: str. ID of the exploration.\n            exp_version: int. Version of the exploration.\n            state_stats_mapping: dict. A dict mapping state names to their\n                corresponding StateStats.\n\n        Returns:\n            ExplorationStats. The exploration stats domain object.\n        \"\"\"\n        return cls(exp_id, exp_version, 0, 0, 0, 0, 0, 0, state_stats_mapping)\n\n    def get_sum_of_first_hit_counts(self):\n        \"\"\"Compute the sum of first hit counts for the exploration stats.\n\n        Returns:\n            int. Sum of first hit counts.\n        \"\"\"\n        sum_first_hits = 0\n        for state_name in self.state_stats_mapping:\n            state_stats = self.state_stats_mapping[state_name]\n            sum_first_hits += state_stats.first_hit_count\n        return sum_first_hits\n\n    def validate(self):\n        \"\"\"Validates the ExplorationStats domain object.\"\"\"\n\n        exploration_stats_properties = [\n            'num_starts_v1',\n            'num_starts_v2',\n            'num_actual_starts_v1',\n            'num_actual_starts_v2',\n            'num_completions_v1',\n            'num_completions_v2',\n        ]\n\n        if not isinstance(self.exp_id, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected exp_id to be a string, received %s' % (self.exp_id))\n\n        if not isinstance(self.exp_version, int):\n            raise utils.ValidationError(\n                'Expected exp_version to be an int, received %s' % (\n                    self.exp_version))\n\n        exploration_stats_dict = self.to_dict()\n\n        for stat_property in exploration_stats_properties:\n            if not isinstance(exploration_stats_dict[stat_property], int):\n                raise utils.ValidationError(\n                    'Expected %s to be an int, received %s' % (\n                        stat_property, exploration_stats_dict[stat_property]))\n            if exploration_stats_dict[stat_property] < 0:\n                raise utils.ValidationError(\n                    '%s cannot have negative values' % (stat_property))\n\n        if not isinstance(self.state_stats_mapping, dict):\n            raise utils.ValidationError(\n                'Expected state_stats_mapping to be a dict, received %s' % (\n                    self.state_stats_mapping))\n\n\nclass StateStats(python_utils.OBJECT):\n    \"\"\"Domain object representing analytics data for an exploration's state.\n    Instances of these domain objects pertain to the exploration ID and version\n    as well.\n    \"\"\"\n\n    def __init__(\n            self, total_answers_count_v1, total_answers_count_v2,\n            useful_feedback_count_v1, useful_feedback_count_v2,\n            total_hit_count_v1, total_hit_count_v2, first_hit_count_v1,\n            first_hit_count_v2, num_times_solution_viewed_v2,\n            num_completions_v1, num_completions_v2):\n        \"\"\"Constructs a StateStats domain object.\n\n        Args:\n            total_answers_count_v1: int. Total number of answers submitted to\n                this state.\n            total_answers_count_v2: int. As above, but for events with version\n                2.\n            useful_feedback_count_v1: int. Total number of answers that received\n                useful feedback.\n            useful_feedback_count_v2: int. As above, but for events with version\n                2.\n            total_hit_count_v1: int. Total number of times the state was\n                entered.\n            total_hit_count_v2: int. As above, but for events with version 2.\n            first_hit_count_v1: int. Number of times the state was entered for\n                the first time.\n            first_hit_count_v2: int. As above, but for events with version 2.\n            num_times_solution_viewed_v2: int. Number of times the solution\n                button was triggered to answer a state (only for version 2).\n            num_completions_v1: int. Number of times the state was completed.\n            num_completions_v2: int. As above, but for events with version 2.\n        \"\"\"\n        self.total_answers_count_v1 = total_answers_count_v1\n        self.total_answers_count_v2 = total_answers_count_v2\n        self.useful_feedback_count_v1 = useful_feedback_count_v1\n        self.useful_feedback_count_v2 = useful_feedback_count_v2\n        self.total_hit_count_v1 = total_hit_count_v1\n        self.total_hit_count_v2 = total_hit_count_v2\n        self.first_hit_count_v1 = first_hit_count_v1\n        self.first_hit_count_v2 = first_hit_count_v2\n        # Solution view analytics were only introduced in v2, and there are no\n        # existing event models in v1 that record solution viewed events.\n        self.num_times_solution_viewed_v2 = num_times_solution_viewed_v2\n        self.num_completions_v1 = num_completions_v1\n        self.num_completions_v2 = num_completions_v2\n\n    @property\n    def total_answers_count(self):\n        \"\"\"Returns the total number of answers submitted to this state.\n\n        Returns:\n            int. The total number of answers submitted to this state.\n        \"\"\"\n        return self.total_answers_count_v1 + self.total_answers_count_v2\n\n    @property\n    def useful_feedback_count(self):\n        \"\"\"Returns the total number of answers that received useful feedback.\n\n        Returns:\n            int. The total number of answers that received useful feedback.\n        \"\"\"\n        return self.useful_feedback_count_v1 + self.useful_feedback_count_v2\n\n    @property\n    def total_hit_count(self):\n        \"\"\"Returns the total number of times the state was entered.\n\n        Returns:\n            int. The total number of times the state was entered.\n        \"\"\"\n        return self.total_hit_count_v1 + self.total_hit_count_v2\n\n    @property\n    def first_hit_count(self):\n        \"\"\"Returns the number of times the state was entered for the first time.\n\n        Returns:\n            int. The number of times the state was entered for the first time.\n        \"\"\"\n        return self.first_hit_count_v1 + self.first_hit_count_v2\n\n    @property\n    def num_completions(self):\n        \"\"\"Returns total number of times the state was completed.\n\n        Returns:\n            int. The total number of times the state was completed.\n        \"\"\"\n        return self.num_completions_v1 + self.num_completions_v2\n\n    @property\n    def num_times_solution_viewed(self):\n        \"\"\"Returns the number of times the solution button was triggered.\n\n        Returns:\n            int. Number of times the solution button was triggered to answer a\n                state only for events for schema version 2.\n        \"\"\"\n        return self.num_times_solution_viewed_v2\n\n    @classmethod\n    def create_default(cls):\n        \"\"\"Creates a StateStats domain object and sets all properties to 0.\"\"\"\n        return cls(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n\n    def to_dict(self):\n        \"\"\"Returns a dict representation of the domain object.\"\"\"\n        state_stats_dict = {\n            'total_answers_count_v1': self.total_answers_count_v1,\n            'total_answers_count_v2': self.total_answers_count_v2,\n            'useful_feedback_count_v1': self.useful_feedback_count_v1,\n            'useful_feedback_count_v2': self.useful_feedback_count_v2,\n            'total_hit_count_v1': self.total_hit_count_v1,\n            'total_hit_count_v2': self.total_hit_count_v2,\n            'first_hit_count_v1': self.first_hit_count_v1,\n            'first_hit_count_v2': self.first_hit_count_v2,\n            'num_times_solution_viewed_v2': (\n                self.num_times_solution_viewed_v2),\n            'num_completions_v1': self.num_completions_v1,\n            'num_completions_v2': self.num_completions_v2\n        }\n        return state_stats_dict\n\n    def to_frontend_dict(self):\n        \"\"\"Returns a dict representation of the domain object for use in the\n        frontend.\n        \"\"\"\n        state_stats_dict = {\n            'total_answers_count': self.total_answers_count,\n            'useful_feedback_count': self.useful_feedback_count,\n            'total_hit_count': self.total_hit_count,\n            'first_hit_count': self.first_hit_count,\n            'num_times_solution_viewed': self.num_times_solution_viewed,\n            'num_completions': self.num_completions\n        }\n        return state_stats_dict\n\n    @classmethod\n    def from_dict(cls, state_stats_dict):\n        \"\"\"Constructs a StateStats domain object from a dict.\"\"\"\n        return cls(\n            state_stats_dict['total_answers_count_v1'],\n            state_stats_dict['total_answers_count_v2'],\n            state_stats_dict['useful_feedback_count_v1'],\n            state_stats_dict['useful_feedback_count_v2'],\n            state_stats_dict['total_hit_count_v1'],\n            state_stats_dict['total_hit_count_v2'],\n            state_stats_dict['first_hit_count_v1'],\n            state_stats_dict['first_hit_count_v2'],\n            state_stats_dict['num_times_solution_viewed_v2'],\n            state_stats_dict['num_completions_v1'],\n            state_stats_dict['num_completions_v2']\n        )\n\n    def validate(self):\n        \"\"\"Validates the StateStats domain object.\"\"\"\n\n        state_stats_properties = [\n            'total_answers_count_v1',\n            'total_answers_count_v2',\n            'useful_feedback_count_v1',\n            'useful_feedback_count_v2',\n            'total_hit_count_v1',\n            'total_hit_count_v2',\n            'first_hit_count_v1',\n            'first_hit_count_v2',\n            'num_times_solution_viewed_v2',\n            'num_completions_v1',\n            'num_completions_v2'\n        ]\n\n        state_stats_dict = self.to_dict()\n\n        for stat_property in state_stats_properties:\n            if not isinstance(state_stats_dict[stat_property], int):\n                raise utils.ValidationError(\n                    'Expected %s to be an int, received %s' % (\n                        stat_property, state_stats_dict[stat_property]))\n            if state_stats_dict[stat_property] < 0:\n                raise utils.ValidationError(\n                    '%s cannot have negative values' % (stat_property))\n\n\nclass ExplorationIssues(python_utils.OBJECT):\n    \"\"\"Domain object representing the exploration to issues mapping for an\n    exploration.\n    \"\"\"\n\n    def __init__(self, exp_id, exp_version, unresolved_issues):\n        \"\"\"Constructs an ExplorationIssues domain object.\n\n        Args:\n            exp_id: str. ID of the exploration.\n            exp_version: int. Version of the exploration.\n            unresolved_issues: list(ExplorationIssue). List of exploration\n                issues.\n        \"\"\"\n        self.exp_id = exp_id\n        self.exp_version = exp_version\n        self.unresolved_issues = unresolved_issues\n\n    @classmethod\n    def create_default(cls, exp_id, exp_version):\n        \"\"\"Creates a default ExplorationIssues domain object.\n\n        Args:\n            exp_id: str. ID of the exploration.\n            exp_version: int. Version of the exploration.\n\n        Returns:\n            ExplorationIssues. The exploration issues domain object.\n        \"\"\"\n        return cls(exp_id, exp_version, [])\n\n    def to_dict(self):\n        \"\"\"Returns a dict representation of the ExplorationIssues domain object.\n\n        Returns:\n            dict. A dict mapping of all fields of ExplorationIssues object.\n        \"\"\"\n        unresolved_issue_dicts = [\n            unresolved_issue.to_dict()\n            for unresolved_issue in self.unresolved_issues]\n        return {\n            'exp_id': self.exp_id,\n            'exp_version': self.exp_version,\n            'unresolved_issues': unresolved_issue_dicts\n        }\n\n    @classmethod\n    def from_dict(cls, exp_issues_dict):\n        \"\"\"Returns an ExplorationIssues object from a dict.\n\n        Args:\n            exp_issues_dict: dict. A dict mapping of all fields of\n                ExplorationIssues object.\n\n        Returns:\n            ExplorationIssues. The corresponding ExplorationIssues domain\n                object.\n        \"\"\"\n        unresolved_issues = [\n            ExplorationIssue.from_dict(unresolved_issue_dict)\n            for unresolved_issue_dict in exp_issues_dict['unresolved_issues']]\n        return cls(\n            exp_issues_dict['exp_id'], exp_issues_dict['exp_version'],\n            unresolved_issues)\n\n    def validate(self):\n        \"\"\"Validates the ExplorationIssues domain object.\"\"\"\n        if not isinstance(self.exp_id, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected exp_id to be a string, received %s' % type(\n                    self.exp_id))\n\n        if not isinstance(self.exp_version, int):\n            raise utils.ValidationError(\n                'Expected exp_version to be an int, received %s' % type(\n                    self.exp_version))\n\n        if not isinstance(self.unresolved_issues, list):\n            raise utils.ValidationError(\n                'Expected unresolved_issues to be a list, received %s' % (\n                    type(self.unresolved_issues)))\n\n        for issue in self.unresolved_issues:\n            issue.validate()\n\n\nclass Playthrough(python_utils.OBJECT):\n    \"\"\"Domain object representing a learner playthrough.\"\"\"\n\n    def __init__(\n            self, exp_id, exp_version, issue_type, issue_customization_args,\n            actions):\n        \"\"\"Constructs a Playthrough domain object.\n\n        Args:\n            exp_id: str. ID of the exploration.\n            exp_version: int. Version of the exploration.\n            issue_type: str. Type of the issue.\n            issue_customization_args: dict. The customization args dict for the\n                given issue_type.\n            actions: list(LearnerAction). List of playthrough learner actions.\n        \"\"\"\n        self.exp_id = exp_id\n        self.exp_version = exp_version\n        self.issue_type = issue_type\n        self.issue_customization_args = issue_customization_args\n        self.actions = actions\n\n    def to_dict(self):\n        \"\"\"Returns a dict representation of the Playthrough domain object.\n\n        Returns:\n            dict. A dict mapping of all fields of Playthrough object.\n        \"\"\"\n        action_dicts = [action.to_dict() for action in self.actions]\n        return {\n            'exp_id': self.exp_id,\n            'exp_version': self.exp_version,\n            'issue_type': self.issue_type,\n            'issue_customization_args': self.issue_customization_args,\n            'actions': action_dicts,\n        }\n\n    @classmethod\n    def from_dict(cls, playthrough_data):\n        \"\"\"Checks whether the playthrough dict has the correct keys and then\n        returns a domain object instance.\n\n        Args:\n            playthrough_data: dict. A dict mapping of all fields of Playthrough\n                object.\n\n        Returns:\n            Playthrough. The corresponding Playthrough domain object.\n        \"\"\"\n        playthrough_properties = [\n            'exp_id', 'exp_version', 'issue_type',\n            'issue_customization_args', 'actions']\n        for playthrough_property in playthrough_properties:\n            if playthrough_property not in playthrough_data:\n                raise utils.ValidationError(\n                    '%s not in playthrough data dict.' % (\n                        playthrough_property))\n\n        actions = [\n            LearnerAction.from_dict(action_dict)\n            for action_dict in playthrough_data['actions']]\n\n        playthrough = cls(\n            playthrough_data['exp_id'],\n            playthrough_data['exp_version'],\n            playthrough_data['issue_type'],\n            playthrough_data['issue_customization_args'],\n            actions)\n\n        playthrough.validate()\n        return playthrough\n\n    def validate(self):\n        \"\"\"Validates the Playthrough domain object.\"\"\"\n        if not isinstance(self.exp_id, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected exp_id to be a string, received %s' % type(\n                    self.exp_id))\n\n        if not isinstance(self.exp_version, int):\n            raise utils.ValidationError(\n                'Expected exp_version to be an int, received %s' % (\n                    type(self.exp_version)))\n\n        if not isinstance(self.issue_type, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected issue_type to be a string, received %s' % type(\n                    self.issue_type))\n\n        if not isinstance(self.issue_customization_args, dict):\n            raise utils.ValidationError(\n                'Expected issue_customization_args to be a dict, '\n                'received %s' % (\n                    type(self.issue_customization_args)))\n\n        try:\n            issue = playthrough_issue_registry.Registry.get_issue_by_type(\n                self.issue_type)\n        except KeyError:\n            raise utils.ValidationError('Invalid issue type: %s' % (\n                self.issue_type))\n\n        customization_args_util.validate_customization_args_and_values(\n            'issue', self.issue_type, self.issue_customization_args,\n            issue.customization_arg_specs)\n\n        if not isinstance(self.actions, list):\n            raise utils.ValidationError(\n                'Expected actions to be a list, received %s' % (\n                    type(self.actions)))\n\n        for action in self.actions:\n            action.validate()\n\n\nclass ExplorationIssue(python_utils.OBJECT):\n    \"\"\"Domain object representing an exploration issue.\"\"\"\n\n    def __init__(\n            self, issue_type, issue_customization_args, playthrough_ids,\n            schema_version, is_valid):\n        \"\"\"Constructs an ExplorationIssue domain object.\n\n        Args:\n            issue_type: str. Type of the issue.\n            issue_customization_args: dict. The customization dict. The keys are\n                names of customization_args and the values are dicts with a\n                single key, 'value', whose corresponding value is the value of\n                the customization arg.\n            playthrough_ids: list(str). List of playthrough IDs.\n            schema_version: int. Schema version for the exploration issue.\n            is_valid: bool. Whether the issue and the associated playthroughs\n                are valid.\n        \"\"\"\n        self.issue_type = issue_type\n        self.issue_customization_args = issue_customization_args\n        self.playthrough_ids = playthrough_ids\n        self.schema_version = schema_version\n        self.is_valid = is_valid\n\n    def to_dict(self):\n        \"\"\"Returns a dict representation of the ExplorationIssue domain object.\n\n        Returns:\n            dict. A dict mapping of all fields of ExplorationIssue object.\n        \"\"\"\n        return {\n            'issue_type': self.issue_type,\n            'issue_customization_args': (\n                customization_args_util.get_full_customization_args(\n                    self.issue_customization_args,\n                    playthrough_issue_registry.Registry.get_issue_by_type(\n                        self.issue_type).customization_arg_specs)),\n            'playthrough_ids': self.playthrough_ids,\n            'schema_version': self.schema_version,\n            'is_valid': self.is_valid\n        }\n\n    @classmethod\n    def from_dict(cls, exp_issue_dict):\n        \"\"\"Checks whether the exploration issue dict has the correct keys and\n        then returns a domain object instance.\n\n        Args:\n            exp_issue_dict: dict. A dict mapping of all fields of\n                ExplorationIssue object.\n\n        Returns:\n            ExplorationIssue. The corresponding ExplorationIssue domain object.\n        \"\"\"\n        exp_issue_properties = [\n            'issue_type', 'schema_version', 'issue_customization_args',\n            'playthrough_ids', 'is_valid']\n        for exp_issue_property in exp_issue_properties:\n            if exp_issue_property not in exp_issue_dict:\n                raise utils.ValidationError(\n                    '%s not in exploration issue dict.' % (\n                        exp_issue_property))\n\n        exp_issue = cls(\n            exp_issue_dict['issue_type'],\n            exp_issue_dict['issue_customization_args'],\n            exp_issue_dict['playthrough_ids'],\n            exp_issue_dict['schema_version'],\n            exp_issue_dict['is_valid'])\n\n        exp_issue.validate()\n        return exp_issue\n\n    @classmethod\n    def update_exp_issue_from_model(cls, issue_dict):\n        \"\"\"Converts the exploration issue blob given from\n        current issue_schema_version to current issue_schema_version + 1.\n        Note that the issue_dict being passed in is modified in-place.\n\n        Args:\n            issue_dict: dict. Dict representing the ExplorationIssue object.\n        \"\"\"\n        current_issue_schema_version = issue_dict['schema_version']\n        issue_dict['schema_version'] += 1\n\n        conversion_fn = getattr(cls, '_convert_issue_v%s_dict_to_v%s_dict' % (\n            current_issue_schema_version, current_issue_schema_version + 1))\n        issue_dict = conversion_fn(issue_dict)\n\n    @classmethod\n    def _convert_issue_v1_dict_to_v2_dict(cls, issue_dict):\n        \"\"\"Converts a v1 issue dict to a v2 issue dict. This function is now\n        implemented only for testing purposes and must be rewritten when an\n        actual schema migration from v1 to v2 takes place.\n        \"\"\"\n        raise NotImplementedError\n\n    def validate(self):\n        \"\"\"Validates the ExplorationIssue domain object.\"\"\"\n        if not isinstance(self.issue_type, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected issue_type to be a string, received %s' % (\n                    type(self.issue_type)))\n\n        if not isinstance(self.schema_version, int):\n            raise utils.ValidationError(\n                'Expected schema_version to be an int, received %s' % (\n                    type(self.schema_version)))\n\n        try:\n            issue = playthrough_issue_registry.Registry.get_issue_by_type(\n                self.issue_type)\n        except KeyError:\n            raise utils.ValidationError('Invalid issue type: %s' % (\n                self.issue_type))\n\n        customization_args_util.validate_customization_args_and_values(\n            'issue', self.issue_type, self.issue_customization_args,\n            issue.customization_arg_specs)\n\n        if not isinstance(self.playthrough_ids, list):\n            raise utils.ValidationError(\n                'Expected playthrough_ids to be a list, received %s' % (\n                    type(self.playthrough_ids)))\n\n        for playthrough_id in self.playthrough_ids:\n            if not isinstance(playthrough_id, python_utils.BASESTRING):\n                raise utils.ValidationError(\n                    'Expected each playthrough_id to be a string, received '\n                    '%s' % type(playthrough_id))\n\n\nclass LearnerAction(python_utils.OBJECT):\n    \"\"\"Domain object representing a learner action.\"\"\"\n\n    def __init__(self, action_type, action_customization_args, schema_version):\n        \"\"\"Constructs a LearnerAction domain object.\n\n        Args:\n            action_type: str. Type of the action.\n            action_customization_args: dict. The customization dict. The keys\n                are names of customization_args and the values are dicts with a\n                single key, 'value', whose corresponding value is the value of\n                the customization arg.\n            schema_version: int. Schema version for the learner action.\n        \"\"\"\n        self.action_type = action_type\n        self.action_customization_args = action_customization_args\n        self.schema_version = schema_version\n\n    def to_dict(self):\n        \"\"\"Returns a dict representation of the LearnerAction domain object.\n\n        Returns:\n            dict. A dict mapping of all fields of LearnerAction object.\n        \"\"\"\n        return {\n            'action_type': self.action_type,\n            'action_customization_args': (\n                customization_args_util.get_full_customization_args(\n                    self.action_customization_args,\n                    action_registry.Registry.get_action_by_type(\n                        self.action_type).customization_arg_specs)),\n            'schema_version': self.schema_version\n        }\n\n    @classmethod\n    def from_dict(cls, action_dict):\n        \"\"\"Returns a LearnerAction object from a dict.\n\n        Args:\n            action_dict: dict. A dict mapping of all fields of LearnerAction\n                object.\n\n        Returns:\n            LearnerAction. The corresponding LearnerAction domain object.\n        \"\"\"\n        return cls(\n            action_dict['action_type'],\n            action_dict['action_customization_args'],\n            action_dict['schema_version'])\n\n    @classmethod\n    def update_learner_action_from_model(cls, action_dict):\n        \"\"\"Converts the learner action blob given from\n        current action_schema_version to current action_schema_version + 1.\n        Note that the action_dict being passed in is modified in-place.\n\n        Args:\n            action_dict: dict. Dict representing the LearnerAction object.\n        \"\"\"\n        current_action_schema_version = action_dict['schema_version']\n        action_dict['schema_version'] += 1\n\n        conversion_fn = getattr(cls, '_convert_action_v%s_dict_to_v%s_dict' % (\n            current_action_schema_version, current_action_schema_version + 1))\n        action_dict = conversion_fn(action_dict)\n\n    @classmethod\n    def _convert_action_v1_dict_to_v2_dict(cls, action_dict):\n        \"\"\"Converts a v1 action dict to a v2 action dict. This function is now\n        implemented only for testing purposes and must be rewritten when an\n        actual schema migration from v1 to v2 takes place.\n        \"\"\"\n        raise NotImplementedError\n\n    def validate(self):\n        \"\"\"Validates the LearnerAction domain object.\"\"\"\n        if not isinstance(self.action_type, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected action_type to be a string, received %s' % (\n                    type(self.action_type)))\n\n        if not isinstance(self.schema_version, int):\n            raise utils.ValidationError(\n                'Expected schema_version to be an int, received %s' % (\n                    type(self.schema_version)))\n\n        try:\n            action = action_registry.Registry.get_action_by_type(\n                self.action_type)\n        except KeyError:\n            raise utils.ValidationError(\n                'Invalid action type: %s' % self.action_type)\n\n        customization_args_util.validate_customization_args_and_values(\n            'action', self.action_type, self.action_customization_args,\n            action.customization_arg_specs)\n\n\n# TODO(bhenning): Monitor sizes (lengths of submitted_answer_list) of these\n# objects and determine if we should enforce an upper bound for\n# submitted_answer_list.\nclass StateAnswers(python_utils.OBJECT):\n    \"\"\"Domain object containing answers submitted to an exploration state.\"\"\"\n\n    def __init__(\n            self, exploration_id, exploration_version, state_name,\n            interaction_id, submitted_answer_list,\n            schema_version=feconf.CURRENT_STATE_ANSWERS_SCHEMA_VERSION):\n        \"\"\"Constructs a StateAnswers domain object.\n\n        Args:\n            exploration_id: The ID of the exploration corresponding to submitted\n                answers.\n            exploration_version: The version of the exploration corresponding to\n                submitted answers.\n            state_name: The state to which the answers were submitted.\n            interaction_id: The ID of the interaction which created the answers.\n            submitted_answer_list: The list of SubmittedAnswer domain objects\n                that were submitted to the exploration and version specified in\n                this object.\n            schema_version: The schema version of this answers object.\n        \"\"\"\n        self.exploration_id = exploration_id\n        self.exploration_version = exploration_version\n        self.state_name = state_name\n        self.interaction_id = interaction_id\n        self.submitted_answer_list = submitted_answer_list\n        self.schema_version = schema_version\n\n    def get_submitted_answer_dict_list(self):\n        \"\"\"Returns the submitted_answer_list stored within this object as a list\n        of StateAnswer dicts.\n        \"\"\"\n        return [state_answer.to_dict()\n                for state_answer in self.submitted_answer_list]\n\n    def validate(self):\n        \"\"\"Validates StateAnswers domain object entity.\"\"\"\n\n        if not isinstance(self.exploration_id, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected exploration_id to be a string, received %s'\n                % python_utils.UNICODE(self.exploration_id))\n\n        if not isinstance(self.state_name, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected state_name to be a string, received %s'\n                % python_utils.UNICODE(self.state_name))\n\n        if self.interaction_id is not None:\n            if not isinstance(self.interaction_id, python_utils.BASESTRING):\n                raise utils.ValidationError(\n                    'Expected interaction_id to be a string, received %s'\n                    % python_utils.UNICODE(self.interaction_id))\n\n            # Verify interaction_id is valid.\n            if (self.interaction_id not in\n                    interaction_registry.Registry.get_all_interaction_ids()):\n                raise utils.ValidationError(\n                    'Unknown interaction_id: %s' % self.interaction_id)\n\n        if not isinstance(self.submitted_answer_list, list):\n            raise utils.ValidationError(\n                'Expected submitted_answer_list to be a list, received %s' %\n                python_utils.UNICODE(self.submitted_answer_list))\n\n        if not isinstance(self.schema_version, int):\n            raise utils.ValidationError(\n                'Expected schema_version to be an integer, received %s'\n                % python_utils.UNICODE(self.schema_version))\n\n        if self.schema_version < 1:\n            raise utils.ValidationError(\n                'schema_version < 1: %d' % self.schema_version)\n\n        if self.schema_version > feconf.CURRENT_STATE_ANSWERS_SCHEMA_VERSION:\n            raise utils.ValidationError(\n                'schema_version > feconf.CURRENT_STATE_ANSWERS_SCHEMA_VERSION '\n                '(%d): %d' % (\n                    feconf.CURRENT_STATE_ANSWERS_SCHEMA_VERSION,\n                    self.schema_version))\n\n\nclass SubmittedAnswer(python_utils.OBJECT):\n    \"\"\"Domain object representing an answer submitted to a state.\"\"\"\n\n    # NOTE TO DEVELOPERS: do not use the rule_spec_str and answer_str\n    # parameters; they are only populated by the answer migration job. They only\n    # represent context that is lost as part of the answer migration and are\n    # used as part of validating the migration was correct. They may be\n    # referenced in future migration or mapreduce jobs, or they may be removed\n    # without warning or migration.\n\n    def __init__(\n            self, answer, interaction_id, answer_group_index,\n            rule_spec_index, classification_categorization, params,\n            session_id, time_spent_in_sec, rule_spec_str=None,\n            answer_str=None):\n        self.answer = answer\n        self.interaction_id = interaction_id\n        self.answer_group_index = answer_group_index\n        self.rule_spec_index = rule_spec_index\n        self.classification_categorization = classification_categorization\n        self.params = params\n        self.session_id = session_id\n        self.time_spent_in_sec = time_spent_in_sec\n        self.rule_spec_str = rule_spec_str\n        self.answer_str = answer_str\n\n    def to_dict(self):\n        \"\"\"Returns the dict of submitted answer.\n\n        Returns:\n            dict. The submitted answer dict.\n        \"\"\"\n        submitted_answer_dict = {\n            'answer': self.answer,\n            'interaction_id': self.interaction_id,\n            'answer_group_index': self.answer_group_index,\n            'rule_spec_index': self.rule_spec_index,\n            'classification_categorization': self.classification_categorization,\n            'params': self.params,\n            'session_id': self.session_id,\n            'time_spent_in_sec': self.time_spent_in_sec,\n        }\n        if self.rule_spec_str is not None:\n            submitted_answer_dict['rule_spec_str'] = self.rule_spec_str\n        if self.answer_str is not None:\n            submitted_answer_dict['answer_str'] = self.answer_str\n        return submitted_answer_dict\n\n    @classmethod\n    def from_dict(cls, submitted_answer_dict):\n        \"\"\"Returns the domain object representing an answer submitted to a\n        state.\n\n        Returns:\n            SubmittedAnswer. The SubmittedAnswer domin object.\n        \"\"\"\n        return cls(\n            submitted_answer_dict['answer'],\n            submitted_answer_dict['interaction_id'],\n            submitted_answer_dict['answer_group_index'],\n            submitted_answer_dict['rule_spec_index'],\n            submitted_answer_dict['classification_categorization'],\n            submitted_answer_dict['params'],\n            submitted_answer_dict['session_id'],\n            submitted_answer_dict['time_spent_in_sec'],\n            rule_spec_str=submitted_answer_dict.get('rule_spec_str'),\n            answer_str=submitted_answer_dict.get('answer_str'))\n\n    def validate(self):\n        \"\"\"Validates this submitted answer object.\"\"\"\n        # TODO(bhenning): Validate the normalized answer against future answer\n        # objects after #956 is addressed.\n        if self.time_spent_in_sec is None:\n            raise utils.ValidationError(\n                'SubmittedAnswers must have a provided time_spent_in_sec')\n        if self.session_id is None:\n            raise utils.ValidationError(\n                'SubmittedAnswers must have a provided session_id')\n\n        if self.rule_spec_str is not None and not isinstance(\n                self.rule_spec_str, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected rule_spec_str to be either None or a string, '\n                'received %s' % python_utils.UNICODE(self.rule_spec_str))\n\n        if self.answer_str is not None and not isinstance(\n                self.answer_str, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected answer_str to be either None or a string, received '\n                '%s' % python_utils.UNICODE(self.answer_str))\n\n        if not isinstance(self.session_id, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected session_id to be a string, received %s' %\n                python_utils.UNICODE(self.session_id))\n\n        if not isinstance(self.time_spent_in_sec, numbers.Number):\n            raise utils.ValidationError(\n                'Expected time_spent_in_sec to be a number, received %s' %\n                python_utils.UNICODE(self.time_spent_in_sec))\n\n        if not isinstance(self.params, dict):\n            raise utils.ValidationError(\n                'Expected params to be a dict, received %s'\n                % python_utils.UNICODE(self.params))\n\n        if not isinstance(self.answer_group_index, int):\n            raise utils.ValidationError(\n                'Expected answer_group_index to be an integer, received %s' %\n                python_utils.UNICODE(self.answer_group_index))\n\n        if self.rule_spec_index is not None and not (\n                isinstance(self.rule_spec_index, int)):\n            raise utils.ValidationError(\n                'Expected rule_spec_index to be an integer, received %s' %\n                python_utils.UNICODE(self.rule_spec_index))\n\n        if self.answer_group_index < 0:\n            raise utils.ValidationError(\n                'Expected answer_group_index to be non-negative, received %d' %\n                self.answer_group_index)\n\n        if self.rule_spec_index is not None and self.rule_spec_index < 0:\n            raise utils.ValidationError(\n                'Expected rule_spec_index to be non-negative, received %d' %\n                self.rule_spec_index)\n\n        if self.time_spent_in_sec < 0.:\n            raise utils.ValidationError(\n                'Expected time_spent_in_sec to be non-negative, received %f' %\n                self.time_spent_in_sec)\n\n        if self.answer is None and (\n                self.interaction_id not in feconf.LINEAR_INTERACTION_IDS):\n            raise utils.ValidationError(\n                'SubmittedAnswers must have a provided answer except for '\n                'linear interactions')\n\n        valid_classification_categories = [\n            exp_domain.EXPLICIT_CLASSIFICATION,\n            exp_domain.TRAINING_DATA_CLASSIFICATION,\n            exp_domain.STATISTICAL_CLASSIFICATION,\n            exp_domain.DEFAULT_OUTCOME_CLASSIFICATION]\n        if self.classification_categorization not in (\n                valid_classification_categories):\n            raise utils.ValidationError(\n                'Expected valid classification_categorization, received %s' %\n                self.classification_categorization)\n\n\nclass AnswerOccurrence(python_utils.OBJECT):\n    \"\"\"Domain object that represents a specific answer that occurred some number\n    of times.\n    \"\"\"\n\n    def __init__(self, answer, frequency):\n        \"\"\"Initialize domain object for answer occurrences.\"\"\"\n        self.answer = answer\n        self.frequency = frequency\n\n    def to_raw_type(self):\n        \"\"\"Returns a Python dict representing the specific answer.\n\n        Returns:\n            dict. The specific answer dict in the following format:\n            {\n                'answer': *. The answer submitted by the learner.\n                'frequency': int. The number of occurrences of the answer.\n            }\n        \"\"\"\n        return {\n            'answer': self.answer,\n            'frequency': self.frequency\n        }\n\n    @classmethod\n    def from_raw_type(cls, answer_occurrence_dict):\n        \"\"\"Returns domain object that represents a specific answer that occurred\n        some number of times.\n\n        Args:\n            answer_occurrence_dict: dict. The specific answer dict in the\n                following format:\n                {\n                    'answer': *. The answer submitted by the learner.\n                    'frequency': int. The number of occurrences of the answer.\n                }\n\n        Returns:\n            AnswerOccurrence. The AnswerOccurrence domain object.\n        \"\"\"\n        return cls(\n            answer_occurrence_dict['answer'],\n            answer_occurrence_dict['frequency'])\n\n\nclass AnswerCalculationOutput(python_utils.OBJECT):\n    \"\"\"Domain object superclass that represents the output of an answer\n    calculation.\n    \"\"\"\n\n    def __init__(self, calculation_output_type):\n        self.calculation_output_type = calculation_output_type\n\n\nclass AnswerFrequencyList(AnswerCalculationOutput):\n    \"\"\"Domain object that represents an output list of AnswerOccurrences.\"\"\"\n\n    def __init__(self, answer_occurrences=None):\n        \"\"\"Initialize domain object for answer frequency list for a given list\n        of AnswerOccurrence objects (default is empty list).\n        \"\"\"\n        super(AnswerFrequencyList, self).__init__(\n            CALC_OUTPUT_TYPE_ANSWER_FREQUENCY_LIST)\n        self.answer_occurrences = (\n            answer_occurrences if answer_occurrences else [])\n\n    def to_raw_type(self):\n        \"\"\"Returns the answer occurrences list with each answer represented as\n        a Python dict.\n\n        Returns:\n            list(dict). A list of answer occurrence dicts. Each dict has the\n                following format:\n                {\n                    'answer': *. The answer submitted by the learner.\n                    'frequency': int. The number of occurrences of the answer.\n                }\n        \"\"\"\n        return [\n            answer_occurrence.to_raw_type()\n            for answer_occurrence in self.answer_occurrences]\n\n    @classmethod\n    def from_raw_type(cls, answer_occurrence_list):\n        \"\"\"Creates a domain object that represents an output list of\n        AnswerOccurrences.\n\n        Args:\n            answer_occurrence_list: list(dict). A list containing answer\n                occurrence dicts in the following format:\n                {\n                    'answer': *. The answer submitted by the learner.\n                    'frequency': int. The number of occurrences of the answer.\n                }\n\n        Returns:\n            AnswerFrequencyList. The domain object for answer occurrences list.\n        \"\"\"\n        return cls([\n            AnswerOccurrence.from_raw_type(answer_occurrence_dict)\n            for answer_occurrence_dict in answer_occurrence_list])\n\n\nclass CategorizedAnswerFrequencyLists(AnswerCalculationOutput):\n    \"\"\"AnswerFrequencyLists that are categorized based on arbitrary\n    categories.\n    \"\"\"\n\n    def __init__(self, categorized_answer_freq_lists=None):\n        \"\"\"Initialize domain object for categorized answer frequency lists for\n        a given dict (default is empty).\n        \"\"\"\n        super(CategorizedAnswerFrequencyLists, self).__init__(\n            CALC_OUTPUT_TYPE_CATEGORIZED_ANSWER_FREQUENCY_LISTS)\n        self.categorized_answer_freq_lists = (\n            categorized_answer_freq_lists\n            if categorized_answer_freq_lists else {})\n\n    def to_raw_type(self):\n        \"\"\"Returns the categorized frequency Python dict.\n\n        Returns:\n            dict. A dict whose keys are category names and whose corresponding\n                values are lists of answer frequency dicts. Each answer\n                frequency dict has the following keys and values:\n                {\n                    'answer': *. The answer submitted by the learner.\n                    'frequency': int. The number of occurrences of the answer.\n                }\n        \"\"\"\n        return {\n            category: answer_frequency_list.to_raw_type()\n            for category, answer_frequency_list in (\n                self.categorized_answer_freq_lists.items())\n        }\n\n    @classmethod\n    def from_raw_type(cls, categorized_frequency_dict):\n        \"\"\"Returns the domain object for categorized answer frequency dict for\n        a given dict.\n\n        Args:\n            categorized_frequency_dict: dict. The categorized answer frequency\n                dict whose keys are category names and whose corresponding\n                values are lists of answer frequency dicts. Each answer\n                frequency dict has the following keys and values:\n                {\n                    'answer': *. The answer submitted by the learner.\n                    'frequency': int. The number of occurrences of the answer.\n                }\n\n        Returns:\n            CategorizedAnswerFrequencyLists. The domain object for categorized\n                answer frequency dict.\n        \"\"\"\n        return cls({\n            category: AnswerFrequencyList.from_raw_type(answer_occurrence_list)\n            for category, answer_occurrence_list in (\n                categorized_frequency_dict.items())\n        })\n\n\nclass StateAnswersCalcOutput(python_utils.OBJECT):\n    \"\"\"Domain object that represents output of calculations operating on\n    state answers.\n    \"\"\"\n\n    def __init__(\n            self, exploration_id, exploration_version, state_name,\n            interaction_id, calculation_id, calculation_output):\n        \"\"\"Initialize domain object for state answers calculation output.\n\n        Args:\n            exploration_id: str. The ID of the exploration corresponding to the\n                answer calculation output.\n            exploration_version: str. The version of the exploration\n                corresponding to the answer calculation output.\n            state_name: str. The name of the exploration state to which the\n                aggregated answers were submitted.\n            interaction_id: str. The ID of the interaction.\n            calculation_id: str. Which calculation was performed on the given\n                answer data.\n            calculation_output: AnswerCalculationOutput. The output of an\n                answer aggregation operation.\n        \"\"\"\n        self.exploration_id = exploration_id\n        self.exploration_version = exploration_version\n        self.state_name = state_name\n        self.calculation_id = calculation_id\n        self.interaction_id = interaction_id\n        self.calculation_output = calculation_output\n\n    def save(self):\n        \"\"\"Validate the domain object and commit it to storage.\"\"\"\n        self.validate()\n        stats_models.StateAnswersCalcOutputModel.create_or_update(\n            self.exploration_id, self.exploration_version, self.state_name,\n            self.interaction_id, self.calculation_id,\n            self.calculation_output.calculation_output_type,\n            self.calculation_output.to_raw_type())\n\n    def validate(self):\n        \"\"\"Validates StateAnswersCalcOutputModel domain object entity before\n        it is commited to storage.\n        \"\"\"\n\n        # There is a danger of data overflow if answer_opts exceeds 1MB. This\n        # will be addressed later if it happens regularly. At the moment, a\n        # ValidationError is raised if an answer exceeds the maximum size.\n        max_bytes_per_calc_output_data = 999999\n\n        if not isinstance(self.exploration_id, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected exploration_id to be a string, received %s'\n                % python_utils.UNICODE(self.exploration_id))\n\n        if not isinstance(self.state_name, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected state_name to be a string, received %s'\n                % python_utils.UNICODE(self.state_name))\n\n        if not isinstance(self.calculation_id, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected calculation_id to be a string, received %s'\n                % python_utils.UNICODE(self.calculation_id))\n\n        if (not isinstance(self.calculation_output, AnswerFrequencyList)\n                and not isinstance(\n                    self.calculation_output, CategorizedAnswerFrequencyLists)):\n            raise utils.ValidationError(\n                'Expected calculation output to be one of AnswerFrequencyList '\n                'or CategorizedAnswerFrequencyLists, encountered: %s' % (\n                    self.calculation_output))\n\n        output_data = self.calculation_output.to_raw_type()\n        if sys.getsizeof(output_data) > max_bytes_per_calc_output_data:\n            # TODO(msl): find a better way to deal with big\n            # calculation output data, e.g. just skip. At the moment,\n            # too long answers produce a ValidationError.\n            raise utils.ValidationError(\n                'calculation_output is too big to be stored (size: %d): %s' % (\n                    sys.getsizeof(output_data),\n                    python_utils.UNICODE(output_data)))\n\n\nclass LearnerAnswerDetails(python_utils.OBJECT):\n    \"\"\"Domain object that represents the answer details submitted by the\n    learner.\n    \"\"\"\n\n    def __init__(\n            self, state_reference, entity_type, interaction_id,\n            learner_answer_info_list, accumulated_answer_info_json_size_bytes,\n            learner_answer_info_schema_version=(\n                feconf.CURRENT_LEARNER_ANSWER_INFO_SCHEMA_VERSION)):\n        \"\"\"Constructs a LearnerAnswerDetail domain object.\n\n        Args:\n            state_reference: str. This field is used to refer to a state\n                in an exploration or question. For an exploration the value\n                will be equal to 'exp_id:state_name' & for question this will\n                be equal to 'question_id' only.\n            entity_type: str. The type of entity, for which the domain\n                object is being created. The value must be one of\n                ENTITY_TYPE_EXPLORATION or ENTITY_TYPE_QUESTION.\n            interaction_id: str. The ID of the interaction, but this value\n                should not be equal to EndExploration and\n                Continue as these interactions cannot solicit answer\n                details.\n            learner_answer_info_list: list(LearnerAnswerInfo). The list of\n                LearnerAnswerInfo objects.\n            accumulated_answer_info_json_size_bytes: int. The size of\n                learner_answer_info_list in bytes.\n            learner_answer_info_schema_version: int. The schema version of the\n                LearnerAnswerInfo dict.\n        \"\"\"\n\n        self.state_reference = state_reference\n        self.entity_type = entity_type\n        self.interaction_id = interaction_id\n        self.learner_answer_info_list = learner_answer_info_list\n        self.accumulated_answer_info_json_size_bytes = (\n            accumulated_answer_info_json_size_bytes)\n        self.learner_answer_info_schema_version = (\n            learner_answer_info_schema_version)\n\n    def to_dict(self):\n        \"\"\"Returns a dict representing LearnerAnswerDetails domain object.\n\n        Returns:\n            dict. A dict, mapping all fields of LearnerAnswerDetails instance.\n        \"\"\"\n        return {\n            'state_reference': self.state_reference,\n            'entity_type': self.entity_type,\n            'interaction_id': self.interaction_id,\n            'learner_answer_info_list': [\n                learner_answer_info.to_dict() for learner_answer_info in (\n                    self.learner_answer_info_list)\n            ],\n            'accumulated_answer_info_json_size_bytes': (\n                self.accumulated_answer_info_json_size_bytes),\n            'learner_answer_info_schema_version': (\n                self.learner_answer_info_schema_version)\n        }\n\n    @classmethod\n    def from_dict(cls, learner_answer_details_dict):\n        \"\"\"Return a LearnerAnswerDetails domain object from a dict.\n\n        Args:\n            learner_answer_details_dict: dict. The dict representation of\n                LearnerAnswerDetails object.\n\n        Returns:\n            LearnerAnswerDetails. The corresponding LearnerAnswerDetails\n                domain object.\n        \"\"\"\n        return cls(\n            learner_answer_details_dict['state_reference'],\n            learner_answer_details_dict['entity_type'],\n            learner_answer_details_dict['interaction_id'],\n            [LearnerAnswerInfo.from_dict(learner_answer_info_dict)\n             for learner_answer_info_dict in learner_answer_details_dict[\n                 'learner_answer_info_list']],\n            learner_answer_details_dict[\n                'accumulated_answer_info_json_size_bytes'],\n            learner_answer_details_dict['learner_answer_info_schema_version']\n        )\n\n    def validate(self):\n        \"\"\"Validates LearnerAnswerDetails domain object.\"\"\"\n\n        if not isinstance(self.state_reference, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected state_reference to be a string, received %s'\n                % python_utils.UNICODE(self.state_reference))\n\n        if not isinstance(self.entity_type, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected entity_type to be a string, received %s'\n                % python_utils.UNICODE(self.entity_type))\n\n        split_state_reference = self.state_reference.split(':')\n        if self.entity_type == feconf.ENTITY_TYPE_EXPLORATION:\n            if len(split_state_reference) != 2:\n                raise utils.ValidationError(\n                    'For entity type exploration, the state reference '\n                    'should be of the form \\'exp_id:state_name\\', but '\n                    'received %s' % (self.state_reference))\n        elif self.entity_type == feconf.ENTITY_TYPE_QUESTION:\n            if len(split_state_reference) != 1:\n                raise utils.ValidationError(\n                    'For entity type question, the state reference should '\n                    'be of the form \\'question_id\\', but received %s' % (\n                        self.state_reference))\n        else:\n            raise utils.ValidationError(\n                'Invalid entity type received %s' % (self.entity_type))\n\n        if not isinstance(self.interaction_id, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected interaction_id to be a string, received %s'\n                % python_utils.UNICODE(self.interaction_id))\n\n        if (self.interaction_id not in\n                interaction_registry.Registry.get_all_interaction_ids()):\n            raise utils.ValidationError(\n                'Unknown interaction_id: %s' % self.interaction_id)\n\n        if self.interaction_id in (\n                constants.INTERACTION_IDS_WITHOUT_ANSWER_DETAILS):\n            raise utils.ValidationError(\n                'The %s interaction does not support soliciting '\n                'answer details from learners.' % (self.interaction_id))\n\n        if not isinstance(self.learner_answer_info_list, list):\n            raise utils.ValidationError(\n                'Expected learner_answer_info_list to be a list, '\n                'received %s'\n                % python_utils.UNICODE(self.learner_answer_info_list))\n\n        for learner_answer_info in self.learner_answer_info_list:\n            learner_answer_info.validate()\n\n        if not isinstance(self.learner_answer_info_schema_version, int):\n            raise utils.ValidationError(\n                'Expected learner_answer_info_schema_version to be an int, '\n                'received %s' % self.learner_answer_info_schema_version)\n\n        if not isinstance(self.accumulated_answer_info_json_size_bytes, int):\n            raise utils.ValidationError(\n                'Expected accumulated_answer_info_json_size_bytes to be an int '\n                'received %s' % self.accumulated_answer_info_json_size_bytes)\n\n    def add_learner_answer_info(self, learner_answer_info):\n        \"\"\"Adds new learner answer info in the learner_answer_info_list.\n\n        Args:\n            learner_answer_info: LearnerAnswerInfo. The learner answer info\n                object, which is created after the learner has submitted the\n                details of the answer.\n        \"\"\"\n        learner_answer_info_dict_size = (\n            learner_answer_info.get_learner_answer_info_dict_size())\n        if (self.accumulated_answer_info_json_size_bytes +\n                learner_answer_info_dict_size <= (\n                    MAX_LEARNER_ANSWER_INFO_LIST_BYTE_SIZE)):\n            self.learner_answer_info_list.append(learner_answer_info)\n            self.accumulated_answer_info_json_size_bytes += (\n                learner_answer_info_dict_size)\n\n    def delete_learner_answer_info(self, learner_answer_info_id):\n        \"\"\"Delete the learner answer info from the learner_answer_info_list.\n\n        Args:\n            learner_answer_info_id: str. The learner answer info\n                id, which needs to be deleted from\n                the learner_answer_info_list.\n\n        Raises:\n            Exception: If the learner answer info with the given id is not\n                found in the learner answer info list.\n        \"\"\"\n        new_learner_answer_info_list = []\n        for learner_answer_info in self.learner_answer_info_list:\n            if learner_answer_info.id != learner_answer_info_id:\n                new_learner_answer_info_list.append(learner_answer_info)\n            else:\n                self.accumulated_answer_info_json_size_bytes -= (\n                    learner_answer_info.get_learner_answer_info_dict_size())\n        if self.learner_answer_info_list == new_learner_answer_info_list:\n            raise Exception('Learner answer info with the given id not found.')\n        else:\n            self.learner_answer_info_list = new_learner_answer_info_list\n\n    def update_state_reference(self, new_state_reference):\n        \"\"\"Updates the state_reference of the LearnerAnswerDetails object.\n\n        Args:\n            new_state_reference: str. The new state reference of the\n                LearnerAnswerDetails.\n        \"\"\"\n        self.state_reference = new_state_reference\n\n\nclass LearnerAnswerInfo(python_utils.OBJECT):\n    \"\"\"Domain object containing the answer details submitted by the learner.\"\"\"\n\n    def __init__(\n            self, learner_answer_info_id, answer,\n            answer_details, created_on):\n        \"\"\"Constructs a LearnerAnswerInfo domain object.\n\n        Args:\n            learner_answer_info_id: str. The id of the LearnerAnswerInfo object.\n            answer: dict or list or str or int or bool. The answer which is\n                submitted by the learner. Actually type of the answer is\n                interaction dependent, like TextInput interactions have\n                string type answer, NumericInput have int type answers etc.\n            answer_details: str. The details the learner will submit when the\n                learner will be asked questions like 'Hey how did you land on\n                this answer', 'Why did you pick that answer' etc.\n            created_on: datetime. The time at which the answer details were\n                received.\n        \"\"\"\n        self.id = learner_answer_info_id\n        self.answer = answer\n        self.answer_details = answer_details\n        self.created_on = created_on\n\n    def to_dict(self):\n        \"\"\"Returns the dict of learner answer info.\n\n        Returns:\n            dict. The learner_answer_info dict.\n        \"\"\"\n        learner_answer_info_dict = {\n            'id': self.id,\n            'answer': self.answer,\n            'answer_details': self.answer_details,\n            'created_on': self.created_on.strftime('%Y-%m-%d %H:%M:%S.%f')\n        }\n        return learner_answer_info_dict\n\n    @classmethod\n    def from_dict(cls, learner_answer_info_dict):\n        \"\"\"Returns a dict representing LearnerAnswerInfo domain object.\n\n        Returns:\n            dict. A dict, mapping all fields of LearnerAnswerInfo instance.\n        \"\"\"\n\n        return cls(\n            learner_answer_info_dict['id'],\n            learner_answer_info_dict['answer'],\n            learner_answer_info_dict['answer_details'],\n            datetime.datetime.strptime(\n                learner_answer_info_dict['created_on'], '%Y-%m-%d %H:%M:%S.%f')\n        )\n\n    @classmethod\n    def get_new_learner_answer_info_id(cls):\n        \"\"\"Generates the learner answer info domain object id.\n\n        Return:\n            learner_answer_info_id: str. The id generated by the function.\n        \"\"\"\n        learner_answer_info_id = (\n            utils.base64_from_int(\n                utils.get_current_time_in_millisecs()) +\n            utils.base64_from_int(utils.get_random_int(127 * 127)))\n        return learner_answer_info_id\n\n    def validate(self):\n        \"\"\"Validates the LearnerAnswerInfo domain object.\"\"\"\n        if not isinstance(self.id, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected id to be a string, received %s' % self.id)\n        if self.answer is None:\n            raise utils.ValidationError(\n                'The answer submitted by the learner cannot be empty')\n        if isinstance(self.answer, dict):\n            if self.answer == {}:\n                raise utils.ValidationError(\n                    'The answer submitted cannot be an empty dict.')\n        if isinstance(self.answer, python_utils.BASESTRING):\n            if self.answer == '':\n                raise utils.ValidationError(\n                    'The answer submitted cannot be an empty string')\n        if not isinstance(self.answer_details, python_utils.BASESTRING):\n            raise utils.ValidationError(\n                'Expected answer_details to be a string, received %s' % type(\n                    self.answer_details))\n        if self.answer_details == '':\n            raise utils.ValidationError(\n                'The answer details submitted cannot be an empty string.')\n        if sys.getsizeof(self.answer_details) > MAX_ANSWER_DETAILS_BYTE_SIZE:\n            raise utils.ValidationError('The answer details size is to large '\n                                        'to be stored')\n        if not isinstance(self.created_on, datetime.datetime):\n            raise utils.ValidationError(\n                'Expected created_on to be a datetime, received %s'\n                % python_utils.UNICODE(self.created_on))\n\n    def get_learner_answer_info_dict_size(self):\n        \"\"\"Returns a size overestimate (in bytes) of the given learner answer\n        info dict.\n\n        Returns:\n            int. Size of the learner_answer_info_dict in bytes.\n        \"\"\"\n        learner_answer_info_dict = self.to_dict()\n        return sys.getsizeof(\n            json.dumps(learner_answer_info_dict, default=python_utils.UNICODE))\n"
    },
    {
      "filename": "core/domain/stats_domain_test.py",
      "content": "# coding: utf-8\n#\n# Copyright 2014 The Oppia Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tests for core.domain.stats_domain.\"\"\"\nfrom __future__ import absolute_import  # pylint: disable=import-only-modules\nfrom __future__ import unicode_literals  # pylint: disable=import-only-modules\n\nimport datetime\n\nfrom core.domain import exp_domain\nfrom core.domain import stats_domain\nfrom core.domain import stats_services\nfrom core.platform import models\nfrom core.tests import test_utils\nimport feconf\nimport python_utils\nimport utils\n\n(stats_models,) = models.Registry.import_models([models.NAMES.statistics])\n\n\nclass ExplorationStatsTests(test_utils.GenericTestBase):\n    \"\"\"Tests the ExplorationStats domain object.\"\"\"\n\n    def setUp(self):\n        super(ExplorationStatsTests, self).setUp()\n\n        self.state_stats_dict = {\n            'total_answers_count_v1': 0,\n            'total_answers_count_v2': 10,\n            'useful_feedback_count_v1': 0,\n            'useful_feedback_count_v2': 4,\n            'total_hit_count_v1': 0,\n            'total_hit_count_v2': 18,\n            'first_hit_count_v1': 0,\n            'first_hit_count_v2': 7,\n            'num_times_solution_viewed_v2': 2,\n            'num_completions_v1': 0,\n            'num_completions_v2': 2\n        }\n\n        self.exploration_stats_dict = {\n            'exp_id': 'exp_id1',\n            'exp_version': 1,\n            'num_starts_v1': 0,\n            'num_starts_v2': 30,\n            'num_actual_starts_v1': 0,\n            'num_actual_starts_v2': 10,\n            'num_completions_v1': 0,\n            'num_completions_v2': 5,\n            'state_stats_mapping': {\n                'Home': self.state_stats_dict,\n                'Home2': self.state_stats_dict\n            }\n        }\n\n        self.exploration_stats = self._get_exploration_stats_from_dict(\n            self.exploration_stats_dict)\n\n    def _get_exploration_stats_from_dict(self, exploration_stats_dict):\n        \"\"\"Converts and returns the ExplorationStats object from the given\n        exploration stats dict.\n        \"\"\"\n        state_stats_mapping = {}\n        for state_name in exploration_stats_dict['state_stats_mapping']:\n            state_stats_mapping[state_name] = stats_domain.StateStats.from_dict(\n                exploration_stats_dict['state_stats_mapping'][state_name])\n        return stats_domain.ExplorationStats(\n            exploration_stats_dict['exp_id'],\n            exploration_stats_dict['exp_version'],\n            exploration_stats_dict['num_starts_v1'],\n            exploration_stats_dict['num_starts_v2'],\n            exploration_stats_dict['num_actual_starts_v1'],\n            exploration_stats_dict['num_actual_starts_v2'],\n            exploration_stats_dict['num_completions_v1'],\n            exploration_stats_dict['num_completions_v2'],\n            state_stats_mapping)\n\n    def test_to_dict(self):\n        expected_exploration_stats_dict = {\n            'exp_id': 'exp_id1',\n            'exp_version': 1,\n            'num_starts_v1': 0,\n            'num_starts_v2': 30,\n            'num_actual_starts_v1': 0,\n            'num_actual_starts_v2': 10,\n            'num_completions_v1': 0,\n            'num_completions_v2': 5,\n            'state_stats_mapping': {\n                'Home': self.state_stats_dict\n            }\n        }\n        observed_exploration_stats = self._get_exploration_stats_from_dict(\n            expected_exploration_stats_dict)\n        self.assertDictEqual(\n            expected_exploration_stats_dict,\n            observed_exploration_stats.to_dict())\n\n    def test_get_sum_of_first_hit_counts(self):\n        \"\"\"Test the get_sum_of_first_hit_counts method.\"\"\"\n        self.assertEqual(\n            self.exploration_stats.get_sum_of_first_hit_counts(), 14)\n\n    def test_validate_for_exploration_stats_with_correct_data(self):\n        self.exploration_stats.validate()\n\n    def test_validate_with_int_exp_id(self):\n        self.exploration_stats.exp_id = 10\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected exp_id to be a string')):\n            self.exploration_stats.validate()\n\n    def test_validation_with_string_num_actual_starts(self):\n        self.exploration_stats.num_actual_starts_v2 = '0'\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected num_actual_starts_v2 to be an int')):\n            self.exploration_stats.validate()\n\n    def test_validation_with_list_state_stats_mapping(self):\n        self.exploration_stats.state_stats_mapping = []\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected state_stats_mapping to be a dict')):\n            self.exploration_stats.validate()\n\n    def test_validation_with_negative_num_completions(self):\n        self.exploration_stats.num_completions_v2 = -5\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            '%s cannot have negative values' % ('num_completions_v2'))):\n            self.exploration_stats.validate()\n\n    def test_validate_exp_version(self):\n        self.exploration_stats.exp_version = 'invalid_exp_version'\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected exp_version to be an int')):\n            self.exploration_stats.validate()\n\n    def test_to_frontend_dict(self):\n        state_stats_dict = {\n            'total_answers_count_v1': 0,\n            'total_answers_count_v2': 10,\n            'useful_feedback_count_v1': 0,\n            'useful_feedback_count_v2': 4,\n            'total_hit_count_v1': 0,\n            'total_hit_count_v2': 18,\n            'first_hit_count_v1': 0,\n            'first_hit_count_v2': 7,\n            'num_times_solution_viewed_v2': 2,\n            'num_completions_v1': 0,\n            'num_completions_v2': 2\n        }\n        exploration_stats_dict = {\n            'exp_id': 'exp_id1',\n            'exp_version': 1,\n            'num_starts_v1': 0,\n            'num_starts_v2': 30,\n            'num_actual_starts_v1': 0,\n            'num_actual_starts_v2': 10,\n            'num_completions_v1': 0,\n            'num_completions_v2': 5,\n            'state_stats_mapping': {\n                'Home': state_stats_dict\n            }\n        }\n\n        expected_state_stats_dict = {\n            'total_answers_count': 10,\n            'useful_feedback_count': 4,\n            'total_hit_count': 18,\n            'first_hit_count': 7,\n            'num_times_solution_viewed': 2,\n            'num_completions': 2\n        }\n\n        expected_frontend_dict = {\n            'exp_id': 'exp_id1',\n            'exp_version': 1,\n            'num_starts': 30,\n            'num_actual_starts': 10,\n            'num_completions': 5,\n            'state_stats_mapping': {\n                'Home': expected_state_stats_dict\n            }\n        }\n\n        exploration_stats = self._get_exploration_stats_from_dict(\n            exploration_stats_dict)\n\n        self.assertEqual(\n            exploration_stats.to_frontend_dict(), expected_frontend_dict)\n\n\nclass StateStatsTests(test_utils.GenericTestBase):\n    \"\"\"Tests the StateStats domain object.\"\"\"\n\n    def setUp(self):\n        super(StateStatsTests, self).setUp()\n\n        self.state_stats = stats_domain.StateStats(\n            0, 10, 0, 4, 0, 18, 0, 7, 2, 0, 2)\n\n    def test_from_dict(self):\n        state_stats_dict = {\n            'total_answers_count_v1': 0,\n            'total_answers_count_v2': 10,\n            'useful_feedback_count_v1': 0,\n            'useful_feedback_count_v2': 4,\n            'total_hit_count_v1': 0,\n            'total_hit_count_v2': 18,\n            'first_hit_count_v1': 0,\n            'first_hit_count_v2': 7,\n            'num_times_solution_viewed_v2': 2,\n            'num_completions_v1': 0,\n            'num_completions_v2': 2\n        }\n        state_stats = stats_domain.StateStats(0, 10, 0, 4, 0, 18, 0, 7, 2, 0, 2)\n        expected_state_stats = stats_domain.StateStats.from_dict(\n            state_stats_dict)\n        self.assertEqual(\n            state_stats.total_answers_count_v1,\n            expected_state_stats.total_answers_count_v1)\n        self.assertEqual(\n            state_stats.total_answers_count_v2,\n            expected_state_stats.total_answers_count_v2)\n        self.assertEqual(\n            state_stats.useful_feedback_count_v1,\n            expected_state_stats.useful_feedback_count_v1)\n        self.assertEqual(\n            state_stats.useful_feedback_count_v2,\n            expected_state_stats.useful_feedback_count_v2)\n        self.assertEqual(\n            state_stats.total_hit_count_v1,\n            expected_state_stats.total_hit_count_v1)\n        self.assertEqual(\n            state_stats.total_hit_count_v2,\n            expected_state_stats.total_hit_count_v2)\n        self.assertEqual(\n            state_stats.first_hit_count_v1,\n            expected_state_stats.first_hit_count_v1)\n        self.assertEqual(\n            state_stats.first_hit_count_v2,\n            expected_state_stats.first_hit_count_v2)\n        self.assertEqual(\n            state_stats.num_times_solution_viewed_v2,\n            expected_state_stats.num_times_solution_viewed_v2)\n        self.assertEqual(\n            state_stats.num_completions_v1,\n            expected_state_stats.num_completions_v1)\n        self.assertEqual(\n            state_stats.num_completions_v2,\n            expected_state_stats.num_completions_v2)\n\n    def test_create_default(self):\n        state_stats = stats_domain.StateStats.create_default()\n        self.assertEqual(state_stats.total_answers_count_v1, 0)\n        self.assertEqual(state_stats.total_answers_count_v2, 0)\n        self.assertEqual(state_stats.useful_feedback_count_v1, 0)\n        self.assertEqual(state_stats.useful_feedback_count_v2, 0)\n        self.assertEqual(state_stats.total_hit_count_v1, 0)\n        self.assertEqual(state_stats.total_hit_count_v2, 0)\n        self.assertEqual(state_stats.total_answers_count_v1, 0)\n        self.assertEqual(state_stats.total_answers_count_v2, 0)\n        self.assertEqual(state_stats.num_times_solution_viewed_v2, 0)\n        self.assertEqual(state_stats.num_completions_v1, 0)\n        self.assertEqual(state_stats.num_completions_v2, 0)\n\n    def test_to_dict(self):\n        state_stats_dict = {\n            'total_answers_count_v1': 0,\n            'total_answers_count_v2': 10,\n            'useful_feedback_count_v1': 0,\n            'useful_feedback_count_v2': 4,\n            'total_hit_count_v1': 0,\n            'total_hit_count_v2': 18,\n            'first_hit_count_v1': 0,\n            'first_hit_count_v2': 7,\n            'num_times_solution_viewed_v2': 2,\n            'num_completions_v1': 0,\n            'num_completions_v2': 2\n        }\n        state_stats = stats_domain.StateStats(0, 10, 0, 4, 0, 18, 0, 7, 2, 0, 2)\n        self.assertEqual(state_stats_dict, state_stats.to_dict())\n\n    def test_validation_for_state_stats_with_correct_data(self):\n        self.state_stats.validate()\n\n    def test_validation_for_state_stats_with_string_total_answers_count(self):\n        self.state_stats.total_answers_count_v2 = '10'\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected total_answers_count_v2 to be an int')):\n            self.state_stats.validate()\n\n    def test_validation_for_state_stats_with_negative_total_answers_count(self):\n        self.state_stats.total_answers_count_v2 = -5\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            '%s cannot have negative values' % ('total_answers_count_v2'))):\n            self.state_stats.validate()\n\n    def test_to_frontend_dict(self):\n        state_stats_dict = {\n            'total_answers_count_v1': 0,\n            'total_answers_count_v2': 10,\n            'useful_feedback_count_v1': 0,\n            'useful_feedback_count_v2': 4,\n            'total_hit_count_v1': 0,\n            'total_hit_count_v2': 18,\n            'first_hit_count_v1': 0,\n            'first_hit_count_v2': 7,\n            'num_times_solution_viewed_v2': 2,\n            'num_completions_v1': 0,\n            'num_completions_v2': 2\n        }\n\n        state_stats = stats_domain.StateStats.from_dict(state_stats_dict)\n\n        expected_state_stats_dict = {\n            'total_answers_count': 10,\n            'useful_feedback_count': 4,\n            'total_hit_count': 18,\n            'first_hit_count': 7,\n            'num_times_solution_viewed': 2,\n            'num_completions': 2\n        }\n\n        self.assertEqual(\n            state_stats.to_frontend_dict(), expected_state_stats_dict)\n\n\nclass ExplorationIssuesTests(test_utils.GenericTestBase):\n    \"\"\"Tests the ExplorationIssues domain object.\"\"\"\n\n    def setUp(self):\n        super(ExplorationIssuesTests, self).setUp()\n\n        self.exp_issues = stats_domain.ExplorationIssues(\n            'exp_id1', 1, [\n                stats_domain.ExplorationIssue.from_dict({\n                    'issue_type': 'EarlyQuit',\n                    'issue_customization_args': {\n                        'state_name': {\n                            'value': 'state_name1'\n                        },\n                        'time_spent_in_exp_in_msecs': {\n                            'value': 200\n                        }\n                    },\n                    'playthrough_ids': ['playthrough_id1'],\n                    'schema_version': 1,\n                    'is_valid': True})\n                ])\n\n    def test_create_default(self):\n        exp_issues = stats_domain.ExplorationIssues.create_default('exp_id1', 1)\n        self.assertEqual(exp_issues.exp_id, 'exp_id1')\n        self.assertEqual(exp_issues.exp_version, 1)\n        self.assertEqual(exp_issues.unresolved_issues, [])\n\n    def test_to_dict(self):\n        exp_issues_dict = self.exp_issues.to_dict()\n\n        self.assertEqual(exp_issues_dict['exp_id'], 'exp_id1')\n        self.assertEqual(exp_issues_dict['exp_version'], 1)\n        self.assertEqual(\n            exp_issues_dict['unresolved_issues'], [{\n                'issue_type': 'EarlyQuit',\n                'issue_customization_args': {\n                    'state_name': {\n                        'value': 'state_name1'\n                    },\n                    'time_spent_in_exp_in_msecs': {\n                        'value': 200\n                    }\n                },\n                'playthrough_ids': ['playthrough_id1'],\n                'schema_version': 1,\n                'is_valid': True\n            }])\n\n    def test_from_dict(self):\n        exp_issues_dict = {\n            'exp_id': 'exp_id1',\n            'exp_version': 1,\n            'unresolved_issues': [{\n                'issue_type': 'EarlyQuit',\n                'issue_customization_args': {\n                    'state_name': {\n                        'value': 'state_name1'\n                    },\n                    'time_spent_in_exp_in_msecs': {\n                        'value': 200\n                    }\n                },\n                'playthrough_ids': ['playthrough_id1'],\n                'schema_version': 1,\n                'is_valid': True\n            }]\n        }\n\n        exp_issues = stats_domain.ExplorationIssues.from_dict(exp_issues_dict)\n\n        self.assertEqual(exp_issues.exp_id, 'exp_id1')\n        self.assertEqual(exp_issues.exp_version, 1)\n        self.assertEqual(\n            exp_issues.unresolved_issues[0].to_dict(),\n            {\n                'issue_type': 'EarlyQuit',\n                'issue_customization_args': {\n                    'state_name': {\n                        'value': 'state_name1'\n                    },\n                    'time_spent_in_exp_in_msecs': {\n                        'value': 200\n                    }\n                },\n                'playthrough_ids': ['playthrough_id1'],\n                'schema_version': 1,\n                'is_valid': True})\n\n    def test_validate_for_exp_issues_with_correct_data(self):\n        self.exp_issues.validate()\n\n    def test_validate_with_int_exp_id(self):\n        self.exp_issues.exp_id = 5\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected exp_id to be a string, received %s' % (type(5)))):\n            self.exp_issues.validate()\n\n    def test_validate_exp_version(self):\n        self.exp_issues.exp_version = 'invalid_version'\n\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected exp_version to be an int')):\n            self.exp_issues.validate()\n\n    def test_validate_unresolved_issues(self):\n        self.exp_issues.unresolved_issues = 0\n\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected unresolved_issues to be a list')):\n            self.exp_issues.validate()\n\n\nclass PlaythroughTests(test_utils.GenericTestBase):\n    \"\"\"Tests the Playthrough domain object.\"\"\"\n\n    def setUp(self):\n        super(PlaythroughTests, self).setUp()\n\n        self.playthrough = self._get_valid_early_quit_playthrough()\n\n    def _get_valid_early_quit_playthrough(self):\n        \"\"\"Returns an early quit playthrough after validating it.\"\"\"\n        playthrough = stats_domain.Playthrough(\n            'exp_id1', 1, 'EarlyQuit', {\n                'state_name': {\n                    'value': 'state_name1'\n                },\n                'time_spent_in_exp_in_msecs': {\n                    'value': 200\n                }\n            }, [stats_domain.LearnerAction.from_dict({\n                'action_type': 'ExplorationStart',\n                'action_customization_args': {\n                    'state_name': {\n                        'value': 'state_name1'\n                    }\n                },\n                'schema_version': 1\n            })])\n        playthrough.validate()\n        return playthrough\n\n    def test_to_dict(self):\n        playthrough = stats_domain.Playthrough(\n            'exp_id1', 1, 'EarlyQuit', {\n                'state_name': {\n                    'value': 'state_name1'\n                },\n                'time_spent_in_exp_in_msecs': {\n                    'value': 200\n                }\n            }, [stats_domain.LearnerAction.from_dict({\n                'action_type': 'ExplorationStart',\n                'action_customization_args': {\n                    'state_name': {\n                        'value': 'state_name1'\n                    }\n                },\n                'schema_version': 1\n            })])\n\n        playthrough_dict = playthrough.to_dict()\n\n        self.assertEqual(playthrough_dict['exp_id'], 'exp_id1')\n        self.assertEqual(playthrough_dict['exp_version'], 1)\n        self.assertEqual(playthrough_dict['issue_type'], 'EarlyQuit')\n        self.assertEqual(\n            playthrough_dict['issue_customization_args'], {\n                'state_name': {\n                    'value': 'state_name1'\n                },\n                'time_spent_in_exp_in_msecs': {\n                    'value': 200\n                }\n            })\n        self.assertEqual(\n            playthrough_dict['actions'], [\n                {\n                    'action_type': 'ExplorationStart',\n                    'action_customization_args': {\n                        'state_name': {\n                            'value': 'state_name1'\n                        }\n                    },\n                    'schema_version': 1\n                }])\n\n    def test_from_dict(self):\n        \"\"\"Test the from_dict() method.\"\"\"\n        playthrough_dict = {\n            'exp_id': 'exp_id1',\n            'exp_version': 1,\n            'issue_type': 'EarlyQuit',\n            'issue_customization_args': {\n                'state_name': {\n                    'value': 'state_name1'\n                },\n                'time_spent_in_exp_in_msecs': {\n                    'value': 200\n                }\n            },\n            'actions': [{\n                'action_type': 'ExplorationStart',\n                'action_customization_args': {\n                    'state_name': {\n                        'value': 'state_name1'\n                    }\n                },\n                'schema_version': 1\n            }],\n        }\n\n        playthrough = stats_domain.Playthrough.from_dict(playthrough_dict)\n\n        self.assertEqual(playthrough.exp_id, 'exp_id1')\n        self.assertEqual(playthrough.exp_version, 1)\n        self.assertEqual(playthrough.issue_type, 'EarlyQuit')\n        self.assertEqual(\n            playthrough.issue_customization_args, {\n                'state_name': {\n                    'value': 'state_name1'\n                },\n                'time_spent_in_exp_in_msecs': {\n                    'value': 200\n                }\n            })\n        self.assertEqual(\n            playthrough.actions[0].to_dict(),\n            {\n                'action_type': 'ExplorationStart',\n                'action_customization_args': {\n                    'state_name': {\n                        'value': 'state_name1'\n                    }\n                },\n                'schema_version': 1\n            })\n\n    def test_from_dict_raises_exception_when_miss_exp_id(self):\n        \"\"\"Test the from_dict() method.\"\"\"\n        # Test that a playthrough dict without 'exp_id' key raises exception.\n        playthrough_dict = {\n            'exp_version': 1,\n            'issue_type': 'EarlyQuit',\n            'issue_customization_args': {},\n            'actions': []\n        }\n        with self.assertRaisesRegexp(\n            utils.ValidationError,\n            'exp_id not in playthrough data dict.'):\n            stats_domain.Playthrough.from_dict(playthrough_dict)\n\n    def test_validate_with_string_exp_version(self):\n        self.playthrough.exp_version = '1'\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected exp_version to be an int, received %s' % (type('1')))):\n            self.playthrough.validate()\n\n    def test_validate_with_invalid_issue_type(self):\n        self.playthrough.issue_type = 'InvalidIssueType'\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Invalid issue type: %s' % self.playthrough.issue_type)):\n            self.playthrough.validate()\n\n    def test_validate_with_invalid_action_type(self):\n        self.playthrough.actions = [\n            stats_domain.LearnerAction.from_dict({\n                'action_type': 'InvalidActionType',\n                'schema_version': 1,\n                'action_customization_args': {\n                    'state_name': {\n                        'value': 'state_name1'\n                    }\n                },\n            })]\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Invalid action type: %s' % 'InvalidActionType')):\n            self.playthrough.validate()\n\n    def test_validate_non_str_exp_id(self):\n        self.playthrough.exp_id = 0\n\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected exp_id to be a string')):\n            self.playthrough.validate()\n\n    def test_validate_non_str_issue_type(self):\n        self.playthrough.issue_type = 0\n\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected issue_type to be a string')):\n            self.playthrough.validate()\n\n    def test_validate_non_list_actions(self):\n        self.playthrough.actions = 0\n\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected actions to be a list')):\n            self.playthrough.validate()\n\n    def test_validate_non_dict_issue_customization_args(self):\n        self.playthrough.issue_customization_args = 0\n\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected issue_customization_args to be a dict')):\n            self.playthrough.validate()\n\n\nclass ExplorationIssueTests(test_utils.GenericTestBase):\n    \"\"\"Tests the ExplorationIssue domain object.\"\"\"\n\n    def setUp(self):\n        super(ExplorationIssueTests, self).setUp()\n\n        self.exp_issue = stats_domain.ExplorationIssue(\n            'EarlyQuit', {}, [], 1, True)\n\n    def test_to_dict(self):\n        exp_issue = stats_domain.ExplorationIssue('EarlyQuit', {}, [], 1, True)\n        exp_issue_dict = exp_issue.to_dict()\n        expected_customization_args = {\n            'time_spent_in_exp_in_msecs': {\n                'value': 0\n            },\n            'state_name': {\n                'value': ''\n            }\n        }\n        self.assertEqual(\n            exp_issue_dict, {\n                'issue_type': 'EarlyQuit',\n                'issue_customization_args': expected_customization_args,\n                'playthrough_ids': [],\n                'schema_version': 1,\n                'is_valid': True\n            })\n\n    def test_from_dict(self):\n        expected_customization_args = {\n            'time_spent_in_exp_in_msecs': {\n                'value': 0\n            },\n            'state_name': {\n                'value': ''\n            }\n        }\n        exp_issue = stats_domain.ExplorationIssue.from_dict({\n            'issue_type': 'EarlyQuit',\n            'issue_customization_args': expected_customization_args,\n            'playthrough_ids': [],\n            'schema_version': 1,\n            'is_valid': True\n        })\n        exp_issue_dict = exp_issue.to_dict()\n        self.assertEqual(\n            exp_issue_dict, {\n                'issue_type': 'EarlyQuit',\n                'issue_customization_args': expected_customization_args,\n                'playthrough_ids': [],\n                'schema_version': 1,\n                'is_valid': True\n            })\n\n    def test_from_dict_raises_exception(self):\n        \"\"\"Test the from_dict() method.\"\"\"\n        # Test that an exploration issue dict without 'issue_type' key raises\n        # exception.\n        exp_issue_dict = {\n            'issue_customization_args': {},\n            'playthrough_ids': [],\n            'schema_version': 1,\n            'is_valid': True\n        }\n        with self.assertRaisesRegexp(\n            utils.ValidationError,\n            'issue_type not in exploration issue dict.'):\n            stats_domain.ExplorationIssue.from_dict(exp_issue_dict)\n\n    def test_cannot_update_exp_issue_from_invalid_schema_version_model(self):\n        exp_issue = stats_domain.ExplorationIssue('EarlyQuit', {}, [], 4, True)\n        exp_issue_dict = exp_issue.to_dict()\n        stats_models.ExplorationIssuesModel.create(\n            'exp_id', 1, [exp_issue_dict])\n\n        exp_issues_model = stats_models.ExplorationIssuesModel.get_model(\n            'exp_id', 1)\n\n        with self.assertRaisesRegexp(\n            Exception,\n            'Sorry, we can only process v1-v%d and unversioned issue schemas at'\n            ' present.' %\n            stats_models.CURRENT_ISSUE_SCHEMA_VERSION):\n            stats_services.get_exp_issues_from_model(exp_issues_model)\n\n    def test_cannot_update_exp_issue_with_no_schema_version(self):\n        exp_issue = stats_domain.ExplorationIssue(\n            'EarlyQuit', {}, [], None, True)\n        exp_issue_dict = exp_issue.to_dict()\n        stats_models.ExplorationIssuesModel.create(\n            'exp_id', 1, [exp_issue_dict])\n\n        exp_issues_model = stats_models.ExplorationIssuesModel.get_model(\n            'exp_id', 1)\n\n        with self.assertRaises(Exception):\n            stats_services.get_exp_issues_from_model(exp_issues_model)\n\n    def test_actual_update_exp_issue_from_model_raises_error(self):\n        exp_issue = stats_domain.ExplorationIssue('EarlyQuit', {}, [], 1, True)\n        exp_issue_dict = exp_issue.to_dict()\n\n        with self.assertRaises(NotImplementedError):\n            stats_domain.ExplorationIssue.update_exp_issue_from_model(\n                exp_issue_dict)\n\n    def test_validate_for_exp_issues_with_correct_data(self):\n        self.exp_issue.validate()\n\n    def test_validate_with_int_issue_type(self):\n        self.exp_issue.issue_type = 5\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected issue_type to be a string, received %s' % (type(5)))):\n            self.exp_issue.validate()\n\n    def test_validate_with_string_schema_version(self):\n        self.exp_issue.schema_version = '1'\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected schema_version to be an int, received %s' % (type('1')))):\n            self.exp_issue.validate()\n\n    def test_validate_issue_type(self):\n        self.exp_issue.issue_type = 'invalid_issue_type'\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Invalid issue type')):\n            self.exp_issue.validate()\n\n    def test_validate_playthrough_ids(self):\n        self.exp_issue.playthrough_ids = 'invalid_playthrough_ids'\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected playthrough_ids to be a list')):\n            self.exp_issue.validate()\n\n    def test_validate_playthrough_id_type(self):\n        self.exp_issue.playthrough_ids = [0, 1]\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected each playthrough_id to be a string')):\n            self.exp_issue.validate()\n\n\n\nclass LearnerActionTests(test_utils.GenericTestBase):\n    \"\"\"Tests the LearnerAction domain object.\"\"\"\n\n    def setUp(self):\n        super(LearnerActionTests, self).setUp()\n\n        self.learner_action = stats_domain.LearnerAction(\n            'ExplorationStart', {}, 1)\n\n    def _dummy_convert_action_v1_dict_to_v2_dict(self, action_dict):\n        \"\"\"A test implementation of schema conversion function.\"\"\"\n        action_dict['schema_version'] = 2\n        if action_dict['action_type'] == 'ExplorationStart':\n            action_dict['action_type'] = 'ExplorationStart1'\n            action_dict['action_customization_args']['new_key'] = 5\n\n        return action_dict\n\n    def test_to_dict(self):\n        learner_action = stats_domain.LearnerAction('ExplorationStart', {}, 1)\n        learner_action_dict = learner_action.to_dict()\n        expected_customization_args = {\n            'state_name': {\n                'value': ''\n            }\n        }\n        self.assertEqual(\n            learner_action_dict, {\n                'action_type': 'ExplorationStart',\n                'action_customization_args': expected_customization_args,\n                'schema_version': 1\n            })\n\n    def test_update_learner_action_from_model(self):\n        \"\"\"Test the migration of learner action domain objects.\"\"\"\n        learner_action = stats_domain.LearnerAction('ExplorationStart', {}, 1)\n        learner_action_dict = learner_action.to_dict()\n\n        playthrough_id = stats_models.PlaythroughModel.create(\n            'exp_id', 1, 'EarlyQuit', {\n                'state_name': {\n                    'value': 'state_name1'\n                },\n                'time_spent_in_exp_in_msecs': {\n                    'value': 200\n                }\n            }, [learner_action_dict])\n\n        playthrough_model = stats_models.PlaythroughModel.get(playthrough_id)\n\n        current_action_schema_version_swap = self.swap(\n            stats_models, 'CURRENT_ACTION_SCHEMA_VERSION', 2)\n        convert_action_dict_swap = self.swap(\n            stats_domain.LearnerAction,\n            '_convert_action_v1_dict_to_v2_dict',\n            self._dummy_convert_action_v1_dict_to_v2_dict)\n\n        with current_action_schema_version_swap, convert_action_dict_swap:\n            playthrough = stats_services.get_playthrough_from_model(\n                playthrough_model)\n\n        self.assertEqual(\n            playthrough.actions[0].action_type, 'ExplorationStart1')\n        self.assertEqual(\n            playthrough.actions[0].action_customization_args['new_key'], 5)\n\n        # For other action types, no changes happen during migration.\n        learner_action1 = stats_domain.LearnerAction('ExplorationQuit', {}, 1)\n        learner_action_dict1 = learner_action1.to_dict()\n\n        playthrough_id_1 = stats_models.PlaythroughModel.create(\n            'exp_id', 1, 'EarlyQuit', {\n                'state_name': {\n                    'value': 'state_name1'\n                },\n                'time_spent_in_exp_in_msecs': {\n                    'value': 200\n                }\n            }, [learner_action_dict1])\n\n        playthrough_model_1 = stats_models.PlaythroughModel.get(\n            playthrough_id_1)\n\n        current_action_schema_version_swap = self.swap(\n            stats_models, 'CURRENT_ACTION_SCHEMA_VERSION', 2)\n        convert_action_dict_swap = self.swap(\n            stats_domain.LearnerAction,\n            '_convert_action_v1_dict_to_v2_dict',\n            self._dummy_convert_action_v1_dict_to_v2_dict)\n\n        with current_action_schema_version_swap, convert_action_dict_swap:\n            playthrough1 = stats_services.get_playthrough_from_model(\n                playthrough_model_1)\n\n        self.assertEqual(\n            playthrough1.actions[0].action_type, 'ExplorationQuit')\n\n    def test_cannot_update_learner_action_from_invalid_schema_version_model(\n            self):\n        learner_action = stats_domain.LearnerAction('ExplorationStart', {}, 4)\n        learner_action_dict = learner_action.to_dict()\n\n        playthrough_id = stats_models.PlaythroughModel.create(\n            'exp_id', 1, 'EarlyQuit', {\n                'state_name': {\n                    'value': 'state_name1'\n                },\n                'time_spent_in_exp_in_msecs': {\n                    'value': 200\n                }\n            }, [learner_action_dict])\n\n        playthrough_model = stats_models.PlaythroughModel.get(playthrough_id)\n\n        with self.assertRaisesRegexp(\n            Exception,\n            'Sorry, we can only process v1-v%d and unversioned action schemas'\n            ' at present.' %\n            stats_models.CURRENT_ISSUE_SCHEMA_VERSION):\n            stats_services.get_playthrough_from_model(\n                playthrough_model)\n\n    def test_cannot_update_learner_action_with_no_schema_version(self):\n        learner_action = stats_domain.LearnerAction(\n            'ExplorationStart', {}, None)\n        learner_action_dict = learner_action.to_dict()\n\n        playthrough_id = stats_models.PlaythroughModel.create(\n            'exp_id', 1, 'EarlyQuit', {\n                'state_name': {\n                    'value': 'state_name1'\n                },\n                'time_spent_in_exp_in_msecs': {\n                    'value': 200\n                }\n            }, [learner_action_dict])\n\n        playthrough_model = stats_models.PlaythroughModel.get(playthrough_id)\n\n        with self.assertRaises(Exception):\n            stats_services.get_playthrough_from_model(playthrough_model)\n\n    def test_actual_update_learner_action_from_model_raises_error(self):\n        learner_action = stats_domain.LearnerAction('ExplorationStart', {}, 1)\n        learner_action_dict = learner_action.to_dict()\n\n        with self.assertRaises(NotImplementedError):\n            stats_domain.LearnerAction.update_learner_action_from_model(\n                learner_action_dict)\n\n    def test_validate_for_learner_action_with_correct_data(self):\n        self.learner_action.validate()\n\n    def test_validate_with_int_action_type(self):\n        self.learner_action.action_type = 5\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected action_type to be a string, received %s' % (type(5)))):\n            self.learner_action.validate()\n\n    def test_validate_with_string_schema_version(self):\n        self.learner_action.schema_version = '1'\n        with self.assertRaisesRegexp(utils.ValidationError, (\n            'Expected schema_version to be an int, received %s' % (type('1')))):\n            self.learner_action.validate()\n\n\nclass StateAnswersTests(test_utils.GenericTestBase):\n    \"\"\"Tests the StateAnswers domain object.\"\"\"\n\n    def test_can_retrieve_properly_constructed_submitted_answer_dict_list(self):\n        state_answers = stats_domain.StateAnswers(\n            'exp_id', 1, 'initial_state', 'TextInput', [\n                stats_domain.SubmittedAnswer(\n                    'Text', 'TextInput', 0, 1,\n                    exp_domain.EXPLICIT_CLASSIFICATION, {}, 'sess', 10.5,\n                    rule_spec_str='rule spec str1', answer_str='answer str1'),\n                stats_domain.SubmittedAnswer(\n                    'Other text', 'TextInput', 1, 0,\n                    exp_domain.DEFAULT_OUTCOME_CLASSIFICATION, {}, 'sess', 7.5,\n                    rule_spec_str='rule spec str2', answer_str='answer str2')])\n        submitted_answer_dict_list = (\n            state_answers.get_submitted_answer_dict_list())\n        self.assertEqual(\n            submitted_answer_dict_list, [{\n                'answer': 'Text',\n                'interaction_id': 'TextInput',\n                'answer_group_index': 0,\n                'rule_spec_index': 1,\n                'classification_categorization': (\n                    exp_domain.EXPLICIT_CLASSIFICATION),\n                'params': {},\n                'session_id': 'sess',\n                'time_spent_in_sec': 10.5,\n                'rule_spec_str': 'rule spec str1',\n                'answer_str': 'answer str1'\n            }, {\n                'answer': 'Other text',\n                'interaction_id': 'TextInput',\n                'answer_group_index': 1,\n                'rule_spec_index': 0,\n                'classification_categorization': (\n                    exp_domain.DEFAULT_OUTCOME_CLASSIFICATION),\n                'params': {},\n                'session_id': 'sess',\n                'time_spent_in_sec': 7.5,\n                'rule_spec_str': 'rule spec str2',\n                'answer_str': 'answer str2'\n            }])\n\n\nclass StateAnswersValidationTests(test_utils.GenericTestBase):\n    \"\"\"Tests the StateAnswers domain object for validation.\"\"\"\n\n    def setUp(self):\n        super(StateAnswersValidationTests, self).setUp()\n        self.state_answers = stats_domain.StateAnswers(\n            'exp_id', 1, 'initial_state', 'TextInput', [])\n\n        # The canonical object should have no validation problems.\n        self.state_answers.validate()\n\n    def test_exploration_id_must_be_string(self):\n        self.state_answers.exploration_id = 0\n        self._assert_validation_error(\n            self.state_answers, 'Expected exploration_id to be a string')\n\n    def test_state_name_must_be_string(self):\n        self.state_answers.state_name = ['state']\n        self._assert_validation_error(\n            self.state_answers, 'Expected state_name to be a string')\n\n    def test_interaction_id_can_be_none(self):\n        self.state_answers.interaction_id = None\n        self.state_answers.validate()\n\n    def test_interaction_id_must_otherwise_be_string(self):\n        self.state_answers.interaction_id = 10\n        self._assert_validation_error(\n            self.state_answers, 'Expected interaction_id to be a string')\n\n    def test_interaction_id_must_refer_to_existing_interaction(self):\n        self.state_answers.interaction_id = 'FakeInteraction'\n        self._assert_validation_error(\n            self.state_answers, 'Unknown interaction_id: FakeInteraction')\n\n    def test_submitted_answer_list_must_be_list(self):\n        self.state_answers.submitted_answer_list = {}\n        self._assert_validation_error(\n            self.state_answers, 'Expected submitted_answer_list to be a list')\n\n    def test_schema_version_must_be_integer(self):\n        self.state_answers.schema_version = '1'\n        self._assert_validation_error(\n            self.state_answers, 'Expected schema_version to be an integer')\n\n    def test_schema_version_must_be_between_one_and_current_version(self):\n        self.state_answers.schema_version = 0\n        self._assert_validation_error(\n            self.state_answers, 'schema_version < 1: 0')\n\n        self.state_answers.schema_version = (\n            feconf.CURRENT_STATE_ANSWERS_SCHEMA_VERSION + 1)\n        self._assert_validation_error(\n            self.state_answers,\n            'schema_version > feconf\\\\.CURRENT_STATE_ANSWERS_SCHEMA_VERSION')\n\n        self.state_answers.schema_version = 1\n        self.state_answers.validate()\n\n\nclass SubmittedAnswerTests(test_utils.GenericTestBase):\n    \"\"\"Tests the SubmittedAnswer domain object.\"\"\"\n\n    def test_can_be_converted_to_from_full_dict(self):\n        submitted_answer = stats_domain.SubmittedAnswer(\n            'Text', 'TextInput', 0, 1, exp_domain.EXPLICIT_CLASSIFICATION, {},\n            'sess', 10.5, rule_spec_str='rule spec str',\n            answer_str='answer str')\n        submitted_answer_dict = submitted_answer.to_dict()\n        cloned_submitted_answer = stats_domain.SubmittedAnswer.from_dict(\n            submitted_answer_dict)\n        self.assertEqual(\n            cloned_submitted_answer.to_dict(), submitted_answer_dict)\n\n    def test_can_be_converted_to_full_dict(self):\n        submitted_answer = stats_domain.SubmittedAnswer(\n            'Text', 'TextInput', 0, 1, exp_domain.EXPLICIT_CLASSIFICATION, {},\n            'sess', 10.5, rule_spec_str='rule spec str',\n            answer_str='answer str')\n        self.assertEqual(submitted_answer.to_dict(), {\n            'answer': 'Text',\n            'interaction_id': 'TextInput',\n            'answer_group_index': 0,\n            'rule_spec_index': 1,\n            'classification_categorization': exp_domain.EXPLICIT_CLASSIFICATION,\n            'params': {},\n            'session_id': 'sess',\n            'time_spent_in_sec': 10.5,\n            'rule_spec_str': 'rule spec str',\n            'answer_str': 'answer str'\n        })\n\n    def test_dict_may_not_include_rule_spec_str_or_answer_str(self):\n        submitted_answer = stats_domain.SubmittedAnswer(\n            'Text', 'TextInput', 0, 1, exp_domain.EXPLICIT_CLASSIFICATION, {},\n            'sess', 10.5)\n        self.assertEqual(submitted_answer.to_dict(), {\n            'answer': 'Text',\n            'interaction_id': 'TextInput',\n            'answer_group_index': 0,\n            'rule_spec_index': 1,\n            'classification_categorization': exp_domain.EXPLICIT_CLASSIFICATION,\n            'params': {},\n            'session_id': 'sess',\n            'time_spent_in_sec': 10.5\n        })\n\n    def test_requires_answer_to_be_created_from_dict(self):\n        with self.assertRaisesRegexp(KeyError, 'answer'):\n            stats_domain.SubmittedAnswer.from_dict({\n                'interaction_id': 'TextInput',\n                'answer_group_index': 0,\n                'rule_spec_index': 1,\n                'classification_categorization': (\n                    exp_domain.EXPLICIT_CLASSIFICATION),\n                'params': {},\n                'session_id': 'sess',\n                'time_spent_in_sec': 10.5\n            })\n\n    def test_requires_interaction_id_to_be_created_from_dict(self):\n        with self.assertRaisesRegexp(KeyError, 'interaction_id'):\n            stats_domain.SubmittedAnswer.from_dict({\n                'answer': 'Text',\n                'answer_group_index': 0,\n                'rule_spec_index': 1,\n                'classification_categorization': (\n                    exp_domain.EXPLICIT_CLASSIFICATION),\n                'params': {},\n                'session_id': 'sess',\n                'time_spent_in_sec': 10.5\n            })\n\n    def test_requires_answer_group_index_to_be_created_from_dict(self):\n        with self.assertRaisesRegexp(KeyError, 'answer_group_index'):\n            stats_domain.SubmittedAnswer.from_dict({\n                'answer': 'Text',\n                'interaction_id': 'TextInput',\n                'rule_spec_index': 1,\n                'classification_categorization': (\n                    exp_domain.EXPLICIT_CLASSIFICATION),\n                'params': {},\n                'session_id': 'sess',\n                'time_spent_in_sec': 10.5\n            })\n\n    def test_requires_rule_spec_index_to_be_created_from_dict(self):\n        with self.assertRaisesRegexp(KeyError, 'rule_spec_index'):\n            stats_domain.SubmittedAnswer.from_dict({\n                'answer': 'Text',\n                'interaction_id': 'TextInput',\n                'answer_group_index': 0,\n                'classification_categorization': (\n                    exp_domain.EXPLICIT_CLASSIFICATION),\n                'params': {},\n                'session_id': 'sess',\n                'time_spent_in_sec': 10.5\n            })\n\n    def test_requires_classification_categ_to_be_created_from_dict(self):\n        with self.assertRaisesRegexp(KeyError, 'classification_categorization'):\n            stats_domain.SubmittedAnswer.from_dict({\n                'answer': 'Text',\n                'interaction_id': 'TextInput',\n                'answer_group_index': 0,\n                'rule_spec_index': 1,\n                'params': {},\n                'session_id': 'sess',\n                'time_spent_in_sec': 10.5\n            })\n\n    def test_requires_params_to_be_created_from_dict(self):\n        with self.assertRaisesRegexp(KeyError, 'params'):\n            stats_domain.SubmittedAnswer.from_dict({\n                'answer': 'Text',\n                'interaction_id': 'TextInput',\n                'answer_group_index': 0,\n                'rule_spec_index': 1,\n                'classification_categorization': (\n                    exp_domain.EXPLICIT_CLASSIFICATION),\n                'session_id': 'sess',\n                'time_spent_in_sec': 10.5\n            })\n\n    def test_requires_session_id_to_be_created_from_dict(self):\n        with self.assertRaisesRegexp(KeyError, 'session_id'):\n            stats_domain.SubmittedAnswer.from_dict({\n                'answer': 'Text',\n                'interaction_id': 'TextInput',\n                'answer_group_index': 0,\n                'rule_spec_index': 1,\n                'classification_categorization': (\n                    exp_domain.EXPLICIT_CLASSIFICATION),\n                'params': {},\n                'time_spent_in_sec': 10.5\n            })\n\n    def test_requires_time_spent_in_sec_to_be_created_from_dict(self):\n        with self.assertRaisesRegexp(KeyError, 'time_spent_in_sec'):\n            stats_domain.SubmittedAnswer.from_dict({\n                'answer': 'Text',\n                'interaction_id': 'TextInput',\n                'answer_group_index': 0,\n                'rule_spec_index': 1,\n                'classification_categorization': (\n                    exp_domain.EXPLICIT_CLASSIFICATION),\n                'params': {},\n                'session_id': 'sess',\n            })\n\n    def test_can_be_created_from_full_dict(self):\n        submitted_answer = stats_domain.SubmittedAnswer.from_dict({\n            'answer': 'Text',\n            'interaction_id': 'TextInput',\n            'answer_group_index': 0,\n            'rule_spec_index': 1,\n            'classification_categorization': (\n                exp_domain.EXPLICIT_CLASSIFICATION),\n            'params': {},\n            'session_id': 'sess',\n            'time_spent_in_sec': 10.5,\n            'rule_spec_str': 'rule spec str',\n            'answer_str': 'answer str'\n        })\n        self.assertEqual(submitted_answer.answer, 'Text')\n        self.assertEqual(submitted_answer.interaction_id, 'TextInput')\n        self.assertEqual(submitted_answer.answer_group_index, 0)\n        self.assertEqual(submitted_answer.rule_spec_index, 1)\n        self.assertEqual(\n            submitted_answer.classification_categorization,\n            exp_domain.EXPLICIT_CLASSIFICATION)\n        self.assertEqual(submitted_answer.params, {})\n        self.assertEqual(submitted_answer.session_id, 'sess')\n        self.assertEqual(submitted_answer.time_spent_in_sec, 10.5)\n        self.assertEqual(submitted_answer.rule_spec_str, 'rule spec str')\n        self.assertEqual(submitted_answer.answer_str, 'answer str')\n\n    def test_can_be_created_from_dict_missing_rule_spec_and_answer(self):\n        submitted_answer = stats_domain.SubmittedAnswer.from_dict({\n            'answer': 'Text',\n            'interaction_id': 'TextInput',\n            'answer_group_index': 0,\n            'rule_spec_index': 1,\n            'classification_categorization': (\n                exp_domain.EXPLICIT_CLASSIFICATION),\n            'params': {},\n            'session_id': 'sess',\n            'time_spent_in_sec': 10.5\n        })\n        self.assertEqual(submitted_answer.answer, 'Text')\n        self.assertEqual(submitted_answer.interaction_id, 'TextInput')\n        self.assertEqual(submitted_answer.answer_group_index, 0)\n        self.assertEqual(submitted_answer.rule_spec_index, 1)\n        self.assertEqual(\n            submitted_answer.classification_categorization,\n            exp_domain.EXPLICIT_CLASSIFICATION)\n        self.assertEqual(submitted_answer.params, {})\n        self.assertEqual(submitted_answer.session_id, 'sess')\n        self.assertEqual(submitted_answer.time_spent_in_sec, 10.5)\n        self.assertIsNone(submitted_answer.rule_spec_str)\n        self.assertIsNone(submitted_answer.answer_str)\n\n\nclass SubmittedAnswerValidationTests(test_utils.GenericTestBase):\n    \"\"\"Tests the SubmittedAnswer domain object for validation.\"\"\"\n\n    def setUp(self):\n        super(SubmittedAnswerValidationTests, self).setUp()\n        self.submitted_answer = stats_domain.SubmittedAnswer(\n            'Text', 'TextInput', 0, 0, exp_domain.EXPLICIT_CLASSIFICATION, {},\n            'session_id', 0.)\n\n        # The canonical object should have no validation problems.\n        self.submitted_answer.validate()\n\n    def test_answer_may_be_none_only_for_linear_interaction(self):\n        # It's valid for answer to be None if the interaction type is Continue.\n        self.submitted_answer.answer = None\n        self._assert_validation_error(\n            self.submitted_answer,\n            'SubmittedAnswers must have a provided answer except for linear '\n            'interactions')\n\n        self.submitted_answer.interaction_id = 'Continue'\n        self.submitted_answer.validate()\n\n    def test_time_spent_in_sec_must_not_be_none(self):\n        self.submitted_answer.time_spent_in_sec = None\n        self._assert_validation_error(\n            self.submitted_answer,\n            'SubmittedAnswers must have a provided time_spent_in_sec')\n\n    def test_time_spent_in_sec_must_be_number(self):\n        self.submitted_answer.time_spent_in_sec = '0'\n        self._assert_validation_error(\n            self.submitted_answer, 'Expected time_spent_in_sec to be a number')\n\n    def test_time_spent_in_sec_must_be_positive(self):\n        self.submitted_answer.time_spent_in_sec = -1.\n        self._assert_validation_error(\n            self.submitted_answer,\n            'Expected time_spent_in_sec to be non-negative')\n\n    def test_session_id_must_not_be_none(self):\n        self.submitted_answer.session_id = None\n        self._assert_validation_error(\n            self.submitted_answer,\n            'SubmittedAnswers must have a provided session_id')\n\n    def test_session_id_must_be_string(self):\n        self.submitted_answer.session_id = 90\n        self._assert_validation_error(\n            self.submitted_answer, 'Expected session_id to be a string')\n\n    def test_params_must_be_dict(self):\n        self.submitted_answer.params = []\n        self._assert_validation_error(\n            self.submitted_answer, 'Expected params to be a dict')\n\n    def test_answer_group_index_must_be_integer(self):\n        self.submitted_answer.answer_group_index = '0'\n        self._assert_validation_error(\n            self.submitted_answer,\n            'Expected answer_group_index to be an integer')\n\n    def test_answer_group_index_must_be_positive(self):\n        self.submitted_answer.answer_group_index = -1\n        self._assert_validation_error(\n            self.submitted_answer,\n            'Expected answer_group_index to be non-negative')\n\n    def test_rule_spec_index_can_be_none(self):\n        self.submitted_answer.rule_spec_index = None\n        self.submitted_answer.validate()\n\n    def test_rule_spec_index_must_be_integer(self):\n        self.submitted_answer.rule_spec_index = '0'\n        self._assert_validation_error(\n            self.submitted_answer, 'Expected rule_spec_index to be an integer')\n        self.submitted_answer.rule_spec_index = ''\n        self._assert_validation_error(\n            self.submitted_answer, 'Expected rule_spec_index to be an integer')\n        self.submitted_answer.rule_spec_index = 0\n        self.submitted_answer.validate()\n\n    def test_rule_spec_index_must_be_positive(self):\n        self.submitted_answer.rule_spec_index = -1\n        self._assert_validation_error(\n            self.submitted_answer,\n            'Expected rule_spec_index to be non-negative')\n\n    def test_classification_categorization_must_be_valid_category(self):\n        self.submitted_answer.classification_categorization = (\n            exp_domain.TRAINING_DATA_CLASSIFICATION)\n        self.submitted_answer.validate()\n\n        self.submitted_answer.classification_categorization = (\n            exp_domain.STATISTICAL_CLASSIFICATION)\n        self.submitted_answer.validate()\n\n        self.submitted_answer.classification_categorization = (\n            exp_domain.DEFAULT_OUTCOME_CLASSIFICATION)\n        self.submitted_answer.validate()\n\n        self.submitted_answer.classification_categorization = 'soft'\n        self._assert_validation_error(\n            self.submitted_answer,\n            'Expected valid classification_categorization')\n\n    def test_rule_spec_str_must_be_none_or_string(self):\n        self.submitted_answer.rule_spec_str = 10\n        self._assert_validation_error(\n            self.submitted_answer,\n            'Expected rule_spec_str to be either None or a string')\n\n        self.submitted_answer.rule_spec_str = 'str'\n        self.submitted_answer.validate()\n\n        self.submitted_answer.rule_spec_str = None\n        self.submitted_answer.validate()\n\n    def test_answer_str_must_be_none_or_string(self):\n        self.submitted_answer.answer_str = 10\n        self._assert_validation_error(\n            self.submitted_answer,\n            'Expected answer_str to be either None or a string')\n\n        self.submitted_answer.answer_str = 'str'\n        self.submitted_answer.validate()\n\n        self.submitted_answer.answer_str = None\n        self.submitted_answer.validate()\n\n\nclass AnswerFrequencyListDomainTests(test_utils.GenericTestBase):\n    \"\"\"Tests AnswerFrequencyList for basic domain object operations.\"\"\"\n\n    ANSWER_A = stats_domain.AnswerOccurrence('answer a', 3)\n    ANSWER_B = stats_domain.AnswerOccurrence('answer b', 2)\n    ANSWER_C = stats_domain.AnswerOccurrence('answer c', 1)\n\n    def test_has_correct_type(self):\n        answer_frequency_list = stats_domain.AnswerFrequencyList([])\n        self.assertEqual(\n            answer_frequency_list.calculation_output_type,\n            stats_domain.CALC_OUTPUT_TYPE_ANSWER_FREQUENCY_LIST)\n\n    def test_defaults_to_empty_list(self):\n        answer_frequency_list = stats_domain.AnswerFrequencyList()\n        self.assertEqual(len(answer_frequency_list.answer_occurrences), 0)\n\n    def test_create_list_from_raw_object(self):\n        answer_frequency_list = (\n            stats_domain.AnswerFrequencyList.from_raw_type([{\n                'answer': 'answer a', 'frequency': 3\n            }, {\n                'answer': 'answer b', 'frequency': 2\n            }]))\n        answer_occurrences = answer_frequency_list.answer_occurrences\n        self.assertEqual(len(answer_occurrences), 2)\n        self.assertEqual(answer_occurrences[0].answer, 'answer a')\n        self.assertEqual(answer_occurrences[0].frequency, 3)\n        self.assertEqual(answer_occurrences[1].answer, 'answer b')\n        self.assertEqual(answer_occurrences[1].frequency, 2)\n\n    def test_convert_list_to_raw_object(self):\n        answer_frequency_list = stats_domain.AnswerFrequencyList(\n            [self.ANSWER_A, self.ANSWER_B])\n        self.assertEqual(answer_frequency_list.to_raw_type(), [{\n            'answer': 'answer a', 'frequency': 3\n        }, {\n            'answer': 'answer b', 'frequency': 2\n        }])\n\n\nclass CategorizedAnswerFrequencyListsDomainTests(test_utils.GenericTestBase):\n    \"\"\"Tests CategorizedAnswerFrequencyLists for basic domain object\n    operations.\n    \"\"\"\n    ANSWER_A = stats_domain.AnswerOccurrence('answer a', 3)\n    ANSWER_B = stats_domain.AnswerOccurrence('answer b', 2)\n    ANSWER_C = stats_domain.AnswerOccurrence('answer c', 1)\n\n    def test_has_correct_type(self):\n        answer_frequency_lists = (\n            stats_domain.CategorizedAnswerFrequencyLists({}))\n        self.assertEqual(\n            answer_frequency_lists.calculation_output_type,\n            stats_domain.CALC_OUTPUT_TYPE_CATEGORIZED_ANSWER_FREQUENCY_LISTS)\n\n    def test_defaults_to_empty_dict(self):\n        answer_frequency_lists = stats_domain.CategorizedAnswerFrequencyLists()\n        self.assertEqual(\n            len(answer_frequency_lists.categorized_answer_freq_lists), 0)\n\n    def test_create_list_from_raw_object(self):\n        answer_frequency_lists = (\n            stats_domain.CategorizedAnswerFrequencyLists.from_raw_type({\n                'category a': [{'answer': 'answer a', 'frequency': 3}],\n                'category b': [{\n                    'answer': 'answer b',\n                    'frequency': 2\n                }, {\n                    'answer': 'answer c',\n                    'frequency': 1\n                }]\n            }))\n        self.assertEqual(\n            len(answer_frequency_lists.categorized_answer_freq_lists), 2)\n        self.assertIn(\n            'category a', answer_frequency_lists.categorized_answer_freq_lists)\n        self.assertIn(\n            'category b', answer_frequency_lists.categorized_answer_freq_lists)\n\n        category_a_answer_list = (\n            answer_frequency_lists.categorized_answer_freq_lists['category a'])\n        category_b_answer_list = (\n            answer_frequency_lists.categorized_answer_freq_lists['category b'])\n        category_a_answers = category_a_answer_list.answer_occurrences\n        category_b_answers = category_b_answer_list.answer_occurrences\n        self.assertEqual(len(category_a_answers), 1)\n        self.assertEqual(len(category_b_answers), 2)\n\n        self.assertEqual(category_a_answers[0].answer, 'answer a')\n        self.assertEqual(category_a_answers[0].frequency, 3)\n        self.assertEqual(category_b_answers[0].answer, 'answer b')\n        self.assertEqual(category_b_answers[0].frequency, 2)\n        self.assertEqual(category_b_answers[1].answer, 'answer c')\n        self.assertEqual(category_b_answers[1].frequency, 1)\n\n    def test_convert_list_to_raw_object(self):\n        answer_frequency_lists = stats_domain.CategorizedAnswerFrequencyLists({\n            'category a': stats_domain.AnswerFrequencyList([self.ANSWER_A]),\n            'category b': stats_domain.AnswerFrequencyList(\n                [self.ANSWER_B, self.ANSWER_C]),\n        })\n        self.assertEqual(answer_frequency_lists.to_raw_type(), {\n            'category a': [{'answer': 'answer a', 'frequency': 3}],\n            'category b': [{\n                'answer': 'answer b',\n                'frequency': 2\n            }, {\n                'answer': 'answer c',\n                'frequency': 1\n            }]\n        })\n\n\nclass StateAnswersCalcOutputValidationTests(test_utils.GenericTestBase):\n    \"\"\"Tests the StateAnswersCalcOutput domain object for validation.\"\"\"\n\n    class MockCalculationOutputObjectWithUnknownType(python_utils.OBJECT):\n        pass\n\n    def setUp(self):\n        super(StateAnswersCalcOutputValidationTests, self).setUp()\n        self.state_answers_calc_output = stats_domain.StateAnswersCalcOutput(\n            'exp_id', 1, 'initial_state', 'TextInput', 'AnswerFrequencies',\n            stats_domain.AnswerFrequencyList.from_raw_type([]))\n\n        # The canonical object should have no validation problems.\n        self.state_answers_calc_output.validate()\n\n    def test_exploration_id_must_be_string(self):\n        self.state_answers_calc_output.exploration_id = 0\n        self._assert_validation_error(\n            self.state_answers_calc_output,\n            'Expected exploration_id to be a string')\n\n    def test_state_name_must_be_string(self):\n        self.state_answers_calc_output.state_name = ['state']\n        self._assert_validation_error(\n            self.state_answers_calc_output,\n            'Expected state_name to be a string')\n\n    def test_calculation_id_must_be_string(self):\n        self.state_answers_calc_output.calculation_id = ['calculation id']\n        self._assert_validation_error(\n            self.state_answers_calc_output,\n            'Expected calculation_id to be a string')\n\n    def test_calculation_output_must_be_known_type(self):\n        self.state_answers_calc_output.calculation_output = (\n            self.MockCalculationOutputObjectWithUnknownType())\n        self._assert_validation_error(\n            self.state_answers_calc_output,\n            'Expected calculation output to be one of')\n\n    def test_calculation_output_must_be_less_than_one_million_bytes(self):\n        occurred_answer = stats_domain.AnswerOccurrence(\n            'This is not a long sentence.', 1)\n        self.state_answers_calc_output.calculation_output = (\n            stats_domain.AnswerFrequencyList(\n                [occurred_answer] * 200000))\n        self._assert_validation_error(\n            self.state_answers_calc_output,\n            'calculation_output is too big to be stored')\n\n\nclass LearnerAnswerDetailsTests(test_utils.GenericTestBase):\n\n    def setUp(self):\n        super(LearnerAnswerDetailsTests, self).setUp()\n        self.learner_answer_details = stats_domain.LearnerAnswerDetails(\n            'exp_id:state_name', feconf.ENTITY_TYPE_EXPLORATION,\n            'TextInput', [stats_domain.LearnerAnswerInfo(\n                'id_1', 'This is my answer', 'This is my answer details',\n                datetime.datetime(2019, 6, 19, 13, 59, 29, 153073))], 4000)\n        self.learner_answer_details.validate()\n\n    def test_to_dict(self):\n        expected_learner_answer_details_dict = {\n            'state_reference': 'exp_id:state_name',\n            'entity_type': 'exploration',\n            'interaction_id': 'TextInput',\n            'learner_answer_info_list': [{\n                'id': 'id_1',\n                'answer': 'This is my answer',\n                'answer_details': 'This is my answer details',\n                'created_on': '2019-06-19 13:59:29.153073'\n            }],\n            'accumulated_answer_info_json_size_bytes': 4000,\n            'learner_answer_info_schema_version': 1}\n        learner_answer_details_dict = self.learner_answer_details.to_dict()\n        self.assertEqual(\n            learner_answer_details_dict, expected_learner_answer_details_dict)\n\n    def test_from_dict(self):\n        learner_answer_details_dict = {\n            'state_reference': 'exp_id:state_name',\n            'entity_type': 'exploration',\n            'interaction_id': 'TextInput',\n            'learner_answer_info_list': [{\n                'id': 'id_1',\n                'answer': 'This is my answer',\n                'answer_details': 'This is my answer details',\n                'created_on': '2019-06-19 13:59:29.153073'\n            }],\n            'accumulated_answer_info_json_size_bytes': 4000,\n            'learner_answer_info_schema_version': 1}\n        learner_answer_details = stats_domain.LearnerAnswerDetails.from_dict(\n            learner_answer_details_dict)\n        self.assertEqual(\n            learner_answer_details.state_reference, 'exp_id:state_name')\n        self.assertEqual(\n            learner_answer_details.entity_type, 'exploration')\n        self.assertEqual(\n            learner_answer_details.interaction_id, 'TextInput')\n        self.assertEqual(\n            len(learner_answer_details.learner_answer_info_list), 1)\n        self.assertEqual(\n            learner_answer_details.learner_answer_info_list[0].answer,\n            'This is my answer')\n        self.assertEqual(\n            learner_answer_details.learner_answer_info_list[0].answer_details,\n            'This is my answer details')\n        self.assertEqual(\n            learner_answer_details.learner_answer_info_list[0].created_on,\n            datetime.datetime(2019, 6, 19, 13, 59, 29, 153073))\n        self.assertEqual(\n            learner_answer_details.accumulated_answer_info_json_size_bytes,\n            4000)\n        self.assertEqual(\n            learner_answer_details.learner_answer_info_schema_version, 1)\n\n    def test_add_learner_answer_info(self):\n        learner_answer_info = stats_domain.LearnerAnswerInfo(\n            'id_2', 'This answer', 'This details',\n            datetime.datetime.strptime('27 Sep 2012', '%d %b %Y'))\n        self.assertEqual(\n            len(self.learner_answer_details.learner_answer_info_list), 1)\n        self.learner_answer_details.add_learner_answer_info(\n            learner_answer_info)\n        self.assertEqual(\n            len(self.learner_answer_details.learner_answer_info_list), 2)\n\n    def test_learner_answer_info_with_big_size_must_not_be_added(self):\n        answer = 'This is answer abc' * 900\n        answer_details = 'This is answer details' * 400\n        created_on = datetime.datetime.strptime('27 Sep 2012', '%d %b %Y')\n        id_base = 'id:'\n        self.assertEqual(\n            len(self.learner_answer_details.learner_answer_info_list), 1)\n        for i in python_utils.RANGE(36):\n            learner_answer_info = stats_domain.LearnerAnswerInfo(\n                id_base + python_utils.UNICODE(\n                    i), answer, answer_details, created_on)\n            self.learner_answer_details.add_learner_answer_info(\n                learner_answer_info)\n        self.assertEqual(\n            len(self.learner_answer_details.learner_answer_info_list), 36)\n        learner_answer_info = stats_domain.LearnerAnswerInfo(\n            'id:40', answer, answer_details, created_on)\n        self.learner_answer_details.add_learner_answer_info(\n            learner_answer_info)\n        # Due to overflow of the size of learner_answer_info_list, this learner\n        # answer info was not added in the list.\n        self.assertEqual(\n            len(self.learner_answer_details.learner_answer_info_list), 36)\n\n    def test_delete_learner_answer_info(self):\n        self.assertEqual(\n            len(self.learner_answer_details.learner_answer_info_list), 1)\n        learner_answer_info = stats_domain.LearnerAnswerInfo(\n            'id_2', 'This answer', 'This details',\n            datetime.datetime.strptime('27 Sep 2012', '%d %b %Y'))\n        self.learner_answer_details.add_learner_answer_info(\n            learner_answer_info)\n        self.assertEqual(\n            len(self.learner_answer_details.learner_answer_info_list), 2)\n        self.learner_answer_details.delete_learner_answer_info('id_1')\n        self.assertEqual(\n            len(self.learner_answer_details.learner_answer_info_list), 1)\n        self.assertNotEqual(\n            self.learner_answer_details.accumulated_answer_info_json_size_bytes,\n            0)\n        with self.assertRaisesRegexp(\n            Exception, 'Learner answer info with the given id not found'):\n            self.learner_answer_details.delete_learner_answer_info('id_3')\n        self.assertEqual(\n            len(self.learner_answer_details.learner_answer_info_list), 1)\n\n    def test_update_state_reference(self):\n        self.assertEqual(\n            self.learner_answer_details.state_reference, 'exp_id:state_name')\n        self.learner_answer_details.update_state_reference(\n            'exp_id_1:state_name_1')\n        self.assertEqual(\n            self.learner_answer_details.state_reference,\n            'exp_id_1:state_name_1')\n\n    def test_state_reference_must_be_string(self):\n        self.learner_answer_details.state_reference = 0\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'Expected state_reference to be a string')\n\n    def test_entity_type_must_be_string(self):\n        self.learner_answer_details.entity_type = 0\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'Expected entity_type to be a string')\n\n    def test_entity_type_must_be_valid(self,):\n        self.learner_answer_details.entity_type = 'topic'\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'Invalid entity type received topic')\n\n    def test_state_reference_must_be_valid_for_exploration(self):\n        self.learner_answer_details.state_reference = 'expidstatename'\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'For entity type exploration, the state reference should')\n\n    def test_state_reference_must_be_valid_for_question(self):\n        self.learner_answer_details.entity_type = 'question'\n        self.learner_answer_details.state_reference = 'expid:statename'\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'For entity type question, the state reference should')\n\n    def test_interaction_id_must_be_valid(self):\n        self.learner_answer_details.interaction_id = 'MyInteraction'\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'Unknown interaction_id: MyInteraction')\n\n    def test_interaction_id_must_be_string(self):\n        self.learner_answer_details.interaction_id = 0\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'Expected interaction_id to be a string')\n\n    def test_continue_interaction_cannot_solicit_answer_details(self):\n        self.learner_answer_details.interaction_id = 'Continue'\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'The Continue interaction does not support '\n            'soliciting answer details')\n\n    def test_end_exploration_interaction_cannot_solicit_answer_details(self):\n        self.learner_answer_details.interaction_id = 'EndExploration'\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'The EndExploration interaction does not support '\n            'soliciting answer details')\n\n    def test_learner_answer_info_must_be_list(self):\n        self.learner_answer_details.learner_answer_info_list = 'list'\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'Expected learner_answer_info_list to be a list')\n\n    def test_learner_answer_info_schema_version_must_be_int(self):\n        self.learner_answer_details.learner_answer_info_schema_version = 'v'\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'Expected learner_answer_info_schema_version to be an int')\n\n    def test_accumulated_answer_info_json_size_bytes_must_be_int(self):\n        self.learner_answer_details.accumulated_answer_info_json_size_bytes = (\n            'size')\n        self._assert_validation_error(\n            self.learner_answer_details,\n            'Expected accumulated_answer_info_json_size_bytes to be an int')\n\n\nclass LearnerAnswerInfoTests(test_utils.GenericTestBase):\n\n    def setUp(self):\n        super(LearnerAnswerInfoTests, self).setUp()\n        self.learner_answer_info = stats_domain.LearnerAnswerInfo(\n            'id_1', 'This is my answer', 'This is my answer details',\n            datetime.datetime(2019, 6, 19, 13, 59, 29, 153073))\n        self.learner_answer_info.validate()\n\n    def test_to_dict(self):\n        expected_learner_answer_info_dict = {\n            'id': 'id_1',\n            'answer': 'This is my answer',\n            'answer_details': 'This is my answer details',\n            'created_on': '2019-06-19 13:59:29.153073'\n        }\n        self.assertEqual(\n            expected_learner_answer_info_dict,\n            self.learner_answer_info.to_dict())\n\n    def test_from_dict(self):\n        learner_answer_info_dict = {\n            'id': 'id_1',\n            'answer': 'This is my answer',\n            'answer_details': 'This is my answer details',\n            'created_on': '2019-06-19 13:59:29.153073'\n        }\n        learner_answer_info = stats_domain.LearnerAnswerInfo.from_dict(\n            learner_answer_info_dict)\n        self.assertEqual(learner_answer_info.id, 'id_1')\n        self.assertEqual(learner_answer_info.answer, 'This is my answer')\n        self.assertEqual(\n            learner_answer_info.answer_details, 'This is my answer details')\n        self.assertEqual(\n            learner_answer_info.created_on,\n            datetime.datetime(2019, 6, 19, 13, 59, 29, 153073))\n\n    def test_from_dict_to_dict(self):\n        learner_answer_info_dict = {\n            'id': 'id_1',\n            'answer': 'This is my answer',\n            'answer_details': 'This is my answer details',\n            'created_on': '2019-06-19 13:59:29.153073'\n        }\n        learner_answer_info = stats_domain.LearnerAnswerInfo.from_dict(\n            learner_answer_info_dict)\n        self.assertEqual(learner_answer_info.id, 'id_1')\n        self.assertEqual(learner_answer_info.answer, 'This is my answer')\n        self.assertEqual(\n            learner_answer_info.answer_details, 'This is my answer details')\n        self.assertEqual(\n            learner_answer_info.created_on,\n            datetime.datetime(2019, 6, 19, 13, 59, 29, 153073))\n        self.assertEqual(\n            learner_answer_info.to_dict(), learner_answer_info_dict)\n\n    def test_get_learner_answer_info_dict_size(self):\n        learner_answer_info_dict_size = (\n            self.learner_answer_info.get_learner_answer_info_dict_size())\n        self.assertNotEqual(learner_answer_info_dict_size, 0)\n        self.assertTrue(learner_answer_info_dict_size > 0)\n\n    def test_get_new_learner_answer_info_id(self):\n        learner_answer_info_id = (\n            stats_domain.LearnerAnswerInfo.get_new_learner_answer_info_id())\n        self.assertNotEqual(learner_answer_info_id, None)\n        self.assertTrue(isinstance(learner_answer_info_id, bytes))\n\n    def test_id_must_be_string(self):\n        self.learner_answer_info.id = 123\n        self._assert_validation_error(\n            self.learner_answer_info, 'Expected id to be a string')\n\n    def test_answer_must_not_be_none(self):\n        self.learner_answer_info.answer = None\n        self._assert_validation_error(\n            self.learner_answer_info,\n            'The answer submitted by the learner cannot be empty')\n\n    def test_answer_must_not_be_empty_dict(self):\n        self.learner_answer_info.answer = {}\n        self._assert_validation_error(\n            self.learner_answer_info,\n            'The answer submitted cannot be an empty dict')\n\n    def test_answer_must_not_be_empty_string(self):\n        self.learner_answer_info.answer = ''\n        self._assert_validation_error(\n            self.learner_answer_info,\n            'The answer submitted cannot be an empty string')\n\n    def test_answer_details_must_not_be_none(self):\n        self.learner_answer_info.answer_details = None\n        self._assert_validation_error(\n            self.learner_answer_info,\n            'Expected answer_details to be a string')\n\n    def test_answer_details_must_be_string(self):\n        self.learner_answer_info.answer_details = 1\n        self._assert_validation_error(\n            self.learner_answer_info,\n            'Expected answer_details to be a string')\n\n    def test_answer_details_must_not_be_empty_string(self):\n        self.learner_answer_info.answer_details = ''\n        self._assert_validation_error(\n            self.learner_answer_info,\n            'The answer details submitted cannot be an empty string')\n\n    def test_large_answer_details_must_not_be_stored(self):\n        self.learner_answer_info.answer_details = 'abcdef' * 2000\n        self._assert_validation_error(\n            self.learner_answer_info,\n            'The answer details size is to large to be stored')\n\n    def test_created_on_must_be_datetime_type(self):\n        self.learner_answer_info.created_on = '19 June 2019'\n        self._assert_validation_error(\n            self.learner_answer_info,\n            'Expected created_on to be a datetime')\n"
    }
  ]
}