{
  "repo_name": "astropy_astropy",
  "issue_id": "7799",
  "issue_description": "# Add narrative docs for WCSAxes's plot_coord\n\nAt the moment, the very handy ``plot_coord`` method in WCSAxes is only mentioned in the API docs, but we really should add a paragraph about it in the narrative docs.",
  "issue_comments": [
    {
      "id": 419894308,
      "user": "giang-nghg",
      "body": "Hi @astrofrog @pllim I'd like to help with this issue. Can you give me some pointers? Thank you."
    },
    {
      "id": 419960500,
      "user": "pllim",
      "body": "@giang-nghg , thank you for your interest! Please see http://docs.astropy.org/en/stable/development/workflow/development_workflow.html for some help in how to contribute. Perhaps @astrofrog can advise on the actual content to be added to narrative docs."
    },
    {
      "id": 420446183,
      "user": "giang-nghg",
      "body": "Thanks @pllim! I actually contributed before. That made me realized, should I leave this issue for someone else who hasn't contributed to astropy? I picked a docs issue since I want to understand how users use the library.\r\nIn case it's ok for me to continue, yes, I don't have background in astrophysics so I don't know how to come up with an example use-case for this method. I could use some help.\r\nIn case you want to leave this for someone who hasn't contributed yet, I can work on other issues. Last time I worked with [this](https://github.com/astropy/astropy/pull/6097) (FITS format), so I could continue with that module. Anything you think I could work on? Thanks!"
    },
    {
      "id": 420488370,
      "user": "pllim",
      "body": "> should I leave this issue for someone else who hasn't contributed to astropy?\r\n\r\nNot necessarily. Given the number of open issues, there is no shortage for everyone interested. ðŸ˜…  I'll leave it up to your discretion."
    },
    {
      "id": 420778644,
      "user": "giang-nghg",
      "body": "Ok, then I'll continue with this. @astrofrog I don't know the library or its audience well to come up with a guide for said method. Can you suggest what kind of example/guide do you want to add for it? Thanks!"
    },
    {
      "id": 421317056,
      "user": "astrofrog",
      "body": "@giang-nghg - I think it would make more sense to focus on a different issue, as this one does require a good understanding of the use cases for ``plot_coord``. As @pllim said, there are a lot of other issues you could pick :)"
    },
    {
      "id": 421627249,
      "user": "giang-nghg",
      "body": "Ok, I'll pick another issue then :)"
    },
    {
      "id": 1182912160,
      "user": "davidmpaz",
      "body": "Hi all,\r\n\r\nIf it is ok for everybody, I would like to have my take on this one :) \r\n\r\nSince I wanted to start contributing and am a novice, I have already read:\r\n\r\n* https://www.astropy.org/contribute.html\r\n* https://docs.astropy.org/en/latest/development/codeguide.html\r\n* http://docs.astropy.org/en/stable/development/workflow/development_workflow.html\r\n\r\nThat being said, let me get o the point. I see the docblock in the method providing developer documentation. Allow me to ask please, what are the  expectations for this task ? And where to add the narrative?, I did look into the wcs directory (docs/wcs) for `plot_coord` but did not found any reference to it.\r\n\r\nthanks in advance,\r\nDavid\r\n"
    },
    {
      "id": 1186105669,
      "user": "davidmpaz",
      "body": "Hi @astrofrog,\r\n\r\nI was reading:\r\n\r\n> Perhaps @astrofrog can advise on the actual content to be added to narrative docs.\r\n\r\n Any hints on what to do achieve/write here? \r\n\r\nthanks in advance,\r\nCheers"
    },
    {
      "id": 1190402245,
      "user": "astrofrog",
      "body": "I think we should update this section:\r\n\r\nhttps://docs.astropy.org/en/stable/visualization/wcsaxes/overlays.html\r\n\r\nto first mention plot_coord and scatter_coord, and then continue to show the current examples as a more general/advanced way."
    },
    {
      "id": 1253379187,
      "user": "davidmpaz",
      "body": "Can someone suggest resources where a non specialist like me could learn about coordinate systems. How are used in Astronomy, coordinate systems with high curvature, etc... Please keep in mind that despite I have a (rusty) Math background from Computer Sciences, my Astronomy background is the one of someone from High School :-)\r\n\r\nthanks in advance,\r\nRegards"
    }
  ],
  "text_context": "# Add narrative docs for WCSAxes's plot_coord\n\nAt the moment, the very handy ``plot_coord`` method in WCSAxes is only mentioned in the API docs, but we really should add a paragraph about it in the narrative docs.\n\nHi @astrofrog @pllim I'd like to help with this issue. Can you give me some pointers? Thank you.\n\n@giang-nghg , thank you for your interest! Please see http://docs.astropy.org/en/stable/development/workflow/development_workflow.html for some help in how to contribute. Perhaps @astrofrog can advise on the actual content to be added to narrative docs.\n\nThanks @pllim! I actually contributed before. That made me realized, should I leave this issue for someone else who hasn't contributed to astropy? I picked a docs issue since I want to understand how users use the library.\r\nIn case it's ok for me to continue, yes, I don't have background in astrophysics so I don't know how to come up with an example use-case for this method. I could use some help.\r\nIn case you want to leave this for someone who hasn't contributed yet, I can work on other issues. Last time I worked with [this](https://github.com/astropy/astropy/pull/6097) (FITS format), so I could continue with that module. Anything you think I could work on? Thanks!\n\n> should I leave this issue for someone else who hasn't contributed to astropy?\r\n\r\nNot necessarily. Given the number of open issues, there is no shortage for everyone interested. ðŸ˜…  I'll leave it up to your discretion.\n\nOk, then I'll continue with this. @astrofrog I don't know the library or its audience well to come up with a guide for said method. Can you suggest what kind of example/guide do you want to add for it? Thanks!\n\n@giang-nghg - I think it would make more sense to focus on a different issue, as this one does require a good understanding of the use cases for ``plot_coord``. As @pllim said, there are a lot of other issues you could pick :)\n\nOk, I'll pick another issue then :)\n\nHi all,\r\n\r\nIf it is ok for everybody, I would like to have my take on this one :) \r\n\r\nSince I wanted to start contributing and am a novice, I have already read:\r\n\r\n* https://www.astropy.org/contribute.html\r\n* https://docs.astropy.org/en/latest/development/codeguide.html\r\n* http://docs.astropy.org/en/stable/development/workflow/development_workflow.html\r\n\r\nThat being said, let me get o the point. I see the docblock in the method providing developer documentation. Allow me to ask please, what are the  expectations for this task ? And where to add the narrative?, I did look into the wcs directory (docs/wcs) for `plot_coord` but did not found any reference to it.\r\n\r\nthanks in advance,\r\nDavid\r\n\n\nHi @astrofrog,\r\n\r\nI was reading:\r\n\r\n> Perhaps @astrofrog can advise on the actual content to be added to narrative docs.\r\n\r\n Any hints on what to do achieve/write here? \r\n\r\nthanks in advance,\r\nCheers\n\nI think we should update this section:\r\n\r\nhttps://docs.astropy.org/en/stable/visualization/wcsaxes/overlays.html\r\n\r\nto first mention plot_coord and scatter_coord, and then continue to show the current examples as a more general/advanced way.\n\nCan someone suggest resources where a non specialist like me could learn about coordinate systems. How are used in Astronomy, coordinate systems with high curvature, etc... Please keep in mind that despite I have a (rusty) Math background from Computer Sciences, my Astronomy background is the one of someone from High School :-)\r\n\r\nthanks in advance,\r\nRegards",
  "pr_link": "https://github.com/astropy/astropy/pull/6097",
  "code_context": [
    {
      "filename": "astropy/io/fits/connect.py",
      "content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\nfrom __future__ import print_function\n\nimport os\nimport re\nimport warnings\nfrom collections import OrderedDict\n\nfrom .. import registry as io_registry\nfrom ... import units as u\nfrom ...extern.six import string_types\nfrom ...table import Table\nfrom ...utils.exceptions import AstropyUserWarning\nfrom . import HDUList, TableHDU, BinTableHDU, GroupsHDU\nfrom .hdu.hdulist import fitsopen as fits_open\nfrom .util import first\nfrom .convenience import table_to_hdu\n\n\n# FITS file signature as per RFC 4047\nFITS_SIGNATURE = (b\"\\x53\\x49\\x4d\\x50\\x4c\\x45\\x20\\x20\\x3d\\x20\\x20\\x20\\x20\\x20\"\n                  b\"\\x20\\x20\\x20\\x20\\x20\\x20\\x20\\x20\\x20\\x20\\x20\\x20\\x20\\x20\"\n                  b\"\\x20\\x54\")\n\n# Keywords to remove for all tables that are read in\nREMOVE_KEYWORDS = ['XTENSION', 'BITPIX', 'NAXIS', 'NAXIS1', 'NAXIS2',\n                   'PCOUNT', 'GCOUNT', 'TFIELDS']\n\n# Column-specific keywords\nCOLUMN_KEYWORDS = ['TFORM[0-9]+',\n                   'TBCOL[0-9]+',\n                   'TSCAL[0-9]+',\n                   'TZERO[0-9]+',\n                   'TNULL[0-9]+',\n                   'TTYPE[0-9]+',\n                   'TUNIT[0-9]+',\n                   'TDISP[0-9]+',\n                   'TDIM[0-9]+',\n                   'THEAP']\n\n\ndef is_column_keyword(keyword):\n    for c in COLUMN_KEYWORDS:\n        if re.match(c, keyword) is not None:\n            return True\n    return False\n\n\ndef is_fits(origin, filepath, fileobj, *args, **kwargs):\n    \"\"\"\n    Determine whether `origin` is a FITS file.\n\n    Parameters\n    ----------\n    origin : str or readable file-like object\n        Path or file object containing a potential FITS file.\n\n    Returns\n    -------\n    is_fits : bool\n        Returns `True` if the given file is a FITS file.\n    \"\"\"\n    if fileobj is not None:\n        pos = fileobj.tell()\n        sig = fileobj.read(30)\n        fileobj.seek(pos)\n        return sig == FITS_SIGNATURE\n    elif filepath is not None:\n        if filepath.lower().endswith(('.fits', '.fits.gz', '.fit', '.fit.gz',\n                                      '.fts', '.fts.gz')):\n            return True\n    elif isinstance(args[0], (HDUList, TableHDU, BinTableHDU, GroupsHDU)):\n        return True\n    else:\n        return False\n\n\ndef read_table_fits(input, hdu=None):\n    \"\"\"\n    Read a Table object from an FITS file\n\n    Parameters\n    ----------\n    input : str or file-like object or compatible `astropy.io.fits` HDU object\n        If a string, the filename to read the table from. If a file object, or\n        a compatible HDU object, the object to extract the table from. The\n        following `astropy.io.fits` HDU objects can be used as input:\n        - :class:`~astropy.io.fits.hdu.table.TableHDU`\n        - :class:`~astropy.io.fits.hdu.table.BinTableHDU`\n        - :class:`~astropy.io.fits.hdu.table.GroupsHDU`\n        - :class:`~astropy.io.fits.hdu.hdulist.HDUList`\n    hdu : int or str, optional\n        The HDU to read the table from.\n    \"\"\"\n\n    if isinstance(input, HDUList):\n\n        # Parse all table objects\n        tables = OrderedDict()\n        for ihdu, hdu_item in enumerate(input):\n            if isinstance(hdu_item, (TableHDU, BinTableHDU, GroupsHDU)):\n                tables[ihdu] = hdu_item\n\n        if len(tables) > 1:\n            if hdu is None:\n                warnings.warn(\"hdu= was not specified but multiple tables\"\n                              \" are present, reading in first available\"\n                              \" table (hdu={0})\".format(first(tables)),\n                              AstropyUserWarning)\n                hdu = first(tables)\n\n            # hdu might not be an integer, so we first need to convert it\n            # to the correct HDU index\n            hdu = input.index_of(hdu)\n\n            if hdu in tables:\n                table = tables[hdu]\n            else:\n                raise ValueError(\"No table found in hdu={0}\".format(hdu))\n\n        elif len(tables) == 1:\n            table = tables[first(tables)]\n        else:\n            raise ValueError(\"No table found\")\n\n    elif isinstance(input, (TableHDU, BinTableHDU, GroupsHDU)):\n\n        table = input\n\n    else:\n\n        hdulist = fits_open(input)\n\n        try:\n            return read_table_fits(hdulist, hdu=hdu)\n        finally:\n            hdulist.close()\n\n    # Check if table is masked\n    masked = False\n    for col in table.columns:\n        if col.null is not None:\n            masked = True\n            break\n\n    # Convert to an astropy.table.Table object\n    t = Table(table.data, masked=masked)\n\n    # Copy over null values if needed\n    if masked:\n        for col in table.columns:\n            if col.null is not None:\n                t[col.name].set_fill_value(col.null)\n                t[col.name].mask[t[col.name] == col.null] = True\n\n    # Copy over units\n    for col in table.columns:\n        if col.unit is not None:\n            t[col.name].unit = u.Unit(\n                col.unit, format='fits', parse_strict='silent')\n\n    # TODO: deal properly with unsigned integers\n\n    for key, value, comment in table.header.cards:\n\n        if key in ['COMMENT', 'HISTORY']:\n            # Convert to io.ascii format\n            if key == 'COMMENT':\n                key = 'comments'\n\n            if key in t.meta:\n                t.meta[key].append(value)\n            else:\n                t.meta[key] = [value]\n\n        elif key in t.meta:  # key is duplicate\n\n            if isinstance(t.meta[key], list):\n                t.meta[key].append(value)\n            else:\n                t.meta[key] = [t.meta[key], value]\n\n        elif (is_column_keyword(key.upper()) or\n              key.upper() in REMOVE_KEYWORDS):\n\n            pass\n\n        else:\n\n            t.meta[key] = value\n\n    # TODO: implement masking\n\n    return t\n\n\ndef write_table_fits(input, output, overwrite=False):\n    \"\"\"\n    Write a Table object to a FITS file\n\n    Parameters\n    ----------\n    input : Table\n        The table to write out.\n    output : str\n        The filename to write the table to.\n    overwrite : bool\n        Whether to overwrite any existing file without warning.\n    \"\"\"\n\n    table_hdu = table_to_hdu(input)\n\n    # Check if output file already exists\n    if isinstance(output, string_types) and os.path.exists(output):\n        if overwrite:\n            os.remove(output)\n        else:\n            raise IOError(\"File exists: {0}\".format(output))\n\n    table_hdu.writeto(output)\n\nio_registry.register_reader('fits', Table, read_table_fits)\nio_registry.register_writer('fits', Table, write_table_fits)\nio_registry.register_identifier('fits', Table, is_fits)\n"
    },
    {
      "filename": "astropy/io/fits/convenience.py",
      "content": "# Licensed under a 3-clause BSD style license - see PYFITS.rst\n\n\"\"\"\nConvenience functions\n=====================\n\nThe functions in this module provide shortcuts for some of the most basic\noperations on FITS files, such as reading and updating the header.  They are\nincluded directly in the 'astropy.io.fits' namespace so that they can be used\nlike::\n\n    astropy.io.fits.getheader(...)\n\nThese functions are primarily for convenience when working with FITS files in\nthe command-line interpreter.  If performing several operations on the same\nfile, such as in a script, it is better to *not* use these functions, as each\none must open and re-parse the file.  In such cases it is better to use\n:func:`astropy.io.fits.open` and work directly with the\n:class:`astropy.io.fits.HDUList` object and underlying HDU objects.\n\nSeveral of the convenience functions, such as `getheader` and `getdata` support\nspecial arguments for selecting which extension HDU to use when working with a\nmulti-extension FITS file.  There are a few supported argument formats for\nselecting the extension.  See the documentation for `getdata` for an\nexplanation of all the different formats.\n\n.. warning::\n    All arguments to convenience functions other than the filename that are\n    *not* for selecting the extension HDU should be passed in as keyword\n    arguments.  This is to avoid ambiguity and conflicts with the\n    extension arguments.  For example, to set NAXIS=1 on the Primary HDU:\n\n    Wrong::\n\n        astropy.io.fits.setval('myimage.fits', 'NAXIS', 1)\n\n    The above example will try to set the NAXIS value on the first extension\n    HDU to blank.  That is, the argument '1' is assumed to specify an extension\n    HDU.\n\n    Right::\n\n        astropy.io.fits.setval('myimage.fits', 'NAXIS', value=1)\n\n    This will set the NAXIS keyword to 1 on the primary HDU (the default).  To\n    specify the first extension HDU use::\n\n        astropy.io.fits.setval('myimage.fits', 'NAXIS', value=1, ext=1)\n\n    This complexity arises out of the attempt to simultaneously support\n    multiple argument formats that were used in past versions of PyFITS.\n    Unfortunately, it is not possible to support all formats without\n    introducing some ambiguity.  A future Astropy release may standardize\n    around a single format and officially deprecate the other formats.\n\"\"\"\n\n\nimport operator\nimport os\nimport warnings\n\nimport numpy as np\n\nfrom .diff import FITSDiff, HDUDiff\nfrom .file import FILE_MODES, _File\nfrom .hdu.base import _BaseHDU, _ValidHDU\nfrom .hdu.hdulist import fitsopen, HDUList\nfrom .hdu.image import PrimaryHDU, ImageHDU\nfrom .hdu.table import BinTableHDU\nfrom .header import Header\nfrom .util import fileobj_closed, fileobj_name, fileobj_mode, _is_int\nfrom .fitsrec import FITS_rec\nfrom ...units import Unit\nfrom ...units.format.fits import UnitScaleError\nfrom ...units import Quantity\nfrom ...extern import six\nfrom ...extern.six import string_types\nfrom ...utils.exceptions import AstropyUserWarning\nfrom ...utils.decorators import deprecated_renamed_argument\n\n\n__all__ = ['getheader', 'getdata', 'getval', 'setval', 'delval', 'writeto',\n           'append', 'update', 'info', 'tabledump', 'tableload',\n           'table_to_hdu', 'printdiff']\n\n\ndef getheader(filename, *args, **kwargs):\n    \"\"\"\n    Get the header from an extension of a FITS file.\n\n    Parameters\n    ----------\n    filename : file path, file object, or file like object\n        File to get header from.  If an opened file object, its mode\n        must be one of the following rb, rb+, or ab+).\n\n    ext, extname, extver\n        The rest of the arguments are for extension specification.  See the\n        `getdata` documentation for explanations/examples.\n\n    kwargs\n        Any additional keyword arguments to be passed to\n        `astropy.io.fits.open`.\n\n    Returns\n    -------\n    header : `Header` object\n    \"\"\"\n\n    mode, closed = _get_file_mode(filename)\n    hdulist, extidx = _getext(filename, mode, *args, **kwargs)\n    try:\n        hdu = hdulist[extidx]\n        header = hdu.header\n    finally:\n        # Use _close instead of close to close without loading any\n        # remaining HDUs for pre-lazy-loading backwards compatibility\n        # In other words, when the full HDUList is opened by a user they\n        # previously expected to be able to look at arbitrary HDUs even\n        # after the file was closed, but for getheader and other convenience\n        # functions this is irrelevant\n        hdulist._close(closed=closed)\n\n    return header\n\n\ndef getdata(filename, *args, **kwargs):\n    \"\"\"\n    Get the data from an extension of a FITS file (and optionally the\n    header).\n\n    Parameters\n    ----------\n    filename : file path, file object, or file like object\n        File to get data from.  If opened, mode must be one of the\n        following rb, rb+, or ab+.\n\n    ext\n        The rest of the arguments are for extension specification.\n        They are flexible and are best illustrated by examples.\n\n        No extra arguments implies the primary header::\n\n            getdata('in.fits')\n\n        By extension number::\n\n            getdata('in.fits', 0)      # the primary header\n            getdata('in.fits', 2)      # the second extension\n            getdata('in.fits', ext=2)  # the second extension\n\n        By name, i.e., ``EXTNAME`` value (if unique)::\n\n            getdata('in.fits', 'sci')\n            getdata('in.fits', extname='sci')  # equivalent\n\n        Note ``EXTNAME`` values are not case sensitive\n\n        By combination of ``EXTNAME`` and EXTVER`` as separate\n        arguments or as a tuple::\n\n            getdata('in.fits', 'sci', 2)  # EXTNAME='SCI' & EXTVER=2\n            getdata('in.fits', extname='sci', extver=2)  # equivalent\n            getdata('in.fits', ('sci', 2))  # equivalent\n\n        Ambiguous or conflicting specifications will raise an exception::\n\n            getdata('in.fits', ext=('sci',1), extname='err', extver=2)\n\n    header : bool, optional\n        If `True`, return the data and the header of the specified HDU as a\n        tuple.\n\n    lower, upper : bool, optional\n        If ``lower`` or ``upper`` are `True`, the field names in the\n        returned data object will be converted to lower or upper case,\n        respectively.\n\n    view : ndarray, optional\n        When given, the data will be returned wrapped in the given ndarray\n        subclass by calling::\n\n           data.view(view)\n\n    kwargs\n        Any additional keyword arguments to be passed to\n        `astropy.io.fits.open`.\n\n    Returns\n    -------\n    array : array, record array or groups data object\n        Type depends on the type of the extension being referenced.\n\n        If the optional keyword ``header`` is set to `True`, this\n        function will return a (``data``, ``header``) tuple.\n    \"\"\"\n\n    mode, closed = _get_file_mode(filename)\n    header = kwargs.pop('header', None)\n    lower = kwargs.pop('lower', None)\n    upper = kwargs.pop('upper', None)\n    view = kwargs.pop('view', None)\n\n    hdulist, extidx = _getext(filename, mode, *args, **kwargs)\n    try:\n        hdu = hdulist[extidx]\n        data = hdu.data\n        if data is None and extidx == 0:\n            try:\n                hdu = hdulist[1]\n                data = hdu.data\n            except IndexError:\n                raise IndexError('No data in this HDU.')\n        if data is None:\n            raise IndexError('No data in this HDU.')\n        if header:\n            hdr = hdu.header\n    finally:\n        # _close instead of close; see note in getheader\n        hdulist._close(closed=closed)\n\n    # Change case of names if requested\n    trans = None\n    if lower:\n        trans = operator.methodcaller('lower')\n    elif upper:\n        trans = operator.methodcaller('upper')\n    if trans:\n        if data.dtype.names is None:\n            # this data does not have fields\n            return\n        if data.dtype.descr[0][0] == '':\n            # this data does not have fields\n            return\n        data.dtype.names = [trans(n) for n in data.dtype.names]\n\n    # allow different views into the underlying ndarray.  Keep the original\n    # view just in case there is a problem\n    if isinstance(view, type) and issubclass(view, np.ndarray):\n        data = data.view(view)\n\n    if header:\n        return data, hdr\n    else:\n        return data\n\n\ndef getval(filename, keyword, *args, **kwargs):\n    \"\"\"\n    Get a keyword's value from a header in a FITS file.\n\n    Parameters\n    ----------\n    filename : file path, file object, or file like object\n        Name of the FITS file, or file object (if opened, mode must be\n        one of the following rb, rb+, or ab+).\n\n    keyword : str\n        Keyword name\n\n    ext, extname, extver\n        The rest of the arguments are for extension specification.\n        See `getdata` for explanations/examples.\n\n    kwargs\n        Any additional keyword arguments to be passed to\n        `astropy.io.fits.open`.\n        *Note:* This function automatically specifies ``do_not_scale_image_data\n        = True`` when opening the file so that values can be retrieved from the\n        unmodified header.\n\n    Returns\n    -------\n    keyword value : str, int, or float\n    \"\"\"\n\n    if 'do_not_scale_image_data' not in kwargs:\n        kwargs['do_not_scale_image_data'] = True\n\n    hdr = getheader(filename, *args, **kwargs)\n    return hdr[keyword]\n\n\ndef setval(filename, keyword, *args, **kwargs):\n    \"\"\"\n    Set a keyword's value from a header in a FITS file.\n\n    If the keyword already exists, it's value/comment will be updated.\n    If it does not exist, a new card will be created and it will be\n    placed before or after the specified location.  If no ``before`` or\n    ``after`` is specified, it will be appended at the end.\n\n    When updating more than one keyword in a file, this convenience\n    function is a much less efficient approach compared with opening\n    the file for update, modifying the header, and closing the file.\n\n    Parameters\n    ----------\n    filename : file path, file object, or file like object\n        Name of the FITS file, or file object If opened, mode must be update\n        (rb+).  An opened file object or `~gzip.GzipFile` object will be closed\n        upon return.\n\n    keyword : str\n        Keyword name\n\n    value : str, int, float, optional\n        Keyword value (default: `None`, meaning don't modify)\n\n    comment : str, optional\n        Keyword comment, (default: `None`, meaning don't modify)\n\n    before : str, int, optional\n        Name of the keyword, or index of the card before which the new card\n        will be placed.  The argument ``before`` takes precedence over\n        ``after`` if both are specified (default: `None`).\n\n    after : str, int, optional\n        Name of the keyword, or index of the card after which the new card will\n        be placed. (default: `None`).\n\n    savecomment : bool, optional\n        When `True`, preserve the current comment for an existing keyword.  The\n        argument ``savecomment`` takes precedence over ``comment`` if both\n        specified.  If ``comment`` is not specified then the current comment\n        will automatically be preserved  (default: `False`).\n\n    ext, extname, extver\n        The rest of the arguments are for extension specification.\n        See `getdata` for explanations/examples.\n\n    kwargs\n        Any additional keyword arguments to be passed to\n        `astropy.io.fits.open`.\n        *Note:* This function automatically specifies ``do_not_scale_image_data\n        = True`` when opening the file so that values can be retrieved from the\n        unmodified header.\n    \"\"\"\n\n    if 'do_not_scale_image_data' not in kwargs:\n        kwargs['do_not_scale_image_data'] = True\n\n    value = kwargs.pop('value', None)\n    comment = kwargs.pop('comment', None)\n    before = kwargs.pop('before', None)\n    after = kwargs.pop('after', None)\n    savecomment = kwargs.pop('savecomment', False)\n\n    closed = fileobj_closed(filename)\n    hdulist, extidx = _getext(filename, 'update', *args, **kwargs)\n    try:\n        if keyword in hdulist[extidx].header and savecomment:\n            comment = None\n        hdulist[extidx].header.set(keyword, value, comment, before, after)\n    finally:\n        # _close instead of close; see note in getheader\n        hdulist._close(closed=closed)\n\n\ndef delval(filename, keyword, *args, **kwargs):\n    \"\"\"\n    Delete all instances of keyword from a header in a FITS file.\n\n    Parameters\n    ----------\n\n    filename : file path, file object, or file like object\n        Name of the FITS file, or file object If opened, mode must be update\n        (rb+).  An opened file object or `~gzip.GzipFile` object will be closed\n        upon return.\n\n    keyword : str, int\n        Keyword name or index\n\n    ext, extname, extver\n        The rest of the arguments are for extension specification.\n        See `getdata` for explanations/examples.\n\n    kwargs\n        Any additional keyword arguments to be passed to\n        `astropy.io.fits.open`.\n        *Note:* This function automatically specifies ``do_not_scale_image_data\n        = True`` when opening the file so that values can be retrieved from the\n        unmodified header.\n    \"\"\"\n\n    if 'do_not_scale_image_data' not in kwargs:\n        kwargs['do_not_scale_image_data'] = True\n\n    closed = fileobj_closed(filename)\n    hdulist, extidx = _getext(filename, 'update', *args, **kwargs)\n    try:\n        del hdulist[extidx].header[keyword]\n    finally:\n        # _close instead of close; see note in getheader\n        hdulist._close(closed=closed)\n\n\n@deprecated_renamed_argument('clobber', 'overwrite', '1.3', pending=True)\ndef writeto(filename, data, header=None, output_verify='exception',\n            overwrite=False, checksum=False):\n    \"\"\"\n    Create a new FITS file using the supplied data/header.\n\n    Parameters\n    ----------\n    filename : file path, file object, or file like object\n        File to write to.  If opened, must be opened in a writeable binary\n        mode such as 'wb' or 'ab+'.\n\n    data : array, record array, or groups data object\n        data to write to the new file\n\n    header : `Header` object, optional\n        the header associated with ``data``. If `None`, a header\n        of the appropriate type is created for the supplied data. This\n        argument is optional.\n\n    output_verify : str\n        Output verification option.  Must be one of ``\"fix\"``, ``\"silentfix\"``,\n        ``\"ignore\"``, ``\"warn\"``, or ``\"exception\"``.  May also be any\n        combination of ``\"fix\"`` or ``\"silentfix\"`` with ``\"+ignore\"``,\n        ``+warn``, or ``+exception\" (e.g. ``\"fix+warn\"``).  See :ref:`verify`\n        for more info.\n\n    overwrite : bool, optional\n        If ``True``, overwrite the output file if it exists. Raises an\n        ``OSError`` (``IOError`` for Python 2) if ``False`` and the\n        output file exists. Default is ``False``.\n\n        .. versionchanged:: 1.3\n           ``overwrite`` replaces the deprecated ``clobber`` argument.\n\n    checksum : bool, optional\n        If `True`, adds both ``DATASUM`` and ``CHECKSUM`` cards to the\n        headers of all HDU's written to the file.\n    \"\"\"\n\n    hdu = _makehdu(data, header)\n    if hdu.is_image and not isinstance(hdu, PrimaryHDU):\n        hdu = PrimaryHDU(data, header=header)\n    hdu.writeto(filename, overwrite=overwrite, output_verify=output_verify,\n                checksum=checksum)\n\n\ndef table_to_hdu(table):\n    \"\"\"\n    Convert an `~astropy.table.Table` object to a FITS\n    `~astropy.io.fits.BinTableHDU`.\n\n    Parameters\n    ----------\n    table : astropy.table.Table\n        The table to convert.\n\n    Returns\n    -------\n    table_hdu : `~astropy.io.fits.BinTableHDU`\n        The FITS binary table HDU.\n    \"\"\"\n    # Avoid circular imports\n    from .connect import is_column_keyword, REMOVE_KEYWORDS\n\n    # Not all tables with mixin columns are supported\n    if table.has_mixin_columns:\n        # Import is done here, in order to avoid it at build time as erfa is not\n        # yet available then.\n        from ...table.column import BaseColumn\n\n        # Only those columns which are instances of BaseColumn or Quantity can be written\n        unsupported_cols = table.columns.not_isinstance((BaseColumn, Quantity))\n        if unsupported_cols:\n            unsupported_names = [col.info.name for col in unsupported_cols]\n            raise ValueError('cannot write table with mixin column(s) {0}'\n                         .format(unsupported_names))\n\n    # Create a new HDU object\n    if table.masked:\n        #float column's default mask value needs to be Nan\n        for column in six.itervalues(table.columns):\n            fill_value = column.get_fill_value()\n            if column.dtype.kind == 'f' and np.allclose(fill_value, 1e20):\n                column.set_fill_value(np.nan)\n\n        table_hdu = BinTableHDU.from_columns(np.array(table.filled()))\n        for col in table_hdu.columns:\n            # Binary FITS tables support TNULL *only* for integer data columns\n            # TODO: Determine a schema for handling non-integer masked columns\n            # in FITS (if at all possible)\n            int_formats = ('B', 'I', 'J', 'K')\n            if not (col.format in int_formats or\n                    col.format.p_format in int_formats):\n                continue\n\n            # The astype is necessary because if the string column is less\n            # than one character, the fill value will be N/A by default which\n            # is too long, and so no values will get masked.\n            fill_value = table[col.name].get_fill_value()\n\n            col.null = fill_value.astype(table[col.name].dtype)\n    else:\n        table_hdu = BinTableHDU.from_columns(np.array(table.filled()))\n\n    # Set units for output HDU\n    for col in table_hdu.columns:\n        unit = table[col.name].unit\n        if unit is not None:\n            try:\n                col.unit = unit.to_string(format='fits')\n            except UnitScaleError:\n                scale = unit.scale\n                raise UnitScaleError(\n                    \"The column '{0}' could not be stored in FITS format \"\n                    \"because it has a scale '({1})' that \"\n                    \"is not recognized by the FITS standard. Either scale \"\n                    \"the data or change the units.\".format(col.name, str(scale)))\n            except ValueError:\n                warnings.warn(\n                    \"The unit '{0}' could not be saved to FITS format\".format(\n                        unit.to_string()), AstropyUserWarning)\n\n            # Try creating a Unit to issue a warning if the unit is not FITS compliant\n            Unit(col.unit, format='fits', parse_strict='warn')\n\n    for key, value in table.meta.items():\n        if is_column_keyword(key.upper()) or key.upper() in REMOVE_KEYWORDS:\n            warnings.warn(\n                \"Meta-data keyword {0} will be ignored since it conflicts \"\n                \"with a FITS reserved keyword\".format(key), AstropyUserWarning)\n\n        # Convert to FITS format\n        if key == 'comments':\n            key = 'comment'\n\n        if isinstance(value, list):\n            for item in value:\n                try:\n                    table_hdu.header.append((key, item))\n                except ValueError:\n                    warnings.warn(\n                        \"Attribute `{0}` of type {1} cannot be added to \"\n                        \"FITS Header - skipping\".format(key, type(value)),\n                        AstropyUserWarning)\n        else:\n            try:\n                table_hdu.header[key] = value\n            except ValueError:\n                warnings.warn(\n                    \"Attribute `{0}` of type {1} cannot be added to FITS \"\n                    \"Header - skipping\".format(key, type(value)),\n                    AstropyUserWarning)\n    return table_hdu\n\n\ndef append(filename, data, header=None, checksum=False, verify=True, **kwargs):\n    \"\"\"\n    Append the header/data to FITS file if filename exists, create if not.\n\n    If only ``data`` is supplied, a minimal header is created.\n\n    Parameters\n    ----------\n    filename : file path, file object, or file like object\n        File to write to.  If opened, must be opened for update (rb+) unless it\n        is a new file, then it must be opened for append (ab+).  A file or\n        `~gzip.GzipFile` object opened for update will be closed after return.\n\n    data : array, table, or group data object\n        the new data used for appending\n\n    header : `Header` object, optional\n        The header associated with ``data``.  If `None`, an appropriate header\n        will be created for the data object supplied.\n\n    checksum : bool, optional\n        When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards to the header\n        of the HDU when written to the file.\n\n    verify : bool, optional\n        When `True`, the existing FITS file will be read in to verify it for\n        correctness before appending.  When `False`, content is simply appended\n        to the end of the file.  Setting ``verify`` to `False` can be much\n        faster.\n\n    kwargs\n        Any additional keyword arguments to be passed to\n        `astropy.io.fits.open`.\n    \"\"\"\n\n    name, closed, noexist_or_empty = _stat_filename_or_fileobj(filename)\n\n    if noexist_or_empty:\n        #\n        # The input file or file like object either doesn't exits or is\n        # empty.  Use the writeto convenience function to write the\n        # output to the empty object.\n        #\n        writeto(filename, data, header, checksum=checksum, **kwargs)\n    else:\n        hdu = _makehdu(data, header)\n\n        if isinstance(hdu, PrimaryHDU):\n            hdu = ImageHDU(data, header)\n\n        if verify or not closed:\n            f = fitsopen(filename, mode='append')\n            try:\n                f.append(hdu)\n\n                # Set a flag in the HDU so that only this HDU gets a checksum\n                # when writing the file.\n                hdu._output_checksum = checksum\n            finally:\n                # _close instead of close; see note in getheader\n                f._close(closed=closed)\n        else:\n            f = _File(filename, mode='append')\n            try:\n                hdu._output_checksum = checksum\n                hdu._writeto(f)\n            finally:\n                f._close()\n\n\ndef update(filename, data, *args, **kwargs):\n    \"\"\"\n    Update the specified extension with the input data/header.\n\n    Parameters\n    ----------\n    filename : file path, file object, or file like object\n        File to update.  If opened, mode must be update (rb+).  An opened file\n        object or `~gzip.GzipFile` object will be closed upon return.\n\n    data : array, table, or group data object\n        the new data used for updating\n\n    header : `Header` object, optional\n        The header associated with ``data``.  If `None`, an appropriate header\n        will be created for the data object supplied.\n\n    ext, extname, extver\n        The rest of the arguments are flexible: the 3rd argument can be the\n        header associated with the data.  If the 3rd argument is not a\n        `Header`, it (and other positional arguments) are assumed to be the\n        extension specification(s).  Header and extension specs can also be\n        keyword arguments.  For example::\n\n            update(file, dat, hdr, 'sci')  # update the 'sci' extension\n            update(file, dat, 3)  # update the 3rd extension\n            update(file, dat, hdr, 3)  # update the 3rd extension\n            update(file, dat, 'sci', 2)  # update the 2nd SCI extension\n            update(file, dat, 3, header=hdr)  # update the 3rd extension\n            update(file, dat, header=hdr, ext=5)  # update the 5th extension\n\n    kwargs\n        Any additional keyword arguments to be passed to\n        `astropy.io.fits.open`.\n    \"\"\"\n\n    # The arguments to this function are a bit trickier to deal with than others\n    # in this module, since the documentation has promised that the header\n    # argument can be an optional positional argument.\n    if args and isinstance(args[0], Header):\n        header = args[0]\n        args = args[1:]\n    else:\n        header = None\n    # The header can also be a keyword argument--if both are provided the\n    # keyword takes precedence\n    header = kwargs.pop('header', header)\n\n    new_hdu = _makehdu(data, header)\n\n    closed = fileobj_closed(filename)\n\n    hdulist, _ext = _getext(filename, 'update', *args, **kwargs)\n    try:\n        hdulist[_ext] = new_hdu\n    finally:\n        # _close instead of close; see note in getheader\n        hdulist._close(closed=closed)\n\n\ndef info(filename, output=None, **kwargs):\n    \"\"\"\n    Print the summary information on a FITS file.\n\n    This includes the name, type, length of header, data shape and type\n    for each extension.\n\n    Parameters\n    ----------\n    filename : file path, file object, or file like object\n        FITS file to obtain info from.  If opened, mode must be one of\n        the following: rb, rb+, or ab+ (i.e. the file must be readable).\n\n    output : file, bool, optional\n        A file-like object to write the output to.  If ``False``, does not\n        output to a file and instead returns a list of tuples representing the\n        HDU info.  Writes to ``sys.stdout`` by default.\n\n    kwargs\n        Any additional keyword arguments to be passed to\n        `astropy.io.fits.open`.\n        *Note:* This function sets ``ignore_missing_end=True`` by default.\n    \"\"\"\n\n    mode, closed = _get_file_mode(filename, default='readonly')\n    # Set the default value for the ignore_missing_end parameter\n    if 'ignore_missing_end' not in kwargs:\n        kwargs['ignore_missing_end'] = True\n\n    f = fitsopen(filename, mode=mode, **kwargs)\n    try:\n        ret = f.info(output=output)\n    finally:\n        if closed:\n            # _close instead of close; see note in getheader\n            f._close()\n\n    return ret\n\n\ndef printdiff(inputa, inputb, *args, **kwargs):\n    \"\"\"\n    Compare two parts of a FITS file, including entire FITS files,\n    FITS `HDUList` objects and FITS ``HDU`` objects.\n\n    Parameters\n    ----------\n    inputa : str, `HDUList` object, or ``HDU`` object\n        The filename of a FITS file, `HDUList`, or ``HDU``\n        object to compare to ``inputb``.\n\n    inputb : str, `HDUList` object, or ``HDU`` object\n        The filename of a FITS file, `HDUList`, or ``HDU``\n        object to compare to ``inputa``.\n\n    ext, extname, extver\n        Additional positional arguments are for extension specification if your\n        inputs are string filenames (will not work if\n        ``inputa`` and ``inputb`` are ``HDU`` objects or `HDUList` objects).\n        They are flexible and are best illustrated by examples.  In addition\n        to using these arguments positionally you can directly call the\n        keyword parameters ``ext``, ``extname``.\n\n        By extension number::\n\n            printdiff('inA.fits', 'inB.fits', 0)      # the primary HDU\n            printdiff('inA.fits', 'inB.fits', 2)      # the second extension\n            printdiff('inA.fits', 'inB.fits', ext=2)  # the second extension\n\n        By name, i.e., ``EXTNAME`` value (if unique). ``EXTNAME`` values are\n        not case sensitive:\n\n            printdiff('inA.fits', 'inB.fits', 'sci')\n            printdiff('inA.fits', 'inB.fits', extname='sci')  # equivalent\n\n        By combination of ``EXTNAME`` and ``EXTVER`` as separate\n        arguments or as a tuple::\n\n            printdiff('inA.fits', 'inB.fits', 'sci', 2)    # EXTNAME='SCI'\n                                                           # & EXTVER=2\n            printdiff('inA.fits', 'inB.fits', extname='sci', extver=2)\n                                                           # equivalent\n            printdiff('inA.fits', 'inB.fits', ('sci', 2))  # equivalent\n\n        Ambiguous or conflicting specifications will raise an exception::\n\n            printdiff('inA.fits', 'inB.fits',\n                      ext=('sci', 1), extname='err', extver=2)\n\n    kwargs\n        Any additional keyword arguments to be passed to\n        `~astropy.io.fits.FITSDiff`.\n\n    Notes\n    -----\n    The primary use for the `printdiff` function is to allow quick print out\n    of a FITS difference report and will write to ``sys.stdout``.\n    To save the diff report to a file please use `~astropy.io.fits.FITSDiff`\n    directly.\n    \"\"\"\n\n    # Pop extension keywords\n    extension = {key: kwargs.pop(key) for key in ['ext', 'extname', 'extver']\n                 if key in kwargs}\n    has_extensions = args or extension\n\n    if isinstance(inputa, string_types) and has_extensions:\n        # Use handy _getext to interpret any ext keywords, but\n        # will need to close a if  fails\n        modea, closeda = _get_file_mode(inputa)\n        modeb, closedb = _get_file_mode(inputb)\n\n        hdulista, extidxa = _getext(inputa, modea, *args, **extension)\n        # Have to close a if b doesn't make it\n        try:\n            hdulistb, extidxb = _getext(inputb, modeb, *args, **extension)\n        except Exception:\n            hdulista._close(closed=closeda)\n            raise\n\n        try:\n            hdua = hdulista[extidxa]\n            hdub = hdulistb[extidxb]\n            # See below print for note\n            print(HDUDiff(hdua, hdub, **kwargs).report())\n\n        finally:\n            # See note about _close in getheader function\n            hdulista._close(closed=closeda)\n            hdulistb._close(closed=closedb)\n\n    # If input is not a string, can feed HDU objects or HDUList directly,\n    # but can't currently handle extensions\n    elif isinstance(inputa, _ValidHDU) and has_extensions:\n        raise ValueError(\"Cannot use extension keywords when providing an \"\n                         \"HDU object.\")\n\n    elif isinstance(inputa, _ValidHDU) and not has_extensions:\n        print(HDUDiff(inputa, inputb, **kwargs).report())\n\n    elif isinstance(inputa, HDUList) and has_extensions:\n        raise NotImplementedError(\"Extension specification with HDUList \"\n                                  \"objects not implemented.\")\n\n    # This function is EXCLUSIVELY for printing the diff report to screen\n    # in a one-liner call, hence the use of print instead of logging\n    else:\n        print(FITSDiff(inputa, inputb, **kwargs).report())\n\n\n@deprecated_renamed_argument('clobber', 'overwrite', '1.3', pending=True)\ndef tabledump(filename, datafile=None, cdfile=None, hfile=None, ext=1,\n              overwrite=False):\n    \"\"\"\n    Dump a table HDU to a file in ASCII format.  The table may be\n    dumped in three separate files, one containing column definitions,\n    one containing header parameters, and one for table data.\n\n    Parameters\n    ----------\n    filename : file path, file object or file-like object\n        Input fits file.\n\n    datafile : file path, file object or file-like object, optional\n        Output data file.  The default is the root name of the input\n        fits file appended with an underscore, followed by the\n        extension number (ext), followed by the extension ``.txt``.\n\n    cdfile : file path, file object or file-like object, optional\n        Output column definitions file.  The default is `None`,\n        no column definitions output is produced.\n\n    hfile : file path, file object or file-like object, optional\n        Output header parameters file.  The default is `None`,\n        no header parameters output is produced.\n\n    ext : int\n        The number of the extension containing the table HDU to be\n        dumped.\n\n    overwrite : bool, optional\n        If ``True``, overwrite the output file if it exists. Raises an\n        ``OSError`` (``IOError`` for Python 2) if ``False`` and the\n        output file exists. Default is ``False``.\n\n        .. versionchanged:: 1.3\n           ``overwrite`` replaces the deprecated ``clobber`` argument.\n\n    Notes\n    -----\n    The primary use for the `tabledump` function is to allow editing in a\n    standard text editor of the table data and parameters.  The\n    `tableload` function can be used to reassemble the table from the\n    three ASCII files.\n    \"\"\"\n\n    # allow file object to already be opened in any of the valid modes\n    # and leave the file in the same state (opened or closed) as when\n    # the function was called\n\n    mode, closed = _get_file_mode(filename, default='readonly')\n    f = fitsopen(filename, mode=mode)\n\n    # Create the default data file name if one was not provided\n    try:\n        if not datafile:\n            # TODO: Really need to provide a better way to access the name of\n            # any files underlying an HDU\n            root, tail = os.path.splitext(f._HDUList__file.name)\n            datafile = root + '_' + repr(ext) + '.txt'\n\n        # Dump the data from the HDU to the files\n        f[ext].dump(datafile, cdfile, hfile, overwrite)\n    finally:\n        if closed:\n            # _close instead of close; see note in getheader\n            f._close()\n\nif isinstance(tabledump.__doc__, string_types):\n    tabledump.__doc__ += BinTableHDU._tdump_file_format.replace('\\n', '\\n    ')\n\n\ndef tableload(datafile, cdfile, hfile=None):\n    \"\"\"\n    Create a table from the input ASCII files.  The input is from up\n    to three separate files, one containing column definitions, one\n    containing header parameters, and one containing column data.  The\n    header parameters file is not required.  When the header\n    parameters file is absent a minimal header is constructed.\n\n    Parameters\n    ----------\n    datafile : file path, file object or file-like object\n        Input data file containing the table data in ASCII format.\n\n    cdfile : file path, file object or file-like object\n        Input column definition file containing the names, formats,\n        display formats, physical units, multidimensional array\n        dimensions, undefined values, scale factors, and offsets\n        associated with the columns in the table.\n\n    hfile : file path, file object or file-like object, optional\n        Input parameter definition file containing the header\n        parameter definitions to be associated with the table.\n        If `None`, a minimal header is constructed.\n\n    Notes\n    -----\n    The primary use for the `tableload` function is to allow the input of\n    ASCII data that was edited in a standard text editor of the table\n    data and parameters.  The tabledump function can be used to create the\n    initial ASCII files.\n    \"\"\"\n\n    return BinTableHDU.load(datafile, cdfile, hfile, replace=True)\n\nif isinstance(tableload.__doc__, string_types):\n    tableload.__doc__ += BinTableHDU._tdump_file_format.replace('\\n', '\\n    ')\n\n\ndef _getext(filename, mode, *args, **kwargs):\n    \"\"\"\n    Open the input file, return the `HDUList` and the extension.\n\n    This supports several different styles of extension selection.  See the\n    :func:`getdata()` documentation for the different possibilities.\n    \"\"\"\n\n    ext = kwargs.pop('ext', None)\n    extname = kwargs.pop('extname', None)\n    extver = kwargs.pop('extver', None)\n\n    err_msg = ('Redundant/conflicting extension arguments(s): {}'.format(\n            {'args': args, 'ext': ext,  'extname': extname,\n             'extver': extver}))\n\n    # This code would be much simpler if just one way of specifying an\n    # extension were picked.  But now we need to support all possible ways for\n    # the time being.\n    if len(args) == 1:\n        # Must be either an extension number, an extension name, or an\n        # (extname, extver) tuple\n        if _is_int(args[0]) or (isinstance(ext, tuple) and len(ext) == 2):\n            if ext is not None or extname is not None or extver is not None:\n                raise TypeError(err_msg)\n            ext = args[0]\n        elif isinstance(args[0], string_types):\n            # The first arg is an extension name; it could still be valid\n            # to provide an extver kwarg\n            if ext is not None or extname is not None:\n                raise TypeError(err_msg)\n            extname = args[0]\n        else:\n            # Take whatever we have as the ext argument; we'll validate it\n            # below\n            ext = args[0]\n    elif len(args) == 2:\n        # Must be an extname and extver\n        if ext is not None or extname is not None or extver is not None:\n            raise TypeError(err_msg)\n        extname = args[0]\n        extver = args[1]\n    elif len(args) > 2:\n        raise TypeError('Too many positional arguments.')\n\n    if (ext is not None and\n            not (_is_int(ext) or\n                 (isinstance(ext, tuple) and len(ext) == 2 and\n                  isinstance(ext[0], string_types) and _is_int(ext[1])))):\n        raise ValueError(\n            'The ext keyword must be either an extension number '\n            '(zero-indexed) or a (extname, extver) tuple.')\n    if extname is not None and not isinstance(extname, string_types):\n        raise ValueError('The extname argument must be a string.')\n    if extver is not None and not _is_int(extver):\n        raise ValueError('The extver argument must be an integer.')\n\n    if ext is None and extname is None and extver is None:\n        ext = 0\n    elif ext is not None and (extname is not None or extver is not None):\n        raise TypeError(err_msg)\n    elif extname:\n        if extver:\n            ext = (extname, extver)\n        else:\n            ext = (extname, 1)\n    elif extver and extname is None:\n        raise TypeError('extver alone cannot specify an extension.')\n\n    hdulist = fitsopen(filename, mode=mode, **kwargs)\n\n    return hdulist, ext\n\n\ndef _makehdu(data, header):\n    if header is None:\n        header = Header()\n    hdu = _BaseHDU(data, header)\n    if hdu.__class__ in (_BaseHDU, _ValidHDU):\n        # The HDU type was unrecognized, possibly due to a\n        # nonexistent/incomplete header\n        if ((isinstance(data, np.ndarray) and data.dtype.fields is not None) or\n                isinstance(data, np.recarray)):\n            hdu = BinTableHDU(data, header=header)\n        elif isinstance(data, np.ndarray):\n            hdu = ImageHDU(data, header=header)\n        else:\n            raise KeyError('Data must be a numpy array.')\n    return hdu\n\n\ndef _stat_filename_or_fileobj(filename):\n    closed = fileobj_closed(filename)\n    name = fileobj_name(filename) or ''\n\n    try:\n        loc = filename.tell()\n    except AttributeError:\n        loc = 0\n\n    noexist_or_empty = ((name and\n                         (not os.path.exists(name) or\n                          (os.path.getsize(name) == 0)))\n                         or (not name and loc == 0))\n\n    return name, closed, noexist_or_empty\n\n\ndef _get_file_mode(filename, default='readonly'):\n    \"\"\"\n    Allow file object to already be opened in any of the valid modes and\n    and leave the file in the same state (opened or closed) as when\n    the function was called.\n    \"\"\"\n\n    mode = default\n    closed = fileobj_closed(filename)\n\n    fmode = fileobj_mode(filename)\n    if fmode is not None:\n        mode = FILE_MODES.get(fmode)\n        if mode is None:\n            raise IOError(\n                \"File mode of the input file object ({!r}) cannot be used to \"\n                \"read/write FITS files.\".format(fmode))\n\n    return mode, closed\n"
    },
    {
      "filename": "astropy/io/fits/tests/test_connect.py",
      "content": "import os\nimport warnings\n\nimport pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom .. import HDUList, PrimaryHDU, BinTableHDU\n\nfrom ... import fits\n\nfrom .... import units as u\nfrom ....extern.six.moves import range, zip\nfrom ....table import Table, QTable\nfrom ....tests.helper import catch_warnings\nfrom ....units.format.fits import UnitScaleError\n\nDATA = os.path.join(os.path.dirname(__file__), 'data')\n\ntry:\n    import pathlib\nexcept ImportError:\n    HAS_PATHLIB = False\nelse:\n    HAS_PATHLIB = True\n\n\ndef equal_data(a, b):\n    for name in a.dtype.names:\n        if not np.all(a[name] == b[name]):\n            return False\n    return True\n\n\nclass TestSingleTable(object):\n\n    def setup_class(self):\n        self.data = np.array(list(zip([1, 2, 3, 4],\n                                      ['a', 'b', 'c', 'd'],\n                                      [2.3, 4.5, 6.7, 8.9])),\n                             dtype=[(str('a'), int), (str('b'), str('U1')), (str('c'), float)])\n\n    def test_simple(self, tmpdir):\n        filename = str(tmpdir.join('test_simple.fts'))\n        t1 = Table(self.data)\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename)\n        assert equal_data(t1, t2)\n\n    @pytest.mark.skipif('not HAS_PATHLIB')\n    def test_simple_pathlib(self, tmpdir):\n        filename = pathlib.Path(str(tmpdir.join('test_simple.fit')))\n        t1 = Table(self.data)\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename)\n        assert equal_data(t1, t2)\n\n    def test_simple_meta(self, tmpdir):\n        filename = str(tmpdir.join('test_simple.fits'))\n        t1 = Table(self.data)\n        t1.meta['A'] = 1\n        t1.meta['B'] = 2.3\n        t1.meta['C'] = 'spam'\n        t1.meta['comments'] = ['this', 'is', 'a', 'long', 'comment']\n        t1.meta['HISTORY'] = ['first', 'second', 'third']\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename)\n        assert equal_data(t1, t2)\n        for key in t1.meta:\n            if isinstance(t1.meta, list):\n                for i in range(len(t1.meta[key])):\n                    assert t1.meta[key][i] == t2.meta[key][i]\n            else:\n                assert t1.meta[key] == t2.meta[key]\n\n    def test_simple_meta_conflicting(self, tmpdir):\n        filename = str(tmpdir.join('test_simple.fits'))\n        t1 = Table(self.data)\n        t1.meta['ttype1'] = 'spam'\n        with catch_warnings() as l:\n            t1.write(filename, overwrite=True)\n        assert len(l) == 1\n        assert str(l[0].message).startswith(\n            'Meta-data keyword ttype1 will be ignored since it conflicts with a FITS reserved keyword')\n\n    def test_simple_noextension(self, tmpdir):\n        \"\"\"\n        Test that file type is recognized without extension\n        \"\"\"\n        filename = str(tmpdir.join('test_simple'))\n        t1 = Table(self.data)\n        t1.write(filename, overwrite=True, format='fits')\n        t2 = Table.read(filename)\n        assert equal_data(t1, t2)\n\n    @pytest.mark.parametrize('table_type', (Table, QTable))\n    def test_with_units(self, table_type, tmpdir):\n        filename = str(tmpdir.join('test_with_units.fits'))\n        t1 = table_type(self.data)\n        t1['a'].unit = u.m\n        t1['c'].unit = u.km / u.s\n        t1.write(filename, overwrite=True)\n        t2 = table_type.read(filename)\n        assert equal_data(t1, t2)\n        assert t2['a'].unit == u.m\n        assert t2['c'].unit == u.km / u.s\n\n    def test_masked(self, tmpdir):\n        filename = str(tmpdir.join('test_masked.fits'))\n        t1 = Table(self.data, masked=True)\n        t1.mask['a'] = [1, 0, 1, 0]\n        t1.mask['b'] = [1, 0, 0, 1]\n        t1.mask['c'] = [0, 1, 1, 0]\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename)\n        assert t2.masked\n        assert equal_data(t1, t2)\n        assert np.all(t1['a'].mask == t2['a'].mask)\n        # Disabled for now, as there is no obvious way to handle masking of\n        # non-integer columns in FITS\n        # TODO: Re-enable these tests if some workaround for this can be found\n        # assert np.all(t1['b'].mask == t2['b'].mask)\n        # assert np.all(t1['c'].mask == t2['c'].mask)\n\n    def test_masked_nan(self, tmpdir):\n        filename = str(tmpdir.join('test_masked_nan.fits'))\n        data = np.array(list(zip([5.2, 8.4, 3.9, 6.3],\n                                 [2.3, 4.5, 6.7, 8.9])),\n                                dtype=[(str('a'), np.float64), (str('b'), np.float32)])\n        t1 = Table(data, masked=True)\n        t1.mask['a'] = [1, 0, 1, 0]\n        t1.mask['b'] = [1, 0, 0, 1]\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename)\n        np.testing.assert_array_almost_equal(t2['a'], [np.nan, 8.4, np.nan, 6.3])\n        np.testing.assert_array_almost_equal(t2['b'], [np.nan, 4.5, 6.7, np.nan])\n        # assert t2.masked\n        # t2.masked = false currently, as the only way to determine whether a table is masked\n        # while reading is to check whether col.null is present. For float columns, col.null\n        # is not initialized\n\n    def test_read_from_fileobj(self, tmpdir):\n        filename = str(tmpdir.join('test_read_from_fileobj.fits'))\n        hdu = BinTableHDU(self.data)\n        hdu.writeto(filename, overwrite=True)\n        with open(filename, 'rb') as f:\n            t = Table.read(f)\n        assert equal_data(t, self.data)\n\n    def test_read_with_nonstandard_units(self):\n        hdu = BinTableHDU(self.data)\n        hdu.columns[0].unit = 'RADIANS'\n        hdu.columns[1].unit = 'spam'\n        hdu.columns[2].unit = 'millieggs'\n        t = Table.read(hdu)\n        assert equal_data(t, self.data)\n\n\nclass TestMultipleHDU(object):\n\n    def setup_class(self):\n        self.data1 = np.array(list(zip([1, 2, 3, 4],\n                                       ['a', 'b', 'c', 'd'],\n                                       [2.3, 4.5, 6.7, 8.9])),\n                              dtype=[(str('a'), int), (str('b'), str('U1')), (str('c'), float)])\n        self.data2 = np.array(list(zip([1.4, 2.3, 3.2, 4.7],\n                                       [2.3, 4.5, 6.7, 8.9])),\n                              dtype=[(str('p'), float), (str('q'), float)])\n        hdu1 = PrimaryHDU()\n        hdu2 = BinTableHDU(self.data1, name='first')\n        hdu3 = BinTableHDU(self.data2, name='second')\n\n        self.hdus = HDUList([hdu1, hdu2, hdu3])\n\n    def teardown_class(self):\n        del self.hdus\n\n    def setup_method(self, method):\n        warnings.filterwarnings('always')\n\n    def test_read(self, tmpdir):\n        filename = str(tmpdir.join('test_read.fits'))\n        self.hdus.writeto(filename)\n        with catch_warnings() as l:\n            t = Table.read(filename)\n        assert len(l) == 1\n        assert str(l[0].message).startswith(\n            'hdu= was not specified but multiple tables are present, reading in first available table (hdu=1)')\n        assert equal_data(t, self.data1)\n\n    def test_read_with_hdu_0(self, tmpdir):\n        filename = str(tmpdir.join('test_read_with_hdu_0.fits'))\n        self.hdus.writeto(filename)\n        with pytest.raises(ValueError) as exc:\n            Table.read(filename, hdu=0)\n        assert exc.value.args[0] == 'No table found in hdu=0'\n\n    @pytest.mark.parametrize('hdu', [1, 'first'])\n    def test_read_with_hdu_1(self, tmpdir, hdu):\n        filename = str(tmpdir.join('test_read_with_hdu_1.fits'))\n        self.hdus.writeto(filename)\n        with catch_warnings() as l:\n            t = Table.read(filename, hdu=hdu)\n        assert len(l) == 0\n        assert equal_data(t, self.data1)\n\n    @pytest.mark.parametrize('hdu', [2, 'second'])\n    def test_read_with_hdu_2(self, tmpdir, hdu):\n        filename = str(tmpdir.join('test_read_with_hdu_2.fits'))\n        self.hdus.writeto(filename)\n        with catch_warnings() as l:\n            t = Table.read(filename, hdu=hdu)\n        assert len(l) == 0\n        assert equal_data(t, self.data2)\n\n    def test_read_from_hdulist(self):\n        with catch_warnings() as l:\n            t = Table.read(self.hdus)\n        assert len(l) == 1\n        assert str(l[0].message).startswith(\n            'hdu= was not specified but multiple tables are present, reading in first available table (hdu=1)')\n        assert equal_data(t, self.data1)\n\n    def test_read_from_hdulist_with_hdu_0(self, tmpdir):\n        with pytest.raises(ValueError) as exc:\n            Table.read(self.hdus, hdu=0)\n        assert exc.value.args[0] == 'No table found in hdu=0'\n\n    @pytest.mark.parametrize('hdu', [1, 'first'])\n    def test_read_from_hdulist_with_hdu_1(self, tmpdir, hdu):\n        with catch_warnings() as l:\n            t = Table.read(self.hdus, hdu=hdu)\n        assert len(l) == 0\n        assert equal_data(t, self.data1)\n\n    @pytest.mark.parametrize('hdu', [2, 'second'])\n    def test_read_from_hdulist_with_hdu_2(self, tmpdir, hdu):\n        with catch_warnings() as l:\n            t = Table.read(self.hdus, hdu=hdu)\n        assert len(l) == 0\n        assert equal_data(t, self.data2)\n\n    def test_read_from_single_hdu(self):\n        with catch_warnings() as l:\n            t = Table.read(self.hdus[1])\n        assert len(l) == 0\n        assert equal_data(t, self.data1)\n\n\ndef test_masking_regression_1795():\n    \"\"\"\n    Regression test for #1795 - this bug originally caused columns where TNULL\n    was not defined to have their first element masked.\n    \"\"\"\n    t = Table.read(os.path.join(DATA, 'tb.fits'))\n    assert np.all(t['c1'].mask == np.array([False, False]))\n    assert np.all(t['c2'].mask == np.array([False, False]))\n    assert np.all(t['c3'].mask == np.array([False, False]))\n    assert np.all(t['c4'].mask == np.array([False, False]))\n    assert np.all(t['c1'].data == np.array([1,2]))\n    assert np.all(t['c2'].data == np.array(['abc', 'xy ']))\n    assert_allclose(t['c3'].data, np.array([3.70000007153, 6.6999997139]))\n    assert np.all(t['c4'].data == np.array([False, True]))\n\n\ndef test_scale_error():\n    a = [1, 4, 5]\n    b = [2.0, 5.0, 8.2]\n    c = ['x', 'y', 'z']\n    t = Table([a, b, c], names=('a', 'b', 'c'), meta={'name': 'first table'})\n    t['a'].unit='1.2'\n    with pytest.raises(UnitScaleError) as exc:\n        t.write('t.fits',format='fits', overwrite=True)\n    assert exc.value.args[0]==\"The column 'a' could not be stored in FITS format because it has a scale '(1.2)' that is not recognized by the FITS standard. Either scale the data or change the units.\"\n\n\ndef test_bool_column(tmpdir):\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/1953\n\n    Ensures that Table columns of bools are properly written to a FITS table.\n    \"\"\"\n\n    arr = np.ones(5, dtype=bool)\n    arr[::2] == np.False_\n\n    t = Table([arr])\n    t.write(str(tmpdir.join('test.fits')), overwrite=True)\n\n    with fits.open(str(tmpdir.join('test.fits'))) as hdul:\n        assert hdul[1].data['col0'].dtype == np.dtype('bool')\n        assert np.all(hdul[1].data['col0'] == arr)\n\n\ndef test_unicode_column(tmpdir):\n    \"\"\"\n    Test that a column of unicode strings is still written as one\n    byte-per-character in the FITS table (so long as the column can be ASCII\n    encoded).\n\n    Regression test for one of the issues fixed in\n    https://github.com/astropy/astropy/pull/4228\n    \"\"\"\n\n    t = Table([np.array([u'a', u'b', u'cd'])])\n    t.write(str(tmpdir.join('test.fits')), overwrite=True)\n\n    with fits.open(str(tmpdir.join('test.fits'))) as hdul:\n        assert np.all(hdul[1].data['col0'] == ['a', 'b', 'cd'])\n        assert hdul[1].header['TFORM1'] == '2A'\n\n    t2 = Table([np.array([u'\\N{SNOWMAN}'])])\n\n    with pytest.raises(UnicodeEncodeError):\n        t2.write(str(tmpdir.join('test.fits')), overwrite=True)\n\n\ndef test_unit_warnings_read_write(tmpdir):\n    filename = str(tmpdir.join('test_unit.fits'))\n    t1 = Table([[1, 2], [3, 4]], names=['a', 'b'])\n    t1['a'].unit = 'm/s'\n    t1['b'].unit = 'not-a-unit'\n\n    with catch_warnings() as l:\n        t1.write(filename, overwrite=True)\n        assert len(l) == 1\n        assert str(l[0].message).startswith(\"'not-a-unit' did not parse as fits unit\")\n\n    with catch_warnings() as l:\n        Table.read(filename, hdu=1)\n    assert len(l) == 0\n\n\ndef test_convert_comment_convention(tmpdir):\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/6079\n    \"\"\"\n    filename = os.path.join(DATA, 'stddata.fits')\n    t = Table.read(filename)\n\n    assert t.meta['comments'] == [\n        '',\n        ' *** End of mandatory fields ***',\n        '',\n        '',\n        ' *** Column names ***',\n        '',\n        '',\n        ' *** Column formats ***',\n        ''\n    ]\n"
    },
    {
      "filename": "astropy/io/fits/tests/test_convenience.py",
      "content": "# Licensed under a 3-clause BSD style license - see PYFITS.rst\n\nfrom __future__ import division, with_statement\n\nimport warnings\n\nimport pytest\nimport numpy as np\n\nfrom ....extern import six  # pylint: disable=W0611\nfrom ....io import fits\nfrom ....table import Table\nfrom .. import printdiff\nfrom ....tests.helper import catch_warnings\n\nfrom . import FitsTestCase\n\n\nclass TestConvenience(FitsTestCase):\n\n    @pytest.mark.skipif('six.PY2')\n    def test_resource_warning(self):\n        warnings.simplefilter('always', ResourceWarning)\n        with catch_warnings() as w:\n            data = fits.getdata(self.data('test0.fits'))\n            assert len(w) == 0\n\n        with catch_warnings() as w:\n            header = fits.getheader(self.data('test0.fits'))\n            assert len(w) == 0\n\n    def test_fileobj_not_closed(self):\n        \"\"\"\n        Tests that file-like objects are not closed after being passed\n        to convenience functions.\n\n        Regression test for https://github.com/astropy/astropy/issues/5063\n        \"\"\"\n\n        f = open(self.data('test0.fits'), 'rb')\n        data = fits.getdata(f)\n        assert not f.closed\n\n        f.seek(0)\n        header = fits.getheader(f)\n        assert not f.closed\n\n    def test_table_to_hdu(self):\n        table = Table([[1, 2, 3], ['a', 'b', 'c'], [2.3, 4.5, 6.7]],\n                      names=['a', 'b', 'c'], dtype=['i', 'U1', 'f'])\n        table['a'].unit = 'm/s'\n        table['b'].unit = 'not-a-unit'\n\n        with catch_warnings() as w:\n            hdu = fits.table_to_hdu(table)\n            assert len(w) == 1\n            assert str(w[0].message).startswith(\"'not-a-unit' did not parse as\"\n                                                \" fits unit\")\n\n        # Check that TUNITn cards appear in the correct order\n        # (https://github.com/astropy/astropy/pull/5720)\n        assert hdu.header.index('TUNIT1') < hdu.header.index('TTYPE2')\n\n        assert isinstance(hdu, fits.BinTableHDU)\n        filename = self.temp('test_table_to_hdu.fits')\n        hdu.writeto(filename, overwrite=True)\n\n    def test_table_to_hdu_convert_comment_convention(self):\n        \"\"\"\n        Regression test for https://github.com/astropy/astropy/issues/6079\n        \"\"\"\n        table = Table([[1, 2, 3], ['a', 'b', 'c'], [2.3, 4.5, 6.7]],\n                      names=['a', 'b', 'c'], dtype=['i', 'U1', 'f'])\n        table.meta['comments'] = ['This', 'is', 'a', 'comment']\n        hdu = fits.table_to_hdu(table)\n\n        assert hdu.header.get('comment') == ['This', 'is', 'a', 'comment']\n        with pytest.raises(ValueError):\n            hdu.header.index('comments')\n\n    def test_table_writeto_header(self):\n        \"\"\"\n        Regression test for https://github.com/astropy/astropy/issues/5988\n        \"\"\"\n        data = np.zeros((5, ), dtype=[('x', np.float), ('y', np.int)])\n        h_in = fits.Header()\n        h_in['ANSWER'] = (42.0, 'LTU&E')\n        filename = self.temp('tabhdr42.fits')\n        fits.writeto(filename, data=data, header=h_in, overwrite=True)\n        h_out = fits.getheader(filename, ext=1)\n        assert h_out['ANSWER'] == 42\n\n    def test_image_extension_update_header(self):\n        \"\"\"\n        Test that _makehdu correctly includes the header. For example in the\n        fits.update convenience function.\n        \"\"\"\n        filename = self.temp('twoextension.fits')\n\n        hdus = [fits.PrimaryHDU(np.zeros((10, 10))),\n                fits.ImageHDU(np.zeros((10, 10)))]\n\n        fits.HDUList(hdus).writeto(filename)\n\n        fits.update(filename,\n                    np.zeros((10, 10)),\n                    header=fits.Header([('WHAT', 100)]),\n                    ext=1)\n        h_out = fits.getheader(filename, ext=1)\n        assert h_out['WHAT'] == 100\n\n    def test_printdiff(self):\n        \"\"\"\n        Test that FITSDiff can run the different inputs without crashing.\n        \"\"\"\n\n        # Testing different string input options\n        assert printdiff(self.data('arange.fits'),\n                         self.data('blank.fits')) is None\n        assert printdiff(self.data('arange.fits'),\n                         self.data('blank.fits'), ext=0) is None\n        assert printdiff(self.data('o4sp040b0_raw.fits'),\n                         self.data('o4sp040b0_raw.fits'),\n                         extname='sci') is None\n\n        # This may seem weird, but check printdiff to see, need to test\n        # incorrect second file\n        with pytest.raises(IOError):\n            printdiff('o4sp040b0_raw.fits', 'fakefile.fits', extname='sci')\n\n        # Test HDU object inputs\n        with fits.open(self.data('stddata.fits'), mode='readonly') as in1:\n            with fits.open(self.data('checksum.fits'), mode='readonly') as in2:\n\n                assert printdiff(in1[0], in2[0]) is None\n\n                with pytest.raises(ValueError):\n                    printdiff(in1[0], in2[0], ext=0)\n\n                assert printdiff(in1, in2) is None\n\n                with pytest.raises(NotImplementedError):\n                    printdiff(in1, in2, 0)\n"
    }
  ],
  "questions": [
    "Hi @astrofrog @pllim I'd like to help with this issue. Can you give me some pointers? Thank you.",
    "> should I leave this issue for someone else who hasn't contributed to astropy?\r\n\r\nNot necessarily. Given the number of open issues, there is no shortage for everyone interested. ðŸ˜…  I'll leave it up to your discretion.",
    "Ok, then I'll continue with this. @astrofrog I don't know the library or its audience well to come up with a guide for said method. Can you suggest what kind of example/guide do you want to add for it? Thanks!"
  ],
  "golden_answers": [
    "Thanks @pllim! I actually contributed before. That made me realized, should I leave this issue for someone else who hasn't contributed to astropy? I picked a docs issue since I want to understand how users use the library.\r\nIn case it's ok for me to continue, yes, I don't have background in astrophysics so I don't know how to come up with an example use-case for this method. I could use some help.\r\nIn case you want to leave this for someone who hasn't contributed yet, I can work on other issues. Last time I worked with [this](https://github.com/astropy/astropy/pull/6097) (FITS format), so I could continue with that module. Anything you think I could work on? Thanks!",
    "@giang-nghg - I think it would make more sense to focus on a different issue, as this one does require a good understanding of the use cases for ``plot_coord``. As @pllim said, there are a lot of other issues you could pick :)",
    "@giang-nghg - I think it would make more sense to focus on a different issue, as this one does require a good understanding of the use cases for ``plot_coord``. As @pllim said, there are a lot of other issues you could pick :)"
  ],
  "questions_generated": [
    "What is the main purpose of the 'plot_coord' method in the WCSAxes module of Astropy?",
    "Where in the Astropy documentation should the narrative about 'plot_coord' be added, and why?",
    "What challenges might a new contributor face when writing narrative documentation for 'plot_coord' in Astropy, and how can they overcome these?",
    "How does the 'plot_coord' method in WCSAxes enhance the functionality of the Astropy library?",
    "Why might it be important to include narrative documentation for methods like 'plot_coord' in the Astropy library?"
  ],
  "golden_answers_generated": [
    "The 'plot_coord' method in the WCSAxes module is used for plotting coordinates on a World Coordinate System (WCS) axes. It is a part of the visualization tools in Astropy that allows users to overlay coordinates on astronomical images using the WCS transformations.",
    "The narrative about 'plot_coord' should be added to the section at https://docs.astropy.org/en/stable/visualization/wcsaxes/overlays.html. This section discusses overlays and coordinate plotting in WCSAxes, making it a suitable place to introduce and explain the usage of the 'plot_coord' method.",
    "A new contributor might face challenges such as understanding the typical use cases for 'plot_coord', the target audience, and how the method fits within the broader context of WCSAxes. To overcome these, they could study existing documentation, seek guidance from experienced contributors, and refer to the API documentation to understand the method's functionality.",
    "The 'plot_coord' method enhances Astropy's functionality by providing a straightforward way to visualize coordinate overlays on WCS-enabled plots. This is particularly useful in astronomical imaging where coordinates need to be accurately represented on images that have been transformed using WCS.",
    "Including narrative documentation for methods like 'plot_coord' is important because it helps users understand how to effectively use the method in practical scenarios, beyond what is covered in API documentation. Narrative docs provide context, examples, and guides that can make the library more accessible and useful, especially to users who may not be familiar with the underlying astrophysical concepts."
  ]
}