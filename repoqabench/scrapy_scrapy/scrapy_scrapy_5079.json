{
  "repo_name": "scrapy_scrapy",
  "issue_id": "5079",
  "issue_description": "# ImagePipeline breaks on invalid images\n\n@apalala reported this issue when a site sends some invalid images, and suggested a fix for the spider middleware:\r\n\r\n```\r\n        image_stream = self.get_images(response, request, info, item=item)\r\n        while True:\r\n            try:\r\n                path, image, buf = next(image_stream)\r\n            except StopIteration:\r\n                break\r\n            except Exception:\r\n                continue\r\n```\r\n\r\nI’ve not checked if there’s a cleaner fix possible (i.e. closer to the call to Pillow code), but it should be trivial to fix either way. I suspect writing a test may be the hardest part here.",
  "issue_comments": [
    {
      "id": 813254227,
      "user": "marlenachatzigrigoriou",
      "body": "Hello, I am new here. I would like to contribute to this issue. "
    },
    {
      "id": 813357047,
      "user": "apalala",
      "body": "Let me gather a few broken images from fandangonow.com on the next run, @Gallaecio. \r\n\r\nThe exception raised by PIL is `OSError`."
    },
    {
      "id": 813384120,
      "user": "apalala",
      "body": "Examples of broken images:\r\n\r\n* https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg\r\n* https://img01.mgo-images.com/image/thumbnail?id=MSRE18FBB98AF3BD2EF21EF2283708829B8A\r\n* https://img01.mgo-images.com/image/thumbnail/v2/content/MMVA6B4523491C0B5A88B392024490A44B7C.jpeg"
    },
    {
      "id": 813394369,
      "user": "Gallaecio",
      "body": "@marlenachatzigrigoriou Thank you! Please, let us know if you have any question.\r\n\r\nIt should be possible to reproduce this issue by creating a Scrapy spider that [uses ImagePipeline](https://docs.scrapy.org/en/latest/topics/media-pipeline.html) and yields an item with its `image_urls` set to `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg']`."
    },
    {
      "id": 813675201,
      "user": "marlenachatzigrigoriou",
      "body": "I've checked the related code and documentation. I've tried to recreate a spider as @Gallaecio indicated, using ImagePipeline but it doesn't store any of the images. \r\n@apalala's suggestion should be embedded in scrapy.pipelines.images.ImagesPipeline image_downloaded method? \r\nI think I need a little bit more guidance."
    },
    {
      "id": 813943543,
      "user": "Gallaecio",
      "body": "I believe the main issue here is that if an item has 1 valid image URL after 1 URL to an image that Pillow fails to parse, none of the 2 images get downloaded.\r\n\r\nSo to reproduce the issue it would be better to use something like `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`.\r\n\r\n> @apalala's suggestion should be embedded in scrapy.pipelines.images.ImagesPipeline image_downloaded method?\r\n\r\nI believe so.\r\n\r\nYou could first try with the current Scrapy implementation and `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`, and verify that none of the 2 images get downloaded.\r\n\r\nThen try adding @apalala’s code to your local clone of Scrapy, installing that version of Scrapy (i.e. `pip install -e <path to your local Scrapy clone>`), and running the spider again, see if this time around the Scrapy logo gets downloaded.\r\n"
    },
    {
      "id": 816597554,
      "user": "marlenachatzigrigoriou",
      "body": "I have reproduced the issue as @Gallaecio indicated and I am trying to fix the code to my local clone. The purpose is to download both images (valid and invalid), or just the valid one, when `image_urls` is set to `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`?"
    },
    {
      "id": 817756620,
      "user": "Gallaecio",
      "body": "I believe the goal is for valid images to get downloaded, to prevent invalid images (which are not expected to be downloaded) to cause valid images to not be downloaded either. For invalid images, as long as there’s some feedback in the logs about them being invalid, I think that’s OK. Users that want invalid images can always switch to the files media pipeline, which downloads all files without any kind of image processing."
    },
    {
      "id": 817760559,
      "user": "apalala",
      "body": "Note that this should be replaced by specific exception types (like `OSError`) and handling to avoid the risk of an infinite loop:\r\n\r\n```\r\nexcept Exception:\r\n    continue\r\n```\r\n\r\nThe sample code relies too much on the iterator eventually reaching `StopIteration`.\r\n\r\n```\r\nexcept OSError as e:\r\n    logger.exception('Could not process image')\r\nexcept Exception as e:\r\n   logger.exception('Stopped processing images')\r\n   break\r\n```\r\n\r\n"
    },
    {
      "id": 817976838,
      "user": "marlenachatzigrigoriou",
      "body": "I have combined @apalala's code with the existing one (in [ImagesPipeline ](https://github.com/scrapy/scrapy/blob/master/scrapy/pipelines/images.py)image_downloaded method). The valid images are downloaded while the invalid ones not, and the `OSError` is faced and not raised anymore. Should I continue with the creation of a test in the [test/test_pipeline_images.py](https://github.com/scrapy/scrapy/blob/master/tests/test_pipeline_images.py) file?"
    },
    {
      "id": 818582086,
      "user": "Gallaecio",
      "body": "@marlenachatzigrigoriou That would be great. You could also already create a (draft) pull request with what you have so far, so that we can provide some feedback."
    },
    {
      "id": 826046279,
      "user": "spittieUM",
      "body": "Hello,\r\n\r\nI know this issue looks to be resolved, but I worked on the bug as well.\r\nWill link a pull request that fixes the error and adds a test.\r\n\r\nThanks."
    },
    {
      "id": 827091312,
      "user": "SabbirAhmedAdor629",
      "body": "> @apalala reported this issue when a site sends some invalid images, and suggested a fix for the spider middleware:\r\n> \r\n> ```\r\n>         image_stream = self.get_images(response, request, info, item=item)\r\n>         while True:\r\n>             try:\r\n>                 path, image, buf = next(image_stream)\r\n>             except StopIteration:\r\n>                 break\r\n>             except Exception:\r\n>                 continue\r\n> ```\r\n> \r\n> I’ve not checked if there’s a cleaner fix possible (i.e. closer to the call to Pillow code), but it should be trivial to fix either way. I suspect writing a test may be the hardest part here.\r\n\r\nHi, I want to work on this is it still available?\r\n"
    },
    {
      "id": 827347682,
      "user": "Gallaecio",
      "body": "There’s 2 on-going pull requests already to fix it. Unless you want to review and provide feedback to those pull requests, it might be best to work on something else."
    },
    {
      "id": 827735786,
      "user": "Gallaecio",
      "body": "@apalala @marlenachatzigrigoriou @spittieUM Looking deeper into the code to provide better feedback for your solutions, it started to seem to me that this issue should not be happening at all, because exceptions from the `get_images` method should not block the download of other images.\r\n\r\nTo be sure, I went ahead and tested the issue myself, creating the following file and running it with `scrapy runspider` in a Python virtual environment with Scrapy and Pillow installed:\r\n\r\n```python\r\nfrom scrapy import Spider\r\n\r\n\r\nclass TestSpider(Spider):\r\n    name = 'test'\r\n    start_urls = ['http://toscrape.com/']\r\n\r\n    custom_settings = {\r\n        'IMAGES_STORE': '',  # TODO: Set your own download path\r\n        'ITEM_PIPELINES': {\r\n            'scrapy.pipelines.images.ImagesPipeline': 1,\r\n        }\r\n    }\r\n\r\n    def parse(self, response):\r\n        yield {\r\n            'image_urls': [\r\n                'http://toscrape.com/img/zyte.png',\r\n                'https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg',\r\n                'http://toscrape.com/img/books.png',\r\n            ],\r\n        }\r\n```\r\n\r\nThis spider did as expected: the 2 good images were downloaded, the bad one was not downloaded.\r\n\r\n@apalala Either I’m not understanding the issue correctly, or there is no issue."
    },
    {
      "id": 827910290,
      "user": "marlenachatzigrigoriou",
      "body": "@Gallaecio I agree. From the first time, without changing the code, the spider was downloading the valid images and not the invalid ones. In my case, the raised OSError exception was visible in the command line but wasn't affecting the download. In this way, I thought that the issue was to face the OSError so it won't be raised anymore."
    },
    {
      "id": 834849131,
      "user": "apalala",
      "body": "@Gallaecio, it may be that the only issue is that having an `OSError` stack trace escape to the logs is unexpected."
    },
    {
      "id": 836294774,
      "user": "Gallaecio",
      "body": "@apalala Shall we close this issue then, or would you want to hide that error or remove the traceback?"
    },
    {
      "id": 836725597,
      "user": "marlenachatzigrigoriou",
      "body": "@Gallaecio, if @apalala wants to remove the traceback, I think that #5097 solves it. But, I guess that the tests need more work."
    },
    {
      "id": 843379109,
      "user": "apalala",
      "body": "I'd say to move to close if the `OSError` does not scape to the logs."
    },
    {
      "id": 855428332,
      "user": "tonycoldashian",
      "body": "Hey!\r\n It's my first time working with Open Source and I'm interested in this and would like to help."
    },
    {
      "id": 869361431,
      "user": "jmat94",
      "body": "Hi! I am new to Open Source and I would like to contribute by coming up with a solution to this issue. "
    },
    {
      "id": 879230300,
      "user": "Gallaecio",
      "body": "> I'd say to move to close if the `OSError` does not scape to the logs.\r\n\r\nClosing, then.\r\n\r\n@marlenachatzigrigoriou I’m really sorry for wasting your time, I should have tested this myself before opening the issue report."
    },
    {
      "id": 879249194,
      "user": "marlenachatzigrigoriou",
      "body": "That's fine @Gallaecio. Thank you for the help in my first effort to contribute, no matter the ending of this issue! "
    }
  ],
  "text_context": "# ImagePipeline breaks on invalid images\n\n@apalala reported this issue when a site sends some invalid images, and suggested a fix for the spider middleware:\r\n\r\n```\r\n        image_stream = self.get_images(response, request, info, item=item)\r\n        while True:\r\n            try:\r\n                path, image, buf = next(image_stream)\r\n            except StopIteration:\r\n                break\r\n            except Exception:\r\n                continue\r\n```\r\n\r\nI’ve not checked if there’s a cleaner fix possible (i.e. closer to the call to Pillow code), but it should be trivial to fix either way. I suspect writing a test may be the hardest part here.\n\nHello, I am new here. I would like to contribute to this issue. \n\nLet me gather a few broken images from fandangonow.com on the next run, @Gallaecio. \r\n\r\nThe exception raised by PIL is `OSError`.\n\nExamples of broken images:\r\n\r\n* https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg\r\n* https://img01.mgo-images.com/image/thumbnail?id=MSRE18FBB98AF3BD2EF21EF2283708829B8A\r\n* https://img01.mgo-images.com/image/thumbnail/v2/content/MMVA6B4523491C0B5A88B392024490A44B7C.jpeg\n\n@marlenachatzigrigoriou Thank you! Please, let us know if you have any question.\r\n\r\nIt should be possible to reproduce this issue by creating a Scrapy spider that [uses ImagePipeline](https://docs.scrapy.org/en/latest/topics/media-pipeline.html) and yields an item with its `image_urls` set to `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg']`.\n\nI've checked the related code and documentation. I've tried to recreate a spider as @Gallaecio indicated, using ImagePipeline but it doesn't store any of the images. \r\n@apalala's suggestion should be embedded in scrapy.pipelines.images.ImagesPipeline image_downloaded method? \r\nI think I need a little bit more guidance.\n\nI believe the main issue here is that if an item has 1 valid image URL after 1 URL to an image that Pillow fails to parse, none of the 2 images get downloaded.\r\n\r\nSo to reproduce the issue it would be better to use something like `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`.\r\n\r\n> @apalala's suggestion should be embedded in scrapy.pipelines.images.ImagesPipeline image_downloaded method?\r\n\r\nI believe so.\r\n\r\nYou could first try with the current Scrapy implementation and `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`, and verify that none of the 2 images get downloaded.\r\n\r\nThen try adding @apalala’s code to your local clone of Scrapy, installing that version of Scrapy (i.e. `pip install -e <path to your local Scrapy clone>`), and running the spider again, see if this time around the Scrapy logo gets downloaded.\r\n\n\nI have reproduced the issue as @Gallaecio indicated and I am trying to fix the code to my local clone. The purpose is to download both images (valid and invalid), or just the valid one, when `image_urls` is set to `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`?\n\nI believe the goal is for valid images to get downloaded, to prevent invalid images (which are not expected to be downloaded) to cause valid images to not be downloaded either. For invalid images, as long as there’s some feedback in the logs about them being invalid, I think that’s OK. Users that want invalid images can always switch to the files media pipeline, which downloads all files without any kind of image processing.\n\nNote that this should be replaced by specific exception types (like `OSError`) and handling to avoid the risk of an infinite loop:\r\n\r\n```\r\nexcept Exception:\r\n    continue\r\n```\r\n\r\nThe sample code relies too much on the iterator eventually reaching `StopIteration`.\r\n\r\n```\r\nexcept OSError as e:\r\n    logger.exception('Could not process image')\r\nexcept Exception as e:\r\n   logger.exception('Stopped processing images')\r\n   break\r\n```\r\n\r\n\n\nI have combined @apalala's code with the existing one (in [ImagesPipeline ](https://github.com/scrapy/scrapy/blob/master/scrapy/pipelines/images.py)image_downloaded method). The valid images are downloaded while the invalid ones not, and the `OSError` is faced and not raised anymore. Should I continue with the creation of a test in the [test/test_pipeline_images.py](https://github.com/scrapy/scrapy/blob/master/tests/test_pipeline_images.py) file?\n\n@marlenachatzigrigoriou That would be great. You could also already create a (draft) pull request with what you have so far, so that we can provide some feedback.\n\nHello,\r\n\r\nI know this issue looks to be resolved, but I worked on the bug as well.\r\nWill link a pull request that fixes the error and adds a test.\r\n\r\nThanks.\n\n> @apalala reported this issue when a site sends some invalid images, and suggested a fix for the spider middleware:\r\n> \r\n> ```\r\n>         image_stream = self.get_images(response, request, info, item=item)\r\n>         while True:\r\n>             try:\r\n>                 path, image, buf = next(image_stream)\r\n>             except StopIteration:\r\n>                 break\r\n>             except Exception:\r\n>                 continue\r\n> ```\r\n> \r\n> I’ve not checked if there’s a cleaner fix possible (i.e. closer to the call to Pillow code), but it should be trivial to fix either way. I suspect writing a test may be the hardest part here.\r\n\r\nHi, I want to work on this is it still available?\r\n\n\nThere’s 2 on-going pull requests already to fix it. Unless you want to review and provide feedback to those pull requests, it might be best to work on something else.\n\n@apalala @marlenachatzigrigoriou @spittieUM Looking deeper into the code to provide better feedback for your solutions, it started to seem to me that this issue should not be happening at all, because exceptions from the `get_images` method should not block the download of other images.\r\n\r\nTo be sure, I went ahead and tested the issue myself, creating the following file and running it with `scrapy runspider` in a Python virtual environment with Scrapy and Pillow installed:\r\n\r\n```python\r\nfrom scrapy import Spider\r\n\r\n\r\nclass TestSpider(Spider):\r\n    name = 'test'\r\n    start_urls = ['http://toscrape.com/']\r\n\r\n    custom_settings = {\r\n        'IMAGES_STORE': '',  # TODO: Set your own download path\r\n        'ITEM_PIPELINES': {\r\n            'scrapy.pipelines.images.ImagesPipeline': 1,\r\n        }\r\n    }\r\n\r\n    def parse(self, response):\r\n        yield {\r\n            'image_urls': [\r\n                'http://toscrape.com/img/zyte.png',\r\n                'https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg',\r\n                'http://toscrape.com/img/books.png',\r\n            ],\r\n        }\r\n```\r\n\r\nThis spider did as expected: the 2 good images were downloaded, the bad one was not downloaded.\r\n\r\n@apalala Either I’m not understanding the issue correctly, or there is no issue.\n\n@Gallaecio I agree. From the first time, without changing the code, the spider was downloading the valid images and not the invalid ones. In my case, the raised OSError exception was visible in the command line but wasn't affecting the download. In this way, I thought that the issue was to face the OSError so it won't be raised anymore.\n\n@Gallaecio, it may be that the only issue is that having an `OSError` stack trace escape to the logs is unexpected.\n\n@apalala Shall we close this issue then, or would you want to hide that error or remove the traceback?\n\n@Gallaecio, if @apalala wants to remove the traceback, I think that #5097 solves it. But, I guess that the tests need more work.\n\nI'd say to move to close if the `OSError` does not scape to the logs.\n\nHey!\r\n It's my first time working with Open Source and I'm interested in this and would like to help.\n\nHi! I am new to Open Source and I would like to contribute by coming up with a solution to this issue. \n\n> I'd say to move to close if the `OSError` does not scape to the logs.\r\n\r\nClosing, then.\r\n\r\n@marlenachatzigrigoriou I’m really sorry for wasting your time, I should have tested this myself before opening the issue report.\n\nThat's fine @Gallaecio. Thank you for the help in my first effort to contribute, no matter the ending of this issue! ",
  "pr_link": "https://github.com/scrapy/scrapy/pull/5115",
  "code_context": [
    {
      "filename": "scrapy/pipelines/images.py",
      "content": "\"\"\"\nImages Pipeline\n\nSee documentation in topics/media-pipeline.rst\n\"\"\"\nimport functools\nimport hashlib\nfrom contextlib import suppress\nfrom io import BytesIO\n\nfrom itemadapter import ItemAdapter\n\nfrom scrapy.exceptions import DropItem, NotConfigured\nfrom scrapy.http import Request\nfrom scrapy.pipelines.files import FileException, FilesPipeline\n# TODO: from scrapy.pipelines.media import MediaPipeline\nfrom scrapy.settings import Settings\nfrom scrapy.utils.misc import md5sum\nfrom scrapy.utils.python import to_bytes\n\n\nclass NoimagesDrop(DropItem):\n    \"\"\"Product with no images exception\"\"\"\n\n\nclass ImageException(FileException):\n    \"\"\"General image error exception\"\"\"\n\n\nclass ImagesPipeline(FilesPipeline):\n    \"\"\"Abstract pipeline that implement the image thumbnail generation logic\n\n    \"\"\"\n\n    MEDIA_NAME = 'image'\n\n    # Uppercase attributes kept for backward compatibility with code that subclasses\n    # ImagesPipeline. They may be overridden by settings.\n    MIN_WIDTH = 0\n    MIN_HEIGHT = 0\n    EXPIRES = 90\n    THUMBS = {}\n    DEFAULT_IMAGES_URLS_FIELD = 'image_urls'\n    DEFAULT_IMAGES_RESULT_FIELD = 'images'\n\n    def __init__(self, store_uri, download_func=None, settings=None):\n        try:\n            from PIL import Image\n            self._Image = Image\n        except ImportError:\n            raise NotConfigured(\n                'ImagesPipeline requires installing Pillow 4.0.0 or later'\n            )\n\n        super().__init__(store_uri, settings=settings, download_func=download_func)\n\n        if isinstance(settings, dict) or settings is None:\n            settings = Settings(settings)\n\n        resolve = functools.partial(self._key_for_pipe,\n                                    base_class_name=\"ImagesPipeline\",\n                                    settings=settings)\n        self.expires = settings.getint(\n            resolve(\"IMAGES_EXPIRES\"), self.EXPIRES\n        )\n\n        if not hasattr(self, \"IMAGES_RESULT_FIELD\"):\n            self.IMAGES_RESULT_FIELD = self.DEFAULT_IMAGES_RESULT_FIELD\n        if not hasattr(self, \"IMAGES_URLS_FIELD\"):\n            self.IMAGES_URLS_FIELD = self.DEFAULT_IMAGES_URLS_FIELD\n\n        self.images_urls_field = settings.get(\n            resolve('IMAGES_URLS_FIELD'),\n            self.IMAGES_URLS_FIELD\n        )\n        self.images_result_field = settings.get(\n            resolve('IMAGES_RESULT_FIELD'),\n            self.IMAGES_RESULT_FIELD\n        )\n        self.min_width = settings.getint(\n            resolve('IMAGES_MIN_WIDTH'), self.MIN_WIDTH\n        )\n        self.min_height = settings.getint(\n            resolve('IMAGES_MIN_HEIGHT'), self.MIN_HEIGHT\n        )\n        self.thumbs = settings.get(\n            resolve('IMAGES_THUMBS'), self.THUMBS\n        )\n\n    @classmethod\n    def from_settings(cls, settings):\n        s3store = cls.STORE_SCHEMES['s3']\n        s3store.AWS_ACCESS_KEY_ID = settings['AWS_ACCESS_KEY_ID']\n        s3store.AWS_SECRET_ACCESS_KEY = settings['AWS_SECRET_ACCESS_KEY']\n        s3store.AWS_ENDPOINT_URL = settings['AWS_ENDPOINT_URL']\n        s3store.AWS_REGION_NAME = settings['AWS_REGION_NAME']\n        s3store.AWS_USE_SSL = settings['AWS_USE_SSL']\n        s3store.AWS_VERIFY = settings['AWS_VERIFY']\n        s3store.POLICY = settings['IMAGES_STORE_S3_ACL']\n\n        gcs_store = cls.STORE_SCHEMES['gs']\n        gcs_store.GCS_PROJECT_ID = settings['GCS_PROJECT_ID']\n        gcs_store.POLICY = settings['IMAGES_STORE_GCS_ACL'] or None\n\n        ftp_store = cls.STORE_SCHEMES['ftp']\n        ftp_store.FTP_USERNAME = settings['FTP_USER']\n        ftp_store.FTP_PASSWORD = settings['FTP_PASSWORD']\n        ftp_store.USE_ACTIVE_MODE = settings.getbool('FEED_STORAGE_FTP_ACTIVE')\n\n        store_uri = settings['IMAGES_STORE']\n        return cls(store_uri, settings=settings)\n\n    def file_downloaded(self, response, request, info, *, item=None):\n        return self.image_downloaded(response, request, info, item=item)\n\n    def image_downloaded(self, response, request, info, *, item=None):\n        checksum = None\n        image_list = self.get_images(response, request, info, item=item)\n\n        while True:\n            try:\n                path, image, buf = next(image_list)\n            except OSError:\n                continue\n            except Exception:\n                break\n            if checksum is None:\n                buf.seek(0)\n                checksum = md5sum(buf)\n            width, height = image.size\n            self.store.persist_file(\n                path, buf, info,\n                meta={'width': width, 'height': height},\n                headers={'Content-Type': 'image/jpeg'})\n        return checksum\n\n    def get_images(self, response, request, info, *, item=None):\n        path = self.file_path(request, response=response, info=info, item=item)\n        orig_image = self._Image.open(BytesIO(response.body))\n\n        width, height = orig_image.size\n        if width < self.min_width or height < self.min_height:\n            raise ImageException(\"Image too small \"\n                                 f\"({width}x{height} < \"\n                                 f\"{self.min_width}x{self.min_height})\")\n\n        image, buf = self.convert_image(orig_image)\n        yield path, image, buf\n\n        for thumb_id, size in self.thumbs.items():\n            thumb_path = self.thumb_path(request, thumb_id, response=response, info=info)\n            thumb_image, thumb_buf = self.convert_image(image, size)\n            yield thumb_path, thumb_image, thumb_buf\n\n    def convert_image(self, image, size=None):\n        if image.format == 'PNG' and image.mode == 'RGBA':\n            background = self._Image.new('RGBA', image.size, (255, 255, 255))\n            background.paste(image, image)\n            image = background.convert('RGB')\n        elif image.mode == 'P':\n            image = image.convert(\"RGBA\")\n            background = self._Image.new('RGBA', image.size, (255, 255, 255))\n            background.paste(image, image)\n            image = background.convert('RGB')\n        elif image.mode != 'RGB':\n            image = image.convert('RGB')\n\n        if size:\n            image = image.copy()\n            image.thumbnail(size, self._Image.ANTIALIAS)\n\n        buf = BytesIO()\n        image.save(buf, 'JPEG')\n        return image, buf\n\n    def get_media_requests(self, item, info):\n        urls = ItemAdapter(item).get(self.images_urls_field, [])\n        return [Request(u) for u in urls]\n\n    def item_completed(self, results, item, info):\n        with suppress(KeyError):\n            ItemAdapter(item)[self.images_result_field] = [x for ok, x in results if ok]\n        return item\n\n    def file_path(self, request, response=None, info=None, *, item=None):\n        image_guid = hashlib.sha1(to_bytes(request.url)).hexdigest()\n        return f'full/{image_guid}.jpg'\n\n    def thumb_path(self, request, thumb_id, response=None, info=None):\n        thumb_guid = hashlib.sha1(to_bytes(request.url)).hexdigest()\n        return f'thumbs/{thumb_id}/{thumb_guid}.jpg'\n"
    },
    {
      "filename": "tests/test_pipeline_images.py",
      "content": "import hashlib\nimport io\nimport random\nfrom shutil import rmtree\nfrom tempfile import mkdtemp\nfrom unittest import skipIf\nimport glob\n\nimport attr\nfrom itemadapter import ItemAdapter\nfrom twisted.trial import unittest\n\nfrom scrapy.http import Request, Response\nfrom scrapy.item import Field, Item\nfrom scrapy.pipelines.images import ImagesPipeline\nfrom scrapy.settings import Settings\nfrom scrapy.utils.python import to_bytes\n\n\ntry:\n    from dataclasses import make_dataclass, field as dataclass_field\nexcept ImportError:\n    make_dataclass = None\n    dataclass_field = None\n\n\ntry:\n    from PIL import Image\nexcept ImportError:\n    skip_pillow = 'Missing Python Imaging Library, install https://pypi.python.org/pypi/Pillow'\nelse:\n    encoders = {'jpeg_encoder', 'jpeg_decoder'}\n    if not encoders.issubset(set(Image.core.__dict__)):\n        skip_pillow = 'Missing JPEG encoders'\n    else:\n        skip_pillow = None\n\n\ndef _mocked_download_func(request, info):\n    response = request.meta.get('response')\n    return response() if callable(response) else response\n\n\nclass ImagesPipelineTestCase(unittest.TestCase):\n\n    skip = skip_pillow\n\n    def setUp(self):\n        self.tempdir = mkdtemp()\n        self.pipeline = ImagesPipeline(self.tempdir, download_func=_mocked_download_func)\n\n    def tearDown(self):\n        rmtree(self.tempdir)\n\n    def test_file_path(self):\n        file_path = self.pipeline.file_path\n        self.assertEqual(\n            file_path(Request(\"https://dev.mydeco.com/mydeco.gif\")),\n            'full/3fd165099d8e71b8a48b2683946e64dbfad8b52d.jpg')\n        self.assertEqual(\n            file_path(Request(\"http://www.maddiebrown.co.uk///catalogue-items//image_54642_12175_95307.jpg\")),\n            'full/0ffcd85d563bca45e2f90becd0ca737bc58a00b2.jpg')\n        self.assertEqual(\n            file_path(Request(\"https://dev.mydeco.com/two/dirs/with%20spaces%2Bsigns.gif\")),\n            'full/b250e3a74fff2e4703e310048a5b13eba79379d2.jpg')\n        self.assertEqual(\n            file_path(Request(\"http://www.dfsonline.co.uk/get_prod_image.php?img=status_0907_mdm.jpg\")),\n            'full/4507be485f38b0da8a0be9eb2e1dfab8a19223f2.jpg')\n        self.assertEqual(\n            file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532/\")),\n            'full/97ee6f8a46cbbb418ea91502fd24176865cf39b2.jpg')\n        self.assertEqual(\n            file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532\")),\n            'full/244e0dd7d96a3b7b01f54eded250c9e272577aa1.jpg')\n        self.assertEqual(\n            file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532\"),\n                      response=Response(\"http://www.dorma.co.uk/images/product_details/2532\"),\n                      info=object()),\n            'full/244e0dd7d96a3b7b01f54eded250c9e272577aa1.jpg')\n\n    def test_thumbnail_name(self):\n        thumb_path = self.pipeline.thumb_path\n        name = '50'\n        self.assertEqual(thumb_path(Request(\"file:///tmp/foo.jpg\"), name),\n                         'thumbs/50/38a86208c36e59d4404db9e37ce04be863ef0335.jpg')\n        self.assertEqual(thumb_path(Request(\"file://foo.png\"), name),\n                         'thumbs/50/e55b765eba0ec7348e50a1df496040449071b96a.jpg')\n        self.assertEqual(thumb_path(Request(\"file:///tmp/foo\"), name),\n                         'thumbs/50/0329ad83ebb8e93ea7c7906d46e9ed55f7349a50.jpg')\n        self.assertEqual(thumb_path(Request(\"file:///tmp/some.name/foo\"), name),\n                         'thumbs/50/850233df65a5b83361798f532f1fc549cd13cbe9.jpg')\n        self.assertEqual(thumb_path(Request(\"file:///tmp/some.name/foo\"), name,\n                                    response=Response(\"file:///tmp/some.name/foo\"),\n                                    info=object()),\n                         'thumbs/50/850233df65a5b83361798f532f1fc549cd13cbe9.jpg')\n\n    def test_pipeline_invalid_images(self):\n        urls = ['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg',\n                'https://img01.mgo-images.com/image/thumbnail/v2/content/MMVA6B4523491C0B5A88B392024490A44B7C.jpeg',\n                'https://scrapy.org/img/scrapylogo.png']\n        for url in urls:\n            Request(url)\n        self.assertEqual(len(glob.glob(self.pipeline.file_path + \"/*\")), 1)\n\n    def test_convert_image(self):\n        SIZE = (100, 100)\n        # straigh forward case: RGB and JPEG\n        COLOUR = (0, 127, 255)\n        im = _create_image('JPEG', 'RGB', SIZE, COLOUR)\n        converted, _ = self.pipeline.convert_image(im)\n        self.assertEqual(converted.mode, 'RGB')\n        self.assertEqual(converted.getcolors(), [(10000, COLOUR)])\n\n        # check that thumbnail keep image ratio\n        thumbnail, _ = self.pipeline.convert_image(converted, size=(10, 25))\n        self.assertEqual(thumbnail.mode, 'RGB')\n        self.assertEqual(thumbnail.size, (10, 10))\n\n        # transparency case: RGBA and PNG\n        COLOUR = (0, 127, 255, 50)\n        im = _create_image('PNG', 'RGBA', SIZE, COLOUR)\n        converted, _ = self.pipeline.convert_image(im)\n        self.assertEqual(converted.mode, 'RGB')\n        self.assertEqual(converted.getcolors(), [(10000, (205, 230, 255))])\n\n        # transparency case with palette: P and PNG\n        COLOUR = (0, 127, 255, 50)\n        im = _create_image('PNG', 'RGBA', SIZE, COLOUR)\n        im = im.convert('P')\n        converted, _ = self.pipeline.convert_image(im)\n        self.assertEqual(converted.mode, 'RGB')\n        self.assertEqual(converted.getcolors(), [(10000, (205, 230, 255))])\n\n\nclass DeprecatedImagesPipeline(ImagesPipeline):\n    def file_key(self, url):\n        return self.image_key(url)\n\n    def image_key(self, url):\n        image_guid = hashlib.sha1(to_bytes(url)).hexdigest()\n        return f'empty/{image_guid}.jpg'\n\n    def thumb_key(self, url, thumb_id):\n        thumb_guid = hashlib.sha1(to_bytes(url)).hexdigest()\n        return f'thumbsup/{thumb_id}/{thumb_guid}.jpg'\n\n\nclass ImagesPipelineTestCaseFieldsMixin:\n\n    skip = skip_pillow\n\n    def test_item_fields_default(self):\n        url = 'http://www.example.com/images/1.jpg'\n        item = self.item_class(name='item1', image_urls=[url])\n        pipeline = ImagesPipeline.from_settings(Settings({'IMAGES_STORE': 's3://example/images/'}))\n        requests = list(pipeline.get_media_requests(item, None))\n        self.assertEqual(requests[0].url, url)\n        results = [(True, {'url': url})]\n        item = pipeline.item_completed(results, item, None)\n        images = ItemAdapter(item).get(\"images\")\n        self.assertEqual(images, [results[0][1]])\n        self.assertIsInstance(item, self.item_class)\n\n    def test_item_fields_override_settings(self):\n        url = 'http://www.example.com/images/1.jpg'\n        item = self.item_class(name='item1', custom_image_urls=[url])\n        pipeline = ImagesPipeline.from_settings(Settings({\n            'IMAGES_STORE': 's3://example/images/',\n            'IMAGES_URLS_FIELD': 'custom_image_urls',\n            'IMAGES_RESULT_FIELD': 'custom_images'\n        }))\n        requests = list(pipeline.get_media_requests(item, None))\n        self.assertEqual(requests[0].url, url)\n        results = [(True, {'url': url})]\n        item = pipeline.item_completed(results, item, None)\n        custom_images = ItemAdapter(item).get(\"custom_images\")\n        self.assertEqual(custom_images, [results[0][1]])\n        self.assertIsInstance(item, self.item_class)\n\n\nclass ImagesPipelineTestCaseFieldsDict(ImagesPipelineTestCaseFieldsMixin, unittest.TestCase):\n    item_class = dict\n\n\nclass ImagesPipelineTestItem(Item):\n    name = Field()\n    # default fields\n    image_urls = Field()\n    images = Field()\n    # overridden fields\n    custom_image_urls = Field()\n    custom_images = Field()\n\n\nclass ImagesPipelineTestCaseFieldsItem(ImagesPipelineTestCaseFieldsMixin, unittest.TestCase):\n    item_class = ImagesPipelineTestItem\n\n\n@skipIf(not make_dataclass, \"dataclasses module is not available\")\nclass ImagesPipelineTestCaseFieldsDataClass(ImagesPipelineTestCaseFieldsMixin, unittest.TestCase):\n    item_class = None\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        if make_dataclass:\n            self.item_class = make_dataclass(\n                \"FilesPipelineTestDataClass\",\n                [\n                    (\"name\", str),\n                    # default fields\n                    (\"image_urls\", list, dataclass_field(default_factory=list)),\n                    (\"images\", list, dataclass_field(default_factory=list)),\n                    # overridden fields\n                    (\"custom_image_urls\", list, dataclass_field(default_factory=list)),\n                    (\"custom_images\", list, dataclass_field(default_factory=list)),\n                ],\n            )\n\n\n@attr.s\nclass ImagesPipelineTestAttrsItem:\n    name = attr.ib(default=\"\")\n    # default fields\n    image_urls = attr.ib(default=lambda: [])\n    images = attr.ib(default=lambda: [])\n    # overridden fields\n    custom_image_urls = attr.ib(default=lambda: [])\n    custom_images = attr.ib(default=lambda: [])\n\n\nclass ImagesPipelineTestCaseFieldsAttrsItem(ImagesPipelineTestCaseFieldsMixin, unittest.TestCase):\n    item_class = ImagesPipelineTestAttrsItem\n\n\nclass ImagesPipelineTestCaseCustomSettings(unittest.TestCase):\n\n    skip = skip_pillow\n\n    img_cls_attribute_names = [\n        # Pipeline attribute names with corresponding setting names.\n        (\"EXPIRES\", \"IMAGES_EXPIRES\"),\n        (\"MIN_WIDTH\", \"IMAGES_MIN_WIDTH\"),\n        (\"MIN_HEIGHT\", \"IMAGES_MIN_HEIGHT\"),\n        (\"IMAGES_URLS_FIELD\", \"IMAGES_URLS_FIELD\"),\n        (\"IMAGES_RESULT_FIELD\", \"IMAGES_RESULT_FIELD\"),\n        (\"THUMBS\", \"IMAGES_THUMBS\")\n    ]\n\n    # This should match what is defined in ImagesPipeline.\n    default_pipeline_settings = dict(\n        MIN_WIDTH=0,\n        MIN_HEIGHT=0,\n        EXPIRES=90,\n        THUMBS={},\n        IMAGES_URLS_FIELD='image_urls',\n        IMAGES_RESULT_FIELD='images'\n    )\n\n    def setUp(self):\n        self.tempdir = mkdtemp()\n\n    def tearDown(self):\n        rmtree(self.tempdir)\n\n    def _generate_fake_settings(self, prefix=None):\n        \"\"\"\n        :param prefix: string for setting keys\n        :return: dictionary of image pipeline settings\n        \"\"\"\n\n        def random_string():\n            return \"\".join([chr(random.randint(97, 123)) for _ in range(10)])\n\n        settings = {\n            \"IMAGES_EXPIRES\": random.randint(100, 1000),\n            \"IMAGES_STORE\": self.tempdir,\n            \"IMAGES_RESULT_FIELD\": random_string(),\n            \"IMAGES_URLS_FIELD\": random_string(),\n            \"IMAGES_MIN_WIDTH\": random.randint(1, 1000),\n            \"IMAGES_MIN_HEIGHT\": random.randint(1, 1000),\n            \"IMAGES_THUMBS\": {\n                'small': (random.randint(1, 1000), random.randint(1, 1000)),\n                'big': (random.randint(1, 1000), random.randint(1, 1000))\n            }\n        }\n        if not prefix:\n            return settings\n\n        return {prefix.upper() + \"_\" + k if k != \"IMAGES_STORE\" else k: v for k, v in settings.items()}\n\n    def _generate_fake_pipeline_subclass(self):\n        \"\"\"\n        :return: ImagePipeline class will all uppercase attributes set.\n        \"\"\"\n        class UserDefinedImagePipeline(ImagesPipeline):\n            # Values should be in different range than fake_settings.\n            MIN_WIDTH = random.randint(1000, 2000)\n            MIN_HEIGHT = random.randint(1000, 2000)\n            THUMBS = {\n                'small': (random.randint(1000, 2000), random.randint(1000, 2000)),\n                'big': (random.randint(1000, 2000), random.randint(1000, 2000))\n            }\n            EXPIRES = random.randint(1000, 2000)\n            IMAGES_URLS_FIELD = \"field_one\"\n            IMAGES_RESULT_FIELD = \"field_two\"\n\n        return UserDefinedImagePipeline\n\n    def test_different_settings_for_different_instances(self):\n        \"\"\"\n        If there are two instances of ImagesPipeline class with different settings, they should\n        have different settings.\n        \"\"\"\n        custom_settings = self._generate_fake_settings()\n        default_settings = Settings()\n        default_sts_pipe = ImagesPipeline(self.tempdir, settings=default_settings)\n        user_sts_pipe = ImagesPipeline.from_settings(Settings(custom_settings))\n        for pipe_attr, settings_attr in self.img_cls_attribute_names:\n            expected_default_value = self.default_pipeline_settings.get(pipe_attr)\n            custom_value = custom_settings.get(settings_attr)\n            self.assertNotEqual(expected_default_value, custom_value)\n            self.assertEqual(getattr(default_sts_pipe, pipe_attr.lower()), expected_default_value)\n            self.assertEqual(getattr(user_sts_pipe, pipe_attr.lower()), custom_value)\n\n    def test_subclass_attrs_preserved_default_settings(self):\n        \"\"\"\n        If image settings are not defined at all subclass of ImagePipeline takes values\n        from class attributes.\n        \"\"\"\n        pipeline_cls = self._generate_fake_pipeline_subclass()\n        pipeline = pipeline_cls.from_settings(Settings({\"IMAGES_STORE\": self.tempdir}))\n        for pipe_attr, settings_attr in self.img_cls_attribute_names:\n            # Instance attribute (lowercase) must be equal to class attribute (uppercase).\n            attr_value = getattr(pipeline, pipe_attr.lower())\n            self.assertNotEqual(attr_value, self.default_pipeline_settings[pipe_attr])\n            self.assertEqual(attr_value, getattr(pipeline, pipe_attr))\n\n    def test_subclass_attrs_preserved_custom_settings(self):\n        \"\"\"\n        If image settings are defined but they are not defined for subclass default\n        values taken from settings should be preserved.\n        \"\"\"\n        pipeline_cls = self._generate_fake_pipeline_subclass()\n        settings = self._generate_fake_settings()\n        pipeline = pipeline_cls.from_settings(Settings(settings))\n        for pipe_attr, settings_attr in self.img_cls_attribute_names:\n            # Instance attribute (lowercase) must be equal to\n            # value defined in settings.\n            value = getattr(pipeline, pipe_attr.lower())\n            self.assertNotEqual(value, self.default_pipeline_settings[pipe_attr])\n            setings_value = settings.get(settings_attr)\n            self.assertEqual(value, setings_value)\n\n    def test_no_custom_settings_for_subclasses(self):\n        \"\"\"\n        If there are no settings for subclass and no subclass attributes, pipeline should use\n        attributes of base class.\n        \"\"\"\n        class UserDefinedImagePipeline(ImagesPipeline):\n            pass\n\n        user_pipeline = UserDefinedImagePipeline.from_settings(Settings({\"IMAGES_STORE\": self.tempdir}))\n        for pipe_attr, settings_attr in self.img_cls_attribute_names:\n            # Values from settings for custom pipeline should be set on pipeline instance.\n            custom_value = self.default_pipeline_settings.get(pipe_attr.upper())\n            self.assertEqual(getattr(user_pipeline, pipe_attr.lower()), custom_value)\n\n    def test_custom_settings_for_subclasses(self):\n        \"\"\"\n        If there are custom settings for subclass and NO class attributes, pipeline should use custom\n        settings.\n        \"\"\"\n        class UserDefinedImagePipeline(ImagesPipeline):\n            pass\n\n        prefix = UserDefinedImagePipeline.__name__.upper()\n        settings = self._generate_fake_settings(prefix=prefix)\n        user_pipeline = UserDefinedImagePipeline.from_settings(Settings(settings))\n        for pipe_attr, settings_attr in self.img_cls_attribute_names:\n            # Values from settings for custom pipeline should be set on pipeline instance.\n            custom_value = settings.get(prefix + \"_\" + settings_attr)\n            self.assertNotEqual(custom_value, self.default_pipeline_settings[pipe_attr])\n            self.assertEqual(getattr(user_pipeline, pipe_attr.lower()), custom_value)\n\n    def test_custom_settings_and_class_attrs_for_subclasses(self):\n        \"\"\"\n        If there are custom settings for subclass AND class attributes\n        setting keys are preferred and override attributes.\n        \"\"\"\n        pipeline_cls = self._generate_fake_pipeline_subclass()\n        prefix = pipeline_cls.__name__.upper()\n        settings = self._generate_fake_settings(prefix=prefix)\n        user_pipeline = pipeline_cls.from_settings(Settings(settings))\n        for pipe_attr, settings_attr in self.img_cls_attribute_names:\n            custom_value = settings.get(prefix + \"_\" + settings_attr)\n            self.assertNotEqual(custom_value, self.default_pipeline_settings[pipe_attr])\n            self.assertEqual(getattr(user_pipeline, pipe_attr.lower()), custom_value)\n\n    def test_cls_attrs_with_DEFAULT_prefix(self):\n        class UserDefinedImagePipeline(ImagesPipeline):\n            DEFAULT_IMAGES_URLS_FIELD = \"something\"\n            DEFAULT_IMAGES_RESULT_FIELD = \"something_else\"\n        pipeline = UserDefinedImagePipeline.from_settings(Settings({\"IMAGES_STORE\": self.tempdir}))\n        self.assertEqual(pipeline.images_result_field, \"something_else\")\n        self.assertEqual(pipeline.images_urls_field, \"something\")\n\n    def test_user_defined_subclass_default_key_names(self):\n        \"\"\"Test situation when user defines subclass of ImagePipeline,\n        but uses attribute names for default pipeline (without prefixing\n        them with pipeline class name).\n        \"\"\"\n        settings = self._generate_fake_settings()\n\n        class UserPipe(ImagesPipeline):\n            pass\n\n        pipeline_cls = UserPipe.from_settings(Settings(settings))\n\n        for pipe_attr, settings_attr in self.img_cls_attribute_names:\n            expected_value = settings.get(settings_attr)\n            self.assertEqual(getattr(pipeline_cls, pipe_attr.lower()),\n                             expected_value)\n\n\ndef _create_image(format, *a, **kw):\n    buf = io.BytesIO()\n    Image.new(*a, **kw).save(buf, format)\n    buf.seek(0)\n    return Image.open(buf)\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n"
    }
  ],
  "questions": [
    "I've checked the related code and documentation. I've tried to recreate a spider as @Gallaecio indicated, using ImagePipeline but it doesn't store any of the images. \r\n@apalala's suggestion should be embedded in scrapy.pipelines.images.ImagesPipeline image_downloaded method? \r\nI think I need a little bit more guidance.",
    "I believe the main issue here is that if an item has 1 valid image URL after 1 URL to an image that Pillow fails to parse, none of the 2 images get downloaded.\r\n\r\nSo to reproduce the issue it would be better to use something like `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`.\r\n\r\n> @apalala's suggestion should be embedded in scrapy.pipelines.images.ImagesPipeline image_downloaded method?\r\n\r\nI believe so.\r\n\r\nYou could first try with the current Scrapy implementation and `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`, and verify that none of the 2 images get downloaded.\r\n\r\nThen try adding @apalala’s code to your local clone of Scrapy, installing that version of Scrapy (i.e. `pip install -e <path to your local Scrapy clone>`), and running the spider again, see if this time around the Scrapy logo gets downloaded.",
    "I have reproduced the issue as @Gallaecio indicated and I am trying to fix the code to my local clone. The purpose is to download both images (valid and invalid), or just the valid one, when `image_urls` is set to `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`?",
    "> @apalala reported this issue when a site sends some invalid images, and suggested a fix for the spider middleware:\r\n> \r\n> ```\r\n>         image_stream = self.get_images(response, request, info, item=item)\r\n>         while True:\r\n>             try:\r\n>                 path, image, buf = next(image_stream)\r\n>             except StopIteration:\r\n>                 break\r\n>             except Exception:\r\n>                 continue\r\n> ```\r\n> \r\n> I’ve not checked if there’s a cleaner fix possible (i.e. closer to the call to Pillow code), but it should be trivial to fix either way. I suspect writing a test may be the hardest part here.\r\n\r\nHi, I want to work on this is it still available?"
  ],
  "golden_answers": [
    "I believe the main issue here is that if an item has 1 valid image URL after 1 URL to an image that Pillow fails to parse, none of the 2 images get downloaded.\r\n\r\nSo to reproduce the issue it would be better to use something like `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`.\r\n\r\n> @apalala's suggestion should be embedded in scrapy.pipelines.images.ImagesPipeline image_downloaded method?\r\n\r\nI believe so.\r\n\r\nYou could first try with the current Scrapy implementation and `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`, and verify that none of the 2 images get downloaded.\r\n\r\nThen try adding @apalala’s code to your local clone of Scrapy, installing that version of Scrapy (i.e. `pip install -e <path to your local Scrapy clone>`), and running the spider again, see if this time around the Scrapy logo gets downloaded.",
    "I have reproduced the issue as @Gallaecio indicated and I am trying to fix the code to my local clone. The purpose is to download both images (valid and invalid), or just the valid one, when `image_urls` is set to `['https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg', 'https://scrapy.org/img/scrapylogo.png']`?",
    "Note that this should be replaced by specific exception types (like `OSError`) and handling to avoid the risk of an infinite loop:\r\n\r\n```\r\nexcept Exception:\r\n    continue\r\n```\r\n\r\nThe sample code relies too much on the iterator eventually reaching `StopIteration`.\r\n\r\n```\r\nexcept OSError as e:\r\n    logger.exception('Could not process image')\r\nexcept Exception as e:\r\n   logger.exception('Stopped processing images')\r\n   break\r\n```",
    "@apalala @marlenachatzigrigoriou @spittieUM Looking deeper into the code to provide better feedback for your solutions, it started to seem to me that this issue should not be happening at all, because exceptions from the `get_images` method should not block the download of other images.\r\n\r\nTo be sure, I went ahead and tested the issue myself, creating the following file and running it with `scrapy runspider` in a Python virtual environment with Scrapy and Pillow installed:\r\n\r\n```python\r\nfrom scrapy import Spider\r\n\r\n\r\nclass TestSpider(Spider):\r\n    name = 'test'\r\n    start_urls = ['http://toscrape.com/']\r\n\r\n    custom_settings = {\r\n        'IMAGES_STORE': '',  # TODO: Set your own download path\r\n        'ITEM_PIPELINES': {\r\n            'scrapy.pipelines.images.ImagesPipeline': 1,\r\n        }\r\n    }\r\n\r\n    def parse(self, response):\r\n        yield {\r\n            'image_urls': [\r\n                'http://toscrape.com/img/zyte.png',\r\n                'https://img01.mgo-images.com/image/thumbnail/v2/content/MMV5CEBE0C5DC82A5028E7EA6B91F904DEF3.jpeg',\r\n                'http://toscrape.com/img/books.png',\r\n            ],\r\n        }\r\n```\r\n\r\nThis spider did as expected: the 2 good images were downloaded, the bad one was not downloaded.\r\n\r\n@apalala Either I’m not understanding the issue correctly, or there is no issue."
  ],
  "questions_generated": [
    "What is the primary issue reported with the ImagePipeline in the scrapy_scrapy repository?",
    "Where is the suggested fix by @apalala intended to be implemented within the Scrapy codebase?",
    "How can the issue with ImagePipeline be reproduced according to the discussion context?",
    "Why might writing a test for this issue be considered the hardest part, as mentioned in the issue description?",
    "What exception is raised by Pillow that needs to be handled to prevent the ImagePipeline from breaking?"
  ],
  "golden_answers_generated": [
    "The primary issue reported is that the ImagePipeline breaks when processing invalid images sent by a site, which prevents any subsequent valid images from being processed and downloaded.",
    "@apalala's suggested fix is intended to be implemented in the ImagesPipeline, specifically within the image_downloaded method, to handle exceptions raised when processing invalid images without halting the pipeline.",
    "To reproduce the issue, create a Scrapy spider that uses the ImagePipeline and yields an item with its image_urls set to include a mix of invalid and valid image URLs. When processed by the current Scrapy implementation, none of the images should get downloaded if the first URL is invalid.",
    "Writing a test may be considered the hardest part because it requires setting up a controlled environment to simulate the behavior of the ImagePipeline when encountering invalid images, ensuring that the fix works correctly without affecting the processing of valid images.",
    "The exception raised by Pillow that needs to be handled is an OSError. Handling this exception within the image processing loop can prevent the pipeline from breaking when encountering invalid images."
  ]
}