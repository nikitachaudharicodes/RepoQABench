{
  "repo_name": "scrapy_scrapy",
  "issue_id": "4222",
  "issue_description": "# SCRAPY_CHECK is not set while running contract\n\n### Description\r\n\r\nHi, it seems that #3739 is not doing what the [documentation describe](https://docs.scrapy.org/en/latest/topics/contracts.html#detecting-check-runs):\r\n\r\n`os.environ.get('SCRAPY_CHECK')` is returning `None` in my contract check.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Create a project from scratch\r\n2. Add a random spider\r\n3. Contract code is as follow\r\n```\r\n    def parse(self, response):\r\n        \"\"\"\r\n        @url http://www.amazon.com/s?field-keywords=selfish+gene\r\n        @returns requests 1 1\r\n        \"\"\"\r\n        print(\"test\", os.environ.get('SCRAPY_CHECK'))\r\n        if os.environ.get('SCRAPY_CHECK'):\r\n            yield scrapy.Request(url=\"next_url\")\r\n```\r\n\r\n**Expected behavior:** Request should be yielded as per the documentation\r\n\r\n**Actual behavior:** Nothing happen\r\n\r\n**Reproduces how often:** In my local project and with fresh project\r\n\r\n### Versions\r\n\r\nWindows\r\n```\r\n(globenv) C:\\Users\\johnl>scrapy version --verbose\r\nScrapy       : 1.8.0\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.5\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.10.0\r\nPython       : 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 19:29:22) [MSC v.1916 32 bit (Intel)]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1c  28 May 2019)\r\ncryptography : 2.7\r\nPlatform     : Windows-10-10.0.18362-SP0\r\n```\r\n\r\nLinux\r\n```\r\nscrapy version --verbose\r\nScrapy       : 1.8.0\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.7.0\r\nPython       : 3.6.8 (default, Oct  7 2019, 12:59:55) - [GCC 8.3.0]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1d  10 Sep 2019)\r\ncryptography : 2.8\r\nPlatform     : Linux-4.4.0-18362-Microsoft-x86_64-with-Ubuntu-18.04-bionic\r\n```\r\n",
  "issue_comments": [
    {
      "id": 563342885,
      "user": "Gallaecio",
      "body": "The variable is only defined at initialization, not at run time. If you have a look at the code example from the documentation, you’ll notice that it is used in `__init__`, not in a callback. I think this is on purpose, although it could be more clear in the documentation.\r\n\r\nI’m turning this ticket into a documentation enhancement request. If you would rather it be a request to have the environment variable also available at run time, from callback, please let me know."
    },
    {
      "id": 563355188,
      "user": "Lightjohn",
      "body": "Thanks for the quick answer.\r\n\r\nI think it could be nice to have it available for the callback running in check mode.\r\nAt least it would make sense to me that the ENV variable is set all the time while check.\r\n\r\nBut from there I can definitely build the check awareness feature that I want from `__init__` very easily.\r\n\r\nEDIT: After giving a little bit more thought I think I will stay with doc enhancement as in my case it's more a trick in my spider that is forcing another trick!"
    },
    {
      "id": 564216347,
      "user": "elacuesta",
      "body": "While I agree that the current behaviour does match the docs, I wonder if this isn't a reasonable use case. From a very quick look, it seems like it could be solved by just including the next code block in the `set_environ` context manager:\r\n\r\n```diff\r\ndiff --git scrapy/commands/check.py scrapy/commands/check.py\r\nindex 9d4437a4..09a76ca7 100644\r\n--- scrapy/commands/check.py\r\n+++ scrapy/commands/check.py\r\n@@ -78,19 +78,19 @@ class Command(ScrapyCommand):\r\n                 elif tested_methods:\r\n                     self.crawler_process.crawl(spidercls)\r\n \r\n-        # start checks\r\n-        if opts.list:\r\n-            for spider, methods in sorted(contract_reqs.items()):\r\n-                if not methods and not opts.verbose:\r\n-                    continue\r\n-                print(spider)\r\n-                for method in sorted(methods):\r\n-                    print('  * %s' % method)\r\n-        else:\r\n-            start = time.time()\r\n-            self.crawler_process.start()\r\n-            stop = time.time()\r\n-\r\n-            result.printErrors()\r\n-            result.printSummary(start, stop)\r\n-            self.exitcode = int(not result.wasSuccessful())\r\n+            # start checks\r\n+            if opts.list:\r\n+                for spider, methods in sorted(contract_reqs.items()):\r\n+                    if not methods and not opts.verbose:\r\n+                        continue\r\n+                    print(spider)\r\n+                    for method in sorted(methods):\r\n+                        print('  * %s' % method)\r\n+            else:\r\n+                start = time.time()\r\n+                self.crawler_process.start()\r\n+                stop = time.time()\r\n+\r\n+                result.printErrors()\r\n+                result.printSummary(start, stop)\r\n+                self.exitcode = int(not result.wasSuccessful())\r\n```\r\n\r\nAny thoughts?"
    },
    {
      "id": 564222680,
      "user": "Gallaecio",
      "body": "I have no strong opinion either way.\r\n\r\n@Matthijsy Do you remember if you had a reason not to apply the environment variable at run time?"
    },
    {
      "id": 564405786,
      "user": "Matthijsy",
      "body": "I am not sure why I did it that way. I think it would be fine to include the check run itself in the environment variable block as well."
    },
    {
      "id": 595094865,
      "user": "ivange94",
      "body": "Is someone working on this? If not I'd like to work on this."
    },
    {
      "id": 597755873,
      "user": "gigatesseract",
      "body": "@Gallaecio @Matthijsy \r\nThe referenced PR has no diff. Does the PR fix the issue? What am I missing?"
    },
    {
      "id": 597761471,
      "user": "Matthijsy",
      "body": "The code has an added tab to include it within the context of `set_environ(SCRAPY_CHECK='true'):`, this makes sure that the environment variable is set during the execution of the code"
    },
    {
      "id": 598092857,
      "user": "gigatesseract",
      "body": "Got it. My bad. \r\nThanks for clarifying."
    },
    {
      "id": 598373876,
      "user": "Gallaecio",
      "body": "https://github.com/scrapy/scrapy/pull/4298, from @faizan2700, is only missing tests. If @faizan2700 is busy, maybe someone else can work on tests, and send a pull request to the corresponding branch in his fork, or create a new pull request built on top of his changes."
    },
    {
      "id": 600413230,
      "user": "faizan2700",
      "body": "when i run tests using tox command in scrapy directory instead of running tests I am getting exception  (ValueError : No closing quotation). I tried to check this online but couldn't solve the problem. Can someone please help me on this (@Gallaecio ) . Thank You"
    }
  ],
  "text_context": "# SCRAPY_CHECK is not set while running contract\n\n### Description\r\n\r\nHi, it seems that #3739 is not doing what the [documentation describe](https://docs.scrapy.org/en/latest/topics/contracts.html#detecting-check-runs):\r\n\r\n`os.environ.get('SCRAPY_CHECK')` is returning `None` in my contract check.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Create a project from scratch\r\n2. Add a random spider\r\n3. Contract code is as follow\r\n```\r\n    def parse(self, response):\r\n        \"\"\"\r\n        @url http://www.amazon.com/s?field-keywords=selfish+gene\r\n        @returns requests 1 1\r\n        \"\"\"\r\n        print(\"test\", os.environ.get('SCRAPY_CHECK'))\r\n        if os.environ.get('SCRAPY_CHECK'):\r\n            yield scrapy.Request(url=\"next_url\")\r\n```\r\n\r\n**Expected behavior:** Request should be yielded as per the documentation\r\n\r\n**Actual behavior:** Nothing happen\r\n\r\n**Reproduces how often:** In my local project and with fresh project\r\n\r\n### Versions\r\n\r\nWindows\r\n```\r\n(globenv) C:\\Users\\johnl>scrapy version --verbose\r\nScrapy       : 1.8.0\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.5\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.10.0\r\nPython       : 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 19:29:22) [MSC v.1916 32 bit (Intel)]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1c  28 May 2019)\r\ncryptography : 2.7\r\nPlatform     : Windows-10-10.0.18362-SP0\r\n```\r\n\r\nLinux\r\n```\r\nscrapy version --verbose\r\nScrapy       : 1.8.0\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.7.0\r\nPython       : 3.6.8 (default, Oct  7 2019, 12:59:55) - [GCC 8.3.0]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1d  10 Sep 2019)\r\ncryptography : 2.8\r\nPlatform     : Linux-4.4.0-18362-Microsoft-x86_64-with-Ubuntu-18.04-bionic\r\n```\r\n\n\nThe variable is only defined at initialization, not at run time. If you have a look at the code example from the documentation, you’ll notice that it is used in `__init__`, not in a callback. I think this is on purpose, although it could be more clear in the documentation.\r\n\r\nI’m turning this ticket into a documentation enhancement request. If you would rather it be a request to have the environment variable also available at run time, from callback, please let me know.\n\nThanks for the quick answer.\r\n\r\nI think it could be nice to have it available for the callback running in check mode.\r\nAt least it would make sense to me that the ENV variable is set all the time while check.\r\n\r\nBut from there I can definitely build the check awareness feature that I want from `__init__` very easily.\r\n\r\nEDIT: After giving a little bit more thought I think I will stay with doc enhancement as in my case it's more a trick in my spider that is forcing another trick!\n\nWhile I agree that the current behaviour does match the docs, I wonder if this isn't a reasonable use case. From a very quick look, it seems like it could be solved by just including the next code block in the `set_environ` context manager:\r\n\r\n```diff\r\ndiff --git scrapy/commands/check.py scrapy/commands/check.py\r\nindex 9d4437a4..09a76ca7 100644\r\n--- scrapy/commands/check.py\r\n+++ scrapy/commands/check.py\r\n@@ -78,19 +78,19 @@ class Command(ScrapyCommand):\r\n                 elif tested_methods:\r\n                     self.crawler_process.crawl(spidercls)\r\n \r\n-        # start checks\r\n-        if opts.list:\r\n-            for spider, methods in sorted(contract_reqs.items()):\r\n-                if not methods and not opts.verbose:\r\n-                    continue\r\n-                print(spider)\r\n-                for method in sorted(methods):\r\n-                    print('  * %s' % method)\r\n-        else:\r\n-            start = time.time()\r\n-            self.crawler_process.start()\r\n-            stop = time.time()\r\n-\r\n-            result.printErrors()\r\n-            result.printSummary(start, stop)\r\n-            self.exitcode = int(not result.wasSuccessful())\r\n+            # start checks\r\n+            if opts.list:\r\n+                for spider, methods in sorted(contract_reqs.items()):\r\n+                    if not methods and not opts.verbose:\r\n+                        continue\r\n+                    print(spider)\r\n+                    for method in sorted(methods):\r\n+                        print('  * %s' % method)\r\n+            else:\r\n+                start = time.time()\r\n+                self.crawler_process.start()\r\n+                stop = time.time()\r\n+\r\n+                result.printErrors()\r\n+                result.printSummary(start, stop)\r\n+                self.exitcode = int(not result.wasSuccessful())\r\n```\r\n\r\nAny thoughts?\n\nI have no strong opinion either way.\r\n\r\n@Matthijsy Do you remember if you had a reason not to apply the environment variable at run time?\n\nI am not sure why I did it that way. I think it would be fine to include the check run itself in the environment variable block as well.\n\nIs someone working on this? If not I'd like to work on this.\n\n@Gallaecio @Matthijsy \r\nThe referenced PR has no diff. Does the PR fix the issue? What am I missing?\n\nThe code has an added tab to include it within the context of `set_environ(SCRAPY_CHECK='true'):`, this makes sure that the environment variable is set during the execution of the code\n\nGot it. My bad. \r\nThanks for clarifying.\n\nhttps://github.com/scrapy/scrapy/pull/4298, from @faizan2700, is only missing tests. If @faizan2700 is busy, maybe someone else can work on tests, and send a pull request to the corresponding branch in his fork, or create a new pull request built on top of his changes.\n\nwhen i run tests using tox command in scrapy directory instead of running tests I am getting exception  (ValueError : No closing quotation). I tried to check this online but couldn't solve the problem. Can someone please help me on this (@Gallaecio ) . Thank You",
  "pr_link": "https://github.com/scrapy/scrapy/pull/4298",
  "code_context": [
    {
      "filename": "scrapy/commands/check.py",
      "content": "import time\nfrom collections import defaultdict\nfrom unittest import TextTestRunner, TextTestResult as _TextTestResult\n\nfrom scrapy.commands import ScrapyCommand\nfrom scrapy.contracts import ContractsManager\nfrom scrapy.utils.misc import load_object, set_environ\nfrom scrapy.utils.conf import build_component_list\n\n\nclass TextTestResult(_TextTestResult):\n    def printSummary(self, start, stop):\n        write = self.stream.write\n        writeln = self.stream.writeln\n\n        run = self.testsRun\n        plural = \"s\" if run != 1 else \"\"\n\n        writeln(self.separator2)\n        writeln(\"Ran %d contract%s in %.3fs\" % (run, plural, stop - start))\n        writeln()\n\n        infos = []\n        if not self.wasSuccessful():\n            write(\"FAILED\")\n            failed, errored = map(len, (self.failures, self.errors))\n            if failed:\n                infos.append(\"failures=%d\" % failed)\n            if errored:\n                infos.append(\"errors=%d\" % errored)\n        else:\n            write(\"OK\")\n\n        if infos:\n            writeln(\" (%s)\" % (\", \".join(infos),))\n        else:\n            write(\"\\n\")\n\n\nclass Command(ScrapyCommand):\n    requires_project = True\n    default_settings = {'LOG_ENABLED': False}\n\n    def syntax(self):\n        return \"[options] <spider>\"\n\n    def short_desc(self):\n        return \"Check spider contracts\"\n\n    def add_options(self, parser):\n        ScrapyCommand.add_options(self, parser)\n        parser.add_option(\"-l\", \"--list\", dest=\"list\", action=\"store_true\",\n                          help=\"only list contracts, without checking them\")\n        parser.add_option(\"-v\", \"--verbose\", dest=\"verbose\", default=False, action='store_true',\n                          help=\"print contract tests for all spiders\")\n\n    def run(self, args, opts):\n        # load contracts\n        contracts = build_component_list(self.settings.getwithbase('SPIDER_CONTRACTS'))\n        conman = ContractsManager(load_object(c) for c in contracts)\n        runner = TextTestRunner(verbosity=2 if opts.verbose else 1)\n        result = TextTestResult(runner.stream, runner.descriptions, runner.verbosity)\n\n        # contract requests\n        contract_reqs = defaultdict(list)\n\n        spider_loader = self.crawler_process.spider_loader\n\n        with set_environ(SCRAPY_CHECK='true'):\n            for spidername in args or spider_loader.list():\n                spidercls = spider_loader.load(spidername)\n                spidercls.start_requests = lambda s: conman.from_spider(s, result)\n\n                tested_methods = conman.tested_methods_from_spidercls(spidercls)\n                if opts.list:\n                    for method in tested_methods:\n                        contract_reqs[spidercls.name].append(method)\n                elif tested_methods:\n                    self.crawler_process.crawl(spidercls)\n\n            # start checks\n            if opts.list:\n                for spider, methods in sorted(contract_reqs.items()):\n                    if not methods and not opts.verbose:\n                        continue\n                    print(spider)\n                    for method in sorted(methods):\n                        print('  * %s' % method)\n            else:\n                start = time.time()\n                self.crawler_process.start()\n                stop = time.time()\n\n                result.printErrors()\n                result.printSummary(start, stop)\n                self.exitcode = int(not result.wasSuccessful())\n"
    }
  ],
  "questions": [
    "### Description\r\n\r\nHi, it seems that #3739 is not doing what the [documentation describe](https://docs.scrapy.org/en/latest/topics/contracts.html#detecting-check-runs):\r\n\r\n`os.environ.get('SCRAPY_CHECK')` is returning `None` in my contract check.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Create a project from scratch\r\n2. Add a random spider\r\n3. Contract code is as follow\r\n```\r\n    def parse(self, response):\r\n        \"\"\"\r\n        @url http://www.amazon.com/s?field-keywords=selfish+gene\r\n        @returns requests 1 1\r\n        \"\"\"\r\n        print(\"test\", os.environ.get('SCRAPY_CHECK'))\r\n        if os.environ.get('SCRAPY_CHECK'):\r\n            yield scrapy.Request(url=\"next_url\")\r\n```\r\n\r\n**Expected behavior:** Request should be yielded as per the documentation\r\n\r\n**Actual behavior:** Nothing happen\r\n\r\n**Reproduces how often:** In my local project and with fresh project\r\n\r\n### Versions\r\n\r\nWindows\r\n```\r\n(globenv) C:\\Users\\johnl>scrapy version --verbose\r\nScrapy       : 1.8.0\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.5\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.10.0\r\nPython       : 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 19:29:22) [MSC v.1916 32 bit (Intel)]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1c  28 May 2019)\r\ncryptography : 2.7\r\nPlatform     : Windows-10-10.0.18362-SP0\r\n```\r\n\r\nLinux\r\n```\r\nscrapy version --verbose\r\nScrapy       : 1.8.0\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.7.0\r\nPython       : 3.6.8 (default, Oct  7 2019, 12:59:55) - [GCC 8.3.0]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1d  10 Sep 2019)\r\ncryptography : 2.8\r\nPlatform     : Linux-4.4.0-18362-Microsoft-x86_64-with-Ubuntu-18.04-bionic\r\n```"
  ],
  "golden_answers": [
    "The variable is only defined at initialization, not at run time. If you have a look at the code example from the documentation, you’ll notice that it is used in `__init__`, not in a callback. I think this is on purpose, although it could be more clear in the documentation.\r\n\r\nI’m turning this ticket into a documentation enhancement request. If you would rather it be a request to have the environment variable also available at run time, from callback, please let me know."
  ],
  "questions_generated": [
    "What is the main issue being discussed in the 'scrapy_scrapy' repository regarding the 'SCRAPY_CHECK' environment variable?",
    "How does the discussed issue affect the expected functionality of the contract checks in the 'scrapy_scrapy' repository?",
    "What is the suggested workaround or enhancement to address the issue with the 'SCRAPY_CHECK' environment variable?",
    "What specific part of the code is responsible for handling the environment variable in the context of this issue?",
    "Why might the current behavior of the 'SCRAPY_CHECK' environment variable be intentional, according to the discussion?"
  ],
  "golden_answers_generated": [
    "The main issue is that the 'SCRAPY_CHECK' environment variable is not set while running a contract check, resulting in 'os.environ.get('SCRAPY_CHECK')' returning 'None'. This is contrary to what the documentation describes, leading to unexpected behavior during contract checks.",
    "The issue affects the expected functionality by preventing the yielding of requests when the 'SCRAPY_CHECK' environment variable is supposed to be set. Since the variable is not set, the condition to yield a request is never met, leading to no requests being processed as documented.",
    "One suggested enhancement is to include the 'SCRAPY_CHECK' environment variable setting within the 'set_environ' context manager to ensure it's available during runtime in callbacks. The issue could also be addressed by clarifying the documentation to reflect the current behavior.",
    "The 'set_environ' context manager within the 'scrapy/commands/check.py' file is responsible for handling environment variables. The suggestion is to modify this part to include the 'SCRAPY_CHECK' environment variable during contract checks.",
    "The current behavior might be intentional to limit the scope of the 'SCRAPY_CHECK' environment variable to the initialization phase rather than runtime callbacks. This could be a design choice to manage environment variables more predictably, although the documentation could be clearer about this behavior."
  ]
}