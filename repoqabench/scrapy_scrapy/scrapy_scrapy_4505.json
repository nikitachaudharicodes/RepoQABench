{
  "repo_name": "scrapy_scrapy",
  "issue_id": "4505",
  "issue_description": "# Using proxy through http fails (https works)\n\n### Description\r\n\r\nWhen I scrape without proxy, both https and http urls work.\r\nUsing proxy through https works just fine. My problem is when I try http urls.\r\nIn that moment I get the `twisted.web.error.SchemeNotSupported: Unsupported scheme: b''` error\r\n\r\nAs I see, most of the people have this issue the other way around.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Scrape a http link with proxy\r\n\r\n**Expected behavior:** Get a 200 with the desired data.\r\n\r\n**Actual behavior:**\r\n```\r\nERROR: Error downloading <GET http://*********>\r\nTraceback (most recent call last):\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\r\n    result = result.throwExceptionIntoGenerator(g)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\r\n    return g.throw(self.type, self.value, self.tb)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 42, in process_request\r\n    defer.returnValue((yield download_func(request=request, spider=spider)))\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/utils/defer.py\", line 55, in mustbe_deferred\r\n    result = f(*args, **kw)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 76, in download_request\r\n    return handler.download_request(request, spider)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 82, in download_request\r\n    return agent.download_request(request)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 361, in download_request\r\n    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 262, in request\r\n    endpoint=self._getEndpoint(self._proxyURI),\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/twisted/web/client.py\", line 1729, in _getEndpoint\r\n    return self._endpointFactory.endpointForURI(uri)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/twisted/web/client.py\", line 1607, in endpointForURI\r\n    raise SchemeNotSupported(\"Unsupported scheme: %r\" % (uri.scheme,))\r\ntwisted.web.error.SchemeNotSupported: Unsupported scheme: b''\r\n```\r\n\r\n**Reproduces how often:** Every time I scrape with proxy\r\n\r\n### Versions\r\n```\r\nScrapy       : 2.0.1\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 20.3.0\r\nPython       : 3.7.3 (default, Apr  3 2019, 05:39:12) - [GCC 8.3.0]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1c  28 May 2019)\r\ncryptography : 2.7\r\nPlatform     : Linux-4.19.0-5-amd64-x86_64-with-debian-10.0\r\n```\r\n### Additional context\r\n\r\nI tried to add some breakpoints at the end to see where it cracks.\r\nI added the following lines in \"twisted/web/client/py\", before the cracking point:\r\n```python\r\n        endpoint = HostnameEndpoint(self._reactor, host, uri.port, **kwargs)\r\n        import logging\r\n        logger = logging.getLogger(__name__)\r\n        logger.error(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\r\n        logger.error(uri)\r\n        logger.error(uri.host)\r\n        logger.error(uri.port)\r\n        logger.error(uri.scheme)\r\n        logger.error(dir(uri))\r\n        if uri.scheme == b'http':\r\n            return endpoint\r\n        elif uri.scheme == b'https':\r\n            connectionCreator = self._policyForHTTPS.creatorForNetloc(uri.host,\r\n                                                                      uri.port)\r\n            return wrapClientTLS(connectionCreator, endpoint)\r\n        else:\r\n            raise SchemeNotSupported(\"Unsupported scheme: %r\" % (uri.scheme,))\r\n```\r\n\r\nApparently in this point there is no schema. If I run the same code with a https url, this code is never reached. It seems that getting up to point there is bad and the proxy is not used\r\n\r\n(edited to apply formatting)\r\n",
  "issue_comments": [
    {
      "id": 615302971,
      "user": "Gallaecio",
      "body": "Could you share a code snippet to reproduce this issue?"
    },
    {
      "id": 615307523,
      "user": "teodoroanca",
      "body": "```\r\n    def make_request(self, url, callback, meta={}, method='GET'):\r\n        proxy_address = getattr(settings, \"PROXY_ADDRESS\")\r\n\r\n        meta.update({\r\n            'proxy': proxy_address,\r\n            'dont_redirect': self.dont_redirect,\r\n        })\r\n        yield Request(\r\n            url,\r\n            meta=meta,\r\n            method=method,\r\n            callback=callback,\r\n            errback=self.handle_error,\r\n            dont_filter=self.dont_filter\r\n        )\r\n```"
    },
    {
      "id": 615317868,
      "user": "Gallaecio",
      "body": "Does your `Request.url` and `PROXY_ADDRESS` both have a URL schema?"
    },
    {
      "id": 616365268,
      "user": "teodoroanca",
      "body": "Apparently, this was the issue. My `PROXY_ADDRESS` did not have a URL schema.\r\nThanks for the help!\r\n\r\nWhat I want to mention is that this behavior can be confusing. I will describe 4 cases:\r\n\r\n 1. `PROXY_ADDRESS`  without URL schema:  `test-proxy.com:3333`\r\n\r\n- if Request.url is https it works just fine\r\n- if Request.url is http it results in `twisted.web.error.SchemeNotSupported: Unsupported scheme: b''`\r\n\r\n2. `PROXY_ADDRESS`  with URL schema:  `http://second-test-proxy.com:5555`\r\n- Both http and https work fine\r\n\r\nIn my case, the solution was to add the 'http' in front of my `PROXY_ADDRESS`. I was confused by the fact that it still was working in case `Request.URL` was 'https' case even without URL schema for the `PROXY_ADDRESS`. I don't know if it is a bug or not."
    },
    {
      "id": 618366544,
      "user": "Gallaecio",
      "body": "I guess we can take this as an enhancement to support schema-less HTTP proxy URLs.\r\n\r\nI checked, and there is no bug, the logic to handle HTTP and HTTPS proxies is different, and the HTTPS one is implemented in a way that the schema is not needed in the proxy URL.\r\n\r\nAs a reference for people wishing to work on this, it should be as simple as modifying `ScrapyProxyAgent.request` so that the URL parameter passed to `self._getEndpoint` is ensured to have `http://` as schema. Parsing the URL, setting the schema and then unparsing should do the job (https://docs.python.org/3/library/urllib.parse.html)."
    },
    {
      "id": 618853664,
      "user": "liveprasad",
      "body": "@Gallaecio  I would like to contribute , I will start this as my first open source contribution\r\nBut I may need some help from you "
    },
    {
      "id": 622124348,
      "user": "willbeaufoy",
      "body": "@liveprasad are you still working on this? If not I can take it."
    },
    {
      "id": 624323777,
      "user": "HausCloud",
      "body": "Hi, I'm pretty new to open source. I have something that is working, but I'm having trouble implementing a test case as required from the contributing docs. "
    },
    {
      "id": 624348168,
      "user": "Gallaecio",
      "body": "@HausCloud Create a pull request with the current state of your changes. Maybe we can help you with the rest."
    },
    {
      "id": 624399320,
      "user": "HausCloud",
      "body": "@Gallaecio Will do! Thanks.\r\n\r\nUPDATE: Done! If any adjustments are needed, I can fix it! I'd probably need a hint towards the right direction for testing however."
    },
    {
      "id": 649177659,
      "user": "ajaymittur",
      "body": "Noticed the pull request was closed accidentally and the branch @HausCloud was working on seems to have been deleted, Is the issue open to work on or is there someone on it already? @Gallaecio "
    }
  ],
  "text_context": "# Using proxy through http fails (https works)\n\n### Description\r\n\r\nWhen I scrape without proxy, both https and http urls work.\r\nUsing proxy through https works just fine. My problem is when I try http urls.\r\nIn that moment I get the `twisted.web.error.SchemeNotSupported: Unsupported scheme: b''` error\r\n\r\nAs I see, most of the people have this issue the other way around.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Scrape a http link with proxy\r\n\r\n**Expected behavior:** Get a 200 with the desired data.\r\n\r\n**Actual behavior:**\r\n```\r\nERROR: Error downloading <GET http://*********>\r\nTraceback (most recent call last):\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\r\n    result = result.throwExceptionIntoGenerator(g)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\r\n    return g.throw(self.type, self.value, self.tb)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 42, in process_request\r\n    defer.returnValue((yield download_func(request=request, spider=spider)))\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/utils/defer.py\", line 55, in mustbe_deferred\r\n    result = f(*args, **kw)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 76, in download_request\r\n    return handler.download_request(request, spider)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 82, in download_request\r\n    return agent.download_request(request)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 361, in download_request\r\n    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 262, in request\r\n    endpoint=self._getEndpoint(self._proxyURI),\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/twisted/web/client.py\", line 1729, in _getEndpoint\r\n    return self._endpointFactory.endpointForURI(uri)\r\n  File \"/srv/scraper/venv/lib/python3.7/site-packages/twisted/web/client.py\", line 1607, in endpointForURI\r\n    raise SchemeNotSupported(\"Unsupported scheme: %r\" % (uri.scheme,))\r\ntwisted.web.error.SchemeNotSupported: Unsupported scheme: b''\r\n```\r\n\r\n**Reproduces how often:** Every time I scrape with proxy\r\n\r\n### Versions\r\n```\r\nScrapy       : 2.0.1\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 20.3.0\r\nPython       : 3.7.3 (default, Apr  3 2019, 05:39:12) - [GCC 8.3.0]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1c  28 May 2019)\r\ncryptography : 2.7\r\nPlatform     : Linux-4.19.0-5-amd64-x86_64-with-debian-10.0\r\n```\r\n### Additional context\r\n\r\nI tried to add some breakpoints at the end to see where it cracks.\r\nI added the following lines in \"twisted/web/client/py\", before the cracking point:\r\n```python\r\n        endpoint = HostnameEndpoint(self._reactor, host, uri.port, **kwargs)\r\n        import logging\r\n        logger = logging.getLogger(__name__)\r\n        logger.error(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\r\n        logger.error(uri)\r\n        logger.error(uri.host)\r\n        logger.error(uri.port)\r\n        logger.error(uri.scheme)\r\n        logger.error(dir(uri))\r\n        if uri.scheme == b'http':\r\n            return endpoint\r\n        elif uri.scheme == b'https':\r\n            connectionCreator = self._policyForHTTPS.creatorForNetloc(uri.host,\r\n                                                                      uri.port)\r\n            return wrapClientTLS(connectionCreator, endpoint)\r\n        else:\r\n            raise SchemeNotSupported(\"Unsupported scheme: %r\" % (uri.scheme,))\r\n```\r\n\r\nApparently in this point there is no schema. If I run the same code with a https url, this code is never reached. It seems that getting up to point there is bad and the proxy is not used\r\n\r\n(edited to apply formatting)\r\n\n\nCould you share a code snippet to reproduce this issue?\n\n```\r\n    def make_request(self, url, callback, meta={}, method='GET'):\r\n        proxy_address = getattr(settings, \"PROXY_ADDRESS\")\r\n\r\n        meta.update({\r\n            'proxy': proxy_address,\r\n            'dont_redirect': self.dont_redirect,\r\n        })\r\n        yield Request(\r\n            url,\r\n            meta=meta,\r\n            method=method,\r\n            callback=callback,\r\n            errback=self.handle_error,\r\n            dont_filter=self.dont_filter\r\n        )\r\n```\n\nDoes your `Request.url` and `PROXY_ADDRESS` both have a URL schema?\n\nApparently, this was the issue. My `PROXY_ADDRESS` did not have a URL schema.\r\nThanks for the help!\r\n\r\nWhat I want to mention is that this behavior can be confusing. I will describe 4 cases:\r\n\r\n 1. `PROXY_ADDRESS`  without URL schema:  `test-proxy.com:3333`\r\n\r\n- if Request.url is https it works just fine\r\n- if Request.url is http it results in `twisted.web.error.SchemeNotSupported: Unsupported scheme: b''`\r\n\r\n2. `PROXY_ADDRESS`  with URL schema:  `http://second-test-proxy.com:5555`\r\n- Both http and https work fine\r\n\r\nIn my case, the solution was to add the 'http' in front of my `PROXY_ADDRESS`. I was confused by the fact that it still was working in case `Request.URL` was 'https' case even without URL schema for the `PROXY_ADDRESS`. I don't know if it is a bug or not.\n\nI guess we can take this as an enhancement to support schema-less HTTP proxy URLs.\r\n\r\nI checked, and there is no bug, the logic to handle HTTP and HTTPS proxies is different, and the HTTPS one is implemented in a way that the schema is not needed in the proxy URL.\r\n\r\nAs a reference for people wishing to work on this, it should be as simple as modifying `ScrapyProxyAgent.request` so that the URL parameter passed to `self._getEndpoint` is ensured to have `http://` as schema. Parsing the URL, setting the schema and then unparsing should do the job (https://docs.python.org/3/library/urllib.parse.html).\n\n@Gallaecio  I would like to contribute , I will start this as my first open source contribution\r\nBut I may need some help from you \n\n@liveprasad are you still working on this? If not I can take it.\n\nHi, I'm pretty new to open source. I have something that is working, but I'm having trouble implementing a test case as required from the contributing docs. \n\n@HausCloud Create a pull request with the current state of your changes. Maybe we can help you with the rest.\n\n@Gallaecio Will do! Thanks.\r\n\r\nUPDATE: Done! If any adjustments are needed, I can fix it! I'd probably need a hint towards the right direction for testing however.\n\nNoticed the pull request was closed accidentally and the branch @HausCloud was working on seems to have been deleted, Is the issue open to work on or is there someone on it already? @Gallaecio ",
  "pr_link": "https://github.com/scrapy/scrapy/pull/4536",
  "code_context": [],
  "questions": [
    "Could you share a code snippet to reproduce this issue?",
    "Does your `Request.url` and `PROXY_ADDRESS` both have a URL schema?"
  ],
  "golden_answers": [
    "```\r\n    def make_request(self, url, callback, meta={}, method='GET'):\r\n        proxy_address = getattr(settings, \"PROXY_ADDRESS\")\r\n\r\n        meta.update({\r\n            'proxy': proxy_address,\r\n            'dont_redirect': self.dont_redirect,\r\n        })\r\n        yield Request(\r\n            url,\r\n            meta=meta,\r\n            method=method,\r\n            callback=callback,\r\n            errback=self.handle_error,\r\n            dont_filter=self.dont_filter\r\n        )\r\n```",
    "Apparently, this was the issue. My `PROXY_ADDRESS` did not have a URL schema.\r\nThanks for the help!\r\n\r\nWhat I want to mention is that this behavior can be confusing. I will describe 4 cases:\r\n\r\n 1. `PROXY_ADDRESS`  without URL schema:  `test-proxy.com:3333`\r\n\r\n- if Request.url is https it works just fine\r\n- if Request.url is http it results in `twisted.web.error.SchemeNotSupported: Unsupported scheme: b''`\r\n\r\n2. `PROXY_ADDRESS`  with URL schema:  `http://second-test-proxy.com:5555`\r\n- Both http and https work fine\r\n\r\nIn my case, the solution was to add the 'http' in front of my `PROXY_ADDRESS`. I was confused by the fact that it still was working in case `Request.URL` was 'https' case even without URL schema for the `PROXY_ADDRESS`. I don't know if it is a bug or not."
  ],
  "questions_generated": [
    "What is the primary issue encountered when using an HTTP proxy with the Scrapy framework in this context?",
    "Which specific part of the Scrapy framework's code is responsible for handling the download requests that could lead to the 'Unsupported scheme' error?",
    "How does the issue described differ from common problems users encounter with proxy configurations in Scrapy?",
    "What debugging steps did the user implement to identify the point of failure in the Twisted framework?",
    "Based on the provided versions, which dependencies are likely involved in resolving the 'Unsupported scheme' error, and why?"
  ],
  "golden_answers_generated": [
    "The primary issue is that using an HTTP proxy causes the error `twisted.web.error.SchemeNotSupported: Unsupported scheme: b''` when attempting to scrape HTTP URLs. This error suggests that the scheme is not being recognized or passed correctly to the Twisted framework.",
    "The error occurs in `scrapy/core/downloader/handlers/http11.py` within the `download_request` method. This method uses the Twisted library to handle HTTP requests, and the error arises when the request method calls `agent.request` without a properly defined scheme in the URI.",
    "Most users typically encounter issues with HTTPS proxies not working, while in this case, the problem is specifically with HTTP proxies. The HTTPS proxies work as expected, but HTTP requests fail due to the unsupported scheme error.",
    "The user added logging statements in the `twisted/web/client.py` file before the error occurs to inspect the URI attributes like `uri.host`, `uri.port`, and `uri.scheme`. This helped them understand that the scheme is missing when the error is raised.",
    "The dependencies involved include Scrapy 2.0.1 and Twisted 20.3.0. Scrapy uses Twisted for handling network operations, and the error originates from Twisted's client handling code. Ensuring compatibility and correct configuration between these two libraries is crucial for resolving the error."
  ]
}