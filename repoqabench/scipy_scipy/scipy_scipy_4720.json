{
  "repo_name": "scipy_scipy",
  "issue_id": "4720",
  "issue_description": "# Cannot generate random variates from noncentral chi-square distribution with dof less than 1\n\nI'm using scipy 0.15.1\n\nThe random variate generation function of the noncentral chi-square distribution yields error when the parameter _degree of freedom_ (dof)  is less than or equal to 1. For example, \n\n``` python\nimport scipy.stats as stats\ndf = 1.0\nnc = 4\nstats.ncx2.rvs(df, nc)\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-55-6be68a9d384a> in <module>()\n----> 1 stats.ncx2.rvs(1.0, nc, loc=0, scale=1, size=1)\n\n/Users/zhangxiaowei/anaconda/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.pyc in rvs(self, *args, **kwds)\n    833             return loc*ones(size, 'd')\n    834 \n--> 835         vals = self._rvs(*args)\n    836         if self._size is not None:\n    837             vals = reshape(vals, size)\n\n/Users/zhangxiaowei/anaconda/lib/python2.7/site-packages/scipy/stats/_continuous_distns.pyc in _rvs(self, df, nc)\n   2931     \"\"\"\n   2932     def _rvs(self, df, nc):\n-> 2933         return mtrand.noncentral_chisquare(df, nc, self._size)\n   2934 \n   2935     def _logpdf(self, x, df, nc):\n\nmtrand.pyx in mtrand.RandomState.noncentral_chisquare (numpy/random/mtrand/mtrand.c:15618)()\n\nValueError: df <= 0\n```\n\nA common implementation of the noncentral chi-square random variate generation differs depending on whether the dof is greater than 1 or not. In particular, suppose we want to generate a noncentral chi-square with dof _d_ and noncentrality parameter _v_. \n1. If _d_ is greater than 1, then it can be generated by \n\n``` python\nimport numpy as np\nnp.random.chisquare(d-1) + (np.random.standard_normal()+np.sqrt(v))**2\n```\n1. Otherwise, it can be generated by \n\n``` python\nimport numpy as np\nnp.random.chisquare(d + 2*np.random.poisson(v/2.0))\n```\n\nI suspect that scipy only implements the first case and ignores the other. \n",
  "issue_comments": [
    {
      "id": 92254657,
      "user": "xiaoweiz",
      "body": "Just found out that scipy uses the implmentation in numpy, which has documented [here](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.noncentral_chisquare.html#numpy.random.noncentral_chisquare) that it only considers the case where degree of freedom greater than 1. \n"
    },
    {
      "id": 92462462,
      "user": "rgommers",
      "body": "The numpy docstring says `>=1`, so `df=1` shouldn't give an error. Plus `ValueError: df <= 0` is a weird error. Can you open a numpy issue for that?\n"
    },
    {
      "id": 92472940,
      "user": "rgommers",
      "body": "At the end of your message you suggest a possible improvement for `stats.ncx2.rvs`. Needs deciding on, do we want to do this in `stats.ncx2` or should we only consider it if `np.random.noncentral_chisquare` gets this enhancement?\n"
    },
    {
      "id": 92517343,
      "user": "xiaoweiz",
      "body": "The fact that `df=1` raises error may be because the algorithm implemented is the one I suggested above: in this case, it needs to generate a chi-square random variate with `df=0`, which is not well defined in mathematics\n"
    },
    {
      "id": 93773668,
      "user": "ev-br",
      "body": "I guess the best course of action is to add it to numpy.random and then bundle the compatibity fix  to scipy.stats.ncx2 until it can use the numpy version where it's implemented. \n"
    },
    {
      "id": 97174250,
      "user": "ev-br",
      "body": "https://github.com/numpy/numpy/pull/5800 merged for numpy 1.10; I don't see a reason to not add it to `stats.ncx2`. @xiaoweiz @behzadnouri \n"
    },
    {
      "id": 97253146,
      "user": "xiaoweiz",
      "body": "Agree. It should also be an easy fix in `scipy`. \n"
    },
    {
      "id": 128498021,
      "user": "ev-br",
      "body": "Am adding an easy-fix label then.\n"
    },
    {
      "id": 168374477,
      "user": "maniteja123",
      "body": "Hi, I just saw this issue. It seems that the code doesn't break for df>0 now and the PR is merged for numpy 1.10. Should the scipy code be changed now or is it just a documentation issue for scipy now since it automatically calls `np.random.noncentral_chisquare` which handles the issue.\n"
    },
    {
      "id": 168376235,
      "user": "xiaoweiz",
      "body": "agree. This can be closed now. \n"
    },
    {
      "id": 168376312,
      "user": "maniteja123",
      "body": "Thanks for clarifying :)\n"
    }
  ],
  "text_context": "# Cannot generate random variates from noncentral chi-square distribution with dof less than 1\n\nI'm using scipy 0.15.1\n\nThe random variate generation function of the noncentral chi-square distribution yields error when the parameter _degree of freedom_ (dof)  is less than or equal to 1. For example, \n\n``` python\nimport scipy.stats as stats\ndf = 1.0\nnc = 4\nstats.ncx2.rvs(df, nc)\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-55-6be68a9d384a> in <module>()\n----> 1 stats.ncx2.rvs(1.0, nc, loc=0, scale=1, size=1)\n\n/Users/zhangxiaowei/anaconda/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.pyc in rvs(self, *args, **kwds)\n    833             return loc*ones(size, 'd')\n    834 \n--> 835         vals = self._rvs(*args)\n    836         if self._size is not None:\n    837             vals = reshape(vals, size)\n\n/Users/zhangxiaowei/anaconda/lib/python2.7/site-packages/scipy/stats/_continuous_distns.pyc in _rvs(self, df, nc)\n   2931     \"\"\"\n   2932     def _rvs(self, df, nc):\n-> 2933         return mtrand.noncentral_chisquare(df, nc, self._size)\n   2934 \n   2935     def _logpdf(self, x, df, nc):\n\nmtrand.pyx in mtrand.RandomState.noncentral_chisquare (numpy/random/mtrand/mtrand.c:15618)()\n\nValueError: df <= 0\n```\n\nA common implementation of the noncentral chi-square random variate generation differs depending on whether the dof is greater than 1 or not. In particular, suppose we want to generate a noncentral chi-square with dof _d_ and noncentrality parameter _v_. \n1. If _d_ is greater than 1, then it can be generated by \n\n``` python\nimport numpy as np\nnp.random.chisquare(d-1) + (np.random.standard_normal()+np.sqrt(v))**2\n```\n1. Otherwise, it can be generated by \n\n``` python\nimport numpy as np\nnp.random.chisquare(d + 2*np.random.poisson(v/2.0))\n```\n\nI suspect that scipy only implements the first case and ignores the other. \n\n\nJust found out that scipy uses the implmentation in numpy, which has documented [here](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.noncentral_chisquare.html#numpy.random.noncentral_chisquare) that it only considers the case where degree of freedom greater than 1. \n\n\nThe numpy docstring says `>=1`, so `df=1` shouldn't give an error. Plus `ValueError: df <= 0` is a weird error. Can you open a numpy issue for that?\n\n\nAt the end of your message you suggest a possible improvement for `stats.ncx2.rvs`. Needs deciding on, do we want to do this in `stats.ncx2` or should we only consider it if `np.random.noncentral_chisquare` gets this enhancement?\n\n\nThe fact that `df=1` raises error may be because the algorithm implemented is the one I suggested above: in this case, it needs to generate a chi-square random variate with `df=0`, which is not well defined in mathematics\n\n\nI guess the best course of action is to add it to numpy.random and then bundle the compatibity fix  to scipy.stats.ncx2 until it can use the numpy version where it's implemented. \n\n\nhttps://github.com/numpy/numpy/pull/5800 merged for numpy 1.10; I don't see a reason to not add it to `stats.ncx2`. @xiaoweiz @behzadnouri \n\n\nAgree. It should also be an easy fix in `scipy`. \n\n\nAm adding an easy-fix label then.\n\n\nHi, I just saw this issue. It seems that the code doesn't break for df>0 now and the PR is merged for numpy 1.10. Should the scipy code be changed now or is it just a documentation issue for scipy now since it automatically calls `np.random.noncentral_chisquare` which handles the issue.\n\n\nagree. This can be closed now. \n\n\nThanks for clarifying :)\n",
  "pr_link": "https://github.com/numpy/numpy/pull/5800",
  "code_context": [
    {
      "filename": "numpy/random/mtrand/distributions.c",
      "content": "/* Copyright 2005 Robert Kern (robert.kern@gmail.com)\n *\n * Permission is hereby granted, free of charge, to any person obtaining a\n * copy of this software and associated documentation files (the\n * \"Software\"), to deal in the Software without restriction, including\n * without limitation the rights to use, copy, modify, merge, publish,\n * distribute, sublicense, and/or sell copies of the Software, and to\n * permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice shall be included\n * in all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n */\n\n/* The implementations of rk_hypergeometric_hyp(), rk_hypergeometric_hrua(),\n * and rk_triangular() were adapted from Ivan Frohne's rv.py which has this\n * license:\n *\n *            Copyright 1998 by Ivan Frohne; Wasilla, Alaska, U.S.A.\n *                            All Rights Reserved\n *\n * Permission to use, copy, modify and distribute this software and its\n * documentation for any purpose, free of charge, is granted subject to the\n * following conditions:\n *   The above copyright notice and this permission notice shall be included in\n *   all copies or substantial portions of the software.\n *\n *   THE SOFTWARE AND DOCUMENTATION IS PROVIDED WITHOUT WARRANTY OF ANY KIND,\n *   EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO MERCHANTABILITY, FITNESS\n *   FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE AUTHOR\n *   OR COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM OR DAMAGES IN A CONTRACT\n *   ACTION, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n *   SOFTWARE OR ITS DOCUMENTATION.\n */\n\n#include <math.h>\n#include <stdlib.h>\n#include \"distributions.h\"\n#include <stdio.h>\n\n#ifndef min\n#define min(x,y) ((x<y)?x:y)\n#define max(x,y) ((x>y)?x:y)\n#endif\n\n#ifndef M_PI\n#define M_PI 3.14159265358979323846264338328\n#endif\n\n/*\n * log-gamma function to support some of these distributions. The\n * algorithm comes from SPECFUN by Shanjie Zhang and Jianming Jin and their\n * book \"Computation of Special Functions\", 1996, John Wiley & Sons, Inc.\n */\nstatic double loggam(double x)\n{\n    double x0, x2, xp, gl, gl0;\n    long k, n;\n\n    static double a[10] = {8.333333333333333e-02,-2.777777777777778e-03,\n         7.936507936507937e-04,-5.952380952380952e-04,\n         8.417508417508418e-04,-1.917526917526918e-03,\n         6.410256410256410e-03,-2.955065359477124e-02,\n         1.796443723688307e-01,-1.39243221690590e+00};\n    x0 = x;\n    n = 0;\n    if ((x == 1.0) || (x == 2.0))\n    {\n        return 0.0;\n    }\n    else if (x <= 7.0)\n    {\n        n = (long)(7 - x);\n        x0 = x + n;\n    }\n    x2 = 1.0/(x0*x0);\n    xp = 2*M_PI;\n    gl0 = a[9];\n    for (k=8; k>=0; k--)\n    {\n        gl0 *= x2;\n        gl0 += a[k];\n    }\n    gl = gl0/x0 + 0.5*log(xp) + (x0-0.5)*log(x0) - x0;\n    if (x <= 7.0)\n    {\n        for (k=1; k<=n; k++)\n        {\n            gl -= log(x0-1.0);\n            x0 -= 1.0;\n        }\n    }\n    return gl;\n}\n\ndouble rk_normal(rk_state *state, double loc, double scale)\n{\n    return loc + scale*rk_gauss(state);\n}\n\ndouble rk_standard_exponential(rk_state *state)\n{\n    /* We use -log(1-U) since U is [0, 1) */\n    return -log(1.0 - rk_double(state));\n}\n\ndouble rk_exponential(rk_state *state, double scale)\n{\n    return scale * rk_standard_exponential(state);\n}\n\ndouble rk_uniform(rk_state *state, double loc, double scale)\n{\n    return loc + scale*rk_double(state);\n}\n\ndouble rk_standard_gamma(rk_state *state, double shape)\n{\n    double b, c;\n    double U, V, X, Y;\n\n    if (shape == 1.0)\n    {\n        return rk_standard_exponential(state);\n    }\n    else if (shape < 1.0)\n    {\n        for (;;)\n        {\n            U = rk_double(state);\n            V = rk_standard_exponential(state);\n            if (U <= 1.0 - shape)\n            {\n                X = pow(U, 1./shape);\n                if (X <= V)\n                {\n                    return X;\n                }\n            }\n            else\n            {\n                Y = -log((1-U)/shape);\n                X = pow(1.0 - shape + shape*Y, 1./shape);\n                if (X <= (V + Y))\n                {\n                    return X;\n                }\n            }\n        }\n    }\n    else\n    {\n        b = shape - 1./3.;\n        c = 1./sqrt(9*b);\n        for (;;)\n        {\n            do\n            {\n                X = rk_gauss(state);\n                V = 1.0 + c*X;\n            } while (V <= 0.0);\n\n            V = V*V*V;\n            U = rk_double(state);\n            if (U < 1.0 - 0.0331*(X*X)*(X*X)) return (b*V);\n            if (log(U) < 0.5*X*X + b*(1. - V + log(V))) return (b*V);\n        }\n    }\n}\n\ndouble rk_gamma(rk_state *state, double shape, double scale)\n{\n    return scale * rk_standard_gamma(state, shape);\n}\n\ndouble rk_beta(rk_state *state, double a, double b)\n{\n    double Ga, Gb;\n\n    if ((a <= 1.0) && (b <= 1.0))\n    {\n        double U, V, X, Y;\n        /* Use Jonk's algorithm */\n\n        while (1)\n        {\n            U = rk_double(state);\n            V = rk_double(state);\n            X = pow(U, 1.0/a);\n            Y = pow(V, 1.0/b);\n\n            if ((X + Y) <= 1.0)\n            {\n                return X / (X + Y);\n            }\n        }\n    }\n    else\n    {\n        Ga = rk_standard_gamma(state, a);\n        Gb = rk_standard_gamma(state, b);\n        return Ga/(Ga + Gb);\n    }\n}\n\ndouble rk_chisquare(rk_state *state, double df)\n{\n    return 2.0*rk_standard_gamma(state, df/2.0);\n}\n\ndouble rk_noncentral_chisquare(rk_state *state, double df, double nonc)\n{\n    if(1 < df)\n    {\n        const double Chi2 = rk_chisquare(state, df - 1);\n        const double N = rk_gauss(state) + sqrt(nonc);\n        return Chi2 + N*N;\n    }\n    else\n    {\n        const long i = rk_poisson(state, nonc / 2.0);\n        return rk_chisquare(state, df + 2 * i);\n    }\n}\n\ndouble rk_f(rk_state *state, double dfnum, double dfden)\n{\n    return ((rk_chisquare(state, dfnum) * dfden) /\n            (rk_chisquare(state, dfden) * dfnum));\n}\n\ndouble rk_noncentral_f(rk_state *state, double dfnum, double dfden, double nonc)\n{\n    double t = rk_noncentral_chisquare(state, dfnum, nonc) * dfden;\n    return t / (rk_chisquare(state, dfden) * dfnum);\n}\n\nlong rk_binomial_btpe(rk_state *state, long n, double p)\n{\n    double r,q,fm,p1,xm,xl,xr,c,laml,lamr,p2,p3,p4;\n    double a,u,v,s,F,rho,t,A,nrq,x1,x2,f1,f2,z,z2,w,w2,x;\n    long m,y,k,i;\n\n    if (!(state->has_binomial) ||\n         (state->nsave != n) ||\n         (state->psave != p))\n    {\n        /* initialize */\n        state->nsave = n;\n        state->psave = p;\n        state->has_binomial = 1;\n        state->r = r = min(p, 1.0-p);\n        state->q = q = 1.0 - r;\n        state->fm = fm = n*r+r;\n        state->m = m = (long)floor(state->fm);\n        state->p1 = p1 = floor(2.195*sqrt(n*r*q)-4.6*q) + 0.5;\n        state->xm = xm = m + 0.5;\n        state->xl = xl = xm - p1;\n        state->xr = xr = xm + p1;\n        state->c = c = 0.134 + 20.5/(15.3 + m);\n        a = (fm - xl)/(fm-xl*r);\n        state->laml = laml = a*(1.0 + a/2.0);\n        a = (xr - fm)/(xr*q);\n        state->lamr = lamr = a*(1.0 + a/2.0);\n        state->p2 = p2 = p1*(1.0 + 2.0*c);\n        state->p3 = p3 = p2 + c/laml;\n        state->p4 = p4 = p3 + c/lamr;\n    }\n    else\n    {\n        r = state->r;\n        q = state->q;\n        fm = state->fm;\n        m = state->m;\n        p1 = state->p1;\n        xm = state->xm;\n        xl = state->xl;\n        xr = state->xr;\n        c = state->c;\n        laml = state->laml;\n        lamr = state->lamr;\n        p2 = state->p2;\n        p3 = state->p3;\n        p4 = state->p4;\n    }\n\n  /* sigh ... */\n  Step10:\n    nrq = n*r*q;\n    u = rk_double(state)*p4;\n    v = rk_double(state);\n    if (u > p1) goto Step20;\n    y = (long)floor(xm - p1*v + u);\n    goto Step60;\n\n  Step20:\n    if (u > p2) goto Step30;\n    x = xl + (u - p1)/c;\n    v = v*c + 1.0 - fabs(m - x + 0.5)/p1;\n    if (v > 1.0) goto Step10;\n    y = (long)floor(x);\n    goto Step50;\n\n  Step30:\n    if (u > p3) goto Step40;\n    y = (long)floor(xl + log(v)/laml);\n    if (y < 0) goto Step10;\n    v = v*(u-p2)*laml;\n    goto Step50;\n\n  Step40:\n    y = (long)floor(xr - log(v)/lamr);\n    if (y > n) goto Step10;\n    v = v*(u-p3)*lamr;\n\n  Step50:\n    k = labs(y - m);\n    if ((k > 20) && (k < ((nrq)/2.0 - 1))) goto Step52;\n\n    s = r/q;\n    a = s*(n+1);\n    F = 1.0;\n    if (m < y)\n    {\n        for (i=m+1; i<=y; i++)\n        {\n            F *= (a/i - s);\n        }\n    }\n    else if (m > y)\n    {\n        for (i=y+1; i<=m; i++)\n        {\n            F /= (a/i - s);\n        }\n    }\n    if (v > F) goto Step10;\n    goto Step60;\n\n    Step52:\n    rho = (k/(nrq))*((k*(k/3.0 + 0.625) + 0.16666666666666666)/nrq + 0.5);\n    t = -k*k/(2*nrq);\n    A = log(v);\n    if (A < (t - rho)) goto Step60;\n    if (A > (t + rho)) goto Step10;\n\n    x1 = y+1;\n    f1 = m+1;\n    z = n+1-m;\n    w = n-y+1;\n    x2 = x1*x1;\n    f2 = f1*f1;\n    z2 = z*z;\n    w2 = w*w;\n    if (A > (xm*log(f1/x1)\n           + (n-m+0.5)*log(z/w)\n           + (y-m)*log(w*r/(x1*q))\n           + (13680.-(462.-(132.-(99.-140./f2)/f2)/f2)/f2)/f1/166320.\n           + (13680.-(462.-(132.-(99.-140./z2)/z2)/z2)/z2)/z/166320.\n           + (13680.-(462.-(132.-(99.-140./x2)/x2)/x2)/x2)/x1/166320.\n           + (13680.-(462.-(132.-(99.-140./w2)/w2)/w2)/w2)/w/166320.))\n    {\n        goto Step10;\n    }\n\n  Step60:\n    if (p > 0.5)\n    {\n        y = n - y;\n    }\n\n    return y;\n}\n\nlong rk_binomial_inversion(rk_state *state, long n, double p)\n{\n    double q, qn, np, px, U;\n    long X, bound;\n\n    if (!(state->has_binomial) ||\n         (state->nsave != n) ||\n         (state->psave != p))\n    {\n        state->nsave = n;\n        state->psave = p;\n        state->has_binomial = 1;\n        state->q = q = 1.0 - p;\n        state->r = qn = exp(n * log(q));\n        state->c = np = n*p;\n        state->m = bound = min(n, np + 10.0*sqrt(np*q + 1));\n    } else\n    {\n        q = state->q;\n        qn = state->r;\n        np = state->c;\n        bound = state->m;\n    }\n    X = 0;\n    px = qn;\n    U = rk_double(state);\n    while (U > px)\n    {\n        X++;\n        if (X > bound)\n        {\n            X = 0;\n            px = qn;\n            U = rk_double(state);\n        } else\n        {\n            U -= px;\n            px  = ((n-X+1) * p * px)/(X*q);\n        }\n    }\n    return X;\n}\n\nlong rk_binomial(rk_state *state, long n, double p)\n{\n    double q;\n\n    if (p <= 0.5)\n    {\n        if (p*n <= 30.0)\n        {\n            return rk_binomial_inversion(state, n, p);\n        }\n        else\n        {\n            return rk_binomial_btpe(state, n, p);\n        }\n    }\n    else\n    {\n        q = 1.0-p;\n        if (q*n <= 30.0)\n        {\n            return n - rk_binomial_inversion(state, n, q);\n        }\n        else\n        {\n            return n - rk_binomial_btpe(state, n, q);\n        }\n    }\n\n}\n\nlong rk_negative_binomial(rk_state *state, double n, double p)\n{\n    double Y;\n\n    Y = rk_gamma(state, n, (1-p)/p);\n    return rk_poisson(state, Y);\n}\n\nlong rk_poisson_mult(rk_state *state, double lam)\n{\n    long X;\n    double prod, U, enlam;\n\n    enlam = exp(-lam);\n    X = 0;\n    prod = 1.0;\n    while (1)\n    {\n        U = rk_double(state);\n        prod *= U;\n        if (prod > enlam)\n        {\n            X += 1;\n        }\n        else\n        {\n            return X;\n        }\n    }\n}\n\n#define LS2PI 0.91893853320467267\n#define TWELFTH 0.083333333333333333333333\nlong rk_poisson_ptrs(rk_state *state, double lam)\n{\n    long k;\n    double U, V, slam, loglam, a, b, invalpha, vr, us;\n\n    slam = sqrt(lam);\n    loglam = log(lam);\n    b = 0.931 + 2.53*slam;\n    a = -0.059 + 0.02483*b;\n    invalpha = 1.1239 + 1.1328/(b-3.4);\n    vr = 0.9277 - 3.6224/(b-2);\n\n    while (1)\n    {\n        U = rk_double(state) - 0.5;\n        V = rk_double(state);\n        us = 0.5 - fabs(U);\n        k = (long)floor((2*a/us + b)*U + lam + 0.43);\n        if ((us >= 0.07) && (V <= vr))\n        {\n            return k;\n        }\n        if ((k < 0) ||\n            ((us < 0.013) && (V > us)))\n        {\n            continue;\n        }\n        if ((log(V) + log(invalpha) - log(a/(us*us)+b)) <=\n            (-lam + k*loglam - loggam(k+1)))\n        {\n            return k;\n        }\n\n\n    }\n\n}\n\nlong rk_poisson(rk_state *state, double lam)\n{\n    if (lam >= 10)\n    {\n        return rk_poisson_ptrs(state, lam);\n    }\n    else if (lam == 0)\n    {\n        return 0;\n    }\n    else\n    {\n        return rk_poisson_mult(state, lam);\n    }\n}\n\ndouble rk_standard_cauchy(rk_state *state)\n{\n    return rk_gauss(state) / rk_gauss(state);\n}\n\ndouble rk_standard_t(rk_state *state, double df)\n{\n    double N, G, X;\n\n    N = rk_gauss(state);\n    G = rk_standard_gamma(state, df/2);\n    X = sqrt(df/2)*N/sqrt(G);\n    return X;\n}\n\n/* Uses the rejection algorithm compared against the wrapped Cauchy\n   distribution suggested by Best and Fisher and documented in\n   Chapter 9 of Luc's Non-Uniform Random Variate Generation.\n   http://cg.scs.carleton.ca/~luc/rnbookindex.html\n   (but corrected to match the algorithm in R and Python)\n*/\ndouble rk_vonmises(rk_state *state, double mu, double kappa)\n{\n    double s;\n    double U, V, W, Y, Z;\n    double result, mod;\n    int neg;\n\n    if (kappa < 1e-8)\n    {\n        return M_PI * (2*rk_double(state)-1);\n    }\n    else\n    {\n        /* with double precision rho is zero until 1.4e-8 */\n        if (kappa < 1e-5) {\n            /*\n             * second order taylor expansion around kappa = 0\n             * precise until relatively large kappas as second order is 0\n             */\n            s = (1./kappa + kappa);\n        }\n        else {\n            double r = 1 + sqrt(1 + 4*kappa*kappa);\n            double rho = (r - sqrt(2*r)) / (2*kappa);\n            s = (1 + rho*rho)/(2*rho);\n        }\n\n        while (1)\n        {\n        U = rk_double(state);\n            Z = cos(M_PI*U);\n            W = (1 + s*Z)/(s + Z);\n            Y = kappa * (s - W);\n            V = rk_double(state);\n            if ((Y*(2-Y) - V >= 0) || (log(Y/V)+1 - Y >= 0))\n            {\n                break;\n            }\n        }\n\n        U = rk_double(state);\n\n        result = acos(W);\n        if (U < 0.5)\n        {\n        result = -result;\n        }\n        result += mu;\n        neg = (result < 0);\n        mod = fabs(result);\n        mod = (fmod(mod+M_PI, 2*M_PI)-M_PI);\n        if (neg)\n        {\n            mod *= -1;\n        }\n\n        return mod;\n    }\n}\n\ndouble rk_pareto(rk_state *state, double a)\n{\n    return exp(rk_standard_exponential(state)/a) - 1;\n}\n\ndouble rk_weibull(rk_state *state, double a)\n{\n    return pow(rk_standard_exponential(state), 1./a);\n}\n\ndouble rk_power(rk_state *state, double a)\n{\n    return pow(1 - exp(-rk_standard_exponential(state)), 1./a);\n}\n\ndouble rk_laplace(rk_state *state, double loc, double scale)\n{\n    double U;\n\n    U = rk_double(state);\n    if (U < 0.5)\n    {\n        U = loc + scale * log(U + U);\n    } else\n    {\n        U = loc - scale * log(2.0 - U - U);\n    }\n    return U;\n}\n\ndouble rk_gumbel(rk_state *state, double loc, double scale)\n{\n    double U;\n\n    U = 1.0 - rk_double(state);\n    return loc - scale * log(-log(U));\n}\n\ndouble rk_logistic(rk_state *state, double loc, double scale)\n{\n    double U;\n\n    U = rk_double(state);\n    return loc + scale * log(U/(1.0 - U));\n}\n\ndouble rk_lognormal(rk_state *state, double mean, double sigma)\n{\n    return exp(rk_normal(state, mean, sigma));\n}\n\ndouble rk_rayleigh(rk_state *state, double mode)\n{\n    return mode*sqrt(-2.0 * log(1.0 - rk_double(state)));\n}\n\ndouble rk_wald(rk_state *state, double mean, double scale)\n{\n    double U, X, Y;\n    double mu_2l;\n\n    mu_2l = mean / (2*scale);\n    Y = rk_gauss(state);\n    Y = mean*Y*Y;\n    X = mean + mu_2l*(Y - sqrt(4*scale*Y + Y*Y));\n    U = rk_double(state);\n    if (U <= mean/(mean+X))\n    {\n        return X;\n    } else\n    {\n        return mean*mean/X;\n    }\n}\n\nlong rk_zipf(rk_state *state, double a)\n{\n    double T, U, V;\n    long X;\n    double am1, b;\n\n    am1 = a - 1.0;\n    b = pow(2.0, am1);\n    do\n    {\n        U = 1.0-rk_double(state);\n        V = rk_double(state);\n        X = (long)floor(pow(U, -1.0/am1));\n        /* The real result may be above what can be represented in a signed\n         * long. It will get casted to -sys.maxint-1. Since this is\n         * a straightforward rejection algorithm, we can just reject this value\n         * in the rejection condition below. This function then models a Zipf\n         * distribution truncated to sys.maxint.\n         */\n        T = pow(1.0 + 1.0/X, am1);\n    } while (((V*X*(T-1.0)/(b-1.0)) > (T/b)) || X < 1);\n    return X;\n}\n\nlong rk_geometric_search(rk_state *state, double p)\n{\n    double U;\n    long X;\n    double sum, prod, q;\n\n    X = 1;\n    sum = prod = p;\n    q = 1.0 - p;\n    U = rk_double(state);\n    while (U > sum)\n    {\n        prod *= q;\n        sum += prod;\n        X++;\n    }\n    return X;\n}\n\nlong rk_geometric_inversion(rk_state *state, double p)\n{\n    return (long)ceil(log(1.0-rk_double(state))/log(1.0-p));\n}\n\nlong rk_geometric(rk_state *state, double p)\n{\n    if (p >= 0.333333333333333333333333)\n    {\n        return rk_geometric_search(state, p);\n    } else\n    {\n        return rk_geometric_inversion(state, p);\n    }\n}\n\nlong rk_hypergeometric_hyp(rk_state *state, long good, long bad, long sample)\n{\n    long d1, K, Z;\n    double d2, U, Y;\n\n    d1 = bad + good - sample;\n    d2 = (double)min(bad, good);\n\n    Y = d2;\n    K = sample;\n    while (Y > 0.0)\n    {\n        U = rk_double(state);\n        Y -= (long)floor(U + Y/(d1 + K));\n        K--;\n        if (K == 0) break;\n    }\n    Z = (long)(d2 - Y);\n    if (good > bad) Z = sample - Z;\n    return Z;\n}\n\n/* D1 = 2*sqrt(2/e) */\n/* D2 = 3 - 2*sqrt(3/e) */\n#define D1 1.7155277699214135\n#define D2 0.8989161620588988\nlong rk_hypergeometric_hrua(rk_state *state, long good, long bad, long sample)\n{\n    long mingoodbad, maxgoodbad, popsize, m, d9;\n    double d4, d5, d6, d7, d8, d10, d11;\n    long Z;\n    double T, W, X, Y;\n\n    mingoodbad = min(good, bad);\n    popsize = good + bad;\n    maxgoodbad = max(good, bad);\n    m = min(sample, popsize - sample);\n    d4 = ((double)mingoodbad) / popsize;\n    d5 = 1.0 - d4;\n    d6 = m*d4 + 0.5;\n    d7 = sqrt((double)(popsize - m) * sample * d4 * d5 / (popsize - 1) + 0.5);\n    d8 = D1*d7 + D2;\n    d9 = (long)floor((double)(m + 1) * (mingoodbad + 1) / (popsize + 2));\n    d10 = (loggam(d9+1) + loggam(mingoodbad-d9+1) + loggam(m-d9+1) +\n           loggam(maxgoodbad-m+d9+1));\n    d11 = min(min(m, mingoodbad)+1.0, floor(d6+16*d7));\n    /* 16 for 16-decimal-digit precision in D1 and D2 */\n\n    while (1)\n    {\n        X = rk_double(state);\n        Y = rk_double(state);\n        W = d6 + d8*(Y- 0.5)/X;\n\n        /* fast rejection: */\n        if ((W < 0.0) || (W >= d11)) continue;\n\n        Z = (long)floor(W);\n        T = d10 - (loggam(Z+1) + loggam(mingoodbad-Z+1) + loggam(m-Z+1) +\n                   loggam(maxgoodbad-m+Z+1));\n\n        /* fast acceptance: */\n        if ((X*(4.0-X)-3.0) <= T) break;\n\n        /* fast rejection: */\n        if (X*(X-T) >= 1) continue;\n\n        if (2.0*log(X) <= T) break;  /* acceptance */\n    }\n\n    /* this is a correction to HRUA* by Ivan Frohne in rv.py */\n    if (good > bad) Z = m - Z;\n\n    /* another fix from rv.py to allow sample to exceed popsize/2 */\n    if (m < sample) Z = good - Z;\n\n    return Z;\n}\n#undef D1\n#undef D2\n\nlong rk_hypergeometric(rk_state *state, long good, long bad, long sample)\n{\n    if (sample > 10)\n    {\n        return rk_hypergeometric_hrua(state, good, bad, sample);\n    } else\n    {\n        return rk_hypergeometric_hyp(state, good, bad, sample);\n    }\n}\n\ndouble rk_triangular(rk_state *state, double left, double mode, double right)\n{\n    double base, leftbase, ratio, leftprod, rightprod;\n    double U;\n\n    base = right - left;\n    leftbase = mode - left;\n    ratio = leftbase / base;\n    leftprod = leftbase*base;\n    rightprod = (right - mode)*base;\n\n    U = rk_double(state);\n    if (U <= ratio)\n    {\n        return left + sqrt(U*leftprod);\n    } else\n    {\n      return right - sqrt((1.0 - U) * rightprod);\n    }\n}\n\nlong rk_logseries(rk_state *state, double p)\n{\n    double q, r, U, V;\n    long result;\n\n    r = log(1.0 - p);\n\n    while (1) {\n        V = rk_double(state);\n        if (V >= p) {\n            return 1;\n        }\n        U = rk_double(state);\n        q = 1.0 - exp(r*U);\n        if (V <= q*q) {\n            result = (long)floor(1 + log(V)/log(q));\n            if (result < 1) {\n                continue;\n            }\n            else {\n                return result;\n            }\n        }\n        if (V >= q) {\n            return 1;\n        }\n        return 2;\n    }\n}\n"
    },
    {
      "filename": "numpy/random/tests/test_random.py",
      "content": "from __future__ import division, absolute_import, print_function\n\nimport numpy as np\nfrom numpy.testing import (\n        TestCase, run_module_suite, assert_, assert_raises, assert_equal,\n        assert_warns)\nfrom numpy import random\nfrom numpy.compat import asbytes\nimport sys\n\nclass TestSeed(TestCase):\n    def test_scalar(self):\n        s = np.random.RandomState(0)\n        assert_equal(s.randint(1000), 684)\n        s = np.random.RandomState(4294967295)\n        assert_equal(s.randint(1000), 419)\n\n    def test_array(self):\n        s = np.random.RandomState(range(10))\n        assert_equal(s.randint(1000), 468)\n        s = np.random.RandomState(np.arange(10))\n        assert_equal(s.randint(1000), 468)\n        s = np.random.RandomState([0])\n        assert_equal(s.randint(1000), 973)\n        s = np.random.RandomState([4294967295])\n        assert_equal(s.randint(1000), 265)\n\n    def test_invalid_scalar(self):\n        # seed must be a unsigned 32 bit integers\n        assert_raises(TypeError, np.random.RandomState, -0.5)\n        assert_raises(ValueError, np.random.RandomState, -1)\n\n    def test_invalid_array(self):\n        # seed must be a unsigned 32 bit integers\n        assert_raises(TypeError, np.random.RandomState, [-0.5])\n        assert_raises(ValueError, np.random.RandomState, [-1])\n        assert_raises(ValueError, np.random.RandomState, [4294967296])\n        assert_raises(ValueError, np.random.RandomState, [1, 2, 4294967296])\n        assert_raises(ValueError, np.random.RandomState, [1, -2, 4294967296])\n\nclass TestBinomial(TestCase):\n    def test_n_zero(self):\n        # Tests the corner case of n == 0 for the binomial distribution.\n        # binomial(0, p) should be zero for any p in [0, 1].\n        # This test addresses issue #3480.\n        zeros = np.zeros(2, dtype='int')\n        for p in [0, .5, 1]:\n            assert_(random.binomial(0, p) == 0)\n            np.testing.assert_array_equal(random.binomial(zeros, p), zeros)\n\n    def test_p_is_nan(self):\n        # Issue #4571.\n        assert_raises(ValueError, random.binomial, 1, np.nan)\n\n\nclass TestMultinomial(TestCase):\n    def test_basic(self):\n        random.multinomial(100, [0.2, 0.8])\n\n    def test_zero_probability(self):\n        random.multinomial(100, [0.2, 0.8, 0.0, 0.0, 0.0])\n\n    def test_int_negative_interval(self):\n        assert_(-5 <= random.randint(-5, -1) < -1)\n        x = random.randint(-5, -1, 5)\n        assert_(np.all(-5 <= x))\n        assert_(np.all(x < -1))\n\n    def test_size(self):\n        # gh-3173\n        p = [0.5, 0.5]\n        assert_equal(np.random.multinomial(1, p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.multinomial(1, p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.multinomial(1, p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.multinomial(1, p, [2, 2]).shape, (2, 2, 2))\n        assert_equal(np.random.multinomial(1, p, (2, 2)).shape, (2, 2, 2))\n        assert_equal(np.random.multinomial(1, p, np.array((2, 2))).shape,\n                     (2, 2, 2))\n\n        assert_raises(TypeError, np.random.multinomial, 1, p,\n                      np.float(1))\n\n\nclass TestSetState(TestCase):\n    def setUp(self):\n        self.seed = 1234567890\n        self.prng = random.RandomState(self.seed)\n        self.state = self.prng.get_state()\n\n    def test_basic(self):\n        old = self.prng.tomaxint(16)\n        self.prng.set_state(self.state)\n        new = self.prng.tomaxint(16)\n        assert_(np.all(old == new))\n\n    def test_gaussian_reset(self):\n        # Make sure the cached every-other-Gaussian is reset.\n        old = self.prng.standard_normal(size=3)\n        self.prng.set_state(self.state)\n        new = self.prng.standard_normal(size=3)\n        assert_(np.all(old == new))\n\n    def test_gaussian_reset_in_media_res(self):\n        # When the state is saved with a cached Gaussian, make sure the\n        # cached Gaussian is restored.\n\n        self.prng.standard_normal()\n        state = self.prng.get_state()\n        old = self.prng.standard_normal(size=3)\n        self.prng.set_state(state)\n        new = self.prng.standard_normal(size=3)\n        assert_(np.all(old == new))\n\n    def test_backwards_compatibility(self):\n        # Make sure we can accept old state tuples that do not have the\n        # cached Gaussian value.\n        old_state = self.state[:-2]\n        x1 = self.prng.standard_normal(size=16)\n        self.prng.set_state(old_state)\n        x2 = self.prng.standard_normal(size=16)\n        self.prng.set_state(self.state)\n        x3 = self.prng.standard_normal(size=16)\n        assert_(np.all(x1 == x2))\n        assert_(np.all(x1 == x3))\n\n    def test_negative_binomial(self):\n        # Ensure that the negative binomial results take floating point\n        # arguments without truncation.\n        self.prng.negative_binomial(0.5, 0.5)\n\nclass TestRandomDist(TestCase):\n    # Make sure the random distrobution return the correct value for a\n    # given seed\n\n    def setUp(self):\n        self.seed = 1234567890\n\n    def test_rand(self):\n        np.random.seed(self.seed)\n        actual = np.random.rand(3, 2)\n        desired = np.array([[0.61879477158567997, 0.59162362775974664],\n                            [0.88868358904449662, 0.89165480011560816],\n                            [0.4575674820298663, 0.7781880808593471]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_randn(self):\n        np.random.seed(self.seed)\n        actual = np.random.randn(3, 2)\n        desired = np.array([[1.34016345771863121, 1.73759122771936081],\n                           [1.498988344300628, -0.2286433324536169],\n                           [2.031033998682787, 2.17032494605655257]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_randint(self):\n        np.random.seed(self.seed)\n        actual = np.random.randint(-99, 99, size=(3, 2))\n        desired = np.array([[31, 3],\n                            [-52, 41],\n                            [-48, -66]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_random_integers(self):\n        np.random.seed(self.seed)\n        actual = np.random.random_integers(-99, 99, size=(3, 2))\n        desired = np.array([[31, 3],\n                            [-52, 41],\n                            [-48, -66]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_random_sample(self):\n        np.random.seed(self.seed)\n        actual = np.random.random_sample((3, 2))\n        desired = np.array([[0.61879477158567997, 0.59162362775974664],\n                            [0.88868358904449662, 0.89165480011560816],\n                            [0.4575674820298663, 0.7781880808593471]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_choice_uniform_replace(self):\n        np.random.seed(self.seed)\n        actual = np.random.choice(4, 4)\n        desired = np.array([2, 3, 2, 3])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_choice_nonuniform_replace(self):\n        np.random.seed(self.seed)\n        actual = np.random.choice(4, 4, p=[0.4, 0.4, 0.1, 0.1])\n        desired = np.array([1, 1, 2, 2])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_choice_uniform_noreplace(self):\n        np.random.seed(self.seed)\n        actual = np.random.choice(4, 3, replace=False)\n        desired = np.array([0, 1, 3])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_choice_nonuniform_noreplace(self):\n        np.random.seed(self.seed)\n        actual = np.random.choice(4, 3, replace=False,\n                                  p=[0.1, 0.3, 0.5, 0.1])\n        desired = np.array([2, 3, 1])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_choice_noninteger(self):\n        np.random.seed(self.seed)\n        actual = np.random.choice(['a', 'b', 'c', 'd'], 4)\n        desired = np.array(['c', 'd', 'c', 'd'])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_choice_exceptions(self):\n        sample = np.random.choice\n        assert_raises(ValueError, sample, -1, 3)\n        assert_raises(ValueError, sample, 3., 3)\n        assert_raises(ValueError, sample, [[1, 2], [3, 4]], 3)\n        assert_raises(ValueError, sample, [], 3)\n        assert_raises(ValueError, sample, [1, 2, 3, 4], 3,\n                                          p=[[0.25, 0.25], [0.25, 0.25]])\n        assert_raises(ValueError, sample, [1, 2], 3, p=[0.4, 0.4, 0.2])\n        assert_raises(ValueError, sample, [1, 2], 3, p=[1.1, -0.1])\n        assert_raises(ValueError, sample, [1, 2], 3, p=[0.4, 0.4])\n        assert_raises(ValueError, sample, [1, 2, 3], 4, replace=False)\n        assert_raises(ValueError, sample, [1, 2, 3], 2, replace=False,\n                                          p=[1, 0, 0])\n\n    def test_choice_return_shape(self):\n        p = [0.1, 0.9]\n        # Check scalar\n        assert_(np.isscalar(np.random.choice(2, replace=True)))\n        assert_(np.isscalar(np.random.choice(2, replace=False)))\n        assert_(np.isscalar(np.random.choice(2, replace=True, p=p)))\n        assert_(np.isscalar(np.random.choice(2, replace=False, p=p)))\n        assert_(np.isscalar(np.random.choice([1, 2], replace=True)))\n        assert_(np.random.choice([None], replace=True) is None)\n        a = np.array([1, 2])\n        arr = np.empty(1, dtype=object)\n        arr[0] = a\n        assert_(np.random.choice(arr, replace=True) is a)\n\n        # Check 0-d array\n        s = tuple()\n        assert_(not np.isscalar(np.random.choice(2, s, replace=True)))\n        assert_(not np.isscalar(np.random.choice(2, s, replace=False)))\n        assert_(not np.isscalar(np.random.choice(2, s, replace=True, p=p)))\n        assert_(not np.isscalar(np.random.choice(2, s, replace=False, p=p)))\n        assert_(not np.isscalar(np.random.choice([1, 2], s, replace=True)))\n        assert_(np.random.choice([None], s, replace=True).ndim == 0)\n        a = np.array([1, 2])\n        arr = np.empty(1, dtype=object)\n        arr[0] = a\n        assert_(np.random.choice(arr, s, replace=True).item() is a)\n\n        # Check multi dimensional array\n        s = (2, 3)\n        p = [0.1, 0.1, 0.1, 0.1, 0.4, 0.2]\n        assert_(np.random.choice(6, s, replace=True).shape, s)\n        assert_(np.random.choice(6, s, replace=False).shape, s)\n        assert_(np.random.choice(6, s, replace=True, p=p).shape, s)\n        assert_(np.random.choice(6, s, replace=False, p=p).shape, s)\n        assert_(np.random.choice(np.arange(6), s, replace=True).shape, s)\n\n    def test_bytes(self):\n        np.random.seed(self.seed)\n        actual = np.random.bytes(10)\n        desired = asbytes('\\x82Ui\\x9e\\xff\\x97+Wf\\xa5')\n        np.testing.assert_equal(actual, desired)\n\n    def test_shuffle(self):\n        # Test lists, arrays, and multidimensional versions of both:\n        for conv in [lambda x: x,\n                     np.asarray,\n                     lambda x: [(i, i) for i in x],\n                     lambda x: np.asarray([(i, i) for i in x])]:\n            np.random.seed(self.seed)\n            alist = conv([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])\n            np.random.shuffle(alist)\n            actual = alist\n            desired = conv([0, 1, 9, 6, 2, 4, 5, 8, 7, 3])\n            np.testing.assert_array_equal(actual, desired)\n\n    def test_shuffle_flexible(self):\n        # gh-4270\n        arr = [(0, 1), (2, 3)]\n        dt = np.dtype([('a', np.int32, 1), ('b', np.int32, 1)])\n        nparr = np.array(arr, dtype=dt)\n        a, b = nparr[0].copy(), nparr[1].copy()\n        for i in range(50):\n            np.random.shuffle(nparr)\n            assert_(a in nparr)\n            assert_(b in nparr)\n\n    def test_shuffle_masked(self):\n        # gh-3263\n        a = np.ma.masked_values(np.reshape(range(20), (5,4)) % 3 - 1, -1)\n        b = np.ma.masked_values(np.arange(20) % 3 - 1, -1)\n        ma = np.ma.count_masked(a)\n        mb = np.ma.count_masked(b)\n        for i in range(50):\n            np.random.shuffle(a)\n            self.assertEqual(ma, np.ma.count_masked(a))\n            np.random.shuffle(b)\n            self.assertEqual(mb, np.ma.count_masked(b))\n\n    def test_beta(self):\n        np.random.seed(self.seed)\n        actual = np.random.beta(.1, .9, size=(3, 2))\n        desired = np.array(\n                [[1.45341850513746058e-02, 5.31297615662868145e-04],\n                 [1.85366619058432324e-06, 4.19214516800110563e-03],\n                 [1.58405155108498093e-04, 1.26252891949397652e-04]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_binomial(self):\n        np.random.seed(self.seed)\n        actual = np.random.binomial(100.123, .456, size=(3, 2))\n        desired = np.array([[37, 43],\n                         [42, 48],\n                         [46, 45]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_chisquare(self):\n        np.random.seed(self.seed)\n        actual = np.random.chisquare(50, size=(3, 2))\n        desired = np.array([[63.87858175501090585, 68.68407748911370447],\n                            [65.77116116901505904, 47.09686762438974483],\n                            [72.3828403199695174, 74.18408615260374006]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=13)\n\n    def test_dirichlet(self):\n        np.random.seed(self.seed)\n        alpha = np.array([51.72840233779265162, 39.74494232180943953])\n        actual = np.random.mtrand.dirichlet(alpha, size=(3, 2))\n        desired = np.array([[[0.54539444573611562, 0.45460555426388438],\n                             [0.62345816822039413, 0.37654183177960598]],\n                            [[0.55206000085785778, 0.44793999914214233],\n                             [0.58964023305154301, 0.41035976694845688]],\n                            [[0.59266909280647828, 0.40733090719352177],\n                             [0.56974431743975207, 0.43025568256024799]]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_dirichlet_size(self):\n        # gh-3173\n        p = np.array([51.72840233779265162, 39.74494232180943953])\n        assert_equal(np.random.dirichlet(p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.dirichlet(p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.dirichlet(p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.dirichlet(p, [2, 2]).shape, (2, 2, 2))\n        assert_equal(np.random.dirichlet(p, (2, 2)).shape, (2, 2, 2))\n        assert_equal(np.random.dirichlet(p, np.array((2, 2))).shape, (2, 2, 2))\n\n        assert_raises(TypeError, np.random.dirichlet, p, np.float(1))\n\n    def test_exponential(self):\n        np.random.seed(self.seed)\n        actual = np.random.exponential(1.1234, size=(3, 2))\n        desired = np.array([[1.08342649775011624, 1.00607889924557314],\n                            [2.46628830085216721, 2.49668106809923884],\n                            [0.68717433461363442, 1.69175666993575979]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_f(self):\n        np.random.seed(self.seed)\n        actual = np.random.f(12, 77, size=(3, 2))\n        desired = np.array([[1.21975394418575878, 1.75135759791559775],\n                            [1.44803115017146489, 1.22108959480396262],\n                            [1.02176975757740629, 1.34431827623300415]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_gamma(self):\n        np.random.seed(self.seed)\n        actual = np.random.gamma(5, 3, size=(3, 2))\n        desired = np.array([[24.60509188649287182, 28.54993563207210627],\n                            [26.13476110204064184, 12.56988482927716078],\n                            [31.71863275789960568, 33.30143302795922011]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_geometric(self):\n        np.random.seed(self.seed)\n        actual = np.random.geometric(.123456789, size=(3, 2))\n        desired = np.array([[8, 7],\n                            [17, 17],\n                            [5, 12]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_gumbel(self):\n        np.random.seed(self.seed)\n        actual = np.random.gumbel(loc=.123456789, scale=2.0, size=(3, 2))\n        desired = np.array([[0.19591898743416816, 0.34405539668096674],\n                            [-1.4492522252274278, -1.47374816298446865],\n                            [1.10651090478803416, -0.69535848626236174]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_hypergeometric(self):\n        np.random.seed(self.seed)\n        actual = np.random.hypergeometric(10.1, 5.5, 14, size=(3, 2))\n        desired = np.array([[10, 10],\n                            [10, 10],\n                            [9, 9]])\n        np.testing.assert_array_equal(actual, desired)\n\n        # Test nbad = 0\n        actual = np.random.hypergeometric(5, 0, 3, size=4)\n        desired = np.array([3, 3, 3, 3])\n        np.testing.assert_array_equal(actual, desired)\n\n        actual = np.random.hypergeometric(15, 0, 12, size=4)\n        desired = np.array([12, 12, 12, 12])\n        np.testing.assert_array_equal(actual, desired)\n\n        # Test ngood = 0\n        actual = np.random.hypergeometric(0, 5, 3, size=4)\n        desired = np.array([0, 0, 0, 0])\n        np.testing.assert_array_equal(actual, desired)\n\n        actual = np.random.hypergeometric(0, 15, 12, size=4)\n        desired = np.array([0, 0, 0, 0])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_laplace(self):\n        np.random.seed(self.seed)\n        actual = np.random.laplace(loc=.123456789, scale=2.0, size=(3, 2))\n        desired = np.array([[0.66599721112760157, 0.52829452552221945],\n                            [3.12791959514407125, 3.18202813572992005],\n                            [-0.05391065675859356, 1.74901336242837324]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_logistic(self):\n        np.random.seed(self.seed)\n        actual = np.random.logistic(loc=.123456789, scale=2.0, size=(3, 2))\n        desired = np.array([[1.09232835305011444, 0.8648196662399954],\n                            [4.27818590694950185, 4.33897006346929714],\n                            [-0.21682183359214885, 2.63373365386060332]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_lognormal(self):\n        np.random.seed(self.seed)\n        actual = np.random.lognormal(mean=.123456789, sigma=2.0, size=(3, 2))\n        desired = np.array([[16.50698631688883822, 36.54846706092654784],\n                            [22.67886599981281748, 0.71617561058995771],\n                            [65.72798501792723869, 86.84341601437161273]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=13)\n\n    def test_logseries(self):\n        np.random.seed(self.seed)\n        actual = np.random.logseries(p=.923456789, size=(3, 2))\n        desired = np.array([[2, 2],\n                            [6, 17],\n                            [3, 6]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_multinomial(self):\n        np.random.seed(self.seed)\n        actual = np.random.multinomial(20, [1/6.]*6, size=(3, 2))\n        desired = np.array([[[4, 3, 5, 4, 2, 2],\n                             [5, 2, 8, 2, 2, 1]],\n                            [[3, 4, 3, 6, 0, 4],\n                             [2, 1, 4, 3, 6, 4]],\n                            [[4, 4, 2, 5, 2, 3],\n                             [4, 3, 4, 2, 3, 4]]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_multivariate_normal(self):\n        np.random.seed(self.seed)\n        mean = (.123456789, 10)\n        # Hmm... not even symmetric.\n        cov = [[1, 0], [1, 0]]\n        size = (3, 2)\n        actual = np.random.multivariate_normal(mean, cov, size)\n        desired = np.array([[[-1.47027513018564449, 10.],\n                             [-1.65915081534845532, 10.]],\n                            [[-2.29186329304599745, 10.],\n                             [-1.77505606019580053, 10.]],\n                            [[-0.54970369430044119, 10.],\n                             [0.29768848031692957, 10.]]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n        # Check for default size, was raising deprecation warning\n        actual = np.random.multivariate_normal(mean, cov)\n        desired = np.array([-0.79441224511977482, 10.])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n        # Check that non positive-semidefinite covariance raises warning\n        mean = [0, 0]\n        cov = [[1, 1 + 1e-10], [1 + 1e-10, 1]]\n        assert_warns(RuntimeWarning, np.random.multivariate_normal, mean, cov)\n\n    def test_negative_binomial(self):\n        np.random.seed(self.seed)\n        actual = np.random.negative_binomial(n=100, p=.12345, size=(3, 2))\n        desired = np.array([[848, 841],\n                            [892, 611],\n                            [779, 647]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_noncentral_chisquare(self):\n        np.random.seed(self.seed)\n        actual = np.random.noncentral_chisquare(df=5, nonc=5, size=(3, 2))\n        desired = np.array([[23.91905354498517511, 13.35324692733826346],\n                            [31.22452661329736401, 16.60047399466177254],\n                            [5.03461598262724586, 17.94973089023519464]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n        actual = np.random.noncentral_chisquare(df=.5, nonc=.2, size=(3, 2))\n        desired = np.array([[ 1.47145377828516666,  0.15052899268012659],\n                            [ 0.00943803056963588,  1.02647251615666169],\n                            [ 0.332334982684171  ,  0.15451287602753125]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_noncentral_f(self):\n        np.random.seed(self.seed)\n        actual = np.random.noncentral_f(dfnum=5, dfden=2, nonc=1,\n                                        size=(3, 2))\n        desired = np.array([[1.40598099674926669, 0.34207973179285761],\n                            [3.57715069265772545, 7.92632662577829805],\n                            [0.43741599463544162, 1.1774208752428319]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_normal(self):\n        np.random.seed(self.seed)\n        actual = np.random.normal(loc=.123456789, scale=2.0, size=(3, 2))\n        desired = np.array([[2.80378370443726244, 3.59863924443872163],\n                            [3.121433477601256, -0.33382987590723379],\n                            [4.18552478636557357, 4.46410668111310471]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_pareto(self):\n        np.random.seed(self.seed)\n        actual = np.random.pareto(a=.123456789, size=(3, 2))\n        desired = np.array(\n                [[2.46852460439034849e+03, 1.41286880810518346e+03],\n                 [5.28287797029485181e+07, 6.57720981047328785e+07],\n                 [1.40840323350391515e+02, 1.98390255135251704e+05]])\n        # For some reason on 32-bit x86 Ubuntu 12.10 the [1, 0] entry in this\n        # matrix differs by 24 nulps. Discussion:\n        #   http://mail.scipy.org/pipermail/numpy-discussion/2012-September/063801.html\n        # Consensus is that this is probably some gcc quirk that affects\n        # rounding but not in any important way, so we just use a looser\n        # tolerance on this test:\n        np.testing.assert_array_almost_equal_nulp(actual, desired, nulp=30)\n\n    def test_poisson(self):\n        np.random.seed(self.seed)\n        actual = np.random.poisson(lam=.123456789, size=(3, 2))\n        desired = np.array([[0, 0],\n                         [1, 0],\n                         [0, 0]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_poisson_exceptions(self):\n        lambig = np.iinfo('l').max\n        lamneg = -1\n        assert_raises(ValueError, np.random.poisson, lamneg)\n        assert_raises(ValueError, np.random.poisson, [lamneg]*10)\n        assert_raises(ValueError, np.random.poisson, lambig)\n        assert_raises(ValueError, np.random.poisson, [lambig]*10)\n\n    def test_power(self):\n        np.random.seed(self.seed)\n        actual = np.random.power(a=.123456789, size=(3, 2))\n        desired = np.array([[0.02048932883240791, 0.01424192241128213],\n                            [0.38446073748535298, 0.39499689943484395],\n                            [0.00177699707563439, 0.13115505880863756]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_rayleigh(self):\n        np.random.seed(self.seed)\n        actual = np.random.rayleigh(scale=10, size=(3, 2))\n        desired = np.array([[13.8882496494248393, 13.383318339044731],\n                            [20.95413364294492098, 21.08285015800712614],\n                            [11.06066537006854311, 17.35468505778271009]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_standard_cauchy(self):\n        np.random.seed(self.seed)\n        actual = np.random.standard_cauchy(size=(3, 2))\n        desired = np.array([[0.77127660196445336, -6.55601161955910605],\n                            [0.93582023391158309, -2.07479293013759447],\n                            [-4.74601644297011926, 0.18338989290760804]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_standard_exponential(self):\n        np.random.seed(self.seed)\n        actual = np.random.standard_exponential(size=(3, 2))\n        desired = np.array([[0.96441739162374596, 0.89556604882105506],\n                            [2.1953785836319808, 2.22243285392490542],\n                            [0.6116915921431676, 1.50592546727413201]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_standard_gamma(self):\n        np.random.seed(self.seed)\n        actual = np.random.standard_gamma(shape=3, size=(3, 2))\n        desired = np.array([[5.50841531318455058, 6.62953470301903103],\n                            [5.93988484943779227, 2.31044849402133989],\n                            [7.54838614231317084, 8.012756093271868]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_standard_normal(self):\n        np.random.seed(self.seed)\n        actual = np.random.standard_normal(size=(3, 2))\n        desired = np.array([[1.34016345771863121, 1.73759122771936081],\n                            [1.498988344300628, -0.2286433324536169],\n                            [2.031033998682787, 2.17032494605655257]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_standard_t(self):\n        np.random.seed(self.seed)\n        actual = np.random.standard_t(df=10, size=(3, 2))\n        desired = np.array([[0.97140611862659965, -0.08830486548450577],\n                            [1.36311143689505321, -0.55317463909867071],\n                            [-0.18473749069684214, 0.61181537341755321]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_triangular(self):\n        np.random.seed(self.seed)\n        actual = np.random.triangular(left=5.12, mode=10.23, right=20.34,\n                                      size=(3, 2))\n        desired = np.array([[12.68117178949215784, 12.4129206149193152],\n                            [16.20131377335158263, 16.25692138747600524],\n                            [11.20400690911820263, 14.4978144835829923]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_uniform(self):\n        np.random.seed(self.seed)\n        actual = np.random.uniform(low=1.23, high=10.54, size=(3, 2))\n        desired = np.array([[6.99097932346268003, 6.73801597444323974],\n                            [9.50364421400426274, 9.53130618907631089],\n                            [5.48995325769805476, 8.47493103280052118]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_uniform_range_bounds(self):\n        fmin = np.finfo('float').min\n        fmax = np.finfo('float').max\n\n        func = np.random.uniform\n        np.testing.assert_raises(OverflowError, func, -np.inf, 0)\n        np.testing.assert_raises(OverflowError, func,  0,      np.inf)\n        np.testing.assert_raises(OverflowError, func,  fmin,   fmax)\n\n        # (fmax / 1e17) - fmin is within range, so this should not throw\n        np.random.uniform(low=fmin, high=fmax / 1e17)\n\n    def test_vonmises(self):\n        np.random.seed(self.seed)\n        actual = np.random.vonmises(mu=1.23, kappa=1.54, size=(3, 2))\n        desired = np.array([[2.28567572673902042, 2.89163838442285037],\n                            [0.38198375564286025, 2.57638023113890746],\n                            [1.19153771588353052, 1.83509849681825354]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_vonmises_small(self):\n        # check infinite loop, gh-4720\n        np.random.seed(self.seed)\n        r = np.random.vonmises(mu=0., kappa=1.1e-8, size=10**6)\n        np.testing.assert_(np.isfinite(r).all())\n\n    def test_wald(self):\n        np.random.seed(self.seed)\n        actual = np.random.wald(mean=1.23, scale=1.54, size=(3, 2))\n        desired = np.array([[3.82935265715889983, 5.13125249184285526],\n                            [0.35045403618358717, 1.50832396872003538],\n                            [0.24124319895843183, 0.22031101461955038]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_weibull(self):\n        np.random.seed(self.seed)\n        actual = np.random.weibull(a=1.23, size=(3, 2))\n        desired = np.array([[0.97097342648766727, 0.91422896443565516],\n                            [1.89517770034962929, 1.91414357960479564],\n                            [0.67057783752390987, 1.39494046635066793]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_zipf(self):\n        np.random.seed(self.seed)\n        actual = np.random.zipf(a=1.23, size=(3, 2))\n        desired = np.array([[66, 29],\n                            [1, 1],\n                            [3, 13]])\n        np.testing.assert_array_equal(actual, desired)\n\n\nclass TestThread(object):\n    # make sure each state produces the same sequence even in threads\n    def setUp(self):\n        self.seeds = range(4)\n\n    def check_function(self, function, sz):\n        from threading import Thread\n\n        out1 = np.empty((len(self.seeds),) + sz)\n        out2 = np.empty((len(self.seeds),) + sz)\n\n        # threaded generation\n        t = [Thread(target=function, args=(np.random.RandomState(s), o))\n             for s, o in zip(self.seeds, out1)]\n        [x.start() for x in t]\n        [x.join() for x in t]\n\n        # the same serial\n        for s, o in zip(self.seeds, out2):\n            function(np.random.RandomState(s), o)\n\n        # these platforms change x87 fpu precision mode in threads\n        if (np.intp().dtype.itemsize == 4 and sys.platform == \"win32\"):\n            np.testing.assert_array_almost_equal(out1, out2)\n        else:\n            np.testing.assert_array_equal(out1, out2)\n\n    def test_normal(self):\n        def gen_random(state, out):\n            out[...] = state.normal(size=10000)\n        self.check_function(gen_random, sz=(10000,))\n\n    def test_exp(self):\n        def gen_random(state, out):\n            out[...] = state.exponential(scale=np.ones((100, 1000)))\n        self.check_function(gen_random, sz=(100, 1000))\n\n    def test_multinomial(self):\n        def gen_random(state, out):\n            out[...] = state.multinomial(10, [1/6.]*6, size=10000)\n        self.check_function(gen_random, sz=(10000,6))\n\n\nif __name__ == \"__main__\":\n    run_module_suite()\n"
    }
  ],
  "questions": [
    "The numpy docstring says `>=1`, so `df=1` shouldn't give an error. Plus `ValueError: df <= 0` is a weird error. Can you open a numpy issue for that?",
    "At the end of your message you suggest a possible improvement for `stats.ncx2.rvs`. Needs deciding on, do we want to do this in `stats.ncx2` or should we only consider it if `np.random.noncentral_chisquare` gets this enhancement?"
  ],
  "golden_answers": [
    "At the end of your message you suggest a possible improvement for `stats.ncx2.rvs`. Needs deciding on, do we want to do this in `stats.ncx2` or should we only consider it if `np.random.noncentral_chisquare` gets this enhancement?",
    "The fact that `df=1` raises error may be because the algorithm implemented is the one I suggested above: in this case, it needs to generate a chi-square random variate with `df=0`, which is not well defined in mathematics"
  ],
  "questions_generated": [
    "What is the primary cause of the ValueError when generating random variates from the noncentral chi-square distribution with a degree of freedom (dof) less than or equal to 1 in scipy?",
    "How does scipy's implementation of noncentral chi-square distribution differ from the common implementation when handling different degrees of freedom?",
    "What specific enhancement is suggested for numpy's noncentral_chisquare method to address the issue discussed?",
    "Why does the error message 'ValueError: df <= 0' appear misleading in the context of this issue?",
    "In the context of scipy's code structure, where does the dependency on numpy's implementation of noncentral chi-square distribution manifest?"
  ],
  "golden_answers_generated": [
    "The primary cause of the ValueError is that scipy's implementation of the noncentral chi-square distribution, which relies on numpy's random variate generation, only handles the case where the degree of freedom is greater than 1. When the degree of freedom is 1, it attempts to generate a chi-square random variate with dof=0, which is mathematically undefined, leading to the error.",
    "Scipy's implementation relies on numpy's noncentral_chisquare method, which only considers degrees of freedom greater than 1. In contrast, a common implementation for generating noncentral chi-square random variates handles two cases: for dof > 1, it uses a sum of a chi-square variate and a transformed normal variate; for dof <= 1, it uses a different approach involving a Poisson distribution.",
    "The enhancement suggested for numpy's noncentral_chisquare method is to implement a generation approach for the noncentral chi-square distribution that works with degrees of freedom <= 1. This would involve using a different algorithm that includes generating a chi-square variate with a modified degree of freedom using the Poisson distribution method.",
    "The error message 'ValueError: df <= 0' is misleading because it suggests that the degree of freedom is non-positive, when in fact the error occurs due to the implementation's inability to handle the edge case where df = 1. The message does not accurately convey that the issue arises from attempts to generate a chi-square variate with an undefined degree of freedom.",
    "In scipy's code structure, the dependency on numpy's implementation of noncentral chi-square distribution is manifested in the _rvs method of the scipy.stats._continuous_distns module. This method calls numpy's mtrand.noncentral_chisquare function to generate random variates, which is where the limitation for degrees of freedom <= 1 is encountered."
  ]
}