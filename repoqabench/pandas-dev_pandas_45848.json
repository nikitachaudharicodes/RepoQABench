{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "45848",
  "issue_description": "# ENH: pd.get_dummies should not default to dtype np.uint8\n\nI was caught by surprise the other day when doing some vector subtraction when using pd.get_dummies. The issue is that the default dtype is np.uint8 which means that cases where a 1 is subtracted from a 0 will result in 255.\r\n\r\nI [tweeted about this surprise](https://twitter.com/willkurt/status/1490163404853686278) (with an example of this issue) and the overwhelming response was that this felt like a pretty big surprise and, in most cases, undesired default behavior. [Bill Tubbs then made a mention of this in another issue](https://github.com/pandas-dev/pandas/issues/19618#issuecomment-1030762635) where it was recommended that a new issue be created for this.\r\n\r\nMy guess is that the defaulting to np.uint8 is to reduce memory demands on what are potentially large, very sparse matrices. While I'm sure there are use cases that demand this, it seems like the risk of defaulting to np.uint8 outweigh the benefits of just choosing an signed representation.",
  "issue_comments": [
    {
      "id": 1030903674,
      "user": "phofl",
      "body": "Please provide the output of pd.show_versions and provide something repriducible.\r\n\r\nwe have a bug template for bug reports or an enhancement template if you think that this is more of an enhancement.\r\n\r\n"
    },
    {
      "id": 1030914927,
      "user": "willkurt",
      "body": "To be clear, this is definitely an enhancement and not a bug since this is [the documented behavior](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) of `get_dummies`.\r\n\r\nThe issue is that defaulting to `np.uint8` is not what most people expect to be the default behavior, and leads to unexpected result in pretty common use cases (subtracting vectors), and is considered to be a pretty severe 'gotcha'.\r\n\r\nI've included the requested information as well as an example below. If you need more info I'm happy to use a template, just provide a pointer where I could find one.\r\n\r\nHere's the output of pd.show_versions:\r\n```\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : 945c9ed766a61c7d2c0a7cbb251b6edebf9cb7d5\r\npython           : 3.10.0.final.0\r\npython-bits      : 64\r\nOS               : Darwin\r\nOS-release       : 19.6.0\r\nVersion          : Darwin Kernel Version 19.6.0: Thu Sep 16 20:58:47 PDT 2021; root:xnu-6153.141.40.1~1/RELEASE_X86_64\r\nmachine          : x86_64\r\nprocessor        : i386\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : en_US.UTF-8\r\nLOCALE           : en_US.UTF-8\r\n\r\npandas           : 1.3.4\r\nnumpy            : 1.21.4\r\npytz             : 2021.3\r\ndateutil         : 2.8.2\r\npip              : 21.3.1\r\nsetuptools       : 57.0.0\r\nCython           : None\r\npytest           : None\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 3.0.3\r\nIPython          : 7.29.0\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfsspec           : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nmatplotlib       : 3.5.1\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : None\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.7.2\r\nsqlalchemy       : None\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nnumba            : None\r\n```\r\n\r\nHere's an example of the issue:\r\n\r\n```\r\nvec1 = pd.get_dummies([\"okay\", \"gotcha\", \"okay\"])\r\nvec2 = pd.get_dummies([\"gotcha\", \"okay\", \"okay\"])\r\ndiff_default = vec1 - vec2\r\ndiff_default\r\n```\r\n\r\nreturns\r\n\r\n```\r\n   gotcha  okay\r\n0     255     1\r\n1       1   255\r\n2       0     0\r\n```\r\n\r\nThe intended behavior can be achieved by specifying any signed dtype as you can see here:\r\n\r\n```\r\nvec1 = pd.get_dummies([\"okay\", \"gotcha\", \"okay\"],\r\n                     dtype=np.float32)\r\nvec2 = pd.get_dummies([\"gotcha\", \"okay\", \"okay\"],\r\n                     dtype=np.float32)\r\ndiff_correct = vec1 - vec2\r\ndiff_correct\r\n```\r\n\r\nreturns the generally expected result:\r\n\r\n```\r\n   gotcha  okay\r\n0    -1.0   1.0\r\n1     1.0  -1.0\r\n2     0.0   0.0\r\n```\r\n\r\nMy (and many other people's) issue with this is that the default should not lead to unexpected results. It doesn't need to be a `np.float32`, but it should be a signed dtype."
    },
    {
      "id": 1030915951,
      "user": "phofl",
      "body": "Thx, we would probably need a deprecation cycle if we would change that"
    },
    {
      "id": 1030930211,
      "user": "willkurt",
      "body": "Makes sense to me. I appreciate you looking into this, thanks!"
    },
    {
      "id": 1030931188,
      "user": "MarcoGorelli",
      "body": "From git log it looks like it's been like this for years, but I can't tell why uint8 was chosen over int8. \n\nI'd be in favour of deprecating the current default in favour of int8"
    },
    {
      "id": 1030938851,
      "user": "dhvalden",
      "body": "I support this change. uint8 can lead to hard to track errors"
    },
    {
      "id": 1205146533,
      "user": "MarcoGorelli",
      "body": "@pandas-dev/pandas-core anyone got any objections to changing the default type? Any reason to not just make the default type `bool`? Then, the return type would be clear, and if people need to do arithmetic operations on the dummy values, they can do their own dtype conversion. But at least they wouldn't run into unexpected behaviour like this\r\n\r\nGeneral suggestion for others who would like this changed: please use reactions to express support, no need to add comments just indicating that you'd also like to see this"
    },
    {
      "id": 1205148327,
      "user": "jreback",
      "body": "bool is a problem as doesn't play nice with missing values\n\ncould certain return Boolean\n\nthis would be a breaking change and so needs to wait for 2.0 (i think their is a tracking issue)"
    },
    {
      "id": 1205155584,
      "user": "MarcoGorelli",
      "body": "> bool is a problem as doesn't play nice with missing values\r\n\r\nSure, but why would `get_dummies` return a missing value anyway? Unless I'm missing something, the return values would always be `0` or `1`"
    },
    {
      "id": 1205155793,
      "user": "bashtage",
      "body": "IMO you either go with `int64` or just make them `float`, if you want to move away from the idea of using the smallest int dtype that can represent the encoded categorical variable. `float` is probably the most sensible (between `int64` and `float`) since it has the same storage requirements and handles `nan` fine. "
    },
    {
      "id": 1205160814,
      "user": "bashtage",
      "body": "> The intended behavior can be achieved by specifying any signed dtype as you can see here:\r\n\r\nThis isn't quite right.  Any int dtype can wrap under the right conditions. It wouldn't happen subtracting 2 dummies, but you cannot know that there isn't some edge case out there.\r\n\r\nI agree that `uint` is particularly problematic here since `np.iinfo(dt).max` is always 1 to the left of 0.\r\n"
    },
    {
      "id": 1205162885,
      "user": "bashtage",
      "body": "Another funny behavior of `get_dummies`\r\n\r\n```\r\n\r\nIn [26]: pd.get_dummies(c,dummy_na=True)\r\nOut[26]:\r\n   a  b  NaN\r\n0  1  0    0\r\n1  0  1    0\r\n2  1  0    0\r\n3  0  0    1\r\n\r\n\r\nIn [25]: ~pd.get_dummies(c,dummy_na=True)\r\nOut[25]:\r\n     a    b  NaN\r\n0  254  255  255\r\n1  255  254  255\r\n2  254  255  255\r\n3  255  255  254\r\n```\r\n\r\nThe suggestion to use `bool` would avoid this issue. "
    },
    {
      "id": 1205165721,
      "user": "MarcoGorelli",
      "body": "Thanks @bashtage \r\n\r\n> float is probably the most sensible (between int64 and float) since it has the same storage requirements and handles nan fine.\r\n\r\nRegarding handling `nan` - is there an example of a case when `get_dummies` returns `nan`? If not, then `bool` should be fine, right?"
    },
    {
      "id": 1205336252,
      "user": "MarcoGorelli",
      "body": "@willkurt do you want to open a PR for this? This'd involve:\r\n\r\n- in `pandas/tests/reshape/test_get_dummies.py`, for tests which don't already specify a `dtype`, pass `np.dtype(np.uint8)`\r\n- add a test which doesn't specify a `dtype`, and assert that a `FutureWarning` with a message like \"the default dtype will change from `'uint8'` to `'bool', please specify a `dtype` to silence this warning` is raised\r\n- in `pandas/core/reshape/encoding.py`, in `_get_dummies_1d`, add a `FutureWarning` with a message like the above if `dtype` wasn't passed by the user\r\n\r\nNot strictly necessary, but I think `dtype=None` could also be changed to `dtype=lib.no_default`\r\n\r\nSounds like there's agreement on changing the default type away from `uint8`, we can always revisit the message about what it'll be changed to in the PR review\r\n\r\nIf anyone wants to work on this, [here](https://pandas.pydata.org/docs/development/contributing.html)'s the contributing guide, and feel free to ask for help if anything's unclear"
    },
    {
      "id": 1205389467,
      "user": "WillAyd",
      "body": "Probably in the minority but I think uint8 is a natural return type. bool would also be ok\r\n\r\nInt64 and float are pretty heavy handed - I think memory usage is really important here. "
    },
    {
      "id": 1250580060,
      "user": "Dev-Khant",
      "body": "Hi everyone, I am starting in Open Source and willing to contribute. Can I work on this issue and can anyone help me get started?"
    },
    {
      "id": 1250649723,
      "user": "MarcoGorelli",
      "body": "Hey - thanks, but there's already a PR open"
    },
    {
      "id": 1250687843,
      "user": "Dev-Khant",
      "body": "OK, can you suggest me any beginner issue to work on."
    },
    {
      "id": 1286598466,
      "user": "wany-oh",
      "body": "Would this change also apply to `Series.str.get_dummies()`?"
    },
    {
      "id": 1286724314,
      "user": "MarcoGorelli",
      "body": "that's a good point, `.str.get_dummies` still defaults to `int64` - want to open a separate issue about changing that to bool too?"
    }
  ],
  "text_context": "# ENH: pd.get_dummies should not default to dtype np.uint8\n\nI was caught by surprise the other day when doing some vector subtraction when using pd.get_dummies. The issue is that the default dtype is np.uint8 which means that cases where a 1 is subtracted from a 0 will result in 255.\r\n\r\nI [tweeted about this surprise](https://twitter.com/willkurt/status/1490163404853686278) (with an example of this issue) and the overwhelming response was that this felt like a pretty big surprise and, in most cases, undesired default behavior. [Bill Tubbs then made a mention of this in another issue](https://github.com/pandas-dev/pandas/issues/19618#issuecomment-1030762635) where it was recommended that a new issue be created for this.\r\n\r\nMy guess is that the defaulting to np.uint8 is to reduce memory demands on what are potentially large, very sparse matrices. While I'm sure there are use cases that demand this, it seems like the risk of defaulting to np.uint8 outweigh the benefits of just choosing an signed representation.\n\nPlease provide the output of pd.show_versions and provide something repriducible.\r\n\r\nwe have a bug template for bug reports or an enhancement template if you think that this is more of an enhancement.\r\n\r\n\n\nTo be clear, this is definitely an enhancement and not a bug since this is [the documented behavior](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) of `get_dummies`.\r\n\r\nThe issue is that defaulting to `np.uint8` is not what most people expect to be the default behavior, and leads to unexpected result in pretty common use cases (subtracting vectors), and is considered to be a pretty severe 'gotcha'.\r\n\r\nI've included the requested information as well as an example below. If you need more info I'm happy to use a template, just provide a pointer where I could find one.\r\n\r\nHere's the output of pd.show_versions:\r\n```\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : 945c9ed766a61c7d2c0a7cbb251b6edebf9cb7d5\r\npython           : 3.10.0.final.0\r\npython-bits      : 64\r\nOS               : Darwin\r\nOS-release       : 19.6.0\r\nVersion          : Darwin Kernel Version 19.6.0: Thu Sep 16 20:58:47 PDT 2021; root:xnu-6153.141.40.1~1/RELEASE_X86_64\r\nmachine          : x86_64\r\nprocessor        : i386\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : en_US.UTF-8\r\nLOCALE           : en_US.UTF-8\r\n\r\npandas           : 1.3.4\r\nnumpy            : 1.21.4\r\npytz             : 2021.3\r\ndateutil         : 2.8.2\r\npip              : 21.3.1\r\nsetuptools       : 57.0.0\r\nCython           : None\r\npytest           : None\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 3.0.3\r\nIPython          : 7.29.0\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfsspec           : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nmatplotlib       : 3.5.1\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : None\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.7.2\r\nsqlalchemy       : None\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nnumba            : None\r\n```\r\n\r\nHere's an example of the issue:\r\n\r\n```\r\nvec1 = pd.get_dummies([\"okay\", \"gotcha\", \"okay\"])\r\nvec2 = pd.get_dummies([\"gotcha\", \"okay\", \"okay\"])\r\ndiff_default = vec1 - vec2\r\ndiff_default\r\n```\r\n\r\nreturns\r\n\r\n```\r\n   gotcha  okay\r\n0     255     1\r\n1       1   255\r\n2       0     0\r\n```\r\n\r\nThe intended behavior can be achieved by specifying any signed dtype as you can see here:\r\n\r\n```\r\nvec1 = pd.get_dummies([\"okay\", \"gotcha\", \"okay\"],\r\n                     dtype=np.float32)\r\nvec2 = pd.get_dummies([\"gotcha\", \"okay\", \"okay\"],\r\n                     dtype=np.float32)\r\ndiff_correct = vec1 - vec2\r\ndiff_correct\r\n```\r\n\r\nreturns the generally expected result:\r\n\r\n```\r\n   gotcha  okay\r\n0    -1.0   1.0\r\n1     1.0  -1.0\r\n2     0.0   0.0\r\n```\r\n\r\nMy (and many other people's) issue with this is that the default should not lead to unexpected results. It doesn't need to be a `np.float32`, but it should be a signed dtype.\n\nThx, we would probably need a deprecation cycle if we would change that\n\nMakes sense to me. I appreciate you looking into this, thanks!\n\nFrom git log it looks like it's been like this for years, but I can't tell why uint8 was chosen over int8. \n\nI'd be in favour of deprecating the current default in favour of int8\n\nI support this change. uint8 can lead to hard to track errors\n\n@pandas-dev/pandas-core anyone got any objections to changing the default type? Any reason to not just make the default type `bool`? Then, the return type would be clear, and if people need to do arithmetic operations on the dummy values, they can do their own dtype conversion. But at least they wouldn't run into unexpected behaviour like this\r\n\r\nGeneral suggestion for others who would like this changed: please use reactions to express support, no need to add comments just indicating that you'd also like to see this\n\nbool is a problem as doesn't play nice with missing values\n\ncould certain return Boolean\n\nthis would be a breaking change and so needs to wait for 2.0 (i think their is a tracking issue)\n\n> bool is a problem as doesn't play nice with missing values\r\n\r\nSure, but why would `get_dummies` return a missing value anyway? Unless I'm missing something, the return values would always be `0` or `1`\n\nIMO you either go with `int64` or just make them `float`, if you want to move away from the idea of using the smallest int dtype that can represent the encoded categorical variable. `float` is probably the most sensible (between `int64` and `float`) since it has the same storage requirements and handles `nan` fine. \n\n> The intended behavior can be achieved by specifying any signed dtype as you can see here:\r\n\r\nThis isn't quite right.  Any int dtype can wrap under the right conditions. It wouldn't happen subtracting 2 dummies, but you cannot know that there isn't some edge case out there.\r\n\r\nI agree that `uint` is particularly problematic here since `np.iinfo(dt).max` is always 1 to the left of 0.\r\n\n\nAnother funny behavior of `get_dummies`\r\n\r\n```\r\n\r\nIn [26]: pd.get_dummies(c,dummy_na=True)\r\nOut[26]:\r\n   a  b  NaN\r\n0  1  0    0\r\n1  0  1    0\r\n2  1  0    0\r\n3  0  0    1\r\n\r\n\r\nIn [25]: ~pd.get_dummies(c,dummy_na=True)\r\nOut[25]:\r\n     a    b  NaN\r\n0  254  255  255\r\n1  255  254  255\r\n2  254  255  255\r\n3  255  255  254\r\n```\r\n\r\nThe suggestion to use `bool` would avoid this issue. \n\nThanks @bashtage \r\n\r\n> float is probably the most sensible (between int64 and float) since it has the same storage requirements and handles nan fine.\r\n\r\nRegarding handling `nan` - is there an example of a case when `get_dummies` returns `nan`? If not, then `bool` should be fine, right?\n\n@willkurt do you want to open a PR for this? This'd involve:\r\n\r\n- in `pandas/tests/reshape/test_get_dummies.py`, for tests which don't already specify a `dtype`, pass `np.dtype(np.uint8)`\r\n- add a test which doesn't specify a `dtype`, and assert that a `FutureWarning` with a message like \"the default dtype will change from `'uint8'` to `'bool', please specify a `dtype` to silence this warning` is raised\r\n- in `pandas/core/reshape/encoding.py`, in `_get_dummies_1d`, add a `FutureWarning` with a message like the above if `dtype` wasn't passed by the user\r\n\r\nNot strictly necessary, but I think `dtype=None` could also be changed to `dtype=lib.no_default`\r\n\r\nSounds like there's agreement on changing the default type away from `uint8`, we can always revisit the message about what it'll be changed to in the PR review\r\n\r\nIf anyone wants to work on this, [here](https://pandas.pydata.org/docs/development/contributing.html)'s the contributing guide, and feel free to ask for help if anything's unclear\n\nProbably in the minority but I think uint8 is a natural return type. bool would also be ok\r\n\r\nInt64 and float are pretty heavy handed - I think memory usage is really important here. \n\nHi everyone, I am starting in Open Source and willing to contribute. Can I work on this issue and can anyone help me get started?\n\nHey - thanks, but there's already a PR open\n\nOK, can you suggest me any beginner issue to work on.\n\nWould this change also apply to `Series.str.get_dummies()`?\n\nthat's a good point, `.str.get_dummies` still defaults to `int64` - want to open a separate issue about changing that to bool too?",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/48022",
  "code_context": [
    {
      "filename": "pandas/core/reshape/encoding.py",
      "content": "from __future__ import annotations\n\nfrom collections import defaultdict\nimport itertools\nfrom typing import (\n    Hashable,\n    Iterable,\n)\n\nimport numpy as np\n\nfrom pandas._libs.sparse import IntIndex\nfrom pandas._typing import Dtype\n\nfrom pandas.core.dtypes.common import (\n    is_integer_dtype,\n    is_list_like,\n    is_object_dtype,\n)\n\nfrom pandas.core.arrays import SparseArray\nfrom pandas.core.arrays.categorical import factorize_from_iterable\nfrom pandas.core.frame import DataFrame\nfrom pandas.core.indexes.api import Index\nfrom pandas.core.series import Series\n\n\ndef get_dummies(\n    data,\n    prefix=None,\n    prefix_sep: str | Iterable[str] | dict[str, str] = \"_\",\n    dummy_na: bool = False,\n    columns=None,\n    sparse: bool = False,\n    drop_first: bool = False,\n    dtype: Dtype | None = None,\n) -> DataFrame:\n    \"\"\"\n    Convert categorical variable into dummy/indicator variables.\n\n    Each variable is converted in as many 0/1 variables as there are different\n    values. Columns in the output are each named after a value; if the input is\n    a DataFrame, the name of the original variable is prepended to the value.\n\n    Parameters\n    ----------\n    data : array-like, Series, or DataFrame\n        Data of which to get dummy indicators.\n    prefix : str, list of str, or dict of str, default None\n        String to append DataFrame column names.\n        Pass a list with length equal to the number of columns\n        when calling get_dummies on a DataFrame. Alternatively, `prefix`\n        can be a dictionary mapping column names to prefixes.\n    prefix_sep : str, default '_'\n        If appending prefix, separator/delimiter to use. Or pass a\n        list or dictionary as with `prefix`.\n    dummy_na : bool, default False\n        Add a column to indicate NaNs, if False NaNs are ignored.\n    columns : list-like, default None\n        Column names in the DataFrame to be encoded.\n        If `columns` is None then all the columns with\n        `object`, `string`, or `category` dtype will be converted.\n    sparse : bool, default False\n        Whether the dummy-encoded columns should be backed by\n        a :class:`SparseArray` (True) or a regular NumPy array (False).\n    drop_first : bool, default False\n        Whether to get k-1 dummies out of k categorical levels by removing the\n        first level.\n    dtype : dtype, default bool\n        Data type for new columns. Only a single dtype is allowed.\n\n    Returns\n    -------\n    DataFrame\n        Dummy-coded data. If `data` contains other columns than the\n        dummy-coded one(s), these will be prepended, unaltered, to the result.\n\n    See Also\n    --------\n    Series.str.get_dummies : Convert Series of strings to dummy codes.\n    :func:`~pandas.from_dummies` : Convert dummy codes to categorical ``DataFrame``.\n\n    Notes\n    -----\n    Reference :ref:`the user guide <reshaping.dummies>` for more examples.\n\n    Examples\n    --------\n    >>> s = pd.Series(list('abca'))\n\n    >>> pd.get_dummies(s)\n           a      b      c\n    0   True  False  False\n    1  False   True  False\n    2  False  False   True\n    3   True  False  False\n\n    >>> s1 = ['a', 'b', np.nan]\n\n    >>> pd.get_dummies(s1)\n           a      b\n    0   True  False\n    1  False   True\n    2  False  False\n\n    >>> pd.get_dummies(s1, dummy_na=True)\n           a      b    NaN\n    0   True  False  False\n    1  False   True  False\n    2  False  False   True\n\n    >>> df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],\n    ...                    'C': [1, 2, 3]})\n\n    >>> pd.get_dummies(df, prefix=['col1', 'col2'])\n       C  col1_a  col1_b  col2_a  col2_b  col2_c\n    0  1    True   False   False    True   False\n    1  2   False    True    True   False   False\n    2  3    True   False   False   False    True\n\n    >>> pd.get_dummies(pd.Series(list('abcaa')))\n           a      b      c\n    0   True  False  False\n    1  False   True  False\n    2  False  False   True\n    3   True  False  False\n    4   True  False  False\n\n    >>> pd.get_dummies(pd.Series(list('abcaa')), drop_first=True)\n           b      c\n    0  False  False\n    1   True  False\n    2  False   True\n    3  False  False\n    4  False  False\n\n    >>> pd.get_dummies(pd.Series(list('abc')), dtype=float)\n         a    b    c\n    0  1.0  0.0  0.0\n    1  0.0  1.0  0.0\n    2  0.0  0.0  1.0\n    \"\"\"\n    from pandas.core.reshape.concat import concat\n\n    dtypes_to_encode = [\"object\", \"string\", \"category\"]\n\n    if isinstance(data, DataFrame):\n        # determine columns being encoded\n        if columns is None:\n            data_to_encode = data.select_dtypes(include=dtypes_to_encode)\n        elif not is_list_like(columns):\n            raise TypeError(\"Input must be a list-like for parameter `columns`\")\n        else:\n            data_to_encode = data[columns]\n\n        # validate prefixes and separator to avoid silently dropping cols\n        def check_len(item, name):\n\n            if is_list_like(item):\n                if not len(item) == data_to_encode.shape[1]:\n                    len_msg = (\n                        f\"Length of '{name}' ({len(item)}) did not match the \"\n                        \"length of the columns being encoded \"\n                        f\"({data_to_encode.shape[1]}).\"\n                    )\n                    raise ValueError(len_msg)\n\n        check_len(prefix, \"prefix\")\n        check_len(prefix_sep, \"prefix_sep\")\n\n        if isinstance(prefix, str):\n            prefix = itertools.cycle([prefix])\n        if isinstance(prefix, dict):\n            prefix = [prefix[col] for col in data_to_encode.columns]\n\n        if prefix is None:\n            prefix = data_to_encode.columns\n\n        # validate separators\n        if isinstance(prefix_sep, str):\n            prefix_sep = itertools.cycle([prefix_sep])\n        elif isinstance(prefix_sep, dict):\n            prefix_sep = [prefix_sep[col] for col in data_to_encode.columns]\n\n        with_dummies: list[DataFrame]\n        if data_to_encode.shape == data.shape:\n            # Encoding the entire df, do not prepend any dropped columns\n            with_dummies = []\n        elif columns is not None:\n            # Encoding only cols specified in columns. Get all cols not in\n            # columns to prepend to result.\n            with_dummies = [data.drop(columns, axis=1)]\n        else:\n            # Encoding only object and category dtype columns. Get remaining\n            # columns to prepend to result.\n            with_dummies = [data.select_dtypes(exclude=dtypes_to_encode)]\n\n        for (col, pre, sep) in zip(data_to_encode.items(), prefix, prefix_sep):\n            # col is (column_name, column), use just column data here\n            dummy = _get_dummies_1d(\n                col[1],\n                prefix=pre,\n                prefix_sep=sep,\n                dummy_na=dummy_na,\n                sparse=sparse,\n                drop_first=drop_first,\n                dtype=dtype,\n            )\n            with_dummies.append(dummy)\n        result = concat(with_dummies, axis=1)\n    else:\n        result = _get_dummies_1d(\n            data,\n            prefix,\n            prefix_sep,\n            dummy_na,\n            sparse=sparse,\n            drop_first=drop_first,\n            dtype=dtype,\n        )\n    return result\n\n\ndef _get_dummies_1d(\n    data,\n    prefix,\n    prefix_sep: str | Iterable[str] | dict[str, str] = \"_\",\n    dummy_na: bool = False,\n    sparse: bool = False,\n    drop_first: bool = False,\n    dtype: Dtype | None = None,\n) -> DataFrame:\n    from pandas.core.reshape.concat import concat\n\n    # Series avoids inconsistent NaN handling\n    codes, levels = factorize_from_iterable(Series(data))\n\n    if dtype is None:\n        dtype = np.dtype(bool)\n    # error: Argument 1 to \"dtype\" has incompatible type \"Union[ExtensionDtype, str,\n    # dtype[Any], Type[object]]\"; expected \"Type[Any]\"\n    dtype = np.dtype(dtype)  # type: ignore[arg-type]\n\n    if is_object_dtype(dtype):\n        raise ValueError(\"dtype=object is not a valid dtype for get_dummies\")\n\n    def get_empty_frame(data) -> DataFrame:\n        index: Index | np.ndarray\n        if isinstance(data, Series):\n            index = data.index\n        else:\n            index = Index(range(len(data)))\n        return DataFrame(index=index)\n\n    # if all NaN\n    if not dummy_na and len(levels) == 0:\n        return get_empty_frame(data)\n\n    codes = codes.copy()\n    if dummy_na:\n        codes[codes == -1] = len(levels)\n        levels = levels.insert(len(levels), np.nan)\n\n    # if dummy_na, we just fake a nan level. drop_first will drop it again\n    if drop_first and len(levels) == 1:\n        return get_empty_frame(data)\n\n    number_of_cols = len(levels)\n\n    if prefix is None:\n        dummy_cols = levels\n    else:\n        dummy_cols = Index([f\"{prefix}{prefix_sep}{level}\" for level in levels])\n\n    index: Index | None\n    if isinstance(data, Series):\n        index = data.index\n    else:\n        index = None\n\n    if sparse:\n\n        fill_value: bool | float\n        if is_integer_dtype(dtype):\n            fill_value = 0\n        elif dtype == np.dtype(bool):\n            fill_value = False\n        else:\n            fill_value = 0.0\n\n        sparse_series = []\n        N = len(data)\n        sp_indices: list[list] = [[] for _ in range(len(dummy_cols))]\n        mask = codes != -1\n        codes = codes[mask]\n        n_idx = np.arange(N)[mask]\n\n        for ndx, code in zip(n_idx, codes):\n            sp_indices[code].append(ndx)\n\n        if drop_first:\n            # remove first categorical level to avoid perfect collinearity\n            # GH12042\n            sp_indices = sp_indices[1:]\n            dummy_cols = dummy_cols[1:]\n        for col, ixs in zip(dummy_cols, sp_indices):\n            sarr = SparseArray(\n                np.ones(len(ixs), dtype=dtype),\n                sparse_index=IntIndex(N, ixs),\n                fill_value=fill_value,\n                dtype=dtype,\n            )\n            sparse_series.append(Series(data=sarr, index=index, name=col))\n\n        return concat(sparse_series, axis=1, copy=False)\n\n    else:\n        # take on axis=1 + transpose to ensure ndarray layout is column-major\n        dummy_mat = np.eye(number_of_cols, dtype=dtype).take(codes, axis=1).T\n\n        if not dummy_na:\n            # reset NaN GH4446\n            dummy_mat[codes == -1] = 0\n\n        if drop_first:\n            # remove first GH12042\n            dummy_mat = dummy_mat[:, 1:]\n            dummy_cols = dummy_cols[1:]\n        return DataFrame(dummy_mat, index=index, columns=dummy_cols)\n\n\ndef from_dummies(\n    data: DataFrame,\n    sep: None | str = None,\n    default_category: None | Hashable | dict[str, Hashable] = None,\n) -> DataFrame:\n    \"\"\"\n    Create a categorical ``DataFrame`` from a ``DataFrame`` of dummy variables.\n\n    Inverts the operation performed by :func:`~pandas.get_dummies`.\n\n    .. versionadded:: 1.5.0\n\n    Parameters\n    ----------\n    data : DataFrame\n        Data which contains dummy-coded variables in form of integer columns of\n        1's and 0's.\n    sep : str, default None\n        Separator used in the column names of the dummy categories they are\n        character indicating the separation of the categorical names from the prefixes.\n        For example, if your column names are 'prefix_A' and 'prefix_B',\n        you can strip the underscore by specifying sep='_'.\n    default_category : None, Hashable or dict of Hashables, default None\n        The default category is the implied category when a value has none of the\n        listed categories specified with a one, i.e. if all dummies in a row are\n        zero. Can be a single value for all variables or a dict directly mapping\n        the default categories to a prefix of a variable.\n\n    Returns\n    -------\n    DataFrame\n        Categorical data decoded from the dummy input-data.\n\n    Raises\n    ------\n    ValueError\n        * When the input ``DataFrame`` ``data`` contains NA values.\n        * When the input ``DataFrame`` ``data`` contains column names with separators\n          that do not match the separator specified with ``sep``.\n        * When a ``dict`` passed to ``default_category`` does not include an implied\n          category for each prefix.\n        * When a value in ``data`` has more than one category assigned to it.\n        * When ``default_category=None`` and a value in ``data`` has no category\n          assigned to it.\n    TypeError\n        * When the input ``data`` is not of type ``DataFrame``.\n        * When the input ``DataFrame`` ``data`` contains non-dummy data.\n        * When the passed ``sep`` is of a wrong data type.\n        * When the passed ``default_category`` is of a wrong data type.\n\n    See Also\n    --------\n    :func:`~pandas.get_dummies` : Convert ``Series`` or ``DataFrame`` to dummy codes.\n    :class:`~pandas.Categorical` : Represent a categorical variable in classic.\n\n    Notes\n    -----\n    The columns of the passed dummy data should only include 1's and 0's,\n    or boolean values.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({\"a\": [1, 0, 0, 1], \"b\": [0, 1, 0, 0],\n    ...                    \"c\": [0, 0, 1, 0]})\n\n    >>> df\n       a  b  c\n    0  1  0  0\n    1  0  1  0\n    2  0  0  1\n    3  1  0  0\n\n    >>> pd.from_dummies(df)\n    0     a\n    1     b\n    2     c\n    3     a\n\n    >>> df = pd.DataFrame({\"col1_a\": [1, 0, 1], \"col1_b\": [0, 1, 0],\n    ...                    \"col2_a\": [0, 1, 0], \"col2_b\": [1, 0, 0],\n    ...                    \"col2_c\": [0, 0, 1]})\n\n    >>> df\n          col1_a  col1_b  col2_a  col2_b  col2_c\n    0       1       0       0       1       0\n    1       0       1       1       0       0\n    2       1       0       0       0       1\n\n    >>> pd.from_dummies(df, sep=\"_\")\n        col1    col2\n    0    a       b\n    1    b       a\n    2    a       c\n\n    >>> df = pd.DataFrame({\"col1_a\": [1, 0, 0], \"col1_b\": [0, 1, 0],\n    ...                    \"col2_a\": [0, 1, 0], \"col2_b\": [1, 0, 0],\n    ...                    \"col2_c\": [0, 0, 0]})\n\n    >>> df\n          col1_a  col1_b  col2_a  col2_b  col2_c\n    0       1       0       0       1       0\n    1       0       1       1       0       0\n    2       0       0       0       0       0\n\n    >>> pd.from_dummies(df, sep=\"_\", default_category={\"col1\": \"d\", \"col2\": \"e\"})\n        col1    col2\n    0    a       b\n    1    b       a\n    2    d       e\n    \"\"\"\n    from pandas.core.reshape.concat import concat\n\n    if not isinstance(data, DataFrame):\n        raise TypeError(\n            \"Expected 'data' to be a 'DataFrame'; \"\n            f\"Received 'data' of type: {type(data).__name__}\"\n        )\n\n    if data.isna().any().any():\n        raise ValueError(\n            \"Dummy DataFrame contains NA value in column: \"\n            f\"'{data.isna().any().idxmax()}'\"\n        )\n\n    # index data with a list of all columns that are dummies\n    try:\n        data_to_decode = data.astype(\"boolean\", copy=False)\n    except TypeError:\n        raise TypeError(\"Passed DataFrame contains non-dummy data\")\n\n    # collect prefixes and get lists to slice data for each prefix\n    variables_slice = defaultdict(list)\n    if sep is None:\n        variables_slice[\"\"] = list(data.columns)\n    elif isinstance(sep, str):\n        for col in data_to_decode.columns:\n            prefix = col.split(sep)[0]\n            if len(prefix) == len(col):\n                raise ValueError(f\"Separator not specified for column: {col}\")\n            variables_slice[prefix].append(col)\n    else:\n        raise TypeError(\n            \"Expected 'sep' to be of type 'str' or 'None'; \"\n            f\"Received 'sep' of type: {type(sep).__name__}\"\n        )\n\n    if default_category is not None:\n        if isinstance(default_category, dict):\n            if not len(default_category) == len(variables_slice):\n                len_msg = (\n                    f\"Length of 'default_category' ({len(default_category)}) \"\n                    f\"did not match the length of the columns being encoded \"\n                    f\"({len(variables_slice)})\"\n                )\n                raise ValueError(len_msg)\n        elif isinstance(default_category, Hashable):\n            default_category = dict(\n                zip(variables_slice, [default_category] * len(variables_slice))\n            )\n        else:\n            raise TypeError(\n                \"Expected 'default_category' to be of type \"\n                \"'None', 'Hashable', or 'dict'; \"\n                \"Received 'default_category' of type: \"\n                f\"{type(default_category).__name__}\"\n            )\n\n    cat_data = {}\n    for prefix, prefix_slice in variables_slice.items():\n        if sep is None:\n            cats = prefix_slice.copy()\n        else:\n            cats = [col[len(prefix + sep) :] for col in prefix_slice]\n        assigned = data_to_decode.loc[:, prefix_slice].sum(axis=1)\n        if any(assigned > 1):\n            raise ValueError(\n                \"Dummy DataFrame contains multi-assignment(s); \"\n                f\"First instance in row: {assigned.idxmax()}\"\n            )\n        elif any(assigned == 0):\n            if isinstance(default_category, dict):\n                cats.append(default_category[prefix])\n            else:\n                raise ValueError(\n                    \"Dummy DataFrame contains unassigned value(s); \"\n                    f\"First instance in row: {assigned.idxmin()}\"\n                )\n            data_slice = concat(\n                (data_to_decode.loc[:, prefix_slice], assigned == 0), axis=1\n            )\n        else:\n            data_slice = data_to_decode.loc[:, prefix_slice]\n        cats_array = np.array(cats, dtype=\"object\")\n        # get indices of True entries along axis=1\n        cat_data[prefix] = cats_array[data_slice.to_numpy().nonzero()[1]]\n\n    return DataFrame(cat_data)\n"
    },
    {
      "filename": "pandas/tests/frame/indexing/test_getitem.py",
      "content": "import re\n\nimport numpy as np\nimport pytest\n\nfrom pandas import (\n    Categorical,\n    CategoricalDtype,\n    CategoricalIndex,\n    DataFrame,\n    DateOffset,\n    DatetimeIndex,\n    Index,\n    MultiIndex,\n    Series,\n    Timestamp,\n    concat,\n    date_range,\n    get_dummies,\n    period_range,\n)\nimport pandas._testing as tm\nfrom pandas.core.arrays import SparseArray\n\n\nclass TestGetitem:\n    def test_getitem_unused_level_raises(self):\n        # GH#20410\n        mi = MultiIndex(\n            levels=[[\"a_lot\", \"onlyone\", \"notevenone\"], [1970, \"\"]],\n            codes=[[1, 0], [1, 0]],\n        )\n        df = DataFrame(-1, index=range(3), columns=mi)\n\n        with pytest.raises(KeyError, match=\"notevenone\"):\n            df[\"notevenone\"]\n\n    def test_getitem_periodindex(self):\n        rng = period_range(\"1/1/2000\", periods=5)\n        df = DataFrame(np.random.randn(10, 5), columns=rng)\n\n        ts = df[rng[0]]\n        tm.assert_series_equal(ts, df.iloc[:, 0])\n\n        # GH#1211; smoketest unrelated to the rest of this test\n        repr(df)\n\n        ts = df[\"1/1/2000\"]\n        tm.assert_series_equal(ts, df.iloc[:, 0])\n\n    def test_getitem_list_of_labels_categoricalindex_cols(self):\n        # GH#16115\n        cats = Categorical([Timestamp(\"12-31-1999\"), Timestamp(\"12-31-2000\")])\n\n        expected = DataFrame([[1, 0], [0, 1]], dtype=\"bool\", index=[0, 1], columns=cats)\n        dummies = get_dummies(cats)\n        result = dummies[list(dummies.columns)]\n        tm.assert_frame_equal(result, expected)\n\n    def test_getitem_sparse_column_return_type_and_dtype(self):\n        # https://github.com/pandas-dev/pandas/issues/23559\n        data = SparseArray([0, 1])\n        df = DataFrame({\"A\": data})\n        expected = Series(data, name=\"A\")\n        result = df[\"A\"]\n        tm.assert_series_equal(result, expected)\n\n        # Also check iloc and loc while we're here\n        result = df.iloc[:, 0]\n        tm.assert_series_equal(result, expected)\n\n        result = df.loc[:, \"A\"]\n        tm.assert_series_equal(result, expected)\n\n    def test_getitem_string_columns(self):\n        # GH#46185\n        df = DataFrame([[1, 2]], columns=Index([\"A\", \"B\"], dtype=\"string\"))\n        result = df.A\n        expected = df[\"A\"]\n        tm.assert_series_equal(result, expected)\n\n\nclass TestGetitemListLike:\n    def test_getitem_list_missing_key(self):\n        # GH#13822, incorrect error string with non-unique columns when missing\n        # column is accessed\n        df = DataFrame({\"x\": [1.0], \"y\": [2.0], \"z\": [3.0]})\n        df.columns = [\"x\", \"x\", \"z\"]\n\n        # Check that we get the correct value in the KeyError\n        with pytest.raises(KeyError, match=r\"\\['y'\\] not in index\"):\n            df[[\"x\", \"y\", \"z\"]]\n\n    def test_getitem_list_duplicates(self):\n        # GH#1943\n        df = DataFrame(np.random.randn(4, 4), columns=list(\"AABC\"))\n        df.columns.name = \"foo\"\n\n        result = df[[\"B\", \"C\"]]\n        assert result.columns.name == \"foo\"\n\n        expected = df.iloc[:, 2:]\n        tm.assert_frame_equal(result, expected)\n\n    def test_getitem_dupe_cols(self):\n        df = DataFrame([[1, 2, 3], [4, 5, 6]], columns=[\"a\", \"a\", \"b\"])\n        msg = \"\\\"None of [Index(['baf'], dtype='object')] are in the [columns]\\\"\"\n        with pytest.raises(KeyError, match=re.escape(msg)):\n            df[[\"baf\"]]\n\n    @pytest.mark.parametrize(\n        \"idx_type\",\n        [\n            list,\n            iter,\n            Index,\n            set,\n            lambda l: dict(zip(l, range(len(l)))),\n            lambda l: dict(zip(l, range(len(l)))).keys(),\n        ],\n        ids=[\"list\", \"iter\", \"Index\", \"set\", \"dict\", \"dict_keys\"],\n    )\n    @pytest.mark.parametrize(\"levels\", [1, 2])\n    def test_getitem_listlike(self, idx_type, levels, float_frame):\n        # GH#21294\n\n        if levels == 1:\n            frame, missing = float_frame, \"food\"\n        else:\n            # MultiIndex columns\n            frame = DataFrame(\n                np.random.randn(8, 3),\n                columns=Index(\n                    [(\"foo\", \"bar\"), (\"baz\", \"qux\"), (\"peek\", \"aboo\")],\n                    name=(\"sth\", \"sth2\"),\n                ),\n            )\n            missing = (\"good\", \"food\")\n\n        keys = [frame.columns[1], frame.columns[0]]\n        idx = idx_type(keys)\n        idx_check = list(idx_type(keys))\n\n        if isinstance(idx, (set, dict)):\n            with tm.assert_produces_warning(FutureWarning):\n                result = frame[idx]\n        else:\n            result = frame[idx]\n\n        expected = frame.loc[:, idx_check]\n        expected.columns.names = frame.columns.names\n\n        tm.assert_frame_equal(result, expected)\n\n        idx = idx_type(keys + [missing])\n        with pytest.raises(KeyError, match=\"not in index\"):\n            with tm.assert_produces_warning(FutureWarning):\n                frame[idx]\n\n    def test_getitem_iloc_generator(self):\n        # GH#39614\n        df = DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n        indexer = (x for x in [1, 2])\n        result = df.iloc[indexer]\n        expected = DataFrame({\"a\": [2, 3], \"b\": [5, 6]}, index=[1, 2])\n        tm.assert_frame_equal(result, expected)\n\n    def test_getitem_iloc_two_dimensional_generator(self):\n        df = DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n        indexer = (x for x in [1, 2])\n        result = df.iloc[indexer, 1]\n        expected = Series([5, 6], name=\"b\", index=[1, 2])\n        tm.assert_series_equal(result, expected)\n\n    def test_getitem_iloc_dateoffset_days(self):\n        # GH 46671\n        df = DataFrame(\n            list(range(10)),\n            index=date_range(\"01-01-2022\", periods=10, freq=DateOffset(days=1)),\n        )\n        result = df.loc[\"2022-01-01\":\"2022-01-03\"]\n        expected = DataFrame(\n            [0, 1, 2],\n            index=DatetimeIndex(\n                [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\"],\n                dtype=\"datetime64[ns]\",\n                freq=DateOffset(days=1),\n            ),\n        )\n        tm.assert_frame_equal(result, expected)\n\n        df = DataFrame(\n            list(range(10)),\n            index=date_range(\n                \"01-01-2022\", periods=10, freq=DateOffset(days=1, hours=2)\n            ),\n        )\n        result = df.loc[\"2022-01-01\":\"2022-01-03\"]\n        expected = DataFrame(\n            [0, 1, 2],\n            index=DatetimeIndex(\n                [\"2022-01-01 00:00:00\", \"2022-01-02 02:00:00\", \"2022-01-03 04:00:00\"],\n                dtype=\"datetime64[ns]\",\n                freq=DateOffset(days=1, hours=2),\n            ),\n        )\n        tm.assert_frame_equal(result, expected)\n\n        df = DataFrame(\n            list(range(10)),\n            index=date_range(\"01-01-2022\", periods=10, freq=DateOffset(minutes=3)),\n        )\n        result = df.loc[\"2022-01-01\":\"2022-01-03\"]\n        tm.assert_frame_equal(result, df)\n\n\nclass TestGetitemCallable:\n    def test_getitem_callable(self, float_frame):\n        # GH#12533\n        result = float_frame[lambda x: \"A\"]\n        expected = float_frame.loc[:, \"A\"]\n        tm.assert_series_equal(result, expected)\n\n        result = float_frame[lambda x: [\"A\", \"B\"]]\n        expected = float_frame.loc[:, [\"A\", \"B\"]]\n        tm.assert_frame_equal(result, float_frame.loc[:, [\"A\", \"B\"]])\n\n        df = float_frame[:3]\n        result = df[lambda x: [True, False, True]]\n        expected = float_frame.iloc[[0, 2], :]\n        tm.assert_frame_equal(result, expected)\n\n    def test_loc_multiindex_columns_one_level(self):\n        # GH#29749\n        df = DataFrame([[1, 2]], columns=[[\"a\", \"b\"]])\n        expected = DataFrame([1], columns=[[\"a\"]])\n\n        result = df[\"a\"]\n        tm.assert_frame_equal(result, expected)\n\n        result = df.loc[:, \"a\"]\n        tm.assert_frame_equal(result, expected)\n\n\nclass TestGetitemBooleanMask:\n    def test_getitem_bool_mask_categorical_index(self):\n\n        df3 = DataFrame(\n            {\n                \"A\": np.arange(6, dtype=\"int64\"),\n            },\n            index=CategoricalIndex(\n                [1, 1, 2, 1, 3, 2],\n                dtype=CategoricalDtype([3, 2, 1], ordered=True),\n                name=\"B\",\n            ),\n        )\n        df4 = DataFrame(\n            {\n                \"A\": np.arange(6, dtype=\"int64\"),\n            },\n            index=CategoricalIndex(\n                [1, 1, 2, 1, 3, 2],\n                dtype=CategoricalDtype([3, 2, 1], ordered=False),\n                name=\"B\",\n            ),\n        )\n\n        result = df3[df3.index == \"a\"]\n        expected = df3.iloc[[]]\n        tm.assert_frame_equal(result, expected)\n\n        result = df4[df4.index == \"a\"]\n        expected = df4.iloc[[]]\n        tm.assert_frame_equal(result, expected)\n\n        result = df3[df3.index == 1]\n        expected = df3.iloc[[0, 1, 3]]\n        tm.assert_frame_equal(result, expected)\n\n        result = df4[df4.index == 1]\n        expected = df4.iloc[[0, 1, 3]]\n        tm.assert_frame_equal(result, expected)\n\n        # since we have an ordered categorical\n\n        # CategoricalIndex([1, 1, 2, 1, 3, 2],\n        #         categories=[3, 2, 1],\n        #         ordered=True,\n        #         name='B')\n        result = df3[df3.index < 2]\n        expected = df3.iloc[[4]]\n        tm.assert_frame_equal(result, expected)\n\n        result = df3[df3.index > 1]\n        expected = df3.iloc[[]]\n        tm.assert_frame_equal(result, expected)\n\n        # unordered\n        # cannot be compared\n\n        # CategoricalIndex([1, 1, 2, 1, 3, 2],\n        #         categories=[3, 2, 1],\n        #         ordered=False,\n        #         name='B')\n        msg = \"Unordered Categoricals can only compare equality or not\"\n        with pytest.raises(TypeError, match=msg):\n            df4[df4.index < 2]\n        with pytest.raises(TypeError, match=msg):\n            df4[df4.index > 1]\n\n    @pytest.mark.parametrize(\n        \"data1,data2,expected_data\",\n        (\n            (\n                [[1, 2], [3, 4]],\n                [[0.5, 6], [7, 8]],\n                [[np.nan, 3.0], [np.nan, 4.0], [np.nan, 7.0], [6.0, 8.0]],\n            ),\n            (\n                [[1, 2], [3, 4]],\n                [[5, 6], [7, 8]],\n                [[np.nan, 3.0], [np.nan, 4.0], [5, 7], [6, 8]],\n            ),\n        ),\n    )\n    def test_getitem_bool_mask_duplicate_columns_mixed_dtypes(\n        self,\n        data1,\n        data2,\n        expected_data,\n    ):\n        # GH#31954\n\n        df1 = DataFrame(np.array(data1))\n        df2 = DataFrame(np.array(data2))\n        df = concat([df1, df2], axis=1)\n\n        result = df[df > 2]\n\n        exdict = {i: np.array(col) for i, col in enumerate(expected_data)}\n        expected = DataFrame(exdict).rename(columns={2: 0, 3: 1})\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.fixture\n    def df_dup_cols(self):\n        dups = [\"A\", \"A\", \"C\", \"D\"]\n        df = DataFrame(np.arange(12).reshape(3, 4), columns=dups, dtype=\"float64\")\n        return df\n\n    def test_getitem_boolean_frame_unaligned_with_duplicate_columns(self, df_dup_cols):\n        # `df.A > 6` is a DataFrame with a different shape from df\n\n        # boolean with the duplicate raises\n        df = df_dup_cols\n        msg = \"cannot reindex on an axis with duplicate labels\"\n        with pytest.raises(ValueError, match=msg):\n            with tm.assert_produces_warning(FutureWarning, match=\"non-unique\"):\n                df[df.A > 6]\n\n    def test_getitem_boolean_series_with_duplicate_columns(self, df_dup_cols):\n        # boolean indexing\n        # GH#4879\n        df = DataFrame(\n            np.arange(12).reshape(3, 4), columns=[\"A\", \"B\", \"C\", \"D\"], dtype=\"float64\"\n        )\n        expected = df[df.C > 6]\n        expected.columns = df_dup_cols.columns\n\n        df = df_dup_cols\n        result = df[df.C > 6]\n\n        tm.assert_frame_equal(result, expected)\n        result.dtypes\n        str(result)\n\n    def test_getitem_boolean_frame_with_duplicate_columns(self, df_dup_cols):\n\n        # where\n        df = DataFrame(\n            np.arange(12).reshape(3, 4), columns=[\"A\", \"B\", \"C\", \"D\"], dtype=\"float64\"\n        )\n        # `df > 6` is a DataFrame with the same shape+alignment as df\n        expected = df[df > 6]\n        expected.columns = df_dup_cols.columns\n\n        df = df_dup_cols\n        result = df[df > 6]\n\n        tm.assert_frame_equal(result, expected)\n        result.dtypes\n        str(result)\n\n    def test_getitem_empty_frame_with_boolean(self):\n        # Test for issue GH#11859\n\n        df = DataFrame()\n        df2 = df[df > 0]\n        tm.assert_frame_equal(df, df2)\n\n    def test_getitem_returns_view_when_column_is_unique_in_df(\n        self, using_copy_on_write\n    ):\n        # GH#45316\n        df = DataFrame([[1, 2, 3], [4, 5, 6]], columns=[\"a\", \"a\", \"b\"])\n        df_orig = df.copy()\n        view = df[\"b\"]\n        view.loc[:] = 100\n        if using_copy_on_write:\n            expected = df_orig\n        else:\n            expected = DataFrame([[1, 2, 100], [4, 5, 100]], columns=[\"a\", \"a\", \"b\"])\n        tm.assert_frame_equal(df, expected)\n\n    def test_getitem_frozenset_unique_in_column(self):\n        # GH#41062\n        df = DataFrame([[1, 2, 3, 4]], columns=[frozenset([\"KEY\"]), \"B\", \"C\", \"C\"])\n        result = df[frozenset([\"KEY\"])]\n        expected = Series([1], name=frozenset([\"KEY\"]))\n        tm.assert_series_equal(result, expected)\n\n\nclass TestGetitemSlice:\n    def test_getitem_slice_float64(self, frame_or_series):\n        values = np.arange(10.0, 50.0, 2)\n        index = Index(values)\n\n        start, end = values[[5, 15]]\n\n        data = np.random.randn(20, 3)\n        if frame_or_series is not DataFrame:\n            data = data[:, 0]\n\n        obj = frame_or_series(data, index=index)\n\n        result = obj[start:end]\n        expected = obj.iloc[5:16]\n        tm.assert_equal(result, expected)\n\n        result = obj.loc[start:end]\n        tm.assert_equal(result, expected)\n\n    def test_getitem_datetime_slice(self):\n        # GH#43223\n        df = DataFrame(\n            {\"a\": 0},\n            index=DatetimeIndex(\n                [\n                    \"11.01.2011 22:00\",\n                    \"11.01.2011 23:00\",\n                    \"12.01.2011 00:00\",\n                    \"2011-01-13 00:00\",\n                ]\n            ),\n        )\n        with tm.assert_produces_warning(FutureWarning):\n            result = df[\"2011-01-01\":\"2011-11-01\"]\n        expected = DataFrame(\n            {\"a\": 0},\n            index=DatetimeIndex(\n                [\"11.01.2011 22:00\", \"11.01.2011 23:00\", \"2011-01-13 00:00\"]\n            ),\n        )\n        tm.assert_frame_equal(result, expected)\n\n\nclass TestGetitemDeprecatedIndexers:\n    @pytest.mark.parametrize(\"key\", [{\"a\", \"b\"}, {\"a\": \"a\"}])\n    def test_getitem_dict_and_set_deprecated(self, key):\n        # GH#42825\n        df = DataFrame(\n            [[1, 2], [3, 4]], columns=MultiIndex.from_tuples([(\"a\", 1), (\"b\", 2)])\n        )\n        with tm.assert_produces_warning(FutureWarning):\n            df[key]\n"
    },
    {
      "filename": "pandas/tests/reshape/test_get_dummies.py",
      "content": "import re\n\nimport numpy as np\nimport pytest\n\nfrom pandas.core.dtypes.common import is_integer_dtype\n\nimport pandas as pd\nfrom pandas import (\n    Categorical,\n    CategoricalIndex,\n    DataFrame,\n    Series,\n    get_dummies,\n)\nimport pandas._testing as tm\nfrom pandas.core.arrays.sparse import (\n    SparseArray,\n    SparseDtype,\n)\n\n\nclass TestGetDummies:\n    @pytest.fixture\n    def df(self):\n        return DataFrame({\"A\": [\"a\", \"b\", \"a\"], \"B\": [\"b\", \"b\", \"c\"], \"C\": [1, 2, 3]})\n\n    @pytest.fixture(params=[\"uint8\", \"i8\", np.float64, bool, None])\n    def dtype(self, request):\n        return np.dtype(request.param)\n\n    @pytest.fixture(params=[\"dense\", \"sparse\"])\n    def sparse(self, request):\n        # params are strings to simplify reading test results,\n        # e.g. TestGetDummies::test_basic[uint8-sparse] instead of [uint8-True]\n        return request.param == \"sparse\"\n\n    def effective_dtype(self, dtype):\n        if dtype is None:\n            return np.uint8\n        return dtype\n\n    def test_get_dummies_raises_on_dtype_object(self, df):\n        msg = \"dtype=object is not a valid dtype for get_dummies\"\n        with pytest.raises(ValueError, match=msg):\n            get_dummies(df, dtype=\"object\")\n\n    def test_get_dummies_basic(self, sparse, dtype):\n        s_list = list(\"abc\")\n        s_series = Series(s_list)\n        s_series_index = Series(s_list, list(\"ABC\"))\n\n        expected = DataFrame(\n            {\"a\": [1, 0, 0], \"b\": [0, 1, 0], \"c\": [0, 0, 1]},\n            dtype=self.effective_dtype(dtype),\n        )\n        if sparse:\n            expected = expected.apply(SparseArray, fill_value=0.0)\n        result = get_dummies(s_list, sparse=sparse, dtype=dtype)\n        tm.assert_frame_equal(result, expected)\n\n        result = get_dummies(s_series, sparse=sparse, dtype=dtype)\n        tm.assert_frame_equal(result, expected)\n\n        expected.index = list(\"ABC\")\n        result = get_dummies(s_series_index, sparse=sparse, dtype=dtype)\n        tm.assert_frame_equal(result, expected)\n\n    def test_get_dummies_basic_types(self, sparse, dtype):\n        # GH 10531\n        s_list = list(\"abc\")\n        s_series = Series(s_list)\n        s_df = DataFrame(\n            {\"a\": [0, 1, 0, 1, 2], \"b\": [\"A\", \"A\", \"B\", \"C\", \"C\"], \"c\": [2, 3, 3, 3, 2]}\n        )\n\n        expected = DataFrame(\n            {\"a\": [1, 0, 0], \"b\": [0, 1, 0], \"c\": [0, 0, 1]},\n            dtype=self.effective_dtype(dtype),\n            columns=list(\"abc\"),\n        )\n        if sparse:\n            if is_integer_dtype(dtype):\n                fill_value = 0\n            elif dtype == bool:\n                fill_value = False\n            else:\n                fill_value = 0.0\n\n            expected = expected.apply(SparseArray, fill_value=fill_value)\n        result = get_dummies(s_list, sparse=sparse, dtype=dtype)\n        tm.assert_frame_equal(result, expected)\n\n        result = get_dummies(s_series, sparse=sparse, dtype=dtype)\n        tm.assert_frame_equal(result, expected)\n\n        result = get_dummies(s_df, columns=s_df.columns, sparse=sparse, dtype=dtype)\n        if sparse:\n            dtype_name = f\"Sparse[{self.effective_dtype(dtype).name}, {fill_value}]\"\n        else:\n            dtype_name = self.effective_dtype(dtype).name\n\n        expected = Series({dtype_name: 8})\n        result = result.dtypes.value_counts()\n        result.index = [str(i) for i in result.index]\n        tm.assert_series_equal(result, expected)\n\n        result = get_dummies(s_df, columns=[\"a\"], sparse=sparse, dtype=dtype)\n\n        expected_counts = {\"int64\": 1, \"object\": 1}\n        expected_counts[dtype_name] = 3 + expected_counts.get(dtype_name, 0)\n\n        expected = Series(expected_counts).sort_index()\n        result = result.dtypes.value_counts()\n        result.index = [str(i) for i in result.index]\n        result = result.sort_index()\n        tm.assert_series_equal(result, expected)\n\n    def test_get_dummies_just_na(self, sparse):\n        just_na_list = [np.nan]\n        just_na_series = Series(just_na_list)\n        just_na_series_index = Series(just_na_list, index=[\"A\"])\n\n        res_list = get_dummies(just_na_list, sparse=sparse)\n        res_series = get_dummies(just_na_series, sparse=sparse)\n        res_series_index = get_dummies(just_na_series_index, sparse=sparse)\n\n        assert res_list.empty\n        assert res_series.empty\n        assert res_series_index.empty\n\n        assert res_list.index.tolist() == [0]\n        assert res_series.index.tolist() == [0]\n        assert res_series_index.index.tolist() == [\"A\"]\n\n    def test_get_dummies_include_na(self, sparse, dtype):\n        s = [\"a\", \"b\", np.nan]\n        res = get_dummies(s, sparse=sparse, dtype=dtype)\n        exp = DataFrame(\n            {\"a\": [1, 0, 0], \"b\": [0, 1, 0]}, dtype=self.effective_dtype(dtype)\n        )\n        if sparse:\n            exp = exp.apply(SparseArray, fill_value=0.0)\n        tm.assert_frame_equal(res, exp)\n\n        # Sparse dataframes do not allow nan labelled columns, see #GH8822\n        res_na = get_dummies(s, dummy_na=True, sparse=sparse, dtype=dtype)\n        exp_na = DataFrame(\n            {np.nan: [0, 0, 1], \"a\": [1, 0, 0], \"b\": [0, 1, 0]},\n            dtype=self.effective_dtype(dtype),\n        )\n        exp_na = exp_na.reindex([\"a\", \"b\", np.nan], axis=1)\n        # hack (NaN handling in assert_index_equal)\n        exp_na.columns = res_na.columns\n        if sparse:\n            exp_na = exp_na.apply(SparseArray, fill_value=0.0)\n        tm.assert_frame_equal(res_na, exp_na)\n\n        res_just_na = get_dummies([np.nan], dummy_na=True, sparse=sparse, dtype=dtype)\n        exp_just_na = DataFrame(\n            Series(1, index=[0]), columns=[np.nan], dtype=self.effective_dtype(dtype)\n        )\n        tm.assert_numpy_array_equal(res_just_na.values, exp_just_na.values)\n\n    def test_get_dummies_unicode(self, sparse):\n        # See GH 6885 - get_dummies chokes on unicode values\n        import unicodedata\n\n        e = \"e\"\n        eacute = unicodedata.lookup(\"LATIN SMALL LETTER E WITH ACUTE\")\n        s = [e, eacute, eacute]\n        res = get_dummies(s, prefix=\"letter\", sparse=sparse)\n        exp = DataFrame(\n            {\"letter_e\": [True, False, False], f\"letter_{eacute}\": [False, True, True]}\n        )\n        if sparse:\n            exp = exp.apply(SparseArray, fill_value=0)\n        tm.assert_frame_equal(res, exp)\n\n    def test_dataframe_dummies_all_obj(self, df, sparse):\n        df = df[[\"A\", \"B\"]]\n        result = get_dummies(df, sparse=sparse)\n        expected = DataFrame(\n            {\"A_a\": [1, 0, 1], \"A_b\": [0, 1, 0], \"B_b\": [1, 1, 0], \"B_c\": [0, 0, 1]},\n            dtype=bool,\n        )\n        if sparse:\n            expected = DataFrame(\n                {\n                    \"A_a\": SparseArray([1, 0, 1], dtype=\"bool\"),\n                    \"A_b\": SparseArray([0, 1, 0], dtype=\"bool\"),\n                    \"B_b\": SparseArray([1, 1, 0], dtype=\"bool\"),\n                    \"B_c\": SparseArray([0, 0, 1], dtype=\"bool\"),\n                }\n            )\n\n        tm.assert_frame_equal(result, expected)\n\n    def test_dataframe_dummies_string_dtype(self, df):\n        # GH44965\n        df = df[[\"A\", \"B\"]]\n        df = df.astype({\"A\": \"object\", \"B\": \"string\"})\n        result = get_dummies(df)\n        expected = DataFrame(\n            {\n                \"A_a\": [1, 0, 1],\n                \"A_b\": [0, 1, 0],\n                \"B_b\": [1, 1, 0],\n                \"B_c\": [0, 0, 1],\n            },\n            dtype=bool,\n        )\n        tm.assert_frame_equal(result, expected)\n\n    def test_dataframe_dummies_mix_default(self, df, sparse, dtype):\n        result = get_dummies(df, sparse=sparse, dtype=dtype)\n        if sparse:\n            arr = SparseArray\n            typ = SparseDtype(dtype, 0)\n        else:\n            arr = np.array\n            typ = dtype\n        expected = DataFrame(\n            {\n                \"C\": [1, 2, 3],\n                \"A_a\": arr([1, 0, 1], dtype=typ),\n                \"A_b\": arr([0, 1, 0], dtype=typ),\n                \"B_b\": arr([1, 1, 0], dtype=typ),\n                \"B_c\": arr([0, 0, 1], dtype=typ),\n            }\n        )\n        expected = expected[[\"C\", \"A_a\", \"A_b\", \"B_b\", \"B_c\"]]\n        tm.assert_frame_equal(result, expected)\n\n    def test_dataframe_dummies_prefix_list(self, df, sparse):\n        prefixes = [\"from_A\", \"from_B\"]\n        result = get_dummies(df, prefix=prefixes, sparse=sparse)\n        expected = DataFrame(\n            {\n                \"C\": [1, 2, 3],\n                \"from_A_a\": [True, False, True],\n                \"from_A_b\": [False, True, False],\n                \"from_B_b\": [True, True, False],\n                \"from_B_c\": [False, False, True],\n            },\n        )\n        expected[[\"C\"]] = df[[\"C\"]]\n        cols = [\"from_A_a\", \"from_A_b\", \"from_B_b\", \"from_B_c\"]\n        expected = expected[[\"C\"] + cols]\n\n        typ = SparseArray if sparse else Series\n        expected[cols] = expected[cols].apply(lambda x: typ(x))\n        tm.assert_frame_equal(result, expected)\n\n    def test_dataframe_dummies_prefix_str(self, df, sparse):\n        # not that you should do this...\n        result = get_dummies(df, prefix=\"bad\", sparse=sparse)\n        bad_columns = [\"bad_a\", \"bad_b\", \"bad_b\", \"bad_c\"]\n        expected = DataFrame(\n            [\n                [1, True, False, True, False],\n                [2, False, True, True, False],\n                [3, True, False, False, True],\n            ],\n            columns=[\"C\"] + bad_columns,\n        )\n        expected = expected.astype({\"C\": np.int64})\n        if sparse:\n            # work around astyping & assigning with duplicate columns\n            # https://github.com/pandas-dev/pandas/issues/14427\n            expected = pd.concat(\n                [\n                    Series([1, 2, 3], name=\"C\"),\n                    Series([True, False, True], name=\"bad_a\", dtype=\"Sparse[bool]\"),\n                    Series([False, True, False], name=\"bad_b\", dtype=\"Sparse[bool]\"),\n                    Series([True, True, False], name=\"bad_b\", dtype=\"Sparse[bool]\"),\n                    Series([False, False, True], name=\"bad_c\", dtype=\"Sparse[bool]\"),\n                ],\n                axis=1,\n            )\n\n        tm.assert_frame_equal(result, expected)\n\n    def test_dataframe_dummies_subset(self, df, sparse):\n        result = get_dummies(df, prefix=[\"from_A\"], columns=[\"A\"], sparse=sparse)\n        expected = DataFrame(\n            {\n                \"B\": [\"b\", \"b\", \"c\"],\n                \"C\": [1, 2, 3],\n                \"from_A_a\": [1, 0, 1],\n                \"from_A_b\": [0, 1, 0],\n            },\n        )\n        cols = expected.columns\n        expected[cols[1:]] = expected[cols[1:]].astype(bool)\n        expected[[\"C\"]] = df[[\"C\"]]\n        if sparse:\n            cols = [\"from_A_a\", \"from_A_b\"]\n            expected[cols] = expected[cols].astype(SparseDtype(\"bool\", 0))\n        tm.assert_frame_equal(result, expected)\n\n    def test_dataframe_dummies_prefix_sep(self, df, sparse):\n        result = get_dummies(df, prefix_sep=\"..\", sparse=sparse)\n        expected = DataFrame(\n            {\n                \"C\": [1, 2, 3],\n                \"A..a\": [True, False, True],\n                \"A..b\": [False, True, False],\n                \"B..b\": [True, True, False],\n                \"B..c\": [False, False, True],\n            },\n        )\n        expected[[\"C\"]] = df[[\"C\"]]\n        expected = expected[[\"C\", \"A..a\", \"A..b\", \"B..b\", \"B..c\"]]\n        if sparse:\n            cols = [\"A..a\", \"A..b\", \"B..b\", \"B..c\"]\n            expected[cols] = expected[cols].astype(SparseDtype(\"bool\", 0))\n\n        tm.assert_frame_equal(result, expected)\n\n        result = get_dummies(df, prefix_sep=[\"..\", \"__\"], sparse=sparse)\n        expected = expected.rename(columns={\"B..b\": \"B__b\", \"B..c\": \"B__c\"})\n        tm.assert_frame_equal(result, expected)\n\n        result = get_dummies(df, prefix_sep={\"A\": \"..\", \"B\": \"__\"}, sparse=sparse)\n        tm.assert_frame_equal(result, expected)\n\n    def test_dataframe_dummies_prefix_bad_length(self, df, sparse):\n        msg = re.escape(\n            \"Length of 'prefix' (1) did not match the length of the columns being \"\n            \"encoded (2)\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            get_dummies(df, prefix=[\"too few\"], sparse=sparse)\n\n    def test_dataframe_dummies_prefix_sep_bad_length(self, df, sparse):\n        msg = re.escape(\n            \"Length of 'prefix_sep' (1) did not match the length of the columns being \"\n            \"encoded (2)\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            get_dummies(df, prefix_sep=[\"bad\"], sparse=sparse)\n\n    def test_dataframe_dummies_prefix_dict(self, sparse):\n        prefixes = {\"A\": \"from_A\", \"B\": \"from_B\"}\n        df = DataFrame({\"C\": [1, 2, 3], \"A\": [\"a\", \"b\", \"a\"], \"B\": [\"b\", \"b\", \"c\"]})\n        result = get_dummies(df, prefix=prefixes, sparse=sparse)\n\n        expected = DataFrame(\n            {\n                \"C\": [1, 2, 3],\n                \"from_A_a\": [1, 0, 1],\n                \"from_A_b\": [0, 1, 0],\n                \"from_B_b\": [1, 1, 0],\n                \"from_B_c\": [0, 0, 1],\n            }\n        )\n\n        columns = [\"from_A_a\", \"from_A_b\", \"from_B_b\", \"from_B_c\"]\n        expected[columns] = expected[columns].astype(bool)\n        if sparse:\n            expected[columns] = expected[columns].astype(SparseDtype(\"bool\", 0))\n\n        tm.assert_frame_equal(result, expected)\n\n    def test_dataframe_dummies_with_na(self, df, sparse, dtype):\n        df.loc[3, :] = [np.nan, np.nan, np.nan]\n        result = get_dummies(df, dummy_na=True, sparse=sparse, dtype=dtype).sort_index(\n            axis=1\n        )\n\n        if sparse:\n            arr = SparseArray\n            typ = SparseDtype(dtype, 0)\n        else:\n            arr = np.array\n            typ = dtype\n\n        expected = DataFrame(\n            {\n                \"C\": [1, 2, 3, np.nan],\n                \"A_a\": arr([1, 0, 1, 0], dtype=typ),\n                \"A_b\": arr([0, 1, 0, 0], dtype=typ),\n                \"A_nan\": arr([0, 0, 0, 1], dtype=typ),\n                \"B_b\": arr([1, 1, 0, 0], dtype=typ),\n                \"B_c\": arr([0, 0, 1, 0], dtype=typ),\n                \"B_nan\": arr([0, 0, 0, 1], dtype=typ),\n            }\n        ).sort_index(axis=1)\n\n        tm.assert_frame_equal(result, expected)\n\n        result = get_dummies(df, dummy_na=False, sparse=sparse, dtype=dtype)\n        expected = expected[[\"C\", \"A_a\", \"A_b\", \"B_b\", \"B_c\"]]\n        tm.assert_frame_equal(result, expected)\n\n    def test_dataframe_dummies_with_categorical(self, df, sparse, dtype):\n        df[\"cat\"] = Categorical([\"x\", \"y\", \"y\"])\n        result = get_dummies(df, sparse=sparse, dtype=dtype).sort_index(axis=1)\n        if sparse:\n            arr = SparseArray\n            typ = SparseDtype(dtype, 0)\n        else:\n            arr = np.array\n            typ = dtype\n\n        expected = DataFrame(\n            {\n                \"C\": [1, 2, 3],\n                \"A_a\": arr([1, 0, 1], dtype=typ),\n                \"A_b\": arr([0, 1, 0], dtype=typ),\n                \"B_b\": arr([1, 1, 0], dtype=typ),\n                \"B_c\": arr([0, 0, 1], dtype=typ),\n                \"cat_x\": arr([1, 0, 0], dtype=typ),\n                \"cat_y\": arr([0, 1, 1], dtype=typ),\n            }\n        ).sort_index(axis=1)\n\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"get_dummies_kwargs,expected\",\n        [\n            (\n                {\"data\": DataFrame({\"\": [\"a\"]})},\n                DataFrame({\"_a\": [True]}),\n            ),\n            (\n                {\"data\": DataFrame({\"x\": [\"\"]})},\n                DataFrame({\"x_\": [True]}),\n            ),\n            (\n                {\"data\": DataFrame({\"x\": [\"a\"]}), \"prefix\": \"\"},\n                DataFrame({\"_a\": [True]}),\n            ),\n            (\n                {\"data\": DataFrame({\"x\": [\"a\"]}), \"prefix_sep\": \"\"},\n                DataFrame({\"xa\": [True]}),\n            ),\n        ],\n    )\n    def test_dataframe_dummies_unicode(self, get_dummies_kwargs, expected):\n        # GH22084 get_dummies incorrectly encodes unicode characters\n        # in dataframe column names\n        result = get_dummies(**get_dummies_kwargs)\n        tm.assert_frame_equal(result, expected)\n\n    def test_get_dummies_basic_drop_first(self, sparse):\n        # GH12402 Add a new parameter `drop_first` to avoid collinearity\n        # Basic case\n        s_list = list(\"abc\")\n        s_series = Series(s_list)\n        s_series_index = Series(s_list, list(\"ABC\"))\n\n        expected = DataFrame({\"b\": [0, 1, 0], \"c\": [0, 0, 1]}, dtype=bool)\n\n        result = get_dummies(s_list, drop_first=True, sparse=sparse)\n        if sparse:\n            expected = expected.apply(SparseArray, fill_value=0)\n        tm.assert_frame_equal(result, expected)\n\n        result = get_dummies(s_series, drop_first=True, sparse=sparse)\n        tm.assert_frame_equal(result, expected)\n\n        expected.index = list(\"ABC\")\n        result = get_dummies(s_series_index, drop_first=True, sparse=sparse)\n        tm.assert_frame_equal(result, expected)\n\n    def test_get_dummies_basic_drop_first_one_level(self, sparse):\n        # Test the case that categorical variable only has one level.\n        s_list = list(\"aaa\")\n        s_series = Series(s_list)\n        s_series_index = Series(s_list, list(\"ABC\"))\n\n        expected = DataFrame(index=np.arange(3))\n\n        result = get_dummies(s_list, drop_first=True, sparse=sparse)\n        tm.assert_frame_equal(result, expected)\n\n        result = get_dummies(s_series, drop_first=True, sparse=sparse)\n        tm.assert_frame_equal(result, expected)\n\n        expected = DataFrame(index=list(\"ABC\"))\n        result = get_dummies(s_series_index, drop_first=True, sparse=sparse)\n        tm.assert_frame_equal(result, expected)\n\n    def test_get_dummies_basic_drop_first_NA(self, sparse):\n        # Test NA handling together with drop_first\n        s_NA = [\"a\", \"b\", np.nan]\n        res = get_dummies(s_NA, drop_first=True, sparse=sparse)\n        exp = DataFrame({\"b\": [0, 1, 0]}, dtype=bool)\n        if sparse:\n            exp = exp.apply(SparseArray, fill_value=0)\n\n        tm.assert_frame_equal(res, exp)\n\n        res_na = get_dummies(s_NA, dummy_na=True, drop_first=True, sparse=sparse)\n        exp_na = DataFrame({\"b\": [0, 1, 0], np.nan: [0, 0, 1]}, dtype=bool).reindex(\n            [\"b\", np.nan], axis=1\n        )\n        if sparse:\n            exp_na = exp_na.apply(SparseArray, fill_value=0)\n        tm.assert_frame_equal(res_na, exp_na)\n\n        res_just_na = get_dummies(\n            [np.nan], dummy_na=True, drop_first=True, sparse=sparse\n        )\n        exp_just_na = DataFrame(index=np.arange(1))\n        tm.assert_frame_equal(res_just_na, exp_just_na)\n\n    def test_dataframe_dummies_drop_first(self, df, sparse):\n        df = df[[\"A\", \"B\"]]\n        result = get_dummies(df, drop_first=True, sparse=sparse)\n        expected = DataFrame({\"A_b\": [0, 1, 0], \"B_c\": [0, 0, 1]}, dtype=bool)\n        if sparse:\n            expected = expected.apply(SparseArray, fill_value=0)\n        tm.assert_frame_equal(result, expected)\n\n    def test_dataframe_dummies_drop_first_with_categorical(self, df, sparse, dtype):\n        df[\"cat\"] = Categorical([\"x\", \"y\", \"y\"])\n        result = get_dummies(df, drop_first=True, sparse=sparse)\n        expected = DataFrame(\n            {\"C\": [1, 2, 3], \"A_b\": [0, 1, 0], \"B_c\": [0, 0, 1], \"cat_y\": [0, 1, 1]}\n        )\n        cols = [\"A_b\", \"B_c\", \"cat_y\"]\n        expected[cols] = expected[cols].astype(bool)\n        expected = expected[[\"C\", \"A_b\", \"B_c\", \"cat_y\"]]\n        if sparse:\n            for col in cols:\n                expected[col] = SparseArray(expected[col])\n        tm.assert_frame_equal(result, expected)\n\n    def test_dataframe_dummies_drop_first_with_na(self, df, sparse):\n        df.loc[3, :] = [np.nan, np.nan, np.nan]\n        result = get_dummies(\n            df, dummy_na=True, drop_first=True, sparse=sparse\n        ).sort_index(axis=1)\n        expected = DataFrame(\n            {\n                \"C\": [1, 2, 3, np.nan],\n                \"A_b\": [0, 1, 0, 0],\n                \"A_nan\": [0, 0, 0, 1],\n                \"B_c\": [0, 0, 1, 0],\n                \"B_nan\": [0, 0, 0, 1],\n            }\n        )\n        cols = [\"A_b\", \"A_nan\", \"B_c\", \"B_nan\"]\n        expected[cols] = expected[cols].astype(bool)\n        expected = expected.sort_index(axis=1)\n        if sparse:\n            for col in cols:\n                expected[col] = SparseArray(expected[col])\n\n        tm.assert_frame_equal(result, expected)\n\n        result = get_dummies(df, dummy_na=False, drop_first=True, sparse=sparse)\n        expected = expected[[\"C\", \"A_b\", \"B_c\"]]\n        tm.assert_frame_equal(result, expected)\n\n    def test_get_dummies_int_int(self):\n        data = Series([1, 2, 1])\n        result = get_dummies(data)\n        expected = DataFrame([[1, 0], [0, 1], [1, 0]], columns=[1, 2], dtype=bool)\n        tm.assert_frame_equal(result, expected)\n\n        data = Series(Categorical([\"a\", \"b\", \"a\"]))\n        result = get_dummies(data)\n        expected = DataFrame(\n            [[1, 0], [0, 1], [1, 0]], columns=Categorical([\"a\", \"b\"]), dtype=bool\n        )\n        tm.assert_frame_equal(result, expected)\n\n    def test_get_dummies_int_df(self, dtype):\n        data = DataFrame(\n            {\n                \"A\": [1, 2, 1],\n                \"B\": Categorical([\"a\", \"b\", \"a\"]),\n                \"C\": [1, 2, 1],\n                \"D\": [1.0, 2.0, 1.0],\n            }\n        )\n        columns = [\"C\", \"D\", \"A_1\", \"A_2\", \"B_a\", \"B_b\"]\n        expected = DataFrame(\n            [[1, 1.0, 1, 0, 1, 0], [2, 2.0, 0, 1, 0, 1], [1, 1.0, 1, 0, 1, 0]],\n            columns=columns,\n        )\n        expected[columns[2:]] = expected[columns[2:]].astype(dtype)\n        result = get_dummies(data, columns=[\"A\", \"B\"], dtype=dtype)\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\"ordered\", [True, False])\n    def test_dataframe_dummies_preserve_categorical_dtype(self, dtype, ordered):\n        # GH13854\n        cat = Categorical(list(\"xy\"), categories=list(\"xyz\"), ordered=ordered)\n        result = get_dummies(cat, dtype=dtype)\n\n        data = np.array([[1, 0, 0], [0, 1, 0]], dtype=self.effective_dtype(dtype))\n        cols = CategoricalIndex(\n            cat.categories, categories=cat.categories, ordered=ordered\n        )\n        expected = DataFrame(data, columns=cols, dtype=self.effective_dtype(dtype))\n\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\"sparse\", [True, False])\n    def test_get_dummies_dont_sparsify_all_columns(self, sparse):\n        # GH18914\n        df = DataFrame.from_dict({\"GDP\": [1, 2], \"Nation\": [\"AB\", \"CD\"]})\n        df = get_dummies(df, columns=[\"Nation\"], sparse=sparse)\n        df2 = df.reindex(columns=[\"GDP\"])\n\n        tm.assert_frame_equal(df[[\"GDP\"]], df2)\n\n    def test_get_dummies_duplicate_columns(self, df):\n        # GH20839\n        df.columns = [\"A\", \"A\", \"A\"]\n        result = get_dummies(df).sort_index(axis=1)\n\n        expected = DataFrame(\n            [\n                [1, True, False, True, False],\n                [2, False, True, True, False],\n                [3, True, False, False, True],\n            ],\n            columns=[\"A\", \"A_a\", \"A_b\", \"A_b\", \"A_c\"],\n        ).sort_index(axis=1)\n\n        expected = expected.astype({\"A\": np.int64})\n\n        tm.assert_frame_equal(result, expected)\n\n    def test_get_dummies_all_sparse(self):\n        df = DataFrame({\"A\": [1, 2]})\n        result = get_dummies(df, columns=[\"A\"], sparse=True)\n        dtype = SparseDtype(\"bool\", 0)\n        expected = DataFrame(\n            {\n                \"A_1\": SparseArray([1, 0], dtype=dtype),\n                \"A_2\": SparseArray([0, 1], dtype=dtype),\n            }\n        )\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\"values\", [\"baz\"])\n    def test_get_dummies_with_string_values(self, values):\n        # issue #28383\n        df = DataFrame(\n            {\n                \"bar\": [1, 2, 3, 4, 5, 6],\n                \"foo\": [\"one\", \"one\", \"one\", \"two\", \"two\", \"two\"],\n                \"baz\": [\"A\", \"B\", \"C\", \"A\", \"B\", \"C\"],\n                \"zoo\": [\"x\", \"y\", \"z\", \"q\", \"w\", \"t\"],\n            }\n        )\n\n        msg = \"Input must be a list-like for parameter `columns`\"\n\n        with pytest.raises(TypeError, match=msg):\n            get_dummies(df, columns=values)\n"
    }
  ],
  "questions": [
    "@pandas-dev/pandas-core anyone got any objections to changing the default type? Any reason to not just make the default type `bool`? Then, the return type would be clear, and if people need to do arithmetic operations on the dummy values, they can do their own dtype conversion. But at least they wouldn't run into unexpected behaviour like this\r\n\r\nGeneral suggestion for others who would like this changed: please use reactions to express support, no need to add comments just indicating that you'd also like to see this",
    "> bool is a problem as doesn't play nice with missing values\r\n\r\nSure, but why would `get_dummies` return a missing value anyway? Unless I'm missing something, the return values would always be `0` or `1`",
    "Thanks @bashtage \r\n\r\n> float is probably the most sensible (between int64 and float) since it has the same storage requirements and handles nan fine.\r\n\r\nRegarding handling `nan` - is there an example of a case when `get_dummies` returns `nan`? If not, then `bool` should be fine, right?",
    "Would this change also apply to `Series.str.get_dummies()`?"
  ],
  "golden_answers": [
    "> bool is a problem as doesn't play nice with missing values\r\n\r\nSure, but why would `get_dummies` return a missing value anyway? Unless I'm missing something, the return values would always be `0` or `1`",
    "IMO you either go with `int64` or just make them `float`, if you want to move away from the idea of using the smallest int dtype that can represent the encoded categorical variable. `float` is probably the most sensible (between `int64` and `float`) since it has the same storage requirements and handles `nan` fine.",
    "@willkurt do you want to open a PR for this? This'd involve:\r\n\r\n- in `pandas/tests/reshape/test_get_dummies.py`, for tests which don't already specify a `dtype`, pass `np.dtype(np.uint8)`\r\n- add a test which doesn't specify a `dtype`, and assert that a `FutureWarning` with a message like \"the default dtype will change from `'uint8'` to `'bool', please specify a `dtype` to silence this warning` is raised\r\n- in `pandas/core/reshape/encoding.py`, in `_get_dummies_1d`, add a `FutureWarning` with a message like the above if `dtype` wasn't passed by the user\r\n\r\nNot strictly necessary, but I think `dtype=None` could also be changed to `dtype=lib.no_default`\r\n\r\nSounds like there's agreement on changing the default type away from `uint8`, we can always revisit the message about what it'll be changed to in the PR review\r\n\r\nIf anyone wants to work on this, [here](https://pandas.pydata.org/docs/development/contributing.html)'s the contributing guide, and feel free to ask for help if anything's unclear",
    "that's a good point, `.str.get_dummies` still defaults to `int64` - want to open a separate issue about changing that to bool too?"
  ],
  "questions_generated": [
    "What is the default dtype used by the pd.get_dummies function, and why might this be problematic for some operations?",
    "In the context of the pd.get_dummies function, what is the likely reason for choosing np.uint8 as the default dtype?",
    "What enhancement is being proposed for the pd.get_dummies function, and what is the motivation behind it?",
    "How does the current issue relate to the documented behavior of pd.get_dummies, and why is it considered an enhancement rather than a bug?",
    "What information was requested from the issue reporter to facilitate the discussion, and why is this information important?"
  ],
  "golden_answers_generated": [
    "The default dtype used by pd.get_dummies is np.uint8. This can be problematic because it is an unsigned integer type, meaning that operations like subtracting 1 from 0 can result in unexpected values such as 255 due to underflow, which is typically not the desired behavior for many users.",
    "The likely reason for choosing np.uint8 as the default dtype in pd.get_dummies is to reduce memory usage. Since np.uint8 is an 8-bit unsigned integer, it requires less memory compared to larger integer types, which can be beneficial when dealing with large and potentially sparse matrices.",
    "The enhancement being proposed is to change the default dtype from np.uint8 to a signed integer type. The motivation behind this is to prevent unexpected behavior, such as underflow resulting in 255 when subtracting one from zero, which users do not typically expect and can lead to severe 'gotcha' moments in common use cases like vector subtraction.",
    "The issue relates to the documented behavior of pd.get_dummies in that the use of np.uint8 is the intended and documented default. It is considered an enhancement rather than a bug because the function is working as documented; however, the default behavior is unexpected and undesirable for many users, prompting a suggestion for improvement.",
    "The issue reporter was asked to provide the output of pd.show_versions and a reproducible example. This information is important because it helps maintainers understand the environment in which the issue was observed, ensuring that any proposed changes or troubleshooting steps are relevant to the reporter's specific setup. It also aids in verifying that the behavior is consistent across different setups."
  ]
}