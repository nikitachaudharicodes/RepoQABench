{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "12857",
  "issue_description": "# BUG: not properly converting S1 in astype ,on PY3\n\nI am trying to create a dataframe where each cell is represented as a single characters rather than python objects. I am able to create and work with the dataframe when using .astype command. However, If i try to print out a larger portion of the table, then I get an error.\n#### Code Sample, a copy-pastable example if possible\n\n```\nimport random\nimport pandas as pd\nlets = 'ACDEFGHIJKLMNOP'\nslen = 50\nnseqs = 1000\nwords = [[random.choice(lets) for x in range(slen)] for _ in range(nseqs)]\ndf = pd.DataFrame(words).astype('S1')\n#this will print correctly:\nprint(df.iloc[:60, :])\n#this will raise an error:\nprint(df.iloc[:61, :])\n```\n#### error raised\n\n```\nC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in _vstack(to_stack, dtype)\n   4248 \n   4249     # work around NumPy 1.6 bug\n-> 4250     if dtype == _NS_DTYPE or dtype == _TD_DTYPE:\n   4251         new_values = np.vstack([x.view('i8') for x in to_stack])\n   4252         return new_values.view(dtype)\nTypeError: data type \"bytes8\" not understood\n```\n#### output of `pd.show_versions()`\n\ncommit: None\npython: 3.4.4.final.0\npython-bits: 64\nOS: Windows\nOS-release: 7\nmachine: AMD64\nprocessor: Intel64 Family 6 Model 61 Stepping 4, GenuineIntel\nbyteorder: little\nLC_ALL: None\nLANG: None\n\npandas: 0.17.1\nnose: None\npip: 8.1.1\nsetuptools: 20.3\nCython: 0.23.4\nnumpy: 1.10.4\nscipy: 0.17.0\nstatsmodels: 0.6.1\nIPython: 4.1.1\nsphinx: 1.4b1\npatsy: 0.4.0\ndateutil: 2.4.2\npytz: 2015.7\nblosc: None\nbottleneck: 1.0.0\ntables: 3.2.2\nnumexpr: 2.4.6\nmatplotlib: 1.5.1\nopenpyxl: 2.3.2\nxlrd: 0.9.4\nxlwt: 1.0.0\nxlsxwriter: 0.8.4\nlxml: 3.5.0\nbs4: 4.4.1\nhtml5lib: None\nhttplib2: None\napiclient: None\nsqlalchemy: 1.0.11\npymysql: None\npsycopg2: None\nJinja2: 2.8\n",
  "issue_comments": [
    {
      "id": 208294917,
      "user": "jorisvandenbossche",
      "body": "@costas821 I cannot reproduce this (also using Windows 7, pandas 0.17.1). If you run the above code sample in a new session, you get that error?\n"
    },
    {
      "id": 208318582,
      "user": "jreback",
      "body": "this fails on the astype. dtype `S1`(and all fixed sized string dtypes are) not supported and should be converted to `object`. Kind of puzzled why this is not. So I'll mark this as a bug.\n"
    },
    {
      "id": 208319570,
      "user": "jreback",
      "body": "So `.astype('U1')` works as excepted (IOW it coerces to `object`), but we need to either raise on `S` dtypes in PY3 I think (or just coerce as we do unicode), though the user is technically saying that want to encode.\n"
    },
    {
      "id": 208332370,
      "user": "cchrysostomou",
      "body": "Well I was kind of hoping that datatype could be supported. When its represented as an object, the memory it takes up is extremely high when all I need is for for each cell to take up a single byte. Everything except for 'printing' seemed to work for me. Is there any work-around for this? \n"
    },
    {
      "id": 208335893,
      "user": "jreback",
      "body": "you are much better off using categoricals\n\n```\n# your frame\nIn [17]: df.memory_usage(deep=True).sum()\nOut[17]: 2300072\n\nIn [18]: uniques = np.sort(pd.unique(df.values.ravel()))\n\n# converted to categoricals (I happen to preserver the mappings, but its actually not necessary)\nIn [19]: df.apply(lambda x: x.astype('category',categories=uniques)).memory_usage(deep=True).sum()\nOut[19]: 84572\n```\n"
    },
    {
      "id": 208379463,
      "user": "cchrysostomou",
      "body": "OK I can go that route, but now I am having some functionality issues. Some things that worked before, no longer work when I set it as a category. If you don't think this is pertinent to the issue, then should I just send you a personal message of what I am trying to do and some sample code?\n\n```\n#  set my frame as category\nuniques = np.sort(pd.unique(df.values.ravel()))\ndf = df.apply(lambda x: x.astype('category', categories=uniques))\n\n# slicing and search operations\ndf_ints = pd.DataFrame(np.zeros((10000, 500)))\ndf_ints[5,3] = 1\n# when df is a category, I cannot do the following\ndf[df_ints==0] = 'Z'  \n# this also raises an error\ndf_ints == 'A'\n```\n"
    },
    {
      "id": 208384949,
      "user": "jreback",
      "body": "categoricals have a sets that are allowed, IOW, to the `categories` themselves. You can \n\n```\nIn [75]: df2 = df.apply(lambda x: x.astype('category', categories=uniques.tolist() + ['Z']))\n\nIn [77]: df2.iloc[0,1] = 'Z'\n```\n"
    },
    {
      "id": 208386958,
      "user": "cchrysostomou",
      "body": "Whoops that was a bad example, my mistake. What I was trying to show was that I cannot use the dataframe df_ints to change values:\n\n`df[df_ints==0] = 'A'  # where 'A' is already defined in set.`\nor find where df is a:\n`df[df=='A']\n`\n"
    },
    {
      "id": 208394783,
      "user": "jreback",
      "body": "hmm, that should work, see #12861 . well good of you to test this out!\nIn the meantime you can do `.astype('U1')` to save some memory (or of course pull-requests to fix issues always welcome!)\n"
    },
    {
      "id": 466251035,
      "user": "mroeschke",
      "body": "This looks fixed on master. Could use a test."
    },
    {
      "id": 502362123,
      "user": "topper-123",
      "body": "Removing the p2/p3 compat label, as Python2 is being dropped and this issue still needs tests."
    },
    {
      "id": 569690481,
      "user": "TomAugspurger",
      "body": "This was fixed by https://github.com/pandas-dev/pandas/pull/30327 (https://github.com/pandas-dev/pandas/commit/ccbe7be367e970dcbcd526f6b883b9db20979638 specifically I think)."
    }
  ],
  "text_context": "# BUG: not properly converting S1 in astype ,on PY3\n\nI am trying to create a dataframe where each cell is represented as a single characters rather than python objects. I am able to create and work with the dataframe when using .astype command. However, If i try to print out a larger portion of the table, then I get an error.\n#### Code Sample, a copy-pastable example if possible\n\n```\nimport random\nimport pandas as pd\nlets = 'ACDEFGHIJKLMNOP'\nslen = 50\nnseqs = 1000\nwords = [[random.choice(lets) for x in range(slen)] for _ in range(nseqs)]\ndf = pd.DataFrame(words).astype('S1')\n#this will print correctly:\nprint(df.iloc[:60, :])\n#this will raise an error:\nprint(df.iloc[:61, :])\n```\n#### error raised\n\n```\nC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in _vstack(to_stack, dtype)\n   4248 \n   4249     # work around NumPy 1.6 bug\n-> 4250     if dtype == _NS_DTYPE or dtype == _TD_DTYPE:\n   4251         new_values = np.vstack([x.view('i8') for x in to_stack])\n   4252         return new_values.view(dtype)\nTypeError: data type \"bytes8\" not understood\n```\n#### output of `pd.show_versions()`\n\ncommit: None\npython: 3.4.4.final.0\npython-bits: 64\nOS: Windows\nOS-release: 7\nmachine: AMD64\nprocessor: Intel64 Family 6 Model 61 Stepping 4, GenuineIntel\nbyteorder: little\nLC_ALL: None\nLANG: None\n\npandas: 0.17.1\nnose: None\npip: 8.1.1\nsetuptools: 20.3\nCython: 0.23.4\nnumpy: 1.10.4\nscipy: 0.17.0\nstatsmodels: 0.6.1\nIPython: 4.1.1\nsphinx: 1.4b1\npatsy: 0.4.0\ndateutil: 2.4.2\npytz: 2015.7\nblosc: None\nbottleneck: 1.0.0\ntables: 3.2.2\nnumexpr: 2.4.6\nmatplotlib: 1.5.1\nopenpyxl: 2.3.2\nxlrd: 0.9.4\nxlwt: 1.0.0\nxlsxwriter: 0.8.4\nlxml: 3.5.0\nbs4: 4.4.1\nhtml5lib: None\nhttplib2: None\napiclient: None\nsqlalchemy: 1.0.11\npymysql: None\npsycopg2: None\nJinja2: 2.8\n\n\n@costas821 I cannot reproduce this (also using Windows 7, pandas 0.17.1). If you run the above code sample in a new session, you get that error?\n\n\nthis fails on the astype. dtype `S1`(and all fixed sized string dtypes are) not supported and should be converted to `object`. Kind of puzzled why this is not. So I'll mark this as a bug.\n\n\nSo `.astype('U1')` works as excepted (IOW it coerces to `object`), but we need to either raise on `S` dtypes in PY3 I think (or just coerce as we do unicode), though the user is technically saying that want to encode.\n\n\nWell I was kind of hoping that datatype could be supported. When its represented as an object, the memory it takes up is extremely high when all I need is for for each cell to take up a single byte. Everything except for 'printing' seemed to work for me. Is there any work-around for this? \n\n\nyou are much better off using categoricals\n\n```\n# your frame\nIn [17]: df.memory_usage(deep=True).sum()\nOut[17]: 2300072\n\nIn [18]: uniques = np.sort(pd.unique(df.values.ravel()))\n\n# converted to categoricals (I happen to preserver the mappings, but its actually not necessary)\nIn [19]: df.apply(lambda x: x.astype('category',categories=uniques)).memory_usage(deep=True).sum()\nOut[19]: 84572\n```\n\n\nOK I can go that route, but now I am having some functionality issues. Some things that worked before, no longer work when I set it as a category. If you don't think this is pertinent to the issue, then should I just send you a personal message of what I am trying to do and some sample code?\n\n```\n#  set my frame as category\nuniques = np.sort(pd.unique(df.values.ravel()))\ndf = df.apply(lambda x: x.astype('category', categories=uniques))\n\n# slicing and search operations\ndf_ints = pd.DataFrame(np.zeros((10000, 500)))\ndf_ints[5,3] = 1\n# when df is a category, I cannot do the following\ndf[df_ints==0] = 'Z'  \n# this also raises an error\ndf_ints == 'A'\n```\n\n\ncategoricals have a sets that are allowed, IOW, to the `categories` themselves. You can \n\n```\nIn [75]: df2 = df.apply(lambda x: x.astype('category', categories=uniques.tolist() + ['Z']))\n\nIn [77]: df2.iloc[0,1] = 'Z'\n```\n\n\nWhoops that was a bad example, my mistake. What I was trying to show was that I cannot use the dataframe df_ints to change values:\n\n`df[df_ints==0] = 'A'  # where 'A' is already defined in set.`\nor find where df is a:\n`df[df=='A']\n`\n\n\nhmm, that should work, see #12861 . well good of you to test this out!\nIn the meantime you can do `.astype('U1')` to save some memory (or of course pull-requests to fix issues always welcome!)\n\n\nThis looks fixed on master. Could use a test.\n\nRemoving the p2/p3 compat label, as Python2 is being dropped and this issue still needs tests.\n\nThis was fixed by https://github.com/pandas-dev/pandas/pull/30327 (https://github.com/pandas-dev/pandas/commit/ccbe7be367e970dcbcd526f6b883b9db20979638 specifically I think).",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/30327",
  "code_context": [
    {
      "filename": "pandas/tests/frame/test_arithmetic.py",
      "content": "from collections import deque\nfrom datetime import datetime\nimport operator\n\nimport numpy as np\nimport pytest\n\nimport pandas as pd\nfrom pandas.tests.frame.common import _check_mixed_float, _check_mixed_int\nimport pandas.util.testing as tm\n\n# -------------------------------------------------------------------\n# Comparisons\n\n\nclass TestFrameComparisons:\n    # Specifically _not_ flex-comparisons\n\n    def test_frame_in_list(self):\n        # GH#12689 this should raise at the DataFrame level, not blocks\n        df = pd.DataFrame(np.random.randn(6, 4), columns=list(\"ABCD\"))\n        msg = \"The truth value of a DataFrame is ambiguous\"\n        with pytest.raises(ValueError, match=msg):\n            df in [None]\n\n    def test_comparison_invalid(self):\n        def check(df, df2):\n\n            for (x, y) in [(df, df2), (df2, df)]:\n                # we expect the result to match Series comparisons for\n                # == and !=, inequalities should raise\n                result = x == y\n                expected = pd.DataFrame(\n                    {col: x[col] == y[col] for col in x.columns},\n                    index=x.index,\n                    columns=x.columns,\n                )\n                tm.assert_frame_equal(result, expected)\n\n                result = x != y\n                expected = pd.DataFrame(\n                    {col: x[col] != y[col] for col in x.columns},\n                    index=x.index,\n                    columns=x.columns,\n                )\n                tm.assert_frame_equal(result, expected)\n\n                with pytest.raises(TypeError):\n                    x >= y\n                with pytest.raises(TypeError):\n                    x > y\n                with pytest.raises(TypeError):\n                    x < y\n                with pytest.raises(TypeError):\n                    x <= y\n\n        # GH4968\n        # invalid date/int comparisons\n        df = pd.DataFrame(np.random.randint(10, size=(10, 1)), columns=[\"a\"])\n        df[\"dates\"] = pd.date_range(\"20010101\", periods=len(df))\n\n        df2 = df.copy()\n        df2[\"dates\"] = df[\"a\"]\n        check(df, df2)\n\n        df = pd.DataFrame(np.random.randint(10, size=(10, 2)), columns=[\"a\", \"b\"])\n        df2 = pd.DataFrame(\n            {\n                \"a\": pd.date_range(\"20010101\", periods=len(df)),\n                \"b\": pd.date_range(\"20100101\", periods=len(df)),\n            }\n        )\n        check(df, df2)\n\n    def test_timestamp_compare(self):\n        # make sure we can compare Timestamps on the right AND left hand side\n        # GH#4982\n        df = pd.DataFrame(\n            {\n                \"dates1\": pd.date_range(\"20010101\", periods=10),\n                \"dates2\": pd.date_range(\"20010102\", periods=10),\n                \"intcol\": np.random.randint(1000000000, size=10),\n                \"floatcol\": np.random.randn(10),\n                \"stringcol\": list(tm.rands(10)),\n            }\n        )\n        df.loc[np.random.rand(len(df)) > 0.5, \"dates2\"] = pd.NaT\n        ops = {\"gt\": \"lt\", \"lt\": \"gt\", \"ge\": \"le\", \"le\": \"ge\", \"eq\": \"eq\", \"ne\": \"ne\"}\n\n        for left, right in ops.items():\n            left_f = getattr(operator, left)\n            right_f = getattr(operator, right)\n\n            # no nats\n            if left in [\"eq\", \"ne\"]:\n                expected = left_f(df, pd.Timestamp(\"20010109\"))\n                result = right_f(pd.Timestamp(\"20010109\"), df)\n                tm.assert_frame_equal(result, expected)\n            else:\n                with pytest.raises(TypeError):\n                    left_f(df, pd.Timestamp(\"20010109\"))\n                with pytest.raises(TypeError):\n                    right_f(pd.Timestamp(\"20010109\"), df)\n            # nats\n            expected = left_f(df, pd.Timestamp(\"nat\"))\n            result = right_f(pd.Timestamp(\"nat\"), df)\n            tm.assert_frame_equal(result, expected)\n\n    def test_mixed_comparison(self):\n        # GH#13128, GH#22163 != datetime64 vs non-dt64 should be False,\n        # not raise TypeError\n        # (this appears to be fixed before GH#22163, not sure when)\n        df = pd.DataFrame([[\"1989-08-01\", 1], [\"1989-08-01\", 2]])\n        other = pd.DataFrame([[\"a\", \"b\"], [\"c\", \"d\"]])\n\n        result = df == other\n        assert not result.any().any()\n\n        result = df != other\n        assert result.all().all()\n\n    def test_df_boolean_comparison_error(self):\n        # GH#4576, GH#22880\n        # comparing DataFrame against list/tuple with len(obj) matching\n        #  len(df.columns) is supported as of GH#22800\n        df = pd.DataFrame(np.arange(6).reshape((3, 2)))\n\n        expected = pd.DataFrame([[False, False], [True, False], [False, False]])\n\n        result = df == (2, 2)\n        tm.assert_frame_equal(result, expected)\n\n        result = df == [2, 2]\n        tm.assert_frame_equal(result, expected)\n\n    def test_df_float_none_comparison(self):\n        df = pd.DataFrame(\n            np.random.randn(8, 3), index=range(8), columns=[\"A\", \"B\", \"C\"]\n        )\n\n        result = df.__eq__(None)\n        assert not result.any().any()\n\n    def test_df_string_comparison(self):\n        df = pd.DataFrame([{\"a\": 1, \"b\": \"foo\"}, {\"a\": 2, \"b\": \"bar\"}])\n        mask_a = df.a > 1\n        tm.assert_frame_equal(df[mask_a], df.loc[1:1, :])\n        tm.assert_frame_equal(df[-mask_a], df.loc[0:0, :])\n\n        mask_b = df.b == \"foo\"\n        tm.assert_frame_equal(df[mask_b], df.loc[0:0, :])\n        tm.assert_frame_equal(df[-mask_b], df.loc[1:1, :])\n\n\nclass TestFrameFlexComparisons:\n    # TODO: test_bool_flex_frame needs a better name\n    def test_bool_flex_frame(self):\n        data = np.random.randn(5, 3)\n        other_data = np.random.randn(5, 3)\n        df = pd.DataFrame(data)\n        other = pd.DataFrame(other_data)\n        ndim_5 = np.ones(df.shape + (1, 3))\n\n        # Unaligned\n        def _check_unaligned_frame(meth, op, df, other):\n            part_o = other.loc[3:, 1:].copy()\n            rs = meth(part_o)\n            xp = op(df, part_o.reindex(index=df.index, columns=df.columns))\n            tm.assert_frame_equal(rs, xp)\n\n        # DataFrame\n        assert df.eq(df).values.all()\n        assert not df.ne(df).values.any()\n        for op in [\"eq\", \"ne\", \"gt\", \"lt\", \"ge\", \"le\"]:\n            f = getattr(df, op)\n            o = getattr(operator, op)\n            # No NAs\n            tm.assert_frame_equal(f(other), o(df, other))\n            _check_unaligned_frame(f, o, df, other)\n            # ndarray\n            tm.assert_frame_equal(f(other.values), o(df, other.values))\n            # scalar\n            tm.assert_frame_equal(f(0), o(df, 0))\n            # NAs\n            msg = \"Unable to coerce to Series/DataFrame\"\n            tm.assert_frame_equal(f(np.nan), o(df, np.nan))\n            with pytest.raises(ValueError, match=msg):\n                f(ndim_5)\n\n        # Series\n        def _test_seq(df, idx_ser, col_ser):\n            idx_eq = df.eq(idx_ser, axis=0)\n            col_eq = df.eq(col_ser)\n            idx_ne = df.ne(idx_ser, axis=0)\n            col_ne = df.ne(col_ser)\n            tm.assert_frame_equal(col_eq, df == pd.Series(col_ser))\n            tm.assert_frame_equal(col_eq, -col_ne)\n            tm.assert_frame_equal(idx_eq, -idx_ne)\n            tm.assert_frame_equal(idx_eq, df.T.eq(idx_ser).T)\n            tm.assert_frame_equal(col_eq, df.eq(list(col_ser)))\n            tm.assert_frame_equal(idx_eq, df.eq(pd.Series(idx_ser), axis=0))\n            tm.assert_frame_equal(idx_eq, df.eq(list(idx_ser), axis=0))\n\n            idx_gt = df.gt(idx_ser, axis=0)\n            col_gt = df.gt(col_ser)\n            idx_le = df.le(idx_ser, axis=0)\n            col_le = df.le(col_ser)\n\n            tm.assert_frame_equal(col_gt, df > pd.Series(col_ser))\n            tm.assert_frame_equal(col_gt, -col_le)\n            tm.assert_frame_equal(idx_gt, -idx_le)\n            tm.assert_frame_equal(idx_gt, df.T.gt(idx_ser).T)\n\n            idx_ge = df.ge(idx_ser, axis=0)\n            col_ge = df.ge(col_ser)\n            idx_lt = df.lt(idx_ser, axis=0)\n            col_lt = df.lt(col_ser)\n            tm.assert_frame_equal(col_ge, df >= pd.Series(col_ser))\n            tm.assert_frame_equal(col_ge, -col_lt)\n            tm.assert_frame_equal(idx_ge, -idx_lt)\n            tm.assert_frame_equal(idx_ge, df.T.ge(idx_ser).T)\n\n        idx_ser = pd.Series(np.random.randn(5))\n        col_ser = pd.Series(np.random.randn(3))\n        _test_seq(df, idx_ser, col_ser)\n\n        # list/tuple\n        _test_seq(df, idx_ser.values, col_ser.values)\n\n        # NA\n        df.loc[0, 0] = np.nan\n        rs = df.eq(df)\n        assert not rs.loc[0, 0]\n        rs = df.ne(df)\n        assert rs.loc[0, 0]\n        rs = df.gt(df)\n        assert not rs.loc[0, 0]\n        rs = df.lt(df)\n        assert not rs.loc[0, 0]\n        rs = df.ge(df)\n        assert not rs.loc[0, 0]\n        rs = df.le(df)\n        assert not rs.loc[0, 0]\n\n    def test_bool_flex_frame_complex_dtype(self):\n        # complex\n        arr = np.array([np.nan, 1, 6, np.nan])\n        arr2 = np.array([2j, np.nan, 7, None])\n        df = pd.DataFrame({\"a\": arr})\n        df2 = pd.DataFrame({\"a\": arr2})\n\n        msg = \"|\".join(\n            [\n                \"'>' not supported between instances of '.*' and 'complex'\",\n                r\"unorderable types: .*complex\\(\\)\",  # PY35\n            ]\n        )\n        with pytest.raises(TypeError, match=msg):\n            # inequalities are not well-defined for complex numbers\n            df.gt(df2)\n        with pytest.raises(TypeError, match=msg):\n            # regression test that we get the same behavior for Series\n            df[\"a\"].gt(df2[\"a\"])\n        with pytest.raises(TypeError, match=msg):\n            # Check that we match numpy behavior here\n            df.values > df2.values\n\n        rs = df.ne(df2)\n        assert rs.values.all()\n\n        arr3 = np.array([2j, np.nan, None])\n        df3 = pd.DataFrame({\"a\": arr3})\n\n        with pytest.raises(TypeError, match=msg):\n            # inequalities are not well-defined for complex numbers\n            df3.gt(2j)\n        with pytest.raises(TypeError, match=msg):\n            # regression test that we get the same behavior for Series\n            df3[\"a\"].gt(2j)\n        with pytest.raises(TypeError, match=msg):\n            # Check that we match numpy behavior here\n            df3.values > 2j\n\n    def test_bool_flex_frame_object_dtype(self):\n        # corner, dtype=object\n        df1 = pd.DataFrame({\"col\": [\"foo\", np.nan, \"bar\"]})\n        df2 = pd.DataFrame({\"col\": [\"foo\", datetime.now(), \"bar\"]})\n        result = df1.ne(df2)\n        exp = pd.DataFrame({\"col\": [False, True, False]})\n        tm.assert_frame_equal(result, exp)\n\n    def test_flex_comparison_nat(self):\n        # GH 15697, GH 22163 df.eq(pd.NaT) should behave like df == pd.NaT,\n        # and _definitely_ not be NaN\n        df = pd.DataFrame([pd.NaT])\n\n        result = df == pd.NaT\n        # result.iloc[0, 0] is a np.bool_ object\n        assert result.iloc[0, 0].item() is False\n\n        result = df.eq(pd.NaT)\n        assert result.iloc[0, 0].item() is False\n\n        result = df != pd.NaT\n        assert result.iloc[0, 0].item() is True\n\n        result = df.ne(pd.NaT)\n        assert result.iloc[0, 0].item() is True\n\n    @pytest.mark.parametrize(\"opname\", [\"eq\", \"ne\", \"gt\", \"lt\", \"ge\", \"le\"])\n    def test_df_flex_cmp_constant_return_types(self, opname):\n        # GH 15077, non-empty DataFrame\n        df = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [1.0, 2.0, 3.0]})\n        const = 2\n\n        result = getattr(df, opname)(const).dtypes.value_counts()\n        tm.assert_series_equal(result, pd.Series([2], index=[np.dtype(bool)]))\n\n    @pytest.mark.parametrize(\"opname\", [\"eq\", \"ne\", \"gt\", \"lt\", \"ge\", \"le\"])\n    def test_df_flex_cmp_constant_return_types_empty(self, opname):\n        # GH 15077 empty DataFrame\n        df = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [1.0, 2.0, 3.0]})\n        const = 2\n\n        empty = df.iloc[:0]\n        result = getattr(empty, opname)(const).dtypes.value_counts()\n        tm.assert_series_equal(result, pd.Series([2], index=[np.dtype(bool)]))\n\n\n# -------------------------------------------------------------------\n# Arithmetic\n\n\nclass TestFrameFlexArithmetic:\n    def test_df_add_td64_columnwise(self):\n        # GH 22534 Check that column-wise addition broadcasts correctly\n        dti = pd.date_range(\"2016-01-01\", periods=10)\n        tdi = pd.timedelta_range(\"1\", periods=10)\n        tser = pd.Series(tdi)\n        df = pd.DataFrame({0: dti, 1: tdi})\n\n        result = df.add(tser, axis=0)\n        expected = pd.DataFrame({0: dti + tdi, 1: tdi + tdi})\n        tm.assert_frame_equal(result, expected)\n\n    def test_df_add_flex_filled_mixed_dtypes(self):\n        # GH 19611\n        dti = pd.date_range(\"2016-01-01\", periods=3)\n        ser = pd.Series([\"1 Day\", \"NaT\", \"2 Days\"], dtype=\"timedelta64[ns]\")\n        df = pd.DataFrame({\"A\": dti, \"B\": ser})\n        other = pd.DataFrame({\"A\": ser, \"B\": ser})\n        fill = pd.Timedelta(days=1).to_timedelta64()\n        result = df.add(other, fill_value=fill)\n\n        expected = pd.DataFrame(\n            {\n                \"A\": pd.Series(\n                    [\"2016-01-02\", \"2016-01-03\", \"2016-01-05\"], dtype=\"datetime64[ns]\"\n                ),\n                \"B\": ser * 2,\n            }\n        )\n        tm.assert_frame_equal(result, expected)\n\n    def test_arith_flex_frame(\n        self, all_arithmetic_operators, float_frame, mixed_float_frame\n    ):\n        # one instance of parametrized fixture\n        op = all_arithmetic_operators\n\n        def f(x, y):\n            # r-versions not in operator-stdlib; get op without \"r\" and invert\n            if op.startswith(\"__r\"):\n                return getattr(operator, op.replace(\"__r\", \"__\"))(y, x)\n            return getattr(operator, op)(x, y)\n\n        result = getattr(float_frame, op)(2 * float_frame)\n        expected = f(float_frame, 2 * float_frame)\n        tm.assert_frame_equal(result, expected)\n\n        # vs mix float\n        result = getattr(mixed_float_frame, op)(2 * mixed_float_frame)\n        expected = f(mixed_float_frame, 2 * mixed_float_frame)\n        tm.assert_frame_equal(result, expected)\n        _check_mixed_float(result, dtype=dict(C=None))\n\n    @pytest.mark.parametrize(\"op\", [\"__add__\", \"__sub__\", \"__mul__\"])\n    def test_arith_flex_frame_mixed(\n        self, op, int_frame, mixed_int_frame, mixed_float_frame\n    ):\n        f = getattr(operator, op)\n\n        # vs mix int\n        result = getattr(mixed_int_frame, op)(2 + mixed_int_frame)\n        expected = f(mixed_int_frame, 2 + mixed_int_frame)\n\n        # no overflow in the uint\n        dtype = None\n        if op in [\"__sub__\"]:\n            dtype = dict(B=\"uint64\", C=None)\n        elif op in [\"__add__\", \"__mul__\"]:\n            dtype = dict(C=None)\n        tm.assert_frame_equal(result, expected)\n        _check_mixed_int(result, dtype=dtype)\n\n        # vs mix float\n        result = getattr(mixed_float_frame, op)(2 * mixed_float_frame)\n        expected = f(mixed_float_frame, 2 * mixed_float_frame)\n        tm.assert_frame_equal(result, expected)\n        _check_mixed_float(result, dtype=dict(C=None))\n\n        # vs plain int\n        result = getattr(int_frame, op)(2 * int_frame)\n        expected = f(int_frame, 2 * int_frame)\n        tm.assert_frame_equal(result, expected)\n\n    def test_arith_flex_frame_raise(self, all_arithmetic_operators, float_frame):\n        # one instance of parametrized fixture\n        op = all_arithmetic_operators\n\n        # Check that arrays with dim >= 3 raise\n        for dim in range(3, 6):\n            arr = np.ones((1,) * dim)\n            msg = \"Unable to coerce to Series/DataFrame\"\n            with pytest.raises(ValueError, match=msg):\n                getattr(float_frame, op)(arr)\n\n    def test_arith_flex_frame_corner(self, float_frame):\n\n        const_add = float_frame.add(1)\n        tm.assert_frame_equal(const_add, float_frame + 1)\n\n        # corner cases\n        result = float_frame.add(float_frame[:0])\n        tm.assert_frame_equal(result, float_frame * np.nan)\n\n        result = float_frame[:0].add(float_frame)\n        tm.assert_frame_equal(result, float_frame * np.nan)\n\n        with pytest.raises(NotImplementedError, match=\"fill_value\"):\n            float_frame.add(float_frame.iloc[0], fill_value=3)\n\n        with pytest.raises(NotImplementedError, match=\"fill_value\"):\n            float_frame.add(float_frame.iloc[0], axis=\"index\", fill_value=3)\n\n    def test_arith_flex_series(self, simple_frame):\n        df = simple_frame\n\n        row = df.xs(\"a\")\n        col = df[\"two\"]\n        # after arithmetic refactor, add truediv here\n        ops = [\"add\", \"sub\", \"mul\", \"mod\"]\n        for op in ops:\n            f = getattr(df, op)\n            op = getattr(operator, op)\n            tm.assert_frame_equal(f(row), op(df, row))\n            tm.assert_frame_equal(f(col, axis=0), op(df.T, col).T)\n\n        # special case for some reason\n        tm.assert_frame_equal(df.add(row, axis=None), df + row)\n\n        # cases which will be refactored after big arithmetic refactor\n        tm.assert_frame_equal(df.div(row), df / row)\n        tm.assert_frame_equal(df.div(col, axis=0), (df.T / col).T)\n\n        # broadcasting issue in GH 7325\n        df = pd.DataFrame(np.arange(3 * 2).reshape((3, 2)), dtype=\"int64\")\n        expected = pd.DataFrame([[np.nan, np.inf], [1.0, 1.5], [1.0, 1.25]])\n        result = df.div(df[0], axis=\"index\")\n        tm.assert_frame_equal(result, expected)\n\n        df = pd.DataFrame(np.arange(3 * 2).reshape((3, 2)), dtype=\"float64\")\n        expected = pd.DataFrame([[np.nan, np.inf], [1.0, 1.5], [1.0, 1.25]])\n        result = df.div(df[0], axis=\"index\")\n        tm.assert_frame_equal(result, expected)\n\n    def test_arith_flex_zero_len_raises(self):\n        # GH 19522 passing fill_value to frame flex arith methods should\n        # raise even in the zero-length special cases\n        ser_len0 = pd.Series([], dtype=object)\n        df_len0 = pd.DataFrame(columns=[\"A\", \"B\"])\n        df = pd.DataFrame([[1, 2], [3, 4]], columns=[\"A\", \"B\"])\n\n        with pytest.raises(NotImplementedError, match=\"fill_value\"):\n            df.add(ser_len0, fill_value=\"E\")\n\n        with pytest.raises(NotImplementedError, match=\"fill_value\"):\n            df_len0.sub(df[\"A\"], axis=None, fill_value=3)\n\n\nclass TestFrameArithmetic:\n    def test_td64_op_nat_casting(self):\n        # Make sure we don't accidentally treat timedelta64(NaT) as datetime64\n        #  when calling dispatch_to_series in DataFrame arithmetic\n        ser = pd.Series([\"NaT\", \"NaT\"], dtype=\"timedelta64[ns]\")\n        df = pd.DataFrame([[1, 2], [3, 4]])\n\n        result = df * ser\n        expected = pd.DataFrame({0: ser, 1: ser})\n        tm.assert_frame_equal(result, expected)\n\n    def test_df_add_2d_array_rowlike_broadcasts(self):\n        # GH#23000\n        arr = np.arange(6).reshape(3, 2)\n        df = pd.DataFrame(arr, columns=[True, False], index=[\"A\", \"B\", \"C\"])\n\n        rowlike = arr[[1], :]  # shape --> (1, ncols)\n        assert rowlike.shape == (1, df.shape[1])\n\n        expected = pd.DataFrame(\n            [[2, 4], [4, 6], [6, 8]],\n            columns=df.columns,\n            index=df.index,\n            # specify dtype explicitly to avoid failing\n            # on 32bit builds\n            dtype=arr.dtype,\n        )\n        result = df + rowlike\n        tm.assert_frame_equal(result, expected)\n        result = rowlike + df\n        tm.assert_frame_equal(result, expected)\n\n    def test_df_add_2d_array_collike_broadcasts(self):\n        # GH#23000\n        arr = np.arange(6).reshape(3, 2)\n        df = pd.DataFrame(arr, columns=[True, False], index=[\"A\", \"B\", \"C\"])\n\n        collike = arr[:, [1]]  # shape --> (nrows, 1)\n        assert collike.shape == (df.shape[0], 1)\n\n        expected = pd.DataFrame(\n            [[1, 2], [5, 6], [9, 10]],\n            columns=df.columns,\n            index=df.index,\n            # specify dtype explicitly to avoid failing\n            # on 32bit builds\n            dtype=arr.dtype,\n        )\n        result = df + collike\n        tm.assert_frame_equal(result, expected)\n        result = collike + df\n        tm.assert_frame_equal(result, expected)\n\n    def test_df_arith_2d_array_rowlike_broadcasts(self, all_arithmetic_operators):\n        # GH#23000\n        opname = all_arithmetic_operators\n\n        arr = np.arange(6).reshape(3, 2)\n        df = pd.DataFrame(arr, columns=[True, False], index=[\"A\", \"B\", \"C\"])\n\n        rowlike = arr[[1], :]  # shape --> (1, ncols)\n        assert rowlike.shape == (1, df.shape[1])\n\n        exvals = [\n            getattr(df.loc[\"A\"], opname)(rowlike.squeeze()),\n            getattr(df.loc[\"B\"], opname)(rowlike.squeeze()),\n            getattr(df.loc[\"C\"], opname)(rowlike.squeeze()),\n        ]\n\n        expected = pd.DataFrame(exvals, columns=df.columns, index=df.index)\n\n        if opname in [\"__rmod__\", \"__rfloordiv__\"]:\n            # exvals will have dtypes [f8, i8, i8] so expected will be\n            #   all-f8, but the DataFrame operation will return mixed dtypes\n            # use exvals[-1].dtype instead of \"i8\" for compat with 32-bit\n            # systems/pythons\n            expected[False] = expected[False].astype(exvals[-1].dtype)\n\n        result = getattr(df, opname)(rowlike)\n        tm.assert_frame_equal(result, expected)\n\n    def test_df_arith_2d_array_collike_broadcasts(self, all_arithmetic_operators):\n        # GH#23000\n        opname = all_arithmetic_operators\n\n        arr = np.arange(6).reshape(3, 2)\n        df = pd.DataFrame(arr, columns=[True, False], index=[\"A\", \"B\", \"C\"])\n\n        collike = arr[:, [1]]  # shape --> (nrows, 1)\n        assert collike.shape == (df.shape[0], 1)\n\n        exvals = {\n            True: getattr(df[True], opname)(collike.squeeze()),\n            False: getattr(df[False], opname)(collike.squeeze()),\n        }\n\n        dtype = None\n        if opname in [\"__rmod__\", \"__rfloordiv__\"]:\n            # Series ops may return mixed int/float dtypes in cases where\n            #   DataFrame op will return all-float.  So we upcast `expected`\n            dtype = np.common_type(*[x.values for x in exvals.values()])\n\n        expected = pd.DataFrame(exvals, columns=df.columns, index=df.index, dtype=dtype)\n\n        result = getattr(df, opname)(collike)\n        tm.assert_frame_equal(result, expected)\n\n    def test_df_bool_mul_int(self):\n        # GH 22047, GH 22163 multiplication by 1 should result in int dtype,\n        # not object dtype\n        df = pd.DataFrame([[False, True], [False, False]])\n        result = df * 1\n\n        # On appveyor this comes back as np.int32 instead of np.int64,\n        # so we check dtype.kind instead of just dtype\n        kinds = result.dtypes.apply(lambda x: x.kind)\n        assert (kinds == \"i\").all()\n\n        result = 1 * df\n        kinds = result.dtypes.apply(lambda x: x.kind)\n        assert (kinds == \"i\").all()\n\n    def test_arith_mixed(self):\n\n        left = pd.DataFrame({\"A\": [\"a\", \"b\", \"c\"], \"B\": [1, 2, 3]})\n\n        result = left + left\n        expected = pd.DataFrame({\"A\": [\"aa\", \"bb\", \"cc\"], \"B\": [2, 4, 6]})\n        tm.assert_frame_equal(result, expected)\n\n    def test_arith_getitem_commute(self):\n        df = pd.DataFrame({\"A\": [1.1, 3.3], \"B\": [2.5, -3.9]})\n\n        def _test_op(df, op):\n            result = op(df, 1)\n\n            if not df.columns.is_unique:\n                raise ValueError(\"Only unique columns supported by this test\")\n\n            for col in result.columns:\n                tm.assert_series_equal(result[col], op(df[col], 1))\n\n        _test_op(df, operator.add)\n        _test_op(df, operator.sub)\n        _test_op(df, operator.mul)\n        _test_op(df, operator.truediv)\n        _test_op(df, operator.floordiv)\n        _test_op(df, operator.pow)\n\n        _test_op(df, lambda x, y: y + x)\n        _test_op(df, lambda x, y: y - x)\n        _test_op(df, lambda x, y: y * x)\n        _test_op(df, lambda x, y: y / x)\n        _test_op(df, lambda x, y: y ** x)\n\n        _test_op(df, lambda x, y: x + y)\n        _test_op(df, lambda x, y: x - y)\n        _test_op(df, lambda x, y: x * y)\n        _test_op(df, lambda x, y: x / y)\n        _test_op(df, lambda x, y: x ** y)\n\n    @pytest.mark.parametrize(\n        \"values\", [[1, 2], (1, 2), np.array([1, 2]), range(1, 3), deque([1, 2])]\n    )\n    def test_arith_alignment_non_pandas_object(self, values):\n        # GH#17901\n        df = pd.DataFrame({\"A\": [1, 1], \"B\": [1, 1]})\n        expected = pd.DataFrame({\"A\": [2, 2], \"B\": [3, 3]})\n        result = df + values\n        tm.assert_frame_equal(result, expected)\n\n    def test_arith_non_pandas_object(self):\n        df = pd.DataFrame(\n            np.arange(1, 10, dtype=\"f8\").reshape(3, 3),\n            columns=[\"one\", \"two\", \"three\"],\n            index=[\"a\", \"b\", \"c\"],\n        )\n\n        val1 = df.xs(\"a\").values\n        added = pd.DataFrame(df.values + val1, index=df.index, columns=df.columns)\n        tm.assert_frame_equal(df + val1, added)\n\n        added = pd.DataFrame((df.values.T + val1).T, index=df.index, columns=df.columns)\n        tm.assert_frame_equal(df.add(val1, axis=0), added)\n\n        val2 = list(df[\"two\"])\n\n        added = pd.DataFrame(df.values + val2, index=df.index, columns=df.columns)\n        tm.assert_frame_equal(df + val2, added)\n\n        added = pd.DataFrame((df.values.T + val2).T, index=df.index, columns=df.columns)\n        tm.assert_frame_equal(df.add(val2, axis=\"index\"), added)\n\n        val3 = np.random.rand(*df.shape)\n        added = pd.DataFrame(df.values + val3, index=df.index, columns=df.columns)\n        tm.assert_frame_equal(df.add(val3), added)\n\n    def test_operations_with_interval_categories_index(self, all_arithmetic_operators):\n        # GH#27415\n        op = all_arithmetic_operators\n        ind = pd.CategoricalIndex(pd.interval_range(start=0.0, end=2.0))\n        data = [1, 2]\n        df = pd.DataFrame([data], columns=ind)\n        num = 10\n        result = getattr(df, op)(num)\n        expected = pd.DataFrame([[getattr(n, op)(num) for n in data]], columns=ind)\n        tm.assert_frame_equal(result, expected)\n\n\ndef test_frame_with_zero_len_series_corner_cases():\n    # GH#28600\n    # easy all-float case\n    df = pd.DataFrame(np.random.randn(6).reshape(3, 2), columns=[\"A\", \"B\"])\n    ser = pd.Series(dtype=np.float64)\n\n    result = df + ser\n    expected = pd.DataFrame(df.values * np.nan, columns=df.columns)\n    tm.assert_frame_equal(result, expected)\n\n    result = df == ser\n    expected = pd.DataFrame(False, index=df.index, columns=df.columns)\n    tm.assert_frame_equal(result, expected)\n\n    # non-float case should not raise on comparison\n    df2 = pd.DataFrame(df.values.view(\"M8[ns]\"), columns=df.columns)\n    result = df2 == ser\n    expected = pd.DataFrame(False, index=df.index, columns=df.columns)\n    tm.assert_frame_equal(result, expected)\n\n\ndef test_zero_len_frame_with_series_corner_cases():\n    # GH#28600\n    df = pd.DataFrame(columns=[\"A\", \"B\"], dtype=np.float64)\n    ser = pd.Series([1, 2], index=[\"A\", \"B\"])\n\n    result = df + ser\n    expected = df\n    tm.assert_frame_equal(result, expected)\n"
    },
    {
      "filename": "pandas/tests/frame/test_constructors.py",
      "content": "from collections import OrderedDict, abc\nfrom datetime import datetime, timedelta\nimport functools\nimport itertools\n\nimport numpy as np\nimport numpy.ma as ma\nimport numpy.ma.mrecords as mrecords\nimport pytest\n\nfrom pandas.compat import is_platform_little_endian\n\nfrom pandas.core.dtypes.common import is_integer_dtype\n\nimport pandas as pd\nfrom pandas import (\n    Categorical,\n    DataFrame,\n    Index,\n    MultiIndex,\n    RangeIndex,\n    Series,\n    Timedelta,\n    Timestamp,\n    date_range,\n    isna,\n)\nfrom pandas.arrays import IntervalArray, PeriodArray\nfrom pandas.core.construction import create_series_with_explicit_dtype\nimport pandas.util.testing as tm\n\nMIXED_FLOAT_DTYPES = [\"float16\", \"float32\", \"float64\"]\nMIXED_INT_DTYPES = [\n    \"uint8\",\n    \"uint16\",\n    \"uint32\",\n    \"uint64\",\n    \"int8\",\n    \"int16\",\n    \"int32\",\n    \"int64\",\n]\n\n\nclass TestDataFrameConstructors:\n    def test_series_with_name_not_matching_column(self):\n        # GH#9232\n        x = pd.Series(range(5), name=1)\n        y = pd.Series(range(5), name=0)\n\n        result = pd.DataFrame(x, columns=[0])\n        expected = pd.DataFrame([], columns=[0])\n        tm.assert_frame_equal(result, expected)\n\n        result = pd.DataFrame(y, columns=[1])\n        expected = pd.DataFrame([], columns=[1])\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"constructor\",\n        [\n            lambda: DataFrame(),\n            lambda: DataFrame(None),\n            lambda: DataFrame({}),\n            lambda: DataFrame(()),\n            lambda: DataFrame([]),\n            lambda: DataFrame((_ for _ in [])),\n            lambda: DataFrame(range(0)),\n            lambda: DataFrame(data=None),\n            lambda: DataFrame(data={}),\n            lambda: DataFrame(data=()),\n            lambda: DataFrame(data=[]),\n            lambda: DataFrame(data=(_ for _ in [])),\n            lambda: DataFrame(data=range(0)),\n        ],\n    )\n    def test_empty_constructor(self, constructor):\n        expected = DataFrame()\n        result = constructor()\n        assert len(result.index) == 0\n        assert len(result.columns) == 0\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"emptylike,expected_index,expected_columns\",\n        [\n            ([[]], RangeIndex(1), RangeIndex(0)),\n            ([[], []], RangeIndex(2), RangeIndex(0)),\n            ([(_ for _ in [])], RangeIndex(1), RangeIndex(0)),\n        ],\n    )\n    def test_emptylike_constructor(self, emptylike, expected_index, expected_columns):\n        expected = DataFrame(index=expected_index, columns=expected_columns)\n        result = DataFrame(emptylike)\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_mixed(self, float_string_frame):\n        index, data = tm.getMixedTypeDict()\n\n        # TODO(wesm), incomplete test?\n        indexed_frame = DataFrame(data, index=index)  # noqa\n        unindexed_frame = DataFrame(data)  # noqa\n\n        assert float_string_frame[\"foo\"].dtype == np.object_\n\n    def test_constructor_cast_failure(self):\n        foo = DataFrame({\"a\": [\"a\", \"b\", \"c\"]}, dtype=np.float64)\n        assert foo[\"a\"].dtype == object\n\n        # GH 3010, constructing with odd arrays\n        df = DataFrame(np.ones((4, 2)))\n\n        # this is ok\n        df[\"foo\"] = np.ones((4, 2)).tolist()\n\n        # this is not ok\n        msg = \"Wrong number of items passed 2, placement implies 1\"\n        with pytest.raises(ValueError, match=msg):\n            df[\"test\"] = np.ones((4, 2))\n\n        # this is ok\n        df[\"foo2\"] = np.ones((4, 2)).tolist()\n\n    def test_constructor_dtype_copy(self):\n        orig_df = DataFrame({\"col1\": [1.0], \"col2\": [2.0], \"col3\": [3.0]})\n\n        new_df = pd.DataFrame(orig_df, dtype=float, copy=True)\n\n        new_df[\"col1\"] = 200.0\n        assert orig_df[\"col1\"][0] == 1.0\n\n    def test_constructor_dtype_nocast_view(self):\n        df = DataFrame([[1, 2]])\n        should_be_view = DataFrame(df, dtype=df[0].dtype)\n        should_be_view[0][0] = 99\n        assert df.values[0, 0] == 99\n\n        should_be_view = DataFrame(df.values, dtype=df[0].dtype)\n        should_be_view[0][0] = 97\n        assert df.values[0, 0] == 97\n\n    def test_constructor_dtype_list_data(self):\n        df = DataFrame([[1, \"2\"], [None, \"a\"]], dtype=object)\n        assert df.loc[1, 0] is None\n        assert df.loc[0, 1] == \"2\"\n\n    def test_constructor_list_frames(self):\n        # see gh-3243\n        result = DataFrame([DataFrame()])\n        assert result.shape == (1, 0)\n\n        result = DataFrame([DataFrame(dict(A=np.arange(5)))])\n        assert isinstance(result.iloc[0, 0], DataFrame)\n\n    def test_constructor_mixed_dtypes(self):\n        def _make_mixed_dtypes_df(typ, ad=None):\n\n            if typ == \"int\":\n                dtypes = MIXED_INT_DTYPES\n                arrays = [np.array(np.random.rand(10), dtype=d) for d in dtypes]\n            elif typ == \"float\":\n                dtypes = MIXED_FLOAT_DTYPES\n                arrays = [\n                    np.array(np.random.randint(10, size=10), dtype=d) for d in dtypes\n                ]\n\n            for d, a in zip(dtypes, arrays):\n                assert a.dtype == d\n            if ad is None:\n                ad = dict()\n            ad.update({d: a for d, a in zip(dtypes, arrays)})\n            return DataFrame(ad)\n\n        def _check_mixed_dtypes(df, dtypes=None):\n            if dtypes is None:\n                dtypes = MIXED_FLOAT_DTYPES + MIXED_INT_DTYPES\n            for d in dtypes:\n                if d in df:\n                    assert df.dtypes[d] == d\n\n        # mixed floating and integer coexist in the same frame\n        df = _make_mixed_dtypes_df(\"float\")\n        _check_mixed_dtypes(df)\n\n        # add lots of types\n        df = _make_mixed_dtypes_df(\"float\", dict(A=1, B=\"foo\", C=\"bar\"))\n        _check_mixed_dtypes(df)\n\n        # GH 622\n        df = _make_mixed_dtypes_df(\"int\")\n        _check_mixed_dtypes(df)\n\n    def test_constructor_complex_dtypes(self):\n        # GH10952\n        a = np.random.rand(10).astype(np.complex64)\n        b = np.random.rand(10).astype(np.complex128)\n\n        df = DataFrame({\"a\": a, \"b\": b})\n        assert a.dtype == df.a.dtype\n        assert b.dtype == df.b.dtype\n\n    def test_constructor_dtype_str_na_values(self, string_dtype):\n        # https://github.com/pandas-dev/pandas/issues/21083\n        df = DataFrame({\"A\": [\"x\", None]}, dtype=string_dtype)\n        result = df.isna()\n        expected = DataFrame({\"A\": [False, True]})\n        tm.assert_frame_equal(result, expected)\n        assert df.iloc[1, 0] is None\n\n        df = DataFrame({\"A\": [\"x\", np.nan]}, dtype=string_dtype)\n        assert np.isnan(df.iloc[1, 0])\n\n    def test_constructor_rec(self, float_frame):\n        rec = float_frame.to_records(index=False)\n        rec.dtype.names = list(rec.dtype.names)[::-1]\n\n        index = float_frame.index\n\n        df = DataFrame(rec)\n        tm.assert_index_equal(df.columns, pd.Index(rec.dtype.names))\n\n        df2 = DataFrame(rec, index=index)\n        tm.assert_index_equal(df2.columns, pd.Index(rec.dtype.names))\n        tm.assert_index_equal(df2.index, index)\n\n        rng = np.arange(len(rec))[::-1]\n        df3 = DataFrame(rec, index=rng, columns=[\"C\", \"B\"])\n        expected = DataFrame(rec, index=rng).reindex(columns=[\"C\", \"B\"])\n        tm.assert_frame_equal(df3, expected)\n\n    def test_constructor_bool(self):\n        df = DataFrame({0: np.ones(10, dtype=bool), 1: np.zeros(10, dtype=bool)})\n        assert df.values.dtype == np.bool_\n\n    def test_constructor_overflow_int64(self):\n        # see gh-14881\n        values = np.array([2 ** 64 - i for i in range(1, 10)], dtype=np.uint64)\n\n        result = DataFrame({\"a\": values})\n        assert result[\"a\"].dtype == np.uint64\n\n        # see gh-2355\n        data_scores = [\n            (6311132704823138710, 273),\n            (2685045978526272070, 23),\n            (8921811264899370420, 45),\n            (17019687244989530680, 270),\n            (9930107427299601010, 273),\n        ]\n        dtype = [(\"uid\", \"u8\"), (\"score\", \"u8\")]\n        data = np.zeros((len(data_scores),), dtype=dtype)\n        data[:] = data_scores\n        df_crawls = DataFrame(data)\n        assert df_crawls[\"uid\"].dtype == np.uint64\n\n    @pytest.mark.parametrize(\n        \"values\",\n        [\n            np.array([2 ** 64], dtype=object),\n            np.array([2 ** 65]),\n            [2 ** 64 + 1],\n            np.array([-(2 ** 63) - 4], dtype=object),\n            np.array([-(2 ** 64) - 1]),\n            [-(2 ** 65) - 2],\n        ],\n    )\n    def test_constructor_int_overflow(self, values):\n        # see gh-18584\n        value = values[0]\n        result = DataFrame(values)\n\n        assert result[0].dtype == object\n        assert result[0][0] == value\n\n    def test_constructor_ordereddict(self):\n        import random\n\n        nitems = 100\n        nums = list(range(nitems))\n        random.shuffle(nums)\n        expected = [\"A{i:d}\".format(i=i) for i in nums]\n        df = DataFrame(OrderedDict(zip(expected, [[0]] * nitems)))\n        assert expected == list(df.columns)\n\n    def test_constructor_dict(self):\n        datetime_series = tm.makeTimeSeries(nper=30)\n        # test expects index shifted by 5\n        datetime_series_short = tm.makeTimeSeries(nper=30)[5:]\n\n        frame = DataFrame({\"col1\": datetime_series, \"col2\": datetime_series_short})\n\n        # col2 is padded with NaN\n        assert len(datetime_series) == 30\n        assert len(datetime_series_short) == 25\n\n        tm.assert_series_equal(frame[\"col1\"], datetime_series.rename(\"col1\"))\n\n        exp = pd.Series(\n            np.concatenate([[np.nan] * 5, datetime_series_short.values]),\n            index=datetime_series.index,\n            name=\"col2\",\n        )\n        tm.assert_series_equal(exp, frame[\"col2\"])\n\n        frame = DataFrame(\n            {\"col1\": datetime_series, \"col2\": datetime_series_short},\n            columns=[\"col2\", \"col3\", \"col4\"],\n        )\n\n        assert len(frame) == len(datetime_series_short)\n        assert \"col1\" not in frame\n        assert isna(frame[\"col3\"]).all()\n\n        # Corner cases\n        assert len(DataFrame()) == 0\n\n        # mix dict and array, wrong size - no spec for which error should raise\n        # first\n        with pytest.raises(ValueError):\n            DataFrame({\"A\": {\"a\": \"a\", \"b\": \"b\"}, \"B\": [\"a\", \"b\", \"c\"]})\n\n        # Length-one dict micro-optimization\n        frame = DataFrame({\"A\": {\"1\": 1, \"2\": 2}})\n        tm.assert_index_equal(frame.index, pd.Index([\"1\", \"2\"]))\n\n        # empty dict plus index\n        idx = Index([0, 1, 2])\n        frame = DataFrame({}, index=idx)\n        assert frame.index is idx\n\n        # empty dict with index and columns\n        idx = Index([0, 1, 2])\n        frame = DataFrame({}, index=idx, columns=idx)\n        assert frame.index is idx\n        assert frame.columns is idx\n        assert len(frame._series) == 3\n\n        # with dict of empty list and Series\n        frame = DataFrame({\"A\": [], \"B\": []}, columns=[\"A\", \"B\"])\n        tm.assert_index_equal(frame.index, Index([], dtype=np.int64))\n\n        # GH 14381\n        # Dict with None value\n        frame_none = DataFrame(dict(a=None), index=[0])\n        frame_none_list = DataFrame(dict(a=[None]), index=[0])\n        assert frame_none._get_value(0, \"a\") is None\n        assert frame_none_list._get_value(0, \"a\") is None\n        tm.assert_frame_equal(frame_none, frame_none_list)\n\n        # GH10856\n        # dict with scalar values should raise error, even if columns passed\n        msg = \"If using all scalar values, you must pass an index\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame({\"a\": 0.7})\n\n        with pytest.raises(ValueError, match=msg):\n            DataFrame({\"a\": 0.7}, columns=[\"a\"])\n\n    @pytest.mark.parametrize(\"scalar\", [2, np.nan, None, \"D\"])\n    def test_constructor_invalid_items_unused(self, scalar):\n        # No error if invalid (scalar) value is in fact not used:\n        result = DataFrame({\"a\": scalar}, columns=[\"b\"])\n        expected = DataFrame(columns=[\"b\"])\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\"value\", [2, np.nan, None, float(\"nan\")])\n    def test_constructor_dict_nan_key(self, value):\n        # GH 18455\n        cols = [1, value, 3]\n        idx = [\"a\", value]\n        values = [[0, 3], [1, 4], [2, 5]]\n        data = {cols[c]: Series(values[c], index=idx) for c in range(3)}\n        result = DataFrame(data).sort_values(1).sort_values(\"a\", axis=1)\n        expected = DataFrame(\n            np.arange(6, dtype=\"int64\").reshape(2, 3), index=idx, columns=cols\n        )\n        tm.assert_frame_equal(result, expected)\n\n        result = DataFrame(data, index=idx).sort_values(\"a\", axis=1)\n        tm.assert_frame_equal(result, expected)\n\n        result = DataFrame(data, index=idx, columns=cols)\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\"value\", [np.nan, None, float(\"nan\")])\n    def test_constructor_dict_nan_tuple_key(self, value):\n        # GH 18455\n        cols = Index([(11, 21), (value, 22), (13, value)])\n        idx = Index([(\"a\", value), (value, 2)])\n        values = [[0, 3], [1, 4], [2, 5]]\n        data = {cols[c]: Series(values[c], index=idx) for c in range(3)}\n        result = DataFrame(data).sort_values((11, 21)).sort_values((\"a\", value), axis=1)\n        expected = DataFrame(\n            np.arange(6, dtype=\"int64\").reshape(2, 3), index=idx, columns=cols\n        )\n        tm.assert_frame_equal(result, expected)\n\n        result = DataFrame(data, index=idx).sort_values((\"a\", value), axis=1)\n        tm.assert_frame_equal(result, expected)\n\n        result = DataFrame(data, index=idx, columns=cols)\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_dict_order_insertion(self):\n        datetime_series = tm.makeTimeSeries(nper=30)\n        datetime_series_short = tm.makeTimeSeries(nper=25)\n\n        # GH19018\n        # initialization ordering: by insertion order if python>= 3.6\n        d = {\"b\": datetime_series_short, \"a\": datetime_series}\n        frame = DataFrame(data=d)\n        expected = DataFrame(data=d, columns=list(\"ba\"))\n        tm.assert_frame_equal(frame, expected)\n\n    def test_constructor_multi_index(self):\n        # GH 4078\n        # construction error with mi and all-nan frame\n        tuples = [(2, 3), (3, 3), (3, 3)]\n        mi = MultiIndex.from_tuples(tuples)\n        df = DataFrame(index=mi, columns=mi)\n        assert pd.isna(df).values.ravel().all()\n\n        tuples = [(3, 3), (2, 3), (3, 3)]\n        mi = MultiIndex.from_tuples(tuples)\n        df = DataFrame(index=mi, columns=mi)\n        assert pd.isna(df).values.ravel().all()\n\n    def test_constructor_2d_index(self):\n        # GH 25416\n        # handling of 2d index in construction\n        df = pd.DataFrame([[1]], columns=[[1]], index=[1, 2])\n        expected = pd.DataFrame(\n            [1, 1],\n            index=pd.Int64Index([1, 2], dtype=\"int64\"),\n            columns=pd.MultiIndex(levels=[[1]], codes=[[0]]),\n        )\n        tm.assert_frame_equal(df, expected)\n\n        df = pd.DataFrame([[1]], columns=[[1]], index=[[1, 2]])\n        expected = pd.DataFrame(\n            [1, 1],\n            index=pd.MultiIndex(levels=[[1, 2]], codes=[[0, 1]]),\n            columns=pd.MultiIndex(levels=[[1]], codes=[[0]]),\n        )\n        tm.assert_frame_equal(df, expected)\n\n    def test_constructor_error_msgs(self):\n        msg = \"Empty data passed with indices specified.\"\n        # passing an empty array with columns specified.\n        with pytest.raises(ValueError, match=msg):\n            DataFrame(np.empty(0), columns=list(\"abc\"))\n\n        msg = \"Mixing dicts with non-Series may lead to ambiguous ordering.\"\n        # mix dict and array, wrong size\n        with pytest.raises(ValueError, match=msg):\n            DataFrame({\"A\": {\"a\": \"a\", \"b\": \"b\"}, \"B\": [\"a\", \"b\", \"c\"]})\n\n        # wrong size ndarray, GH 3105\n        msg = r\"Shape of passed values is \\(4, 3\\), indices imply \\(3, 3\\)\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame(\n                np.arange(12).reshape((4, 3)),\n                columns=[\"foo\", \"bar\", \"baz\"],\n                index=pd.date_range(\"2000-01-01\", periods=3),\n            )\n\n        arr = np.array([[4, 5, 6]])\n        msg = r\"Shape of passed values is \\(1, 3\\), indices imply \\(1, 4\\)\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame(index=[0], columns=range(0, 4), data=arr)\n\n        arr = np.array([4, 5, 6])\n        msg = r\"Shape of passed values is \\(3, 1\\), indices imply \\(1, 4\\)\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame(index=[0], columns=range(0, 4), data=arr)\n\n        # higher dim raise exception\n        with pytest.raises(ValueError, match=\"Must pass 2-d input\"):\n            DataFrame(np.zeros((3, 3, 3)), columns=[\"A\", \"B\", \"C\"], index=[1])\n\n        # wrong size axis labels\n        msg = \"Shape of passed values \" r\"is \\(2, 3\\), indices \" r\"imply \\(1, 3\\)\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame(np.random.rand(2, 3), columns=[\"A\", \"B\", \"C\"], index=[1])\n\n        msg = \"Shape of passed values \" r\"is \\(2, 3\\), indices \" r\"imply \\(2, 2\\)\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame(np.random.rand(2, 3), columns=[\"A\", \"B\"], index=[1, 2])\n\n        # gh-26429\n        msg = \"2 columns passed, passed data had 10 columns\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame((range(10), range(10, 20)), columns=(\"ones\", \"twos\"))\n\n        msg = \"If using all scalar values, you must pass an index\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame({\"a\": False, \"b\": True})\n\n    def test_constructor_with_embedded_frames(self):\n\n        # embedded data frames\n        df1 = DataFrame({\"a\": [1, 2, 3], \"b\": [3, 4, 5]})\n        df2 = DataFrame([df1, df1 + 10])\n\n        df2.dtypes\n        str(df2)\n\n        result = df2.loc[0, 0]\n        tm.assert_frame_equal(result, df1)\n\n        result = df2.loc[1, 0]\n        tm.assert_frame_equal(result, df1 + 10)\n\n    def test_constructor_subclass_dict(self, float_frame):\n        # Test for passing dict subclass to constructor\n        data = {\n            \"col1\": tm.TestSubDict((x, 10.0 * x) for x in range(10)),\n            \"col2\": tm.TestSubDict((x, 20.0 * x) for x in range(10)),\n        }\n        df = DataFrame(data)\n        refdf = DataFrame({col: dict(val.items()) for col, val in data.items()})\n        tm.assert_frame_equal(refdf, df)\n\n        data = tm.TestSubDict(data.items())\n        df = DataFrame(data)\n        tm.assert_frame_equal(refdf, df)\n\n        # try with defaultdict\n        from collections import defaultdict\n\n        data = {}\n        float_frame[\"B\"][:10] = np.nan\n        for k, v in float_frame.items():\n            dct = defaultdict(dict)\n            dct.update(v.to_dict())\n            data[k] = dct\n        frame = DataFrame(data)\n        expected = frame.reindex(index=float_frame.index)\n        tm.assert_frame_equal(float_frame, expected)\n\n    def test_constructor_dict_block(self):\n        expected = np.array([[4.0, 3.0, 2.0, 1.0]])\n        df = DataFrame(\n            {\"d\": [4.0], \"c\": [3.0], \"b\": [2.0], \"a\": [1.0]},\n            columns=[\"d\", \"c\", \"b\", \"a\"],\n        )\n        tm.assert_numpy_array_equal(df.values, expected)\n\n    def test_constructor_dict_cast(self):\n        # cast float tests\n        test_data = {\"A\": {\"1\": 1, \"2\": 2}, \"B\": {\"1\": \"1\", \"2\": \"2\", \"3\": \"3\"}}\n        frame = DataFrame(test_data, dtype=float)\n        assert len(frame) == 3\n        assert frame[\"B\"].dtype == np.float64\n        assert frame[\"A\"].dtype == np.float64\n\n        frame = DataFrame(test_data)\n        assert len(frame) == 3\n        assert frame[\"B\"].dtype == np.object_\n        assert frame[\"A\"].dtype == np.float64\n\n        # can't cast to float\n        test_data = {\n            \"A\": dict(zip(range(20), tm.makeStringIndex(20))),\n            \"B\": dict(zip(range(15), np.random.randn(15))),\n        }\n        frame = DataFrame(test_data, dtype=float)\n        assert len(frame) == 20\n        assert frame[\"A\"].dtype == np.object_\n        assert frame[\"B\"].dtype == np.float64\n\n    def test_constructor_dict_dont_upcast(self):\n        d = {\"Col1\": {\"Row1\": \"A String\", \"Row2\": np.nan}}\n        df = DataFrame(d)\n        assert isinstance(df[\"Col1\"][\"Row2\"], float)\n\n        dm = DataFrame([[1, 2], [\"a\", \"b\"]], index=[1, 2], columns=[1, 2])\n        assert isinstance(dm[1][1], int)\n\n    def test_constructor_dict_of_tuples(self):\n        # GH #1491\n        data = {\"a\": (1, 2, 3), \"b\": (4, 5, 6)}\n\n        result = DataFrame(data)\n        expected = DataFrame({k: list(v) for k, v in data.items()})\n        tm.assert_frame_equal(result, expected, check_dtype=False)\n\n    def test_constructor_dict_of_ranges(self):\n        # GH 26356\n        data = {\"a\": range(3), \"b\": range(3, 6)}\n\n        result = DataFrame(data)\n        expected = DataFrame({\"a\": [0, 1, 2], \"b\": [3, 4, 5]})\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_dict_of_iterators(self):\n        # GH 26349\n        data = {\"a\": iter(range(3)), \"b\": reversed(range(3))}\n\n        result = DataFrame(data)\n        expected = DataFrame({\"a\": [0, 1, 2], \"b\": [2, 1, 0]})\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_dict_of_generators(self):\n        # GH 26349\n        data = {\"a\": (i for i in (range(3))), \"b\": (i for i in reversed(range(3)))}\n        result = DataFrame(data)\n        expected = DataFrame({\"a\": [0, 1, 2], \"b\": [2, 1, 0]})\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_dict_multiindex(self):\n        def check(result, expected):\n            return tm.assert_frame_equal(\n                result,\n                expected,\n                check_dtype=True,\n                check_index_type=True,\n                check_column_type=True,\n                check_names=True,\n            )\n\n        d = {\n            (\"a\", \"a\"): {(\"i\", \"i\"): 0, (\"i\", \"j\"): 1, (\"j\", \"i\"): 2},\n            (\"b\", \"a\"): {(\"i\", \"i\"): 6, (\"i\", \"j\"): 5, (\"j\", \"i\"): 4},\n            (\"b\", \"c\"): {(\"i\", \"i\"): 7, (\"i\", \"j\"): 8, (\"j\", \"i\"): 9},\n        }\n        _d = sorted(d.items())\n        df = DataFrame(d)\n        expected = DataFrame(\n            [x[1] for x in _d], index=MultiIndex.from_tuples([x[0] for x in _d])\n        ).T\n        expected.index = MultiIndex.from_tuples(expected.index)\n        check(df, expected)\n\n        d[\"z\"] = {\"y\": 123.0, (\"i\", \"i\"): 111, (\"i\", \"j\"): 111, (\"j\", \"i\"): 111}\n        _d.insert(0, (\"z\", d[\"z\"]))\n        expected = DataFrame(\n            [x[1] for x in _d], index=Index([x[0] for x in _d], tupleize_cols=False)\n        ).T\n        expected.index = Index(expected.index, tupleize_cols=False)\n        df = DataFrame(d)\n        df = df.reindex(columns=expected.columns, index=expected.index)\n        check(df, expected)\n\n    def test_constructor_dict_datetime64_index(self):\n        # GH 10160\n        dates_as_str = [\"1984-02-19\", \"1988-11-06\", \"1989-12-03\", \"1990-03-15\"]\n\n        def create_data(constructor):\n            return {i: {constructor(s): 2 * i} for i, s in enumerate(dates_as_str)}\n\n        data_datetime64 = create_data(np.datetime64)\n        data_datetime = create_data(lambda x: datetime.strptime(x, \"%Y-%m-%d\"))\n        data_Timestamp = create_data(Timestamp)\n\n        expected = DataFrame(\n            [\n                {0: 0, 1: None, 2: None, 3: None},\n                {0: None, 1: 2, 2: None, 3: None},\n                {0: None, 1: None, 2: 4, 3: None},\n                {0: None, 1: None, 2: None, 3: 6},\n            ],\n            index=[Timestamp(dt) for dt in dates_as_str],\n        )\n\n        result_datetime64 = DataFrame(data_datetime64)\n        result_datetime = DataFrame(data_datetime)\n        result_Timestamp = DataFrame(data_Timestamp)\n        tm.assert_frame_equal(result_datetime64, expected)\n        tm.assert_frame_equal(result_datetime, expected)\n        tm.assert_frame_equal(result_Timestamp, expected)\n\n    def test_constructor_dict_timedelta64_index(self):\n        # GH 10160\n        td_as_int = [1, 2, 3, 4]\n\n        def create_data(constructor):\n            return {i: {constructor(s): 2 * i} for i, s in enumerate(td_as_int)}\n\n        data_timedelta64 = create_data(lambda x: np.timedelta64(x, \"D\"))\n        data_timedelta = create_data(lambda x: timedelta(days=x))\n        data_Timedelta = create_data(lambda x: Timedelta(x, \"D\"))\n\n        expected = DataFrame(\n            [\n                {0: 0, 1: None, 2: None, 3: None},\n                {0: None, 1: 2, 2: None, 3: None},\n                {0: None, 1: None, 2: 4, 3: None},\n                {0: None, 1: None, 2: None, 3: 6},\n            ],\n            index=[Timedelta(td, \"D\") for td in td_as_int],\n        )\n\n        result_timedelta64 = DataFrame(data_timedelta64)\n        result_timedelta = DataFrame(data_timedelta)\n        result_Timedelta = DataFrame(data_Timedelta)\n        tm.assert_frame_equal(result_timedelta64, expected)\n        tm.assert_frame_equal(result_timedelta, expected)\n        tm.assert_frame_equal(result_Timedelta, expected)\n\n    def test_constructor_period(self):\n        # PeriodIndex\n        a = pd.PeriodIndex([\"2012-01\", \"NaT\", \"2012-04\"], freq=\"M\")\n        b = pd.PeriodIndex([\"2012-02-01\", \"2012-03-01\", \"NaT\"], freq=\"D\")\n        df = pd.DataFrame({\"a\": a, \"b\": b})\n        assert df[\"a\"].dtype == a.dtype\n        assert df[\"b\"].dtype == b.dtype\n\n        # list of periods\n        df = pd.DataFrame(\n            {\"a\": a.astype(object).tolist(), \"b\": b.astype(object).tolist()}\n        )\n        assert df[\"a\"].dtype == a.dtype\n        assert df[\"b\"].dtype == b.dtype\n\n    def test_nested_dict_frame_constructor(self):\n        rng = pd.period_range(\"1/1/2000\", periods=5)\n        df = DataFrame(np.random.randn(10, 5), columns=rng)\n\n        data = {}\n        for col in df.columns:\n            for row in df.index:\n                data.setdefault(col, {})[row] = df._get_value(row, col)\n\n        result = DataFrame(data, columns=rng)\n        tm.assert_frame_equal(result, df)\n\n        data = {}\n        for col in df.columns:\n            for row in df.index:\n                data.setdefault(row, {})[col] = df._get_value(row, col)\n\n        result = DataFrame(data, index=rng).T\n        tm.assert_frame_equal(result, df)\n\n    def _check_basic_constructor(self, empty):\n        # mat: 2d matrix with shape (3, 2) to input. empty - makes sized\n        # objects\n        mat = empty((2, 3), dtype=float)\n        # 2-D input\n        frame = DataFrame(mat, columns=[\"A\", \"B\", \"C\"], index=[1, 2])\n\n        assert len(frame.index) == 2\n        assert len(frame.columns) == 3\n\n        # 1-D input\n        frame = DataFrame(empty((3,)), columns=[\"A\"], index=[1, 2, 3])\n        assert len(frame.index) == 3\n        assert len(frame.columns) == 1\n\n        # cast type\n        frame = DataFrame(mat, columns=[\"A\", \"B\", \"C\"], index=[1, 2], dtype=np.int64)\n        assert frame.values.dtype == np.int64\n\n        # wrong size axis labels\n        msg = r\"Shape of passed values is \\(2, 3\\), indices imply \\(1, 3\\)\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame(mat, columns=[\"A\", \"B\", \"C\"], index=[1])\n        msg = r\"Shape of passed values is \\(2, 3\\), indices imply \\(2, 2\\)\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame(mat, columns=[\"A\", \"B\"], index=[1, 2])\n\n        # higher dim raise exception\n        with pytest.raises(ValueError, match=\"Must pass 2-d input\"):\n            DataFrame(empty((3, 3, 3)), columns=[\"A\", \"B\", \"C\"], index=[1])\n\n        # automatic labeling\n        frame = DataFrame(mat)\n        tm.assert_index_equal(frame.index, pd.Int64Index(range(2)))\n        tm.assert_index_equal(frame.columns, pd.Int64Index(range(3)))\n\n        frame = DataFrame(mat, index=[1, 2])\n        tm.assert_index_equal(frame.columns, pd.Int64Index(range(3)))\n\n        frame = DataFrame(mat, columns=[\"A\", \"B\", \"C\"])\n        tm.assert_index_equal(frame.index, pd.Int64Index(range(2)))\n\n        # 0-length axis\n        frame = DataFrame(empty((0, 3)))\n        assert len(frame.index) == 0\n\n        frame = DataFrame(empty((3, 0)))\n        assert len(frame.columns) == 0\n\n    def test_constructor_ndarray(self):\n        self._check_basic_constructor(np.ones)\n\n        frame = DataFrame([\"foo\", \"bar\"], index=[0, 1], columns=[\"A\"])\n        assert len(frame) == 2\n\n    def test_constructor_maskedarray(self):\n        self._check_basic_constructor(ma.masked_all)\n\n        # Check non-masked values\n        mat = ma.masked_all((2, 3), dtype=float)\n        mat[0, 0] = 1.0\n        mat[1, 2] = 2.0\n        frame = DataFrame(mat, columns=[\"A\", \"B\", \"C\"], index=[1, 2])\n        assert 1.0 == frame[\"A\"][1]\n        assert 2.0 == frame[\"C\"][2]\n\n        # what is this even checking??\n        mat = ma.masked_all((2, 3), dtype=float)\n        frame = DataFrame(mat, columns=[\"A\", \"B\", \"C\"], index=[1, 2])\n        assert np.all(~np.asarray(frame == frame))\n\n    def test_constructor_maskedarray_nonfloat(self):\n        # masked int promoted to float\n        mat = ma.masked_all((2, 3), dtype=int)\n        # 2-D input\n        frame = DataFrame(mat, columns=[\"A\", \"B\", \"C\"], index=[1, 2])\n\n        assert len(frame.index) == 2\n        assert len(frame.columns) == 3\n        assert np.all(~np.asarray(frame == frame))\n\n        # cast type\n        frame = DataFrame(mat, columns=[\"A\", \"B\", \"C\"], index=[1, 2], dtype=np.float64)\n        assert frame.values.dtype == np.float64\n\n        # Check non-masked values\n        mat2 = ma.copy(mat)\n        mat2[0, 0] = 1\n        mat2[1, 2] = 2\n        frame = DataFrame(mat2, columns=[\"A\", \"B\", \"C\"], index=[1, 2])\n        assert 1 == frame[\"A\"][1]\n        assert 2 == frame[\"C\"][2]\n\n        # masked np.datetime64 stays (use NaT as null)\n        mat = ma.masked_all((2, 3), dtype=\"M8[ns]\")\n        # 2-D input\n        frame = DataFrame(mat, columns=[\"A\", \"B\", \"C\"], index=[1, 2])\n\n        assert len(frame.index) == 2\n        assert len(frame.columns) == 3\n        assert isna(frame).values.all()\n\n        # cast type\n        frame = DataFrame(mat, columns=[\"A\", \"B\", \"C\"], index=[1, 2], dtype=np.int64)\n        assert frame.values.dtype == np.int64\n\n        # Check non-masked values\n        mat2 = ma.copy(mat)\n        mat2[0, 0] = 1\n        mat2[1, 2] = 2\n        frame = DataFrame(mat2, columns=[\"A\", \"B\", \"C\"], index=[1, 2])\n        assert 1 == frame[\"A\"].view(\"i8\")[1]\n        assert 2 == frame[\"C\"].view(\"i8\")[2]\n\n        # masked bool promoted to object\n        mat = ma.masked_all((2, 3), dtype=bool)\n        # 2-D input\n        frame = DataFrame(mat, columns=[\"A\", \"B\", \"C\"], index=[1, 2])\n\n        assert len(frame.index) == 2\n        assert len(frame.columns) == 3\n        assert np.all(~np.asarray(frame == frame))\n\n        # cast type\n        frame = DataFrame(mat, columns=[\"A\", \"B\", \"C\"], index=[1, 2], dtype=object)\n        assert frame.values.dtype == object\n\n        # Check non-masked values\n        mat2 = ma.copy(mat)\n        mat2[0, 0] = True\n        mat2[1, 2] = False\n        frame = DataFrame(mat2, columns=[\"A\", \"B\", \"C\"], index=[1, 2])\n        assert frame[\"A\"][1] is True\n        assert frame[\"C\"][2] is False\n\n    def test_constructor_maskedarray_hardened(self):\n        # Check numpy masked arrays with hard masks -- from GH24574\n        mat_hard = ma.masked_all((2, 2), dtype=float).harden_mask()\n        result = pd.DataFrame(mat_hard, columns=[\"A\", \"B\"], index=[1, 2])\n        expected = pd.DataFrame(\n            {\"A\": [np.nan, np.nan], \"B\": [np.nan, np.nan]},\n            columns=[\"A\", \"B\"],\n            index=[1, 2],\n            dtype=float,\n        )\n        tm.assert_frame_equal(result, expected)\n        # Check case where mask is hard but no data are masked\n        mat_hard = ma.ones((2, 2), dtype=float).harden_mask()\n        result = pd.DataFrame(mat_hard, columns=[\"A\", \"B\"], index=[1, 2])\n        expected = pd.DataFrame(\n            {\"A\": [1.0, 1.0], \"B\": [1.0, 1.0]},\n            columns=[\"A\", \"B\"],\n            index=[1, 2],\n            dtype=float,\n        )\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_maskedrecarray_dtype(self):\n        # Ensure constructor honors dtype\n        data = np.ma.array(\n            np.ma.zeros(5, dtype=[(\"date\", \"<f8\"), (\"price\", \"<f8\")]), mask=[False] * 5\n        )\n        data = data.view(mrecords.mrecarray)\n        result = pd.DataFrame(data, dtype=int)\n        expected = pd.DataFrame(np.zeros((5, 2), dtype=int), columns=[\"date\", \"price\"])\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_mrecarray(self):\n        # Ensure mrecarray produces frame identical to dict of masked arrays\n        # from GH3479\n\n        assert_fr_equal = functools.partial(\n            tm.assert_frame_equal,\n            check_index_type=True,\n            check_column_type=True,\n            check_frame_type=True,\n        )\n        arrays = [\n            (\"float\", np.array([1.5, 2.0])),\n            (\"int\", np.array([1, 2])),\n            (\"str\", np.array([\"abc\", \"def\"])),\n        ]\n        for name, arr in arrays[:]:\n            arrays.append(\n                (\"masked1_\" + name, np.ma.masked_array(arr, mask=[False, True]))\n            )\n        arrays.append((\"masked_all\", np.ma.masked_all((2,))))\n        arrays.append((\"masked_none\", np.ma.masked_array([1.0, 2.5], mask=False)))\n\n        # call assert_frame_equal for all selections of 3 arrays\n        for comb in itertools.combinations(arrays, 3):\n            names, data = zip(*comb)\n            mrecs = mrecords.fromarrays(data, names=names)\n\n            # fill the comb\n            comb = {k: (v.filled() if hasattr(v, \"filled\") else v) for k, v in comb}\n\n            expected = DataFrame(comb, columns=names)\n            result = DataFrame(mrecs)\n            assert_fr_equal(result, expected)\n\n            # specify columns\n            expected = DataFrame(comb, columns=names[::-1])\n            result = DataFrame(mrecs, columns=names[::-1])\n            assert_fr_equal(result, expected)\n\n            # specify index\n            expected = DataFrame(comb, columns=names, index=[1, 2])\n            result = DataFrame(mrecs, index=[1, 2])\n            assert_fr_equal(result, expected)\n\n    def test_constructor_corner_shape(self):\n        df = DataFrame(index=[])\n        assert df.values.shape == (0, 0)\n\n    @pytest.mark.parametrize(\n        \"data, index, columns, dtype, expected\",\n        [\n            (None, list(range(10)), [\"a\", \"b\"], object, np.object_),\n            (None, None, [\"a\", \"b\"], \"int64\", np.dtype(\"int64\")),\n            (None, list(range(10)), [\"a\", \"b\"], int, np.dtype(\"float64\")),\n            ({}, None, [\"foo\", \"bar\"], None, np.object_),\n            ({\"b\": 1}, list(range(10)), list(\"abc\"), int, np.dtype(\"float64\")),\n        ],\n    )\n    def test_constructor_dtype(self, data, index, columns, dtype, expected):\n        df = DataFrame(data, index, columns, dtype)\n        assert df.values.dtype == expected\n\n    def test_constructor_scalar_inference(self):\n        data = {\"int\": 1, \"bool\": True, \"float\": 3.0, \"complex\": 4j, \"object\": \"foo\"}\n        df = DataFrame(data, index=np.arange(10))\n\n        assert df[\"int\"].dtype == np.int64\n        assert df[\"bool\"].dtype == np.bool_\n        assert df[\"float\"].dtype == np.float64\n        assert df[\"complex\"].dtype == np.complex128\n        assert df[\"object\"].dtype == np.object_\n\n    def test_constructor_arrays_and_scalars(self):\n        df = DataFrame({\"a\": np.random.randn(10), \"b\": True})\n        exp = DataFrame({\"a\": df[\"a\"].values, \"b\": [True] * 10})\n\n        tm.assert_frame_equal(df, exp)\n        with pytest.raises(ValueError, match=\"must pass an index\"):\n            DataFrame({\"a\": False, \"b\": True})\n\n    def test_constructor_DataFrame(self, float_frame):\n        df = DataFrame(float_frame)\n        tm.assert_frame_equal(df, float_frame)\n\n        df_casted = DataFrame(float_frame, dtype=np.int64)\n        assert df_casted.values.dtype == np.int64\n\n    def test_constructor_more(self, float_frame):\n        # used to be in test_matrix.py\n        arr = np.random.randn(10)\n        dm = DataFrame(arr, columns=[\"A\"], index=np.arange(10))\n        assert dm.values.ndim == 2\n\n        arr = np.random.randn(0)\n        dm = DataFrame(arr)\n        assert dm.values.ndim == 2\n        assert dm.values.ndim == 2\n\n        # no data specified\n        dm = DataFrame(columns=[\"A\", \"B\"], index=np.arange(10))\n        assert dm.values.shape == (10, 2)\n\n        dm = DataFrame(columns=[\"A\", \"B\"])\n        assert dm.values.shape == (0, 2)\n\n        dm = DataFrame(index=np.arange(10))\n        assert dm.values.shape == (10, 0)\n\n        # can't cast\n        mat = np.array([\"foo\", \"bar\"], dtype=object).reshape(2, 1)\n        with pytest.raises(ValueError, match=\"cast\"):\n            DataFrame(mat, index=[0, 1], columns=[0], dtype=float)\n\n        dm = DataFrame(DataFrame(float_frame._series))\n        tm.assert_frame_equal(dm, float_frame)\n\n        # int cast\n        dm = DataFrame(\n            {\"A\": np.ones(10, dtype=int), \"B\": np.ones(10, dtype=np.float64)},\n            index=np.arange(10),\n        )\n\n        assert len(dm.columns) == 2\n        assert dm.values.dtype == np.float64\n\n    def test_constructor_empty_list(self):\n        df = DataFrame([], index=[])\n        expected = DataFrame(index=[])\n        tm.assert_frame_equal(df, expected)\n\n        # GH 9939\n        df = DataFrame([], columns=[\"A\", \"B\"])\n        expected = DataFrame({}, columns=[\"A\", \"B\"])\n        tm.assert_frame_equal(df, expected)\n\n        # Empty generator: list(empty_gen()) == []\n        def empty_gen():\n            return\n            yield\n\n        df = DataFrame(empty_gen(), columns=[\"A\", \"B\"])\n        tm.assert_frame_equal(df, expected)\n\n    def test_constructor_list_of_lists(self):\n        # GH #484\n        df = DataFrame(data=[[1, \"a\"], [2, \"b\"]], columns=[\"num\", \"str\"])\n        assert is_integer_dtype(df[\"num\"])\n        assert df[\"str\"].dtype == np.object_\n\n        # GH 4851\n        # list of 0-dim ndarrays\n        expected = DataFrame({0: np.arange(10)})\n        data = [np.array(x) for x in range(10)]\n        result = DataFrame(data)\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_sequence_like(self):\n        # GH 3783\n        # collections.Squence like\n\n        class DummyContainer(abc.Sequence):\n            def __init__(self, lst):\n                self._lst = lst\n\n            def __getitem__(self, n):\n                return self._lst.__getitem__(n)\n\n            def __len__(self, n):\n                return self._lst.__len__()\n\n        lst_containers = [DummyContainer([1, \"a\"]), DummyContainer([2, \"b\"])]\n        columns = [\"num\", \"str\"]\n        result = DataFrame(lst_containers, columns=columns)\n        expected = DataFrame([[1, \"a\"], [2, \"b\"]], columns=columns)\n        tm.assert_frame_equal(result, expected, check_dtype=False)\n\n        # GH 4297\n        # support Array\n        import array\n\n        result = DataFrame({\"A\": array.array(\"i\", range(10))})\n        expected = DataFrame({\"A\": list(range(10))})\n        tm.assert_frame_equal(result, expected, check_dtype=False)\n\n        expected = DataFrame([list(range(10)), list(range(10))])\n        result = DataFrame([array.array(\"i\", range(10)), array.array(\"i\", range(10))])\n        tm.assert_frame_equal(result, expected, check_dtype=False)\n\n    def test_constructor_range(self):\n        # GH26342\n        result = DataFrame(range(10))\n        expected = DataFrame(list(range(10)))\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_list_of_ranges(self):\n        result = DataFrame([range(10), range(10)])\n        expected = DataFrame([list(range(10)), list(range(10))])\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_iterable(self):\n        # GH 21987\n        class Iter:\n            def __iter__(self):\n                for i in range(10):\n                    yield [1, 2, 3]\n\n        expected = DataFrame([[1, 2, 3]] * 10)\n        result = DataFrame(Iter())\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_iterator(self):\n        result = DataFrame(iter(range(10)))\n        expected = DataFrame(list(range(10)))\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_list_of_iterators(self):\n        result = DataFrame([iter(range(10)), iter(range(10))])\n        expected = DataFrame([list(range(10)), list(range(10))])\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_generator(self):\n        # related #2305\n\n        gen1 = (i for i in range(10))\n        gen2 = (i for i in range(10))\n\n        expected = DataFrame([list(range(10)), list(range(10))])\n        result = DataFrame([gen1, gen2])\n        tm.assert_frame_equal(result, expected)\n\n        gen = ([i, \"a\"] for i in range(10))\n        result = DataFrame(gen)\n        expected = DataFrame({0: range(10), 1: \"a\"})\n        tm.assert_frame_equal(result, expected, check_dtype=False)\n\n    def test_constructor_list_of_odicts(self):\n        data = [\n            OrderedDict([[\"a\", 1.5], [\"b\", 3], [\"c\", 4], [\"d\", 6]]),\n            OrderedDict([[\"a\", 1.5], [\"b\", 3], [\"d\", 6]]),\n            OrderedDict([[\"a\", 1.5], [\"d\", 6]]),\n            OrderedDict(),\n            OrderedDict([[\"a\", 1.5], [\"b\", 3], [\"c\", 4]]),\n            OrderedDict([[\"b\", 3], [\"c\", 4], [\"d\", 6]]),\n        ]\n\n        result = DataFrame(data)\n        expected = DataFrame.from_dict(\n            dict(zip(range(len(data)), data)), orient=\"index\"\n        )\n        tm.assert_frame_equal(result, expected.reindex(result.index))\n\n        result = DataFrame([{}])\n        expected = DataFrame(index=[0])\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_ordered_dict_preserve_order(self):\n        # see gh-13304\n        expected = DataFrame([[2, 1]], columns=[\"b\", \"a\"])\n\n        data = OrderedDict()\n        data[\"b\"] = [2]\n        data[\"a\"] = [1]\n\n        result = DataFrame(data)\n        tm.assert_frame_equal(result, expected)\n\n        data = OrderedDict()\n        data[\"b\"] = 2\n        data[\"a\"] = 1\n\n        result = DataFrame([data])\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_ordered_dict_conflicting_orders(self):\n        # the first dict element sets the ordering for the DataFrame,\n        # even if there are conflicting orders from subsequent ones\n        row_one = OrderedDict()\n        row_one[\"b\"] = 2\n        row_one[\"a\"] = 1\n\n        row_two = OrderedDict()\n        row_two[\"a\"] = 1\n        row_two[\"b\"] = 2\n\n        row_three = {\"b\": 2, \"a\": 1}\n\n        expected = DataFrame([[2, 1], [2, 1]], columns=[\"b\", \"a\"])\n        result = DataFrame([row_one, row_two])\n        tm.assert_frame_equal(result, expected)\n\n        expected = DataFrame([[2, 1], [2, 1], [2, 1]], columns=[\"b\", \"a\"])\n        result = DataFrame([row_one, row_two, row_three])\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_list_of_series(self):\n        data = [\n            OrderedDict([[\"a\", 1.5], [\"b\", 3.0], [\"c\", 4.0]]),\n            OrderedDict([[\"a\", 1.5], [\"b\", 3.0], [\"c\", 6.0]]),\n        ]\n        sdict = OrderedDict(zip([\"x\", \"y\"], data))\n        idx = Index([\"a\", \"b\", \"c\"])\n\n        # all named\n        data2 = [\n            Series([1.5, 3, 4], idx, dtype=\"O\", name=\"x\"),\n            Series([1.5, 3, 6], idx, name=\"y\"),\n        ]\n        result = DataFrame(data2)\n        expected = DataFrame.from_dict(sdict, orient=\"index\")\n        tm.assert_frame_equal(result, expected)\n\n        # some unnamed\n        data2 = [\n            Series([1.5, 3, 4], idx, dtype=\"O\", name=\"x\"),\n            Series([1.5, 3, 6], idx),\n        ]\n        result = DataFrame(data2)\n\n        sdict = OrderedDict(zip([\"x\", \"Unnamed 0\"], data))\n        expected = DataFrame.from_dict(sdict, orient=\"index\")\n        tm.assert_frame_equal(result, expected)\n\n        # none named\n        data = [\n            OrderedDict([[\"a\", 1.5], [\"b\", 3], [\"c\", 4], [\"d\", 6]]),\n            OrderedDict([[\"a\", 1.5], [\"b\", 3], [\"d\", 6]]),\n            OrderedDict([[\"a\", 1.5], [\"d\", 6]]),\n            OrderedDict(),\n            OrderedDict([[\"a\", 1.5], [\"b\", 3], [\"c\", 4]]),\n            OrderedDict([[\"b\", 3], [\"c\", 4], [\"d\", 6]]),\n        ]\n        data = [\n            create_series_with_explicit_dtype(d, dtype_if_empty=object) for d in data\n        ]\n\n        result = DataFrame(data)\n        sdict = OrderedDict(zip(range(len(data)), data))\n        expected = DataFrame.from_dict(sdict, orient=\"index\")\n        tm.assert_frame_equal(result, expected.reindex(result.index))\n\n        result2 = DataFrame(data, index=np.arange(6))\n        tm.assert_frame_equal(result, result2)\n\n        result = DataFrame([Series(dtype=object)])\n        expected = DataFrame(index=[0])\n        tm.assert_frame_equal(result, expected)\n\n        data = [\n            OrderedDict([[\"a\", 1.5], [\"b\", 3.0], [\"c\", 4.0]]),\n            OrderedDict([[\"a\", 1.5], [\"b\", 3.0], [\"c\", 6.0]]),\n        ]\n        sdict = OrderedDict(zip(range(len(data)), data))\n\n        idx = Index([\"a\", \"b\", \"c\"])\n        data2 = [Series([1.5, 3, 4], idx, dtype=\"O\"), Series([1.5, 3, 6], idx)]\n        result = DataFrame(data2)\n        expected = DataFrame.from_dict(sdict, orient=\"index\")\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_list_of_series_aligned_index(self):\n        series = [pd.Series(i, index=[\"b\", \"a\", \"c\"], name=str(i)) for i in range(3)]\n        result = pd.DataFrame(series)\n        expected = pd.DataFrame(\n            {\"b\": [0, 1, 2], \"a\": [0, 1, 2], \"c\": [0, 1, 2]},\n            columns=[\"b\", \"a\", \"c\"],\n            index=[\"0\", \"1\", \"2\"],\n        )\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_list_of_derived_dicts(self):\n        class CustomDict(dict):\n            pass\n\n        d = {\"a\": 1.5, \"b\": 3}\n\n        data_custom = [CustomDict(d)]\n        data = [d]\n\n        result_custom = DataFrame(data_custom)\n        result = DataFrame(data)\n        tm.assert_frame_equal(result, result_custom)\n\n    def test_constructor_ragged(self):\n        data = {\"A\": np.random.randn(10), \"B\": np.random.randn(8)}\n        with pytest.raises(ValueError, match=\"arrays must all be same length\"):\n            DataFrame(data)\n\n    def test_constructor_scalar(self):\n        idx = Index(range(3))\n        df = DataFrame({\"a\": 0}, index=idx)\n        expected = DataFrame({\"a\": [0, 0, 0]}, index=idx)\n        tm.assert_frame_equal(df, expected, check_dtype=False)\n\n    def test_constructor_Series_copy_bug(self, float_frame):\n        df = DataFrame(float_frame[\"A\"], index=float_frame.index, columns=[\"A\"])\n        df.copy()\n\n    def test_constructor_mixed_dict_and_Series(self):\n        data = {}\n        data[\"A\"] = {\"foo\": 1, \"bar\": 2, \"baz\": 3}\n        data[\"B\"] = Series([4, 3, 2, 1], index=[\"bar\", \"qux\", \"baz\", \"foo\"])\n\n        result = DataFrame(data)\n        assert result.index.is_monotonic\n\n        # ordering ambiguous, raise exception\n        with pytest.raises(ValueError, match=\"ambiguous ordering\"):\n            DataFrame({\"A\": [\"a\", \"b\"], \"B\": {\"a\": \"a\", \"b\": \"b\"}})\n\n        # this is OK though\n        result = DataFrame({\"A\": [\"a\", \"b\"], \"B\": Series([\"a\", \"b\"], index=[\"a\", \"b\"])})\n        expected = DataFrame({\"A\": [\"a\", \"b\"], \"B\": [\"a\", \"b\"]}, index=[\"a\", \"b\"])\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_mixed_type_rows(self):\n        # Issue 25075\n        data = [[1, 2], (3, 4)]\n        result = DataFrame(data)\n        expected = DataFrame([[1, 2], [3, 4]])\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"tuples,lists\",\n        [\n            ((), []),\n            ((()), []),\n            (((), ()), [(), ()]),\n            (((), ()), [[], []]),\n            (([], []), [[], []]),\n            (([1, 2, 3], [4, 5, 6]), [[1, 2, 3], [4, 5, 6]]),\n        ],\n    )\n    def test_constructor_tuple(self, tuples, lists):\n        # GH 25691\n        result = DataFrame(tuples)\n        expected = DataFrame(lists)\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_list_of_tuples(self):\n        result = DataFrame({\"A\": [(1, 2), (3, 4)]})\n        expected = DataFrame({\"A\": Series([(1, 2), (3, 4)])})\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_list_of_namedtuples(self):\n        # GH11181\n        from collections import namedtuple\n\n        named_tuple = namedtuple(\"Pandas\", list(\"ab\"))\n        tuples = [named_tuple(1, 3), named_tuple(2, 4)]\n        expected = DataFrame({\"a\": [1, 2], \"b\": [3, 4]})\n        result = DataFrame(tuples)\n        tm.assert_frame_equal(result, expected)\n\n        # with columns\n        expected = DataFrame({\"y\": [1, 2], \"z\": [3, 4]})\n        result = DataFrame(tuples, columns=[\"y\", \"z\"])\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_list_of_dict_order(self):\n        # GH10056\n        data = [\n            {\"First\": 1, \"Second\": 4, \"Third\": 7, \"Fourth\": 10},\n            {\"Second\": 5, \"First\": 2, \"Fourth\": 11, \"Third\": 8},\n            {\"Second\": 6, \"First\": 3, \"Fourth\": 12, \"Third\": 9, \"YYY\": 14, \"XXX\": 13},\n        ]\n        expected = DataFrame(\n            {\n                \"First\": [1, 2, 3],\n                \"Second\": [4, 5, 6],\n                \"Third\": [7, 8, 9],\n                \"Fourth\": [10, 11, 12],\n                \"YYY\": [None, None, 14],\n                \"XXX\": [None, None, 13],\n            }\n        )\n        result = DataFrame(data)\n        tm.assert_frame_equal(result, expected)\n\n    def test_constructor_orient(self, float_string_frame):\n        data_dict = float_string_frame.T._series\n        recons = DataFrame.from_dict(data_dict, orient=\"index\")\n        expected = float_string_frame.reindex(index=recons.index)\n        tm.assert_frame_equal(recons, expected)\n\n        # dict of sequence\n        a = {\"hi\": [32, 3, 3], \"there\": [3, 5, 3]}\n        rs = DataFrame.from_dict(a, orient=\"index\")\n        xp = DataFrame.from_dict(a).T.reindex(list(a.keys()))\n        tm.assert_frame_equal(rs, xp)\n\n    def test_constructor_from_ordered_dict(self):\n        # GH8425\n        a = OrderedDict(\n            [\n                (\"one\", OrderedDict([(\"col_a\", \"foo1\"), (\"col_b\", \"bar1\")])),\n                (\"two\", OrderedDict([(\"col_a\", \"foo2\"), (\"col_b\", \"bar2\")])),\n                (\"three\", OrderedDict([(\"col_a\", \"foo3\"), (\"col_b\", \"bar3\")])),\n            ]\n        )\n        expected = DataFrame.from_dict(a, orient=\"columns\").T\n        result = DataFrame.from_dict(a, orient=\"index\")\n        tm.assert_frame_equal(result, expected)\n\n    def test_from_dict_columns_parameter(self):\n        # GH 18529\n        # Test new columns parameter for from_dict that was added to make\n        # from_items(..., orient='index', columns=[...]) easier to replicate\n        result = DataFrame.from_dict(\n            OrderedDict([(\"A\", [1, 2]), (\"B\", [4, 5])]),\n            orient=\"index\",\n            columns=[\"one\", \"two\"],\n        )\n        expected = DataFrame([[1, 2], [4, 5]], index=[\"A\", \"B\"], columns=[\"one\", \"two\"])\n        tm.assert_frame_equal(result, expected)\n\n        msg = \"cannot use columns parameter with orient='columns'\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame.from_dict(\n                dict([(\"A\", [1, 2]), (\"B\", [4, 5])]),\n                orient=\"columns\",\n                columns=[\"one\", \"two\"],\n            )\n        with pytest.raises(ValueError, match=msg):\n            DataFrame.from_dict(\n                dict([(\"A\", [1, 2]), (\"B\", [4, 5])]), columns=[\"one\", \"two\"]\n            )\n\n    @pytest.mark.parametrize(\n        \"data_dict, keys\",\n        [\n            ([{(\"a\",): 1}, {(\"a\",): 2}], [(\"a\",)]),\n            ([OrderedDict([((\"a\",), 1), ((\"b\",), 2)])], [(\"a\",), (\"b\",)]),\n            ([{(\"a\", \"b\"): 1}], [(\"a\", \"b\")]),\n        ],\n    )\n    def test_constructor_from_dict_tuples(self, data_dict, keys):\n        # GH 16769\n        df = DataFrame.from_dict(data_dict)\n\n        result = df.columns\n        expected = Index(keys, dtype=\"object\", tupleize_cols=False)\n\n        tm.assert_index_equal(result, expected)\n\n    def test_constructor_Series_named(self):\n        a = Series([1, 2, 3], index=[\"a\", \"b\", \"c\"], name=\"x\")\n        df = DataFrame(a)\n        assert df.columns[0] == \"x\"\n        tm.assert_index_equal(df.index, a.index)\n\n        # ndarray like\n        arr = np.random.randn(10)\n        s = Series(arr, name=\"x\")\n        df = DataFrame(s)\n        expected = DataFrame(dict(x=s))\n        tm.assert_frame_equal(df, expected)\n\n        s = Series(arr, index=range(3, 13))\n        df = DataFrame(s)\n        expected = DataFrame({0: s})\n        tm.assert_frame_equal(df, expected)\n\n        msg = r\"Shape of passed values is \\(10, 1\\), indices imply \\(10, 2\\)\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame(s, columns=[1, 2])\n\n        # #2234\n        a = Series([], name=\"x\", dtype=object)\n        df = DataFrame(a)\n        assert df.columns[0] == \"x\"\n\n        # series with name and w/o\n        s1 = Series(arr, name=\"x\")\n        df = DataFrame([s1, arr]).T\n        expected = DataFrame({\"x\": s1, \"Unnamed 0\": arr}, columns=[\"x\", \"Unnamed 0\"])\n        tm.assert_frame_equal(df, expected)\n\n        # this is a bit non-intuitive here; the series collapse down to arrays\n        df = DataFrame([arr, s1]).T\n        expected = DataFrame({1: s1, 0: arr}, columns=[0, 1])\n        tm.assert_frame_equal(df, expected)\n\n    def test_constructor_Series_named_and_columns(self):\n        # GH 9232 validation\n\n        s0 = Series(range(5), name=0)\n        s1 = Series(range(5), name=1)\n\n        # matching name and column gives standard frame\n        tm.assert_frame_equal(pd.DataFrame(s0, columns=[0]), s0.to_frame())\n        tm.assert_frame_equal(pd.DataFrame(s1, columns=[1]), s1.to_frame())\n\n        # non-matching produces empty frame\n        assert pd.DataFrame(s0, columns=[1]).empty\n        assert pd.DataFrame(s1, columns=[0]).empty\n\n    def test_constructor_Series_differently_indexed(self):\n        # name\n        s1 = Series([1, 2, 3], index=[\"a\", \"b\", \"c\"], name=\"x\")\n\n        # no name\n        s2 = Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n\n        other_index = Index([\"a\", \"b\"])\n\n        df1 = DataFrame(s1, index=other_index)\n        exp1 = DataFrame(s1.reindex(other_index))\n        assert df1.columns[0] == \"x\"\n        tm.assert_frame_equal(df1, exp1)\n\n        df2 = DataFrame(s2, index=other_index)\n        exp2 = DataFrame(s2.reindex(other_index))\n        assert df2.columns[0] == 0\n        tm.assert_index_equal(df2.index, other_index)\n        tm.assert_frame_equal(df2, exp2)\n\n    def test_constructor_manager_resize(self, float_frame):\n        index = list(float_frame.index[:5])\n        columns = list(float_frame.columns[:3])\n\n        result = DataFrame(float_frame._data, index=index, columns=columns)\n        tm.assert_index_equal(result.index, Index(index))\n        tm.assert_index_equal(result.columns, Index(columns))\n\n    def test_constructor_mix_series_nonseries(self, float_frame):\n        df = DataFrame(\n            {\"A\": float_frame[\"A\"], \"B\": list(float_frame[\"B\"])}, columns=[\"A\", \"B\"]\n        )\n        tm.assert_frame_equal(df, float_frame.loc[:, [\"A\", \"B\"]])\n\n        msg = \"does not match index length\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame({\"A\": float_frame[\"A\"], \"B\": list(float_frame[\"B\"])[:-2]})\n\n    def test_constructor_miscast_na_int_dtype(self):\n        df = DataFrame([[np.nan, 1], [1, 0]], dtype=np.int64)\n        expected = DataFrame([[np.nan, 1], [1, 0]])\n        tm.assert_frame_equal(df, expected)\n\n    def test_constructor_column_duplicates(self):\n        # it works! #2079\n        df = DataFrame([[8, 5]], columns=[\"a\", \"a\"])\n        edf = DataFrame([[8, 5]])\n        edf.columns = [\"a\", \"a\"]\n\n        tm.assert_frame_equal(df, edf)\n\n        idf = DataFrame.from_records([(8, 5)], columns=[\"a\", \"a\"])\n\n        tm.assert_frame_equal(idf, edf)\n\n        msg = \"If using all scalar values, you must pass an index\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame.from_dict(OrderedDict([(\"b\", 8), (\"a\", 5), (\"a\", 6)]))\n\n    def test_constructor_empty_with_string_dtype(self):\n        # GH 9428\n        expected = DataFrame(index=[0, 1], columns=[0, 1], dtype=object)\n\n        df = DataFrame(index=[0, 1], columns=[0, 1], dtype=str)\n        tm.assert_frame_equal(df, expected)\n        df = DataFrame(index=[0, 1], columns=[0, 1], dtype=np.str_)\n        tm.assert_frame_equal(df, expected)\n        df = DataFrame(index=[0, 1], columns=[0, 1], dtype=np.unicode_)\n        tm.assert_frame_equal(df, expected)\n        df = DataFrame(index=[0, 1], columns=[0, 1], dtype=\"U5\")\n        tm.assert_frame_equal(df, expected)\n\n    def test_constructor_single_value(self):\n        # expecting single value upcasting here\n        df = DataFrame(0.0, index=[1, 2, 3], columns=[\"a\", \"b\", \"c\"])\n        tm.assert_frame_equal(\n            df, DataFrame(np.zeros(df.shape).astype(\"float64\"), df.index, df.columns)\n        )\n\n        df = DataFrame(0, index=[1, 2, 3], columns=[\"a\", \"b\", \"c\"])\n        tm.assert_frame_equal(\n            df, DataFrame(np.zeros(df.shape).astype(\"int64\"), df.index, df.columns)\n        )\n\n        df = DataFrame(\"a\", index=[1, 2], columns=[\"a\", \"c\"])\n        tm.assert_frame_equal(\n            df,\n            DataFrame(\n                np.array([[\"a\", \"a\"], [\"a\", \"a\"]], dtype=object),\n                index=[1, 2],\n                columns=[\"a\", \"c\"],\n            ),\n        )\n\n        msg = \"DataFrame constructor not properly called!\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame(\"a\", [1, 2])\n        with pytest.raises(ValueError, match=msg):\n            DataFrame(\"a\", columns=[\"a\", \"c\"])\n\n        msg = \"incompatible data and dtype\"\n        with pytest.raises(TypeError, match=msg):\n            DataFrame(\"a\", [1, 2], [\"a\", \"c\"], float)\n\n    def test_constructor_with_datetimes(self):\n        intname = np.dtype(np.int_).name\n        floatname = np.dtype(np.float_).name\n        datetime64name = np.dtype(\"M8[ns]\").name\n        objectname = np.dtype(np.object_).name\n\n        # single item\n        df = DataFrame(\n            {\n                \"A\": 1,\n                \"B\": \"foo\",\n                \"C\": \"bar\",\n                \"D\": Timestamp(\"20010101\"),\n                \"E\": datetime(2001, 1, 2, 0, 0),\n            },\n            index=np.arange(10),\n        )\n        result = df.dtypes\n        expected = Series(\n            [np.dtype(\"int64\")]\n            + [np.dtype(objectname)] * 2\n            + [np.dtype(datetime64name)] * 2,\n            index=list(\"ABCDE\"),\n        )\n        tm.assert_series_equal(result, expected)\n\n        # check with ndarray construction ndim==0 (e.g. we are passing a ndim 0\n        # ndarray with a dtype specified)\n        df = DataFrame(\n            {\n                \"a\": 1.0,\n                \"b\": 2,\n                \"c\": \"foo\",\n                floatname: np.array(1.0, dtype=floatname),\n                intname: np.array(1, dtype=intname),\n            },\n            index=np.arange(10),\n        )\n        result = df.dtypes\n        expected = Series(\n            [np.dtype(\"float64\")]\n            + [np.dtype(\"int64\")]\n            + [np.dtype(\"object\")]\n            + [np.dtype(\"float64\")]\n            + [np.dtype(intname)],\n            index=[\"a\", \"b\", \"c\", floatname, intname],\n        )\n        tm.assert_series_equal(result, expected)\n\n        # check with ndarray construction ndim>0\n        df = DataFrame(\n            {\n                \"a\": 1.0,\n                \"b\": 2,\n                \"c\": \"foo\",\n                floatname: np.array([1.0] * 10, dtype=floatname),\n                intname: np.array([1] * 10, dtype=intname),\n            },\n            index=np.arange(10),\n        )\n        result = df.dtypes\n        expected = Series(\n            [np.dtype(\"float64\")]\n            + [np.dtype(\"int64\")]\n            + [np.dtype(\"object\")]\n            + [np.dtype(\"float64\")]\n            + [np.dtype(intname)],\n            index=[\"a\", \"b\", \"c\", floatname, intname],\n        )\n        tm.assert_series_equal(result, expected)\n\n        # GH 2809\n        ind = date_range(start=\"2000-01-01\", freq=\"D\", periods=10)\n        datetimes = [ts.to_pydatetime() for ts in ind]\n        datetime_s = Series(datetimes)\n        assert datetime_s.dtype == \"M8[ns]\"\n\n        # GH 2810\n        ind = date_range(start=\"2000-01-01\", freq=\"D\", periods=10)\n        datetimes = [ts.to_pydatetime() for ts in ind]\n        dates = [ts.date() for ts in ind]\n        df = DataFrame(datetimes, columns=[\"datetimes\"])\n        df[\"dates\"] = dates\n        result = df.dtypes\n        expected = Series(\n            [np.dtype(\"datetime64[ns]\"), np.dtype(\"object\")],\n            index=[\"datetimes\", \"dates\"],\n        )\n        tm.assert_series_equal(result, expected)\n\n        # GH 7594\n        # don't coerce tz-aware\n        import pytz\n\n        tz = pytz.timezone(\"US/Eastern\")\n        dt = tz.localize(datetime(2012, 1, 1))\n\n        df = DataFrame({\"End Date\": dt}, index=[0])\n        assert df.iat[0, 0] == dt\n        tm.assert_series_equal(\n            df.dtypes, Series({\"End Date\": \"datetime64[ns, US/Eastern]\"})\n        )\n\n        df = DataFrame([{\"End Date\": dt}])\n        assert df.iat[0, 0] == dt\n        tm.assert_series_equal(\n            df.dtypes, Series({\"End Date\": \"datetime64[ns, US/Eastern]\"})\n        )\n\n        # tz-aware (UTC and other tz's)\n        # GH 8411\n        dr = date_range(\"20130101\", periods=3)\n        df = DataFrame({\"value\": dr})\n        assert df.iat[0, 0].tz is None\n        dr = date_range(\"20130101\", periods=3, tz=\"UTC\")\n        df = DataFrame({\"value\": dr})\n        assert str(df.iat[0, 0].tz) == \"UTC\"\n        dr = date_range(\"20130101\", periods=3, tz=\"US/Eastern\")\n        df = DataFrame({\"value\": dr})\n        assert str(df.iat[0, 0].tz) == \"US/Eastern\"\n\n        # GH 7822\n        # preserver an index with a tz on dict construction\n        i = date_range(\"1/1/2011\", periods=5, freq=\"10s\", tz=\"US/Eastern\")\n\n        expected = DataFrame({\"a\": i.to_series().reset_index(drop=True)})\n        df = DataFrame()\n        df[\"a\"] = i\n        tm.assert_frame_equal(df, expected)\n\n        df = DataFrame({\"a\": i})\n        tm.assert_frame_equal(df, expected)\n\n        # multiples\n        i_no_tz = date_range(\"1/1/2011\", periods=5, freq=\"10s\")\n        df = DataFrame({\"a\": i, \"b\": i_no_tz})\n        expected = DataFrame({\"a\": i.to_series().reset_index(drop=True), \"b\": i_no_tz})\n        tm.assert_frame_equal(df, expected)\n\n    @pytest.mark.parametrize(\n        \"arr\",\n        [\n            np.array([None, None, None, None, datetime.now(), None]),\n            np.array([None, None, datetime.now(), None]),\n            [[np.datetime64(\"NaT\")], [None]],\n            [[np.datetime64(\"NaT\")], [pd.NaT]],\n            [[None], [np.datetime64(\"NaT\")]],\n            [[None], [pd.NaT]],\n            [[pd.NaT], [np.datetime64(\"NaT\")]],\n            [[pd.NaT], [None]],\n        ],\n    )\n    def test_constructor_datetimes_with_nulls(self, arr):\n        # gh-15869, GH#11220\n        result = DataFrame(arr).dtypes\n        expected = Series([np.dtype(\"datetime64[ns]\")])\n        tm.assert_series_equal(result, expected)\n\n    def test_constructor_for_list_with_dtypes(self):\n        # test list of lists/ndarrays\n        df = DataFrame([np.arange(5) for x in range(5)])\n        result = df.dtypes\n        expected = Series([np.dtype(\"int64\")] * 5)\n        tm.assert_series_equal(result, expected)\n\n        df = DataFrame([np.array(np.arange(5), dtype=\"int32\") for x in range(5)])\n        result = df.dtypes\n        expected = Series([np.dtype(\"int64\")] * 5)\n        tm.assert_series_equal(result, expected)\n\n        # overflow issue? (we always expecte int64 upcasting here)\n        df = DataFrame({\"a\": [2 ** 31, 2 ** 31 + 1]})\n        assert df.dtypes.iloc[0] == np.dtype(\"int64\")\n\n        # GH #2751 (construction with no index specified), make sure we cast to\n        # platform values\n        df = DataFrame([1, 2])\n        assert df.dtypes.iloc[0] == np.dtype(\"int64\")\n\n        df = DataFrame([1.0, 2.0])\n        assert df.dtypes.iloc[0] == np.dtype(\"float64\")\n\n        df = DataFrame({\"a\": [1, 2]})\n        assert df.dtypes.iloc[0] == np.dtype(\"int64\")\n\n        df = DataFrame({\"a\": [1.0, 2.0]})\n        assert df.dtypes.iloc[0] == np.dtype(\"float64\")\n\n        df = DataFrame({\"a\": 1}, index=range(3))\n        assert df.dtypes.iloc[0] == np.dtype(\"int64\")\n\n        df = DataFrame({\"a\": 1.0}, index=range(3))\n        assert df.dtypes.iloc[0] == np.dtype(\"float64\")\n\n        # with object list\n        df = DataFrame(\n            {\n                \"a\": [1, 2, 4, 7],\n                \"b\": [1.2, 2.3, 5.1, 6.3],\n                \"c\": list(\"abcd\"),\n                \"d\": [datetime(2000, 1, 1) for i in range(4)],\n                \"e\": [1.0, 2, 4.0, 7],\n            }\n        )\n        result = df.dtypes\n        expected = Series(\n            [\n                np.dtype(\"int64\"),\n                np.dtype(\"float64\"),\n                np.dtype(\"object\"),\n                np.dtype(\"datetime64[ns]\"),\n                np.dtype(\"float64\"),\n            ],\n            index=list(\"abcde\"),\n        )\n        tm.assert_series_equal(result, expected)\n\n    def test_constructor_frame_copy(self, float_frame):\n        cop = DataFrame(float_frame, copy=True)\n        cop[\"A\"] = 5\n        assert (cop[\"A\"] == 5).all()\n        assert not (float_frame[\"A\"] == 5).all()\n\n    def test_constructor_ndarray_copy(self, float_frame):\n        df = DataFrame(float_frame.values)\n\n        float_frame.values[5] = 5\n        assert (df.values[5] == 5).all()\n\n        df = DataFrame(float_frame.values, copy=True)\n        float_frame.values[6] = 6\n        assert not (df.values[6] == 6).all()\n\n    def test_constructor_series_copy(self, float_frame):\n        series = float_frame._series\n\n        df = DataFrame({\"A\": series[\"A\"]})\n        df[\"A\"][:] = 5\n\n        assert not (series[\"A\"] == 5).all()\n\n    def test_constructor_with_nas(self):\n        # GH 5016\n        # na's in indices\n\n        def check(df):\n            for i in range(len(df.columns)):\n                df.iloc[:, i]\n\n            indexer = np.arange(len(df.columns))[isna(df.columns)]\n\n            # No NaN found -> error\n            if len(indexer) == 0:\n                msg = (\n                    \"cannot do label indexing on\"\n                    r\" <class 'pandas\\.core\\.indexes\\.range\\.RangeIndex'>\"\n                    r\" with these indexers \\[nan\\] of <class 'float'>\"\n                )\n                with pytest.raises(TypeError, match=msg):\n                    df.loc[:, np.nan]\n            # single nan should result in Series\n            elif len(indexer) == 1:\n                tm.assert_series_equal(df.iloc[:, indexer[0]], df.loc[:, np.nan])\n            # multiple nans should result in DataFrame\n            else:\n                tm.assert_frame_equal(df.iloc[:, indexer], df.loc[:, np.nan])\n\n        df = DataFrame([[1, 2, 3], [4, 5, 6]], index=[1, np.nan])\n        check(df)\n\n        df = DataFrame([[1, 2, 3], [4, 5, 6]], columns=[1.1, 2.2, np.nan])\n        check(df)\n\n        df = DataFrame([[0, 1, 2, 3], [4, 5, 6, 7]], columns=[np.nan, 1.1, 2.2, np.nan])\n        check(df)\n\n        df = DataFrame(\n            [[0.0, 1, 2, 3.0], [4, 5, 6, 7]], columns=[np.nan, 1.1, 2.2, np.nan]\n        )\n        check(df)\n\n        # GH 21428 (non-unique columns)\n        df = DataFrame([[0.0, 1, 2, 3.0], [4, 5, 6, 7]], columns=[np.nan, 1, 2, 2])\n        check(df)\n\n    def test_constructor_lists_to_object_dtype(self):\n        # from #1074\n        d = DataFrame({\"a\": [np.nan, False]})\n        assert d[\"a\"].dtype == np.object_\n        assert not d[\"a\"][1]\n\n    def test_constructor_categorical(self):\n\n        # GH8626\n\n        # dict creation\n        df = DataFrame({\"A\": list(\"abc\")}, dtype=\"category\")\n        expected = Series(list(\"abc\"), dtype=\"category\", name=\"A\")\n        tm.assert_series_equal(df[\"A\"], expected)\n\n        # to_frame\n        s = Series(list(\"abc\"), dtype=\"category\")\n        result = s.to_frame()\n        expected = Series(list(\"abc\"), dtype=\"category\", name=0)\n        tm.assert_series_equal(result[0], expected)\n        result = s.to_frame(name=\"foo\")\n        expected = Series(list(\"abc\"), dtype=\"category\", name=\"foo\")\n        tm.assert_series_equal(result[\"foo\"], expected)\n\n        # list-like creation\n        df = DataFrame(list(\"abc\"), dtype=\"category\")\n        expected = Series(list(\"abc\"), dtype=\"category\", name=0)\n        tm.assert_series_equal(df[0], expected)\n\n        # ndim != 1\n        df = DataFrame([Categorical(list(\"abc\"))])\n        expected = DataFrame({0: Series(list(\"abc\"), dtype=\"category\")})\n        tm.assert_frame_equal(df, expected)\n\n        df = DataFrame([Categorical(list(\"abc\")), Categorical(list(\"abd\"))])\n        expected = DataFrame(\n            {\n                0: Series(list(\"abc\"), dtype=\"category\"),\n                1: Series(list(\"abd\"), dtype=\"category\"),\n            },\n            columns=[0, 1],\n        )\n        tm.assert_frame_equal(df, expected)\n\n        # mixed\n        df = DataFrame([Categorical(list(\"abc\")), list(\"def\")])\n        expected = DataFrame(\n            {0: Series(list(\"abc\"), dtype=\"category\"), 1: list(\"def\")}, columns=[0, 1]\n        )\n        tm.assert_frame_equal(df, expected)\n\n        # invalid (shape)\n        msg = r\"Shape of passed values is \\(6, 2\\), indices imply \\(3, 2\\)\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame([Categorical(list(\"abc\")), Categorical(list(\"abdefg\"))])\n\n        # ndim > 1\n        msg = \"> 1 ndim Categorical are not supported at this time\"\n        with pytest.raises(NotImplementedError, match=msg):\n            Categorical(np.array([list(\"abcd\")]))\n\n    def test_constructor_categorical_series(self):\n\n        items = [1, 2, 3, 1]\n        exp = Series(items).astype(\"category\")\n        res = Series(items, dtype=\"category\")\n        tm.assert_series_equal(res, exp)\n\n        items = [\"a\", \"b\", \"c\", \"a\"]\n        exp = Series(items).astype(\"category\")\n        res = Series(items, dtype=\"category\")\n        tm.assert_series_equal(res, exp)\n\n        # insert into frame with different index\n        # GH 8076\n        index = date_range(\"20000101\", periods=3)\n        expected = Series(\n            Categorical(values=[np.nan, np.nan, np.nan], categories=[\"a\", \"b\", \"c\"])\n        )\n        expected.index = index\n\n        expected = DataFrame({\"x\": expected})\n        df = DataFrame({\"x\": Series([\"a\", \"b\", \"c\"], dtype=\"category\")}, index=index)\n        tm.assert_frame_equal(df, expected)\n\n    def test_from_records_to_records(self):\n        # from numpy documentation\n        arr = np.zeros((2,), dtype=(\"i4,f4,a10\"))\n        arr[:] = [(1, 2.0, \"Hello\"), (2, 3.0, \"World\")]\n\n        # TODO(wesm): unused\n        frame = DataFrame.from_records(arr)  # noqa\n\n        index = pd.Index(np.arange(len(arr))[::-1])\n        indexed_frame = DataFrame.from_records(arr, index=index)\n        tm.assert_index_equal(indexed_frame.index, index)\n\n        # without names, it should go to last ditch\n        arr2 = np.zeros((2, 3))\n        tm.assert_frame_equal(DataFrame.from_records(arr2), DataFrame(arr2))\n\n        # wrong length\n        msg = r\"Shape of passed values is \\(2, 3\\), indices imply \\(1, 3\\)\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame.from_records(arr, index=index[:-1])\n\n        indexed_frame = DataFrame.from_records(arr, index=\"f1\")\n\n        # what to do?\n        records = indexed_frame.to_records()\n        assert len(records.dtype.names) == 3\n\n        records = indexed_frame.to_records(index=False)\n        assert len(records.dtype.names) == 2\n        assert \"index\" not in records.dtype.names\n\n    def test_from_records_nones(self):\n        tuples = [(1, 2, None, 3), (1, 2, None, 3), (None, 2, 5, 3)]\n\n        df = DataFrame.from_records(tuples, columns=[\"a\", \"b\", \"c\", \"d\"])\n        assert np.isnan(df[\"c\"][0])\n\n    def test_from_records_iterator(self):\n        arr = np.array(\n            [(1.0, 1.0, 2, 2), (3.0, 3.0, 4, 4), (5.0, 5.0, 6, 6), (7.0, 7.0, 8, 8)],\n            dtype=[\n                (\"x\", np.float64),\n                (\"u\", np.float32),\n                (\"y\", np.int64),\n                (\"z\", np.int32),\n            ],\n        )\n        df = DataFrame.from_records(iter(arr), nrows=2)\n        xp = DataFrame(\n            {\n                \"x\": np.array([1.0, 3.0], dtype=np.float64),\n                \"u\": np.array([1.0, 3.0], dtype=np.float32),\n                \"y\": np.array([2, 4], dtype=np.int64),\n                \"z\": np.array([2, 4], dtype=np.int32),\n            }\n        )\n        tm.assert_frame_equal(df.reindex_like(xp), xp)\n\n        # no dtypes specified here, so just compare with the default\n        arr = [(1.0, 2), (3.0, 4), (5.0, 6), (7.0, 8)]\n        df = DataFrame.from_records(iter(arr), columns=[\"x\", \"y\"], nrows=2)\n        tm.assert_frame_equal(df, xp.reindex(columns=[\"x\", \"y\"]), check_dtype=False)\n\n    def test_from_records_tuples_generator(self):\n        def tuple_generator(length):\n            for i in range(length):\n                letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n                yield (i, letters[i % len(letters)], i / length)\n\n        columns_names = [\"Integer\", \"String\", \"Float\"]\n        columns = [\n            [i[j] for i in tuple_generator(10)] for j in range(len(columns_names))\n        ]\n        data = {\"Integer\": columns[0], \"String\": columns[1], \"Float\": columns[2]}\n        expected = DataFrame(data, columns=columns_names)\n\n        generator = tuple_generator(10)\n        result = DataFrame.from_records(generator, columns=columns_names)\n        tm.assert_frame_equal(result, expected)\n\n    def test_from_records_lists_generator(self):\n        def list_generator(length):\n            for i in range(length):\n                letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n                yield [i, letters[i % len(letters)], i / length]\n\n        columns_names = [\"Integer\", \"String\", \"Float\"]\n        columns = [\n            [i[j] for i in list_generator(10)] for j in range(len(columns_names))\n        ]\n        data = {\"Integer\": columns[0], \"String\": columns[1], \"Float\": columns[2]}\n        expected = DataFrame(data, columns=columns_names)\n\n        generator = list_generator(10)\n        result = DataFrame.from_records(generator, columns=columns_names)\n        tm.assert_frame_equal(result, expected)\n\n    def test_from_records_columns_not_modified(self):\n        tuples = [(1, 2, 3), (1, 2, 3), (2, 5, 3)]\n\n        columns = [\"a\", \"b\", \"c\"]\n        original_columns = list(columns)\n\n        df = DataFrame.from_records(tuples, columns=columns, index=\"a\")  # noqa\n\n        assert columns == original_columns\n\n    def test_from_records_decimal(self):\n        from decimal import Decimal\n\n        tuples = [(Decimal(\"1.5\"),), (Decimal(\"2.5\"),), (None,)]\n\n        df = DataFrame.from_records(tuples, columns=[\"a\"])\n        assert df[\"a\"].dtype == object\n\n        df = DataFrame.from_records(tuples, columns=[\"a\"], coerce_float=True)\n        assert df[\"a\"].dtype == np.float64\n        assert np.isnan(df[\"a\"].values[-1])\n\n    def test_from_records_duplicates(self):\n        result = DataFrame.from_records([(1, 2, 3), (4, 5, 6)], columns=[\"a\", \"b\", \"a\"])\n\n        expected = DataFrame([(1, 2, 3), (4, 5, 6)], columns=[\"a\", \"b\", \"a\"])\n\n        tm.assert_frame_equal(result, expected)\n\n    def test_from_records_set_index_name(self):\n        def create_dict(order_id):\n            return {\n                \"order_id\": order_id,\n                \"quantity\": np.random.randint(1, 10),\n                \"price\": np.random.randint(1, 10),\n            }\n\n        documents = [create_dict(i) for i in range(10)]\n        # demo missing data\n        documents.append({\"order_id\": 10, \"quantity\": 5})\n\n        result = DataFrame.from_records(documents, index=\"order_id\")\n        assert result.index.name == \"order_id\"\n\n        # MultiIndex\n        result = DataFrame.from_records(documents, index=[\"order_id\", \"quantity\"])\n        assert result.index.names == (\"order_id\", \"quantity\")\n\n    def test_from_records_misc_brokenness(self):\n        # #2179\n\n        data = {1: [\"foo\"], 2: [\"bar\"]}\n\n        result = DataFrame.from_records(data, columns=[\"a\", \"b\"])\n        exp = DataFrame(data, columns=[\"a\", \"b\"])\n        tm.assert_frame_equal(result, exp)\n\n        # overlap in index/index_names\n\n        data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n\n        result = DataFrame.from_records(data, index=[\"a\", \"b\", \"c\"])\n        exp = DataFrame(data, index=[\"a\", \"b\", \"c\"])\n        tm.assert_frame_equal(result, exp)\n\n        # GH 2623\n        rows = []\n        rows.append([datetime(2010, 1, 1), 1])\n        rows.append([datetime(2010, 1, 2), \"hi\"])  # test col upconverts to obj\n        df2_obj = DataFrame.from_records(rows, columns=[\"date\", \"test\"])\n        result = df2_obj.dtypes\n        expected = Series(\n            [np.dtype(\"datetime64[ns]\"), np.dtype(\"object\")], index=[\"date\", \"test\"]\n        )\n        tm.assert_series_equal(result, expected)\n\n        rows = []\n        rows.append([datetime(2010, 1, 1), 1])\n        rows.append([datetime(2010, 1, 2), 1])\n        df2_obj = DataFrame.from_records(rows, columns=[\"date\", \"test\"])\n        result = df2_obj.dtypes\n        expected = Series(\n            [np.dtype(\"datetime64[ns]\"), np.dtype(\"int64\")], index=[\"date\", \"test\"]\n        )\n        tm.assert_series_equal(result, expected)\n\n    def test_from_records_empty(self):\n        # 3562\n        result = DataFrame.from_records([], columns=[\"a\", \"b\", \"c\"])\n        expected = DataFrame(columns=[\"a\", \"b\", \"c\"])\n        tm.assert_frame_equal(result, expected)\n\n        result = DataFrame.from_records([], columns=[\"a\", \"b\", \"b\"])\n        expected = DataFrame(columns=[\"a\", \"b\", \"b\"])\n        tm.assert_frame_equal(result, expected)\n\n    def test_from_records_empty_with_nonempty_fields_gh3682(self):\n        a = np.array([(1, 2)], dtype=[(\"id\", np.int64), (\"value\", np.int64)])\n        df = DataFrame.from_records(a, index=\"id\")\n        tm.assert_index_equal(df.index, Index([1], name=\"id\"))\n        assert df.index.name == \"id\"\n        tm.assert_index_equal(df.columns, Index([\"value\"]))\n\n        b = np.array([], dtype=[(\"id\", np.int64), (\"value\", np.int64)])\n        df = DataFrame.from_records(b, index=\"id\")\n        tm.assert_index_equal(df.index, Index([], name=\"id\"))\n        assert df.index.name == \"id\"\n\n    def test_from_records_with_datetimes(self):\n\n        # this may fail on certain platforms because of a numpy issue\n        # related GH6140\n        if not is_platform_little_endian():\n            pytest.skip(\"known failure of test on non-little endian\")\n\n        # construction with a null in a recarray\n        # GH 6140\n        expected = DataFrame({\"EXPIRY\": [datetime(2005, 3, 1, 0, 0), None]})\n\n        arrdata = [np.array([datetime(2005, 3, 1, 0, 0), None])]\n        dtypes = [(\"EXPIRY\", \"<M8[ns]\")]\n\n        try:\n            recarray = np.core.records.fromarrays(arrdata, dtype=dtypes)\n        except (ValueError):\n            pytest.skip(\"known failure of numpy rec array creation\")\n\n        result = DataFrame.from_records(recarray)\n        tm.assert_frame_equal(result, expected)\n\n        # coercion should work too\n        arrdata = [np.array([datetime(2005, 3, 1, 0, 0), None])]\n        dtypes = [(\"EXPIRY\", \"<M8[m]\")]\n        recarray = np.core.records.fromarrays(arrdata, dtype=dtypes)\n        result = DataFrame.from_records(recarray)\n        tm.assert_frame_equal(result, expected)\n\n    def test_from_records_sequencelike(self):\n        df = DataFrame(\n            {\n                \"A\": np.array(np.random.randn(6), dtype=np.float64),\n                \"A1\": np.array(np.random.randn(6), dtype=np.float64),\n                \"B\": np.array(np.arange(6), dtype=np.int64),\n                \"C\": [\"foo\"] * 6,\n                \"D\": np.array([True, False] * 3, dtype=bool),\n                \"E\": np.array(np.random.randn(6), dtype=np.float32),\n                \"E1\": np.array(np.random.randn(6), dtype=np.float32),\n                \"F\": np.array(np.arange(6), dtype=np.int32),\n            }\n        )\n\n        # this is actually tricky to create the recordlike arrays and\n        # have the dtypes be intact\n        blocks = df._to_dict_of_blocks()\n        tuples = []\n        columns = []\n        dtypes = []\n        for dtype, b in blocks.items():\n            columns.extend(b.columns)\n            dtypes.extend([(c, np.dtype(dtype).descr[0][1]) for c in b.columns])\n        for i in range(len(df.index)):\n            tup = []\n            for _, b in blocks.items():\n                tup.extend(b.iloc[i].values)\n            tuples.append(tuple(tup))\n\n        recarray = np.array(tuples, dtype=dtypes).view(np.recarray)\n        recarray2 = df.to_records()\n        lists = [list(x) for x in tuples]\n\n        # tuples (lose the dtype info)\n        result = DataFrame.from_records(tuples, columns=columns).reindex(\n            columns=df.columns\n        )\n\n        # created recarray and with to_records recarray (have dtype info)\n        result2 = DataFrame.from_records(recarray, columns=columns).reindex(\n            columns=df.columns\n        )\n        result3 = DataFrame.from_records(recarray2, columns=columns).reindex(\n            columns=df.columns\n        )\n\n        # list of tupels (no dtype info)\n        result4 = DataFrame.from_records(lists, columns=columns).reindex(\n            columns=df.columns\n        )\n\n        tm.assert_frame_equal(result, df, check_dtype=False)\n        tm.assert_frame_equal(result2, df)\n        tm.assert_frame_equal(result3, df)\n        tm.assert_frame_equal(result4, df, check_dtype=False)\n\n        # tuples is in the order of the columns\n        result = DataFrame.from_records(tuples)\n        tm.assert_index_equal(result.columns, pd.RangeIndex(8))\n\n        # test exclude parameter & we are casting the results here (as we don't\n        # have dtype info to recover)\n        columns_to_test = [columns.index(\"C\"), columns.index(\"E1\")]\n\n        exclude = list(set(range(8)) - set(columns_to_test))\n        result = DataFrame.from_records(tuples, exclude=exclude)\n        result.columns = [columns[i] for i in sorted(columns_to_test)]\n        tm.assert_series_equal(result[\"C\"], df[\"C\"])\n        tm.assert_series_equal(result[\"E1\"], df[\"E1\"].astype(\"float64\"))\n\n        # empty case\n        result = DataFrame.from_records([], columns=[\"foo\", \"bar\", \"baz\"])\n        assert len(result) == 0\n        tm.assert_index_equal(result.columns, pd.Index([\"foo\", \"bar\", \"baz\"]))\n\n        result = DataFrame.from_records([])\n        assert len(result) == 0\n        assert len(result.columns) == 0\n\n    def test_from_records_dictlike(self):\n\n        # test the dict methods\n        df = DataFrame(\n            {\n                \"A\": np.array(np.random.randn(6), dtype=np.float64),\n                \"A1\": np.array(np.random.randn(6), dtype=np.float64),\n                \"B\": np.array(np.arange(6), dtype=np.int64),\n                \"C\": [\"foo\"] * 6,\n                \"D\": np.array([True, False] * 3, dtype=bool),\n                \"E\": np.array(np.random.randn(6), dtype=np.float32),\n                \"E1\": np.array(np.random.randn(6), dtype=np.float32),\n                \"F\": np.array(np.arange(6), dtype=np.int32),\n            }\n        )\n\n        # columns is in a different order here than the actual items iterated\n        # from the dict\n        blocks = df._to_dict_of_blocks()\n        columns = []\n        for dtype, b in blocks.items():\n            columns.extend(b.columns)\n\n        asdict = {x: y for x, y in df.items()}\n        asdict2 = {x: y.values for x, y in df.items()}\n\n        # dict of series & dict of ndarrays (have dtype info)\n        results = []\n        results.append(DataFrame.from_records(asdict).reindex(columns=df.columns))\n        results.append(\n            DataFrame.from_records(asdict, columns=columns).reindex(columns=df.columns)\n        )\n        results.append(\n            DataFrame.from_records(asdict2, columns=columns).reindex(columns=df.columns)\n        )\n\n        for r in results:\n            tm.assert_frame_equal(r, df)\n\n    def test_from_records_with_index_data(self):\n        df = DataFrame(np.random.randn(10, 3), columns=[\"A\", \"B\", \"C\"])\n\n        data = np.random.randn(10)\n        df1 = DataFrame.from_records(df, index=data)\n        tm.assert_index_equal(df1.index, Index(data))\n\n    def test_from_records_bad_index_column(self):\n        df = DataFrame(np.random.randn(10, 3), columns=[\"A\", \"B\", \"C\"])\n\n        # should pass\n        df1 = DataFrame.from_records(df, index=[\"C\"])\n        tm.assert_index_equal(df1.index, Index(df.C))\n\n        df1 = DataFrame.from_records(df, index=\"C\")\n        tm.assert_index_equal(df1.index, Index(df.C))\n\n        # should fail\n        msg = r\"Shape of passed values is \\(10, 3\\), indices imply \\(1, 3\\)\"\n        with pytest.raises(ValueError, match=msg):\n            DataFrame.from_records(df, index=[2])\n        with pytest.raises(KeyError, match=r\"^2$\"):\n            DataFrame.from_records(df, index=2)\n\n    def test_from_records_non_tuple(self):\n        class Record:\n            def __init__(self, *args):\n                self.args = args\n\n            def __getitem__(self, i):\n                return self.args[i]\n\n            def __iter__(self):\n                return iter(self.args)\n\n        recs = [Record(1, 2, 3), Record(4, 5, 6), Record(7, 8, 9)]\n        tups = [tuple(rec) for rec in recs]\n\n        result = DataFrame.from_records(recs)\n        expected = DataFrame.from_records(tups)\n        tm.assert_frame_equal(result, expected)\n\n    def test_from_records_len0_with_columns(self):\n        # #2633\n        result = DataFrame.from_records([], index=\"foo\", columns=[\"foo\", \"bar\"])\n        expected = Index([\"bar\"])\n\n        assert len(result) == 0\n        assert result.index.name == \"foo\"\n        tm.assert_index_equal(result.columns, expected)\n\n    def test_from_records_series_list_dict(self):\n        # GH27358\n        expected = DataFrame([[{\"a\": 1, \"b\": 2}, {\"a\": 3, \"b\": 4}]]).T\n        data = Series([[{\"a\": 1, \"b\": 2}], [{\"a\": 3, \"b\": 4}]])\n        result = DataFrame.from_records(data)\n        tm.assert_frame_equal(result, expected)\n\n    def test_to_frame_with_falsey_names(self):\n        # GH 16114\n        result = Series(name=0, dtype=object).to_frame().dtypes\n        expected = Series({0: object})\n        tm.assert_series_equal(result, expected)\n\n        result = DataFrame(Series(name=0, dtype=object)).dtypes\n        tm.assert_series_equal(result, expected)\n\n    @pytest.mark.parametrize(\"dtype\", [None, \"uint8\", \"category\"])\n    def test_constructor_range_dtype(self, dtype):\n        expected = DataFrame({\"A\": [0, 1, 2, 3, 4]}, dtype=dtype or \"int64\")\n\n        # GH 26342\n        result = DataFrame(range(5), columns=[\"A\"], dtype=dtype)\n        tm.assert_frame_equal(result, expected)\n\n        # GH 16804\n        result = DataFrame({\"A\": range(5)}, dtype=dtype)\n        tm.assert_frame_equal(result, expected)\n\n    def test_frame_from_list_subclass(self):\n        # GH21226\n        class List(list):\n            pass\n\n        expected = DataFrame([[1, 2, 3], [4, 5, 6]])\n        result = DataFrame(List([List([1, 2, 3]), List([4, 5, 6])]))\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"extension_arr\",\n        [\n            Categorical(list(\"aabbc\")),\n            pd.SparseArray([1, np.nan, np.nan, np.nan]),\n            IntervalArray([pd.Interval(0, 1), pd.Interval(1, 5)]),\n            PeriodArray(pd.period_range(start=\"1/1/2017\", end=\"1/1/2018\", freq=\"M\")),\n        ],\n    )\n    def test_constructor_with_extension_array(self, extension_arr):\n        # GH11363\n        expected = DataFrame(Series(extension_arr))\n        result = DataFrame(extension_arr)\n        tm.assert_frame_equal(result, expected)\n\n\nclass TestDataFrameConstructorWithDatetimeTZ:\n    def test_from_dict(self):\n\n        # 8260\n        # support datetime64 with tz\n\n        idx = Index(date_range(\"20130101\", periods=3, tz=\"US/Eastern\"), name=\"foo\")\n        dr = date_range(\"20130110\", periods=3)\n\n        # construction\n        df = DataFrame({\"A\": idx, \"B\": dr})\n        assert df[\"A\"].dtype, \"M8[ns, US/Eastern\"\n        assert df[\"A\"].name == \"A\"\n        tm.assert_series_equal(df[\"A\"], Series(idx, name=\"A\"))\n        tm.assert_series_equal(df[\"B\"], Series(dr, name=\"B\"))\n\n    def test_from_index(self):\n\n        # from index\n        idx2 = date_range(\"20130101\", periods=3, tz=\"US/Eastern\", name=\"foo\")\n        df2 = DataFrame(idx2)\n        tm.assert_series_equal(df2[\"foo\"], Series(idx2, name=\"foo\"))\n        df2 = DataFrame(Series(idx2))\n        tm.assert_series_equal(df2[\"foo\"], Series(idx2, name=\"foo\"))\n\n        idx2 = date_range(\"20130101\", periods=3, tz=\"US/Eastern\")\n        df2 = DataFrame(idx2)\n        tm.assert_series_equal(df2[0], Series(idx2, name=0))\n        df2 = DataFrame(Series(idx2))\n        tm.assert_series_equal(df2[0], Series(idx2, name=0))\n\n    def test_frame_dict_constructor_datetime64_1680(self):\n        dr = date_range(\"1/1/2012\", periods=10)\n        s = Series(dr, index=dr)\n\n        # it works!\n        DataFrame({\"a\": \"foo\", \"b\": s}, index=dr)\n        DataFrame({\"a\": \"foo\", \"b\": s.values}, index=dr)\n\n    def test_frame_datetime64_mixed_index_ctor_1681(self):\n        dr = date_range(\"2011/1/1\", \"2012/1/1\", freq=\"W-FRI\")\n        ts = Series(dr)\n\n        # it works!\n        d = DataFrame({\"A\": \"foo\", \"B\": ts}, index=dr)\n        assert d[\"B\"].isna().all()\n\n    def test_frame_timeseries_to_records(self):\n        index = date_range(\"1/1/2000\", periods=10)\n        df = DataFrame(np.random.randn(10, 3), index=index, columns=[\"a\", \"b\", \"c\"])\n\n        result = df.to_records()\n        result[\"index\"].dtype == \"M8[ns]\"\n\n        result = df.to_records(index=False)\n\n    def test_frame_timeseries_column(self):\n        # GH19157\n        dr = date_range(start=\"20130101T10:00:00\", periods=3, freq=\"T\", tz=\"US/Eastern\")\n        result = DataFrame(dr, columns=[\"timestamps\"])\n        expected = DataFrame(\n            {\n                \"timestamps\": [\n                    Timestamp(\"20130101T10:00:00\", tz=\"US/Eastern\"),\n                    Timestamp(\"20130101T10:01:00\", tz=\"US/Eastern\"),\n                    Timestamp(\"20130101T10:02:00\", tz=\"US/Eastern\"),\n                ]\n            }\n        )\n        tm.assert_frame_equal(result, expected)\n\n    def test_nested_dict_construction(self):\n        # GH22227\n        columns = [\"Nevada\", \"Ohio\"]\n        pop = {\n            \"Nevada\": {2001: 2.4, 2002: 2.9},\n            \"Ohio\": {2000: 1.5, 2001: 1.7, 2002: 3.6},\n        }\n        result = pd.DataFrame(pop, index=[2001, 2002, 2003], columns=columns)\n        expected = pd.DataFrame(\n            [(2.4, 1.7), (2.9, 3.6), (np.nan, np.nan)],\n            columns=columns,\n            index=pd.Index([2001, 2002, 2003]),\n        )\n        tm.assert_frame_equal(result, expected)\n\n    def test_from_tzaware_object_array(self):\n        # GH#26825 2D object array of tzaware timestamps should not raise\n        dti = pd.date_range(\"2016-04-05 04:30\", periods=3, tz=\"UTC\")\n        data = dti._data.astype(object).reshape(1, -1)\n        df = pd.DataFrame(data)\n        assert df.shape == (1, 3)\n        assert (df.dtypes == dti.dtype).all()\n        assert (df == dti).all().all()\n\n    def test_from_tzaware_mixed_object_array(self):\n        # GH#26825\n        arr = np.array(\n            [\n                [\n                    Timestamp(\"2013-01-01 00:00:00\"),\n                    Timestamp(\"2013-01-02 00:00:00\"),\n                    Timestamp(\"2013-01-03 00:00:00\"),\n                ],\n                [\n                    Timestamp(\"2013-01-01 00:00:00-0500\", tz=\"US/Eastern\"),\n                    pd.NaT,\n                    Timestamp(\"2013-01-03 00:00:00-0500\", tz=\"US/Eastern\"),\n                ],\n                [\n                    Timestamp(\"2013-01-01 00:00:00+0100\", tz=\"CET\"),\n                    pd.NaT,\n                    Timestamp(\"2013-01-03 00:00:00+0100\", tz=\"CET\"),\n                ],\n            ],\n            dtype=object,\n        ).T\n        res = DataFrame(arr, columns=[\"A\", \"B\", \"C\"])\n\n        expected_dtypes = [\n            \"datetime64[ns]\",\n            \"datetime64[ns, US/Eastern]\",\n            \"datetime64[ns, CET]\",\n        ]\n        assert (res.dtypes == expected_dtypes).all()\n"
    },
    {
      "filename": "pandas/tests/io/parser/test_header.py",
      "content": "\"\"\"\nTests that the file header is properly handled or inferred\nduring parsing for all of the parsers defined in parsers.py\n\"\"\"\n\nfrom collections import namedtuple\nfrom io import StringIO\n\nimport numpy as np\nimport pytest\n\nfrom pandas.errors import ParserError\n\nfrom pandas import DataFrame, Index, MultiIndex\nimport pandas.util.testing as tm\n\n\ndef test_read_with_bad_header(all_parsers):\n    parser = all_parsers\n    msg = r\"but only \\d+ lines in file\"\n\n    with pytest.raises(ValueError, match=msg):\n        s = StringIO(\",,\")\n        parser.read_csv(s, header=[10])\n\n\ndef test_negative_header(all_parsers):\n    # see gh-27779\n    parser = all_parsers\n    data = \"\"\"1,2,3,4,5\n6,7,8,9,10\n11,12,13,14,15\n\"\"\"\n    with pytest.raises(\n        ValueError,\n        match=\"Passing negative integer to header is invalid. \"\n        \"For no header, use header=None instead\",\n    ):\n        parser.read_csv(StringIO(data), header=-1)\n\n\n@pytest.mark.parametrize(\"header\", [([-1, 2, 4]), ([-5, 0])])\ndef test_negative_multi_index_header(all_parsers, header):\n    # see gh-27779\n    parser = all_parsers\n    data = \"\"\"1,2,3,4,5\n        6,7,8,9,10\n        11,12,13,14,15\n        \"\"\"\n    with pytest.raises(\n        ValueError, match=\"cannot specify multi-index header with negative integers\"\n    ):\n        parser.read_csv(StringIO(data), header=header)\n\n\n@pytest.mark.parametrize(\"header\", [True, False])\ndef test_bool_header_arg(all_parsers, header):\n    # see gh-6114\n    parser = all_parsers\n    data = \"\"\"\\\nMyColumn\na\nb\na\nb\"\"\"\n    msg = \"Passing a bool to header is invalid\"\n    with pytest.raises(TypeError, match=msg):\n        parser.read_csv(StringIO(data), header=header)\n\n\ndef test_no_header_prefix(all_parsers):\n    parser = all_parsers\n    data = \"\"\"1,2,3,4,5\n6,7,8,9,10\n11,12,13,14,15\n\"\"\"\n    result = parser.read_csv(StringIO(data), prefix=\"Field\", header=None)\n    expected = DataFrame(\n        [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15]],\n        columns=[\"Field0\", \"Field1\", \"Field2\", \"Field3\", \"Field4\"],\n    )\n    tm.assert_frame_equal(result, expected)\n\n\ndef test_header_with_index_col(all_parsers):\n    parser = all_parsers\n    data = \"\"\"foo,1,2,3\nbar,4,5,6\nbaz,7,8,9\n\"\"\"\n    names = [\"A\", \"B\", \"C\"]\n    result = parser.read_csv(StringIO(data), names=names)\n\n    expected = DataFrame(\n        [[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n        index=[\"foo\", \"bar\", \"baz\"],\n        columns=[\"A\", \"B\", \"C\"],\n    )\n    tm.assert_frame_equal(result, expected)\n\n\ndef test_header_not_first_line(all_parsers):\n    parser = all_parsers\n    data = \"\"\"got,to,ignore,this,line\ngot,to,ignore,this,line\nindex,A,B,C,D\nfoo,2,3,4,5\nbar,7,8,9,10\nbaz,12,13,14,15\n\"\"\"\n    data2 = \"\"\"index,A,B,C,D\nfoo,2,3,4,5\nbar,7,8,9,10\nbaz,12,13,14,15\n\"\"\"\n\n    result = parser.read_csv(StringIO(data), header=2, index_col=0)\n    expected = parser.read_csv(StringIO(data2), header=0, index_col=0)\n    tm.assert_frame_equal(result, expected)\n\n\ndef test_header_multi_index(all_parsers):\n    parser = all_parsers\n    expected = tm.makeCustomDataframe(5, 3, r_idx_nlevels=2, c_idx_nlevels=4)\n\n    data = \"\"\"\\\nC0,,C_l0_g0,C_l0_g1,C_l0_g2\n\nC1,,C_l1_g0,C_l1_g1,C_l1_g2\nC2,,C_l2_g0,C_l2_g1,C_l2_g2\nC3,,C_l3_g0,C_l3_g1,C_l3_g2\nR0,R1,,,\nR_l0_g0,R_l1_g0,R0C0,R0C1,R0C2\nR_l0_g1,R_l1_g1,R1C0,R1C1,R1C2\nR_l0_g2,R_l1_g2,R2C0,R2C1,R2C2\nR_l0_g3,R_l1_g3,R3C0,R3C1,R3C2\nR_l0_g4,R_l1_g4,R4C0,R4C1,R4C2\n\"\"\"\n    result = parser.read_csv(StringIO(data), header=[0, 1, 2, 3], index_col=[0, 1])\n    tm.assert_frame_equal(result, expected)\n\n\n@pytest.mark.parametrize(\n    \"kwargs,msg\",\n    [\n        (\n            dict(index_col=[\"foo\", \"bar\"]),\n            (\n                \"index_col must only contain \"\n                \"row numbers when specifying \"\n                \"a multi-index header\"\n            ),\n        ),\n        (\n            dict(index_col=[0, 1], names=[\"foo\", \"bar\"]),\n            (\"cannot specify names when specifying a multi-index header\"),\n        ),\n        (\n            dict(index_col=[0, 1], usecols=[\"foo\", \"bar\"]),\n            (\"cannot specify usecols when specifying a multi-index header\"),\n        ),\n    ],\n)\ndef test_header_multi_index_invalid(all_parsers, kwargs, msg):\n    data = \"\"\"\\\nC0,,C_l0_g0,C_l0_g1,C_l0_g2\n\nC1,,C_l1_g0,C_l1_g1,C_l1_g2\nC2,,C_l2_g0,C_l2_g1,C_l2_g2\nC3,,C_l3_g0,C_l3_g1,C_l3_g2\nR0,R1,,,\nR_l0_g0,R_l1_g0,R0C0,R0C1,R0C2\nR_l0_g1,R_l1_g1,R1C0,R1C1,R1C2\nR_l0_g2,R_l1_g2,R2C0,R2C1,R2C2\nR_l0_g3,R_l1_g3,R3C0,R3C1,R3C2\nR_l0_g4,R_l1_g4,R4C0,R4C1,R4C2\n\"\"\"\n    parser = all_parsers\n\n    with pytest.raises(ValueError, match=msg):\n        parser.read_csv(StringIO(data), header=[0, 1, 2, 3], **kwargs)\n\n\n_TestTuple = namedtuple(\"names\", [\"first\", \"second\"])\n\n\n@pytest.mark.parametrize(\n    \"kwargs\",\n    [\n        dict(header=[0, 1]),\n        dict(\n            skiprows=3,\n            names=[\n                (\"a\", \"q\"),\n                (\"a\", \"r\"),\n                (\"a\", \"s\"),\n                (\"b\", \"t\"),\n                (\"c\", \"u\"),\n                (\"c\", \"v\"),\n            ],\n        ),\n        dict(\n            skiprows=3,\n            names=[\n                _TestTuple(\"a\", \"q\"),\n                _TestTuple(\"a\", \"r\"),\n                _TestTuple(\"a\", \"s\"),\n                _TestTuple(\"b\", \"t\"),\n                _TestTuple(\"c\", \"u\"),\n                _TestTuple(\"c\", \"v\"),\n            ],\n        ),\n    ],\n)\ndef test_header_multi_index_common_format1(all_parsers, kwargs):\n    parser = all_parsers\n    expected = DataFrame(\n        [[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12]],\n        index=[\"one\", \"two\"],\n        columns=MultiIndex.from_tuples(\n            [(\"a\", \"q\"), (\"a\", \"r\"), (\"a\", \"s\"), (\"b\", \"t\"), (\"c\", \"u\"), (\"c\", \"v\")]\n        ),\n    )\n    data = \"\"\",a,a,a,b,c,c\n,q,r,s,t,u,v\n,,,,,,\none,1,2,3,4,5,6\ntwo,7,8,9,10,11,12\"\"\"\n\n    result = parser.read_csv(StringIO(data), index_col=0, **kwargs)\n    tm.assert_frame_equal(result, expected)\n\n\n@pytest.mark.parametrize(\n    \"kwargs\",\n    [\n        dict(header=[0, 1]),\n        dict(\n            skiprows=2,\n            names=[\n                (\"a\", \"q\"),\n                (\"a\", \"r\"),\n                (\"a\", \"s\"),\n                (\"b\", \"t\"),\n                (\"c\", \"u\"),\n                (\"c\", \"v\"),\n            ],\n        ),\n        dict(\n            skiprows=2,\n            names=[\n                _TestTuple(\"a\", \"q\"),\n                _TestTuple(\"a\", \"r\"),\n                _TestTuple(\"a\", \"s\"),\n                _TestTuple(\"b\", \"t\"),\n                _TestTuple(\"c\", \"u\"),\n                _TestTuple(\"c\", \"v\"),\n            ],\n        ),\n    ],\n)\ndef test_header_multi_index_common_format2(all_parsers, kwargs):\n    parser = all_parsers\n    expected = DataFrame(\n        [[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12]],\n        index=[\"one\", \"two\"],\n        columns=MultiIndex.from_tuples(\n            [(\"a\", \"q\"), (\"a\", \"r\"), (\"a\", \"s\"), (\"b\", \"t\"), (\"c\", \"u\"), (\"c\", \"v\")]\n        ),\n    )\n    data = \"\"\",a,a,a,b,c,c\n,q,r,s,t,u,v\none,1,2,3,4,5,6\ntwo,7,8,9,10,11,12\"\"\"\n\n    result = parser.read_csv(StringIO(data), index_col=0, **kwargs)\n    tm.assert_frame_equal(result, expected)\n\n\n@pytest.mark.parametrize(\n    \"kwargs\",\n    [\n        dict(header=[0, 1]),\n        dict(\n            skiprows=2,\n            names=[\n                (\"a\", \"q\"),\n                (\"a\", \"r\"),\n                (\"a\", \"s\"),\n                (\"b\", \"t\"),\n                (\"c\", \"u\"),\n                (\"c\", \"v\"),\n            ],\n        ),\n        dict(\n            skiprows=2,\n            names=[\n                _TestTuple(\"a\", \"q\"),\n                _TestTuple(\"a\", \"r\"),\n                _TestTuple(\"a\", \"s\"),\n                _TestTuple(\"b\", \"t\"),\n                _TestTuple(\"c\", \"u\"),\n                _TestTuple(\"c\", \"v\"),\n            ],\n        ),\n    ],\n)\ndef test_header_multi_index_common_format3(all_parsers, kwargs):\n    parser = all_parsers\n    expected = DataFrame(\n        [[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12]],\n        index=[\"one\", \"two\"],\n        columns=MultiIndex.from_tuples(\n            [(\"a\", \"q\"), (\"a\", \"r\"), (\"a\", \"s\"), (\"b\", \"t\"), (\"c\", \"u\"), (\"c\", \"v\")]\n        ),\n    )\n    expected = expected.reset_index(drop=True)\n    data = \"\"\"a,a,a,b,c,c\nq,r,s,t,u,v\n1,2,3,4,5,6\n7,8,9,10,11,12\"\"\"\n\n    result = parser.read_csv(StringIO(data), index_col=None, **kwargs)\n    tm.assert_frame_equal(result, expected)\n\n\ndef test_header_multi_index_common_format_malformed1(all_parsers):\n    parser = all_parsers\n    expected = DataFrame(\n        np.array([[2, 3, 4, 5, 6], [8, 9, 10, 11, 12]], dtype=\"int64\"),\n        index=Index([1, 7]),\n        columns=MultiIndex(\n            levels=[[\"a\", \"b\", \"c\"], [\"r\", \"s\", \"t\", \"u\", \"v\"]],\n            codes=[[0, 0, 1, 2, 2], [0, 1, 2, 3, 4]],\n            names=[\"a\", \"q\"],\n        ),\n    )\n    data = \"\"\"a,a,a,b,c,c\nq,r,s,t,u,v\n1,2,3,4,5,6\n7,8,9,10,11,12\"\"\"\n\n    result = parser.read_csv(StringIO(data), header=[0, 1], index_col=0)\n    tm.assert_frame_equal(expected, result)\n\n\ndef test_header_multi_index_common_format_malformed2(all_parsers):\n    parser = all_parsers\n    expected = DataFrame(\n        np.array([[2, 3, 4, 5, 6], [8, 9, 10, 11, 12]], dtype=\"int64\"),\n        index=Index([1, 7]),\n        columns=MultiIndex(\n            levels=[[\"a\", \"b\", \"c\"], [\"r\", \"s\", \"t\", \"u\", \"v\"]],\n            codes=[[0, 0, 1, 2, 2], [0, 1, 2, 3, 4]],\n            names=[None, \"q\"],\n        ),\n    )\n\n    data = \"\"\",a,a,b,c,c\nq,r,s,t,u,v\n1,2,3,4,5,6\n7,8,9,10,11,12\"\"\"\n\n    result = parser.read_csv(StringIO(data), header=[0, 1], index_col=0)\n    tm.assert_frame_equal(expected, result)\n\n\ndef test_header_multi_index_common_format_malformed3(all_parsers):\n    parser = all_parsers\n    expected = DataFrame(\n        np.array([[3, 4, 5, 6], [9, 10, 11, 12]], dtype=\"int64\"),\n        index=MultiIndex(levels=[[1, 7], [2, 8]], codes=[[0, 1], [0, 1]]),\n        columns=MultiIndex(\n            levels=[[\"a\", \"b\", \"c\"], [\"s\", \"t\", \"u\", \"v\"]],\n            codes=[[0, 1, 2, 2], [0, 1, 2, 3]],\n            names=[None, \"q\"],\n        ),\n    )\n    data = \"\"\",a,a,b,c,c\nq,r,s,t,u,v\n1,2,3,4,5,6\n7,8,9,10,11,12\"\"\"\n\n    result = parser.read_csv(StringIO(data), header=[0, 1], index_col=[0, 1])\n    tm.assert_frame_equal(expected, result)\n\n\n@pytest.mark.parametrize(\n    \"data,header\", [(\"1,2,3\\n4,5,6\", None), (\"foo,bar,baz\\n1,2,3\\n4,5,6\", 0)]\n)\ndef test_header_names_backward_compat(all_parsers, data, header):\n    # see gh-2539\n    parser = all_parsers\n    expected = parser.read_csv(StringIO(\"1,2,3\\n4,5,6\"), names=[\"a\", \"b\", \"c\"])\n\n    result = parser.read_csv(StringIO(data), names=[\"a\", \"b\", \"c\"], header=header)\n    tm.assert_frame_equal(result, expected)\n\n\n@pytest.mark.parametrize(\"kwargs\", [dict(), dict(index_col=False)])\ndef test_read_only_header_no_rows(all_parsers, kwargs):\n    # See gh-7773\n    parser = all_parsers\n    expected = DataFrame(columns=[\"a\", \"b\", \"c\"])\n\n    result = parser.read_csv(StringIO(\"a,b,c\"), **kwargs)\n    tm.assert_frame_equal(result, expected)\n\n\n@pytest.mark.parametrize(\n    \"kwargs,names\",\n    [\n        (dict(), [0, 1, 2, 3, 4]),\n        (dict(prefix=\"X\"), [\"X0\", \"X1\", \"X2\", \"X3\", \"X4\"]),\n        (\n            dict(names=[\"foo\", \"bar\", \"baz\", \"quux\", \"panda\"]),\n            [\"foo\", \"bar\", \"baz\", \"quux\", \"panda\"],\n        ),\n    ],\n)\ndef test_no_header(all_parsers, kwargs, names):\n    parser = all_parsers\n    data = \"\"\"1,2,3,4,5\n6,7,8,9,10\n11,12,13,14,15\n\"\"\"\n    expected = DataFrame(\n        [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15]], columns=names\n    )\n    result = parser.read_csv(StringIO(data), header=None, **kwargs)\n    tm.assert_frame_equal(result, expected)\n\n\n@pytest.mark.parametrize(\"header\", [[\"a\", \"b\"], \"string_header\"])\ndef test_non_int_header(all_parsers, header):\n    # see gh-16338\n    msg = \"header must be integer or list of integers\"\n    data = \"\"\"1,2\\n3,4\"\"\"\n    parser = all_parsers\n\n    with pytest.raises(ValueError, match=msg):\n        parser.read_csv(StringIO(data), header=header)\n\n\ndef test_singleton_header(all_parsers):\n    # see gh-7757\n    data = \"\"\"a,b,c\\n0,1,2\\n1,2,3\"\"\"\n    parser = all_parsers\n\n    expected = DataFrame({\"a\": [0, 1], \"b\": [1, 2], \"c\": [2, 3]})\n    result = parser.read_csv(StringIO(data), header=[0])\n    tm.assert_frame_equal(result, expected)\n\n\n@pytest.mark.parametrize(\n    \"data,expected\",\n    [\n        (\n            \"A,A,A,B\\none,one,one,two\\n0,40,34,0.1\",\n            DataFrame(\n                [[0, 40, 34, 0.1]],\n                columns=MultiIndex.from_tuples(\n                    [(\"A\", \"one\"), (\"A\", \"one.1\"), (\"A\", \"one.2\"), (\"B\", \"two\")]\n                ),\n            ),\n        ),\n        (\n            \"A,A,A,B\\none,one,one.1,two\\n0,40,34,0.1\",\n            DataFrame(\n                [[0, 40, 34, 0.1]],\n                columns=MultiIndex.from_tuples(\n                    [(\"A\", \"one\"), (\"A\", \"one.1\"), (\"A\", \"one.1.1\"), (\"B\", \"two\")]\n                ),\n            ),\n        ),\n        (\n            \"A,A,A,B,B\\none,one,one.1,two,two\\n0,40,34,0.1,0.1\",\n            DataFrame(\n                [[0, 40, 34, 0.1, 0.1]],\n                columns=MultiIndex.from_tuples(\n                    [\n                        (\"A\", \"one\"),\n                        (\"A\", \"one.1\"),\n                        (\"A\", \"one.1.1\"),\n                        (\"B\", \"two\"),\n                        (\"B\", \"two.1\"),\n                    ]\n                ),\n            ),\n        ),\n    ],\n)\ndef test_mangles_multi_index(all_parsers, data, expected):\n    # see gh-18062\n    parser = all_parsers\n\n    result = parser.read_csv(StringIO(data), header=[0, 1])\n    tm.assert_frame_equal(result, expected)\n\n\n@pytest.mark.parametrize(\"index_col\", [None, [0]])\n@pytest.mark.parametrize(\n    \"columns\", [None, ([\"\", \"Unnamed\"]), ([\"Unnamed\", \"\"]), ([\"Unnamed\", \"NotUnnamed\"])]\n)\ndef test_multi_index_unnamed(all_parsers, index_col, columns):\n    # see gh-23687\n    #\n    # When specifying a multi-index header, make sure that\n    # we don't error just because one of the rows in our header\n    # has ALL column names containing the string \"Unnamed\". The\n    # correct condition to check is whether the row contains\n    # ALL columns that did not have names (and instead were given\n    # placeholder ones).\n    parser = all_parsers\n    header = [0, 1]\n\n    if index_col is None:\n        data = \",\".join(columns or [\"\", \"\"]) + \"\\n0,1\\n2,3\\n4,5\\n\"\n    else:\n        data = \",\".join([\"\"] + (columns or [\"\", \"\"])) + \"\\n,0,1\\n0,2,3\\n1,4,5\\n\"\n\n    if columns is None:\n        msg = (\n            r\"Passed header=\\[0,1\\] are too \"\n            r\"many rows for this multi_index of columns\"\n        )\n        with pytest.raises(ParserError, match=msg):\n            parser.read_csv(StringIO(data), header=header, index_col=index_col)\n    else:\n        result = parser.read_csv(StringIO(data), header=header, index_col=index_col)\n        template = \"Unnamed: {i}_level_0\"\n        exp_columns = []\n\n        for i, col in enumerate(columns):\n            if not col:  # Unnamed.\n                col = template.format(i=i if index_col is None else i + 1)\n\n            exp_columns.append(col)\n\n        columns = MultiIndex.from_tuples(zip(exp_columns, [\"0\", \"1\"]))\n        expected = DataFrame([[2, 3], [4, 5]], columns=columns)\n        tm.assert_frame_equal(result, expected)\n\n\ndef test_read_csv_multiindex_columns(all_parsers):\n    # GH#6051\n    parser = all_parsers\n\n    s1 = \"Male, Male, Male, Female, Female\\nR, R, L, R, R\\n.86, .67, .88, .78, .81\"\n    s2 = (\n        \"Male, Male, Male, Female, Female\\n\"\n        \"R, R, L, R, R\\n\"\n        \".86, .67, .88, .78, .81\\n\"\n        \".86, .67, .88, .78, .82\"\n    )\n\n    mi = MultiIndex.from_tuples(\n        [\n            (\"Male\", \"R\"),\n            (\" Male\", \" R\"),\n            (\" Male\", \" L\"),\n            (\" Female\", \" R\"),\n            (\" Female\", \" R.1\"),\n        ]\n    )\n    expected = DataFrame(\n        [[0.86, 0.67, 0.88, 0.78, 0.81], [0.86, 0.67, 0.88, 0.78, 0.82]], columns=mi\n    )\n\n    df1 = parser.read_csv(StringIO(s1), header=[0, 1])\n    tm.assert_frame_equal(df1, expected.iloc[:1])\n    df2 = parser.read_csv(StringIO(s2), header=[0, 1])\n    tm.assert_frame_equal(df2, expected)\n"
    }
  ],
  "questions": [
    "@costas821 I cannot reproduce this (also using Windows 7, pandas 0.17.1). If you run the above code sample in a new session, you get that error?",
    "OK I can go that route, but now I am having some functionality issues. Some things that worked before, no longer work when I set it as a category. If you don't think this is pertinent to the issue, then should I just send you a personal message of what I am trying to do and some sample code?\n\n```\n#  set my frame as category\nuniques = np.sort(pd.unique(df.values.ravel()))\ndf = df.apply(lambda x: x.astype('category', categories=uniques))\n\n# slicing and search operations\ndf_ints = pd.DataFrame(np.zeros((10000, 500)))\ndf_ints[5,3] = 1\n# when df is a category, I cannot do the following\ndf[df_ints==0] = 'Z'  \n# this also raises an error\ndf_ints == 'A'\n```"
  ],
  "golden_answers": [
    "this fails on the astype. dtype `S1`(and all fixed sized string dtypes are) not supported and should be converted to `object`. Kind of puzzled why this is not. So I'll mark this as a bug.",
    "categoricals have a sets that are allowed, IOW, to the `categories` themselves. You can \n\n```\nIn [75]: df2 = df.apply(lambda x: x.astype('category', categories=uniques.tolist() + ['Z']))\n\nIn [77]: df2.iloc[0,1] = 'Z'\n```"
  ],
  "questions_generated": [
    "What is causing the 'TypeError: data type \"bytes8\" not understood' error when attempting to print a larger portion of the DataFrame?",
    "Why does printing a smaller portion of the DataFrame not raise an error?",
    "What workaround is suggested to manage memory usage while maintaining single-byte character representation in the DataFrame?",
    "How does the dtype 'U1' behave differently from 'S1' in this context, and why is it recommended?",
    "What is the role of the function _vstack in pandas, and why does it contribute to the error when using dtype 'S1'?"
  ],
  "golden_answers_generated": [
    "The error is caused by using the dtype 'S1' in the DataFrame, which is not properly handled in Python 3. The 'S1' dtype is a fixed-size string dtype that is not supported in Python 3, leading to this error during operations like printing a larger portion of the DataFrame.",
    "Printing a smaller portion of the DataFrame does not raise an error likely because the operation does not trigger the specific code path that mishandles the 'S1' dtype. The issue occurs when the internal mechanism of pandas, like vstack in this context, is engaged, leading to the TypeError.",
    "The suggested workaround is to use pandas' 'category' dtype. By converting the DataFrame to use categorical data types, memory usage is significantly reduced while still allowing each cell to effectively represent single-byte characters.",
    "The dtype 'U1' represents a Unicode string of length 1, which is properly coerced to an 'object' dtype in Python 3, avoiding the errors encountered with 'S1'. It is recommended because it allows for similar functionality without triggering the issues associated with fixed-size string dtypes that are unsupported in Python 3.",
    "The function _vstack in pandas is used to vertically stack arrays, and it includes logic that checks for certain dtypes, such as _NS_DTYPE and _TD_DTYPE. The error occurs because this function does not properly handle the 'S1' dtype, leading to the TypeError when pandas attempts to perform operations involving the dtype conversion or stacking of arrays with 'S1'."
  ]
}