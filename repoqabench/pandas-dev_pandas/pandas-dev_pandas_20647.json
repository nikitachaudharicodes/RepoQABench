{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "20647",
  "issue_description": "# API/BUG: center=True in expanding operations returns non-sensical results\n\nWhat is `center=True` supposed to do in `df.expanding()...` operations?\r\n\r\nUsing the example from the docstring of `.expanding()`:\r\n\r\n```\r\nIn [103]: df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\r\n\r\nIn [105]: df.expanding(2).sum()\r\nOut[105]: \r\n     B\r\n0  NaN\r\n1  1.0\r\n2  3.0\r\n3  3.0\r\n4  7.0\r\n```\r\n\r\nNow adding `center=True`:\r\n\r\n```\r\nIn [106]: df.expanding(2, center=True).sum()\r\nOut[106]: \r\n     B\r\n0  3.0\r\n1  3.0\r\n2  7.0\r\n3  7.0\r\n4  6.0\r\n```\r\n\r\nTwo observations: it seems it just shifted the first rows (which is not the same as centering) and I don't know where the last values are coming from (and they should certainly not decrease again in an expanding sum with only positive values). \r\n\r\nFurther, I also cannot think of what it actually *should* do. If we really want to center it, that would mean returning with a new index (as the real center would only increase with 0.5 and be something like [0, 0.5, 1, 1.5, 2] for those data).\r\n\r\nSo maybe we should rather remove this keyword for `expanding` ?",
  "issue_comments": [
    {
      "id": 380003458,
      "user": "jorisvandenbossche",
      "body": "Hmm, I see that we in the past removed the `center` keyword in the `pd.expanding_` functions, exactly because it did not make sense (https://github.com/pandas-dev/pandas/pull/7934). But it seems with the refactor to the `expanding()` method, it was introduced again"
    },
    {
      "id": 380071694,
      "user": "jreback",
      "body": "yes center doesn’t make sense in context of expanding"
    },
    {
      "id": 380585232,
      "user": "pulkitmaloo",
      "body": "I'd like to work on this "
    },
    {
      "id": 380602640,
      "user": "gfyoung",
      "body": "Go for it!  No need to ask for permission unless someone else is working on it."
    },
    {
      "id": 388883310,
      "user": "dragosthealex",
      "body": "Is anyone still working on this?"
    },
    {
      "id": 388947039,
      "user": "jorisvandenbossche",
      "body": "I don't think so (unless @stillmatic did work on it? If you do, best to say so on this issue), so feel free to take a look at it!"
    },
    {
      "id": 388959139,
      "user": "stillmatic",
      "body": "i started working on this issue but don't think my solution is correct/finished. Haven't had time to finish (there are many dependencies). If you have a good idea go ahead, otherwise I might be able to find time and get this done"
    },
    {
      "id": 388980746,
      "user": "dragosthealex",
      "body": "@stillmatic in the commit you removed `center` parameter from `rolling` method as well, which I believe introduced most broken dependencies. But I believe in that one, centering makes sense.\r\n\r\n@jorisvandenbossche I believe in this example center should do nothing if it's supposed to be consistent with functionality of `rolling`. \r\nAs far as I understand, when center=False, the result of the operation applied on the window is placed at the index of last element in window. e.g. `df = DataFrame({'B': [0, 1, 2, 3, 4, 5]})`\r\n`df.rolling(3).sum()` gives [NaN, NaN, 3.0, 6.0, 9.0, 12.0]\r\n\r\nWhen setting center=True, the result is placed at the index of element in center of the window (index in window / 2), effectively shifting the results back.\r\n`df.rolling(3, center=True).sum()` gives [NaN, 3.0, 6.0, 9.0, 12.0, NaN]\r\n\r\n`df.rolling(2).sum()` gives same result as df.rolling(2, center=True).sum()`, because the center of window of len=2, is index=1 -> second element in window, which is also the last.\r\nThus, `df.expanding(2).sum()` should give same result as `df.expanding(2, center=True).sum()`, so there must be a bug somewhere.\r\nPlease let me know if you think I got it wrong.\r\n\r\nIn terms of whether it's actually useful for `expanding` I'm not sure as I am not really familiar, but it should have the same effect as in `rolling` e.g.\r\n`df.expanding(3).sum()` gives [NaN, NaN, 3.0, 6.0, 10.0, 15.0]\r\nAnd `df.expanding(3, center=True).sum()` should give [NaN, 3.0, 6.0, 10.0, 15.0, NaN] right?"
    },
    {
      "id": 605613871,
      "user": "sumanau7",
      "body": "take"
    },
    {
      "id": 646974454,
      "user": "MBrouns",
      "body": "It seems like `center` is indeed a weird option for an `expanding` window. I just ran the test suite and there are no tests breaking when I remove the `center` option from expanding (except for one that checks whether there's validation on the center parameter). Also, a code search on GitHub doesn't reveal any instances where `center` is used in conjuction with `expanding`.\r\n\r\nCombined with the current output simply being wrong, I think that means we can move forward with deprecating `center`. I'll submit a PR."
    },
    {
      "id": 646974473,
      "user": "MBrouns",
      "body": "take"
    }
  ],
  "text_context": "# API/BUG: center=True in expanding operations returns non-sensical results\n\nWhat is `center=True` supposed to do in `df.expanding()...` operations?\r\n\r\nUsing the example from the docstring of `.expanding()`:\r\n\r\n```\r\nIn [103]: df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\r\n\r\nIn [105]: df.expanding(2).sum()\r\nOut[105]: \r\n     B\r\n0  NaN\r\n1  1.0\r\n2  3.0\r\n3  3.0\r\n4  7.0\r\n```\r\n\r\nNow adding `center=True`:\r\n\r\n```\r\nIn [106]: df.expanding(2, center=True).sum()\r\nOut[106]: \r\n     B\r\n0  3.0\r\n1  3.0\r\n2  7.0\r\n3  7.0\r\n4  6.0\r\n```\r\n\r\nTwo observations: it seems it just shifted the first rows (which is not the same as centering) and I don't know where the last values are coming from (and they should certainly not decrease again in an expanding sum with only positive values). \r\n\r\nFurther, I also cannot think of what it actually *should* do. If we really want to center it, that would mean returning with a new index (as the real center would only increase with 0.5 and be something like [0, 0.5, 1, 1.5, 2] for those data).\r\n\r\nSo maybe we should rather remove this keyword for `expanding` ?\n\nHmm, I see that we in the past removed the `center` keyword in the `pd.expanding_` functions, exactly because it did not make sense (https://github.com/pandas-dev/pandas/pull/7934). But it seems with the refactor to the `expanding()` method, it was introduced again\n\nyes center doesn’t make sense in context of expanding\n\nI'd like to work on this \n\nGo for it!  No need to ask for permission unless someone else is working on it.\n\nIs anyone still working on this?\n\nI don't think so (unless @stillmatic did work on it? If you do, best to say so on this issue), so feel free to take a look at it!\n\ni started working on this issue but don't think my solution is correct/finished. Haven't had time to finish (there are many dependencies). If you have a good idea go ahead, otherwise I might be able to find time and get this done\n\n@stillmatic in the commit you removed `center` parameter from `rolling` method as well, which I believe introduced most broken dependencies. But I believe in that one, centering makes sense.\r\n\r\n@jorisvandenbossche I believe in this example center should do nothing if it's supposed to be consistent with functionality of `rolling`. \r\nAs far as I understand, when center=False, the result of the operation applied on the window is placed at the index of last element in window. e.g. `df = DataFrame({'B': [0, 1, 2, 3, 4, 5]})`\r\n`df.rolling(3).sum()` gives [NaN, NaN, 3.0, 6.0, 9.0, 12.0]\r\n\r\nWhen setting center=True, the result is placed at the index of element in center of the window (index in window / 2), effectively shifting the results back.\r\n`df.rolling(3, center=True).sum()` gives [NaN, 3.0, 6.0, 9.0, 12.0, NaN]\r\n\r\n`df.rolling(2).sum()` gives same result as df.rolling(2, center=True).sum()`, because the center of window of len=2, is index=1 -> second element in window, which is also the last.\r\nThus, `df.expanding(2).sum()` should give same result as `df.expanding(2, center=True).sum()`, so there must be a bug somewhere.\r\nPlease let me know if you think I got it wrong.\r\n\r\nIn terms of whether it's actually useful for `expanding` I'm not sure as I am not really familiar, but it should have the same effect as in `rolling` e.g.\r\n`df.expanding(3).sum()` gives [NaN, NaN, 3.0, 6.0, 10.0, 15.0]\r\nAnd `df.expanding(3, center=True).sum()` should give [NaN, 3.0, 6.0, 10.0, 15.0, NaN] right?\n\ntake\n\nIt seems like `center` is indeed a weird option for an `expanding` window. I just ran the test suite and there are no tests breaking when I remove the `center` option from expanding (except for one that checks whether there's validation on the center parameter). Also, a code search on GitHub doesn't reveal any instances where `center` is used in conjuction with `expanding`.\r\n\r\nCombined with the current output simply being wrong, I think that means we can move forward with deprecating `center`. I'll submit a PR.\n\ntake",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/7934",
  "code_context": [
    {
      "filename": "pandas/stats/moments.py",
      "content": "\"\"\"\nProvides rolling statistical moments and related descriptive\nstatistics implemented in Cython\n\"\"\"\nfrom __future__ import division\n\nfrom functools import wraps\nfrom collections import defaultdict\n\nfrom numpy import NaN\nimport numpy as np\n\nfrom pandas.core.api import DataFrame, Series, Panel, notnull\nimport pandas.algos as algos\nimport pandas.core.common as pdcom\n\nfrom pandas.util.decorators import Substitution, Appender\n\n__all__ = ['rolling_count', 'rolling_max', 'rolling_min',\n           'rolling_sum', 'rolling_mean', 'rolling_std', 'rolling_cov',\n           'rolling_corr', 'rolling_var', 'rolling_skew', 'rolling_kurt',\n           'rolling_quantile', 'rolling_median', 'rolling_apply',\n           'rolling_corr_pairwise', 'rolling_window',\n           'ewma', 'ewmvar', 'ewmstd', 'ewmvol', 'ewmcorr', 'ewmcov',\n           'expanding_count', 'expanding_max', 'expanding_min',\n           'expanding_sum', 'expanding_mean', 'expanding_std',\n           'expanding_cov', 'expanding_corr', 'expanding_var',\n           'expanding_skew', 'expanding_kurt', 'expanding_quantile',\n           'expanding_median', 'expanding_apply', 'expanding_corr_pairwise']\n\n#------------------------------------------------------------------------------\n# Docs\n\n# The order of arguments for the _doc_template is:\n# (header, args, kwargs, returns, notes)\n\n_doc_template = \"\"\"\n%s\n\nParameters\n----------\n%s%s\nReturns\n-------\n%s\n%s\n\"\"\"\n\n_roll_kw = \"\"\"window : int\n    Size of the moving window. This is the number of observations used for\n    calculating the statistic.\nmin_periods : int, default None\n    Minimum number of observations in window required to have a value\n    (otherwise result is NA).\nfreq : string or DateOffset object, optional (default None)\n    Frequency to conform the data to before computing the statistic. Specified\n    as a frequency string or DateOffset object.\ncenter : boolean, default False\n    Set the labels at the center of the window.\nhow : string, default '%s'\n    Method for down- or re-sampling\n\"\"\"\n\n_roll_notes = r\"\"\"\nNotes\n-----\nBy default, the result is set to the right edge of the window. This can be\nchanged to the center of the window by setting ``center=True``.\n\nThe `freq` keyword is used to conform time series data to a specified\nfrequency by resampling the data. This is done with the default parameters\nof :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n\"\"\"\n\n\n_ewm_kw = r\"\"\"com : float. optional\n    Center of mass: :math:`\\alpha = 1 / (1 + com)`,\nspan : float, optional\n    Specify decay in terms of span, :math:`\\alpha = 2 / (span + 1)`\nhalflife : float, optional\n    Specify decay in terms of halflife, :math:`\\alpha = 1 - exp(log(0.5) / halflife)`\nmin_periods : int, default 0\n    Number of observations in sample to require (only affects\n    beginning)\nfreq : None or string alias / date offset object, default=None\n    Frequency to conform to before computing statistic\nadjust : boolean, default True\n    Divide by decaying adjustment factor in beginning periods to account for\n    imbalance in relative weightings (viewing EWMA as a moving average)\nhow : string, default 'mean'\n    Method for down- or re-sampling\nignore_na : boolean, default False\n    Ignore missing values when calculating weights;\n    specify True to reproduce pre-0.15.0 behavior\n\"\"\"\n\n_ewm_notes = r\"\"\"\nNotes\n-----\nEither center of mass or span must be specified\n\nEWMA is sometimes specified using a \"span\" parameter `s`, we have that the\ndecay parameter :math:`\\alpha` is related to the span as\n:math:`\\alpha = 2 / (s + 1) = 1 / (1 + c)`\n\nwhere `c` is the center of mass. Given a span, the associated center of mass is\n:math:`c = (s - 1) / 2`\n\nSo a \"20-day EWMA\" would have center 9.5.\n\nWhen adjust is True (default), weighted averages are calculated using weights\n    (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n\nWhen adjust is False, weighted averages are calculated recursively as:\n    weighted_average[0] = arg[0];\n    weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n\nWhen ignore_na is False (default), weights are based on absolute positions.\nFor example, the weights of x and y used in calculating the final weighted\naverage of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n(1-alpha)**2 and alpha (if adjust is False).\n\nWhen ignore_na is True (reproducing pre-0.15.0 behavior), weights are based on\nrelative positions. For example, the weights of x and y used in calculating\nthe final weighted average of [x, None, y] are 1-alpha and 1 (if adjust is \nTrue), and 1-alpha and alpha (if adjust is False).\n\"\"\"\n\n_expanding_kw = \"\"\"min_periods : int, default None\n    Minimum number of observations in window required to have a value\n    (otherwise result is NA).\nfreq : string or DateOffset object, optional (default None)\n    Frequency to conform the data to before computing the statistic. Specified\n    as a frequency string or DateOffset object.\n\"\"\"\n\n\n_type_of_input_retval = \"y : type of input argument\"\n\n_flex_retval = \"\"\"y : type depends on inputs\n    DataFrame / DataFrame -> DataFrame (matches on columns) or Panel (pairwise)\n    DataFrame / Series -> Computes result for each column\n    Series / Series -> Series\"\"\"\n\n_pairwise_retval = \"y : Panel whose items are df1.index values\"\n\n_unary_arg = \"arg : Series, DataFrame\\n\"\n\n_binary_arg_flex = \"\"\"arg1 : Series, DataFrame, or ndarray\narg2 : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to arg1 and produce pairwise output\n\"\"\"\n\n_binary_arg = \"\"\"arg1 : Series, DataFrame, or ndarray\narg2 : Series, DataFrame, or ndarray\n\"\"\"\n\n_pairwise_arg = \"\"\"df1 : DataFrame\ndf2 : DataFrame\n\"\"\"\n\n_pairwise_kw = \"\"\"pairwise : bool, default False\n    If False then only matching columns between arg1 and arg2 will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a Panel in the case of DataFrame inputs. In the case of missing\n    elements, only complete pairwise observations will be used.\n\"\"\"\n\n_bias_kw = r\"\"\"bias : boolean, default False\n    Use a standard estimation bias correction\n\"\"\"\n\n\ndef rolling_count(arg, window, freq=None, center=False, how=None):\n    \"\"\"\n    Rolling count of number of non-NaN observations inside provided window.\n\n    Parameters\n    ----------\n    arg :  DataFrame or numpy ndarray-like\n    window : int\n        Size of the moving window. This is the number of observations used for\n        calculating the statistic.\n    freq : string or DateOffset object, optional (default None)\n        Frequency to conform the data to before computing the statistic. Specified\n        as a frequency string or DateOffset object.\n    center : boolean, default False\n        Whether the label should correspond with center of window\n    how : string, default 'mean'\n        Method for down- or re-sampling\n\n    Returns\n    -------\n    rolling_count : type of caller\n\n    Notes\n    -----\n    The `freq` keyword is used to conform time series data to a specified\n    frequency by resampling the data. This is done with the default parameters\n    of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n    \"\"\"\n    arg = _conv_timerule(arg, freq, how)\n    window = min(window, len(arg))\n\n    return_hook, values = _process_data_structure(arg, kill_inf=False)\n\n    converted = np.isfinite(values).astype(float)\n    result = rolling_sum(converted, window, min_periods=1,\n                         center=center)  # already converted\n\n    # putmask here?\n    result[np.isnan(result)] = 0\n\n    return return_hook(result)\n\n\n@Substitution(\"Unbiased moving covariance.\", _binary_arg_flex,\n              _roll_kw%'None'+_pairwise_kw, _flex_retval, _roll_notes)\n@Appender(_doc_template)\ndef rolling_cov(arg1, arg2=None, window=None, min_periods=None, freq=None,\n                center=False, pairwise=None, how=None):\n    if window is None and isinstance(arg2, (int, float)):\n        window = arg2\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise  # only default unset\n    elif arg2 is None:\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise  # only default unset\n    arg1 = _conv_timerule(arg1, freq, how)\n    arg2 = _conv_timerule(arg2, freq, how)\n\n    def _get_cov(X, Y):\n        mean = lambda x: rolling_mean(x, window, min_periods, center=center)\n        count = rolling_count(X + Y, window, center=center)\n        bias_adj = count / (count - 1)\n        return (mean(X * Y) - mean(X) * mean(Y)) * bias_adj\n    rs = _flex_binary_moment(arg1, arg2, _get_cov, pairwise=bool(pairwise))\n    return rs\n\n\n@Substitution(\"Moving sample correlation.\", _binary_arg_flex,\n              _roll_kw%'None'+_pairwise_kw, _flex_retval, _roll_notes)\n@Appender(_doc_template)\ndef rolling_corr(arg1, arg2=None, window=None, min_periods=None, freq=None,\n                 center=False, pairwise=None, how=None):\n    if window is None and isinstance(arg2, (int, float)):\n        window = arg2\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise  # only default unset\n    elif arg2 is None:\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise  # only default unset\n    arg1 = _conv_timerule(arg1, freq, how)\n    arg2 = _conv_timerule(arg2, freq, how)\n\n    def _get_corr(a, b):\n        num = rolling_cov(a, b, window, min_periods, freq=freq,\n                          center=center)\n        den = (rolling_std(a, window, min_periods, freq=freq,\n                           center=center) *\n               rolling_std(b, window, min_periods, freq=freq,\n                           center=center))\n        return num / den\n\n    return _flex_binary_moment(arg1, arg2, _get_corr, pairwise=bool(pairwise))\n\n\ndef _flex_binary_moment(arg1, arg2, f, pairwise=False):\n    if not (isinstance(arg1,(np.ndarray, Series, DataFrame)) and\n            isinstance(arg2,(np.ndarray, Series, DataFrame))):\n        raise TypeError(\"arguments to moment function must be of type \"\n                         \"np.ndarray/Series/DataFrame\")\n\n    if isinstance(arg1, (np.ndarray, Series)) and \\\n            isinstance(arg2, (np.ndarray,Series)):\n        X, Y = _prep_binary(arg1, arg2)\n        return f(X, Y)\n\n    elif isinstance(arg1, DataFrame):\n        def dataframe_from_int_dict(data, frame_template):\n            result = DataFrame(data, index=frame_template.index)\n            result.columns = frame_template.columns[result.columns]\n            return result\n\n        results = {}\n        if isinstance(arg2, DataFrame):\n            if pairwise is False:\n                if arg1 is arg2:\n                    # special case in order to handle duplicate column names\n                    for i, col in enumerate(arg1.columns):\n                        results[i] = f(arg1.iloc[:, i], arg2.iloc[:, i])\n                    return dataframe_from_int_dict(results, arg1)\n                else:\n                    if not arg1.columns.is_unique:\n                        raise ValueError(\"'arg1' columns are not unique\")\n                    if not arg2.columns.is_unique:\n                        raise ValueError(\"'arg2' columns are not unique\")\n                    X, Y = arg1.align(arg2, join='outer')\n                    X = X + 0 * Y\n                    Y = Y + 0 * X\n                    res_columns = arg1.columns.union(arg2.columns)\n                    for col in res_columns:\n                        if col in X and col in Y:\n                            results[col] = f(X[col], Y[col])\n                    return DataFrame(results, index=X.index, columns=res_columns)\n            elif pairwise is True:\n                results = defaultdict(dict)\n                for i, k1 in enumerate(arg1.columns):\n                    for j, k2 in enumerate(arg2.columns):\n                        if j<i and arg2 is arg1:\n                            # Symmetric case\n                            results[i][j] = results[j][i]\n                        else:\n                            results[i][j] = f(*_prep_binary(arg1.iloc[:, i], arg2.iloc[:, j]))\n                p = Panel.from_dict(results).swapaxes('items', 'major')\n                p.major_axis = arg1.columns[p.major_axis]\n                p.minor_axis = arg2.columns[p.minor_axis]\n                return p\n            else:\n                raise ValueError(\"'pairwise' is not True/False\")\n        else:\n            results = {}\n            for i, col in enumerate(arg1.columns):\n                results[i] = f(*_prep_binary(arg1.iloc[:, i], arg2))\n            return dataframe_from_int_dict(results, arg1)\n\n    else:\n        return _flex_binary_moment(arg2, arg1, f)\n\n\n@Substitution(\"Deprecated. Use rolling_corr(..., pairwise=True) instead.\\n\\n\"\n              \"Pairwise moving sample correlation\", _pairwise_arg,\n              _roll_kw%'None', _pairwise_retval, _roll_notes)\n@Appender(_doc_template)\ndef rolling_corr_pairwise(df1, df2=None, window=None, min_periods=None,\n                          freq=None, center=False):\n    import warnings\n    warnings.warn(\"rolling_corr_pairwise is deprecated, use rolling_corr(..., pairwise=True)\", FutureWarning)\n    return rolling_corr(df1, df2, window=window, min_periods=min_periods,\n                        freq=freq, center=center,\n                        pairwise=True)\n\n\ndef _rolling_moment(arg, window, func, minp, axis=0, freq=None, center=False,\n                    how=None, args=(), kwargs={}, **kwds):\n    \"\"\"\n    Rolling statistical measure using supplied function. Designed to be\n    used with passed-in Cython array-based functions.\n\n    Parameters\n    ----------\n    arg :  DataFrame or numpy ndarray-like\n    window : Number of observations used for calculating statistic\n    func : Cython function to compute rolling statistic on raw series\n    minp : int\n        Minimum number of observations required to have a value\n    axis : int, default 0\n    freq : None or string alias / date offset object, default=None\n        Frequency to conform to before computing statistic\n    center : boolean, default False\n        Whether the label should correspond with center of window\n    how : string, default 'mean'\n        Method for down- or re-sampling\n    args : tuple\n        Passed on to func\n    kwargs : dict\n        Passed on to func\n\n    Returns\n    -------\n    y : type of input\n    \"\"\"\n    arg = _conv_timerule(arg, freq, how)\n    offset = int((window - 1) / 2.) if center else 0\n    additional_nans = np.array([np.NaN] * offset)\n    calc = lambda x: func(np.concatenate((x, additional_nans)) if center else x,\n                          window, minp=minp, args=args, kwargs=kwargs,\n                          **kwds)\n    return_hook, values = _process_data_structure(arg)\n    # actually calculate the moment. Faster way to do this?\n    if values.ndim > 1:\n        result = np.apply_along_axis(calc, axis, values)\n    else:\n        result = calc(values)\n\n    if center:\n        result = _center_window(result, window, axis)\n    \n    return return_hook(result)\n\n\ndef _center_window(rs, window, axis):\n    if axis > rs.ndim-1:\n        raise ValueError(\"Requested axis is larger then no. of argument \"\n                         \"dimensions\")\n\n    offset = int((window - 1) / 2.)\n    if offset > 0:\n        if isinstance(rs, (Series, DataFrame, Panel)):\n            rs = rs.slice_shift(-offset, axis=axis)\n        else:\n            lead_indexer = [slice(None)] * rs.ndim\n            lead_indexer[axis] = slice(offset, None)\n            rs = np.copy(rs[tuple(lead_indexer)])\n    return rs\n\n\ndef _process_data_structure(arg, kill_inf=True):\n    if isinstance(arg, DataFrame):\n        return_hook = lambda v: type(arg)(v, index=arg.index,\n                                          columns=arg.columns)\n        values = arg.values\n    elif isinstance(arg, Series):\n        values = arg.values\n        return_hook = lambda v: Series(v, arg.index)\n    else:\n        return_hook = lambda v: v\n        values = arg\n\n    if not issubclass(values.dtype.type, float):\n        values = values.astype(float)\n\n    if kill_inf:\n        values = values.copy()\n        values[np.isinf(values)] = np.NaN\n\n    return return_hook, values\n\n#------------------------------------------------------------------------------\n# Exponential moving moments\n\n\ndef _get_center_of_mass(com, span, halflife):\n    valid_count = len([x for x in [com, span, halflife] if x is not None])\n    if valid_count > 1:\n        raise Exception(\"com, span, and halflife are mutually exclusive\")\n\n    if span is not None:\n        # convert span to center of mass\n        com = (span - 1) / 2.\n    elif halflife is not None:\n        # convert halflife to center of mass\n        decay = 1 - np.exp(np.log(0.5) / halflife)\n        com = 1 / decay - 1\n    elif com is None:\n        raise Exception(\"Must pass one of com, span, or halflife\")\n\n    return float(com)\n\n\n@Substitution(\"Exponentially-weighted moving average\", _unary_arg, _ewm_kw,\n              _type_of_input_retval, _ewm_notes)\n@Appender(_doc_template)\ndef ewma(arg, com=None, span=None, halflife=None, min_periods=0, freq=None,\n         adjust=True, how=None, ignore_na=False):\n    com = _get_center_of_mass(com, span, halflife)\n    arg = _conv_timerule(arg, freq, how)\n\n    def _ewma(v):\n        result = algos.ewma(v, com, int(adjust), int(ignore_na))\n        if min_periods > 1:\n            first_index = _first_valid_index(v)\n            result[first_index: first_index + min_periods - 1] = NaN\n        return result\n\n    return_hook, values = _process_data_structure(arg)\n    output = np.apply_along_axis(_ewma, 0, values)\n    return return_hook(output)\n\n\ndef _first_valid_index(arr):\n    # argmax scans from left\n    return notnull(arr).argmax() if len(arr) else 0\n\n\n@Substitution(\"Exponentially-weighted moving variance\", _unary_arg,\n              _ewm_kw+_bias_kw, _type_of_input_retval, _ewm_notes)\n@Appender(_doc_template)\ndef ewmvar(arg, com=None, span=None, halflife=None, min_periods=0, bias=False,\n           freq=None, how=None, ignore_na=False):\n    com = _get_center_of_mass(com, span, halflife)\n    arg = _conv_timerule(arg, freq, how)\n    moment2nd = ewma(arg * arg, com=com, min_periods=min_periods, ignore_na=ignore_na)\n    moment1st = ewma(arg, com=com, min_periods=min_periods, ignore_na=ignore_na)\n\n    result = moment2nd - moment1st ** 2\n    if not bias:\n        result *= (1.0 + 2.0 * com) / (2.0 * com)\n\n    return result\n\n\n@Substitution(\"Exponentially-weighted moving std\", _unary_arg,\n              _ewm_kw+_bias_kw, _type_of_input_retval, _ewm_notes)\n@Appender(_doc_template)\ndef ewmstd(arg, com=None, span=None, halflife=None, min_periods=0, bias=False,\n           ignore_na=False):\n    result = ewmvar(arg, com=com, span=span, halflife=halflife,\n                    min_periods=min_periods, bias=bias, ignore_na=ignore_na)\n    return _zsqrt(result)\n\newmvol = ewmstd\n\n\n@Substitution(\"Exponentially-weighted moving covariance\", _binary_arg_flex,\n              _ewm_kw+_pairwise_kw, _type_of_input_retval, _ewm_notes)\n@Appender(_doc_template)\ndef ewmcov(arg1, arg2=None, com=None, span=None, halflife=None, min_periods=0,\n           bias=False, freq=None, pairwise=None, how=None, ignore_na=False):\n    if arg2 is None:\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise\n    elif isinstance(arg2, (int, float)) and com is None:\n        com = arg2\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise\n    arg1 = _conv_timerule(arg1, freq, how)\n    arg2 = _conv_timerule(arg2, freq, how)\n\n    def _get_ewmcov(X, Y):\n        mean = lambda x: ewma(x, com=com, span=span, halflife=halflife, min_periods=min_periods,\n                              ignore_na=ignore_na)\n        return (mean(X * Y) - mean(X) * mean(Y))\n    result = _flex_binary_moment(arg1, arg2, _get_ewmcov,\n                                 pairwise=bool(pairwise))\n    if not bias:\n        com = _get_center_of_mass(com, span, halflife)\n        result *= (1.0 + 2.0 * com) / (2.0 * com)\n\n    return result\n\n\n@Substitution(\"Exponentially-weighted moving correlation\", _binary_arg_flex,\n              _ewm_kw+_pairwise_kw, _type_of_input_retval, _ewm_notes)\n@Appender(_doc_template)\ndef ewmcorr(arg1, arg2=None, com=None, span=None, halflife=None, min_periods=0,\n            freq=None, pairwise=None, how=None, ignore_na=False):\n    if arg2 is None:\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise\n    elif isinstance(arg2, (int, float)) and com is None:\n        com = arg2\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise\n    arg1 = _conv_timerule(arg1, freq, how)\n    arg2 = _conv_timerule(arg2, freq, how)\n\n    def _get_ewmcorr(X, Y):\n        mean = lambda x: ewma(x, com=com, span=span, halflife=halflife, min_periods=min_periods,\n                              ignore_na=ignore_na)\n        var = lambda x: ewmvar(x, com=com, span=span, halflife=halflife, min_periods=min_periods,\n                               bias=True, ignore_na=ignore_na)\n        return (mean(X * Y) - mean(X) * mean(Y)) / _zsqrt(var(X) * var(Y))\n    result = _flex_binary_moment(arg1, arg2, _get_ewmcorr,\n                                 pairwise=bool(pairwise))\n    return result\n\n\ndef _zsqrt(x):\n    result = np.sqrt(x)\n    mask = x < 0\n\n    if isinstance(x, DataFrame):\n        if mask.values.any():\n            result[mask] = 0\n    else:\n        if mask.any():\n            result[mask] = 0\n\n    return result\n\n\ndef _prep_binary(arg1, arg2):\n    if not isinstance(arg2, type(arg1)):\n        raise Exception('Input arrays must be of the same type!')\n\n    # mask out values, this also makes a common index...\n    X = arg1 + 0 * arg2\n    Y = arg2 + 0 * arg1\n\n    return X, Y\n\n#----------------------------------------------------------------------\n# Python interface to Cython functions\n\n\ndef _conv_timerule(arg, freq, how):\n\n    types = (DataFrame, Series)\n    if freq is not None and isinstance(arg, types):\n        # Conform to whatever frequency needed.\n        arg = arg.resample(freq, how=how)\n\n    return arg\n\n\ndef _require_min_periods(p):\n    def _check_func(minp, window):\n        if minp is None:\n            return window\n        else:\n            return max(p, minp)\n    return _check_func\n\n\ndef _use_window(minp, window):\n    if minp is None:\n        return window\n    else:\n        return minp\n\n\ndef _rolling_func(func, desc, check_minp=_use_window, how=None):\n    if how is None:\n        how_arg_str = 'None'\n    else:\n        how_arg_str = \"'%s\"%how\n\n    @Substitution(desc, _unary_arg, _roll_kw%how_arg_str, _type_of_input_retval,\n                  _roll_notes)\n    @Appender(_doc_template)\n    @wraps(func)\n    def f(arg, window, min_periods=None, freq=None, center=False, how=how,\n          **kwargs):\n        def call_cython(arg, window, minp, args=(), kwargs={}, **kwds):\n            minp = check_minp(minp, window)\n            return func(arg, window, minp, **kwds)\n        return _rolling_moment(arg, window, call_cython, min_periods, freq=freq,\n                               center=center, how=how, **kwargs)\n\n    return f\n\nrolling_max = _rolling_func(algos.roll_max2, 'Moving maximum.', how='max')\nrolling_min = _rolling_func(algos.roll_min2, 'Moving minimum.', how='min')\nrolling_sum = _rolling_func(algos.roll_sum, 'Moving sum.')\nrolling_mean = _rolling_func(algos.roll_mean, 'Moving mean.')\nrolling_median = _rolling_func(algos.roll_median_cython, 'Moving median.',\n                               how='median')\n\n_ts_std = lambda *a, **kw: _zsqrt(algos.roll_var(*a, **kw))\nrolling_std = _rolling_func(_ts_std, 'Unbiased moving standard deviation.',\n                            check_minp=_require_min_periods(1))\nrolling_var = _rolling_func(algos.roll_var, 'Unbiased moving variance.',\n                            check_minp=_require_min_periods(1))\nrolling_skew = _rolling_func(algos.roll_skew, 'Unbiased moving skewness.',\n                             check_minp=_require_min_periods(3))\nrolling_kurt = _rolling_func(algos.roll_kurt, 'Unbiased moving kurtosis.',\n                             check_minp=_require_min_periods(4))\n\n\ndef rolling_quantile(arg, window, quantile, min_periods=None, freq=None,\n                     center=False):\n    \"\"\"Moving quantile.\n\n    Parameters\n    ----------\n    arg : Series, DataFrame\n    window : int\n        Size of the moving window. This is the number of observations used for\n        calculating the statistic.\n    quantile : float\n        0 <= quantile <= 1\n    min_periods : int, default None\n        Minimum number of observations in window required to have a value\n        (otherwise result is NA).\n    freq : string or DateOffset object, optional (default None)\n        Frequency to conform the data to before computing the statistic. Specified\n        as a frequency string or DateOffset object.\n    center : boolean, default False\n        Whether the label should correspond with center of window\n\n    Returns\n    -------\n    y : type of input argument\n\n    Notes\n    -----\n    By default, the result is set to the right edge of the window. This can be\n    changed to the center of the window by setting ``center=True``.\n\n    The `freq` keyword is used to conform time series data to a specified\n    frequency by resampling the data. This is done with the default parameters\n    of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n    \"\"\"\n\n    def call_cython(arg, window, minp, args=(), kwargs={}):\n        minp = _use_window(minp, window)\n        return algos.roll_quantile(arg, window, minp, quantile)\n    return _rolling_moment(arg, window, call_cython, min_periods, freq=freq,\n                           center=center)\n\n\ndef rolling_apply(arg, window, func, min_periods=None, freq=None,\n                  center=False, args=(), kwargs={}):\n    \"\"\"Generic moving function application.\n\n    Parameters\n    ----------\n    arg : Series, DataFrame\n    window : int\n        Size of the moving window. This is the number of observations used for\n        calculating the statistic.\n    func : function\n        Must produce a single value from an ndarray input\n    min_periods : int, default None\n        Minimum number of observations in window required to have a value\n        (otherwise result is NA).\n    freq : string or DateOffset object, optional (default None)\n        Frequency to conform the data to before computing the statistic. Specified\n        as a frequency string or DateOffset object.\n    center : boolean, default False\n        Whether the label should correspond with center of window\n    args : tuple\n        Passed on to func\n    kwargs : dict\n        Passed on to func\n\n    Returns\n    -------\n    y : type of input argument\n\n    Notes\n    -----\n    By default, the result is set to the right edge of the window. This can be\n    changed to the center of the window by setting ``center=True``.\n\n    The `freq` keyword is used to conform time series data to a specified\n    frequency by resampling the data. This is done with the default parameters\n    of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n    \"\"\"\n    def call_cython(arg, window, minp, args, kwargs):\n        minp = _use_window(minp, window)\n        return algos.roll_generic(arg, window, minp, func, args, kwargs)\n    return _rolling_moment(arg, window, call_cython, min_periods, freq=freq,\n                           center=center, args=args, kwargs=kwargs)\n\n\ndef rolling_window(arg, window=None, win_type=None, min_periods=None,\n                   freq=None, center=False, mean=True,\n                   axis=0, how=None, **kwargs):\n    \"\"\"\n    Applies a moving window of type ``window_type`` and size ``window``\n    on the data.\n\n    Parameters\n    ----------\n    arg : Series, DataFrame\n    window : int or ndarray\n        Weighting window specification. If the window is an integer, then it is\n        treated as the window length and win_type is required\n    win_type : str, default None\n        Window type (see Notes)\n    min_periods : int, default None\n        Minimum number of observations in window required to have a value\n        (otherwise result is NA).\n    freq : string or DateOffset object, optional (default None)\n        Frequency to conform the data to before computing the statistic. Specified\n        as a frequency string or DateOffset object.\n    center : boolean, default False\n        Whether the label should correspond with center of window\n    mean : boolean, default True\n        If True computes weighted mean, else weighted sum\n    axis : {0, 1}, default 0\n    how : string, default 'mean'\n        Method for down- or re-sampling\n\n    Returns\n    -------\n    y : type of input argument\n\n    Notes\n    -----\n    The recognized window types are:\n\n    * ``boxcar``\n    * ``triang``\n    * ``blackman``\n    * ``hamming``\n    * ``bartlett``\n    * ``parzen``\n    * ``bohman``\n    * ``blackmanharris``\n    * ``nuttall``\n    * ``barthann``\n    * ``kaiser`` (needs beta)\n    * ``gaussian`` (needs std)\n    * ``general_gaussian`` (needs power, width)\n    * ``slepian`` (needs width).\n\n    By default, the result is set to the right edge of the window. This can be\n    changed to the center of the window by setting ``center=True``.\n\n    The `freq` keyword is used to conform time series data to a specified\n    frequency by resampling the data. This is done with the default parameters\n    of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n    \"\"\"\n    if isinstance(window, (list, tuple, np.ndarray)):\n        if win_type is not None:\n            raise ValueError(('Do not specify window type if using custom '\n                              'weights'))\n        window = pdcom._asarray_tuplesafe(window).astype(float)\n    elif pdcom.is_integer(window):  # window size\n        if win_type is None:\n            raise ValueError('Must specify window type')\n        try:\n            import scipy.signal as sig\n        except ImportError:\n            raise ImportError('Please install scipy to generate window weight')\n        win_type = _validate_win_type(win_type, kwargs)  # may pop from kwargs\n        window = sig.get_window(win_type, window).astype(float)\n    else:\n        raise ValueError('Invalid window %s' % str(window))\n\n    minp = _use_window(min_periods, len(window))\n\n    arg = _conv_timerule(arg, freq, how)\n    return_hook, values = _process_data_structure(arg)\n\n    offset = int((len(window) - 1) / 2.) if center else 0\n    additional_nans = np.array([np.NaN] * offset)\n    f = lambda x: algos.roll_window(np.concatenate((x, additional_nans)) if center else x,\n                                    window, minp, avg=mean)\n    result = np.apply_along_axis(f, axis, values)\n\n    if center:\n        result = _center_window(result, len(window), axis)\n\n    return return_hook(result)\n\n\ndef _validate_win_type(win_type, kwargs):\n    # may pop from kwargs\n    arg_map = {'kaiser': ['beta'],\n               'gaussian': ['std'],\n               'general_gaussian': ['power', 'width'],\n               'slepian': ['width']}\n    if win_type in arg_map:\n        return tuple([win_type] +\n                     _pop_args(win_type, arg_map[win_type], kwargs))\n    return win_type\n\n\ndef _pop_args(win_type, arg_names, kwargs):\n    msg = '%s window requires %%s' % win_type\n    all_args = []\n    for n in arg_names:\n        if n not in kwargs:\n            raise ValueError(msg % n)\n        all_args.append(kwargs.pop(n))\n    return all_args\n\n\ndef _expanding_func(func, desc, check_minp=_use_window):\n    @Substitution(desc, _unary_arg, _expanding_kw, _type_of_input_retval, \"\")\n    @Appender(_doc_template)\n    @wraps(func)\n    def f(arg, min_periods=1, freq=None, **kwargs):\n        window = len(arg)\n\n        def call_cython(arg, window, minp, args=(), kwargs={}, **kwds):\n            minp = check_minp(minp, window)\n            return func(arg, window, minp, **kwds)\n        return _rolling_moment(arg, window, call_cython, min_periods, freq=freq,\n                               **kwargs)\n\n    return f\n\nexpanding_max = _expanding_func(algos.roll_max2, 'Expanding maximum.')\nexpanding_min = _expanding_func(algos.roll_min2, 'Expanding minimum.')\nexpanding_sum = _expanding_func(algos.roll_sum, 'Expanding sum.')\nexpanding_mean = _expanding_func(algos.roll_mean, 'Expanding mean.')\nexpanding_median = _expanding_func(\n    algos.roll_median_cython, 'Expanding median.')\n\nexpanding_std = _expanding_func(_ts_std,\n                                'Unbiased expanding standard deviation.',\n                                check_minp=_require_min_periods(2))\nexpanding_var = _expanding_func(algos.roll_var, 'Unbiased expanding variance.',\n                                check_minp=_require_min_periods(2))\nexpanding_skew = _expanding_func(\n    algos.roll_skew, 'Unbiased expanding skewness.',\n    check_minp=_require_min_periods(3))\nexpanding_kurt = _expanding_func(\n    algos.roll_kurt, 'Unbiased expanding kurtosis.',\n    check_minp=_require_min_periods(4))\n\n\ndef expanding_count(arg, freq=None):\n    \"\"\"\n    Expanding count of number of non-NaN observations.\n\n    Parameters\n    ----------\n    arg :  DataFrame or numpy ndarray-like\n    freq : string or DateOffset object, optional (default None)\n        Frequency to conform the data to before computing the statistic. Specified\n        as a frequency string or DateOffset object.\n\n    Returns\n    -------\n    expanding_count : type of caller\n\n    Notes\n    -----\n    The `freq` keyword is used to conform time series data to a specified\n    frequency by resampling the data. This is done with the default parameters\n    of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n    \"\"\"\n    return rolling_count(arg, len(arg), freq=freq)\n\n\ndef expanding_quantile(arg, quantile, min_periods=1, freq=None):\n    \"\"\"Expanding quantile.\n\n    Parameters\n    ----------\n    arg : Series, DataFrame\n    quantile : float\n        0 <= quantile <= 1\n    min_periods : int, default None\n        Minimum number of observations in window required to have a value\n        (otherwise result is NA).\n    freq : string or DateOffset object, optional (default None)\n        Frequency to conform the data to before computing the statistic. Specified\n        as a frequency string or DateOffset object.\n\n    Returns\n    -------\n    y : type of input argument\n\n    Notes\n    -----\n    The `freq` keyword is used to conform time series data to a specified\n    frequency by resampling the data. This is done with the default parameters\n    of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n    \"\"\"\n    return rolling_quantile(arg, len(arg), quantile, min_periods=min_periods,\n                            freq=freq)\n\n\n@Substitution(\"Unbiased expanding covariance.\", _binary_arg_flex,\n              _expanding_kw+_pairwise_kw, _flex_retval, \"\")\n@Appender(_doc_template)\ndef expanding_cov(arg1, arg2=None, min_periods=1, freq=None, pairwise=None):\n    if arg2 is None:\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise\n    elif isinstance(arg2, (int, float)) and min_periods is None:\n        min_periods = arg2\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise\n    window = len(arg1) + len(arg2)\n    return rolling_cov(arg1, arg2, window,\n                       min_periods=min_periods, freq=freq,\n                       pairwise=pairwise)\n\n\n@Substitution(\"Expanding sample correlation.\", _binary_arg_flex,\n              _expanding_kw+_pairwise_kw, _flex_retval, \"\")\n@Appender(_doc_template)\ndef expanding_corr(arg1, arg2=None, min_periods=1, freq=None, pairwise=None):\n    if arg2 is None:\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise\n    elif isinstance(arg2, (int, float)) and min_periods is None:\n        min_periods = arg2\n        arg2 = arg1\n        pairwise = True if pairwise is None else pairwise\n    window = len(arg1) + len(arg2)\n    return rolling_corr(arg1, arg2, window,\n                        min_periods=min_periods,\n                        freq=freq, pairwise=pairwise)\n\n\n@Substitution(\"Deprecated. Use expanding_corr(..., pairwise=True) instead.\\n\\n\"\n              \"Pairwise expanding sample correlation\", _pairwise_arg,\n              _expanding_kw, _pairwise_retval, \"\")\n@Appender(_doc_template)\ndef expanding_corr_pairwise(df1, df2=None, min_periods=1, freq=None):\n    import warnings\n    warnings.warn(\"expanding_corr_pairwise is deprecated, use expanding_corr(..., pairwise=True)\", FutureWarning)\n    return expanding_corr(df1, df2, min_periods=min_periods,\n                          freq=freq, pairwise=True)\n\n\ndef expanding_apply(arg, func, min_periods=1, freq=None,\n                    args=(), kwargs={}):\n    \"\"\"Generic expanding function application.\n\n    Parameters\n    ----------\n    arg : Series, DataFrame\n    func : function\n        Must produce a single value from an ndarray input\n    min_periods : int, default None\n        Minimum number of observations in window required to have a value\n        (otherwise result is NA).\n    freq : string or DateOffset object, optional (default None)\n        Frequency to conform the data to before computing the statistic. Specified\n        as a frequency string or DateOffset object.\n    args : tuple\n        Passed on to func\n    kwargs : dict\n        Passed on to func\n\n    Returns\n    -------\n    y : type of input argument\n\n    Notes\n    -----\n    The `freq` keyword is used to conform time series data to a specified\n    frequency by resampling the data. This is done with the default parameters\n    of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n    \"\"\"\n    window = len(arg)\n    return rolling_apply(arg, window, func, min_periods=min_periods, freq=freq,\n                         args=args, kwargs=kwargs)\n"
    },
    {
      "filename": "pandas/stats/tests/test_moments.py",
      "content": "import nose\nimport sys\nimport functools\n\nfrom datetime import datetime\nfrom numpy.random import randn\nimport numpy as np\n\nfrom pandas import Series, DataFrame, Panel, bdate_range, isnull, notnull\nfrom pandas.util.testing import (\n    assert_almost_equal, assert_series_equal, assert_frame_equal, assert_panel_equal, assert_index_equal\n)\nimport pandas.core.datetools as datetools\nimport pandas.stats.moments as mom\nimport pandas.util.testing as tm\nfrom pandas.compat import range, zip, PY3, StringIO\n\nN, K = 100, 10\n\n\nclass TestMoments(tm.TestCase):\n\n    _multiprocess_can_split_ = True\n\n    _nan_locs = np.arange(20, 40)\n    _inf_locs = np.array([])\n\n    def setUp(self):\n        arr = randn(N)\n        arr[self._nan_locs] = np.NaN\n\n        self.arr = arr\n        self.rng = bdate_range(datetime(2009, 1, 1), periods=N)\n\n        self.series = Series(arr.copy(), index=self.rng)\n\n        self.frame = DataFrame(randn(N, K), index=self.rng,\n                               columns=np.arange(K))\n\n    def test_centered_axis_validation(self):\n        # ok\n        mom.rolling_mean(Series(np.ones(10)),3,center=True ,axis=0)\n        # bad axis\n        self.assertRaises(ValueError, mom.rolling_mean,Series(np.ones(10)),3,center=True ,axis=1)\n\n        # ok ok\n        mom.rolling_mean(DataFrame(np.ones((10,10))),3,center=True ,axis=0)\n        mom.rolling_mean(DataFrame(np.ones((10,10))),3,center=True ,axis=1)\n        # bad axis\n        self.assertRaises(ValueError, mom.rolling_mean,DataFrame(np.ones((10,10))),3,center=True ,axis=2)\n\n    def test_rolling_sum(self):\n        self._check_moment_func(mom.rolling_sum, np.sum)\n\n    def test_rolling_count(self):\n        counter = lambda x: np.isfinite(x).astype(float).sum()\n        self._check_moment_func(mom.rolling_count, counter,\n                                has_min_periods=False,\n                                preserve_nan=False,\n                                fill_value=0)\n\n    def test_rolling_mean(self):\n        self._check_moment_func(mom.rolling_mean, np.mean)\n\n    def test_cmov_mean(self):\n        tm._skip_if_no_scipy()\n        try:\n            from scikits.timeseries.lib import cmov_mean\n        except ImportError:\n            raise nose.SkipTest(\"no scikits.timeseries\")\n\n        vals = np.random.randn(10)\n        xp = cmov_mean(vals, 5)\n\n        rs = mom.rolling_mean(vals, 5, center=True)\n        assert_almost_equal(xp.compressed(), rs[2:-2])\n        assert_almost_equal(xp.mask, np.isnan(rs))\n\n        xp = Series(rs)\n        rs = mom.rolling_mean(Series(vals), 5, center=True)\n        assert_series_equal(xp, rs)\n\n    def test_cmov_window(self):\n        tm._skip_if_no_scipy()\n        try:\n            from scikits.timeseries.lib import cmov_window\n        except ImportError:\n            raise nose.SkipTest(\"no scikits.timeseries\")\n\n        vals = np.random.randn(10)\n        xp = cmov_window(vals, 5, 'boxcar')\n\n        rs = mom.rolling_window(vals, 5, 'boxcar', center=True)\n        assert_almost_equal(xp.compressed(), rs[2:-2])\n        assert_almost_equal(xp.mask, np.isnan(rs))\n\n        xp = Series(rs)\n        rs = mom.rolling_window(Series(vals), 5, 'boxcar', center=True)\n        assert_series_equal(xp, rs)\n\n    def test_cmov_window_corner(self):\n        tm._skip_if_no_scipy()\n        try:\n            from scikits.timeseries.lib import cmov_window\n        except ImportError:\n            raise nose.SkipTest(\"no scikits.timeseries\")\n\n        # all nan\n        vals = np.empty(10, dtype=float)\n        vals.fill(np.nan)\n        rs = mom.rolling_window(vals, 5, 'boxcar', center=True)\n        self.assertTrue(np.isnan(rs).all())\n\n        # empty\n        vals = np.array([])\n        rs = mom.rolling_window(vals, 5, 'boxcar', center=True)\n        self.assertEqual(len(rs), 0)\n\n        # shorter than window\n        vals = np.random.randn(5)\n        rs = mom.rolling_window(vals, 10, 'boxcar')\n        self.assertTrue(np.isnan(rs).all())\n        self.assertEqual(len(rs), 5)\n\n    def test_cmov_window_frame(self):\n        tm._skip_if_no_scipy()\n        try:\n            from scikits.timeseries.lib import cmov_window\n        except ImportError:\n            raise nose.SkipTest(\"no scikits.timeseries\")\n\n        # DataFrame\n        vals = np.random.randn(10, 2)\n        xp = cmov_window(vals, 5, 'boxcar')\n        rs = mom.rolling_window(DataFrame(vals), 5, 'boxcar', center=True)\n        assert_frame_equal(DataFrame(xp), rs)\n\n    def test_cmov_window_na_min_periods(self):\n        tm._skip_if_no_scipy()\n        try:\n            from scikits.timeseries.lib import cmov_window\n        except ImportError:\n            raise nose.SkipTest(\"no scikits.timeseries\")\n\n        # min_periods\n        vals = Series(np.random.randn(10))\n        vals[4] = np.nan\n        vals[8] = np.nan\n\n        xp = mom.rolling_mean(vals, 5, min_periods=4, center=True)\n        rs = mom.rolling_window(vals, 5, 'boxcar', min_periods=4, center=True)\n\n        assert_series_equal(xp, rs)\n\n    def test_cmov_window_regular(self):\n        tm._skip_if_no_scipy()\n        try:\n            from scikits.timeseries.lib import cmov_window\n        except ImportError:\n            raise nose.SkipTest(\"no scikits.timeseries\")\n\n        win_types = ['triang', 'blackman', 'hamming', 'bartlett', 'bohman',\n                     'blackmanharris', 'nuttall', 'barthann']\n        for wt in win_types:\n            vals = np.random.randn(10)\n            xp = cmov_window(vals, 5, wt)\n\n            rs = mom.rolling_window(Series(vals), 5, wt, center=True)\n            assert_series_equal(Series(xp), rs)\n\n    def test_cmov_window_special(self):\n        tm._skip_if_no_scipy()\n        try:\n            from scikits.timeseries.lib import cmov_window\n        except ImportError:\n            raise nose.SkipTest(\"no scikits.timeseries\")\n\n        win_types = ['kaiser', 'gaussian', 'general_gaussian', 'slepian']\n        kwds = [{'beta': 1.}, {'std': 1.}, {'power': 2., 'width': 2.},\n                {'width': 0.5}]\n\n        for wt, k in zip(win_types, kwds):\n            vals = np.random.randn(10)\n            xp = cmov_window(vals, 5, (wt,) + tuple(k.values()))\n\n            rs = mom.rolling_window(Series(vals), 5, wt, center=True,\n                                    **k)\n            assert_series_equal(Series(xp), rs)\n\n    def test_rolling_median(self):\n        self._check_moment_func(mom.rolling_median, np.median)\n\n    def test_rolling_min(self):\n        self._check_moment_func(mom.rolling_min, np.min)\n\n        a = np.array([1, 2, 3, 4, 5])\n        b = mom.rolling_min(a, window=100, min_periods=1)\n        assert_almost_equal(b, np.ones(len(a)))\n\n        self.assertRaises(ValueError, mom.rolling_min, np.array([1,\n                          2, 3]), window=3, min_periods=5)\n\n    def test_rolling_max(self):\n        self._check_moment_func(mom.rolling_max, np.max)\n\n        a = np.array([1, 2, 3, 4, 5])\n        b = mom.rolling_max(a, window=100, min_periods=1)\n        assert_almost_equal(a, b)\n\n        self.assertRaises(ValueError, mom.rolling_max, np.array([1,\n                          2, 3]), window=3, min_periods=5)\n\n    def test_rolling_quantile(self):\n        qs = [.1, .5, .9]\n\n        def scoreatpercentile(a, per):\n            values = np.sort(a, axis=0)\n\n            idx = per / 1. * (values.shape[0] - 1)\n            return values[int(idx)]\n\n        for q in qs:\n            def f(x, window, min_periods=None, freq=None, center=False):\n                return mom.rolling_quantile(x, window, q,\n                                            min_periods=min_periods,\n                                            freq=freq,\n                                            center=center)\n\n            def alt(x):\n                return scoreatpercentile(x, q)\n\n            self._check_moment_func(f, alt)\n\n    def test_rolling_apply(self):\n        ser = Series([])\n        assert_series_equal(\n            ser, mom.rolling_apply(ser, 10, lambda x: x.mean()))\n\n        def roll_mean(x, window, min_periods=None, freq=None, center=False):\n            return mom.rolling_apply(x, window,\n                                     lambda x: x[np.isfinite(x)].mean(),\n                                     min_periods=min_periods,\n                                     freq=freq,\n                                     center=center)\n        self._check_moment_func(roll_mean, np.mean)\n\n    def test_rolling_apply_out_of_bounds(self):\n        # #1850\n        arr = np.arange(4)\n\n        # it works!\n        result = mom.rolling_apply(arr, 10, np.sum)\n        self.assertTrue(isnull(result).all())\n\n        result = mom.rolling_apply(arr, 10, np.sum, min_periods=1)\n        assert_almost_equal(result, result)\n\n    def test_rolling_std(self):\n        self._check_moment_func(mom.rolling_std,\n                                lambda x: np.std(x, ddof=1))\n        self._check_moment_func(functools.partial(mom.rolling_std, ddof=0),\n                                lambda x: np.std(x, ddof=0))\n\n    def test_rolling_std_1obs(self):\n        result = mom.rolling_std(np.array([1., 2., 3., 4., 5.]),\n                                 1, min_periods=1)\n        expected = np.zeros(5)\n\n        assert_almost_equal(result, expected)\n\n        result = mom.rolling_std(np.array([np.nan, np.nan, 3., 4., 5.]),\n                                 3, min_periods=2)\n        self.assertTrue(np.isnan(result[2]))\n\n    def test_rolling_std_neg_sqrt(self):\n        # unit test from Bottleneck\n\n        # Test move_nanstd for neg sqrt.\n\n        a = np.array([0.0011448196318903589,\n                      0.00028718669878572767,\n                      0.00028718669878572767,\n                      0.00028718669878572767,\n                      0.00028718669878572767])\n        b = mom.rolling_std(a, window=3)\n        self.assertTrue(np.isfinite(b[2:]).all())\n\n        b = mom.ewmstd(a, span=3)\n        self.assertTrue(np.isfinite(b[2:]).all())\n\n    def test_rolling_var(self):\n        self._check_moment_func(mom.rolling_var,\n                                lambda x: np.var(x, ddof=1),\n                                test_stable=True)\n        self._check_moment_func(functools.partial(mom.rolling_var, ddof=0),\n                                lambda x: np.var(x, ddof=0))\n\n    def test_rolling_skew(self):\n        try:\n            from scipy.stats import skew\n        except ImportError:\n            raise nose.SkipTest('no scipy')\n        self._check_moment_func(mom.rolling_skew,\n                                lambda x: skew(x, bias=False))\n\n    def test_rolling_kurt(self):\n        try:\n            from scipy.stats import kurtosis\n        except ImportError:\n            raise nose.SkipTest('no scipy')\n        self._check_moment_func(mom.rolling_kurt,\n                                lambda x: kurtosis(x, bias=False))\n\n    def test_fperr_robustness(self):\n        # TODO: remove this once python 2.5 out of picture\n        if PY3:\n            raise nose.SkipTest(\"doesn't work on python 3\")\n\n        # #2114\n        data = '\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1a@\\xaa\\xaa\\xaa\\xaa\\xaa\\xaa\\x02@8\\x8e\\xe38\\x8e\\xe3\\xe8?z\\t\\xed%\\xb4\\x97\\xd0?\\xa2\\x0c<\\xdd\\x9a\\x1f\\xb6?\\x82\\xbb\\xfa&y\\x7f\\x9d?\\xac\\'\\xa7\\xc4P\\xaa\\x83?\\x90\\xdf\\xde\\xb0k8j?`\\xea\\xe9u\\xf2zQ?*\\xe37\\x9d\\x98N7?\\xe2.\\xf5&v\\x13\\x1f?\\xec\\xc9\\xf8\\x19\\xa4\\xb7\\x04?\\x90b\\xf6w\\x85\\x9f\\xeb>\\xb5A\\xa4\\xfaXj\\xd2>F\\x02\\xdb\\xf8\\xcb\\x8d\\xb8>.\\xac<\\xfb\\x87^\\xa0>\\xe8:\\xa6\\xf9_\\xd3\\x85>\\xfb?\\xe2cUU\\xfd?\\xfc\\x7fA\\xed8\\x8e\\xe3?\\xa5\\xaa\\xac\\x91\\xf6\\x12\\xca?n\\x1cs\\xb6\\xf9a\\xb1?\\xe8%D\\xf3L-\\x97?5\\xddZD\\x11\\xe7~?#>\\xe7\\x82\\x0b\\x9ad?\\xd9R4Y\\x0fxK?;7x;\\nP2?N\\xf4JO\\xb8j\\x18?4\\xf81\\x8a%G\\x00?\\x9a\\xf5\\x97\\r2\\xb4\\xe5>\\xcd\\x9c\\xca\\xbcB\\xf0\\xcc>3\\x13\\x87(\\xd7J\\xb3>\\x99\\x19\\xb4\\xe0\\x1e\\xb9\\x99>ff\\xcd\\x95\\x14&\\x81>\\x88\\x88\\xbc\\xc7p\\xddf>`\\x0b\\xa6_\\x96|N>@\\xb2n\\xea\\x0eS4>U\\x98\\x938i\\x19\\x1b>\\x8eeb\\xd0\\xf0\\x10\\x02>\\xbd\\xdc-k\\x96\\x16\\xe8=(\\x93\\x1e\\xf2\\x0e\\x0f\\xd0=\\xe0n\\xd3Bii\\xb5=*\\xe9\\x19Y\\x8c\\x8c\\x9c=\\xc6\\xf0\\xbb\\x90]\\x08\\x83=]\\x96\\xfa\\xc0|`i=>d\\xfc\\xd5\\xfd\\xeaP=R0\\xfb\\xc7\\xa7\\x8e6=\\xc2\\x95\\xf9_\\x8a\\x13\\x1e=\\xd6c\\xa6\\xea\\x06\\r\\x04=r\\xda\\xdd8\\t\\xbc\\xea<\\xf6\\xe6\\x93\\xd0\\xb0\\xd2\\xd1<\\x9d\\xdeok\\x96\\xc3\\xb7<&~\\xea9s\\xaf\\x9f<UUUUUU\\x13@q\\x1c\\xc7q\\x1c\\xc7\\xf9?\\xf6\\x12\\xdaKh/\\xe1?\\xf2\\xc3\"e\\xe0\\xe9\\xc6?\\xed\\xaf\\x831+\\x8d\\xae?\\xf3\\x1f\\xad\\xcb\\x1c^\\x94?\\x15\\x1e\\xdd\\xbd>\\xb8\\x02@\\xc6\\xd2&\\xfd\\xa8\\xf5\\xe8?\\xd9\\xe1\\x19\\xfe\\xc5\\xa3\\xd0?v\\x82\"\\xa8\\xb2/\\xb6?\\x9dX\\x835\\xee\\x94\\x9d?h\\x90W\\xce\\x9e\\xb8\\x83?\\x8a\\xc0th~Kj?\\\\\\x80\\xf8\\x9a\\xa9\\x87Q?%\\xab\\xa0\\xce\\x8c_7?1\\xe4\\x80\\x13\\x11*\\x1f? \\x98\\x00\\r\\xb6\\xc6\\x04?\\x80u\\xabf\\x9d\\xb3\\xeb>UNrD\\xbew\\xd2>\\x1c\\x13C[\\xa8\\x9f\\xb8>\\x12b\\xd7<pj\\xa0>m-\\x1fQ@\\xe3\\x85>\\xe6\\x91)l\\x00/m>Da\\xc6\\xf2\\xaatS>\\x05\\xd7]\\xee\\xe3\\xf09>'\n\n        arr = np.frombuffer(data, dtype='<f8')\n        if sys.byteorder != \"little\":\n            arr = arr.byteswap().newbyteorder()\n\n        result = mom.rolling_sum(arr, 2)\n        self.assertTrue((result[1:] >= 0).all())\n\n        result = mom.rolling_mean(arr, 2)\n        self.assertTrue((result[1:] >= 0).all())\n\n        result = mom.rolling_var(arr, 2)\n        self.assertTrue((result[1:] >= 0).all())\n\n        # #2527, ugh\n        arr = np.array([0.00012456, 0.0003, 0])\n        result = mom.rolling_mean(arr, 1)\n        self.assertTrue(result[-1] >= 0)\n\n        result = mom.rolling_mean(-arr, 1)\n        self.assertTrue(result[-1] <= 0)\n\n    def _check_moment_func(self, func, static_comp, window=50,\n                           has_min_periods=True,\n                           has_center=True,\n                           has_time_rule=True,\n                           preserve_nan=True,\n                           fill_value=None,\n                           test_stable=False):\n\n        self._check_ndarray(func, static_comp, window=window,\n                            has_min_periods=has_min_periods,\n                            preserve_nan=preserve_nan,\n                            has_center=has_center,\n                            fill_value=fill_value,\n                            test_stable=test_stable)\n\n        self._check_structures(func, static_comp,\n                               has_min_periods=has_min_periods,\n                               has_time_rule=has_time_rule,\n                               fill_value=fill_value,\n                               has_center=has_center)\n\n    def _check_ndarray(self, func, static_comp, window=50,\n                       has_min_periods=True,\n                       preserve_nan=True,\n                       has_center=True,\n                       fill_value=None,\n                       test_stable=False,\n                       test_window=True):\n\n        result = func(self.arr, window)\n        assert_almost_equal(result[-1],\n                            static_comp(self.arr[-50:]))\n\n        if preserve_nan:\n            assert(np.isnan(result[self._nan_locs]).all())\n\n        # excluding NaNs correctly\n        arr = randn(50)\n        arr[:10] = np.NaN\n        arr[-10:] = np.NaN\n\n        if has_min_periods:\n            result = func(arr, 50, min_periods=30)\n            assert_almost_equal(result[-1], static_comp(arr[10:-10]))\n\n            # min_periods is working correctly\n            result = func(arr, 20, min_periods=15)\n            self.assertTrue(np.isnan(result[23]))\n            self.assertFalse(np.isnan(result[24]))\n\n            self.assertFalse(np.isnan(result[-6]))\n            self.assertTrue(np.isnan(result[-5]))\n\n            arr2 = randn(20)\n            result = func(arr2, 10, min_periods=5)\n            self.assertTrue(isnull(result[3]))\n            self.assertTrue(notnull(result[4]))\n\n            # min_periods=0\n            result0 = func(arr, 20, min_periods=0)\n            result1 = func(arr, 20, min_periods=1)\n            assert_almost_equal(result0, result1)\n        else:\n            result = func(arr, 50)\n            assert_almost_equal(result[-1], static_comp(arr[10:-10]))\n\n        # GH 7925\n        if has_center:\n            if has_min_periods:\n                result = func(arr, 20, min_periods=15, center=True)\n                expected = func(np.concatenate((arr, np.array([np.NaN] * 9))), 20, min_periods=15)[9:]\n            else:\n                result = func(arr, 20, center=True)\n                expected = func(np.concatenate((arr, np.array([np.NaN] * 9))), 20)[9:]\n\n            self.assert_numpy_array_equivalent(result, expected)\n\n        if test_stable:\n            result = func(self.arr + 1e9, window)\n            assert_almost_equal(result[-1],\n                                static_comp(self.arr[-50:] + 1e9))\n\n        # Test window larger than array, #7297\n        if test_window:\n            if has_min_periods:\n                for minp in (0, len(self.arr)-1, len(self.arr)):\n                    result = func(self.arr, len(self.arr)+1, min_periods=minp)\n                    expected = func(self.arr, len(self.arr), min_periods=minp)\n                    nan_mask = np.isnan(result)\n                    self.assertTrue(np.array_equal(nan_mask,\n                                                   np.isnan(expected)))\n                    nan_mask = ~nan_mask\n                    assert_almost_equal(result[nan_mask], expected[nan_mask])\n            else:\n                result = func(self.arr, len(self.arr)+1)\n                expected = func(self.arr, len(self.arr))\n                nan_mask = np.isnan(result)\n                self.assertTrue(np.array_equal(nan_mask, np.isnan(expected)))\n                nan_mask = ~nan_mask\n                assert_almost_equal(result[nan_mask], expected[nan_mask])\n\n\n\n\n    def _check_structures(self, func, static_comp,\n                          has_min_periods=True, has_time_rule=True,\n                          has_center=True,\n                          fill_value=None):\n\n        series_result = func(self.series, 50)\n        tm.assert_isinstance(series_result, Series)\n\n        frame_result = func(self.frame, 50)\n        self.assertEqual(type(frame_result), DataFrame)\n\n        # check time_rule works\n        if has_time_rule:\n            win = 25\n            minp = 10\n\n            if has_min_periods:\n                series_result = func(self.series[::2], win, min_periods=minp,\n                                     freq='B')\n                frame_result = func(self.frame[::2], win, min_periods=minp,\n                                    freq='B')\n            else:\n                series_result = func(self.series[::2], win, freq='B')\n                frame_result = func(self.frame[::2], win, freq='B')\n\n            last_date = series_result.index[-1]\n            prev_date = last_date - 24 * datetools.bday\n\n            trunc_series = self.series[::2].truncate(prev_date, last_date)\n            trunc_frame = self.frame[::2].truncate(prev_date, last_date)\n\n            assert_almost_equal(series_result[-1], static_comp(trunc_series))\n\n            assert_almost_equal(frame_result.xs(last_date),\n                                trunc_frame.apply(static_comp))\n\n        # GH 7925\n        if has_center:\n            if has_min_periods:\n                minp = 10\n                series_xp = func(self.series.reindex(list(self.series.index)+['x%d'%x for x in range(12)]), 25, min_periods=minp).shift(-12).reindex(self.series.index)\n                frame_xp = func(self.frame.reindex(list(self.frame.index)+['x%d'%x for x in range(12)]), 25, min_periods=minp).shift(-12).reindex(self.frame.index)\n\n                series_rs = func(self.series, 25, min_periods=minp,\n                                 center=True)\n                frame_rs = func(self.frame, 25, min_periods=minp,\n                                center=True)\n\n            else:\n                series_xp = func(self.series.reindex(list(self.series.index)+['x%d'%x for x in range(12)]), 25).shift(-12).reindex(self.series.index)\n                frame_xp = func(self.frame.reindex(list(self.frame.index)+['x%d'%x for x in range(12)]), 25).shift(-12).reindex(self.frame.index)\n\n                series_rs = func(self.series, 25, center=True)\n                frame_rs = func(self.frame, 25, center=True)\n\n            if fill_value is not None:\n                series_xp = series_xp.fillna(fill_value)\n                frame_xp = frame_xp.fillna(fill_value)\n            assert_series_equal(series_xp, series_rs)\n            assert_frame_equal(frame_xp, frame_rs)\n\n    def test_ewma(self):\n        self._check_ew(mom.ewma)\n\n        arr = np.zeros(1000)\n        arr[5] = 1\n        result = mom.ewma(arr, span=100, adjust=False).sum()\n        self.assertTrue(np.abs(result - 1) < 1e-2)\n\n        s = Series([1.0, 2.0, 4.0, 8.0])\n        \n        expected = Series([1.0, 1.6, 2.736842, 4.923077])\n        for f in [lambda s: mom.ewma(s, com=2.0, adjust=True),\n                  lambda s: mom.ewma(s, com=2.0, adjust=True, ignore_na=False),\n                  lambda s: mom.ewma(s, com=2.0, adjust=True, ignore_na=True),\n                 ]:\n            result = f(s)\n            assert_series_equal(result, expected)\n\n        expected = Series([1.0, 1.333333, 2.222222, 4.148148])\n        for f in [lambda s: mom.ewma(s, com=2.0, adjust=False),\n                  lambda s: mom.ewma(s, com=2.0, adjust=False, ignore_na=False),\n                  lambda s: mom.ewma(s, com=2.0, adjust=False, ignore_na=True),\n                 ]:\n            result = f(s)\n            assert_series_equal(result, expected)\n\n    def test_ewma_nan_handling(self):\n        s = Series([1.] + [np.nan] * 5 + [1.])\n        result = mom.ewma(s, com=5)\n        assert_almost_equal(result, [1.] * len(s))\n\n        s = Series([np.nan] * 2 + [1.] + [np.nan] * 2 + [1.])\n        result = mom.ewma(s, com=5)\n        assert_almost_equal(result, [np.nan] * 2 + [1.] * 4)\n\n        # GH 7603\n        s0 = Series([np.nan, 1., 101.])\n        s1 = Series([1., np.nan, 101.])\n        s2 = Series([np.nan, 1., np.nan, np.nan, 101., np.nan])\n        s3 = Series([1., np.nan, 101., 50.])\n        com = 2.\n        alpha = 1. / (1. + com)\n\n        def simple_wma(s, w):\n            return (s.multiply(w).cumsum() / w.cumsum()).fillna(method='ffill')\n\n        for (s, adjust, ignore_na, w) in [\n                (s0, True, False, [np.nan, (1. - alpha), 1.]),\n                (s0, True, True, [np.nan, (1. - alpha), 1.]),\n                (s0, False, False, [np.nan, (1. - alpha), alpha]),\n                (s0, False, True, [np.nan, (1. - alpha), alpha]),\n                (s1, True, False, [(1. - alpha)**2, np.nan, 1.]),\n                (s1, True, True, [(1. - alpha), np.nan, 1.]),\n                (s1, False, False, [(1. - alpha)**2, np.nan, alpha]),\n                (s1, False, True, [(1. - alpha), np.nan, alpha]),\n                (s2, True, False, [np.nan, (1. - alpha)**3, np.nan, np.nan, 1., np.nan]),\n                (s2, True, True, [np.nan, (1. - alpha), np.nan, np.nan, 1., np.nan]),\n                (s2, False, False, [np.nan, (1. - alpha)**3, np.nan, np.nan, alpha, np.nan]),\n                (s2, False, True, [np.nan, (1. - alpha), np.nan, np.nan, alpha, np.nan]),\n                (s3, True, False, [(1. - alpha)**3, np.nan, (1. - alpha), 1.]),\n                (s3, True, True, [(1. - alpha)**2, np.nan, (1. - alpha), 1.]),\n                (s3, False, False, [(1. - alpha)**3, np.nan, (1. - alpha) * alpha, alpha * ((1. - alpha)**2 + alpha)]),\n                (s3, False, True, [(1. - alpha)**2, np.nan, (1. - alpha) * alpha, alpha]),\n                ]:\n            expected = simple_wma(s, Series(w))\n            result = mom.ewma(s, com=com, adjust=adjust, ignore_na=ignore_na)\n            assert_series_equal(result, expected)\n            if ignore_na is False:\n                # check that ignore_na defaults to False\n                result = mom.ewma(s, com=com, adjust=adjust)\n                assert_series_equal(result, expected)\n\n    def test_ewmvar(self):\n        self._check_ew(mom.ewmvar)\n\n    def test_ewmvol(self):\n        self._check_ew(mom.ewmvol)\n\n    def test_ewma_span_com_args(self):\n        A = mom.ewma(self.arr, com=9.5)\n        B = mom.ewma(self.arr, span=20)\n        assert_almost_equal(A, B)\n\n        self.assertRaises(Exception, mom.ewma, self.arr, com=9.5, span=20)\n        self.assertRaises(Exception, mom.ewma, self.arr)\n\n    def test_ewma_halflife_arg(self):\n        A = mom.ewma(self.arr, com=13.932726172912965)\n        B = mom.ewma(self.arr, halflife=10.0)\n        assert_almost_equal(A, B)\n\n        self.assertRaises(Exception, mom.ewma, self.arr, span=20, halflife=50)\n        self.assertRaises(Exception, mom.ewma, self.arr, com=9.5, halflife=50)\n        self.assertRaises(Exception, mom.ewma, self.arr, com=9.5, span=20, halflife=50)\n        self.assertRaises(Exception, mom.ewma, self.arr)\n\n    def test_ew_empty_arrays(self):\n        arr = np.array([], dtype=np.float64)\n\n        funcs = [mom.ewma, mom.ewmvol, mom.ewmvar]\n        for f in funcs:\n            result = f(arr, 3)\n            assert_almost_equal(result, arr)\n\n    def _check_ew(self, func):\n        self._check_ew_ndarray(func)\n        self._check_ew_structures(func)\n\n    def _check_ew_ndarray(self, func, preserve_nan=False):\n        result = func(self.arr, com=10)\n        if preserve_nan:\n            assert(np.isnan(result[self._nan_locs]).all())\n\n        # excluding NaNs correctly\n        arr = randn(50)\n        arr[:10] = np.NaN\n        arr[-10:] = np.NaN\n        s = Series(arr)\n\n        # check min_periods\n        # GH 7898\n        result = func(s, 50, min_periods=2)\n        self.assertTrue(np.isnan(result.values[:11]).all())\n        self.assertFalse(np.isnan(result.values[11:]).any())\n\n        for min_periods in (0, 1):\n            result = func(s, 50, min_periods=min_periods)\n            if func == mom.ewma:\n                self.assertTrue(np.isnan(result.values[:10]).all())\n                self.assertFalse(np.isnan(result.values[10:]).any())\n            else:\n                # ewmstd, ewmvol, ewmvar *should* require at least two values,\n                # but currently require only one, for some reason\n                self.assertTrue(np.isnan(result.values[:10]).all())\n                self.assertFalse(np.isnan(result.values[10:]).any())\n\n            # check series of length 0\n            result = func(Series([]), 50, min_periods=min_periods)\n            assert_series_equal(result, Series([]))\n\n            # check series of length 1\n            result = func(Series([1.]), 50, min_periods=min_periods)\n            if func == mom.ewma:\n                assert_series_equal(result, Series([1.]))\n            else:\n                # ewmstd, ewmvol, ewmvar *should* require at least two values,\n                # so should return NaN, but currently require one, so return 0.\n                assert_series_equal(result, Series([0.]))\n\n        # pass in ints\n        result2 = func(np.arange(50), span=10)\n        self.assertEqual(result2.dtype, np.float_)\n\n    def _check_ew_structures(self, func):\n        series_result = func(self.series, com=10)\n        tm.assert_isinstance(series_result, Series)\n        frame_result = func(self.frame, com=10)\n        self.assertEqual(type(frame_result), DataFrame)\n\n    # binary moments\n    def test_rolling_cov(self):\n        A = self.series\n        B = A + randn(len(A))\n\n        result = mom.rolling_cov(A, B, 50, min_periods=25)\n        assert_almost_equal(result[-1], np.cov(A[-50:], B[-50:])[0, 1])\n\n    def test_rolling_cov_pairwise(self):\n        self._check_pairwise_moment(mom.rolling_cov, 10, min_periods=5)\n\n    def test_rolling_corr(self):\n        A = self.series\n        B = A + randn(len(A))\n\n        result = mom.rolling_corr(A, B, 50, min_periods=25)\n        assert_almost_equal(result[-1], np.corrcoef(A[-50:], B[-50:])[0, 1])\n\n        # test for correct bias correction\n        a = tm.makeTimeSeries()\n        b = tm.makeTimeSeries()\n        a[:5] = np.nan\n        b[:10] = np.nan\n\n        result = mom.rolling_corr(a, b, len(a), min_periods=1)\n        assert_almost_equal(result[-1], a.corr(b))\n\n    def test_rolling_corr_pairwise(self):\n        self._check_pairwise_moment(mom.rolling_corr, 10, min_periods=5)\n\n    def _check_pairwise_moment(self, func, *args, **kwargs):\n        panel = func(self.frame, *args, **kwargs)\n\n        actual = panel.ix[:, 1, 5]\n        expected = func(self.frame[1], self.frame[5], *args, **kwargs)\n        tm.assert_series_equal(actual, expected)\n\n    def test_flex_binary_moment(self):\n        # GH3155\n        # don't blow the stack\n        self.assertRaises(TypeError, mom._flex_binary_moment,5,6,None)\n\n    def test_corr_sanity(self):\n        #GH 3155\n        df = DataFrame(\n            np.array(\n                    [[ 0.87024726,  0.18505595],\n                      [ 0.64355431,  0.3091617 ],\n                      [ 0.92372966,  0.50552513],\n                      [ 0.00203756,  0.04520709],\n                      [ 0.84780328,  0.33394331],\n                      [ 0.78369152,  0.63919667]])\n            )\n\n        res = mom.rolling_corr(df[0],df[1],5,center=True)\n        self.assertTrue(all([np.abs(np.nan_to_num(x)) <=1 for x in res]))\n\n        # and some fuzzing\n        for i in range(10):\n            df = DataFrame(np.random.rand(30,2))\n            res = mom.rolling_corr(df[0],df[1],5,center=True)\n            try:\n                self.assertTrue(all([np.abs(np.nan_to_num(x)) <=1 for x in res]))\n            except:\n                print(res)\n\n\n    def test_flex_binary_frame(self):\n        def _check(method):\n            series = self.frame[1]\n\n            res = method(series, self.frame, 10)\n            res2 = method(self.frame, series, 10)\n            exp = self.frame.apply(lambda x: method(series, x, 10))\n\n            tm.assert_frame_equal(res, exp)\n            tm.assert_frame_equal(res2, exp)\n\n            frame2 = self.frame.copy()\n            frame2.values[:] = np.random.randn(*frame2.shape)\n\n            res3 = method(self.frame, frame2, 10)\n            exp = DataFrame(dict((k, method(self.frame[k], frame2[k], 10))\n                                 for k in self.frame))\n            tm.assert_frame_equal(res3, exp)\n\n        methods = [mom.rolling_corr, mom.rolling_cov]\n        for meth in methods:\n            _check(meth)\n\n    def test_ewmcov(self):\n        self._check_binary_ew(mom.ewmcov)\n\n    def test_ewmcov_pairwise(self):\n        self._check_pairwise_moment(mom.ewmcov, span=10, min_periods=5)\n\n    def test_ewmcorr(self):\n        self._check_binary_ew(mom.ewmcorr)\n\n    def test_ewmcorr_pairwise(self):\n        self._check_pairwise_moment(mom.ewmcorr, span=10, min_periods=5)\n\n    def _check_binary_ew(self, func):\n        A = Series(randn(50), index=np.arange(50))\n        B = A[2:] + randn(48)\n\n        A[:10] = np.NaN\n        B[-10:] = np.NaN\n\n        result = func(A, B, 20, min_periods=5)\n        self.assertTrue(np.isnan(result.values[:14]).all())\n        self.assertFalse(np.isnan(result.values[14:]).any())\n\n        # GH 7898\n        for min_periods in (0, 1, 2):\n            result = func(A, B, 20, min_periods=min_periods)\n            # binary functions (ewmcov, ewmcorr) *should* require at least two values\n            if (func == mom.ewmcov) and (min_periods <= 1):\n                # currenty ewmcov requires only one value, for some reason.\n                self.assertTrue(np.isnan(result.values[:10]).all())\n                self.assertFalse(np.isnan(result.values[10:]).any())\n            else:\n                self.assertTrue(np.isnan(result.values[:11]).all())\n                self.assertFalse(np.isnan(result.values[11:]).any())\n\n            # check series of length 0\n            result = func(Series([]), Series([]), 50, min_periods=min_periods)\n            assert_series_equal(result, Series([]))\n\n            # check series of length 1\n            result = func(Series([1.]), Series([1.]), 50, min_periods=min_periods)\n            if (func == mom.ewmcov) and (min_periods <= 1):\n                # currenty ewmcov requires only one value, for some reason.\n                assert_series_equal(result, Series([0.]))\n            else:\n                assert_series_equal(result, Series([np.NaN]))\n\n        self.assertRaises(Exception, func, A, randn(50), 20, min_periods=5)\n\n    def test_expanding_apply(self):\n        ser = Series([])\n        assert_series_equal(ser, mom.expanding_apply(ser, lambda x: x.mean()))\n\n        def expanding_mean(x, min_periods=1, freq=None):\n            return mom.expanding_apply(x,\n                                       lambda x: x.mean(),\n                                       min_periods=min_periods,\n                                       freq=freq)\n        self._check_expanding(expanding_mean, np.mean)\n\n    def test_expanding_apply_args_kwargs(self):\n        def mean_w_arg(x, const):\n            return np.mean(x) + const\n\n        df = DataFrame(np.random.rand(20, 3))\n\n        expected = mom.expanding_apply(df, np.mean) + 20.\n\n        assert_frame_equal(mom.expanding_apply(df, mean_w_arg, args=(20,)),\n                            expected)\n        assert_frame_equal(mom.expanding_apply(df, mean_w_arg,\n                                               kwargs={'const' : 20}),\n                            expected)\n\n\n    def test_expanding_corr(self):\n        A = self.series.dropna()\n        B = (A + randn(len(A)))[:-5]\n\n        result = mom.expanding_corr(A, B)\n\n        rolling_result = mom.rolling_corr(A, B, len(A), min_periods=1)\n\n        assert_almost_equal(rolling_result, result)\n\n    def test_expanding_count(self):\n        result = mom.expanding_count(self.series)\n        assert_almost_equal(result, mom.rolling_count(self.series,\n                                                      len(self.series)))\n\n    def test_expanding_quantile(self):\n        result = mom.expanding_quantile(self.series, 0.5)\n\n        rolling_result = mom.rolling_quantile(self.series,\n                                              len(self.series),\n                                              0.5, min_periods=1)\n\n        assert_almost_equal(result, rolling_result)\n\n    def test_expanding_cov(self):\n        A = self.series\n        B = (A + randn(len(A)))[:-5]\n\n        result = mom.expanding_cov(A, B)\n\n        rolling_result = mom.rolling_cov(A, B, len(A), min_periods=1)\n\n        assert_almost_equal(rolling_result, result)\n\n    def test_expanding_max(self):\n        self._check_expanding(mom.expanding_max, np.max, preserve_nan=False)\n\n    def test_expanding_cov_pairwise(self):\n        result = mom.expanding_cov(self.frame)\n\n        rolling_result = mom.rolling_cov(self.frame, len(self.frame),\n                                         min_periods=1)\n\n        for i in result.items:\n            assert_almost_equal(result[i], rolling_result[i])\n\n    def test_expanding_corr_pairwise(self):\n        result = mom.expanding_corr(self.frame)\n\n        rolling_result = mom.rolling_corr(self.frame, len(self.frame),\n                                          min_periods=1)\n\n        for i in result.items:\n            assert_almost_equal(result[i], rolling_result[i])\n\n    def test_expanding_cov_diff_index(self):\n        # GH 7512\n        s1 = Series([1, 2, 3], index=[0, 1, 2])\n        s2 = Series([1, 3], index=[0, 2])\n        result = mom.expanding_cov(s1, s2)\n        expected = Series([None, None, 2.0])\n        assert_series_equal(result, expected)\n\n        s2a = Series([1, None, 3], index=[0, 1, 2])\n        result = mom.expanding_cov(s1, s2a)\n        assert_series_equal(result, expected)\n\n        s1 = Series([7, 8, 10], index=[0, 1, 3])\n        s2 = Series([7, 9, 10], index=[0, 2, 3])\n        result = mom.expanding_cov(s1, s2)\n        expected = Series([None, None, None, 4.5])\n        assert_series_equal(result, expected)\n\n    def test_expanding_corr_diff_index(self):\n        # GH 7512\n        s1 = Series([1, 2, 3], index=[0, 1, 2])\n        s2 = Series([1, 3], index=[0, 2])\n        result = mom.expanding_corr(s1, s2)\n        expected = Series([None, None, 1.0])\n        assert_series_equal(result, expected)\n\n        s2a = Series([1, None, 3], index=[0, 1, 2])\n        result = mom.expanding_corr(s1, s2a)\n        assert_series_equal(result, expected)\n\n        s1 = Series([7, 8, 10], index=[0, 1, 3])\n        s2 = Series([7, 9, 10], index=[0, 2, 3])\n        result = mom.expanding_corr(s1, s2)\n        expected = Series([None, None, None, 1.])\n        assert_series_equal(result, expected)\n\n    def test_rolling_cov_diff_length(self):\n        # GH 7512\n        s1 = Series([1, 2, 3], index=[0, 1, 2])\n        s2 = Series([1, 3], index=[0, 2])\n        result = mom.rolling_cov(s1, s2, window=3, min_periods=2)\n        expected = Series([None, None, 2.0])\n        assert_series_equal(result, expected)\n\n        s2a = Series([1, None, 3], index=[0, 1, 2])\n        result = mom.rolling_cov(s1, s2a, window=3, min_periods=2)\n        assert_series_equal(result, expected)\n\n    def test_rolling_corr_diff_length(self):\n        # GH 7512\n        s1 = Series([1, 2, 3], index=[0, 1, 2])\n        s2 = Series([1, 3], index=[0, 2])\n        result = mom.rolling_corr(s1, s2, window=3, min_periods=2)\n        expected = Series([None, None, 1.0])\n        assert_series_equal(result, expected)\n\n        s2a = Series([1, None, 3], index=[0, 1, 2])\n        result = mom.rolling_corr(s1, s2a, window=3, min_periods=2)\n        assert_series_equal(result, expected)\n\n    def test_rolling_functions_window_non_shrinkage(self):\n        # GH 7764\n        s = Series(range(4))\n        s_expected = Series(np.nan, index=s.index)\n        df = DataFrame([[1,5], [3, 2], [3,9], [-1,0]], columns=['A','B'])\n        df_expected = DataFrame(np.nan, index=df.index, columns=df.columns)\n        df_expected_panel = Panel(items=df.index, major_axis=df.columns, minor_axis=df.columns)\n\n        functions = [lambda x: mom.rolling_cov(x, x, pairwise=False, window=10, min_periods=5),\n                     lambda x: mom.rolling_corr(x, x, pairwise=False, window=10, min_periods=5),\n                     lambda x: mom.rolling_max(x, window=10, min_periods=5),\n                     lambda x: mom.rolling_min(x, window=10, min_periods=5),\n                     lambda x: mom.rolling_sum(x, window=10, min_periods=5),\n                     lambda x: mom.rolling_mean(x, window=10, min_periods=5),\n                     lambda x: mom.rolling_std(x, window=10, min_periods=5),\n                     lambda x: mom.rolling_var(x, window=10, min_periods=5),\n                     lambda x: mom.rolling_skew(x, window=10, min_periods=5),\n                     lambda x: mom.rolling_kurt(x, window=10, min_periods=5),\n                     lambda x: mom.rolling_quantile(x, quantile=0.5, window=10, min_periods=5),\n                     lambda x: mom.rolling_median(x, window=10, min_periods=5),\n                     lambda x: mom.rolling_apply(x, func=sum, window=10, min_periods=5),\n                     lambda x: mom.rolling_window(x, win_type='boxcar', window=10, min_periods=5),\n                    ]\n        for f in functions:\n            try:\n                s_result = f(s)\n                assert_series_equal(s_result, s_expected)\n\n                df_result = f(df)\n                assert_frame_equal(df_result, df_expected)\n            except (ImportError):\n\n                # scipy needed for rolling_window\n                continue\n\n        functions = [lambda x: mom.rolling_cov(x, x, pairwise=True, window=10, min_periods=5),\n                     lambda x: mom.rolling_corr(x, x, pairwise=True, window=10, min_periods=5),\n                     # rolling_corr_pairwise is depracated, so the following line should be deleted\n                     # when rolling_corr_pairwise is removed.\n                     lambda x: mom.rolling_corr_pairwise(x, x, window=10, min_periods=5),\n                    ]\n        for f in functions:\n            df_result_panel = f(df)\n            assert_panel_equal(df_result_panel, df_expected_panel)\n\n    def test_expanding_cov_pairwise_diff_length(self):\n        # GH 7512\n        df1 = DataFrame([[1,5], [3, 2], [3,9]], columns=['A','B'])\n        df1a = DataFrame([[1,5], [3,9]], index=[0,2], columns=['A','B'])\n        df2 = DataFrame([[5,6], [None,None], [2,1]], columns=['X','Y'])\n        df2a = DataFrame([[5,6], [2,1]], index=[0,2], columns=['X','Y'])\n        result1 = mom.expanding_cov(df1, df2, pairwise=True)[2]\n        result2 = mom.expanding_cov(df1, df2a, pairwise=True)[2]\n        result3 = mom.expanding_cov(df1a, df2, pairwise=True)[2]\n        result4 = mom.expanding_cov(df1a, df2a, pairwise=True)[2]\n        expected = DataFrame([[-3., -5.], [-6., -10.]], index=['A','B'], columns=['X','Y'])\n        assert_frame_equal(result1, expected)\n        assert_frame_equal(result2, expected)\n        assert_frame_equal(result3, expected)\n        assert_frame_equal(result4, expected)\n\n    def test_expanding_corr_pairwise_diff_length(self):\n        # GH 7512\n        df1 = DataFrame([[1,2], [3, 2], [3,4]], columns=['A','B'])\n        df1a = DataFrame([[1,2], [3,4]], index=[0,2], columns=['A','B'])\n        df2 = DataFrame([[5,6], [None,None], [2,1]], columns=['X','Y'])\n        df2a = DataFrame([[5,6], [2,1]], index=[0,2], columns=['X','Y'])\n        result1 = mom.expanding_corr(df1, df2, pairwise=True)[2]\n        result2 = mom.expanding_corr(df1, df2a, pairwise=True)[2]\n        result3 = mom.expanding_corr(df1a, df2, pairwise=True)[2]\n        result4 = mom.expanding_corr(df1a, df2a, pairwise=True)[2]\n        expected = DataFrame([[-1.0, -1.0], [-1.0, -1.0]], index=['A','B'], columns=['X','Y'])\n        assert_frame_equal(result1, expected)\n        assert_frame_equal(result2, expected)\n        assert_frame_equal(result3, expected)\n        assert_frame_equal(result4, expected)\n    \n    def test_pairwise_stats_column_names_order(self):\n        # GH 7738\n        df1s = [DataFrame([[2,4],[1,2],[5,2],[8,1]], columns=[0,1]),\n                DataFrame([[2,4],[1,2],[5,2],[8,1]], columns=[1,0]),\n                DataFrame([[2,4],[1,2],[5,2],[8,1]], columns=[1,1]),\n                DataFrame([[2,4],[1,2],[5,2],[8,1]], columns=['C','C']),\n                DataFrame([[2,4],[1,2],[5,2],[8,1]], columns=[1.,0]),\n                DataFrame([[2,4],[1,2],[5,2],[8,1]], columns=[0.,1]),\n                DataFrame([[2,4],[1,2],[5,2],[8,1]], columns=['C',1]),\n                DataFrame([[2.,4.],[1.,2.],[5.,2.],[8.,1.]], columns=[1,0.]),\n                DataFrame([[2,4.],[1,2.],[5,2.],[8,1.]], columns=[0,1.]),\n                DataFrame([[2,4],[1,2],[5,2],[8,1.]], columns=[1.,'X']),\n               ]\n        df2 = DataFrame([[None,1,1],[None,1,2],[None,3,2],[None,8,1]], columns=['Y','Z','X'])\n        s = Series([1,1,3,8])\n\n        # DataFrame methods (which do not call _flex_binary_moment())\n        for f in [lambda x: x.cov(),\n                  lambda x: x.corr(),\n                 ]:\n            results = [f(df) for df in df1s]\n            for (df, result) in zip(df1s, results):\n                assert_index_equal(result.index, df.columns)\n                assert_index_equal(result.columns, df.columns)\n            for i, result in enumerate(results):\n                if i > 0:\n                    self.assert_numpy_array_equivalent(result, results[0])\n\n        # DataFrame with itself, pairwise=True\n        for f in [lambda x: mom.expanding_cov(x, pairwise=True),\n                  lambda x: mom.expanding_corr(x, pairwise=True),\n                  lambda x: mom.rolling_cov(x, window=3, pairwise=True),\n                  lambda x: mom.rolling_corr(x, window=3, pairwise=True),\n                  lambda x: mom.ewmcov(x, com=3, pairwise=True),\n                  lambda x: mom.ewmcorr(x, com=3, pairwise=True),\n                 ]:\n            results = [f(df) for df in df1s]\n            for (df, result) in zip(df1s, results):\n                assert_index_equal(result.items, df.index)\n                assert_index_equal(result.major_axis, df.columns)\n                assert_index_equal(result.minor_axis, df.columns)\n            for i, result in enumerate(results):\n                if i > 0:\n                    self.assert_numpy_array_equivalent(result, results[0])\n\n        # DataFrame with itself, pairwise=False\n        for f in [lambda x: mom.expanding_cov(x, pairwise=False),\n                  lambda x: mom.expanding_corr(x, pairwise=False),\n                  lambda x: mom.rolling_cov(x, window=3, pairwise=False),\n                  lambda x: mom.rolling_corr(x, window=3, pairwise=False),\n                  lambda x: mom.ewmcov(x, com=3, pairwise=False),\n                  lambda x: mom.ewmcorr(x, com=3, pairwise=False),\n                 ]:\n            results = [f(df) for df in df1s]\n            for (df, result) in zip(df1s, results):\n                assert_index_equal(result.index, df.index)\n                assert_index_equal(result.columns, df.columns)\n            for i, result in enumerate(results):\n                if i > 0:\n                    self.assert_numpy_array_equivalent(result, results[0])\n\n        # DataFrame with another DataFrame, pairwise=True\n        for f in [lambda x, y: mom.expanding_cov(x, y, pairwise=True),\n                  lambda x, y: mom.expanding_corr(x, y, pairwise=True),\n                  lambda x, y: mom.rolling_cov(x, y, window=3, pairwise=True),\n                  lambda x, y: mom.rolling_corr(x, y, window=3, pairwise=True),\n                  lambda x, y: mom.ewmcov(x, y, com=3, pairwise=True),\n                  lambda x, y: mom.ewmcorr(x, y, com=3, pairwise=True),\n                 ]:\n            results = [f(df, df2) for df in df1s]\n            for (df, result) in zip(df1s, results):\n                assert_index_equal(result.items, df.index)\n                assert_index_equal(result.major_axis, df.columns)\n                assert_index_equal(result.minor_axis, df2.columns)\n            for i, result in enumerate(results):\n                if i > 0:\n                    self.assert_numpy_array_equivalent(result, results[0])\n\n        # DataFrame with another DataFrame, pairwise=False\n        for f in [lambda x, y: mom.expanding_cov(x, y, pairwise=False),\n                  lambda x, y: mom.expanding_corr(x, y, pairwise=False),\n                  lambda x, y: mom.rolling_cov(x, y, window=3, pairwise=False),\n                  lambda x, y: mom.rolling_corr(x, y, window=3, pairwise=False),\n                  lambda x, y: mom.ewmcov(x, y, com=3, pairwise=False),\n                  lambda x, y: mom.ewmcorr(x, y, com=3, pairwise=False),\n                 ]:\n            results = [f(df, df2) if df.columns.is_unique else None for df in df1s]\n            for (df, result) in zip(df1s, results):\n                if result is not None:\n                    expected_index = df.index.union(df2.index)\n                    expected_columns = df.columns.union(df2.columns)\n                    assert_index_equal(result.index, expected_index)\n                    assert_index_equal(result.columns, expected_columns)\n                else:\n                    tm.assertRaisesRegexp(ValueError, \"'arg1' columns are not unique\", f, df, df2)\n                    tm.assertRaisesRegexp(ValueError, \"'arg2' columns are not unique\", f, df2, df)\n\n        # DataFrame with a Series\n        for f in [lambda x, y: mom.expanding_cov(x, y),\n                  lambda x, y: mom.expanding_corr(x, y),\n                  lambda x, y: mom.rolling_cov(x, y, window=3),\n                  lambda x, y: mom.rolling_corr(x, y, window=3),\n                  lambda x, y: mom.ewmcov(x, y, com=3),\n                  lambda x, y: mom.ewmcorr(x, y, com=3),\n                 ]:\n            results = [f(df, s) for df in df1s] + [f(s, df) for df in df1s]\n            for (df, result) in zip(df1s, results):\n                assert_index_equal(result.index, df.index)\n                assert_index_equal(result.columns, df.columns)\n            for i, result in enumerate(results):\n                if i > 0:\n                    self.assert_numpy_array_equivalent(result, results[0])\n\n    def test_rolling_skew_edge_cases(self):\n\n        all_nan = Series([np.NaN] * 5)\n\n        # yields all NaN (0 variance)\n        d = Series([1] * 5)\n        x = mom.rolling_skew(d, window=5)\n        assert_series_equal(all_nan, x)\n\n        # yields all NaN (window too small)\n        d = Series(np.random.randn(5))\n        x = mom.rolling_skew(d, window=2)\n        assert_series_equal(all_nan, x)\n\n        # yields [NaN, NaN, NaN, 0.177994, 1.548824]\n        d = Series([-1.50837035, -0.1297039 ,  0.19501095,\n                       1.73508164,  0.41941401])\n        expected = Series([np.NaN, np.NaN, np.NaN,\n                              0.177994, 1.548824])\n        x = mom.rolling_skew(d, window=4)\n        assert_series_equal(expected, x)\n\n    def test_rolling_kurt_edge_cases(self):\n\n        all_nan = Series([np.NaN] * 5)\n\n        # yields all NaN (0 variance)\n        d = Series([1] * 5)\n        x = mom.rolling_kurt(d, window=5)\n        assert_series_equal(all_nan, x)\n\n        # yields all NaN (window too small)\n        d = Series(np.random.randn(5))\n        x = mom.rolling_kurt(d, window=3)\n        assert_series_equal(all_nan, x)\n\n        # yields [NaN, NaN, NaN, 1.224307, 2.671499]\n        d = Series([-1.50837035, -0.1297039 ,  0.19501095,\n                    1.73508164,  0.41941401])\n        expected = Series([np.NaN, np.NaN, np.NaN,\n                           1.224307, 2.671499])\n        x = mom.rolling_kurt(d, window=4)\n        assert_series_equal(expected, x)\n\n    def _check_expanding_ndarray(self, func, static_comp, has_min_periods=True,\n                                 has_time_rule=True, preserve_nan=True):\n        result = func(self.arr)\n\n        assert_almost_equal(result[10],\n                            static_comp(self.arr[:11]))\n\n        if preserve_nan:\n            assert(np.isnan(result[self._nan_locs]).all())\n\n        arr = randn(50)\n\n        if has_min_periods:\n            result = func(arr, min_periods=30)\n            assert(np.isnan(result[:29]).all())\n            assert_almost_equal(result[-1], static_comp(arr[:50]))\n\n            # min_periods is working correctly\n            result = func(arr, min_periods=15)\n            self.assertTrue(np.isnan(result[13]))\n            self.assertFalse(np.isnan(result[14]))\n\n            arr2 = randn(20)\n            result = func(arr2, min_periods=5)\n            self.assertTrue(isnull(result[3]))\n            self.assertTrue(notnull(result[4]))\n\n            # min_periods=0\n            result0 = func(arr, min_periods=0)\n            result1 = func(arr, min_periods=1)\n            assert_almost_equal(result0, result1)\n        else:\n            result = func(arr)\n            assert_almost_equal(result[-1], static_comp(arr[:50]))\n\n    def _check_expanding_structures(self, func):\n        series_result = func(self.series)\n        tm.assert_isinstance(series_result, Series)\n        frame_result = func(self.frame)\n        self.assertEqual(type(frame_result), DataFrame)\n\n    def _check_expanding(self, func, static_comp, has_min_periods=True,\n                         has_time_rule=True,\n                         preserve_nan=True):\n        self._check_expanding_ndarray(func, static_comp,\n                                      has_min_periods=has_min_periods,\n                                      has_time_rule=has_time_rule,\n                                      preserve_nan=preserve_nan)\n        self._check_expanding_structures(func)\n\n    def test_rolling_max_gh6297(self):\n        \"\"\"Replicate result expected in GH #6297\"\"\"\n\n        indices = [datetime(1975, 1, i) for i in range(1, 6)]\n        # So that we can have 2 datapoints on one of the days\n        indices.append(datetime(1975, 1, 3, 6, 0))\n        series = Series(range(1, 7), index=indices)\n        # Use floats instead of ints as values\n        series = series.map(lambda x: float(x))\n        # Sort chronologically\n        series = series.sort_index()\n\n        expected = Series([1.0, 2.0, 6.0, 4.0, 5.0],\n                          index=[datetime(1975, 1, i, 0)\n                                 for i in range(1, 6)])\n        x = mom.rolling_max(series, window=1, freq='D')\n        assert_series_equal(expected, x)\n\n    def test_rolling_max_how_resample(self):\n\n        indices = [datetime(1975, 1, i) for i in range(1, 6)]\n        # So that we can have 3 datapoints on last day (4, 10, and 20)\n        indices.append(datetime(1975, 1, 5, 1))\n        indices.append(datetime(1975, 1, 5, 2))\n        series = Series(list(range(0, 5)) + [10, 20], index=indices)\n        # Use floats instead of ints as values\n        series = series.map(lambda x: float(x))\n        # Sort chronologically\n        series = series.sort_index()\n\n        # Default how should be max\n        expected = Series([0.0, 1.0, 2.0, 3.0, 20.0],\n                          index=[datetime(1975, 1, i, 0)\n                                 for i in range(1, 6)])\n        x = mom.rolling_max(series, window=1, freq='D')\n        assert_series_equal(expected, x)\n\n        # Now specify median (10.0)\n        expected = Series([0.0, 1.0, 2.0, 3.0, 10.0],\n                          index=[datetime(1975, 1, i, 0)\n                                 for i in range(1, 6)])\n        x = mom.rolling_max(series, window=1, freq='D', how='median')\n        assert_series_equal(expected, x)\n\n        # Now specify mean (4+10+20)/3\n        v = (4.0+10.0+20.0)/3.0\n        expected = Series([0.0, 1.0, 2.0, 3.0, v],\n                          index=[datetime(1975, 1, i, 0)\n                                 for i in range(1, 6)])\n        x = mom.rolling_max(series, window=1, freq='D', how='mean')\n        assert_series_equal(expected, x)\n\n\n    def test_rolling_min_how_resample(self):\n\n        indices = [datetime(1975, 1, i) for i in range(1, 6)]\n        # So that we can have 3 datapoints on last day (4, 10, and 20)\n        indices.append(datetime(1975, 1, 5, 1))\n        indices.append(datetime(1975, 1, 5, 2))\n        series = Series(list(range(0, 5)) + [10, 20], index=indices)\n        # Use floats instead of ints as values\n        series = series.map(lambda x: float(x))\n        # Sort chronologically\n        series = series.sort_index()\n\n        # Default how should be min\n        expected = Series([0.0, 1.0, 2.0, 3.0, 4.0],\n                          index=[datetime(1975, 1, i, 0)\n                                 for i in range(1, 6)])\n        x = mom.rolling_min(series, window=1, freq='D')\n        assert_series_equal(expected, x)\n\n    def test_rolling_median_how_resample(self):\n\n        indices = [datetime(1975, 1, i) for i in range(1, 6)]\n        # So that we can have 3 datapoints on last day (4, 10, and 20)\n        indices.append(datetime(1975, 1, 5, 1))\n        indices.append(datetime(1975, 1, 5, 2))\n        series = Series(list(range(0, 5)) + [10, 20], index=indices)\n        # Use floats instead of ints as values\n        series = series.map(lambda x: float(x))\n        # Sort chronologically\n        series = series.sort_index()\n\n        # Default how should be median\n        expected = Series([0.0, 1.0, 2.0, 3.0, 10],\n                          index=[datetime(1975, 1, i, 0)\n                                 for i in range(1, 6)])\n        x = mom.rolling_median(series, window=1, freq='D')\n        assert_series_equal(expected, x)\n\nif __name__ == '__main__':\n    import nose\n    nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],\n                   exit=False)\n"
    }
  ]
}