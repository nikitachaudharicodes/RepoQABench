{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "43038",
  "issue_description": "# BUG: Compare type `int64` with `Int64` fails\n\n- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\n```python\r\npd.api.types.pandas_dtype(\"int64\") == \"Int64\"\r\n\r\n```\r\n\r\n#### Problem description\r\n\r\nThe code above fails (`TypeError: data type 'Int64' not understood`) while the following cases pass:\r\n```Python\r\npd.api.types.pandas_dtype(\"int64\") == \"int64\"\r\npd.api.types.pandas_dtype(\"Int64\") == \"Int64\"\r\npd.api.types.pandas_dtype(\"Int64\") == \"int64\"\r\n```\r\n\r\n#### Expected Output\r\n`False`\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : c7f7443c1bad8262358114d5e88cd9c8a308e8aa\r\npython           : 3.7.11.final.0\r\npython-bits      : 64\r\nOS               : Windows\r\nOS-release       : 10\r\nVersion          : 10.0.19041\r\nmachine          : AMD64\r\nprocessor        : Intel64 Family 6 Model 142 Stepping 10, GenuineIntel\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : en_US.UTF-8\r\nLOCALE           : None.None\r\n\r\npandas           : 1.3.1\r\nnumpy            : 1.20.3\r\npytz             : 2021.1\r\ndateutil         : 2.8.2\r\npip              : 21.2.2\r\nsetuptools       : 52.0.0.post20210125\r\nCython           : 0.29.24\r\npytest           : 6.1.2\r\nhypothesis       : 6.14.1\r\nsphinx           : 4.0.2\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : 1.4.4\r\nlxml.etree       : 4.6.3\r\nhtml5lib         : 1.1\r\npymysql          : 1.0.2\r\npsycopg2         : None\r\njinja2           : 3.0.1\r\nIPython          : 7.22.0\r\npandas_datareader: None\r\nbs4              : 4.9.3\r\nbottleneck       : 1.3.2\r\nfsspec           : 2021.07.0\r\nfastparquet      : None\r\ngcsfs            : None\r\nmatplotlib       : 3.4.2\r\nnumexpr          : 2.7.3\r\nodfpy            : None\r\nopenpyxl         : 3.0.7\r\npandas_gbq       : None\r\npyarrow          : 3.0.0\r\npyxlsb           : None\r\ns3fs             : 0.4.2\r\nscipy            : 1.6.2\r\nsqlalchemy       : 1.4.22\r\ntables           : 3.6.1\r\ntabulate         : 0.8.9\r\nxarray           : 0.19.0\r\nxlrd             : 2.0.1\r\nxlwt             : 1.3.0\r\nnumba            : 0.53.0\r\n\r\n</details>\r\n",
  "issue_comments": [
    {
      "id": 898942199,
      "user": "jbrockmendel",
      "body": "This is an issue with `np.dtpye.__eq__`, should be fixed by https://github.com/numpy/numpy/pull/19228"
    },
    {
      "id": 899412886,
      "user": "simonjayhawkins",
      "body": "can't reproduce on pandas 1.2.5 onwards.\r\n\r\n```\r\n>>> pd.__version__\r\n'1.2.5'\r\n>>> pd.api.types.pandas_dtype(\"int64\") == \"Int64\"\r\nFalse\r\n```\r\n\r\n> #### Expected Output\r\n> `True`\r\n\r\nnumpy int dtypes can't hold missing values, so `False` seem more appropriate.\r\n"
    },
    {
      "id": 899614372,
      "user": "ChiQiao",
      "body": "Thanks @jbrockmendel and @simonjayhawkins for the input\r\n\r\n> can't reproduce on pandas 1.2.5 onwards.\r\n\r\nSince it may be a bug from numpy, I wonder which numpy version you were using?\r\nAlso, I wonder if you were able to reproduce the bug given the environment I posted (pandas 1.3.1, numpy 1.20.3)?\r\n\r\n\r\n\r\n\r\n> numpy int dtypes can't hold missing values, so `False` seem more appropriate.\r\n\r\nYes, that was a typo on my side. I've updated the description."
    },
    {
      "id": 908544126,
      "user": "kwhkim",
      "body": "In my case, no bug found. (But I can not understand how it can be a bug from `numpy` when `numpy` does not support integer `NA`s. Isn't it the reason that they named integer NA as `pd.NA`?)\r\n\r\n```\r\n>>> pd.api.types.pandas_dtype(\"int64\") == \"Int64\"\r\nFalse\r\n>>> pd.__version__\r\n'1.3.1'\r\n>>> np.__version__\r\n'1.21.1'\r\n```"
    },
    {
      "id": 941841371,
      "user": "mzeitlin11",
      "body": "See discussion in #43993 - this is fixed for newer versions of numpy, contributions welcome to add a regression test!"
    },
    {
      "id": 947687006,
      "user": "paulvdbles",
      "body": "take"
    },
    {
      "id": 978180877,
      "user": "ata-turhan",
      "body": "take"
    },
    {
      "id": 978183807,
      "user": "ata-turhan",
      "body": "Can you give me an example for how to add a regression test for this issue? Thank you :)"
    },
    {
      "id": 978193406,
      "user": "mzeitlin11",
      "body": "> Can you give me an example for how to add a regression test for this issue? Thank you :)\r\n\r\nI'd recommend looking at closed `good first issues` about testing (for example from https://github.com/pandas-dev/pandas/issues?q=is%3Aissue+label%3A%22good+first+issue%22+is%3Aclosed+label%3A%22Needs+Tests%22). If you look at some pull requests which close the issue, those should be good examples"
    },
    {
      "id": 1017602792,
      "user": "simonjayhawkins",
      "body": "closing as tests added in #44840"
    }
  ],
  "text_context": "# BUG: Compare type `int64` with `Int64` fails\n\n- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\n```python\r\npd.api.types.pandas_dtype(\"int64\") == \"Int64\"\r\n\r\n```\r\n\r\n#### Problem description\r\n\r\nThe code above fails (`TypeError: data type 'Int64' not understood`) while the following cases pass:\r\n```Python\r\npd.api.types.pandas_dtype(\"int64\") == \"int64\"\r\npd.api.types.pandas_dtype(\"Int64\") == \"Int64\"\r\npd.api.types.pandas_dtype(\"Int64\") == \"int64\"\r\n```\r\n\r\n#### Expected Output\r\n`False`\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : c7f7443c1bad8262358114d5e88cd9c8a308e8aa\r\npython           : 3.7.11.final.0\r\npython-bits      : 64\r\nOS               : Windows\r\nOS-release       : 10\r\nVersion          : 10.0.19041\r\nmachine          : AMD64\r\nprocessor        : Intel64 Family 6 Model 142 Stepping 10, GenuineIntel\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : en_US.UTF-8\r\nLOCALE           : None.None\r\n\r\npandas           : 1.3.1\r\nnumpy            : 1.20.3\r\npytz             : 2021.1\r\ndateutil         : 2.8.2\r\npip              : 21.2.2\r\nsetuptools       : 52.0.0.post20210125\r\nCython           : 0.29.24\r\npytest           : 6.1.2\r\nhypothesis       : 6.14.1\r\nsphinx           : 4.0.2\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : 1.4.4\r\nlxml.etree       : 4.6.3\r\nhtml5lib         : 1.1\r\npymysql          : 1.0.2\r\npsycopg2         : None\r\njinja2           : 3.0.1\r\nIPython          : 7.22.0\r\npandas_datareader: None\r\nbs4              : 4.9.3\r\nbottleneck       : 1.3.2\r\nfsspec           : 2021.07.0\r\nfastparquet      : None\r\ngcsfs            : None\r\nmatplotlib       : 3.4.2\r\nnumexpr          : 2.7.3\r\nodfpy            : None\r\nopenpyxl         : 3.0.7\r\npandas_gbq       : None\r\npyarrow          : 3.0.0\r\npyxlsb           : None\r\ns3fs             : 0.4.2\r\nscipy            : 1.6.2\r\nsqlalchemy       : 1.4.22\r\ntables           : 3.6.1\r\ntabulate         : 0.8.9\r\nxarray           : 0.19.0\r\nxlrd             : 2.0.1\r\nxlwt             : 1.3.0\r\nnumba            : 0.53.0\r\n\r\n</details>\r\n\n\nThis is an issue with `np.dtpye.__eq__`, should be fixed by https://github.com/numpy/numpy/pull/19228\n\ncan't reproduce on pandas 1.2.5 onwards.\r\n\r\n```\r\n>>> pd.__version__\r\n'1.2.5'\r\n>>> pd.api.types.pandas_dtype(\"int64\") == \"Int64\"\r\nFalse\r\n```\r\n\r\n> #### Expected Output\r\n> `True`\r\n\r\nnumpy int dtypes can't hold missing values, so `False` seem more appropriate.\r\n\n\nThanks @jbrockmendel and @simonjayhawkins for the input\r\n\r\n> can't reproduce on pandas 1.2.5 onwards.\r\n\r\nSince it may be a bug from numpy, I wonder which numpy version you were using?\r\nAlso, I wonder if you were able to reproduce the bug given the environment I posted (pandas 1.3.1, numpy 1.20.3)?\r\n\r\n\r\n\r\n\r\n> numpy int dtypes can't hold missing values, so `False` seem more appropriate.\r\n\r\nYes, that was a typo on my side. I've updated the description.\n\nIn my case, no bug found. (But I can not understand how it can be a bug from `numpy` when `numpy` does not support integer `NA`s. Isn't it the reason that they named integer NA as `pd.NA`?)\r\n\r\n```\r\n>>> pd.api.types.pandas_dtype(\"int64\") == \"Int64\"\r\nFalse\r\n>>> pd.__version__\r\n'1.3.1'\r\n>>> np.__version__\r\n'1.21.1'\r\n```\n\nSee discussion in #43993 - this is fixed for newer versions of numpy, contributions welcome to add a regression test!\n\ntake\n\ntake\n\nCan you give me an example for how to add a regression test for this issue? Thank you :)\n\n> Can you give me an example for how to add a regression test for this issue? Thank you :)\r\n\r\nI'd recommend looking at closed `good first issues` about testing (for example from https://github.com/pandas-dev/pandas/issues?q=is%3Aissue+label%3A%22good+first+issue%22+is%3Aclosed+label%3A%22Needs+Tests%22). If you look at some pull requests which close the issue, those should be good examples\n\nclosing as tests added in #44840",
  "pr_link": "https://github.com/numpy/numpy/pull/19228",
  "code_context": [
    {
      "filename": "numpy/core/src/multiarray/descriptor.c",
      "content": "/* Array Descr Object */\n\n#define PY_SSIZE_T_CLEAN\n#include <Python.h>\n#include \"structmember.h\"\n\n#define NPY_NO_DEPRECATED_API NPY_API_VERSION\n#define _MULTIARRAYMODULE\n#include \"numpy/arrayobject.h\"\n#include \"numpy/arrayscalars.h\"\n\n#include \"npy_config.h\"\n#include \"npy_ctypes.h\"\n#include \"npy_pycompat.h\"\n\n#include \"_datetime.h\"\n#include \"common.h\"\n#include \"templ_common.h\" /* for npy_mul_with_overflow_intp */\n#include \"descriptor.h\"\n#include \"alloc.h\"\n#include \"assert.h\"\n#include \"npy_buffer.h\"\n\n/*\n * offset:    A starting offset.\n * alignment: A power-of-two alignment.\n *\n * This macro returns the smallest value >= 'offset'\n * that is divisible by 'alignment'. Because 'alignment'\n * is a power of two and integers are twos-complement,\n * it is possible to use some simple bit-fiddling to do this.\n */\n#define NPY_NEXT_ALIGNED_OFFSET(offset, alignment) \\\n                (((offset) + (alignment) - 1) & (-(alignment)))\n\n#ifndef PyDictProxy_Check\n#define PyDictProxy_Check(obj) (Py_TYPE(obj) == &PyDictProxy_Type)\n#endif\n\nstatic PyObject *typeDict = NULL;   /* Must be explicitly loaded */\n\nstatic PyArray_Descr *\n_try_convert_from_inherit_tuple(PyArray_Descr *type, PyObject *newobj);\n\nstatic PyArray_Descr *\n_convert_from_any(PyObject *obj, int align);\n\n/*\n * This function creates a dtype object when the object is a ctypes subclass.\n *\n * Returns `Py_NotImplemented` if the type is not a ctypes subclass.\n */\nstatic PyArray_Descr *\n_try_convert_from_ctypes_type(PyTypeObject *type)\n{\n    PyObject *_numpy_dtype_ctypes;\n    PyObject *res;\n\n    if (!npy_ctypes_check(type)) {\n        Py_INCREF(Py_NotImplemented);\n        return (PyArray_Descr *)Py_NotImplemented;\n    }\n\n    /* Call the python function of the same name. */\n    _numpy_dtype_ctypes = PyImport_ImportModule(\"numpy.core._dtype_ctypes\");\n    if (_numpy_dtype_ctypes == NULL) {\n        return NULL;\n    }\n    res = PyObject_CallMethod(_numpy_dtype_ctypes, \"dtype_from_ctypes_type\", \"O\", (PyObject *)type);\n    Py_DECREF(_numpy_dtype_ctypes);\n    if (res == NULL) {\n        return NULL;\n    }\n\n    /*\n     * sanity check that dtype_from_ctypes_type returned the right type,\n     * since getting it wrong would give segfaults.\n     */\n    if (!PyObject_TypeCheck(res, &PyArrayDescr_Type)) {\n        Py_DECREF(res);\n        PyErr_BadInternalCall();\n        return NULL;\n    }\n\n    return (PyArray_Descr *)res;\n}\n\nstatic PyArray_Descr *\n_convert_from_any(PyObject *obj, int align);\n\n/*\n * This function creates a dtype object when the object has a \"dtype\" attribute,\n * and it can be converted to a dtype object.\n *\n * Returns `Py_NotImplemented` if this is not possible.\n * Currently the only failure mode for a NULL return is a RecursionError.\n */\nstatic PyArray_Descr *\n_try_convert_from_dtype_attr(PyObject *obj)\n{\n    /* For arbitrary objects that have a \"dtype\" attribute */\n    PyObject *dtypedescr = PyObject_GetAttrString(obj, \"dtype\");\n    if (dtypedescr == NULL) {\n        /*\n         * This can be reached due to recursion limit being hit while fetching\n         * the attribute (tested for py3.7). This removes the custom message.\n         */\n        goto fail;\n    }\n\n    if (PyArray_DescrCheck(dtypedescr)) {\n        /* The dtype attribute is already a valid descriptor */\n        return (PyArray_Descr *)dtypedescr;\n    }\n\n    if (Py_EnterRecursiveCall(\n            \" while trying to convert the given data type from its \"\n            \"`.dtype` attribute.\") != 0) {\n        Py_DECREF(dtypedescr);\n        return NULL;\n    }\n\n    PyArray_Descr *newdescr = _convert_from_any(dtypedescr, 0);\n    Py_DECREF(dtypedescr);\n    Py_LeaveRecursiveCall();\n    if (newdescr == NULL) {\n        goto fail;\n    }\n\n    /* Deprecated 2021-01-05, NumPy 1.21 */\n    if (DEPRECATE(\"in the future the `.dtype` attribute of a given data\"\n                  \"type object must be a valid dtype instance. \"\n                  \"`data_type.dtype` may need to be coerced using \"\n                  \"`np.dtype(data_type.dtype)`. (Deprecated NumPy 1.20)\") < 0) {\n        Py_DECREF(newdescr);\n        return NULL;\n    }\n\n    return newdescr;\n\n  fail:\n    /* Ignore all but recursion errors, to give ctypes a full try. */\n    if (!PyErr_ExceptionMatches(PyExc_RecursionError)) {\n        PyErr_Clear();\n        Py_INCREF(Py_NotImplemented);\n        return (PyArray_Descr *)Py_NotImplemented;\n    }\n    return NULL;\n}\n\n/* Expose to another file with a prefixed name */\nNPY_NO_EXPORT PyArray_Descr *\n_arraydescr_try_convert_from_dtype_attr(PyObject *obj)\n{\n    return _try_convert_from_dtype_attr(obj);\n}\n\n/*\n * Sets the global typeDict object, which is a dictionary mapping\n * dtype names to numpy scalar types.\n */\nNPY_NO_EXPORT PyObject *\narray_set_typeDict(PyObject *NPY_UNUSED(ignored), PyObject *args)\n{\n    PyObject *dict;\n\n    if (!PyArg_ParseTuple(args, \"O:set_typeDict\", &dict)) {\n        return NULL;\n    }\n    /* Decrement old reference (if any)*/\n    Py_XDECREF(typeDict);\n    typeDict = dict;\n    /* Create an internal reference to it */\n    Py_INCREF(dict);\n    Py_RETURN_NONE;\n}\n\n#define _chk_byteorder(arg) (arg == '>' || arg == '<' ||        \\\n                             arg == '|' || arg == '=')\n\nstatic int\n_check_for_commastring(const char *type, Py_ssize_t len)\n{\n    Py_ssize_t i;\n    int sqbracket;\n\n    /* Check for ints at start of string */\n    if ((type[0] >= '0'\n                && type[0] <= '9')\n            || ((len > 1)\n                && _chk_byteorder(type[0])\n                && (type[1] >= '0'\n                && type[1] <= '9'))) {\n        return 1;\n    }\n    /* Check for empty tuple */\n    if (((len > 1)\n                && (type[0] == '('\n                && type[1] == ')'))\n            || ((len > 3)\n                && _chk_byteorder(type[0])\n                && (type[1] == '('\n                && type[2] == ')'))) {\n        return 1;\n    }\n    /*\n     * Check for presence of commas outside square [] brackets. This\n     * allows commas inside of [], for parameterized dtypes to use.\n     */\n    sqbracket = 0;\n    for (i = 0; i < len; i++) {\n        switch (type[i]) {\n            case ',':\n                if (sqbracket == 0) {\n                    return 1;\n                }\n                break;\n            case '[':\n                ++sqbracket;\n                break;\n            case ']':\n                --sqbracket;\n                break;\n        }\n    }\n    return 0;\n}\n\n#undef _chk_byteorder\n\nstatic int\nis_datetime_typestr(char const *type, Py_ssize_t len)\n{\n    if (len < 2) {\n        return 0;\n    }\n    if (type[1] == '8' && (type[0] == 'M' || type[0] == 'm')) {\n        return 1;\n    }\n    if (len < 10) {\n        return 0;\n    }\n    if (strncmp(type, \"datetime64\", 10) == 0) {\n        return 1;\n    }\n    if (len < 11) {\n        return 0;\n    }\n    if (strncmp(type, \"timedelta64\", 11) == 0) {\n        return 1;\n    }\n    return 0;\n}\n\nstatic PyArray_Descr *\n_convert_from_tuple(PyObject *obj, int align)\n{\n    if (PyTuple_GET_SIZE(obj) != 2) {\n        PyErr_Format(PyExc_TypeError, \n\t        \"Tuple must have size 2, but has size %zd\",\n\t        PyTuple_GET_SIZE(obj));\n        return NULL;\n    }\n    PyArray_Descr *type = _convert_from_any(PyTuple_GET_ITEM(obj, 0), align);\n    if (type == NULL) {\n        return NULL;\n    }\n    PyObject *val = PyTuple_GET_ITEM(obj,1);\n    /* try to interpret next item as a type */\n    PyArray_Descr *res = _try_convert_from_inherit_tuple(type, val);\n    if ((PyObject *)res != Py_NotImplemented) {\n        Py_DECREF(type);\n        return res;\n    }\n    Py_DECREF(res);\n    /*\n     * We get here if _try_convert_from_inherit_tuple failed without crashing\n     */\n    if (PyDataType_ISUNSIZED(type)) {\n        /* interpret next item as a typesize */\n        int itemsize = PyArray_PyIntAsInt(PyTuple_GET_ITEM(obj,1));\n\n        if (error_converting(itemsize)) {\n            PyErr_SetString(PyExc_ValueError,\n                    \"invalid itemsize in generic type tuple\");\n            Py_DECREF(type);\n            return NULL;\n        }\n        PyArray_DESCR_REPLACE(type);\n        if (type == NULL) {\n            return NULL;\n        }\n        if (type->type_num == NPY_UNICODE) {\n            type->elsize = itemsize << 2;\n        }\n        else {\n            type->elsize = itemsize;\n        }\n        return type;\n    }\n    else if (type->metadata && (PyDict_Check(val) || PyDictProxy_Check(val))) {\n        /* Assume it's a metadata dictionary */\n        if (PyDict_Merge(type->metadata, val, 0) == -1) {\n            Py_DECREF(type);\n            return NULL;\n        }\n        return type;\n    }\n    else {\n        /*\n         * interpret next item as shape (if it's a tuple)\n         * and reset the type to NPY_VOID with\n         * a new fields attribute.\n         */\n        PyArray_Dims shape = {NULL, -1};\n        if (!(PyArray_IntpConverter(val, &shape)) || (shape.len > NPY_MAXDIMS)) {\n            PyErr_SetString(PyExc_ValueError,\n                    \"invalid shape in fixed-type tuple.\");\n            goto fail;\n        }\n        /* if (type, ()) was given it is equivalent to type... */\n        if (shape.len == 0 && PyTuple_Check(val)) {\n            npy_free_cache_dim_obj(shape);\n            return type;\n        }\n        /* (type, 1) use to be equivalent to type, but is deprecated */\n        if (shape.len == 1\n                && shape.ptr[0] == 1\n                && PyNumber_Check(val)) {\n            /* 2019-05-20, 1.17 */\n            if (DEPRECATE_FUTUREWARNING(\n                        \"Passing (type, 1) or '1type' as a synonym of type is \"\n                        \"deprecated; in a future version of numpy, it will be \"\n                        \"understood as (type, (1,)) / '(1,)type'.\") < 0) {\n                goto fail;\n            }\n            npy_free_cache_dim_obj(shape);\n            return type;\n        }\n\n        /* validate and set shape */\n        for (int i=0; i < shape.len; i++) {\n            if (shape.ptr[i] < 0) {\n                PyErr_SetString(PyExc_ValueError,\n                                \"invalid shape in fixed-type tuple: \"\n                                \"dimension smaller then zero.\");\n                goto fail;\n            }\n            if (shape.ptr[i] > NPY_MAX_INT) {\n                PyErr_SetString(PyExc_ValueError,\n                                \"invalid shape in fixed-type tuple: \"\n                                \"dimension does not fit into a C int.\");\n                goto fail;\n            }\n        }\n        npy_intp items = PyArray_OverflowMultiplyList(shape.ptr, shape.len);\n        int overflowed;\n        int nbytes;\n        if (items < 0 || items > NPY_MAX_INT) {\n            overflowed = 1;\n        }\n        else {\n            overflowed = npy_mul_with_overflow_int(\n                &nbytes, type->elsize, (int) items);\n        }\n        if (overflowed) {\n            PyErr_SetString(PyExc_ValueError,\n                            \"invalid shape in fixed-type tuple: dtype size in \"\n                            \"bytes must fit into a C int.\");\n            goto fail;\n        }\n        PyArray_Descr *newdescr = PyArray_DescrNewFromType(NPY_VOID);\n        if (newdescr == NULL) {\n            goto fail;\n        }\n        newdescr->elsize = nbytes;\n        newdescr->subarray = PyArray_malloc(sizeof(PyArray_ArrayDescr));\n        if (newdescr->subarray == NULL) {\n            Py_DECREF(newdescr);\n            PyErr_NoMemory();\n            goto fail;\n        }\n        newdescr->flags = type->flags;\n        newdescr->alignment = type->alignment;\n        newdescr->subarray->base = type;\n        type = NULL;\n        Py_XDECREF(newdescr->fields);\n        Py_XDECREF(newdescr->names);\n        newdescr->fields = NULL;\n        newdescr->names = NULL;\n\n        /*\n         * Create a new subarray->shape tuple (it can be an arbitrary\n         * sequence of integer like objects, neither of which is safe.\n         */\n        newdescr->subarray->shape = PyTuple_New(shape.len);\n        if (newdescr->subarray->shape == NULL) {\n            Py_DECREF(newdescr);\n            goto fail;\n        }\n        for (int i=0; i < shape.len; i++) {\n            PyTuple_SET_ITEM(newdescr->subarray->shape, i,\n                             PyLong_FromLong((long)shape.ptr[i]));\n\n            if (PyTuple_GET_ITEM(newdescr->subarray->shape, i) == NULL) {\n                Py_DECREF(newdescr);\n                goto fail;\n            }\n        }\n\n        npy_free_cache_dim_obj(shape);\n        return newdescr;\n\n    fail:\n        Py_XDECREF(type);\n        npy_free_cache_dim_obj(shape);\n        return NULL;\n    }\n}\n\n/*\n * obj is a list.  Each item is a tuple with\n *\n * (field-name, data-type (either a list or a string), and an optional\n * shape parameter).\n *\n * field-name can be a string or a 2-tuple\n * data-type can now be a list, string, or 2-tuple\n *          (string, metadata dictionary)\n */\nstatic PyArray_Descr *\n_convert_from_array_descr(PyObject *obj, int align)\n{\n    int n = PyList_GET_SIZE(obj);\n    PyObject *nameslist = PyTuple_New(n);\n    if (!nameslist) {\n        return NULL;\n    }\n\n    /* Types with fields need the Python C API for field access */\n    char dtypeflags = NPY_NEEDS_PYAPI;\n    int maxalign = 0;\n    int totalsize = 0;\n    PyObject *fields = PyDict_New();\n    if (!fields) {\n        return NULL;\n    }\n    for (int i = 0; i < n; i++) {\n        PyObject *item = PyList_GET_ITEM(obj, i);\n        if (!PyTuple_Check(item) || (PyTuple_GET_SIZE(item) < 2)) {\n            PyErr_Format(PyExc_TypeError, \n\t\t\t \"Field elements must be 2- or 3-tuples, got '%R'\", \n\t\t\t item);\n            goto fail;\n        }\n        PyObject *name = PyTuple_GET_ITEM(item, 0);\n        PyObject *title;\n        if (PyUnicode_Check(name)) {\n            title = NULL;\n        }\n        else if (PyTuple_Check(name)) {\n            if (PyTuple_GET_SIZE(name) != 2) {\n                PyErr_Format(PyExc_TypeError, \n\t\t\t\t\"If a tuple, the first element of a field tuple must have \"\n\t\t\t\t\"two elements, not %zd\",\n\t\t\t       \tPyTuple_GET_SIZE(name));\n                goto fail;\n            }\n            title = PyTuple_GET_ITEM(name, 0);\n            name = PyTuple_GET_ITEM(name, 1);\n            if (!PyUnicode_Check(name)) {\n                PyErr_SetString(PyExc_TypeError, \"Field name must be a str\");\n                goto fail;\n            }\n        }\n        else {\n            PyErr_SetString(PyExc_TypeError, \n\t\t\t            \"First element of field tuple is \"\n\t\t\t            \"neither a tuple nor str\");\n            goto fail;\n        }\n\n        /* Insert name into nameslist */\n        Py_INCREF(name);\n\n        if (PyUnicode_GetLength(name) == 0) {\n            Py_DECREF(name);\n            if (title == NULL) {\n                name = PyUnicode_FromFormat(\"f%d\", i);\n                if (name == NULL) {\n                    goto fail;\n                }\n            }\n            /* On Py3, allow only non-empty Unicode strings as field names */\n            else if (PyUnicode_Check(title) && PyUnicode_GetLength(title) > 0) {\n                name = title;\n                Py_INCREF(name);\n            }\n            else {\n                PyErr_SetString(PyExc_TypeError, \"Field titles must be non-empty strings\");\n                goto fail;\n            }\n        }\n        PyTuple_SET_ITEM(nameslist, i, name);\n\n        /* Process rest */\n        PyArray_Descr *conv;\n        if (PyTuple_GET_SIZE(item) == 2) {\n            conv = _convert_from_any(PyTuple_GET_ITEM(item, 1), align);\n            if (conv == NULL) {\n                goto fail;\n            }\n        }\n        else if (PyTuple_GET_SIZE(item) == 3) {\n            PyObject *newobj = PyTuple_GetSlice(item, 1, 3);\n            conv = _convert_from_any(newobj, align);\n            Py_DECREF(newobj);\n            if (conv == NULL) {\n                goto fail;\n            }\n        }\n        else {\n            PyErr_Format(PyExc_TypeError,\n                    \"Field elements must be tuples with at most 3 elements, got '%R'\", item);\n            goto fail;\n        }\n        if ((PyDict_GetItemWithError(fields, name) != NULL)\n             || (title\n                 && PyUnicode_Check(title)\n                 && (PyDict_GetItemWithError(fields, title) != NULL))) {\n            PyErr_Format(PyExc_ValueError,\n                    \"field %R occurs more than once\", name);\n            Py_DECREF(conv);\n            goto fail;\n        }\n        else if (PyErr_Occurred()) {\n            /* Dict lookup crashed */\n            Py_DECREF(conv);\n            goto fail;\n        }\n        dtypeflags |= (conv->flags & NPY_FROM_FIELDS);\n        if (align) {\n            int _align = conv->alignment;\n            if (_align > 1) {\n                totalsize = NPY_NEXT_ALIGNED_OFFSET(totalsize, _align);\n            }\n            maxalign = PyArray_MAX(maxalign, _align);\n        }\n        PyObject *tup = PyTuple_New((title == NULL ? 2 : 3));\n        if (tup == NULL) {\n            goto fail;\n        }\n        PyTuple_SET_ITEM(tup, 0, (PyObject *)conv);\n        PyTuple_SET_ITEM(tup, 1, PyLong_FromLong((long) totalsize));\n\n        /*\n         * Title can be \"meta-data\".  Only insert it\n         * into the fields dictionary if it is a string\n         * and if it is not the same as the name.\n         */\n        if (title != NULL) {\n            Py_INCREF(title);\n            PyTuple_SET_ITEM(tup, 2, title);\n            if (PyDict_SetItem(fields, name, tup) < 0) {\n                goto fail;\n            }\n            if (PyUnicode_Check(title)) {\n                PyObject *existing = PyDict_GetItemWithError(fields, title);\n                if (existing == NULL && PyErr_Occurred()) {\n                    goto fail;\n                }\n                if (existing != NULL) {\n                    PyErr_SetString(PyExc_ValueError,\n                            \"title already used as a name or title.\");\n                    Py_DECREF(tup);\n                    goto fail;\n                }\n                if (PyDict_SetItem(fields, title, tup) < 0) {\n                    goto fail;\n                }\n            }\n        }\n        else {\n            if (PyDict_SetItem(fields, name, tup) < 0) {\n                goto fail;\n            }\n        }\n\n        totalsize += conv->elsize;\n        Py_DECREF(tup);\n    }\n\n    if (maxalign > 1) {\n        totalsize = NPY_NEXT_ALIGNED_OFFSET(totalsize, maxalign);\n    }\n\n    PyArray_Descr *new = PyArray_DescrNewFromType(NPY_VOID);\n    if (new == NULL) {\n        Py_XDECREF(fields);\n        Py_XDECREF(nameslist);\n        return NULL;\n    }\n    new->fields = fields;\n    new->names = nameslist;\n    new->elsize = totalsize;\n    new->flags = dtypeflags;\n\n    /* Structured arrays get a sticky aligned bit */\n    if (align) {\n        new->flags |= NPY_ALIGNED_STRUCT;\n        new->alignment = maxalign;\n    }\n    return new;\n\n fail:\n    Py_DECREF(fields);\n    Py_DECREF(nameslist);\n    return NULL;\n\n}\n\n/*\n * a list specifying a data-type can just be\n * a list of formats.  The names for the fields\n * will default to f0, f1, f2, and so forth.\n */\nstatic PyArray_Descr *\n_convert_from_list(PyObject *obj, int align)\n{\n    int n = PyList_GET_SIZE(obj);\n    /*\n     * Ignore any empty string at end which _internal._commastring\n     * can produce\n     */\n    PyObject *last_item = PyList_GET_ITEM(obj, n-1);\n    if (PyUnicode_Check(last_item)) {\n        Py_ssize_t s = PySequence_Size(last_item);\n        if (s < 0) {\n            return NULL;\n        }\n        if (s == 0) {\n            n = n - 1;\n        }\n    }\n    if (n == 0) {\n        PyErr_SetString(PyExc_ValueError, \"Expected at least one field name\");\n        return NULL;\n    }\n    PyObject *nameslist = PyTuple_New(n);\n    if (!nameslist) {\n        return NULL;\n    }\n    PyObject *fields = PyDict_New();\n    if (!fields) {\n        Py_DECREF(nameslist);\n        return NULL;\n    }\n\n    /* Types with fields need the Python C API for field access */\n    char dtypeflags = NPY_NEEDS_PYAPI;\n    int maxalign = 0;\n    int totalsize = 0;\n    for (int i = 0; i < n; i++) {\n        PyArray_Descr *conv = _convert_from_any(\n                PyList_GET_ITEM(obj, i), align);\n        if (conv == NULL) {\n            goto fail;\n        }\n        dtypeflags |= (conv->flags & NPY_FROM_FIELDS);\n        if (align) {\n            int _align = conv->alignment;\n            if (_align > 1) {\n                totalsize = NPY_NEXT_ALIGNED_OFFSET(totalsize, _align);\n            }\n            maxalign = PyArray_MAX(maxalign, _align);\n        }\n        PyObject *size_obj = PyLong_FromLong((long) totalsize);\n        if (!size_obj) {\n            Py_DECREF(conv);\n            goto fail;\n        }\n        PyObject *tup = PyTuple_New(2);\n        if (!tup) {\n            Py_DECREF(size_obj);\n            Py_DECREF(conv);\n            goto fail;\n        }\n        PyTuple_SET_ITEM(tup, 0, (PyObject *)conv);\n        PyTuple_SET_ITEM(tup, 1, size_obj);\n        PyObject *key = PyUnicode_FromFormat(\"f%d\", i);\n        if (!key) {\n            Py_DECREF(tup);\n            goto fail;\n        }\n        /* steals a reference to key */\n        PyTuple_SET_ITEM(nameslist, i, key);\n        int ret = PyDict_SetItem(fields, key, tup);\n        Py_DECREF(tup);\n        if (ret < 0) {\n            goto fail;\n        }\n        totalsize += conv->elsize;\n    }\n    PyArray_Descr *new = PyArray_DescrNewFromType(NPY_VOID);\n    new->fields = fields;\n    new->names = nameslist;\n    new->flags = dtypeflags;\n    if (maxalign > 1) {\n        totalsize = NPY_NEXT_ALIGNED_OFFSET(totalsize, maxalign);\n    }\n    /* Structured arrays get a sticky aligned bit */\n    if (align) {\n        new->flags |= NPY_ALIGNED_STRUCT;\n        new->alignment = maxalign;\n    }\n    new->elsize = totalsize;\n    return new;\n\n fail:\n    Py_DECREF(nameslist);\n    Py_DECREF(fields);\n    return NULL;\n}\n\n\n/*\n * comma-separated string\n * this is the format developed by the numarray records module and implemented\n * by the format parser in that module this is an alternative implementation\n * found in the _internal.py file patterned after that one -- the approach is\n * to try to convert to a list (with tuples if any repeat information is\n * present) and then call the _convert_from_list)\n *\n * TODO: Calling Python from C like this in critical-path code is not\n *       a good idea. This should all be converted to C code.\n */\nstatic PyArray_Descr *\n_convert_from_commastring(PyObject *obj, int align)\n{\n    PyObject *listobj;\n    PyArray_Descr *res;\n    PyObject *_numpy_internal;\n    assert(PyUnicode_Check(obj));\n    _numpy_internal = PyImport_ImportModule(\"numpy.core._internal\");\n    if (_numpy_internal == NULL) {\n        return NULL;\n    }\n    listobj = PyObject_CallMethod(_numpy_internal, \"_commastring\", \"O\", obj);\n    Py_DECREF(_numpy_internal);\n    if (listobj == NULL) {\n        return NULL;\n    }\n    if (!PyList_Check(listobj) || PyList_GET_SIZE(listobj) < 1) {\n        PyErr_SetString(PyExc_RuntimeError,\n                \"_commastring is not returning a list with len >= 1\");\n        Py_DECREF(listobj);\n        return NULL;\n    }\n    if (PyList_GET_SIZE(listobj) == 1) {\n        res = _convert_from_any(PyList_GET_ITEM(listobj, 0), align);\n    }\n    else {\n        res = _convert_from_list(listobj, align);\n    }\n    Py_DECREF(listobj);\n    return res;\n}\n\nstatic int\n_is_tuple_of_integers(PyObject *obj)\n{\n    int i;\n\n    if (!PyTuple_Check(obj)) {\n        return 0;\n    }\n    for (i = 0; i < PyTuple_GET_SIZE(obj); i++) {\n        if (!PyArray_IsIntegerScalar(PyTuple_GET_ITEM(obj, i))) {\n            return 0;\n        }\n    }\n    return 1;\n}\n\n/*\n * helper function for _try_convert_from_inherit_tuple to disallow dtypes of the form\n * (old_dtype, new_dtype) where either of the dtypes contains python\n * objects - these dtypes are not useful and can be a source of segfaults,\n * when an attempt is made to interpret a python object as a different dtype\n * or vice versa\n * an exception is made for dtypes of the form ('O', [('name', 'O')]), which\n * people have been using to add a field to an object array without fields\n */\nstatic int\n_validate_union_object_dtype(PyArray_Descr *new, PyArray_Descr *conv)\n{\n    PyObject *name, *tup;\n    PyArray_Descr *dtype;\n\n    if (!PyDataType_REFCHK(new) && !PyDataType_REFCHK(conv)) {\n        return 0;\n    }\n    if (PyDataType_HASFIELDS(new) || new->kind != 'O') {\n        goto fail;\n    }\n    if (!PyDataType_HASFIELDS(conv) || PyTuple_GET_SIZE(conv->names) != 1) {\n        goto fail;\n    }\n    name = PyTuple_GET_ITEM(conv->names, 0);\n    if (name == NULL) {\n        return -1;\n    }\n    tup = PyDict_GetItemWithError(conv->fields, name);\n    if (tup == NULL) {\n        if (!PyErr_Occurred()) {\n            /* fields was missing the name it claimed to contain */\n            PyErr_BadInternalCall();\n        }\n        return -1;\n    }\n    dtype = (PyArray_Descr *)PyTuple_GET_ITEM(tup, 0);\n    if (dtype == NULL) {\n        return -1;\n    }\n    if (dtype->kind != 'O') {\n        goto fail;\n    }\n    return 0;\n\nfail:\n    PyErr_SetString(PyExc_ValueError,\n            \"dtypes of the form (old_dtype, new_dtype) containing the object \"\n            \"dtype are not supported\");\n    return -1;\n}\n\n/*\n * A tuple type would be either (generic typeobject, typesize)\n * or (fixed-length data-type, shape)\n *\n * or (inheriting data-type, new-data-type)\n * The new data-type must have the same itemsize as the inheriting data-type\n * unless the latter is 0\n *\n * Thus (int32, {'real':(int16,0),'imag',(int16,2)})\n *\n * is one way to specify a descriptor that will give\n * a['real'] and a['imag'] to an int32 array.\n *\n * leave type reference alone\n *\n * Returns `Py_NotImplemented` if the second tuple item is not\n * appropriate.\n */\nstatic PyArray_Descr *\n_try_convert_from_inherit_tuple(PyArray_Descr *type, PyObject *newobj)\n{\n    if (PyArray_IsScalar(newobj, Integer) || _is_tuple_of_integers(newobj)) {\n        /* It's a subarray or flexible type instead */\n        Py_INCREF(Py_NotImplemented);\n        return (PyArray_Descr *)Py_NotImplemented;\n    }\n    PyArray_Descr *conv = _convert_from_any(newobj, 0);\n    if (conv == NULL) {\n        /* Let someone else try to convert this */\n        PyErr_Clear();\n        Py_INCREF(Py_NotImplemented);\n        return (PyArray_Descr *)Py_NotImplemented;\n    }\n    PyArray_Descr *new = PyArray_DescrNew(type);\n    if (new == NULL) {\n        goto fail;\n    }\n    if (PyDataType_ISUNSIZED(new)) {\n        new->elsize = conv->elsize;\n    }\n    else if (new->elsize != conv->elsize) {\n        PyErr_SetString(PyExc_ValueError,\n                \"mismatch in size of old and new data-descriptor\");\n        Py_DECREF(new);\n        goto fail;\n    }\n    else if (_validate_union_object_dtype(new, conv) < 0) {\n        Py_DECREF(new);\n        goto fail;\n    }\n\n    if (PyDataType_HASFIELDS(conv)) {\n        Py_XDECREF(new->fields);\n        new->fields = conv->fields;\n        Py_XINCREF(new->fields);\n\n        Py_XDECREF(new->names);\n        new->names = conv->names;\n        Py_XINCREF(new->names);\n    }\n    if (conv->metadata != NULL) {\n        Py_XDECREF(new->metadata);\n        new->metadata = conv->metadata;\n        Py_XINCREF(new->metadata);\n    }\n    /*\n     * Certain flags must be inherited from the fields.  This is needed\n     * only for void dtypes (or subclasses of it such as a record dtype).\n     * For other dtypes, the field part will only be used for direct field\n     * access and thus flag inheritance should not be necessary.\n     * (We only allow object fields if the dtype is object as well.)\n     * This ensures copying over of the NPY_FROM_FIELDS \"inherited\" flags.\n     */\n    if (new->type_num == NPY_VOID) {\n        new->flags = conv->flags;\n    }\n    Py_DECREF(conv);\n    return new;\n\n fail:\n    Py_DECREF(conv);\n    return NULL;\n}\n\n/*\n * Validates that any field of the structured array 'dtype' which has\n * the NPY_ITEM_HASOBJECT flag set does not overlap with another field.\n *\n * This algorithm is worst case O(n^2). It could be done with a sort\n * and sweep algorithm, but the structured dtype representation is\n * rather ugly right now, so writing something better can wait until\n * that representation is made sane.\n *\n * Returns 0 on success, -1 if an exception is raised.\n */\nstatic int\n_validate_object_field_overlap(PyArray_Descr *dtype)\n{\n    PyObject *names, *fields, *key, *tup, *title;\n    Py_ssize_t i, j, names_size;\n    PyArray_Descr *fld_dtype, *fld2_dtype;\n    int fld_offset, fld2_offset;\n\n    /* Get some properties from the dtype */\n    names = dtype->names;\n    names_size = PyTuple_GET_SIZE(names);\n    fields = dtype->fields;\n\n    for (i = 0; i < names_size; ++i) {\n        key = PyTuple_GET_ITEM(names, i);\n        if (key == NULL) {\n            return -1;\n        }\n        tup = PyDict_GetItemWithError(fields, key);\n        if (tup == NULL) {\n            if (!PyErr_Occurred()) {\n                /* fields was missing the name it claimed to contain */\n                PyErr_BadInternalCall();\n            }\n            return -1;\n        }\n        if (!PyArg_ParseTuple(tup, \"Oi|O\", &fld_dtype, &fld_offset, &title)) {\n            return -1;\n        }\n\n        /* If this field has objects, check for overlaps */\n        if (PyDataType_REFCHK(fld_dtype)) {\n            for (j = 0; j < names_size; ++j) {\n                if (i != j) {\n                    key = PyTuple_GET_ITEM(names, j);\n                    if (key == NULL) {\n                        return -1;\n                    }\n                    tup = PyDict_GetItemWithError(fields, key);\n                    if (tup == NULL) {\n                        if (!PyErr_Occurred()) {\n                            /* fields was missing the name it claimed to contain */\n                            PyErr_BadInternalCall();\n                        }\n                        return -1;\n                    }\n                    if (!PyArg_ParseTuple(tup, \"Oi|O\", &fld2_dtype,\n                                                &fld2_offset, &title)) {\n                        return -1;\n                    }\n                    /* Raise an exception if it overlaps */\n                    if (fld_offset < fld2_offset + fld2_dtype->elsize &&\n                                fld2_offset < fld_offset + fld_dtype->elsize) {\n                        PyErr_SetString(PyExc_TypeError,\n                                \"Cannot create a NumPy dtype with overlapping \"\n                                \"object fields\");\n                        return -1;\n                    }\n                }\n            }\n        }\n    }\n\n    /* It passed all the overlap tests */\n    return 0;\n}\n\n/*\n * a dictionary specifying a data-type\n * must have at least two and up to four\n * keys These must all be sequences of the same length.\n *\n * can also have an additional key called \"metadata\" which can be any dictionary\n *\n * \"names\" --- field names\n * \"formats\" --- the data-type descriptors for the field.\n *\n * Optional:\n *\n * \"offsets\" --- integers indicating the offset into the\n * record of the start of the field.\n * if not given, then \"consecutive offsets\"\n * will be assumed and placed in the dictionary.\n *\n * \"titles\" --- Allows the use of an additional key\n * for the fields dictionary.(if these are strings\n * or unicode objects) or\n * this can also be meta-data to\n * be passed around with the field description.\n *\n * Attribute-lookup-based field names merely has to query the fields\n * dictionary of the data-descriptor.  Any result present can be used\n * to return the correct field.\n *\n * So, the notion of what is a name and what is a title is really quite\n * arbitrary.\n *\n * What does distinguish a title, however, is that if it is not None,\n * it will be placed at the end of the tuple inserted into the\n * fields dictionary.and can therefore be used to carry meta-data around.\n *\n * If the dictionary does not have \"names\" and \"formats\" entries,\n * then it will be checked for conformity and used directly.\n */\nstatic PyArray_Descr *\n_convert_from_field_dict(PyObject *obj, int align)\n{\n    PyObject *_numpy_internal;\n    PyArray_Descr *res;\n\n    _numpy_internal = PyImport_ImportModule(\"numpy.core._internal\");\n    if (_numpy_internal == NULL) {\n        return NULL;\n    }\n    res = (PyArray_Descr *)PyObject_CallMethod(_numpy_internal,\n            \"_usefields\", \"Oi\", obj, align);\n    Py_DECREF(_numpy_internal);\n    return res;\n}\n\n/*\n * Creates a struct dtype object from a Python dictionary.\n */\nstatic PyArray_Descr *\n_convert_from_dict(PyObject *obj, int align)\n{\n    PyObject *fields = PyDict_New();\n    if (fields == NULL) {\n        return (PyArray_Descr *)PyErr_NoMemory();\n    }\n    /*\n     * Use PyMapping_GetItemString to support dictproxy objects as well.\n     */\n    PyObject *names = PyMapping_GetItemString(obj, \"names\");\n    if (names == NULL) {\n        Py_DECREF(fields);\n        /* XXX should check this is a KeyError */\n        PyErr_Clear();\n        return _convert_from_field_dict(obj, align);\n    }\n    PyObject *descrs = PyMapping_GetItemString(obj, \"formats\");\n    if (descrs == NULL) {\n        Py_DECREF(fields);\n        /* XXX should check this is a KeyError */\n        PyErr_Clear();\n        Py_DECREF(names);\n        return _convert_from_field_dict(obj, align);\n    }\n    int n = PyObject_Length(names);\n    PyObject *offsets = PyMapping_GetItemString(obj, \"offsets\");\n    if (!offsets) {\n        PyErr_Clear();\n    }\n    PyObject *titles = PyMapping_GetItemString(obj, \"titles\");\n    if (!titles) {\n        PyErr_Clear();\n    }\n\n    if ((n > PyObject_Length(descrs))\n        || (offsets && (n > PyObject_Length(offsets)))\n        || (titles && (n > PyObject_Length(titles)))) {\n        PyErr_SetString(PyExc_ValueError,\n                \"'names', 'formats', 'offsets', and 'titles' dict \"\n                \"entries must have the same length\");\n        goto fail;\n    }\n\n    /*\n     * If a property 'aligned' is in the dict, it overrides the align flag\n     * to be True if it not already true.\n     */\n    PyObject *tmp = PyMapping_GetItemString(obj, \"aligned\");\n    if (tmp == NULL) {\n        PyErr_Clear();\n    } else {\n        if (tmp == Py_True) {\n            align = 1;\n        }\n        else if (tmp != Py_False) {\n            Py_DECREF(tmp);\n            PyErr_SetString(PyExc_ValueError,\n                    \"NumPy dtype descriptor includes 'aligned' entry, \"\n                    \"but its value is neither True nor False\");\n            goto fail;\n        }\n        Py_DECREF(tmp);\n    }\n\n    /* Types with fields need the Python C API for field access */\n    char dtypeflags = NPY_NEEDS_PYAPI;\n    int totalsize = 0;\n    int maxalign = 0;\n    int has_out_of_order_fields = 0;\n    for (int i = 0; i < n; i++) {\n        /* Build item to insert (descr, offset, [title])*/\n        int len = 2;\n        PyObject *title = NULL;\n        PyObject *ind = PyLong_FromLong(i);\n        if (titles) {\n            title=PyObject_GetItem(titles, ind);\n            if (title && title != Py_None) {\n                len = 3;\n            }\n            else {\n                Py_XDECREF(title);\n            }\n            PyErr_Clear();\n        }\n        PyObject *tup = PyTuple_New(len);\n        PyObject *descr = PyObject_GetItem(descrs, ind);\n        if (!descr) {\n            Py_DECREF(tup);\n            Py_DECREF(ind);\n            goto fail;\n        }\n        PyArray_Descr *newdescr = _convert_from_any(descr, align);\n        Py_DECREF(descr);\n        if (newdescr == NULL) {\n            Py_DECREF(tup);\n            Py_DECREF(ind);\n            goto fail;\n        }\n        PyTuple_SET_ITEM(tup, 0, (PyObject *)newdescr);\n        int _align = 1;\n        if (align) {\n            _align = newdescr->alignment;\n            maxalign = PyArray_MAX(maxalign,_align);\n        }\n        if (offsets) {\n            PyObject *off = PyObject_GetItem(offsets, ind);\n            if (!off) {\n                Py_DECREF(tup);\n                Py_DECREF(ind);\n                goto fail;\n            }\n            long offset = PyArray_PyIntAsInt(off);\n            if (error_converting(offset)) {\n                Py_DECREF(off);\n                Py_DECREF(tup);\n                Py_DECREF(ind);\n                goto fail;\n            }\n            Py_DECREF(off);\n            if (offset < 0) {\n                PyErr_Format(PyExc_ValueError, \"offset %ld cannot be negative\",\n                             offset);\n                Py_DECREF(tup);\n                Py_DECREF(ind);\n                goto fail;\n            }\n\n            PyTuple_SET_ITEM(tup, 1, PyLong_FromLong(offset));\n            /* Flag whether the fields are specified out of order */\n            if (offset < totalsize) {\n                has_out_of_order_fields = 1;\n            }\n            /* If align=True, enforce field alignment */\n            if (align && offset % newdescr->alignment != 0) {\n                PyErr_Format(PyExc_ValueError,\n                        \"offset %ld for NumPy dtype with fields is \"\n                        \"not divisible by the field alignment %d \"\n                        \"with align=True\",\n                        offset, newdescr->alignment);\n                Py_DECREF(ind);\n                Py_DECREF(tup);\n                goto fail;\n            }\n            else if (offset + newdescr->elsize > totalsize) {\n                totalsize = offset + newdescr->elsize;\n            }\n        }\n        else {\n            if (align && _align > 1) {\n                totalsize = NPY_NEXT_ALIGNED_OFFSET(totalsize, _align);\n            }\n            PyTuple_SET_ITEM(tup, 1, PyLong_FromLong(totalsize));\n            totalsize += newdescr->elsize;\n        }\n        if (len == 3) {\n            PyTuple_SET_ITEM(tup, 2, title);\n        }\n        PyObject *name = PyObject_GetItem(names, ind);\n        Py_DECREF(ind);\n        if (!name) {\n            Py_DECREF(tup);\n            goto fail;\n        }\n        if (!PyUnicode_Check(name)) {\n            PyErr_SetString(PyExc_ValueError,\n                    \"field names must be strings\");\n            Py_DECREF(tup);\n            goto fail;\n        }\n\n        /* Insert into dictionary */\n        if (PyDict_GetItemWithError(fields, name) != NULL) {\n            PyErr_SetString(PyExc_ValueError,\n                    \"name already used as a name or title\");\n            Py_DECREF(tup);\n            goto fail;\n        }\n        else if (PyErr_Occurred()) {\n            /* MemoryError during dict lookup */\n            Py_DECREF(tup);\n            goto fail;\n        }\n        int ret = PyDict_SetItem(fields, name, tup);\n        Py_DECREF(name);\n        if (ret < 0) {\n            Py_DECREF(tup);\n            goto fail;\n        }\n        if (len == 3) {\n            if (PyUnicode_Check(title)) {\n                if (PyDict_GetItemWithError(fields, title) != NULL) {\n                    PyErr_SetString(PyExc_ValueError,\n                            \"title already used as a name or title.\");\n                    Py_DECREF(tup);\n                    goto fail;\n                }\n                else if (PyErr_Occurred()) {\n                    /* MemoryError during dict lookup */\n                    goto fail;\n                }\n                if (PyDict_SetItem(fields, title, tup) < 0) {\n                    Py_DECREF(tup);\n                    goto fail;\n                }\n            }\n        }\n        Py_DECREF(tup);\n        dtypeflags |= (newdescr->flags & NPY_FROM_FIELDS);\n    }\n\n    PyArray_Descr *new = PyArray_DescrNewFromType(NPY_VOID);\n    if (new == NULL) {\n        goto fail;\n    }\n    if (maxalign > 1) {\n        totalsize = NPY_NEXT_ALIGNED_OFFSET(totalsize, maxalign);\n    }\n    if (align) {\n        new->alignment = maxalign;\n    }\n    new->elsize = totalsize;\n    if (!PyTuple_Check(names)) {\n        Py_SETREF(names, PySequence_Tuple(names));\n        if (names == NULL) {\n            Py_DECREF(new);\n            goto fail;\n        }\n    }\n    new->names = names;\n    new->fields = fields;\n    new->flags = dtypeflags;\n    /* new takes responsibility for DECREFing names, fields */\n    names = NULL;\n    fields = NULL;\n\n    /*\n     * If the fields weren't in order, and there was an OBJECT type,\n     * need to verify that no OBJECT types overlap with something else.\n     */\n    if (has_out_of_order_fields && PyDataType_REFCHK(new)) {\n        if (_validate_object_field_overlap(new) < 0) {\n            Py_DECREF(new);\n            goto fail;\n        }\n    }\n\n    /* Structured arrays get a sticky aligned bit */\n    if (align) {\n        new->flags |= NPY_ALIGNED_STRUCT;\n    }\n\n    /* Override the itemsize if provided */\n    tmp = PyMapping_GetItemString(obj, \"itemsize\");\n    if (tmp == NULL) {\n        PyErr_Clear();\n    } else {\n        int itemsize = (int)PyArray_PyIntAsInt(tmp);\n        Py_DECREF(tmp);\n        if (error_converting(itemsize)) {\n            Py_DECREF(new);\n            goto fail;\n        }\n        /* Make sure the itemsize isn't made too small */\n        if (itemsize < new->elsize) {\n            PyErr_Format(PyExc_ValueError,\n                    \"NumPy dtype descriptor requires %d bytes, \"\n                    \"cannot override to smaller itemsize of %d\",\n                    new->elsize, itemsize);\n            Py_DECREF(new);\n            goto fail;\n        }\n        /* If align is set, make sure the alignment divides into the size */\n        if (align && itemsize % new->alignment != 0) {\n            PyErr_Format(PyExc_ValueError,\n                    \"NumPy dtype descriptor requires alignment of %d bytes, \"\n                    \"which is not divisible into the specified itemsize %d\",\n                    new->alignment, itemsize);\n            Py_DECREF(new);\n            goto fail;\n        }\n        /* Set the itemsize */\n        new->elsize = itemsize;\n    }\n\n    /* Add the metadata if provided */\n    PyObject *metadata = PyMapping_GetItemString(obj, \"metadata\");\n\n    if (metadata == NULL) {\n        PyErr_Clear();\n    }\n    else if (new->metadata == NULL) {\n        new->metadata = metadata;\n    }\n    else {\n        int ret = PyDict_Merge(new->metadata, metadata, 0);\n        Py_DECREF(metadata);\n        if (ret < 0) {\n            Py_DECREF(new);\n            goto fail;\n        }\n    }\n\n    Py_XDECREF(fields);\n    Py_XDECREF(names);\n    Py_XDECREF(descrs);\n    Py_XDECREF(offsets);\n    Py_XDECREF(titles);\n    return new;\n\n fail:\n    Py_XDECREF(fields);\n    Py_XDECREF(names);\n    Py_XDECREF(descrs);\n    Py_XDECREF(offsets);\n    Py_XDECREF(titles);\n    return NULL;\n}\n\n\n/*NUMPY_API*/\nNPY_NO_EXPORT PyArray_Descr *\nPyArray_DescrNewFromType(int type_num)\n{\n    PyArray_Descr *old;\n    PyArray_Descr *new;\n\n    old = PyArray_DescrFromType(type_num);\n    new = PyArray_DescrNew(old);\n    Py_DECREF(old);\n    return new;\n}\n\n/*NUMPY_API\n * Get typenum from an object -- None goes to NULL\n */\nNPY_NO_EXPORT int\nPyArray_DescrConverter2(PyObject *obj, PyArray_Descr **at)\n{\n    if (obj == Py_None) {\n        *at = NULL;\n        return NPY_SUCCEED;\n    }\n    else {\n        return PyArray_DescrConverter(obj, at);\n    }\n}\n\n/**\n * Get a dtype instance from a python type\n */\nstatic PyArray_Descr *\n_convert_from_type(PyObject *obj) {\n    PyTypeObject *typ = (PyTypeObject*)obj;\n\n    if (PyType_IsSubtype(typ, &PyGenericArrType_Type)) {\n        return PyArray_DescrFromTypeObject(obj);\n    }\n    else if (typ == &PyLong_Type) {\n        return PyArray_DescrFromType(NPY_LONG);\n    }\n    else if (typ == &PyFloat_Type) {\n        return PyArray_DescrFromType(NPY_DOUBLE);\n    }\n    else if (typ == &PyComplex_Type) {\n        return PyArray_DescrFromType(NPY_CDOUBLE);\n    }\n    else if (typ == &PyBool_Type) {\n        return PyArray_DescrFromType(NPY_BOOL);\n    }\n    else if (typ == &PyBytes_Type) {\n        /*\n         * TODO: This should be deprecated, and have special handling for\n         *       dtype=bytes/\"S\" in coercion: It should not rely on \"S0\".\n         */\n        return PyArray_DescrFromType(NPY_STRING);\n    }\n    else if (typ == &PyUnicode_Type) {\n        /*\n         * TODO: This should be deprecated, and have special handling for\n         *       dtype=str/\"U\" in coercion: It should not rely on \"U0\".\n         */\n        return PyArray_DescrFromType(NPY_UNICODE);\n    }\n    else if (typ == &PyMemoryView_Type) {\n        return PyArray_DescrFromType(NPY_VOID);\n    }\n    else if (typ == &PyBaseObject_Type) {\n        return PyArray_DescrFromType(NPY_OBJECT);\n    }\n    else {\n        PyArray_Descr *ret = _try_convert_from_dtype_attr(obj);\n        if ((PyObject *)ret != Py_NotImplemented) {\n            return ret;\n        }\n        Py_DECREF(ret);\n\n        /*\n         * Note: this comes after _try_convert_from_dtype_attr because the ctypes\n         * type might override the dtype if numpy does not otherwise\n         * support it.\n         */\n        ret = _try_convert_from_ctypes_type(typ);\n        if ((PyObject *)ret != Py_NotImplemented) {\n            return ret;\n        }\n        Py_DECREF(ret);\n\n        /*\n         * All other classes are treated as object. This can be convenient\n         * to convey an intention of using it for a specific python type\n         * and possibly allow converting to a new type-specific dtype in the future. It may make sense to\n         * only allow this only within `dtype=...` keyword argument context\n         * in the future.\n         */\n        return PyArray_DescrFromType(NPY_OBJECT);\n    }\n}\n\n\nstatic PyArray_Descr *\n_convert_from_str(PyObject *obj, int align);\n\nstatic PyArray_Descr *\n_convert_from_any(PyObject *obj, int align)\n{\n    /* default */\n    if (obj == Py_None) {\n        return PyArray_DescrFromType(NPY_DEFAULT_TYPE);\n    }\n    else if (PyArray_DescrCheck(obj)) {\n        PyArray_Descr *ret = (PyArray_Descr *)obj;\n        Py_INCREF(ret);\n        return ret;\n    }\n    else if (PyType_Check(obj)) {\n        return _convert_from_type(obj);\n    }\n    /* or a typecode string */\n    else if (PyBytes_Check(obj)) {\n        /* Allow bytes format strings: convert to unicode */\n        PyObject *obj2 = PyUnicode_FromEncodedObject(obj, NULL, NULL);\n        if (obj2 == NULL) {\n            /* Convert the exception into a TypeError */\n            if (PyErr_ExceptionMatches(PyExc_UnicodeDecodeError)) {\n                PyErr_SetString(PyExc_TypeError,\n                        \"data type not understood\");\n            }\n            return NULL;\n        }\n        PyArray_Descr *ret = _convert_from_str(obj2, align);\n        Py_DECREF(obj2);\n        return ret;\n    }\n    else if (PyUnicode_Check(obj)) {\n        return _convert_from_str(obj, align);\n    }\n    else if (PyTuple_Check(obj)) {\n        /* or a tuple */\n        if (Py_EnterRecursiveCall(\n                \" while trying to convert the given data type from\"\n                \" a tuple object\" ) != 0) {\n            return NULL;\n        }\n        PyArray_Descr *ret = _convert_from_tuple(obj, align);\n        Py_LeaveRecursiveCall();\n        return ret;\n    }\n    else if (PyList_Check(obj)) {\n        /* or a list */\n        if (Py_EnterRecursiveCall(\n                \" while trying to convert the given data type from\"\n                \" a list object\" ) != 0) {\n            return NULL;\n        }\n        PyArray_Descr *ret = _convert_from_array_descr(obj, align);\n        Py_LeaveRecursiveCall();\n        return ret;\n    }\n    else if (PyDict_Check(obj) || PyDictProxy_Check(obj)) {\n        /* or a dictionary */\n        if (Py_EnterRecursiveCall(\n                \" while trying to convert the given data type from\"\n                \" a dict object\" ) != 0) {\n            return NULL;\n        }\n        PyArray_Descr *ret = _convert_from_dict(obj, align);\n        Py_LeaveRecursiveCall();\n        return ret;\n    }\n    else if (PyArray_Check(obj)) {\n        PyErr_SetString(PyExc_TypeError, \"Cannot construct a dtype from an array\");\n        return NULL;\n    }\n    else {\n        PyArray_Descr *ret = _try_convert_from_dtype_attr(obj);\n        if ((PyObject *)ret != Py_NotImplemented) {\n            return ret;\n        }\n        Py_DECREF(ret);\n        /*\n         * Note: this comes after _try_convert_from_dtype_attr because the ctypes\n         * type might override the dtype if numpy does not otherwise\n         * support it.\n         */\n        ret = _try_convert_from_ctypes_type(Py_TYPE(obj));\n        if ((PyObject *)ret != Py_NotImplemented) {\n            return ret;\n        }\n        Py_DECREF(ret);\n        PyErr_Format(PyExc_TypeError, \"Cannot interpret '%R' as a data type\", obj);\n        return NULL;\n    }\n}\n\n\n/*NUMPY_API\n * Get typenum from an object -- None goes to NPY_DEFAULT_TYPE\n * This function takes a Python object representing a type and converts it\n * to a the correct PyArray_Descr * structure to describe the type.\n *\n * Many objects can be used to represent a data-type which in NumPy is\n * quite a flexible concept.\n *\n * This is the central code that converts Python objects to\n * Type-descriptor objects that are used throughout numpy.\n *\n * Returns a new reference in *at, but the returned should not be\n * modified as it may be one of the canonical immutable objects or\n * a reference to the input obj.\n */\nNPY_NO_EXPORT int\nPyArray_DescrConverter(PyObject *obj, PyArray_Descr **at)\n{\n    *at = _convert_from_any(obj, 0);\n    return (*at) ? NPY_SUCCEED : NPY_FAIL;\n}\n\n/** Convert a bytestring specification into a dtype */\nstatic PyArray_Descr *\n_convert_from_str(PyObject *obj, int align)\n{\n    /* Check for a string typecode. */\n    Py_ssize_t len = 0;\n    char const *type = PyUnicode_AsUTF8AndSize(obj, &len);\n    if (type == NULL) {\n        return NULL;\n    }\n\n    /* Empty string is invalid */\n    if (len == 0) {\n        goto fail;\n    }\n\n    /* check for commas present or first (or second) element a digit */\n    if (_check_for_commastring(type, len)) {\n        return _convert_from_commastring(obj, align);\n    }\n\n    /* Process the endian character. '|' is replaced by '='*/\n    char endian = '=';\n    switch (type[0]) {\n        case '>':\n        case '<':\n        case '=':\n            endian = type[0];\n            ++type;\n            --len;\n            break;\n\n        case '|':\n            endian = '=';\n            ++type;\n            --len;\n            break;\n    }\n\n    /* Just an endian character is invalid */\n    if (len == 0) {\n        goto fail;\n    }\n\n    /* Check for datetime format */\n    if (is_datetime_typestr(type, len)) {\n        PyArray_Descr *ret = parse_dtype_from_datetime_typestr(type, len);\n        if (ret == NULL) {\n            return NULL;\n        }\n        /* ret has byte order '=' at this point */\n        if (!PyArray_ISNBO(endian)) {\n            ret->byteorder = endian;\n        }\n        return ret;\n    }\n\n    int check_num = NPY_NOTYPE + 10;\n    int elsize = 0;\n    /* A typecode like 'd' */\n    if (len == 1) {\n        /* Python byte string characters are unsigned */\n        check_num = (unsigned char) type[0];\n    }\n    /* A kind + size like 'f8' */\n    else {\n        char *typeend = NULL;\n        int kind;\n\n        /* Parse the integer, make sure it's the rest of the string */\n        elsize = (int)strtol(type + 1, &typeend, 10);\n        if (typeend - type == len) {\n\n            kind = type[0];\n            switch (kind) {\n                case NPY_STRINGLTR:\n                case NPY_STRINGLTR2:\n                    check_num = NPY_STRING;\n                    break;\n\n                /*\n                 * When specifying length of UNICODE\n                 * the number of characters is given to match\n                 * the STRING interface.  Each character can be\n                 * more than one byte and itemsize must be\n                 * the number of bytes.\n                 */\n                case NPY_UNICODELTR:\n                    check_num = NPY_UNICODE;\n                    elsize <<= 2;\n                    break;\n\n                case NPY_VOIDLTR:\n                    check_num = NPY_VOID;\n                    break;\n\n                default:\n                    if (elsize == 0) {\n                        check_num = NPY_NOTYPE+10;\n                    }\n                    /* Support for generic processing c8, i4, f8, etc...*/\n                    else {\n                        check_num = PyArray_TypestrConvert(elsize, kind);\n                        if (check_num == NPY_NOTYPE) {\n                            check_num += 10;\n                        }\n                        elsize = 0;\n                    }\n            }\n        }\n    }\n\n    if (PyErr_Occurred()) {\n        goto fail;\n    }\n\n    PyArray_Descr *ret;\n    if ((check_num == NPY_NOTYPE + 10) ||\n            (ret = PyArray_DescrFromType(check_num)) == NULL) {\n        PyErr_Clear();\n        /* Now check to see if the object is registered in typeDict */\n        if (typeDict == NULL) {\n            goto fail;\n        }\n        PyObject *item = PyDict_GetItemWithError(typeDict, obj);\n        if (item == NULL) {\n            if (PyErr_Occurred()) {\n                return NULL;\n            }\n            goto fail;\n        }\n\n        /* Check for a deprecated Numeric-style typecode */\n        /* `Uint` has deliberately weird uppercasing */\n        char *dep_tps[] = {\"Bytes\", \"Datetime64\", \"Str\", \"Uint\"};\n        int ndep_tps = sizeof(dep_tps) / sizeof(dep_tps[0]);\n        for (int i = 0; i < ndep_tps; ++i) {\n            char *dep_tp = dep_tps[i];\n\n            if (strncmp(type, dep_tp, strlen(dep_tp)) == 0) {\n                /* Deprecated 2020-06-09, NumPy 1.20 */\n                if (DEPRECATE(\"Numeric-style type codes are \"\n                              \"deprecated and will result in \"\n                              \"an error in the future.\") < 0) {\n                    goto fail;\n                }\n            }\n        }\n        /*\n         * Probably only ever dispatches to `_convert_from_type`, but who\n         * knows what users are injecting into `np.typeDict`.\n         */\n        return _convert_from_any(item, align);\n    }\n\n    if (PyDataType_ISUNSIZED(ret) && ret->elsize != elsize) {\n        PyArray_DESCR_REPLACE(ret);\n        if (ret == NULL) {\n            return NULL;\n        }\n        ret->elsize = elsize;\n    }\n    if (endian != '=' && PyArray_ISNBO(endian)) {\n        endian = '=';\n    }\n    if (endian != '=' && ret->byteorder != '|' && ret->byteorder != endian) {\n        PyArray_DESCR_REPLACE(ret);\n        if (ret == NULL) {\n            return NULL;\n        }\n        ret->byteorder = endian;\n    }\n    return ret;\n\nfail:\n    PyErr_Format(PyExc_TypeError, \"data type %R not understood\", obj);\n    return NULL;\n}\n\n/** Array Descr Objects for dynamic types **/\n\n/*\n * There are some statically-defined PyArray_Descr objects corresponding\n * to the basic built-in types.\n * These can and should be DECREF'd and INCREF'd as appropriate, anyway.\n * If a mistake is made in reference counting, deallocation on these\n * builtins will be attempted leading to problems.\n *\n * This lets us deal with all PyArray_Descr objects using reference\n * counting (regardless of whether they are statically or dynamically\n * allocated).\n */\n\n/*NUMPY_API\n * base cannot be NULL\n */\nNPY_NO_EXPORT PyArray_Descr *\nPyArray_DescrNew(PyArray_Descr *base)\n{\n    PyArray_Descr *newdescr = PyObject_New(PyArray_Descr, Py_TYPE(base));\n\n    if (newdescr == NULL) {\n        return NULL;\n    }\n    /* Don't copy PyObject_HEAD part */\n    memcpy((char *)newdescr + sizeof(PyObject),\n           (char *)base + sizeof(PyObject),\n           sizeof(PyArray_Descr) - sizeof(PyObject));\n\n    /*\n     * The c_metadata has a by-value ownership model, need to clone it\n     * (basically a deep copy, but the auxdata clone function has some\n     * flexibility still) so the new PyArray_Descr object owns\n     * a copy of the data. Having both 'base' and 'newdescr' point to\n     * the same auxdata pointer would cause a double-free of memory.\n     */\n    if (base->c_metadata != NULL) {\n        newdescr->c_metadata = NPY_AUXDATA_CLONE(base->c_metadata);\n        if (newdescr->c_metadata == NULL) {\n            PyErr_NoMemory();\n            /* TODO: This seems wrong, as the old fields get decref'd? */\n            Py_DECREF(newdescr);\n            return NULL;\n        }\n    }\n\n    if (newdescr->fields == Py_None) {\n        newdescr->fields = NULL;\n    }\n    Py_XINCREF(newdescr->fields);\n    Py_XINCREF(newdescr->names);\n    if (newdescr->subarray) {\n        newdescr->subarray = PyArray_malloc(sizeof(PyArray_ArrayDescr));\n        if (newdescr->subarray == NULL) {\n            Py_DECREF(newdescr);\n            return (PyArray_Descr *)PyErr_NoMemory();\n        }\n        memcpy(newdescr->subarray, base->subarray, sizeof(PyArray_ArrayDescr));\n        Py_INCREF(newdescr->subarray->shape);\n        Py_INCREF(newdescr->subarray->base);\n    }\n    Py_XINCREF(newdescr->typeobj);\n    Py_XINCREF(newdescr->metadata);\n    newdescr->hash = -1;\n\n    return newdescr;\n}\n\n/*\n * should never be called for builtin-types unless\n * there is a reference-count problem\n */\nstatic void\narraydescr_dealloc(PyArray_Descr *self)\n{\n    if (self->fields == Py_None) {\n        fprintf(stderr, \"*** Reference count error detected: \"\n                \"an attempt was made to deallocate the dtype %d (%c) ***\\n\",\n                self->type_num, self->type);\n        assert(0);\n        Py_INCREF(self);\n        Py_INCREF(self);\n        return;\n    }\n    Py_XDECREF(self->typeobj);\n    Py_XDECREF(self->names);\n    Py_XDECREF(self->fields);\n    if (self->subarray) {\n        Py_XDECREF(self->subarray->shape);\n        Py_DECREF(self->subarray->base);\n        PyArray_free(self->subarray);\n    }\n    Py_XDECREF(self->metadata);\n    NPY_AUXDATA_FREE(self->c_metadata);\n    self->c_metadata = NULL;\n    Py_TYPE(self)->tp_free((PyObject *)self);\n}\n\n/*\n * we need to be careful about setting attributes because these\n * objects are pointed to by arrays that depend on them for interpreting\n * data.  Currently no attributes of data-type objects can be set\n * directly except names.\n */\nstatic PyMemberDef arraydescr_members[] = {\n    {\"type\",\n        T_OBJECT, offsetof(PyArray_Descr, typeobj), READONLY, NULL},\n    {\"kind\",\n        T_CHAR, offsetof(PyArray_Descr, kind), READONLY, NULL},\n    {\"char\",\n        T_CHAR, offsetof(PyArray_Descr, type), READONLY, NULL},\n    {\"num\",\n        T_INT, offsetof(PyArray_Descr, type_num), READONLY, NULL},\n    {\"byteorder\",\n        T_CHAR, offsetof(PyArray_Descr, byteorder), READONLY, NULL},\n    {\"itemsize\",\n        T_INT, offsetof(PyArray_Descr, elsize), READONLY, NULL},\n    {\"alignment\",\n        T_INT, offsetof(PyArray_Descr, alignment), READONLY, NULL},\n    {\"flags\",\n        T_BYTE, offsetof(PyArray_Descr, flags), READONLY, NULL},\n    {NULL, 0, 0, 0, NULL},\n};\n\nstatic PyObject *\narraydescr_subdescr_get(PyArray_Descr *self)\n{\n    if (!PyDataType_HASSUBARRAY(self)) {\n        Py_RETURN_NONE;\n    }\n    return Py_BuildValue(\"OO\",\n            (PyObject *)self->subarray->base, self->subarray->shape);\n}\n\nNPY_NO_EXPORT PyObject *\narraydescr_protocol_typestr_get(PyArray_Descr *self)\n{\n    char basic_ = self->kind;\n    char endian = self->byteorder;\n    int size = self->elsize;\n    PyObject *ret;\n\n    if (endian == '=') {\n        endian = '<';\n        if (!PyArray_IsNativeByteOrder(endian)) {\n            endian = '>';\n        }\n    }\n    if (self->type_num == NPY_UNICODE) {\n        size >>= 2;\n    }\n    if (self->type_num == NPY_OBJECT) {\n        ret = PyUnicode_FromFormat(\"%c%c\", endian, basic_);\n    }\n    else {\n        ret = PyUnicode_FromFormat(\"%c%c%d\", endian, basic_, size);\n    }\n    if (ret == NULL) {\n        return NULL;\n    }\n\n    if (PyDataType_ISDATETIME(self)) {\n        PyArray_DatetimeMetaData *meta;\n        meta = get_datetime_metadata_from_dtype(self);\n        if (meta == NULL) {\n            Py_DECREF(ret);\n            return NULL;\n        }\n        PyObject *umeta = metastr_to_unicode(meta, 0);\n        if (umeta == NULL) {\n            Py_DECREF(ret);\n            return NULL;\n        }\n\n        Py_SETREF(ret, PyUnicode_Concat(ret, umeta));\n        Py_DECREF(umeta);\n    }\n    return ret;\n}\n\nstatic PyObject *\narraydescr_name_get(PyArray_Descr *self)\n{\n    /* let python handle this */\n    PyObject *_numpy_dtype;\n    PyObject *res;\n    _numpy_dtype = PyImport_ImportModule(\"numpy.core._dtype\");\n    if (_numpy_dtype == NULL) {\n        return NULL;\n    }\n    res = PyObject_CallMethod(_numpy_dtype, \"_name_get\", \"O\", self);\n    Py_DECREF(_numpy_dtype);\n    return res;\n}\n\nstatic PyObject *\narraydescr_base_get(PyArray_Descr *self)\n{\n    if (!PyDataType_HASSUBARRAY(self)) {\n        Py_INCREF(self);\n        return (PyObject *)self;\n    }\n    Py_INCREF(self->subarray->base);\n    return (PyObject *)(self->subarray->base);\n}\n\nstatic PyObject *\narraydescr_shape_get(PyArray_Descr *self)\n{\n    if (!PyDataType_HASSUBARRAY(self)) {\n        return PyTuple_New(0);\n    }\n    assert(PyTuple_Check(self->subarray->shape));\n    Py_INCREF(self->subarray->shape);\n    return self->subarray->shape;\n}\n\nstatic PyObject *\narraydescr_ndim_get(PyArray_Descr *self)\n{\n    Py_ssize_t ndim;\n\n    if (!PyDataType_HASSUBARRAY(self)) {\n        return PyLong_FromLong(0);\n    }\n\n    /*\n     * PyTuple_Size has built in check\n     * for tuple argument\n     */\n    ndim = PyTuple_Size(self->subarray->shape);\n    return PyLong_FromLong(ndim);\n}\n\n\nNPY_NO_EXPORT PyObject *\narraydescr_protocol_descr_get(PyArray_Descr *self)\n{\n    PyObject *dobj, *res;\n    PyObject *_numpy_internal;\n\n    if (!PyDataType_HASFIELDS(self)) {\n        /* get default */\n        dobj = PyTuple_New(2);\n        if (dobj == NULL) {\n            return NULL;\n        }\n        PyTuple_SET_ITEM(dobj, 0, PyUnicode_FromString(\"\"));\n        PyTuple_SET_ITEM(dobj, 1, arraydescr_protocol_typestr_get(self));\n        res = PyList_New(1);\n        if (res == NULL) {\n            Py_DECREF(dobj);\n            return NULL;\n        }\n        PyList_SET_ITEM(res, 0, dobj);\n        return res;\n    }\n\n    _numpy_internal = PyImport_ImportModule(\"numpy.core._internal\");\n    if (_numpy_internal == NULL) {\n        return NULL;\n    }\n    res = PyObject_CallMethod(_numpy_internal, \"_array_descr\", \"O\", self);\n    Py_DECREF(_numpy_internal);\n    return res;\n}\n\n/*\n * returns 1 for a builtin type\n * and 2 for a user-defined data-type descriptor\n * return 0 if neither (i.e. it's a copy of one)\n */\nstatic PyObject *\narraydescr_isbuiltin_get(PyArray_Descr *self)\n{\n    long val;\n    val = 0;\n    if (self->fields == Py_None) {\n        val = 1;\n    }\n    if (PyTypeNum_ISUSERDEF(self->type_num)) {\n        val = 2;\n    }\n    return PyLong_FromLong(val);\n}\n\nstatic int\n_arraydescr_isnative(PyArray_Descr *self)\n{\n    if (!PyDataType_HASFIELDS(self)) {\n        return PyArray_ISNBO(self->byteorder);\n    }\n    else {\n        PyObject *key, *value, *title = NULL;\n        PyArray_Descr *new;\n        int offset;\n        Py_ssize_t pos = 0;\n        while (PyDict_Next(self->fields, &pos, &key, &value)) {\n            if (NPY_TITLE_KEY(key, value)) {\n                continue;\n            }\n            if (!PyArg_ParseTuple(value, \"Oi|O\", &new, &offset, &title)) {\n                return -1;\n            }\n            if (!_arraydescr_isnative(new)) {\n                return 0;\n            }\n        }\n    }\n    return 1;\n}\n\n/*\n * return Py_True if this data-type descriptor\n * has native byteorder if no fields are defined\n *\n * or if all sub-fields have native-byteorder if\n * fields are defined\n */\nstatic PyObject *\narraydescr_isnative_get(PyArray_Descr *self)\n{\n    PyObject *ret;\n    int retval;\n    retval = _arraydescr_isnative(self);\n    if (retval == -1) {\n        return NULL;\n    }\n    ret = retval ? Py_True : Py_False;\n    Py_INCREF(ret);\n    return ret;\n}\n\nstatic PyObject *\narraydescr_isalignedstruct_get(PyArray_Descr *self)\n{\n    PyObject *ret;\n    ret = (self->flags&NPY_ALIGNED_STRUCT) ? Py_True : Py_False;\n    Py_INCREF(ret);\n    return ret;\n}\n\nstatic PyObject *\narraydescr_fields_get(PyArray_Descr *self)\n{\n    if (!PyDataType_HASFIELDS(self)) {\n        Py_RETURN_NONE;\n    }\n    return PyDictProxy_New(self->fields);\n}\n\nstatic PyObject *\narraydescr_metadata_get(PyArray_Descr *self)\n{\n    if (self->metadata == NULL) {\n        Py_RETURN_NONE;\n    }\n    return PyDictProxy_New(self->metadata);\n}\n\nstatic PyObject *\narraydescr_hasobject_get(PyArray_Descr *self)\n{\n    if (PyDataType_FLAGCHK(self, NPY_ITEM_HASOBJECT)) {\n        Py_RETURN_TRUE;\n    }\n    else {\n        Py_RETURN_FALSE;\n    }\n}\n\nstatic PyObject *\narraydescr_names_get(PyArray_Descr *self)\n{\n    if (!PyDataType_HASFIELDS(self)) {\n        Py_RETURN_NONE;\n    }\n    Py_INCREF(self->names);\n    return self->names;\n}\n\nstatic int\narraydescr_names_set(PyArray_Descr *self, PyObject *val)\n{\n    int N = 0;\n    int i;\n    PyObject *new_names;\n    PyObject *new_fields;\n\n    if (val == NULL) {\n        PyErr_SetString(PyExc_AttributeError,\n                \"Cannot delete dtype names attribute\");\n        return -1;\n    }\n    if (!PyDataType_HASFIELDS(self)) {\n        PyErr_SetString(PyExc_ValueError,\n                \"there are no fields defined\");\n        return -1;\n    }\n\n    /*\n     * FIXME\n     *\n     * This deprecation has been temporarily removed for the NumPy 1.7\n     * release. It should be re-added after the 1.7 branch is done,\n     * and a convenience API to replace the typical use-cases for\n     * mutable names should be implemented.\n     *\n     * if (DEPRECATE(\"Setting NumPy dtype names is deprecated, the dtype \"\n     *                \"will become immutable in a future version\") < 0) {\n     *     return -1;\n     * }\n     */\n\n    N = PyTuple_GET_SIZE(self->names);\n    if (!PySequence_Check(val) || PyObject_Size((PyObject *)val) != N) {\n        PyErr_Format(PyExc_ValueError,\n                \"must replace all names at once with a sequence of length %d\",\n                N);\n        return -1;\n    }\n    /* Make sure all entries are strings */\n    for (i = 0; i < N; i++) {\n        PyObject *item;\n        int valid = 1;\n        item = PySequence_GetItem(val, i);\n        valid = PyUnicode_Check(item);\n        Py_DECREF(item);\n        if (!valid) {\n            PyErr_Format(PyExc_ValueError,\n                    \"item #%d of names is of type %s and not string\",\n                    i, Py_TYPE(item)->tp_name);\n            return -1;\n        }\n    }\n    /* Invalidate cached hash value */\n    self->hash = -1;\n    /* Update dictionary keys in fields */\n    new_names = PySequence_Tuple(val);\n    if (new_names == NULL) {\n        return -1;\n    }\n    new_fields = PyDict_New();\n    if (new_fields == NULL) {\n        Py_DECREF(new_names);\n        return -1;\n    }\n    for (i = 0; i < N; i++) {\n        PyObject *key;\n        PyObject *item;\n        PyObject *new_key;\n        int ret;\n        key = PyTuple_GET_ITEM(self->names, i);\n        /* Borrowed references to item and new_key */\n        item = PyDict_GetItemWithError(self->fields, key);\n        if (item == NULL) {\n            if (!PyErr_Occurred()) {\n                /* fields was missing the name it claimed to contain */\n                PyErr_BadInternalCall();\n            }\n            Py_DECREF(new_names);\n            Py_DECREF(new_fields);\n            return -1;\n        }\n        new_key = PyTuple_GET_ITEM(new_names, i);\n        /* Check for duplicates */\n        ret = PyDict_Contains(new_fields, new_key);\n        if (ret < 0) {\n            Py_DECREF(new_names);\n            Py_DECREF(new_fields);\n            return -1;\n        }\n        else if (ret != 0) {\n            PyErr_SetString(PyExc_ValueError, \"Duplicate field names given.\");\n            Py_DECREF(new_names);\n            Py_DECREF(new_fields);\n            return -1;\n        }\n        if (PyDict_SetItem(new_fields, new_key, item) < 0) {\n            Py_DECREF(new_names);\n            Py_DECREF(new_fields);\n            return -1;\n        }\n    }\n\n    /* Replace names */\n    Py_DECREF(self->names);\n    self->names = new_names;\n\n    /* Replace fields */\n    Py_DECREF(self->fields);\n    self->fields = new_fields;\n\n    return 0;\n}\n\nstatic PyGetSetDef arraydescr_getsets[] = {\n    {\"subdtype\",\n        (getter)arraydescr_subdescr_get,\n        NULL, NULL, NULL},\n    {\"descr\",\n        (getter)arraydescr_protocol_descr_get,\n        NULL, NULL, NULL},\n    {\"str\",\n        (getter)arraydescr_protocol_typestr_get,\n        NULL, NULL, NULL},\n    {\"name\",\n        (getter)arraydescr_name_get,\n        NULL, NULL, NULL},\n    {\"base\",\n        (getter)arraydescr_base_get,\n        NULL, NULL, NULL},\n    {\"shape\",\n        (getter)arraydescr_shape_get,\n        NULL, NULL, NULL},\n    {\"ndim\",\n        (getter)arraydescr_ndim_get,\n        NULL, NULL, NULL},\n    {\"isbuiltin\",\n        (getter)arraydescr_isbuiltin_get,\n        NULL, NULL, NULL},\n    {\"isnative\",\n        (getter)arraydescr_isnative_get,\n        NULL, NULL, NULL},\n    {\"isalignedstruct\",\n        (getter)arraydescr_isalignedstruct_get,\n        NULL, NULL, NULL},\n    {\"fields\",\n        (getter)arraydescr_fields_get,\n        NULL, NULL, NULL},\n    {\"metadata\",\n        (getter)arraydescr_metadata_get,\n        NULL, NULL, NULL},\n    {\"names\",\n        (getter)arraydescr_names_get,\n        (setter)arraydescr_names_set,\n        NULL, NULL},\n    {\"hasobject\",\n        (getter)arraydescr_hasobject_get,\n        NULL, NULL, NULL},\n    {NULL, NULL, NULL, NULL, NULL},\n};\n\nstatic PyObject *\narraydescr_new(PyTypeObject *subtype,\n                PyObject *args, PyObject *kwds)\n{\n    if (subtype != &PyArrayDescr_Type) {\n        /* The DTypeMeta class should prevent this from happening. */\n        PyErr_Format(PyExc_SystemError,\n                \"'%S' must not inherit np.dtype.__new__().\", subtype);\n        return NULL;\n    }\n\n    PyObject *odescr, *metadata=NULL;\n    PyArray_Descr *descr, *conv;\n    npy_bool align = NPY_FALSE;\n    npy_bool copy = NPY_FALSE;\n    npy_bool copied = NPY_FALSE;\n\n    static char *kwlist[] = {\"dtype\", \"align\", \"copy\", \"metadata\", NULL};\n\n    if (!PyArg_ParseTupleAndKeywords(args, kwds, \"O|O&O&O!:dtype\", kwlist,\n                &odescr,\n                PyArray_BoolConverter, &align,\n                PyArray_BoolConverter, &copy,\n                &PyDict_Type, &metadata)) {\n        return NULL;\n    }\n\n    conv = _convert_from_any(odescr, align);\n    if (conv == NULL) {\n        return NULL;\n    }\n\n    /* Get a new copy of it unless it's already a copy */\n    if (copy && conv->fields == Py_None) {\n        descr = PyArray_DescrNew(conv);\n        Py_DECREF(conv);\n        conv = descr;\n        copied = NPY_TRUE;\n    }\n\n    if ((metadata != NULL)) {\n        /*\n         * We need to be sure to make a new copy of the data-type and any\n         * underlying dictionary\n         */\n        if (!copied) {\n            copied = NPY_TRUE;\n            descr = PyArray_DescrNew(conv);\n            Py_DECREF(conv);\n            conv = descr;\n        }\n        if ((conv->metadata != NULL)) {\n            /*\n             * Make a copy of the metadata before merging with the\n             * input metadata so that this data-type descriptor has\n             * it's own copy\n             */\n            /* Save a reference */\n            odescr = conv->metadata;\n            conv->metadata = PyDict_Copy(odescr);\n            /* Decrement the old reference */\n            Py_DECREF(odescr);\n\n            /*\n             * Update conv->metadata with anything new in metadata\n             * keyword, but do not over-write anything already there\n             */\n            if (PyDict_Merge(conv->metadata, metadata, 0) != 0) {\n                Py_DECREF(conv);\n                return NULL;\n            }\n        }\n        else {\n            /* Make a copy of the input dictionary */\n            conv->metadata = PyDict_Copy(metadata);\n        }\n    }\n\n    return (PyObject *)conv;\n}\n\n\n/*\n * Return a tuple of\n * (cleaned metadata dictionary, tuple with (str, num))\n */\nstatic PyObject *\n_get_pickleabletype_from_datetime_metadata(PyArray_Descr *dtype)\n{\n    PyObject *ret, *dt_tuple;\n    PyArray_DatetimeMetaData *meta;\n\n    /* Create the 2-item tuple to return */\n    ret = PyTuple_New(2);\n    if (ret == NULL) {\n        return NULL;\n    }\n\n    /* Store the metadata dictionary */\n    if (dtype->metadata != NULL) {\n        Py_INCREF(dtype->metadata);\n        PyTuple_SET_ITEM(ret, 0, dtype->metadata);\n    } else {\n        PyTuple_SET_ITEM(ret, 0, PyDict_New());\n    }\n\n    /* Convert the datetime metadata into a tuple */\n    meta = get_datetime_metadata_from_dtype(dtype);\n    if (meta == NULL) {\n        Py_DECREF(ret);\n        return NULL;\n    }\n    /* Use a 4-tuple that numpy 1.6 knows how to unpickle */\n    dt_tuple = PyTuple_New(4);\n    if (dt_tuple == NULL) {\n        Py_DECREF(ret);\n        return NULL;\n    }\n    PyTuple_SET_ITEM(dt_tuple, 0,\n            PyBytes_FromString(_datetime_strings[meta->base]));\n    PyTuple_SET_ITEM(dt_tuple, 1,\n            PyLong_FromLong(meta->num));\n    PyTuple_SET_ITEM(dt_tuple, 2,\n            PyLong_FromLong(1));\n    PyTuple_SET_ITEM(dt_tuple, 3,\n            PyLong_FromLong(1));\n\n    PyTuple_SET_ITEM(ret, 1, dt_tuple);\n\n    return ret;\n}\n\n/*\n * return a tuple of (callable object, args, state).\n *\n * TODO: This method needs to change so that unpickling doesn't\n *       use __setstate__. This is required for the dtype\n *       to be an immutable object.\n */\nstatic PyObject *\narraydescr_reduce(PyArray_Descr *self, PyObject *NPY_UNUSED(args))\n{\n    /*\n     * version number of this pickle type. Increment if we need to\n     * change the format. Be sure to handle the old versions in\n     * arraydescr_setstate.\n    */\n    const int version = 4;\n    PyObject *ret, *mod, *obj;\n    PyObject *state;\n    char endian;\n    int elsize, alignment;\n\n    ret = PyTuple_New(3);\n    if (ret == NULL) {\n        return NULL;\n    }\n    mod = PyImport_ImportModule(\"numpy.core._multiarray_umath\");\n    if (mod == NULL) {\n        Py_DECREF(ret);\n        return NULL;\n    }\n    obj = PyObject_GetAttrString(mod, \"dtype\");\n    Py_DECREF(mod);\n    if (obj == NULL) {\n        Py_DECREF(ret);\n        return NULL;\n    }\n    PyTuple_SET_ITEM(ret, 0, obj);\n    if (PyTypeNum_ISUSERDEF(self->type_num)\n            || ((self->type_num == NPY_VOID\n                    && self->typeobj != &PyVoidArrType_Type))) {\n        obj = (PyObject *)self->typeobj;\n        Py_INCREF(obj);\n    }\n    else {\n        elsize = self->elsize;\n        if (self->type_num == NPY_UNICODE) {\n            elsize >>= 2;\n        }\n        obj = PyUnicode_FromFormat(\"%c%d\",self->kind, elsize);\n    }\n    PyTuple_SET_ITEM(ret, 1, Py_BuildValue(\"(NOO)\", obj, Py_False, Py_True));\n\n    /*\n     * Now return the state which is at least byteorder,\n     * subarray, and fields\n     */\n    endian = self->byteorder;\n    if (endian == '=') {\n        endian = '<';\n        if (!PyArray_IsNativeByteOrder(endian)) {\n            endian = '>';\n        }\n    }\n    if (PyDataType_ISDATETIME(self)) {\n        PyObject *newobj;\n        state = PyTuple_New(9);\n        PyTuple_SET_ITEM(state, 0, PyLong_FromLong(version));\n        /*\n         * newobj is a tuple of the Python metadata dictionary\n         * and tuple of date_time info (str, num)\n         */\n        newobj = _get_pickleabletype_from_datetime_metadata(self);\n        if (newobj == NULL) {\n            Py_DECREF(state);\n            Py_DECREF(ret);\n            return NULL;\n        }\n        PyTuple_SET_ITEM(state, 8, newobj);\n    }\n    else if (self->metadata) {\n        state = PyTuple_New(9);\n        PyTuple_SET_ITEM(state, 0, PyLong_FromLong(version));\n        Py_INCREF(self->metadata);\n        PyTuple_SET_ITEM(state, 8, self->metadata);\n    }\n    else { /* Use version 3 pickle format */\n        state = PyTuple_New(8);\n        PyTuple_SET_ITEM(state, 0, PyLong_FromLong(3));\n    }\n\n    PyTuple_SET_ITEM(state, 1, PyUnicode_FromFormat(\"%c\", endian));\n    PyTuple_SET_ITEM(state, 2, arraydescr_subdescr_get(self));\n    if (PyDataType_HASFIELDS(self)) {\n        Py_INCREF(self->names);\n        Py_INCREF(self->fields);\n        PyTuple_SET_ITEM(state, 3, self->names);\n        PyTuple_SET_ITEM(state, 4, self->fields);\n    }\n    else {\n        PyTuple_SET_ITEM(state, 3, Py_None);\n        PyTuple_SET_ITEM(state, 4, Py_None);\n        Py_INCREF(Py_None);\n        Py_INCREF(Py_None);\n    }\n\n    /* for extended types it also includes elsize and alignment */\n    if (PyTypeNum_ISEXTENDED(self->type_num)) {\n        elsize = self->elsize;\n        alignment = self->alignment;\n    }\n    else {\n        elsize = -1;\n        alignment = -1;\n    }\n    PyTuple_SET_ITEM(state, 5, PyLong_FromLong(elsize));\n    PyTuple_SET_ITEM(state, 6, PyLong_FromLong(alignment));\n    PyTuple_SET_ITEM(state, 7, PyLong_FromLong(self->flags));\n\n    PyTuple_SET_ITEM(ret, 2, state);\n    return ret;\n}\n\n/*\n * returns NPY_OBJECT_DTYPE_FLAGS if this data-type has an object portion used\n * when setting the state because hasobject is not stored.\n */\nstatic char\n_descr_find_object(PyArray_Descr *self)\n{\n    if (self->flags\n            || self->type_num == NPY_OBJECT\n            || self->kind == 'O') {\n        return NPY_OBJECT_DTYPE_FLAGS;\n    }\n    if (PyDataType_HASFIELDS(self)) {\n        PyObject *key, *value, *title = NULL;\n        PyArray_Descr *new;\n        int offset;\n        Py_ssize_t pos = 0;\n\n        while (PyDict_Next(self->fields, &pos, &key, &value)) {\n            if (NPY_TITLE_KEY(key, value)) {\n                continue;\n            }\n            if (!PyArg_ParseTuple(value, \"Oi|O\", &new, &offset, &title)) {\n                PyErr_Clear();\n                return 0;\n            }\n            if (_descr_find_object(new)) {\n                new->flags = NPY_OBJECT_DTYPE_FLAGS;\n                return NPY_OBJECT_DTYPE_FLAGS;\n            }\n        }\n    }\n    return 0;\n}\n\n/*\n * state is at least byteorder, subarray, and fields but could include elsize\n * and alignment for EXTENDED arrays\n */\nstatic PyObject *\narraydescr_setstate(PyArray_Descr *self, PyObject *args)\n{\n    int elsize = -1, alignment = -1;\n    int version = 4;\n    char endian;\n    PyObject *endian_obj;\n    PyObject *subarray, *fields, *names = NULL, *metadata=NULL;\n    int incref_names = 1;\n    int int_dtypeflags = 0;\n    char dtypeflags;\n\n    if (self->fields == Py_None) {\n        Py_RETURN_NONE;\n    }\n    if (PyTuple_GET_SIZE(args) != 1\n            || !(PyTuple_Check(PyTuple_GET_ITEM(args, 0)))) {\n        PyErr_BadInternalCall();\n        return NULL;\n    }\n    switch (PyTuple_GET_SIZE(PyTuple_GET_ITEM(args,0))) {\n    case 9:\n        if (!PyArg_ParseTuple(args, \"(iOOOOiiiO):__setstate__\",\n                    &version, &endian_obj,\n                    &subarray, &names, &fields, &elsize,\n                    &alignment, &int_dtypeflags, &metadata)) {\n            PyErr_Clear();\n            return NULL;\n        }\n        break;\n    case 8:\n        if (!PyArg_ParseTuple(args, \"(iOOOOiii):__setstate__\",\n                    &version, &endian_obj,\n                    &subarray, &names, &fields, &elsize,\n                    &alignment, &int_dtypeflags)) {\n            return NULL;\n        }\n        break;\n    case 7:\n        if (!PyArg_ParseTuple(args, \"(iOOOOii):__setstate__\",\n                    &version, &endian_obj,\n                    &subarray, &names, &fields, &elsize,\n                    &alignment)) {\n            return NULL;\n        }\n        break;\n    case 6:\n        if (!PyArg_ParseTuple(args, \"(iOOOii):__setstate__\",\n                    &version,\n                    &endian_obj, &subarray, &fields,\n                    &elsize, &alignment)) {\n            return NULL;\n        }\n        break;\n    case 5:\n        version = 0;\n        if (!PyArg_ParseTuple(args, \"(OOOii):__setstate__\",\n                    &endian_obj, &subarray, &fields, &elsize,\n                    &alignment)) {\n            return NULL;\n        }\n        break;\n    default:\n        /* raise an error */\n        if (PyTuple_GET_SIZE(PyTuple_GET_ITEM(args,0)) > 5) {\n            version = PyLong_AsLong(PyTuple_GET_ITEM(args, 0));\n        }\n        else {\n            version = -1;\n        }\n    }\n\n    /*\n     * If we ever need another pickle format, increment the version\n     * number. But we should still be able to handle the old versions.\n     */\n    if (version < 0 || version > 4) {\n        PyErr_Format(PyExc_ValueError,\n                     \"can't handle version %d of numpy.dtype pickle\",\n                     version);\n        return NULL;\n    }\n    /* Invalidate cached hash value */\n    self->hash = -1;\n\n    if (version == 1 || version == 0) {\n        if (fields != Py_None) {\n            PyObject *key, *list;\n            key = PyLong_FromLong(-1);\n            list = PyDict_GetItemWithError(fields, key);\n            if (!list) {\n                if (!PyErr_Occurred()) {\n                    /* fields was missing the name it claimed to contain */\n                    PyErr_BadInternalCall();\n                }\n                return NULL;\n            }\n            Py_INCREF(list);\n            names = list;\n            PyDict_DelItem(fields, key);\n            incref_names = 0;\n        }\n        else {\n            names = Py_None;\n        }\n    }\n\n    /* Parse endian */\n    if (PyUnicode_Check(endian_obj) || PyBytes_Check(endian_obj)) {\n        PyObject *tmp = NULL;\n        char *str;\n        Py_ssize_t len;\n\n        if (PyUnicode_Check(endian_obj)) {\n            tmp = PyUnicode_AsASCIIString(endian_obj);\n            if (tmp == NULL) {\n                return NULL;\n            }\n            endian_obj = tmp;\n        }\n\n        if (PyBytes_AsStringAndSize(endian_obj, &str, &len) < 0) {\n            Py_XDECREF(tmp);\n            return NULL;\n        }\n        if (len != 1) {\n            PyErr_SetString(PyExc_ValueError,\n                            \"endian is not 1-char string in Numpy dtype unpickling\");\n            Py_XDECREF(tmp);\n            return NULL;\n        }\n        endian = str[0];\n        Py_XDECREF(tmp);\n    }\n    else {\n        PyErr_SetString(PyExc_ValueError,\n                        \"endian is not a string in Numpy dtype unpickling\");\n        return NULL;\n    }\n\n    if ((fields == Py_None && names != Py_None) ||\n        (names == Py_None && fields != Py_None)) {\n        PyErr_Format(PyExc_ValueError,\n                \"inconsistent fields and names in Numpy dtype unpickling\");\n        return NULL;\n    }\n\n    if (names != Py_None && !PyTuple_Check(names)) {\n        PyErr_Format(PyExc_ValueError,\n                \"non-tuple names in Numpy dtype unpickling\");\n        return NULL;\n    }\n\n    if (fields != Py_None && !PyDict_Check(fields)) {\n        PyErr_Format(PyExc_ValueError,\n                \"non-dict fields in Numpy dtype unpickling\");\n        return NULL;\n    }\n\n    if (endian != '|' && PyArray_IsNativeByteOrder(endian)) {\n        endian = '=';\n    }\n    self->byteorder = endian;\n    if (self->subarray) {\n        Py_XDECREF(self->subarray->base);\n        Py_XDECREF(self->subarray->shape);\n        PyArray_free(self->subarray);\n    }\n    self->subarray = NULL;\n\n    if (subarray != Py_None) {\n        PyObject *subarray_shape;\n\n        /*\n         * Ensure that subarray[0] is an ArrayDescr and\n         * that subarray_shape obtained from subarray[1] is a tuple of integers.\n         */\n        if (!(PyTuple_Check(subarray) &&\n              PyTuple_Size(subarray) == 2 &&\n              PyArray_DescrCheck(PyTuple_GET_ITEM(subarray, 0)))) {\n            PyErr_Format(PyExc_ValueError,\n                         \"incorrect subarray in __setstate__\");\n            return NULL;\n        }\n        subarray_shape = PyTuple_GET_ITEM(subarray, 1);\n        if (PyNumber_Check(subarray_shape)) {\n            PyObject *tmp;\n            tmp = PyNumber_Long(subarray_shape);\n            if (tmp == NULL) {\n                return NULL;\n            }\n            subarray_shape = Py_BuildValue(\"(O)\", tmp);\n            Py_DECREF(tmp);\n            if (subarray_shape == NULL) {\n                return NULL;\n            }\n        }\n        else if (_is_tuple_of_integers(subarray_shape)) {\n            Py_INCREF(subarray_shape);\n        }\n        else {\n            PyErr_Format(PyExc_ValueError,\n                         \"incorrect subarray shape in __setstate__\");\n            return NULL;\n        }\n\n        self->subarray = PyArray_malloc(sizeof(PyArray_ArrayDescr));\n        if (!PyDataType_HASSUBARRAY(self)) {\n            return PyErr_NoMemory();\n        }\n        self->subarray->base = (PyArray_Descr *)PyTuple_GET_ITEM(subarray, 0);\n        Py_INCREF(self->subarray->base);\n        self->subarray->shape = subarray_shape;\n    }\n\n    if (fields != Py_None) {\n        /*\n         * Ensure names are of appropriate string type\n         */\n        Py_ssize_t i;\n        int names_ok = 1;\n        PyObject *name;\n\n        for (i = 0; i < PyTuple_GET_SIZE(names); ++i) {\n            name = PyTuple_GET_ITEM(names, i);\n            if (!PyUnicode_Check(name)) {\n                names_ok = 0;\n                break;\n            }\n        }\n\n        if (names_ok) {\n            Py_XDECREF(self->fields);\n            self->fields = fields;\n            Py_INCREF(fields);\n            Py_XDECREF(self->names);\n            self->names = names;\n            if (incref_names) {\n                Py_INCREF(names);\n            }\n        }\n        else {\n            /*\n             * To support pickle.load(f, encoding='bytes') for loading Py2\n             * generated pickles on Py3, we need to be more lenient and convert\n             * field names from byte strings to unicode.\n             */\n            PyObject *tmp, *new_name, *field;\n\n            tmp = PyDict_New();\n            if (tmp == NULL) {\n                return NULL;\n            }\n            Py_XDECREF(self->fields);\n            self->fields = tmp;\n\n            tmp = PyTuple_New(PyTuple_GET_SIZE(names));\n            if (tmp == NULL) {\n                return NULL;\n            }\n            Py_XDECREF(self->names);\n            self->names = tmp;\n\n            for (i = 0; i < PyTuple_GET_SIZE(names); ++i) {\n                name = PyTuple_GET_ITEM(names, i);\n                field = PyDict_GetItemWithError(fields, name);\n                if (!field) {\n                    if (!PyErr_Occurred()) {\n                        /* fields was missing the name it claimed to contain */\n                        PyErr_BadInternalCall();\n                    }\n                    return NULL;\n                }\n\n                if (PyUnicode_Check(name)) {\n                    new_name = name;\n                    Py_INCREF(new_name);\n                }\n                else {\n                    new_name = PyUnicode_FromEncodedObject(name, \"ASCII\", \"strict\");\n                    if (new_name == NULL) {\n                        return NULL;\n                    }\n                }\n\n                PyTuple_SET_ITEM(self->names, i, new_name);\n                if (PyDict_SetItem(self->fields, new_name, field) != 0) {\n                    return NULL;\n                }\n            }\n        }\n    }\n\n    if (PyTypeNum_ISEXTENDED(self->type_num)) {\n        self->elsize = elsize;\n        self->alignment = alignment;\n    }\n\n    /*\n     * We use an integer converted to char for backward compatibility with\n     * pickled arrays. Pickled arrays created with previous versions encoded\n     * flags as an int even though it actually was a char in the PyArray_Descr\n     * structure\n     */\n    dtypeflags = int_dtypeflags;\n    if (dtypeflags != int_dtypeflags) {\n        PyErr_Format(PyExc_ValueError,\n                     \"incorrect value for flags variable (overflow)\");\n        return NULL;\n    }\n    else {\n        self->flags = dtypeflags;\n    }\n\n    if (version < 3) {\n        self->flags = _descr_find_object(self);\n    }\n\n    /*\n     * We have a borrowed reference to metadata so no need\n     * to alter reference count when throwing away Py_None.\n     */\n    if (metadata == Py_None) {\n        metadata = NULL;\n    }\n\n    if (PyDataType_ISDATETIME(self) && (metadata != NULL)) {\n        PyObject *old_metadata;\n        PyArray_DatetimeMetaData temp_dt_data;\n\n        if ((! PyTuple_Check(metadata)) || (PyTuple_Size(metadata) != 2)) {\n            PyErr_Format(PyExc_ValueError,\n                    \"Invalid datetime dtype (metadata, c_metadata): %R\",\n                    metadata);\n            return NULL;\n        }\n\n        if (convert_datetime_metadata_tuple_to_datetime_metadata(\n                                    PyTuple_GET_ITEM(metadata, 1),\n                                    &temp_dt_data,\n                                    NPY_TRUE) < 0) {\n            return NULL;\n        }\n\n        old_metadata = self->metadata;\n        self->metadata = PyTuple_GET_ITEM(metadata, 0);\n        memcpy((char *) &((PyArray_DatetimeDTypeMetaData *)self->c_metadata)->meta,\n               (char *) &temp_dt_data,\n               sizeof(PyArray_DatetimeMetaData));\n        Py_XINCREF(self->metadata);\n        Py_XDECREF(old_metadata);\n    }\n    else {\n        PyObject *old_metadata = self->metadata;\n        self->metadata = metadata;\n        Py_XINCREF(self->metadata);\n        Py_XDECREF(old_metadata);\n    }\n\n    Py_RETURN_NONE;\n}\n\n/*NUMPY_API\n *\n * Get type-descriptor from an object forcing alignment if possible\n * None goes to DEFAULT type.\n *\n * any object with the .fields attribute and/or .itemsize attribute (if the\n *.fields attribute does not give the total size -- i.e. a partial record\n * naming).  If itemsize is given it must be >= size computed from fields\n *\n * The .fields attribute must return a convertible dictionary if present.\n * Result inherits from NPY_VOID.\n*/\nNPY_NO_EXPORT int\nPyArray_DescrAlignConverter(PyObject *obj, PyArray_Descr **at)\n{\n    *at = _convert_from_any(obj, 1);\n    return (*at) ? NPY_SUCCEED : NPY_FAIL;\n}\n\n/*NUMPY_API\n *\n * Get type-descriptor from an object forcing alignment if possible\n * None goes to NULL.\n */\nNPY_NO_EXPORT int\nPyArray_DescrAlignConverter2(PyObject *obj, PyArray_Descr **at)\n{\n    if (obj == Py_None) {\n        *at = NULL;\n        return NPY_SUCCEED;\n    }\n    else {\n        return PyArray_DescrAlignConverter(obj, at);\n    }\n}\n\n\n\n/*NUMPY_API\n *\n * returns a copy of the PyArray_Descr structure with the byteorder\n * altered:\n * no arguments:  The byteorder is swapped (in all subfields as well)\n * single argument:  The byteorder is forced to the given state\n * (in all subfields as well)\n *\n * Valid states:  ('big', '>') or ('little' or '<')\n * ('native', or '=')\n *\n * If a descr structure with | is encountered it's own\n * byte-order is not changed but any fields are:\n *\n *\n * Deep bytorder change of a data-type descriptor\n * *** Leaves reference count of self unchanged --- does not DECREF self ***\n */\nNPY_NO_EXPORT PyArray_Descr *\nPyArray_DescrNewByteorder(PyArray_Descr *self, char newendian)\n{\n    PyArray_Descr *new;\n    char endian;\n\n    new = PyArray_DescrNew(self);\n    endian = new->byteorder;\n    if (endian != NPY_IGNORE) {\n        if (newendian == NPY_SWAP) {\n            /* swap byteorder */\n            if (PyArray_ISNBO(endian)) {\n                endian = NPY_OPPBYTE;\n            }\n            else {\n                endian = NPY_NATBYTE;\n            }\n            new->byteorder = endian;\n        }\n        else if (newendian != NPY_IGNORE) {\n            new->byteorder = newendian;\n        }\n    }\n    if (PyDataType_HASFIELDS(new)) {\n        PyObject *newfields;\n        PyObject *key, *value;\n        PyObject *newvalue;\n        PyObject *old;\n        PyArray_Descr *newdescr;\n        Py_ssize_t pos = 0;\n        int len, i;\n\n        newfields = PyDict_New();\n        /* make new dictionary with replaced PyArray_Descr Objects */\n        while (PyDict_Next(self->fields, &pos, &key, &value)) {\n            if (NPY_TITLE_KEY(key, value)) {\n                continue;\n            }\n            if (!PyUnicode_Check(key) || !PyTuple_Check(value) ||\n                ((len=PyTuple_GET_SIZE(value)) < 2)) {\n                continue;\n            }\n            old = PyTuple_GET_ITEM(value, 0);\n            if (!PyArray_DescrCheck(old)) {\n                continue;\n            }\n            newdescr = PyArray_DescrNewByteorder(\n                    (PyArray_Descr *)old, newendian);\n            if (newdescr == NULL) {\n                Py_DECREF(newfields); Py_DECREF(new);\n                return NULL;\n            }\n            newvalue = PyTuple_New(len);\n            PyTuple_SET_ITEM(newvalue, 0, (PyObject *)newdescr);\n            for (i = 1; i < len; i++) {\n                old = PyTuple_GET_ITEM(value, i);\n                Py_INCREF(old);\n                PyTuple_SET_ITEM(newvalue, i, old);\n            }\n            int ret = PyDict_SetItem(newfields, key, newvalue);\n            Py_DECREF(newvalue);\n            if (ret < 0) {\n                Py_DECREF(newfields);\n                Py_DECREF(new);\n                return NULL;\n            }\n        }\n        Py_DECREF(new->fields);\n        new->fields = newfields;\n    }\n    if (PyDataType_HASSUBARRAY(new)) {\n        Py_DECREF(new->subarray->base);\n        new->subarray->base = PyArray_DescrNewByteorder(\n                self->subarray->base, newendian);\n    }\n    return new;\n}\n\n\nstatic PyObject *\narraydescr_newbyteorder(PyArray_Descr *self, PyObject *args)\n{\n    char endian=NPY_SWAP;\n\n    if (!PyArg_ParseTuple(args, \"|O&:newbyteorder\", PyArray_ByteorderConverter,\n                &endian)) {\n        return NULL;\n    }\n    return (PyObject *)PyArray_DescrNewByteorder(self, endian);\n}\n\nstatic PyMethodDef arraydescr_methods[] = {\n    /* for pickling */\n    {\"__reduce__\",\n        (PyCFunction)arraydescr_reduce,\n        METH_VARARGS, NULL},\n    {\"__setstate__\",\n        (PyCFunction)arraydescr_setstate,\n        METH_VARARGS, NULL},\n    {\"newbyteorder\",\n        (PyCFunction)arraydescr_newbyteorder,\n        METH_VARARGS, NULL},\n    {NULL, NULL, 0, NULL}           /* sentinel */\n};\n\n/*\n * Checks whether the structured data type in 'dtype'\n * has a simple layout, where all the fields are in order,\n * and follow each other with no alignment padding.\n *\n * When this returns true, the dtype can be reconstructed\n * from a list of the field names and dtypes with no additional\n * dtype parameters.\n *\n * Returns 1 if it has a simple layout, 0 otherwise.\n */\nNPY_NO_EXPORT int\nis_dtype_struct_simple_unaligned_layout(PyArray_Descr *dtype)\n{\n    PyObject *names, *fields, *key, *tup, *title;\n    Py_ssize_t i, names_size;\n    PyArray_Descr *fld_dtype;\n    int fld_offset;\n    npy_intp total_offset;\n\n    /* Get some properties from the dtype */\n    names = dtype->names;\n    names_size = PyTuple_GET_SIZE(names);\n    fields = dtype->fields;\n\n    /* Start at offset zero */\n    total_offset = 0;\n\n    for (i = 0; i < names_size; ++i) {\n        key = PyTuple_GET_ITEM(names, i);\n        if (key == NULL) {\n            return 0;\n        }\n        tup = PyDict_GetItem(fields, key);\n        if (tup == NULL) {\n            return 0;\n        }\n        if (!PyArg_ParseTuple(tup, \"Oi|O\", &fld_dtype, &fld_offset, &title)) {\n            PyErr_Clear();\n            return 0;\n        }\n        /* If this field doesn't follow the pattern, not a simple layout */\n        if (total_offset != fld_offset) {\n            return 0;\n        }\n        /* Get the next offset */\n        total_offset += fld_dtype->elsize;\n    }\n\n    /*\n     * If the itemsize doesn't match the final offset, it's\n     * not a simple layout.\n     */\n    if (total_offset != dtype->elsize) {\n        return 0;\n    }\n\n    /* It's a simple layout, since all the above tests passed */\n    return 1;\n}\n\n/*\n * The general dtype repr function.\n */\nstatic PyObject *\narraydescr_repr(PyArray_Descr *dtype)\n{\n    PyObject *_numpy_dtype;\n    PyObject *res;\n    _numpy_dtype = PyImport_ImportModule(\"numpy.core._dtype\");\n    if (_numpy_dtype == NULL) {\n        return NULL;\n    }\n    res = PyObject_CallMethod(_numpy_dtype, \"__repr__\", \"O\", dtype);\n    Py_DECREF(_numpy_dtype);\n    return res;\n}\n/*\n * The general dtype str function.\n */\nstatic PyObject *\narraydescr_str(PyArray_Descr *dtype)\n{\n    PyObject *_numpy_dtype;\n    PyObject *res;\n    _numpy_dtype = PyImport_ImportModule(\"numpy.core._dtype\");\n    if (_numpy_dtype == NULL) {\n        return NULL;\n    }\n    res = PyObject_CallMethod(_numpy_dtype, \"__str__\", \"O\", dtype);\n    Py_DECREF(_numpy_dtype);\n    return res;\n}\n\nstatic PyObject *\narraydescr_richcompare(PyArray_Descr *self, PyObject *other, int cmp_op)\n{\n    PyArray_Descr *new = _convert_from_any(other, 0);\n    if (new == NULL) {\n        /* Cannot convert `other` to dtype */\n        PyErr_Clear();\n        Py_RETURN_NOTIMPLEMENTED;\n    }\n\n    npy_bool ret;\n    switch (cmp_op) {\n    case Py_LT:\n        ret = !PyArray_EquivTypes(self, new) && PyArray_CanCastTo(self, new);\n        Py_DECREF(new);\n        return PyBool_FromLong(ret);\n    case Py_LE:\n        ret = PyArray_CanCastTo(self, new);\n        Py_DECREF(new);\n        return PyBool_FromLong(ret);\n    case Py_EQ:\n        ret = PyArray_EquivTypes(self, new);\n        Py_DECREF(new);\n        return PyBool_FromLong(ret);\n    case Py_NE:\n        ret = !PyArray_EquivTypes(self, new);\n        Py_DECREF(new);\n        return PyBool_FromLong(ret);\n    case Py_GT:\n        ret = !PyArray_EquivTypes(self, new) && PyArray_CanCastTo(new, self);\n        Py_DECREF(new);\n        return PyBool_FromLong(ret);\n    case Py_GE:\n        ret = PyArray_CanCastTo(new, self);\n        Py_DECREF(new);\n        return PyBool_FromLong(ret);\n    default:\n        Py_DECREF(new);\n        Py_RETURN_NOTIMPLEMENTED;\n    }\n}\n\nstatic int\ndescr_nonzero(PyObject *NPY_UNUSED(self))\n{\n    /* `bool(np.dtype(...)) == True` for all dtypes. Needed to override default\n     * nonzero implementation, which checks if `len(object) > 0`. */\n    return 1;\n}\n\nstatic PyNumberMethods descr_as_number = {\n    .nb_bool = (inquiry)descr_nonzero,\n};\n\n/*************************************************************************\n ****************   Implement Mapping Protocol ***************************\n *************************************************************************/\n\nstatic Py_ssize_t\ndescr_length(PyObject *self0)\n{\n    PyArray_Descr *self = (PyArray_Descr *)self0;\n\n    if (PyDataType_HASFIELDS(self)) {\n        return PyTuple_GET_SIZE(self->names);\n    }\n    else {\n        return 0;\n    }\n}\n\nstatic PyObject *\ndescr_repeat(PyObject *self, Py_ssize_t length)\n{\n    PyObject *tup;\n    PyArray_Descr *new;\n    if (length < 0) {\n        return PyErr_Format(PyExc_ValueError,\n                \"Array length must be >= 0, not %\"NPY_INTP_FMT, (npy_intp)length);\n    }\n    tup = Py_BuildValue(\"O\" NPY_SSIZE_T_PYFMT, self, length);\n    if (tup == NULL) {\n        return NULL;\n    }\n    new = _convert_from_any(tup, 0);\n    Py_DECREF(tup);\n    return (PyObject *)new;\n}\n\nstatic int\n_check_has_fields(PyArray_Descr *self)\n{\n    if (!PyDataType_HASFIELDS(self)) {\n        PyErr_Format(PyExc_KeyError, \"There are no fields in dtype %S.\", self);\n        return -1;\n    }\n    else {\n        return 0;\n    }\n}\n\nstatic PyObject *\n_subscript_by_name(PyArray_Descr *self, PyObject *op)\n{\n    PyObject *obj = PyDict_GetItemWithError(self->fields, op);\n    if (obj == NULL) {\n        if (!PyErr_Occurred()) {\n            PyErr_Format(PyExc_KeyError,\n                    \"Field named %R not found.\", op);\n        }\n        return NULL;\n    }\n    PyObject *descr = PyTuple_GET_ITEM(obj, 0);\n    Py_INCREF(descr);\n    return descr;\n}\n\nstatic PyObject *\n_subscript_by_index(PyArray_Descr *self, Py_ssize_t i)\n{\n    PyObject *name = PySequence_GetItem(self->names, i);\n    PyObject *ret;\n    if (name == NULL) {\n        PyErr_Format(PyExc_IndexError,\n                     \"Field index %zd out of range.\", i);\n        return NULL;\n    }\n    ret = _subscript_by_name(self, name);\n    Py_DECREF(name);\n    return ret;\n}\n\nstatic npy_bool\n_is_list_of_strings(PyObject *obj)\n{\n    int seqlen, i;\n    if (!PyList_CheckExact(obj)) {\n        return NPY_FALSE;\n    }\n    seqlen = PyList_GET_SIZE(obj);\n    for (i = 0; i < seqlen; i++) {\n        PyObject *item = PyList_GET_ITEM(obj, i);\n        if (!PyUnicode_Check(item)) {\n            return NPY_FALSE;\n        }\n    }\n\n    return NPY_TRUE;\n}\n\nNPY_NO_EXPORT PyArray_Descr *\narraydescr_field_subset_view(PyArray_Descr *self, PyObject *ind)\n{\n    int seqlen, i;\n    PyObject *fields = NULL;\n    PyObject *names = NULL;\n    PyArray_Descr *view_dtype;\n\n    seqlen = PySequence_Size(ind);\n    if (seqlen == -1) {\n        return NULL;\n    }\n\n    fields = PyDict_New();\n    if (fields == NULL) {\n        goto fail;\n    }\n    names = PyTuple_New(seqlen);\n    if (names == NULL) {\n        goto fail;\n    }\n\n    for (i = 0; i < seqlen; i++) {\n        PyObject *name;\n        PyObject *tup;\n\n        name = PySequence_GetItem(ind, i);\n        if (name == NULL) {\n            goto fail;\n        }\n\n        /* Let the names tuple steal a reference now, so we don't need to\n         * decref name if an error occurs further on.\n         */\n        PyTuple_SET_ITEM(names, i, name);\n\n        tup = PyDict_GetItemWithError(self->fields, name);\n        if (tup == NULL) {\n            if (!PyErr_Occurred()) {\n                PyErr_SetObject(PyExc_KeyError, name);\n            }\n            goto fail;\n        }\n\n        /* disallow use of titles as index */\n        if (PyTuple_Size(tup) == 3) {\n            PyObject *title = PyTuple_GET_ITEM(tup, 2);\n            int titlecmp = PyObject_RichCompareBool(title, name, Py_EQ);\n            if (titlecmp < 0) {\n                goto fail;\n            }\n            if (titlecmp == 1) {\n                /* if title == name, we were given a title, not a field name */\n                PyErr_SetString(PyExc_KeyError,\n                            \"cannot use field titles in multi-field index\");\n                goto fail;\n            }\n            if (PyDict_SetItem(fields, title, tup) < 0) {\n                goto fail;\n            }\n        }\n        /* disallow duplicate field indices */\n        if (PyDict_Contains(fields, name)) {\n            PyObject *msg = NULL;\n            PyObject *fmt = PyUnicode_FromString(\n                                   \"duplicate field of name {!r}\");\n            if (fmt != NULL) {\n                msg = PyObject_CallMethod(fmt, \"format\", \"O\", name);\n                Py_DECREF(fmt);\n            }\n            PyErr_SetObject(PyExc_ValueError, msg);\n            Py_XDECREF(msg);\n            goto fail;\n        }\n        if (PyDict_SetItem(fields, name, tup) < 0) {\n            goto fail;\n        }\n    }\n\n    view_dtype = PyArray_DescrNewFromType(NPY_VOID);\n    if (view_dtype == NULL) {\n        goto fail;\n    }\n    view_dtype->elsize = self->elsize;\n    view_dtype->names = names;\n    view_dtype->fields = fields;\n    view_dtype->flags = self->flags;\n    return view_dtype;\n\nfail:\n    Py_XDECREF(fields);\n    Py_XDECREF(names);\n    return NULL;\n}\n\nstatic PyObject *\ndescr_subscript(PyArray_Descr *self, PyObject *op)\n{\n    if (_check_has_fields(self) < 0) {\n        return NULL;\n    }\n\n    if (PyUnicode_Check(op)) {\n        return _subscript_by_name(self, op);\n    }\n    else if (_is_list_of_strings(op)) {\n        return (PyObject *)arraydescr_field_subset_view(self, op);\n    }\n    else {\n        Py_ssize_t i = PyArray_PyIntAsIntp(op);\n        if (error_converting(i)) {\n            /* if converting to an int gives a type error, adjust the message */\n            PyObject *err = PyErr_Occurred();\n            if (PyErr_GivenExceptionMatches(err, PyExc_TypeError)) {\n                PyErr_SetString(PyExc_TypeError,\n                        \"Field key must be an integer field offset, \"\n                        \"single field name, or list of field names.\");\n            }\n            return NULL;\n        }\n        return _subscript_by_index(self, i);\n    }\n}\n\nstatic PySequenceMethods descr_as_sequence = {\n    (lenfunc) descr_length,                  /* sq_length */\n    (binaryfunc) NULL,                       /* sq_concat */\n    (ssizeargfunc) descr_repeat,             /* sq_repeat */\n    (ssizeargfunc) NULL,                     /* sq_item */\n    (ssizessizeargfunc) NULL,                /* sq_slice */\n    (ssizeobjargproc) NULL,                  /* sq_ass_item */\n    (ssizessizeobjargproc) NULL,             /* sq_ass_slice */\n    (objobjproc) NULL,                       /* sq_contains */\n    (binaryfunc) NULL,                       /* sq_inplace_concat */\n    (ssizeargfunc) NULL,                     /* sq_inplace_repeat */\n};\n\nstatic PyMappingMethods descr_as_mapping = {\n    descr_length,                                /* mp_length*/\n    (binaryfunc)descr_subscript,                 /* mp_subscript*/\n    (objobjargproc)NULL,                         /* mp_ass_subscript*/\n};\n\n/****************** End of Mapping Protocol ******************************/\n\n\n/*\n * NOTE: Since this is a MetaClass, the name has Full appended here, the\n *       correct name of the type is PyArrayDescr_Type.\n */\nNPY_NO_EXPORT PyArray_DTypeMeta PyArrayDescr_TypeFull = {\n    {{\n        /* NULL represents `type`, this is set to DTypeMeta at import time */\n        PyVarObject_HEAD_INIT(NULL, 0)\n        .tp_name = \"numpy.dtype\",\n        .tp_basicsize = sizeof(PyArray_Descr),\n        .tp_dealloc = (destructor)arraydescr_dealloc,\n        .tp_repr = (reprfunc)arraydescr_repr,\n        .tp_as_number = &descr_as_number,\n        .tp_as_sequence = &descr_as_sequence,\n        .tp_as_mapping = &descr_as_mapping,\n        .tp_str = (reprfunc)arraydescr_str,\n        .tp_flags = Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE,\n        .tp_richcompare = (richcmpfunc)arraydescr_richcompare,\n        .tp_methods = arraydescr_methods,\n        .tp_members = arraydescr_members,\n        .tp_getset = arraydescr_getsets,\n        .tp_new = arraydescr_new,\n    },},\n    .type_num = -1,\n    .kind = '\\0',\n    .abstract = 1,\n    .parametric = 0,\n    .singleton = 0,\n    .scalar_type = NULL,\n};\n"
    },
    {
      "filename": "numpy/core/tests/test_dtype.py",
      "content": "import sys\nimport operator\nimport pytest\nimport ctypes\nimport gc\nimport warnings\n\nimport numpy as np\nfrom numpy.core._rational_tests import rational\nfrom numpy.core._multiarray_tests import create_custom_field_dtype\nfrom numpy.testing import (\n    assert_, assert_equal, assert_array_equal, assert_raises, HAS_REFCOUNT)\nfrom numpy.compat import pickle\nfrom itertools import permutations\n\ndef assert_dtype_equal(a, b):\n    assert_equal(a, b)\n    assert_equal(hash(a), hash(b),\n                 \"two equivalent types do not hash to the same value !\")\n\ndef assert_dtype_not_equal(a, b):\n    assert_(a != b)\n    assert_(hash(a) != hash(b),\n            \"two different types hash to the same value !\")\n\nclass TestBuiltin:\n    @pytest.mark.parametrize('t', [int, float, complex, np.int32, str, object,\n                                   np.compat.unicode])\n    def test_run(self, t):\n        \"\"\"Only test hash runs at all.\"\"\"\n        dt = np.dtype(t)\n        hash(dt)\n\n    @pytest.mark.parametrize('t', [int, float])\n    def test_dtype(self, t):\n        # Make sure equivalent byte order char hash the same (e.g. < and = on\n        # little endian)\n        dt = np.dtype(t)\n        dt2 = dt.newbyteorder(\"<\")\n        dt3 = dt.newbyteorder(\">\")\n        if dt == dt2:\n            assert_(dt.byteorder != dt2.byteorder, \"bogus test\")\n            assert_dtype_equal(dt, dt2)\n        else:\n            assert_(dt.byteorder != dt3.byteorder, \"bogus test\")\n            assert_dtype_equal(dt, dt3)\n\n    def test_equivalent_dtype_hashing(self):\n        # Make sure equivalent dtypes with different type num hash equal\n        uintp = np.dtype(np.uintp)\n        if uintp.itemsize == 4:\n            left = uintp\n            right = np.dtype(np.uint32)\n        else:\n            left = uintp\n            right = np.dtype(np.ulonglong)\n        assert_(left == right)\n        assert_(hash(left) == hash(right))\n\n    def test_invalid_types(self):\n        # Make sure invalid type strings raise an error\n\n        assert_raises(TypeError, np.dtype, 'O3')\n        assert_raises(TypeError, np.dtype, 'O5')\n        assert_raises(TypeError, np.dtype, 'O7')\n        assert_raises(TypeError, np.dtype, 'b3')\n        assert_raises(TypeError, np.dtype, 'h4')\n        assert_raises(TypeError, np.dtype, 'I5')\n        assert_raises(TypeError, np.dtype, 'e3')\n        assert_raises(TypeError, np.dtype, 'f5')\n\n        if np.dtype('g').itemsize == 8 or np.dtype('g').itemsize == 16:\n            assert_raises(TypeError, np.dtype, 'g12')\n        elif np.dtype('g').itemsize == 12:\n            assert_raises(TypeError, np.dtype, 'g16')\n\n        if np.dtype('l').itemsize == 8:\n            assert_raises(TypeError, np.dtype, 'l4')\n            assert_raises(TypeError, np.dtype, 'L4')\n        else:\n            assert_raises(TypeError, np.dtype, 'l8')\n            assert_raises(TypeError, np.dtype, 'L8')\n\n        if np.dtype('q').itemsize == 8:\n            assert_raises(TypeError, np.dtype, 'q4')\n            assert_raises(TypeError, np.dtype, 'Q4')\n        else:\n            assert_raises(TypeError, np.dtype, 'q8')\n            assert_raises(TypeError, np.dtype, 'Q8')\n\n    def test_richcompare_invalid_dtype_equality(self):\n        # Make sure objects that cannot be converted to valid\n        # dtypes results in False/True when compared to valid dtypes.\n        # Here 7 cannot be converted to dtype. No exceptions should be raised\n\n        assert not np.dtype(np.int32) == 7, \"dtype richcompare failed for ==\"\n        assert np.dtype(np.int32) != 7, \"dtype richcompare failed for !=\"\n\n    @pytest.mark.parametrize(\n        'operation',\n        [operator.le, operator.lt, operator.ge, operator.gt])\n    def test_richcompare_invalid_dtype_comparison(self, operation):\n        # Make sure TypeError is raised for comparison operators\n        # for invalid dtypes. Here 7 is an invalid dtype.\n\n        with pytest.raises(TypeError):\n            operation(np.dtype(np.int32), 7)\n\n    @pytest.mark.parametrize(\"dtype\",\n             ['Bool', 'Complex32', 'Complex64', 'Float16', 'Float32', 'Float64',\n              'Int8', 'Int16', 'Int32', 'Int64', 'Object0', 'Timedelta64',\n              'UInt8', 'UInt16', 'UInt32', 'UInt64', 'Void0',\n              \"Float128\", \"Complex128\"])\n    def test_numeric_style_types_are_invalid(self, dtype):\n        with assert_raises(TypeError):\n            np.dtype(dtype)\n\n    @pytest.mark.parametrize(\n        'value',\n        ['m8', 'M8', 'datetime64', 'timedelta64',\n         'i4, (2,3)f8, f4', 'a3, 3u8, (3,4)a10',\n         '>f', '<f', '=f', '|f',\n        ])\n    def test_dtype_bytes_str_equivalence(self, value):\n        bytes_value = value.encode('ascii')\n        from_bytes = np.dtype(bytes_value)\n        from_str = np.dtype(value)\n        assert_dtype_equal(from_bytes, from_str)\n\n    def test_dtype_from_bytes(self):\n        # Empty bytes object\n        assert_raises(TypeError, np.dtype, b'')\n        # Byte order indicator, but no type\n        assert_raises(TypeError, np.dtype, b'|')\n\n        # Single character with ordinal < NPY_NTYPES returns\n        # type by index into _builtin_descrs\n        assert_dtype_equal(np.dtype(bytes([0])), np.dtype('bool'))\n        assert_dtype_equal(np.dtype(bytes([17])), np.dtype(object))\n\n        # Single character where value is a valid type code\n        assert_dtype_equal(np.dtype(b'f'), np.dtype('float32'))\n\n        # Bytes with non-ascii values raise errors\n        assert_raises(TypeError, np.dtype, b'\\xff')\n        assert_raises(TypeError, np.dtype, b's\\xff')\n\n    def test_bad_param(self):\n        # Can't give a size that's too small\n        assert_raises(ValueError, np.dtype,\n                        {'names':['f0', 'f1'],\n                         'formats':['i4', 'i1'],\n                         'offsets':[0, 4],\n                         'itemsize':4})\n        # If alignment is enabled, the alignment (4) must divide the itemsize\n        assert_raises(ValueError, np.dtype,\n                        {'names':['f0', 'f1'],\n                         'formats':['i4', 'i1'],\n                         'offsets':[0, 4],\n                         'itemsize':9}, align=True)\n        # If alignment is enabled, the individual fields must be aligned\n        assert_raises(ValueError, np.dtype,\n                        {'names':['f0', 'f1'],\n                         'formats':['i1', 'f4'],\n                         'offsets':[0, 2]}, align=True)\n\n    def test_field_order_equality(self):\n        x = np.dtype({'names': ['A', 'B'],\n                      'formats': ['i4', 'f4'],\n                      'offsets': [0, 4]})\n        y = np.dtype({'names': ['B', 'A'],\n                      'formats': ['f4', 'i4'],\n                      'offsets': [4, 0]})\n        assert_equal(x == y, False)\n        # But it is currently an equivalent cast:\n        assert np.can_cast(x, y, casting=\"equiv\")\n\n\nclass TestRecord:\n    def test_equivalent_record(self):\n        \"\"\"Test whether equivalent record dtypes hash the same.\"\"\"\n        a = np.dtype([('yo', int)])\n        b = np.dtype([('yo', int)])\n        assert_dtype_equal(a, b)\n\n    def test_different_names(self):\n        # In theory, they may hash the same (collision) ?\n        a = np.dtype([('yo', int)])\n        b = np.dtype([('ye', int)])\n        assert_dtype_not_equal(a, b)\n\n    def test_different_titles(self):\n        # In theory, they may hash the same (collision) ?\n        a = np.dtype({'names': ['r', 'b'],\n                      'formats': ['u1', 'u1'],\n                      'titles': ['Red pixel', 'Blue pixel']})\n        b = np.dtype({'names': ['r', 'b'],\n                      'formats': ['u1', 'u1'],\n                      'titles': ['RRed pixel', 'Blue pixel']})\n        assert_dtype_not_equal(a, b)\n\n    @pytest.mark.skipif(not HAS_REFCOUNT, reason=\"Python lacks refcounts\")\n    def test_refcount_dictionary_setting(self):\n        names = [\"name1\"]\n        formats = [\"f8\"]\n        titles = [\"t1\"]\n        offsets = [0]\n        d = dict(names=names, formats=formats, titles=titles, offsets=offsets)\n        refcounts = {k: sys.getrefcount(i) for k, i in d.items()}\n        np.dtype(d)\n        refcounts_new = {k: sys.getrefcount(i) for k, i in d.items()}\n        assert refcounts == refcounts_new\n\n    def test_mutate(self):\n        # Mutating a dtype should reset the cached hash value\n        a = np.dtype([('yo', int)])\n        b = np.dtype([('yo', int)])\n        c = np.dtype([('ye', int)])\n        assert_dtype_equal(a, b)\n        assert_dtype_not_equal(a, c)\n        a.names = ['ye']\n        assert_dtype_equal(a, c)\n        assert_dtype_not_equal(a, b)\n        state = b.__reduce__()[2]\n        a.__setstate__(state)\n        assert_dtype_equal(a, b)\n        assert_dtype_not_equal(a, c)\n\n    def test_not_lists(self):\n        \"\"\"Test if an appropriate exception is raised when passing bad values to\n        the dtype constructor.\n        \"\"\"\n        assert_raises(TypeError, np.dtype,\n                      dict(names={'A', 'B'}, formats=['f8', 'i4']))\n        assert_raises(TypeError, np.dtype,\n                      dict(names=['A', 'B'], formats={'f8', 'i4'}))\n\n    def test_aligned_size(self):\n        # Check that structured dtypes get padded to an aligned size\n        dt = np.dtype('i4, i1', align=True)\n        assert_equal(dt.itemsize, 8)\n        dt = np.dtype([('f0', 'i4'), ('f1', 'i1')], align=True)\n        assert_equal(dt.itemsize, 8)\n        dt = np.dtype({'names':['f0', 'f1'],\n                       'formats':['i4', 'u1'],\n                       'offsets':[0, 4]}, align=True)\n        assert_equal(dt.itemsize, 8)\n        dt = np.dtype({'f0': ('i4', 0), 'f1':('u1', 4)}, align=True)\n        assert_equal(dt.itemsize, 8)\n        # Nesting should preserve that alignment\n        dt1 = np.dtype([('f0', 'i4'),\n                       ('f1', [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')]),\n                       ('f2', 'i1')], align=True)\n        assert_equal(dt1.itemsize, 20)\n        dt2 = np.dtype({'names':['f0', 'f1', 'f2'],\n                       'formats':['i4',\n                                  [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')],\n                                  'i1'],\n                       'offsets':[0, 4, 16]}, align=True)\n        assert_equal(dt2.itemsize, 20)\n        dt3 = np.dtype({'f0': ('i4', 0),\n                       'f1': ([('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')], 4),\n                       'f2': ('i1', 16)}, align=True)\n        assert_equal(dt3.itemsize, 20)\n        assert_equal(dt1, dt2)\n        assert_equal(dt2, dt3)\n        # Nesting should preserve packing\n        dt1 = np.dtype([('f0', 'i4'),\n                       ('f1', [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')]),\n                       ('f2', 'i1')], align=False)\n        assert_equal(dt1.itemsize, 11)\n        dt2 = np.dtype({'names':['f0', 'f1', 'f2'],\n                       'formats':['i4',\n                                  [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')],\n                                  'i1'],\n                       'offsets':[0, 4, 10]}, align=False)\n        assert_equal(dt2.itemsize, 11)\n        dt3 = np.dtype({'f0': ('i4', 0),\n                       'f1': ([('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')], 4),\n                       'f2': ('i1', 10)}, align=False)\n        assert_equal(dt3.itemsize, 11)\n        assert_equal(dt1, dt2)\n        assert_equal(dt2, dt3)\n        # Array of subtype should preserve alignment\n        dt1 = np.dtype([('a', '|i1'),\n                        ('b', [('f0', '<i2'),\n                        ('f1', '<f4')], 2)], align=True)\n        assert_equal(dt1.descr, [('a', '|i1'), ('', '|V3'),\n                                 ('b', [('f0', '<i2'), ('', '|V2'),\n                                 ('f1', '<f4')], (2,))])\n\n    def test_union_struct(self):\n        # Should be able to create union dtypes\n        dt = np.dtype({'names':['f0', 'f1', 'f2'], 'formats':['<u4', '<u2', '<u2'],\n                        'offsets':[0, 0, 2]}, align=True)\n        assert_equal(dt.itemsize, 4)\n        a = np.array([3], dtype='<u4').view(dt)\n        a['f1'] = 10\n        a['f2'] = 36\n        assert_equal(a['f0'], 10 + 36*256*256)\n        # Should be able to specify fields out of order\n        dt = np.dtype({'names':['f0', 'f1', 'f2'], 'formats':['<u4', '<u2', '<u2'],\n                        'offsets':[4, 0, 2]}, align=True)\n        assert_equal(dt.itemsize, 8)\n        # field name should not matter: assignment is by position\n        dt2 = np.dtype({'names':['f2', 'f0', 'f1'],\n                        'formats':['<u4', '<u2', '<u2'],\n                        'offsets':[4, 0, 2]}, align=True)\n        vals = [(0, 1, 2), (3, -1, 4)]\n        vals2 = [(0, 1, 2), (3, -1, 4)]\n        a = np.array(vals, dt)\n        b = np.array(vals2, dt2)\n        assert_equal(a.astype(dt2), b)\n        assert_equal(b.astype(dt), a)\n        assert_equal(a.view(dt2), b)\n        assert_equal(b.view(dt), a)\n        # Should not be able to overlap objects with other types\n        assert_raises(TypeError, np.dtype,\n                {'names':['f0', 'f1'],\n                 'formats':['O', 'i1'],\n                 'offsets':[0, 2]})\n        assert_raises(TypeError, np.dtype,\n                {'names':['f0', 'f1'],\n                 'formats':['i4', 'O'],\n                 'offsets':[0, 3]})\n        assert_raises(TypeError, np.dtype,\n                {'names':['f0', 'f1'],\n                 'formats':[[('a', 'O')], 'i1'],\n                 'offsets':[0, 2]})\n        assert_raises(TypeError, np.dtype,\n                {'names':['f0', 'f1'],\n                 'formats':['i4', [('a', 'O')]],\n                 'offsets':[0, 3]})\n        # Out of order should still be ok, however\n        dt = np.dtype({'names':['f0', 'f1'],\n                       'formats':['i1', 'O'],\n                       'offsets':[np.dtype('intp').itemsize, 0]})\n\n    @pytest.mark.parametrize([\"obj\", \"dtype\", \"expected\"],\n        [([], (\"(2)f4,\"), np.empty((0, 2), dtype=\"f4\")),\n         (3, \"(3)f4,\", [3, 3, 3]),\n         (np.float64(2), \"(2)f4,\", [2, 2]),\n         ([((0, 1), (1, 2)), ((2,),)], '(2,2)f4', None),\n         ([\"1\", \"2\"], \"(2)i,\", None)])\n    def test_subarray_list(self, obj, dtype, expected):\n        dtype = np.dtype(dtype)\n        res = np.array(obj, dtype=dtype)\n\n        if expected is None:\n            # iterate the 1-d list to fill the array\n            expected = np.empty(len(obj), dtype=dtype)\n            for i in range(len(expected)):\n                expected[i] = obj[i]\n\n        assert_array_equal(res, expected)\n\n    def test_comma_datetime(self):\n        dt = np.dtype('M8[D],datetime64[Y],i8')\n        assert_equal(dt, np.dtype([('f0', 'M8[D]'),\n                                   ('f1', 'datetime64[Y]'),\n                                   ('f2', 'i8')]))\n\n    def test_from_dictproxy(self):\n        # Tests for PR #5920\n        dt = np.dtype({'names': ['a', 'b'], 'formats': ['i4', 'f4']})\n        assert_dtype_equal(dt, np.dtype(dt.fields))\n        dt2 = np.dtype((np.void, dt.fields))\n        assert_equal(dt2.fields, dt.fields)\n\n    def test_from_dict_with_zero_width_field(self):\n        # Regression test for #6430 / #2196\n        dt = np.dtype([('val1', np.float32, (0,)), ('val2', int)])\n        dt2 = np.dtype({'names': ['val1', 'val2'],\n                        'formats': [(np.float32, (0,)), int]})\n\n        assert_dtype_equal(dt, dt2)\n        assert_equal(dt.fields['val1'][0].itemsize, 0)\n        assert_equal(dt.itemsize, dt.fields['val2'][0].itemsize)\n\n    def test_bool_commastring(self):\n        d = np.dtype('?,?,?')  # raises?\n        assert_equal(len(d.names), 3)\n        for n in d.names:\n            assert_equal(d.fields[n][0], np.dtype('?'))\n\n    def test_nonint_offsets(self):\n        # gh-8059\n        def make_dtype(off):\n            return np.dtype({'names': ['A'], 'formats': ['i4'],\n                             'offsets': [off]})\n\n        assert_raises(TypeError, make_dtype, 'ASD')\n        assert_raises(OverflowError, make_dtype, 2**70)\n        assert_raises(TypeError, make_dtype, 2.3)\n        assert_raises(ValueError, make_dtype, -10)\n\n        # no errors here:\n        dt = make_dtype(np.uint32(0))\n        np.zeros(1, dtype=dt)[0].item()\n\n    def test_fields_by_index(self):\n        dt = np.dtype([('a', np.int8), ('b', np.float32, 3)])\n        assert_dtype_equal(dt[0], np.dtype(np.int8))\n        assert_dtype_equal(dt[1], np.dtype((np.float32, 3)))\n        assert_dtype_equal(dt[-1], dt[1])\n        assert_dtype_equal(dt[-2], dt[0])\n        assert_raises(IndexError, lambda: dt[-3])\n\n        assert_raises(TypeError, operator.getitem, dt, 3.0)\n\n        assert_equal(dt[1], dt[np.int8(1)])\n\n    @pytest.mark.parametrize('align_flag',[False, True])\n    def test_multifield_index(self, align_flag):\n        # indexing with a list produces subfields\n        # the align flag should be preserved\n        dt = np.dtype([\n            (('title', 'col1'), '<U20'), ('A', '<f8'), ('B', '<f8')\n        ], align=align_flag)\n\n        dt_sub = dt[['B', 'col1']]\n        assert_equal(\n            dt_sub,\n            np.dtype({\n                'names': ['B', 'col1'],\n                'formats': ['<f8', '<U20'],\n                'offsets': [88, 0],\n                'titles': [None, 'title'],\n                'itemsize': 96\n            })\n        )\n        assert_equal(dt_sub.isalignedstruct, align_flag)\n\n        dt_sub = dt[['B']]\n        assert_equal(\n            dt_sub,\n            np.dtype({\n                'names': ['B'],\n                'formats': ['<f8'],\n                'offsets': [88],\n                'itemsize': 96\n            })\n        )\n        assert_equal(dt_sub.isalignedstruct, align_flag)\n\n        dt_sub = dt[[]]\n        assert_equal(\n            dt_sub,\n            np.dtype({\n                'names': [],\n                'formats': [],\n                'offsets': [],\n                'itemsize': 96\n            })\n        )\n        assert_equal(dt_sub.isalignedstruct, align_flag)\n\n        assert_raises(TypeError, operator.getitem, dt, ())\n        assert_raises(TypeError, operator.getitem, dt, [1, 2, 3])\n        assert_raises(TypeError, operator.getitem, dt, ['col1', 2])\n        assert_raises(KeyError, operator.getitem, dt, ['fake'])\n        assert_raises(KeyError, operator.getitem, dt, ['title'])\n        assert_raises(ValueError, operator.getitem, dt, ['col1', 'col1'])\n\n    def test_partial_dict(self):\n        # 'names' is missing\n        assert_raises(ValueError, np.dtype,\n                {'formats': ['i4', 'i4'], 'f0': ('i4', 0), 'f1':('i4', 4)})\n\n    def test_fieldless_views(self):\n        a = np.zeros(2, dtype={'names':[], 'formats':[], 'offsets':[],\n                               'itemsize':8})\n        assert_raises(ValueError, a.view, np.dtype([]))\n\n        d = np.dtype((np.dtype([]), 10))\n        assert_equal(d.shape, (10,))\n        assert_equal(d.itemsize, 0)\n        assert_equal(d.base, np.dtype([]))\n\n        arr = np.fromiter((() for i in range(10)), [])\n        assert_equal(arr.dtype, np.dtype([]))\n        assert_raises(ValueError, np.frombuffer, b'', dtype=[])\n        assert_equal(np.frombuffer(b'', dtype=[], count=2),\n                     np.empty(2, dtype=[]))\n\n        assert_raises(ValueError, np.dtype, ([], 'f8'))\n        assert_raises(ValueError, np.zeros(1, dtype='i4').view, [])\n\n        assert_equal(np.zeros(2, dtype=[]) == np.zeros(2, dtype=[]),\n                     np.ones(2, dtype=bool))\n\n        assert_equal(np.zeros((1, 2), dtype=[]) == a,\n                     np.ones((1, 2), dtype=bool))\n\n\nclass TestSubarray:\n    def test_single_subarray(self):\n        a = np.dtype((int, (2)))\n        b = np.dtype((int, (2,)))\n        assert_dtype_equal(a, b)\n\n        assert_equal(type(a.subdtype[1]), tuple)\n        assert_equal(type(b.subdtype[1]), tuple)\n\n    def test_equivalent_record(self):\n        \"\"\"Test whether equivalent subarray dtypes hash the same.\"\"\"\n        a = np.dtype((int, (2, 3)))\n        b = np.dtype((int, (2, 3)))\n        assert_dtype_equal(a, b)\n\n    def test_nonequivalent_record(self):\n        \"\"\"Test whether different subarray dtypes hash differently.\"\"\"\n        a = np.dtype((int, (2, 3)))\n        b = np.dtype((int, (3, 2)))\n        assert_dtype_not_equal(a, b)\n\n        a = np.dtype((int, (2, 3)))\n        b = np.dtype((int, (2, 2)))\n        assert_dtype_not_equal(a, b)\n\n        a = np.dtype((int, (1, 2, 3)))\n        b = np.dtype((int, (1, 2)))\n        assert_dtype_not_equal(a, b)\n\n    def test_shape_equal(self):\n        \"\"\"Test some data types that are equal\"\"\"\n        assert_dtype_equal(np.dtype('f8'), np.dtype(('f8', tuple())))\n        # FutureWarning during deprecation period; after it is passed this\n        # should instead check that \"(1)f8\" == \"1f8\" == (\"f8\", 1).\n        with pytest.warns(FutureWarning):\n            assert_dtype_equal(np.dtype('f8'), np.dtype(('f8', 1)))\n        assert_dtype_equal(np.dtype((int, 2)), np.dtype((int, (2,))))\n        assert_dtype_equal(np.dtype(('<f4', (3, 2))), np.dtype(('<f4', (3, 2))))\n        d = ([('a', 'f4', (1, 2)), ('b', 'f8', (3, 1))], (3, 2))\n        assert_dtype_equal(np.dtype(d), np.dtype(d))\n\n    def test_shape_simple(self):\n        \"\"\"Test some simple cases that shouldn't be equal\"\"\"\n        assert_dtype_not_equal(np.dtype('f8'), np.dtype(('f8', (1,))))\n        assert_dtype_not_equal(np.dtype(('f8', (1,))), np.dtype(('f8', (1, 1))))\n        assert_dtype_not_equal(np.dtype(('f4', (3, 2))), np.dtype(('f4', (2, 3))))\n\n    def test_shape_monster(self):\n        \"\"\"Test some more complicated cases that shouldn't be equal\"\"\"\n        assert_dtype_not_equal(\n            np.dtype(([('a', 'f4', (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),\n            np.dtype(([('a', 'f4', (1, 2)), ('b', 'f8', (1, 3))], (2, 2))))\n        assert_dtype_not_equal(\n            np.dtype(([('a', 'f4', (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),\n            np.dtype(([('a', 'f4', (2, 1)), ('b', 'i8', (1, 3))], (2, 2))))\n        assert_dtype_not_equal(\n            np.dtype(([('a', 'f4', (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),\n            np.dtype(([('e', 'f8', (1, 3)), ('d', 'f4', (2, 1))], (2, 2))))\n        assert_dtype_not_equal(\n            np.dtype(([('a', [('a', 'i4', 6)], (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),\n            np.dtype(([('a', [('a', 'u4', 6)], (2, 1)), ('b', 'f8', (1, 3))], (2, 2))))\n\n    def test_shape_sequence(self):\n        # Any sequence of integers should work as shape, but the result\n        # should be a tuple (immutable) of base type integers.\n        a = np.array([1, 2, 3], dtype=np.int16)\n        l = [1, 2, 3]\n        # Array gets converted\n        dt = np.dtype([('a', 'f4', a)])\n        assert_(isinstance(dt['a'].shape, tuple))\n        assert_(isinstance(dt['a'].shape[0], int))\n        # List gets converted\n        dt = np.dtype([('a', 'f4', l)])\n        assert_(isinstance(dt['a'].shape, tuple))\n        #\n\n        class IntLike:\n            def __index__(self):\n                return 3\n\n            def __int__(self):\n                # (a PyNumber_Check fails without __int__)\n                return 3\n\n        dt = np.dtype([('a', 'f4', IntLike())])\n        assert_(isinstance(dt['a'].shape, tuple))\n        assert_(isinstance(dt['a'].shape[0], int))\n        dt = np.dtype([('a', 'f4', (IntLike(),))])\n        assert_(isinstance(dt['a'].shape, tuple))\n        assert_(isinstance(dt['a'].shape[0], int))\n\n    def test_shape_matches_ndim(self):\n        dt = np.dtype([('a', 'f4', ())])\n        assert_equal(dt['a'].shape, ())\n        assert_equal(dt['a'].ndim, 0)\n\n        dt = np.dtype([('a', 'f4')])\n        assert_equal(dt['a'].shape, ())\n        assert_equal(dt['a'].ndim, 0)\n\n        dt = np.dtype([('a', 'f4', 4)])\n        assert_equal(dt['a'].shape, (4,))\n        assert_equal(dt['a'].ndim, 1)\n\n        dt = np.dtype([('a', 'f4', (1, 2, 3))])\n        assert_equal(dt['a'].shape, (1, 2, 3))\n        assert_equal(dt['a'].ndim, 3)\n\n    def test_shape_invalid(self):\n        # Check that the shape is valid.\n        max_int = np.iinfo(np.intc).max\n        max_intp = np.iinfo(np.intp).max\n        # Too large values (the datatype is part of this)\n        assert_raises(ValueError, np.dtype, [('a', 'f4', max_int // 4 + 1)])\n        assert_raises(ValueError, np.dtype, [('a', 'f4', max_int + 1)])\n        assert_raises(ValueError, np.dtype, [('a', 'f4', (max_int, 2))])\n        # Takes a different code path (fails earlier:\n        assert_raises(ValueError, np.dtype, [('a', 'f4', max_intp + 1)])\n        # Negative values\n        assert_raises(ValueError, np.dtype, [('a', 'f4', -1)])\n        assert_raises(ValueError, np.dtype, [('a', 'f4', (-1, -1))])\n\n    def test_alignment(self):\n        #Check that subarrays are aligned\n        t1 = np.dtype('(1,)i4', align=True)\n        t2 = np.dtype('2i4', align=True)\n        assert_equal(t1.alignment, t2.alignment)\n\n\ndef iter_struct_object_dtypes():\n    \"\"\"\n    Iterates over a few complex dtypes and object pattern which\n    fill the array with a given object (defaults to a singleton).\n\n    Yields\n    ------\n    dtype : dtype\n    pattern : tuple\n        Structured tuple for use with `np.array`.\n    count : int\n        Number of objects stored in the dtype.\n    singleton : object\n        A singleton object. The returned pattern is constructed so that\n        all objects inside the datatype are set to the singleton.\n    \"\"\"\n    obj = object()\n\n    dt = np.dtype([('b', 'O', (2, 3))])\n    p = ([[obj] * 3] * 2,)\n    yield pytest.param(dt, p, 6, obj, id=\"<subarray>\")\n\n    dt = np.dtype([('a', 'i4'), ('b', 'O', (2, 3))])\n    p = (0, [[obj] * 3] * 2)\n    yield pytest.param(dt, p, 6, obj, id=\"<subarray in field>\")\n\n    dt = np.dtype([('a', 'i4'),\n                   ('b', [('ba', 'O'), ('bb', 'i1')], (2, 3))])\n    p = (0, [[(obj, 0)] * 3] * 2)\n    yield pytest.param(dt, p, 6, obj, id=\"<structured subarray 1>\")\n\n    dt = np.dtype([('a', 'i4'),\n                   ('b', [('ba', 'O'), ('bb', 'O')], (2, 3))])\n    p = (0, [[(obj, obj)] * 3] * 2)\n    yield pytest.param(dt, p, 12, obj, id=\"<structured subarray 2>\")\n\n\n@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"Python lacks refcounts\")\nclass TestStructuredObjectRefcounting:\n    \"\"\"These tests cover various uses of complicated structured types which\n    include objects and thus require reference counting.\n    \"\"\"\n    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],\n                             iter_struct_object_dtypes())\n    @pytest.mark.parametrize([\"creation_func\", \"creation_obj\"], [\n        pytest.param(np.empty, None,\n             # None is probably used for too many things\n             marks=pytest.mark.skip(\"unreliable due to python's behaviour\")),\n        (np.ones, 1),\n        (np.zeros, 0)])\n    def test_structured_object_create_delete(self, dt, pat, count, singleton,\n                                             creation_func, creation_obj):\n        \"\"\"Structured object reference counting in creation and deletion\"\"\"\n        # The test assumes that 0, 1, and None are singletons.\n        gc.collect()\n        before = sys.getrefcount(creation_obj)\n        arr = creation_func(3, dt)\n\n        now = sys.getrefcount(creation_obj)\n        assert now - before == count * 3\n        del arr\n        now = sys.getrefcount(creation_obj)\n        assert now == before\n\n    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],\n                             iter_struct_object_dtypes())\n    def test_structured_object_item_setting(self, dt, pat, count, singleton):\n        \"\"\"Structured object reference counting for simple item setting\"\"\"\n        one = 1\n\n        gc.collect()\n        before = sys.getrefcount(singleton)\n        arr = np.array([pat] * 3, dt)\n        assert sys.getrefcount(singleton) - before == count * 3\n        # Fill with `1` and check that it was replaced correctly:\n        before2 = sys.getrefcount(one)\n        arr[...] = one\n        after2 = sys.getrefcount(one)\n        assert after2 - before2 == count * 3\n        del arr\n        gc.collect()\n        assert sys.getrefcount(one) == before2\n        assert sys.getrefcount(singleton) == before\n\n    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],\n                             iter_struct_object_dtypes())\n    @pytest.mark.parametrize(\n        ['shape', 'index', 'items_changed'],\n        [((3,), ([0, 2],), 2),\n         ((3, 2), ([0, 2], slice(None)), 4),\n         ((3, 2), ([0, 2], [1]), 2),\n         ((3,), ([True, False, True]), 2)])\n    def test_structured_object_indexing(self, shape, index, items_changed,\n                                        dt, pat, count, singleton):\n        \"\"\"Structured object reference counting for advanced indexing.\"\"\"\n        zero = 0\n        one = 1\n\n        arr = np.zeros(shape, dt)\n\n        gc.collect()\n        before_zero = sys.getrefcount(zero)\n        before_one = sys.getrefcount(one)\n        # Test item getting:\n        part = arr[index]\n        after_zero = sys.getrefcount(zero)\n        assert after_zero - before_zero == count * items_changed\n        del part\n        # Test item setting:\n        arr[index] = one\n        gc.collect()\n        after_zero = sys.getrefcount(zero)\n        after_one = sys.getrefcount(one)\n        assert before_zero - after_zero == count * items_changed\n        assert after_one - before_one == count * items_changed\n\n    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],\n                             iter_struct_object_dtypes())\n    def test_structured_object_take_and_repeat(self, dt, pat, count, singleton):\n        \"\"\"Structured object reference counting for specialized functions.\n        The older functions such as take and repeat use different code paths\n        then item setting (when writing this).\n        \"\"\"\n        indices = [0, 1]\n\n        arr = np.array([pat] * 3, dt)\n        gc.collect()\n        before = sys.getrefcount(singleton)\n        res = arr.take(indices)\n        after = sys.getrefcount(singleton)\n        assert after - before == count * 2\n        new = res.repeat(10)\n        gc.collect()\n        after_repeat = sys.getrefcount(singleton)\n        assert after_repeat - after == count * 2 * 10\n\n\nclass TestStructuredDtypeSparseFields:\n    \"\"\"Tests subarray fields which contain sparse dtypes so that\n    not all memory is used by the dtype work. Such dtype's should\n    leave the underlying memory unchanged.\n    \"\"\"\n    dtype = np.dtype([('a', {'names':['aa', 'ab'], 'formats':['f', 'f'],\n                             'offsets':[0, 4]}, (2, 3))])\n    sparse_dtype = np.dtype([('a', {'names':['ab'], 'formats':['f'],\n                                    'offsets':[4]}, (2, 3))])\n\n    def test_sparse_field_assignment(self):\n        arr = np.zeros(3, self.dtype)\n        sparse_arr = arr.view(self.sparse_dtype)\n\n        sparse_arr[...] = np.finfo(np.float32).max\n        # dtype is reduced when accessing the field, so shape is (3, 2, 3):\n        assert_array_equal(arr[\"a\"][\"aa\"], np.zeros((3, 2, 3)))\n\n    def test_sparse_field_assignment_fancy(self):\n        # Fancy assignment goes to the copyswap function for complex types:\n        arr = np.zeros(3, self.dtype)\n        sparse_arr = arr.view(self.sparse_dtype)\n\n        sparse_arr[[0, 1, 2]] = np.finfo(np.float32).max\n        # dtype is reduced when accessing the field, so shape is (3, 2, 3):\n        assert_array_equal(arr[\"a\"][\"aa\"], np.zeros((3, 2, 3)))\n\n\nclass TestMonsterType:\n    \"\"\"Test deeply nested subtypes.\"\"\"\n\n    def test1(self):\n        simple1 = np.dtype({'names': ['r', 'b'], 'formats': ['u1', 'u1'],\n            'titles': ['Red pixel', 'Blue pixel']})\n        a = np.dtype([('yo', int), ('ye', simple1),\n            ('yi', np.dtype((int, (3, 2))))])\n        b = np.dtype([('yo', int), ('ye', simple1),\n            ('yi', np.dtype((int, (3, 2))))])\n        assert_dtype_equal(a, b)\n\n        c = np.dtype([('yo', int), ('ye', simple1),\n            ('yi', np.dtype((a, (3, 2))))])\n        d = np.dtype([('yo', int), ('ye', simple1),\n            ('yi', np.dtype((a, (3, 2))))])\n        assert_dtype_equal(c, d)\n\n    def test_list_recursion(self):\n        l = list()\n        l.append(('f', l))\n        with pytest.raises(RecursionError):\n            np.dtype(l)\n\n    def test_tuple_recursion(self):\n        d = np.int32\n        for i in range(100000):\n            d = (d, (1,))\n        with pytest.raises(RecursionError):\n            np.dtype(d)\n\n    def test_dict_recursion(self):\n        d = dict(names=['self'], formats=[None], offsets=[0])\n        d['formats'][0] = d\n        with pytest.raises(RecursionError):\n            np.dtype(d)\n\n\nclass TestMetadata:\n    def test_no_metadata(self):\n        d = np.dtype(int)\n        assert_(d.metadata is None)\n\n    def test_metadata_takes_dict(self):\n        d = np.dtype(int, metadata={'datum': 1})\n        assert_(d.metadata == {'datum': 1})\n\n    def test_metadata_rejects_nondict(self):\n        assert_raises(TypeError, np.dtype, int, metadata='datum')\n        assert_raises(TypeError, np.dtype, int, metadata=1)\n        assert_raises(TypeError, np.dtype, int, metadata=None)\n\n    def test_nested_metadata(self):\n        d = np.dtype([('a', np.dtype(int, metadata={'datum': 1}))])\n        assert_(d['a'].metadata == {'datum': 1})\n\n    def test_base_metadata_copied(self):\n        d = np.dtype((np.void, np.dtype('i4,i4', metadata={'datum': 1})))\n        assert_(d.metadata == {'datum': 1})\n\nclass TestString:\n    def test_complex_dtype_str(self):\n        dt = np.dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)),\n                                ('rtile', '>f4', (64, 36))], (3,)),\n                       ('bottom', [('bleft', ('>f4', (8, 64)), (1,)),\n                                   ('bright', '>f4', (8, 36))])])\n        assert_equal(str(dt),\n                     \"[('top', [('tiles', ('>f4', (64, 64)), (1,)), \"\n                     \"('rtile', '>f4', (64, 36))], (3,)), \"\n                     \"('bottom', [('bleft', ('>f4', (8, 64)), (1,)), \"\n                     \"('bright', '>f4', (8, 36))])]\")\n\n        # If the sticky aligned flag is set to True, it makes the\n        # str() function use a dict representation with an 'aligned' flag\n        dt = np.dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)),\n                                ('rtile', '>f4', (64, 36))],\n                                (3,)),\n                       ('bottom', [('bleft', ('>f4', (8, 64)), (1,)),\n                                   ('bright', '>f4', (8, 36))])],\n                       align=True)\n        assert_equal(str(dt),\n                    \"{'names':['top','bottom'], \"\n                     \"'formats':[([('tiles', ('>f4', (64, 64)), (1,)), \"\n                                  \"('rtile', '>f4', (64, 36))], (3,)),\"\n                                 \"[('bleft', ('>f4', (8, 64)), (1,)), \"\n                                  \"('bright', '>f4', (8, 36))]], \"\n                     \"'offsets':[0,76800], \"\n                     \"'itemsize':80000, \"\n                     \"'aligned':True}\")\n        assert_equal(np.dtype(eval(str(dt))), dt)\n\n        dt = np.dtype({'names': ['r', 'g', 'b'], 'formats': ['u1', 'u1', 'u1'],\n                        'offsets': [0, 1, 2],\n                        'titles': ['Red pixel', 'Green pixel', 'Blue pixel']})\n        assert_equal(str(dt),\n                    \"[(('Red pixel', 'r'), 'u1'), \"\n                    \"(('Green pixel', 'g'), 'u1'), \"\n                    \"(('Blue pixel', 'b'), 'u1')]\")\n\n        dt = np.dtype({'names': ['rgba', 'r', 'g', 'b'],\n                       'formats': ['<u4', 'u1', 'u1', 'u1'],\n                       'offsets': [0, 0, 1, 2],\n                       'titles': ['Color', 'Red pixel',\n                                  'Green pixel', 'Blue pixel']})\n        assert_equal(str(dt),\n                    \"{'names':['rgba','r','g','b'],\"\n                    \" 'formats':['<u4','u1','u1','u1'],\"\n                    \" 'offsets':[0,0,1,2],\"\n                    \" 'titles':['Color','Red pixel',\"\n                              \"'Green pixel','Blue pixel'],\"\n                    \" 'itemsize':4}\")\n\n        dt = np.dtype({'names': ['r', 'b'], 'formats': ['u1', 'u1'],\n                        'offsets': [0, 2],\n                        'titles': ['Red pixel', 'Blue pixel']})\n        assert_equal(str(dt),\n                    \"{'names':['r','b'],\"\n                    \" 'formats':['u1','u1'],\"\n                    \" 'offsets':[0,2],\"\n                    \" 'titles':['Red pixel','Blue pixel'],\"\n                    \" 'itemsize':3}\")\n\n        dt = np.dtype([('a', '<m8[D]'), ('b', '<M8[us]')])\n        assert_equal(str(dt),\n                    \"[('a', '<m8[D]'), ('b', '<M8[us]')]\")\n\n    def test_repr_structured(self):\n        dt = np.dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)),\n                                ('rtile', '>f4', (64, 36))], (3,)),\n                       ('bottom', [('bleft', ('>f4', (8, 64)), (1,)),\n                                   ('bright', '>f4', (8, 36))])])\n        assert_equal(repr(dt),\n                     \"dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)), \"\n                     \"('rtile', '>f4', (64, 36))], (3,)), \"\n                     \"('bottom', [('bleft', ('>f4', (8, 64)), (1,)), \"\n                     \"('bright', '>f4', (8, 36))])])\")\n\n        dt = np.dtype({'names': ['r', 'g', 'b'], 'formats': ['u1', 'u1', 'u1'],\n                        'offsets': [0, 1, 2],\n                        'titles': ['Red pixel', 'Green pixel', 'Blue pixel']},\n                        align=True)\n        assert_equal(repr(dt),\n                    \"dtype([(('Red pixel', 'r'), 'u1'), \"\n                    \"(('Green pixel', 'g'), 'u1'), \"\n                    \"(('Blue pixel', 'b'), 'u1')], align=True)\")\n\n    def test_repr_structured_not_packed(self):\n        dt = np.dtype({'names': ['rgba', 'r', 'g', 'b'],\n                       'formats': ['<u4', 'u1', 'u1', 'u1'],\n                       'offsets': [0, 0, 1, 2],\n                       'titles': ['Color', 'Red pixel',\n                                  'Green pixel', 'Blue pixel']}, align=True)\n        assert_equal(repr(dt),\n                    \"dtype({'names':['rgba','r','g','b'],\"\n                    \" 'formats':['<u4','u1','u1','u1'],\"\n                    \" 'offsets':[0,0,1,2],\"\n                    \" 'titles':['Color','Red pixel',\"\n                              \"'Green pixel','Blue pixel'],\"\n                    \" 'itemsize':4}, align=True)\")\n\n        dt = np.dtype({'names': ['r', 'b'], 'formats': ['u1', 'u1'],\n                        'offsets': [0, 2],\n                        'titles': ['Red pixel', 'Blue pixel'],\n                        'itemsize': 4})\n        assert_equal(repr(dt),\n                    \"dtype({'names':['r','b'], \"\n                    \"'formats':['u1','u1'], \"\n                    \"'offsets':[0,2], \"\n                    \"'titles':['Red pixel','Blue pixel'], \"\n                    \"'itemsize':4})\")\n\n    def test_repr_structured_datetime(self):\n        dt = np.dtype([('a', '<M8[D]'), ('b', '<m8[us]')])\n        assert_equal(repr(dt),\n                    \"dtype([('a', '<M8[D]'), ('b', '<m8[us]')])\")\n\n    def test_repr_str_subarray(self):\n        dt = np.dtype(('<i2', (1,)))\n        assert_equal(repr(dt), \"dtype(('<i2', (1,)))\")\n        assert_equal(str(dt), \"('<i2', (1,))\")\n\n    def test_base_dtype_with_object_type(self):\n        # Issue gh-2798, should not error.\n        np.array(['a'], dtype=\"O\").astype((\"O\", [(\"name\", \"O\")]))\n\n    def test_empty_string_to_object(self):\n        # Pull request #4722\n        np.array([\"\", \"\"]).astype(object)\n\n    def test_void_subclass_unsized(self):\n        dt = np.dtype(np.record)\n        assert_equal(repr(dt), \"dtype('V')\")\n        assert_equal(str(dt), '|V0')\n        assert_equal(dt.name, 'record')\n\n    def test_void_subclass_sized(self):\n        dt = np.dtype((np.record, 2))\n        assert_equal(repr(dt), \"dtype('V2')\")\n        assert_equal(str(dt), '|V2')\n        assert_equal(dt.name, 'record16')\n\n    def test_void_subclass_fields(self):\n        dt = np.dtype((np.record, [('a', '<u2')]))\n        assert_equal(repr(dt), \"dtype((numpy.record, [('a', '<u2')]))\")\n        assert_equal(str(dt), \"(numpy.record, [('a', '<u2')])\")\n        assert_equal(dt.name, 'record16')\n\n\nclass TestDtypeAttributeDeletion:\n\n    def test_dtype_non_writable_attributes_deletion(self):\n        dt = np.dtype(np.double)\n        attr = [\"subdtype\", \"descr\", \"str\", \"name\", \"base\", \"shape\",\n                \"isbuiltin\", \"isnative\", \"isalignedstruct\", \"fields\",\n                \"metadata\", \"hasobject\"]\n\n        for s in attr:\n            assert_raises(AttributeError, delattr, dt, s)\n\n    def test_dtype_writable_attributes_deletion(self):\n        dt = np.dtype(np.double)\n        attr = [\"names\"]\n        for s in attr:\n            assert_raises(AttributeError, delattr, dt, s)\n\n\nclass TestDtypeAttributes:\n    def test_descr_has_trailing_void(self):\n        # see gh-6359\n        dtype = np.dtype({\n            'names': ['A', 'B'],\n            'formats': ['f4', 'f4'],\n            'offsets': [0, 8],\n            'itemsize': 16})\n        new_dtype = np.dtype(dtype.descr)\n        assert_equal(new_dtype.itemsize, 16)\n\n    def test_name_dtype_subclass(self):\n        # Ticket #4357\n        class user_def_subcls(np.void):\n            pass\n        assert_equal(np.dtype(user_def_subcls).name, 'user_def_subcls')\n\n\nclass TestPickling:\n\n    def check_pickling(self, dtype):\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            buf = pickle.dumps(dtype, proto)\n            # The dtype pickling itself pickles `np.dtype` if it is pickled\n            # as a singleton `dtype` should be stored in the buffer:\n            assert b\"_DType_reconstruct\" not in buf\n            assert b\"dtype\" in buf\n            pickled = pickle.loads(buf)\n            assert_equal(pickled, dtype)\n            assert_equal(pickled.descr, dtype.descr)\n            if dtype.metadata is not None:\n                assert_equal(pickled.metadata, dtype.metadata)\n            # Check the reconstructed dtype is functional\n            x = np.zeros(3, dtype=dtype)\n            y = np.zeros(3, dtype=pickled)\n            assert_equal(x, y)\n            assert_equal(x[0], y[0])\n\n    @pytest.mark.parametrize('t', [int, float, complex, np.int32, str, object,\n                                   np.compat.unicode, bool])\n    def test_builtin(self, t):\n        self.check_pickling(np.dtype(t))\n\n    def test_structured(self):\n        dt = np.dtype(([('a', '>f4', (2, 1)), ('b', '<f8', (1, 3))], (2, 2)))\n        self.check_pickling(dt)\n\n    def test_structured_aligned(self):\n        dt = np.dtype('i4, i1', align=True)\n        self.check_pickling(dt)\n\n    def test_structured_unaligned(self):\n        dt = np.dtype('i4, i1', align=False)\n        self.check_pickling(dt)\n\n    def test_structured_padded(self):\n        dt = np.dtype({\n            'names': ['A', 'B'],\n            'formats': ['f4', 'f4'],\n            'offsets': [0, 8],\n            'itemsize': 16})\n        self.check_pickling(dt)\n\n    def test_structured_titles(self):\n        dt = np.dtype({'names': ['r', 'b'],\n                       'formats': ['u1', 'u1'],\n                       'titles': ['Red pixel', 'Blue pixel']})\n        self.check_pickling(dt)\n\n    @pytest.mark.parametrize('base', ['m8', 'M8'])\n    @pytest.mark.parametrize('unit', ['', 'Y', 'M', 'W', 'D', 'h', 'm', 's',\n                                      'ms', 'us', 'ns', 'ps', 'fs', 'as'])\n    def test_datetime(self, base, unit):\n        dt = np.dtype('%s[%s]' % (base, unit) if unit else base)\n        self.check_pickling(dt)\n        if unit:\n            dt = np.dtype('%s[7%s]' % (base, unit))\n            self.check_pickling(dt)\n\n    def test_metadata(self):\n        dt = np.dtype(int, metadata={'datum': 1})\n        self.check_pickling(dt)\n\n    @pytest.mark.parametrize(\"DType\",\n        [type(np.dtype(t)) for t in np.typecodes['All']] +\n        [np.dtype(rational), np.dtype])\n    def test_pickle_types(self, DType):\n        # Check that DTypes (the classes/types) roundtrip when pickling\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            roundtrip_DType = pickle.loads(pickle.dumps(DType, proto))\n            assert roundtrip_DType is DType\n\n\nclass TestPromotion:\n    \"\"\"Test cases related to more complex DType promotions.  Further promotion\n    tests are defined in `test_numeric.py`\n    \"\"\"\n    @pytest.mark.parametrize([\"other\", \"expected\"],\n            [(2**16-1, np.complex64),\n             (2**32-1, np.complex128),\n             (np.float16(2), np.complex64),\n             (np.float32(2), np.complex64),\n             (np.longdouble(2), np.complex64),\n             # Base of the double value to sidestep any rounding issues:\n             (np.longdouble(np.nextafter(1.7e308, 0.)), np.complex128),\n             # Additionally use \"nextafter\" so the cast can't round down:\n             (np.longdouble(np.nextafter(1.7e308, np.inf)), np.clongdouble),\n             # repeat for complex scalars:\n             (np.complex64(2), np.complex64),\n             (np.clongdouble(2), np.complex64),\n             # Base of the double value to sidestep any rounding issues:\n             (np.clongdouble(np.nextafter(1.7e308, 0.) * 1j), np.complex128),\n             # Additionally use \"nextafter\" so the cast can't round down:\n             (np.clongdouble(np.nextafter(1.7e308, np.inf)), np.clongdouble),\n             ])\n    def test_complex_other_value_based(self, other, expected):\n        # This would change if we modify the value based promotion\n        min_complex = np.dtype(np.complex64)\n\n        res = np.result_type(other, min_complex)\n        assert res == expected\n        # Check the same for a simple ufunc call that uses the same logic:\n        res = np.minimum(other, np.ones(3, dtype=min_complex)).dtype\n        assert res == expected\n\n    @pytest.mark.parametrize([\"other\", \"expected\"],\n                 [(np.bool_, np.complex128),\n                  (np.int64, np.complex128),\n                  (np.float16, np.complex64),\n                  (np.float32, np.complex64),\n                  (np.float64, np.complex128),\n                  (np.longdouble, np.clongdouble),\n                  (np.complex64, np.complex64),\n                  (np.complex128, np.complex128),\n                  (np.clongdouble, np.clongdouble),\n                  ])\n    def test_complex_scalar_value_based(self, other, expected):\n        # This would change if we modify the value based promotion\n        complex_scalar = 1j\n\n        res = np.result_type(other, complex_scalar)\n        assert res == expected\n        # Check the same for a simple ufunc call that uses the same logic:\n        res = np.minimum(np.ones(3, dtype=other), complex_scalar).dtype\n        assert res == expected\n\n    def test_complex_pyscalar_promote_rational(self):\n        with pytest.raises(TypeError,\n                match=r\".* do not have a common DType\"):\n            np.result_type(1j, rational)\n\n        with pytest.raises(TypeError,\n                match=r\".* no common DType exists for the given inputs\"):\n            np.result_type(1j, rational(1, 2))\n\n    @pytest.mark.parametrize([\"other\", \"expected\"],\n            [(1, rational), (1., np.float64)])\n    def test_float_int_pyscalar_promote_rational(self, other, expected):\n        # Note that rationals are a bit akward as they promote with float64\n        # or default ints, but not float16 or uint8/int8 (which looks\n        # inconsistent here)\n        with pytest.raises(TypeError,\n                match=r\".* do not have a common DType\"):\n            np.result_type(other, rational)\n\n        assert np.result_type(other, rational(1, 2)) == expected\n\n    @pytest.mark.parametrize([\"dtypes\", \"expected\"], [\n             # These promotions are not associative/commutative:\n             ([np.uint16, np.int16, np.float16], np.float32),\n             ([np.uint16, np.int8, np.float16], np.float32),\n             ([np.uint8, np.int16, np.float16], np.float32),\n             # The following promotions are not ambiguous, but cover code\n             # paths of abstract promotion (no particular logic being tested)\n             ([1, 1, np.float64], np.float64),\n             ([1, 1., np.complex128], np.complex128),\n             ([1, 1j, np.float64], np.complex128),\n             ([1., 1., np.int64], np.float64),\n             ([1., 1j, np.float64], np.complex128),\n             ([1j, 1j, np.float64], np.complex128),\n             ([1, True, np.bool_], np.int_),\n            ])\n    def test_permutations_do_not_influence_result(self, dtypes, expected):\n        # Tests that most permutations do not influence the result.  In the\n        # above some uint and int combintations promote to a larger integer\n        # type, which would then promote to a larger than necessary float.\n        for perm in permutations(dtypes):\n            assert np.result_type(*perm) == expected\n\n\ndef test_rational_dtype():\n    # test for bug gh-5719\n    a = np.array([1111], dtype=rational).astype\n    assert_raises(OverflowError, a, 'int8')\n\n    # test that dtype detection finds user-defined types\n    x = rational(1)\n    assert_equal(np.array([x,x]).dtype, np.dtype(rational))\n\n\ndef test_dtypes_are_true():\n    # test for gh-6294\n    assert bool(np.dtype('f8'))\n    assert bool(np.dtype('i8'))\n    assert bool(np.dtype([('a', 'i8'), ('b', 'f4')]))\n\n\ndef test_invalid_dtype_string():\n    # test for gh-10440\n    assert_raises(TypeError, np.dtype, 'f8,i8,[f8,i8]')\n    assert_raises(TypeError, np.dtype, u'Fl\\xfcgel')\n\n\ndef test_keyword_argument():\n    # test for https://github.com/numpy/numpy/pull/16574#issuecomment-642660971\n    assert np.dtype(dtype=np.float64) == np.dtype(np.float64)\n\n\nclass TestFromDTypeAttribute:\n    def test_simple(self):\n        class dt:\n            dtype = np.dtype(\"f8\")\n\n        assert np.dtype(dt) == np.float64\n        assert np.dtype(dt()) == np.float64\n\n    def test_recursion(self):\n        class dt:\n            pass\n\n        dt.dtype = dt\n        with pytest.raises(RecursionError):\n            np.dtype(dt)\n\n        dt_instance = dt()\n        dt_instance.dtype = dt\n        with pytest.raises(RecursionError):\n            np.dtype(dt_instance)\n\n    def test_void_subtype(self):\n        class dt(np.void):\n            # This code path is fully untested before, so it is unclear\n            # what this should be useful for. Note that if np.void is used\n            # numpy will think we are deallocating a base type [1.17, 2019-02].\n            dtype = np.dtype(\"f,f\")\n\n        np.dtype(dt)\n        np.dtype(dt(1))\n\n    def test_void_subtype_recursion(self):\n        class vdt(np.void):\n            pass\n\n        vdt.dtype = vdt\n\n        with pytest.raises(RecursionError):\n            np.dtype(vdt)\n\n        with pytest.raises(RecursionError):\n            np.dtype(vdt(1))\n\n\nclass TestDTypeClasses:\n    @pytest.mark.parametrize(\"dtype\", list(np.typecodes['All']) + [rational])\n    def test_basic_dtypes_subclass_properties(self, dtype):\n        # Note: Except for the isinstance and type checks, these attributes\n        #       are considered currently private and may change.\n        dtype = np.dtype(dtype)\n        assert isinstance(dtype, np.dtype)\n        assert type(dtype) is not np.dtype\n        assert type(dtype).__name__ == f\"dtype[{dtype.type.__name__}]\"\n        assert type(dtype).__module__ == \"numpy\"\n        assert not type(dtype)._abstract\n\n        # the flexible dtypes and datetime/timedelta have additional parameters\n        # which are more than just storage information, these would need to be\n        # given when creating a dtype:\n        parametric = (np.void, np.str_, np.bytes_, np.datetime64, np.timedelta64)\n        if dtype.type not in parametric:\n            assert not type(dtype)._parametric\n            assert type(dtype)() is dtype\n        else:\n            assert type(dtype)._parametric\n            with assert_raises(TypeError):\n                type(dtype)()\n\n    def test_dtype_superclass(self):\n        assert type(np.dtype) is not type\n        assert isinstance(np.dtype, type)\n\n        assert type(np.dtype).__name__ == \"_DTypeMeta\"\n        assert type(np.dtype).__module__ == \"numpy\"\n        assert np.dtype._abstract\n\n\nclass TestFromCTypes:\n\n    @staticmethod\n    def check(ctype, dtype):\n        dtype = np.dtype(dtype)\n        assert_equal(np.dtype(ctype), dtype)\n        assert_equal(np.dtype(ctype()), dtype)\n\n    def test_array(self):\n        c8 = ctypes.c_uint8\n        self.check(     3 * c8,  (np.uint8, (3,)))\n        self.check(     1 * c8,  (np.uint8, (1,)))\n        self.check(     0 * c8,  (np.uint8, (0,)))\n        self.check(1 * (3 * c8), ((np.uint8, (3,)), (1,)))\n        self.check(3 * (1 * c8), ((np.uint8, (1,)), (3,)))\n\n    def test_padded_structure(self):\n        class PaddedStruct(ctypes.Structure):\n            _fields_ = [\n                ('a', ctypes.c_uint8),\n                ('b', ctypes.c_uint16)\n            ]\n        expected = np.dtype([\n            ('a', np.uint8),\n            ('b', np.uint16)\n        ], align=True)\n        self.check(PaddedStruct, expected)\n\n    def test_bit_fields(self):\n        class BitfieldStruct(ctypes.Structure):\n            _fields_ = [\n                ('a', ctypes.c_uint8, 7),\n                ('b', ctypes.c_uint8, 1)\n            ]\n        assert_raises(TypeError, np.dtype, BitfieldStruct)\n        assert_raises(TypeError, np.dtype, BitfieldStruct())\n\n    def test_pointer(self):\n        p_uint8 = ctypes.POINTER(ctypes.c_uint8)\n        assert_raises(TypeError, np.dtype, p_uint8)\n\n    def test_void_pointer(self):\n        self.check(ctypes.c_void_p, np.uintp)\n\n    def test_union(self):\n        class Union(ctypes.Union):\n            _fields_ = [\n                ('a', ctypes.c_uint8),\n                ('b', ctypes.c_uint16),\n            ]\n        expected = np.dtype(dict(\n            names=['a', 'b'],\n            formats=[np.uint8, np.uint16],\n            offsets=[0, 0],\n            itemsize=2\n        ))\n        self.check(Union, expected)\n\n    def test_union_with_struct_packed(self):\n        class Struct(ctypes.Structure):\n            _pack_ = 1\n            _fields_ = [\n                ('one', ctypes.c_uint8),\n                ('two', ctypes.c_uint32)\n            ]\n\n        class Union(ctypes.Union):\n            _fields_ = [\n                ('a', ctypes.c_uint8),\n                ('b', ctypes.c_uint16),\n                ('c', ctypes.c_uint32),\n                ('d', Struct),\n            ]\n        expected = np.dtype(dict(\n            names=['a', 'b', 'c', 'd'],\n            formats=['u1', np.uint16, np.uint32, [('one', 'u1'), ('two', np.uint32)]],\n            offsets=[0, 0, 0, 0],\n            itemsize=ctypes.sizeof(Union)\n        ))\n        self.check(Union, expected)\n\n    def test_union_packed(self):\n        class Struct(ctypes.Structure):\n            _fields_ = [\n                ('one', ctypes.c_uint8),\n                ('two', ctypes.c_uint32)\n            ]\n            _pack_ = 1\n        class Union(ctypes.Union):\n            _pack_ = 1\n            _fields_ = [\n                ('a', ctypes.c_uint8),\n                ('b', ctypes.c_uint16),\n                ('c', ctypes.c_uint32),\n                ('d', Struct),\n            ]\n        expected = np.dtype(dict(\n            names=['a', 'b', 'c', 'd'],\n            formats=['u1', np.uint16, np.uint32, [('one', 'u1'), ('two', np.uint32)]],\n            offsets=[0, 0, 0, 0],\n            itemsize=ctypes.sizeof(Union)\n        ))\n        self.check(Union, expected)\n\n    def test_packed_structure(self):\n        class PackedStructure(ctypes.Structure):\n            _pack_ = 1\n            _fields_ = [\n                ('a', ctypes.c_uint8),\n                ('b', ctypes.c_uint16)\n            ]\n        expected = np.dtype([\n            ('a', np.uint8),\n            ('b', np.uint16)\n        ])\n        self.check(PackedStructure, expected)\n\n    def test_large_packed_structure(self):\n        class PackedStructure(ctypes.Structure):\n            _pack_ = 2\n            _fields_ = [\n                ('a', ctypes.c_uint8),\n                ('b', ctypes.c_uint16),\n                ('c', ctypes.c_uint8),\n                ('d', ctypes.c_uint16),\n                ('e', ctypes.c_uint32),\n                ('f', ctypes.c_uint32),\n                ('g', ctypes.c_uint8)\n                ]\n        expected = np.dtype(dict(\n            formats=[np.uint8, np.uint16, np.uint8, np.uint16, np.uint32, np.uint32, np.uint8 ],\n            offsets=[0, 2, 4, 6, 8, 12, 16],\n            names=['a', 'b', 'c', 'd', 'e', 'f', 'g'],\n            itemsize=18))\n        self.check(PackedStructure, expected)\n\n    def test_big_endian_structure_packed(self):\n        class BigEndStruct(ctypes.BigEndianStructure):\n            _fields_ = [\n                ('one', ctypes.c_uint8),\n                ('two', ctypes.c_uint32)\n            ]\n            _pack_ = 1\n        expected = np.dtype([('one', 'u1'), ('two', '>u4')])\n        self.check(BigEndStruct, expected)\n\n    def test_little_endian_structure_packed(self):\n        class LittleEndStruct(ctypes.LittleEndianStructure):\n            _fields_ = [\n                ('one', ctypes.c_uint8),\n                ('two', ctypes.c_uint32)\n            ]\n            _pack_ = 1\n        expected = np.dtype([('one', 'u1'), ('two', '<u4')])\n        self.check(LittleEndStruct, expected)\n\n    def test_little_endian_structure(self):\n        class PaddedStruct(ctypes.LittleEndianStructure):\n            _fields_ = [\n                ('a', ctypes.c_uint8),\n                ('b', ctypes.c_uint16)\n            ]\n        expected = np.dtype([\n            ('a', '<B'),\n            ('b', '<H')\n        ], align=True)\n        self.check(PaddedStruct, expected)\n\n    def test_big_endian_structure(self):\n        class PaddedStruct(ctypes.BigEndianStructure):\n            _fields_ = [\n                ('a', ctypes.c_uint8),\n                ('b', ctypes.c_uint16)\n            ]\n        expected = np.dtype([\n            ('a', '>B'),\n            ('b', '>H')\n        ], align=True)\n        self.check(PaddedStruct, expected)\n\n    def test_simple_endian_types(self):\n        self.check(ctypes.c_uint16.__ctype_le__, np.dtype('<u2'))\n        self.check(ctypes.c_uint16.__ctype_be__, np.dtype('>u2'))\n        self.check(ctypes.c_uint8.__ctype_le__, np.dtype('u1'))\n        self.check(ctypes.c_uint8.__ctype_be__, np.dtype('u1'))\n\n    all_types = set(np.typecodes['All'])\n    all_pairs = permutations(all_types, 2)\n\n    @pytest.mark.parametrize(\"pair\", all_pairs)\n    def test_pairs(self, pair):\n        \"\"\"\n        Check that np.dtype('x,y') matches [np.dtype('x'), np.dtype('y')]\n        Example: np.dtype('d,I') -> dtype([('f0', '<f8'), ('f1', '<u4')])\n        \"\"\"\n        # gh-5645: check that np.dtype('i,L') can be used\n        pair_type = np.dtype('{},{}'.format(*pair))\n        expected = np.dtype([('f0', pair[0]), ('f1', pair[1])])\n        assert_equal(pair_type, expected)\n\n\nclass TestUserDType:\n    @pytest.mark.leaks_references(reason=\"dynamically creates custom dtype.\")\n    def test_custom_structured_dtype(self):\n        class mytype:\n            pass\n\n        blueprint = np.dtype([(\"field\", object)])\n        dt = create_custom_field_dtype(blueprint, mytype, 0)\n        assert dt.type == mytype\n        # We cannot (currently) *create* this dtype with `np.dtype` because\n        # mytype does not inherit from `np.generic`.  This seems like an\n        # unnecessary restriction, but one that has been around forever:\n        assert np.dtype(mytype) == np.dtype(\"O\")\n\n    def test_custom_structured_dtype_errors(self):\n        class mytype:\n            pass\n\n        blueprint = np.dtype([(\"field\", object)])\n\n        with pytest.raises(ValueError):\n            # Tests what happens if fields are unset during creation\n            # which is currently rejected due to the containing object\n            # (see PyArray_RegisterDataType).\n            create_custom_field_dtype(blueprint, mytype, 1)\n\n        with pytest.raises(RuntimeError):\n            # Tests that a dtype must have its type field set up to np.dtype\n            # or in this case a builtin instance.\n            create_custom_field_dtype(blueprint, mytype, 2)\n"
    }
  ],
  "questions": [
    "Thanks @jbrockmendel and @simonjayhawkins for the input\r\n\r\n> can't reproduce on pandas 1.2.5 onwards.\r\n\r\nSince it may be a bug from numpy, I wonder which numpy version you were using?\r\nAlso, I wonder if you were able to reproduce the bug given the environment I posted (pandas 1.3.1, numpy 1.20.3)?\r\n\r\n\r\n\r\n\r\n> numpy int dtypes can't hold missing values, so `False` seem more appropriate.\r\n\r\nYes, that was a typo on my side. I've updated the description.",
    "Can you give me an example for how to add a regression test for this issue? Thank you :)"
  ],
  "golden_answers": [
    "In my case, no bug found. (But I can not understand how it can be a bug from `numpy` when `numpy` does not support integer `NA`s. Isn't it the reason that they named integer NA as `pd.NA`?)\r\n\r\n```\r\n>>> pd.api.types.pandas_dtype(\"int64\") == \"Int64\"\r\nFalse\r\n>>> pd.__version__\r\n'1.3.1'\r\n>>> np.__version__\r\n'1.21.1'\r\n```",
    "> Can you give me an example for how to add a regression test for this issue? Thank you :)\r\n\r\nI'd recommend looking at closed `good first issues` about testing (for example from https://github.com/pandas-dev/pandas/issues?q=is%3Aissue+label%3A%22good+first+issue%22+is%3Aclosed+label%3A%22Needs+Tests%22). If you look at some pull requests which close the issue, those should be good examples"
  ],
  "questions_generated": [
    "What is the primary issue being reported in the pandas repository regarding type comparison?",
    "Why does the comparison between 'int64' and 'Int64' fail, while other similar comparisons pass?",
    "How does the numpy issue contribute to the pandas dtype comparison problem?",
    "What is the expected output of comparing pd.api.types.pandas_dtype('int64') with 'Int64', and why?",
    "What potential solutions or fixes were identified for the dtype comparison issue in the pandas repository?"
  ],
  "golden_answers_generated": [
    "The primary issue is that comparing the pandas dtype 'int64' with 'Int64' using pd.api.types.pandas_dtype('int64') == 'Int64' results in a TypeError, while similar comparisons succeed. The expected output for this comparison should be False, but it fails instead.",
    "The comparison fails due to an issue with the numpy dtype equality function (__eq__), which does not correctly understand or handle the 'Int64' dtype. This is in contrast to other comparisons like 'int64' with 'int64' or 'Int64' with 'Int64', which do not encounter this issue because they match exactly or are correctly interpreted by the dtype function.",
    "The numpy issue contributes to the problem because the dtype comparison logic in pandas relies on numpy's dtype handling. The bug in numpy's dtype equality function (__eq__) leads to the failure in recognizing or comparing 'Int64' correctly, resulting in a TypeError when attempting to compare 'int64' and 'Int64'.",
    "The expected output of comparing pd.api.types.pandas_dtype('int64') with 'Int64' is False. This is because 'int64' refers to a numpy integer type that cannot hold missing values, while 'Int64' refers to a pandas extension type that can handle missing values. Thus, they are conceptually different and should not be considered equal.",
    "The discussion suggested that the issue might be resolved by a fix in the numpy repository, specifically numpy/numpy#19228, which addresses the dtype equality function. Additionally, it was noted that this issue could not be reproduced in certain versions of pandas, indicating that updates to either pandas or numpy might have already resolved the issue in newer versions."
  ]
}