{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "31644",
  "issue_description": "# replace method does't work with string type Series\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\n>>>pd.Series(['A','B']).replace(r'.','C',regex=True)\r\n0    C\r\n1    C\r\ndtype: object\r\npd.Series(['A','B']).astype('string').replace(r'.','C',regex=True)\r\n0    A\r\n1    B\r\ndtype: string\r\n```\r\n#### Problem description\r\n\r\nIt seems that replace doesn't work with the string type Series.\r\nWhy these two codes return different results?",
  "issue_comments": [
    {
      "id": 581793124,
      "user": "charlesdong1991",
      "body": "looks buggy \r\n\r\ninvestigation is welcome"
    },
    {
      "id": 581795339,
      "user": "GYHHAHA",
      "body": "```python\r\n>>>pd.Series(['A','B']).astype('string').replace('.','C',regex=True)\r\n0    A\r\n1    B\r\ndtype: string\r\n```\r\nThanks for answer !\r\nBut still not work.\r\nAnd also I want to ask a related question.\r\nSince the str.replace for string does not allow pd.NA for the parameter 'repl', if I want change some strings which meet a certain regex condition to pd.NA, how can I get the correct result. Thanks !"
    },
    {
      "id": 581797378,
      "user": "charlesdong1991",
      "body": "you mean something like this `pd.Series(['A','B']).astype('string').replace('A', pd.NA)`?\r\nworks to me at least on master:\r\n```python\r\n>>> pd.Series(['A','B']).astype('string').replace('A', pd.NA)\r\n0    <NA>\r\n1       B\r\ndtype: string\r\n```"
    },
    {
      "id": 581798408,
      "user": "GYHHAHA",
      "body": "Oh? I get an error.\r\n```python\r\n>>>pd.Series(['A','B']).astype('string').replace('A', pd.NA)\r\nIndexError: arrays used as indices must be of integer (or boolean) type\r\n```\r\n"
    },
    {
      "id": 581798574,
      "user": "charlesdong1991",
      "body": "Are you running it on master branch?"
    },
    {
      "id": 581799015,
      "user": "GYHHAHA",
      "body": "I have already updated to the latest version 1.0.0."
    },
    {
      "id": 581799416,
      "user": "charlesdong1991",
      "body": "yeah, there are some fixes after 1.0.0, but not released yet, so some new fixes can only be tested on master. Please let me know if you still have this issue on pandas master branch"
    },
    {
      "id": 581799850,
      "user": "GYHHAHA",
      "body": "Oh, I haven't do that.\r\nI will run it on master branch and check the issue again.\r\nThanks !"
    },
    {
      "id": 581830593,
      "user": "GYHHAHA",
      "body": "It works for the pd.NA issue on master branch, but still not work for the original issue. @charlesdong1991 "
    },
    {
      "id": 581832175,
      "user": "charlesdong1991",
      "body": "thanks for confirming the issue on master, are you interested in investigating it? @GYHHAHA "
    },
    {
      "id": 581835342,
      "user": "GYHHAHA",
      "body": "Sorry, I'm not sophisticated on the Pandas source code, but I will pay close attention on that when the next version releases.\r\nAnd also, it seems when pd.NA appears in the string type Series, an error will be raised for the replace method.\r\n```python\r\n>>>pd.Series(['A',np.nan],dtype='O').replace('A','B')\r\n0      B\r\n1    NaN\r\ndtype: object\r\n>>>pd.Series(['A',np.nan],dtype='string').replace('A','B')\r\nAssertionError: B\r\n``` \r\nThe error seems not very clear."
    },
    {
      "id": 581836953,
      "user": "charlesdong1991",
      "body": "thanks for the report, your finding is very helpful!! @GYHHAHA \r\n\r\ni will look into it a bit"
    },
    {
      "id": 581836999,
      "user": "charlesdong1991",
      "body": "take"
    },
    {
      "id": 581838177,
      "user": "GYHHAHA",
      "body": "I guess a rough reason for that is, not like the np.nan, the pd.NA doesn't stand for a constant value, so when launch a match for 'A', it's not clear whether pd.NA equals 'A', so the error is raised.\r\nJust my guess. : )"
    },
    {
      "id": 581850680,
      "user": "GYHHAHA",
      "body": "Is it possible to take pd.NA as a legal choice for the 'repl' parameter of str.replace method in the latter version? It seems to be more natural."
    },
    {
      "id": 887228471,
      "user": "mroeschke",
      "body": "Looks to work on master now. Could use a test\r\n\r\n```\r\nIn [20]: pd.Series(['A','B']).astype('string').replace(r'.','C',regex=True)\r\nOut[20]:\r\n0    C\r\n1    C\r\ndtype: string\r\n```"
    },
    {
      "id": 887336041,
      "user": "SidharthArya",
      "body": "take"
    },
    {
      "id": 1050635072,
      "user": "klimpt",
      "body": "I think there is another bug:\r\n\r\n```python\r\n>>> pd.Series([\"a\", pd.NA, \"a\"]).astype(\"string\").replace([\"a\"], \"b\", regex=True) #strange behaviour\r\n0       b\r\n1    <NA>\r\n2       a\r\ndtype: string\r\n>>> pd.Series([\"a\", pd.NA, \"a\"]).astype(\"string\").replace(\"a\", \"b\", regex=True) #replace works fine \r\n0       b\r\n1    <NA>\r\n2       b\r\ndtype: string\r\n```\r\n\r\n**Problem description**\r\nIf series contains `pd.NA` **and** dtype is string **and** `regex=True`**and** `to_replace` is a list or a dict, then replace does not work for elements after `pd.NA`.\r\n"
    }
  ],
  "text_context": "# replace method does't work with string type Series\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\n>>>pd.Series(['A','B']).replace(r'.','C',regex=True)\r\n0    C\r\n1    C\r\ndtype: object\r\npd.Series(['A','B']).astype('string').replace(r'.','C',regex=True)\r\n0    A\r\n1    B\r\ndtype: string\r\n```\r\n#### Problem description\r\n\r\nIt seems that replace doesn't work with the string type Series.\r\nWhy these two codes return different results?\n\nlooks buggy \r\n\r\ninvestigation is welcome\n\n```python\r\n>>>pd.Series(['A','B']).astype('string').replace('.','C',regex=True)\r\n0    A\r\n1    B\r\ndtype: string\r\n```\r\nThanks for answer !\r\nBut still not work.\r\nAnd also I want to ask a related question.\r\nSince the str.replace for string does not allow pd.NA for the parameter 'repl', if I want change some strings which meet a certain regex condition to pd.NA, how can I get the correct result. Thanks !\n\nyou mean something like this `pd.Series(['A','B']).astype('string').replace('A', pd.NA)`?\r\nworks to me at least on master:\r\n```python\r\n>>> pd.Series(['A','B']).astype('string').replace('A', pd.NA)\r\n0    <NA>\r\n1       B\r\ndtype: string\r\n```\n\nOh? I get an error.\r\n```python\r\n>>>pd.Series(['A','B']).astype('string').replace('A', pd.NA)\r\nIndexError: arrays used as indices must be of integer (or boolean) type\r\n```\r\n\n\nAre you running it on master branch?\n\nI have already updated to the latest version 1.0.0.\n\nyeah, there are some fixes after 1.0.0, but not released yet, so some new fixes can only be tested on master. Please let me know if you still have this issue on pandas master branch\n\nOh, I haven't do that.\r\nI will run it on master branch and check the issue again.\r\nThanks !\n\nIt works for the pd.NA issue on master branch, but still not work for the original issue. @charlesdong1991 \n\nthanks for confirming the issue on master, are you interested in investigating it? @GYHHAHA \n\nSorry, I'm not sophisticated on the Pandas source code, but I will pay close attention on that when the next version releases.\r\nAnd also, it seems when pd.NA appears in the string type Series, an error will be raised for the replace method.\r\n```python\r\n>>>pd.Series(['A',np.nan],dtype='O').replace('A','B')\r\n0      B\r\n1    NaN\r\ndtype: object\r\n>>>pd.Series(['A',np.nan],dtype='string').replace('A','B')\r\nAssertionError: B\r\n``` \r\nThe error seems not very clear.\n\nthanks for the report, your finding is very helpful!! @GYHHAHA \r\n\r\ni will look into it a bit\n\ntake\n\nI guess a rough reason for that is, not like the np.nan, the pd.NA doesn't stand for a constant value, so when launch a match for 'A', it's not clear whether pd.NA equals 'A', so the error is raised.\r\nJust my guess. : )\n\nIs it possible to take pd.NA as a legal choice for the 'repl' parameter of str.replace method in the latter version? It seems to be more natural.\n\nLooks to work on master now. Could use a test\r\n\r\n```\r\nIn [20]: pd.Series(['A','B']).astype('string').replace(r'.','C',regex=True)\r\nOut[20]:\r\n0    C\r\n1    C\r\ndtype: string\r\n```\n\ntake\n\nI think there is another bug:\r\n\r\n```python\r\n>>> pd.Series([\"a\", pd.NA, \"a\"]).astype(\"string\").replace([\"a\"], \"b\", regex=True) #strange behaviour\r\n0       b\r\n1    <NA>\r\n2       a\r\ndtype: string\r\n>>> pd.Series([\"a\", pd.NA, \"a\"]).astype(\"string\").replace(\"a\", \"b\", regex=True) #replace works fine \r\n0       b\r\n1    <NA>\r\n2       b\r\ndtype: string\r\n```\r\n\r\n**Problem description**\r\nIf series contains `pd.NA` **and** dtype is string **and** `regex=True`**and** `to_replace` is a list or a dict, then replace does not work for elements after `pd.NA`.\r\n",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/44940",
  "code_context": [
    {
      "filename": "pandas/core/array_algos/replace.py",
      "content": "\"\"\"\nMethods used by Block.replace and related methods.\n\"\"\"\nfrom __future__ import annotations\n\nimport operator\nimport re\nfrom typing import (\n    Any,\n    Pattern,\n)\n\nimport numpy as np\n\nfrom pandas._typing import (\n    ArrayLike,\n    Scalar,\n)\n\nfrom pandas.core.dtypes.common import (\n    is_datetimelike_v_numeric,\n    is_numeric_v_string_like,\n    is_re,\n    is_re_compilable,\n    is_scalar,\n)\nfrom pandas.core.dtypes.missing import isna\n\n\ndef should_use_regex(regex: bool, to_replace: Any) -> bool:\n    \"\"\"\n    Decide whether to treat `to_replace` as a regular expression.\n    \"\"\"\n    if is_re(to_replace):\n        regex = True\n\n    regex = regex and is_re_compilable(to_replace)\n\n    # Don't use regex if the pattern is empty.\n    regex = regex and re.compile(to_replace).pattern != \"\"\n    return regex\n\n\ndef compare_or_regex_search(\n    a: ArrayLike, b: Scalar | Pattern, regex: bool, mask: np.ndarray\n) -> ArrayLike | bool:\n    \"\"\"\n    Compare two array-like inputs of the same shape or two scalar values\n\n    Calls operator.eq or re.search, depending on regex argument. If regex is\n    True, perform an element-wise regex matching.\n\n    Parameters\n    ----------\n    a : array-like\n    b : scalar or regex pattern\n    regex : bool\n    mask : np.ndarray[bool]\n\n    Returns\n    -------\n    mask : array-like of bool\n    \"\"\"\n    if isna(b):\n        return ~mask\n\n    def _check_comparison_types(\n        result: ArrayLike | bool, a: ArrayLike, b: Scalar | Pattern\n    ):\n        \"\"\"\n        Raises an error if the two arrays (a,b) cannot be compared.\n        Otherwise, returns the comparison result as expected.\n        \"\"\"\n        if is_scalar(result) and isinstance(a, np.ndarray):\n            type_names = [type(a).__name__, type(b).__name__]\n\n            type_names[0] = f\"ndarray(dtype={a.dtype})\"\n\n            raise TypeError(\n                f\"Cannot compare types {repr(type_names[0])} and {repr(type_names[1])}\"\n            )\n\n    if not regex or not should_use_regex(regex, b):\n        # TODO: should use missing.mask_missing?\n        op = lambda x: operator.eq(x, b)\n    else:\n        op = np.vectorize(\n            lambda x: bool(re.search(b, x))\n            if isinstance(x, str) and isinstance(b, (str, Pattern))\n            else False\n        )\n\n    # GH#32621 use mask to avoid comparing to NAs\n    if isinstance(a, np.ndarray):\n        a = a[mask]\n\n    if is_numeric_v_string_like(a, b):\n        # GH#29553 avoid deprecation warnings from numpy\n        return np.zeros(a.shape, dtype=bool)\n\n    elif is_datetimelike_v_numeric(a, b):\n        # GH#29553 avoid deprecation warnings from numpy\n        _check_comparison_types(False, a, b)\n        return False\n\n    result = op(a)\n\n    if isinstance(result, np.ndarray) and mask is not None:\n        # The shape of the mask can differ to that of the result\n        # since we may compare only a subset of a's or b's elements\n        tmp = np.zeros(mask.shape, dtype=np.bool_)\n        np.place(tmp, mask, result)\n        result = tmp\n\n    _check_comparison_types(result, a, b)\n    return result\n\n\ndef replace_regex(values: ArrayLike, rx: re.Pattern, value, mask: np.ndarray | None):\n    \"\"\"\n    Parameters\n    ----------\n    values : ArrayLike\n        Object dtype.\n    rx : re.Pattern\n    value : Any\n    mask : np.ndarray[bool], optional\n\n    Notes\n    -----\n    Alters values in-place.\n    \"\"\"\n\n    # deal with replacing values with objects (strings) that match but\n    # whose replacement is not a string (numeric, nan, object)\n    if isna(value) or not isinstance(value, str):\n\n        def re_replacer(s):\n            if is_re(rx) and isinstance(s, str):\n                return value if rx.search(s) is not None else s\n            else:\n                return s\n\n    else:\n        # value is guaranteed to be a string here, s can be either a string\n        # or null if it's null it gets returned\n        def re_replacer(s):\n            if is_re(rx) and isinstance(s, str):\n                return rx.sub(value, s)\n            else:\n                return s\n\n    f = np.vectorize(re_replacer, otypes=[np.object_])\n\n    if mask is None:\n        values[:] = f(values)\n    else:\n        values[mask] = f(values[mask])\n"
    },
    {
      "filename": "pandas/core/internals/blocks.py",
      "content": "from __future__ import annotations\n\nfrom functools import wraps\nimport re\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Iterable,\n    Sequence,\n    cast,\n    final,\n)\nimport warnings\n\nimport numpy as np\n\nfrom pandas._libs import (\n    Timestamp,\n    algos as libalgos,\n    internals as libinternals,\n    lib,\n    writers,\n)\nfrom pandas._libs.internals import BlockPlacement\nfrom pandas._typing import (\n    ArrayLike,\n    DtypeObj,\n    F,\n    Shape,\n    npt,\n)\nfrom pandas.compat import np_version_under1p20\nfrom pandas.util._decorators import cache_readonly\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.util._validators import validate_bool_kwarg\n\nfrom pandas.core.dtypes.cast import (\n    astype_array_safe,\n    can_hold_element,\n    find_common_type,\n    infer_dtype_from,\n    maybe_downcast_numeric,\n    maybe_downcast_to_dtype,\n    maybe_upcast,\n    soft_convert_objects,\n)\nfrom pandas.core.dtypes.common import (\n    is_1d_only_ea_dtype,\n    is_1d_only_ea_obj,\n    is_dtype_equal,\n    is_extension_array_dtype,\n    is_interval_dtype,\n    is_list_like,\n    is_string_dtype,\n)\nfrom pandas.core.dtypes.dtypes import (\n    CategoricalDtype,\n    ExtensionDtype,\n    PandasDtype,\n    PeriodDtype,\n)\nfrom pandas.core.dtypes.generic import (\n    ABCDataFrame,\n    ABCIndex,\n    ABCPandasArray,\n    ABCSeries,\n)\nfrom pandas.core.dtypes.inference import is_inferred_bool_dtype\nfrom pandas.core.dtypes.missing import (\n    is_valid_na_for_dtype,\n    isna,\n    na_value_for_dtype,\n)\n\nimport pandas.core.algorithms as algos\nfrom pandas.core.array_algos.putmask import (\n    extract_bool_array,\n    putmask_inplace,\n    putmask_smart,\n    putmask_without_repeat,\n    setitem_datetimelike_compat,\n    validate_putmask,\n)\nfrom pandas.core.array_algos.quantile import quantile_compat\nfrom pandas.core.array_algos.replace import (\n    compare_or_regex_search,\n    replace_regex,\n    should_use_regex,\n)\nfrom pandas.core.array_algos.transforms import shift\nfrom pandas.core.arrays import (\n    Categorical,\n    DatetimeArray,\n    ExtensionArray,\n    IntervalArray,\n    PandasArray,\n    PeriodArray,\n    TimedeltaArray,\n)\nfrom pandas.core.arrays._mixins import NDArrayBackedExtensionArray\nfrom pandas.core.arrays.sparse import SparseDtype\nfrom pandas.core.base import PandasObject\nimport pandas.core.common as com\nimport pandas.core.computation.expressions as expressions\nfrom pandas.core.construction import (\n    ensure_wrapped_if_datetimelike,\n    extract_array,\n)\nfrom pandas.core.indexers import (\n    check_setitem_lengths,\n    is_empty_indexer,\n    is_scalar_indexer,\n)\nimport pandas.core.missing as missing\n\nif TYPE_CHECKING:\n    from pandas import (\n        Float64Index,\n        Index,\n    )\n\n# comparison is faster than is_object_dtype\n_dtype_obj = np.dtype(\"object\")\n\n\ndef maybe_split(meth: F) -> F:\n    \"\"\"\n    If we have a multi-column block, split and operate block-wise.  Otherwise\n    use the original method.\n    \"\"\"\n\n    @wraps(meth)\n    def newfunc(self, *args, **kwargs) -> list[Block]:\n\n        if self.ndim == 1 or self.shape[0] == 1:\n            return meth(self, *args, **kwargs)\n        else:\n            # Split and operate column-by-column\n            return self.split_and_operate(meth, *args, **kwargs)\n\n    return cast(F, newfunc)\n\n\nclass Block(PandasObject):\n    \"\"\"\n    Canonical n-dimensional unit of homogeneous dtype contained in a pandas\n    data structure\n\n    Index-ignorant; let the container take care of that\n    \"\"\"\n\n    values: np.ndarray | ExtensionArray\n    ndim: int\n    __init__: Callable\n\n    __slots__ = ()\n    is_numeric = False\n    is_object = False\n    is_extension = False\n    _can_consolidate = True\n    _validate_ndim = True\n\n    @final\n    @cache_readonly\n    def _consolidate_key(self):\n        return self._can_consolidate, self.dtype.name\n\n    @property\n    def is_view(self) -> bool:\n        \"\"\"return a boolean if I am possibly a view\"\"\"\n        values = self.values\n        values = cast(np.ndarray, values)\n        return values.base is not None\n\n    @final\n    @cache_readonly\n    def _can_hold_na(self) -> bool:\n        \"\"\"\n        Can we store NA values in this Block?\n        \"\"\"\n        dtype = self.dtype\n        if isinstance(dtype, np.dtype):\n            return dtype.kind not in [\"b\", \"i\", \"u\"]\n        return dtype._can_hold_na\n\n    @final\n    @cache_readonly\n    def is_categorical(self) -> bool:\n        warnings.warn(\n            \"Block.is_categorical is deprecated and will be removed in a \"\n            \"future version.  Use isinstance(block.values, Categorical) \"\n            \"instead. See https://github.com/pandas-dev/pandas/issues/40226\",\n            DeprecationWarning,\n            stacklevel=find_stack_level(),\n        )\n        return isinstance(self.values, Categorical)\n\n    @final\n    @property\n    def is_bool(self) -> bool:\n        \"\"\"\n        We can be bool if a) we are bool dtype or b) object dtype with bool objects.\n        \"\"\"\n        return is_inferred_bool_dtype(self.values)\n\n    @final\n    def external_values(self):\n        return external_values(self.values)\n\n    @property\n    def array_values(self) -> ExtensionArray:\n        \"\"\"\n        The array that Series.array returns. Always an ExtensionArray.\n        \"\"\"\n        # error: Argument 1 to \"PandasArray\" has incompatible type \"Union[ndarray,\n        # ExtensionArray]\"; expected \"Union[ndarray, PandasArray]\"\n        return PandasArray(self.values)  # type: ignore[arg-type]\n\n    def get_values(self, dtype: DtypeObj | None = None) -> np.ndarray:\n        \"\"\"\n        return an internal format, currently just the ndarray\n        this is often overridden to handle to_dense like operations\n        \"\"\"\n        if dtype == _dtype_obj:\n            return self.values.astype(_dtype_obj)\n        # error: Incompatible return value type (got \"Union[ndarray, ExtensionArray]\",\n        # expected \"ndarray\")\n        return self.values  # type: ignore[return-value]\n\n    def values_for_json(self) -> np.ndarray:\n        # Incompatible return value type (got \"Union[ndarray[Any, Any],\n        # ExtensionArray]\", expected \"ndarray[Any, Any]\")\n        return self.values  # type: ignore[return-value]\n\n    @final\n    @cache_readonly\n    def fill_value(self):\n        # Used in reindex_indexer\n        return na_value_for_dtype(self.dtype, compat=False)\n\n    @property\n    def mgr_locs(self) -> BlockPlacement:\n        return self._mgr_locs\n\n    @mgr_locs.setter\n    def mgr_locs(self, new_mgr_locs: BlockPlacement):\n        self._mgr_locs = new_mgr_locs\n\n    @final\n    def make_block(self, values, placement=None) -> Block:\n        \"\"\"\n        Create a new block, with type inference propagate any values that are\n        not specified\n        \"\"\"\n        if placement is None:\n            placement = self._mgr_locs\n        if self.is_extension:\n            values = ensure_block_shape(values, ndim=self.ndim)\n\n        # TODO: perf by not going through new_block\n        # We assume maybe_coerce_values has already been called\n        return new_block(values, placement=placement, ndim=self.ndim)\n\n    @final\n    def make_block_same_class(\n        self, values, placement: BlockPlacement | None = None\n    ) -> Block:\n        \"\"\"Wrap given values in a block of same type as self.\"\"\"\n        if placement is None:\n            placement = self._mgr_locs\n\n        if values.dtype.kind in [\"m\", \"M\"]:\n\n            new_values = ensure_wrapped_if_datetimelike(values)\n            if new_values is not values:\n                # TODO(2.0): remove once fastparquet has stopped relying on it\n                warnings.warn(\n                    \"In a future version, Block.make_block_same_class will \"\n                    \"assume that datetime64 and timedelta64 ndarrays have \"\n                    \"already been cast to DatetimeArray and TimedeltaArray, \"\n                    \"respectively.\",\n                    DeprecationWarning,\n                    stacklevel=find_stack_level(),\n                )\n            values = new_values\n\n        # We assume maybe_coerce_values has already been called\n        return type(self)(values, placement=placement, ndim=self.ndim)\n\n    @final\n    def __repr__(self) -> str:\n        # don't want to print out all of the items here\n        name = type(self).__name__\n        if self.ndim == 1:\n            result = f\"{name}: {len(self)} dtype: {self.dtype}\"\n        else:\n\n            shape = \" x \".join([str(s) for s in self.shape])\n            result = f\"{name}: {self.mgr_locs.indexer}, {shape}, dtype: {self.dtype}\"\n\n        return result\n\n    @final\n    def __len__(self) -> int:\n        return len(self.values)\n\n    def _slice(self, slicer) -> ArrayLike:\n        \"\"\"return a slice of my values\"\"\"\n\n        return self.values[slicer]\n\n    @final\n    def getitem_block(self, slicer: slice | npt.NDArray[np.intp]) -> Block:\n        \"\"\"\n        Perform __getitem__-like, return result as block.\n\n        Only supports slices that preserve dimensionality.\n        \"\"\"\n        axis0_slicer = slicer[0] if isinstance(slicer, tuple) else slicer\n        new_mgr_locs = self._mgr_locs[axis0_slicer]\n\n        new_values = self._slice(slicer)\n\n        if new_values.ndim != self.values.ndim:\n            raise ValueError(\"Only same dim slicing is allowed\")\n\n        return type(self)(new_values, new_mgr_locs, self.ndim)\n\n    @final\n    def getitem_block_columns(\n        self, slicer: slice, new_mgr_locs: BlockPlacement\n    ) -> Block:\n        \"\"\"\n        Perform __getitem__-like, return result as block.\n\n        Only supports slices that preserve dimensionality.\n        \"\"\"\n        new_values = self._slice(slicer)\n\n        if new_values.ndim != self.values.ndim:\n            raise ValueError(\"Only same dim slicing is allowed\")\n\n        return type(self)(new_values, new_mgr_locs, self.ndim)\n\n    # NB: this cannot be made cache_readonly because in libreduction we pin\n    #  new .values that can have different shape GH#42631\n    @property\n    def shape(self) -> Shape:\n        return self.values.shape\n\n    @cache_readonly\n    def dtype(self) -> DtypeObj:\n        return self.values.dtype\n\n    def iget(self, i):\n        return self.values[i]\n\n    def set_inplace(self, locs, values) -> None:\n        \"\"\"\n        Modify block values in-place with new item value.\n\n        Notes\n        -----\n        `set` never creates a new array or new Block, whereas `setitem` _may_\n        create a new array and always creates a new Block.\n        \"\"\"\n        self.values[locs] = values\n\n    def delete(self, loc) -> None:\n        \"\"\"\n        Delete given loc(-s) from block in-place.\n        \"\"\"\n        self.values = np.delete(self.values, loc, 0)\n        self.mgr_locs = self._mgr_locs.delete(loc)\n        try:\n            self._cache.clear()\n        except AttributeError:\n            # _cache not yet initialized\n            pass\n\n    @final\n    def apply(self, func, **kwargs) -> list[Block]:\n        \"\"\"\n        apply the function to my values; return a block if we are not\n        one\n        \"\"\"\n        result = func(self.values, **kwargs)\n\n        return self._split_op_result(result)\n\n    def reduce(self, func, ignore_failures: bool = False) -> list[Block]:\n        # We will apply the function and reshape the result into a single-row\n        #  Block with the same mgr_locs; squeezing will be done at a higher level\n        assert self.ndim == 2\n\n        try:\n            result = func(self.values)\n        except (TypeError, NotImplementedError):\n            if ignore_failures:\n                return []\n            raise\n\n        if self.values.ndim == 1:\n            # TODO(EA2D): special case not needed with 2D EAs\n            res_values = np.array([[result]])\n        else:\n            res_values = result.reshape(-1, 1)\n\n        nb = self.make_block(res_values)\n        return [nb]\n\n    @final\n    def _split_op_result(self, result: ArrayLike) -> list[Block]:\n        # See also: split_and_operate\n        if result.ndim > 1 and isinstance(result.dtype, ExtensionDtype):\n            # TODO(EA2D): unnecessary with 2D EAs\n            # if we get a 2D ExtensionArray, we need to split it into 1D pieces\n            nbs = []\n            for i, loc in enumerate(self._mgr_locs):\n                if not is_1d_only_ea_obj(result):\n                    vals = result[i : i + 1]\n                else:\n                    vals = result[i]\n\n                block = self.make_block(values=vals, placement=loc)\n                nbs.append(block)\n            return nbs\n\n        nb = self.make_block(result)\n\n        return [nb]\n\n    def fillna(\n        self, value, limit=None, inplace: bool = False, downcast=None\n    ) -> list[Block]:\n        \"\"\"\n        fillna on the block with the value. If we fail, then convert to\n        ObjectBlock and try again\n        \"\"\"\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\n\n        mask = isna(self.values)\n        mask, noop = validate_putmask(self.values, mask)\n\n        if limit is not None:\n            limit = libalgos.validate_limit(None, limit=limit)\n            mask[mask.cumsum(self.ndim - 1) > limit] = False\n\n        if not self._can_hold_na:\n            if inplace:\n                return [self]\n            else:\n                return [self.copy()]\n\n        if self._can_hold_element(value):\n            nb = self if inplace else self.copy()\n            putmask_inplace(nb.values, mask, value)\n            return nb._maybe_downcast([nb], downcast)\n\n        if noop:\n            # we can't process the value, but nothing to do\n            return [self] if inplace else [self.copy()]\n\n        elif self.ndim == 1 or self.shape[0] == 1:\n            blk = self.coerce_to_target_dtype(value)\n            # bc we have already cast, inplace=True may avoid an extra copy\n            return blk.fillna(value, limit=limit, inplace=True, downcast=None)\n\n        else:\n            # operate column-by-column\n            return self.split_and_operate(\n                type(self).fillna, value, limit=limit, inplace=inplace, downcast=None\n            )\n\n    @final\n    def _split(self) -> list[Block]:\n        \"\"\"\n        Split a block into a list of single-column blocks.\n        \"\"\"\n        assert self.ndim == 2\n\n        new_blocks = []\n        for i, ref_loc in enumerate(self._mgr_locs):\n            vals = self.values[slice(i, i + 1)]\n\n            bp = BlockPlacement(ref_loc)\n            nb = type(self)(vals, placement=bp, ndim=2)\n            new_blocks.append(nb)\n        return new_blocks\n\n    @final\n    def split_and_operate(self, func, *args, **kwargs) -> list[Block]:\n        \"\"\"\n        Split the block and apply func column-by-column.\n\n        Parameters\n        ----------\n        func : Block method\n        *args\n        **kwargs\n\n        Returns\n        -------\n        List[Block]\n        \"\"\"\n        assert self.ndim == 2 and self.shape[0] != 1\n\n        res_blocks = []\n        for nb in self._split():\n            rbs = func(nb, *args, **kwargs)\n            res_blocks.extend(rbs)\n        return res_blocks\n\n    @final\n    def _maybe_downcast(self, blocks: list[Block], downcast=None) -> list[Block]:\n\n        if self.dtype == _dtype_obj:\n            # TODO: why is behavior different for object dtype?\n            if downcast is not None:\n                return blocks\n\n            # split and convert the blocks\n            return extend_blocks(\n                [blk.convert(datetime=True, numeric=False) for blk in blocks]\n            )\n\n        if downcast is None:\n            return blocks\n        if downcast is False:\n            # turn if off completely\n            # TODO: not reached, deprecate in favor of downcast=None\n            return blocks\n\n        return extend_blocks([b._downcast_2d(downcast) for b in blocks])\n\n    @final\n    @maybe_split\n    def _downcast_2d(self, dtype) -> list[Block]:\n        \"\"\"\n        downcast specialized to 2D case post-validation.\n\n        Refactored to allow use of maybe_split.\n        \"\"\"\n        new_values = maybe_downcast_to_dtype(self.values, dtype=dtype)\n        return [self.make_block(new_values)]\n\n    @final\n    def astype(self, dtype: DtypeObj, copy: bool = False, errors: str = \"raise\"):\n        \"\"\"\n        Coerce to the new dtype.\n\n        Parameters\n        ----------\n        dtype : np.dtype or ExtensionDtype\n        copy : bool, default False\n            copy if indicated\n        errors : str, {'raise', 'ignore'}, default 'raise'\n            - ``raise`` : allow exceptions to be raised\n            - ``ignore`` : suppress exceptions. On error return original object\n\n        Returns\n        -------\n        Block\n        \"\"\"\n        values = self.values\n\n        new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n\n        new_values = maybe_coerce_values(new_values)\n        newb = self.make_block(new_values)\n        if newb.shape != self.shape:\n            raise TypeError(\n                f\"cannot set astype for copy = [{copy}] for dtype \"\n                f\"({self.dtype.name} [{self.shape}]) to different shape \"\n                f\"({newb.dtype.name} [{newb.shape}])\"\n            )\n        return newb\n\n    def convert(\n        self,\n        copy: bool = True,\n        datetime: bool = True,\n        numeric: bool = True,\n        timedelta: bool = True,\n    ) -> list[Block]:\n        \"\"\"\n        attempt to coerce any object types to better types return a copy\n        of the block (if copy = True) by definition we are not an ObjectBlock\n        here!\n        \"\"\"\n        return [self.copy()] if copy else [self]\n\n    @final\n    def _can_hold_element(self, element: Any) -> bool:\n        \"\"\"require the same dtype as ourselves\"\"\"\n        element = extract_array(element, extract_numpy=True)\n        return can_hold_element(self.values, element)\n\n    @final\n    def should_store(self, value: ArrayLike) -> bool:\n        \"\"\"\n        Should we set self.values[indexer] = value inplace or do we need to cast?\n\n        Parameters\n        ----------\n        value : np.ndarray or ExtensionArray\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        # faster equivalent to is_dtype_equal(value.dtype, self.dtype)\n        try:\n            return value.dtype == self.dtype\n        except TypeError:\n            return False\n\n    @final\n    def to_native_types(self, na_rep=\"nan\", quoting=None, **kwargs):\n        \"\"\"convert to our native types format\"\"\"\n        result = to_native_types(self.values, na_rep=na_rep, quoting=quoting, **kwargs)\n        return self.make_block(result)\n\n    # block actions #\n    @final\n    def copy(self, deep: bool = True):\n        \"\"\"copy constructor\"\"\"\n        values = self.values\n        if deep:\n            values = values.copy()\n        return type(self)(values, placement=self._mgr_locs, ndim=self.ndim)\n\n    # ---------------------------------------------------------------------\n    # Replace\n\n    @final\n    def replace(\n        self,\n        to_replace,\n        value,\n        inplace: bool = False,\n        # mask may be pre-computed if we're called from replace_list\n        mask: npt.NDArray[np.bool_] | None = None,\n    ) -> list[Block]:\n        \"\"\"\n        replace the to_replace value with value, possible to create new\n        blocks here this is just a call to putmask.\n        \"\"\"\n\n        # Note: the checks we do in NDFrame.replace ensure we never get\n        #  here with listlike to_replace or value, as those cases\n        #  go through replace_list\n\n        values = self.values\n\n        if isinstance(values, Categorical):\n            # TODO: avoid special-casing\n            blk = self if inplace else self.copy()\n            blk.values._replace(to_replace=to_replace, value=value, inplace=True)\n            return [blk]\n\n        if not self._can_hold_element(to_replace):\n            # We cannot hold `to_replace`, so we know immediately that\n            #  replacing it is a no-op.\n            # Note: If to_replace were a list, NDFrame.replace would call\n            #  replace_list instead of replace.\n            return [self] if inplace else [self.copy()]\n\n        if mask is None:\n            mask = missing.mask_missing(values, to_replace)\n        if not mask.any():\n            # Note: we get here with test_replace_extension_other incorrectly\n            #  bc _can_hold_element is incorrect.\n            return [self] if inplace else [self.copy()]\n\n        elif self._can_hold_element(value):\n            blk = self if inplace else self.copy()\n            putmask_inplace(blk.values, mask, value)\n            blocks = blk.convert(numeric=False, copy=False)\n            return blocks\n\n        elif self.ndim == 1 or self.shape[0] == 1:\n            blk = self.coerce_to_target_dtype(value)\n            return blk.replace(\n                to_replace=to_replace,\n                value=value,\n                inplace=True,\n                mask=mask,\n            )\n\n        else:\n            # split so that we only upcast where necessary\n            return self.split_and_operate(\n                type(self).replace, to_replace, value, inplace=True\n            )\n\n    @final\n    def _replace_regex(\n        self,\n        to_replace,\n        value,\n        inplace: bool = False,\n        convert: bool = True,\n        mask=None,\n    ) -> list[Block]:\n        \"\"\"\n        Replace elements by the given value.\n\n        Parameters\n        ----------\n        to_replace : object or pattern\n            Scalar to replace or regular expression to match.\n        value : object\n            Replacement object.\n        inplace : bool, default False\n            Perform inplace modification.\n        convert : bool, default True\n            If true, try to coerce any object types to better types.\n        mask : array-like of bool, optional\n            True indicate corresponding element is ignored.\n\n        Returns\n        -------\n        List[Block]\n        \"\"\"\n        if not self._can_hold_element(to_replace):\n            # i.e. only ObjectBlock, but could in principle include a\n            #  String ExtensionBlock\n            return [self] if inplace else [self.copy()]\n\n        rx = re.compile(to_replace)\n\n        new_values = self.values if inplace else self.values.copy()\n        replace_regex(new_values, rx, value, mask)\n\n        block = self.make_block(new_values)\n        return [block]\n\n    @final\n    def replace_list(\n        self,\n        src_list: Iterable[Any],\n        dest_list: Sequence[Any],\n        inplace: bool = False,\n        regex: bool = False,\n    ) -> list[Block]:\n        \"\"\"\n        See BlockManager.replace_list docstring.\n        \"\"\"\n        values = self.values\n\n        # Exclude anything that we know we won't contain\n        pairs = [\n            (x, y) for x, y in zip(src_list, dest_list) if self._can_hold_element(x)\n        ]\n        if not len(pairs):\n            # shortcut, nothing to replace\n            return [self] if inplace else [self.copy()]\n\n        src_len = len(pairs) - 1\n\n        if is_string_dtype(values):\n            # Calculate the mask once, prior to the call of comp\n            # in order to avoid repeating the same computations\n            mask = ~isna(values)\n            masks = [\n                compare_or_regex_search(values, s[0], regex=regex, mask=mask)\n                for s in pairs\n            ]\n        else:\n            # GH#38086 faster if we know we dont need to check for regex\n            masks = [missing.mask_missing(values, s[0]) for s in pairs]\n\n        # error: Argument 1 to \"extract_bool_array\" has incompatible type\n        # \"Union[ExtensionArray, ndarray, bool]\"; expected \"Union[ExtensionArray,\n        # ndarray]\"\n        masks = [extract_bool_array(x) for x in masks]  # type: ignore[arg-type]\n\n        rb = [self if inplace else self.copy()]\n        for i, (src, dest) in enumerate(pairs):\n            convert = i == src_len  # only convert once at the end\n            new_rb: list[Block] = []\n\n            # GH-39338: _replace_coerce can split a block into\n            # single-column blocks, so track the index so we know\n            # where to index into the mask\n            for blk_num, blk in enumerate(rb):\n                if len(rb) == 1:\n                    m = masks[i]\n                else:\n                    mib = masks[i]\n                    assert not isinstance(mib, bool)\n                    m = mib[blk_num : blk_num + 1]\n\n                result = blk._replace_coerce(\n                    to_replace=src,\n                    value=dest,\n                    mask=m,\n                    inplace=inplace,\n                    regex=regex,\n                )\n                if convert and blk.is_object:\n                    result = extend_blocks(\n                        [b.convert(numeric=False, copy=True) for b in result]\n                    )\n                new_rb.extend(result)\n            rb = new_rb\n        return rb\n\n    @final\n    def _replace_coerce(\n        self,\n        to_replace,\n        value,\n        mask: np.ndarray,\n        inplace: bool = True,\n        regex: bool = False,\n    ) -> list[Block]:\n        \"\"\"\n        Replace value corresponding to the given boolean array with another\n        value.\n\n        Parameters\n        ----------\n        to_replace : object or pattern\n            Scalar to replace or regular expression to match.\n        value : object\n            Replacement object.\n        mask : np.ndarray[bool]\n            True indicate corresponding element is ignored.\n        inplace : bool, default True\n            Perform inplace modification.\n        regex : bool, default False\n            If true, perform regular expression substitution.\n\n        Returns\n        -------\n        List[Block]\n        \"\"\"\n        if should_use_regex(regex, to_replace):\n            return self._replace_regex(\n                to_replace,\n                value,\n                inplace=inplace,\n                convert=False,\n                mask=mask,\n            )\n        else:\n            return self.replace(\n                to_replace=to_replace, value=value, inplace=inplace, mask=mask\n            )\n\n    # ---------------------------------------------------------------------\n\n    def _maybe_squeeze_arg(self, arg: np.ndarray) -> np.ndarray:\n        \"\"\"\n        For compatibility with 1D-only ExtensionArrays.\n        \"\"\"\n        return arg\n\n    def setitem(self, indexer, value):\n        \"\"\"\n        Attempt self.values[indexer] = value, possibly creating a new array.\n\n        Parameters\n        ----------\n        indexer : tuple, list-like, array-like, slice, int\n            The subset of self.values to set\n        value : object\n            The value being set\n\n        Returns\n        -------\n        Block\n\n        Notes\n        -----\n        `indexer` is a direct slice/positional indexer. `value` must\n        be a compatible shape.\n        \"\"\"\n        transpose = self.ndim == 2\n\n        if isinstance(indexer, np.ndarray) and indexer.ndim > self.ndim:\n            raise ValueError(f\"Cannot set values with ndim > {self.ndim}\")\n\n        # coerce None values, if appropriate\n        if value is None:\n            if self.is_numeric:\n                value = np.nan\n\n        # coerce if block dtype can store value\n        values = cast(np.ndarray, self.values)\n        if not self._can_hold_element(value):\n            # current dtype cannot store value, coerce to common dtype\n            return self.coerce_to_target_dtype(value).setitem(indexer, value)\n\n        # value must be storable at this moment\n        if is_extension_array_dtype(getattr(value, \"dtype\", None)):\n            # We need to be careful not to allow through strings that\n            #  can be parsed to EADtypes\n            arr_value = value\n        else:\n            arr_value = np.asarray(value)\n\n        if transpose:\n            values = values.T\n\n        # length checking\n        check_setitem_lengths(indexer, value, values)\n\n        if is_empty_indexer(indexer, arr_value):\n            # GH#8669 empty indexers, test_loc_setitem_boolean_mask_allfalse\n            pass\n\n        elif is_scalar_indexer(indexer, self.ndim):\n            # setting a single element for each dim and with a rhs that could\n            #  be e.g. a list; see GH#6043\n            values[indexer] = value\n\n        else:\n            value = setitem_datetimelike_compat(values, len(values[indexer]), value)\n            values[indexer] = value\n\n        return self\n\n    def putmask(self, mask, new) -> list[Block]:\n        \"\"\"\n        putmask the data to the block; it is possible that we may create a\n        new dtype of block\n\n        Return the resulting block(s).\n\n        Parameters\n        ----------\n        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\n        new : a ndarray/object\n\n        Returns\n        -------\n        List[Block]\n        \"\"\"\n        orig_mask = mask\n        values = cast(np.ndarray, self.values)\n        mask, noop = validate_putmask(values.T, mask)\n        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\n\n        if new is lib.no_default:\n            new = self.fill_value\n\n        # if we are passed a scalar None, convert it here\n        if not self.is_object and is_valid_na_for_dtype(new, self.dtype):\n            new = self.fill_value\n\n        if self._can_hold_element(new):\n            putmask_without_repeat(values.T, mask, new)\n            return [self]\n\n        elif np_version_under1p20 and infer_dtype_from(new)[0].kind in [\"m\", \"M\"]:\n            # using putmask with object dtype will incorrectly cast to object\n            # Having excluded self._can_hold_element, we know we cannot operate\n            #  in-place, so we are safe using `where`\n            return self.where(new, ~mask)\n\n        elif noop:\n            return [self]\n\n        elif self.ndim == 1 or self.shape[0] == 1:\n            # no need to split columns\n\n            if not is_list_like(new):\n                # putmask_smart can't save us the need to cast\n                return self.coerce_to_target_dtype(new).putmask(mask, new)\n\n            # This differs from\n            #  `self.coerce_to_target_dtype(new).putmask(mask, new)`\n            # because putmask_smart will check if new[mask] may be held\n            # by our dtype.\n            nv = putmask_smart(values.T, mask, new).T\n            return [self.make_block(nv)]\n\n        else:\n            is_array = isinstance(new, np.ndarray)\n\n            res_blocks = []\n            nbs = self._split()\n            for i, nb in enumerate(nbs):\n                n = new\n                if is_array:\n                    # we have a different value per-column\n                    n = new[:, i : i + 1]\n\n                submask = orig_mask[:, i : i + 1]\n                rbs = nb.putmask(submask, n)\n                res_blocks.extend(rbs)\n            return res_blocks\n\n    @final\n    def coerce_to_target_dtype(self, other) -> Block:\n        \"\"\"\n        coerce the current block to a dtype compat for other\n        we will return a block, possibly object, and not raise\n\n        we can also safely try to coerce to the same dtype\n        and will receive the same block\n        \"\"\"\n        # if we cannot then coerce to object\n        dtype, _ = infer_dtype_from(other, pandas_dtype=True)\n\n        new_dtype = find_common_type([self.dtype, dtype])\n\n        return self.astype(new_dtype, copy=False)\n\n    def interpolate(\n        self,\n        method: str = \"pad\",\n        axis: int = 0,\n        index: Index | None = None,\n        inplace: bool = False,\n        limit: int | None = None,\n        limit_direction: str = \"forward\",\n        limit_area: str | None = None,\n        fill_value: Any | None = None,\n        coerce: bool = False,\n        downcast: str | None = None,\n        **kwargs,\n    ) -> list[Block]:\n\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\n\n        if not self._can_hold_na:\n            # If there are no NAs, then interpolate is a no-op\n            return [self] if inplace else [self.copy()]\n\n        if self.is_object and self.ndim == 2 and self.shape[0] != 1 and axis == 0:\n            # split improves performance in ndarray.copy()\n            return self.split_and_operate(\n                type(self).interpolate,\n                method,\n                axis,\n                index,\n                inplace,\n                limit,\n                limit_direction,\n                limit_area,\n                fill_value,\n                coerce,\n                downcast,\n                **kwargs,\n            )\n\n        try:\n            m = missing.clean_fill_method(method)\n        except ValueError:\n            m = None\n        if m is None and self.dtype.kind != \"f\":\n            # only deal with floats\n            # bc we already checked that can_hold_na, we dont have int dtype here\n            # TODO: make a copy if not inplace?\n            return [self]\n\n        data = self.values if inplace else self.values.copy()\n        data = cast(np.ndarray, data)  # bc overridden by ExtensionBlock\n\n        missing.interpolate_array_2d(\n            data,\n            method=method,\n            axis=axis,\n            index=index,\n            limit=limit,\n            limit_direction=limit_direction,\n            limit_area=limit_area,\n            fill_value=fill_value,\n            **kwargs,\n        )\n\n        nb = self.make_block_same_class(data)\n        return nb._maybe_downcast([nb], downcast)\n\n    def take_nd(\n        self,\n        indexer,\n        axis: int,\n        new_mgr_locs: BlockPlacement | None = None,\n        fill_value=lib.no_default,\n    ) -> Block:\n        \"\"\"\n        Take values according to indexer and return them as a block.bb\n\n        \"\"\"\n        # algos.take_nd dispatches for DatetimeTZBlock, CategoricalBlock\n        # so need to preserve types\n        # sparse is treated like an ndarray, but needs .get_values() shaping\n\n        values = self.values\n\n        if fill_value is lib.no_default:\n            fill_value = self.fill_value\n            allow_fill = False\n        else:\n            allow_fill = True\n\n        new_values = algos.take_nd(\n            values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value\n        )\n\n        # Called from three places in managers, all of which satisfy\n        #  this assertion\n        assert not (axis == 0 and new_mgr_locs is None)\n        if new_mgr_locs is None:\n            new_mgr_locs = self._mgr_locs\n\n        if not is_dtype_equal(new_values.dtype, self.dtype):\n            return self.make_block(new_values, new_mgr_locs)\n        else:\n            return self.make_block_same_class(new_values, new_mgr_locs)\n\n    def diff(self, n: int, axis: int = 1) -> list[Block]:\n        \"\"\"return block for the diff of the values\"\"\"\n        new_values = algos.diff(self.values, n, axis=axis)\n        return [self.make_block(values=new_values)]\n\n    def shift(self, periods: int, axis: int = 0, fill_value: Any = None) -> list[Block]:\n        \"\"\"shift the block by periods, possibly upcast\"\"\"\n        # convert integer to float if necessary. need to do a lot more than\n        # that, handle boolean etc also\n\n        values = cast(np.ndarray, self.values)\n\n        new_values, fill_value = maybe_upcast(values, fill_value)\n\n        new_values = shift(new_values, periods, axis, fill_value)\n\n        return [self.make_block(new_values)]\n\n    def where(self, other, cond) -> list[Block]:\n        \"\"\"\n        evaluate the block; return result block(s) from the result\n\n        Parameters\n        ----------\n        other : a ndarray/object\n        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\n\n        Returns\n        -------\n        List[Block]\n        \"\"\"\n        assert cond.ndim == self.ndim\n        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\n\n        transpose = self.ndim == 2\n\n        # EABlocks override where\n        values = cast(np.ndarray, self.values)\n        orig_other = other\n        if transpose:\n            values = values.T\n\n        icond, noop = validate_putmask(values, ~cond)\n\n        if other is lib.no_default:\n            other = self.fill_value\n\n        if is_valid_na_for_dtype(other, self.dtype) and self.dtype != _dtype_obj:\n            other = self.fill_value\n\n        if noop:\n            # TODO: avoid the downcasting at the end in this case?\n            # GH-39595: Always return a copy\n            result = values.copy()\n\n        elif not self._can_hold_element(other):\n            # we cannot coerce, return a compat dtype\n            block = self.coerce_to_target_dtype(other)\n            blocks = block.where(orig_other, cond)\n            return self._maybe_downcast(blocks, \"infer\")\n\n        else:\n            alt = setitem_datetimelike_compat(values, icond.sum(), other)\n            if alt is not other:\n                if is_list_like(other) and len(other) < len(values):\n                    # call np.where with other to get the appropriate ValueError\n                    np.where(~icond, values, other)\n                    raise NotImplementedError(\n                        \"This should not be reached; call to np.where above is \"\n                        \"expected to raise ValueError. Please report a bug at \"\n                        \"github.com/pandas-dev/pandas\"\n                    )\n                result = values.copy()\n                np.putmask(result, icond, alt)\n            else:\n                # By the time we get here, we should have all Series/Index\n                #  args extracted to ndarray\n                if (\n                    is_list_like(other)\n                    and not isinstance(other, np.ndarray)\n                    and len(other) == self.shape[-1]\n                ):\n                    # If we don't do this broadcasting here, then expressions.where\n                    #  will broadcast a 1D other to be row-like instead of\n                    #  column-like.\n                    other = np.array(other).reshape(values.shape)\n                    # If lengths don't match (or len(other)==1), we will raise\n                    #  inside expressions.where, see test_series_where\n\n                # Note: expressions.where may upcast.\n                result = expressions.where(~icond, values, other)\n\n        if self._can_hold_na or self.ndim == 1:\n\n            if transpose:\n                result = result.T\n\n            return [self.make_block(result)]\n\n        # might need to separate out blocks\n        cond = ~icond\n        axis = cond.ndim - 1\n        cond = cond.swapaxes(axis, 0)\n        mask = cond.all(axis=1)\n\n        result_blocks: list[Block] = []\n        for m in [mask, ~mask]:\n            if m.any():\n                taken = result.take(m.nonzero()[0], axis=axis)\n                r = maybe_downcast_numeric(taken, self.dtype)\n                nb = self.make_block(r.T, placement=self._mgr_locs[m])\n                result_blocks.append(nb)\n\n        return result_blocks\n\n    def _unstack(\n        self,\n        unstacker,\n        fill_value,\n        new_placement: npt.NDArray[np.intp],\n        needs_masking: npt.NDArray[np.bool_],\n    ):\n        \"\"\"\n        Return a list of unstacked blocks of self\n\n        Parameters\n        ----------\n        unstacker : reshape._Unstacker\n        fill_value : int\n            Only used in ExtensionBlock._unstack\n        new_placement : np.ndarray[np.intp]\n        allow_fill : bool\n        needs_masking : np.ndarray[bool]\n\n        Returns\n        -------\n        blocks : list of Block\n            New blocks of unstacked values.\n        mask : array-like of bool\n            The mask of columns of `blocks` we should keep.\n        \"\"\"\n        new_values, mask = unstacker.get_new_values(\n            self.values.T, fill_value=fill_value\n        )\n\n        mask = mask.any(0)\n        # TODO: in all tests we have mask.all(); can we rely on that?\n\n        # Note: these next two lines ensure that\n        #  mask.sum() == sum(len(nb.mgr_locs) for nb in blocks)\n        #  which the calling function needs in order to pass verify_integrity=False\n        #  to the BlockManager constructor\n        new_values = new_values.T[mask]\n        new_placement = new_placement[mask]\n\n        bp = BlockPlacement(new_placement)\n        blocks = [new_block_2d(new_values, placement=bp)]\n        return blocks, mask\n\n    @final\n    def quantile(\n        self, qs: Float64Index, interpolation=\"linear\", axis: int = 0\n    ) -> Block:\n        \"\"\"\n        compute the quantiles of the\n\n        Parameters\n        ----------\n        qs : Float64Index\n            List of the quantiles to be computed.\n        interpolation : str, default 'linear'\n            Type of interpolation.\n        axis : int, default 0\n            Axis to compute.\n\n        Returns\n        -------\n        Block\n        \"\"\"\n        # We should always have ndim == 2 because Series dispatches to DataFrame\n        assert self.ndim == 2\n        assert axis == 1  # only ever called this way\n        assert is_list_like(qs)  # caller is responsible for this\n\n        result = quantile_compat(self.values, np.asarray(qs._values), interpolation)\n        # ensure_block_shape needed for cases where we start with EA and result\n        #  is ndarray, e.g. IntegerArray, SparseArray\n        result = ensure_block_shape(result, ndim=2)\n        return new_block_2d(result, placement=self._mgr_locs)\n\n\nclass EABackedBlock(Block):\n    \"\"\"\n    Mixin for Block subclasses backed by ExtensionArray.\n    \"\"\"\n\n    values: ExtensionArray\n\n    def putmask(self, mask, new) -> list[Block]:\n        \"\"\"\n        See Block.putmask.__doc__\n        \"\"\"\n        mask = extract_bool_array(mask)\n\n        values = self.values\n\n        mask = self._maybe_squeeze_arg(mask)\n\n        try:\n            # Caller is responsible for ensuring matching lengths\n            values._putmask(mask, new)\n        except (TypeError, ValueError) as err:\n            if isinstance(err, ValueError) and \"Timezones don't match\" not in str(err):\n                # TODO(2.0): remove catching ValueError at all since\n                #  DTA raising here is deprecated\n                raise\n\n            if is_interval_dtype(self.dtype):\n                # Discussion about what we want to support in the general\n                #  case GH#39584\n                blk = self.coerce_to_target_dtype(new)\n                if blk.dtype == _dtype_obj:\n                    # For now at least, only support casting e.g.\n                    #  Interval[int64]->Interval[float64],\n                    raise\n                return blk.putmask(mask, new)\n\n            elif isinstance(self, NDArrayBackedExtensionBlock):\n                # NB: not (yet) the same as\n                #  isinstance(values, NDArrayBackedExtensionArray)\n                blk = self.coerce_to_target_dtype(new)\n                return blk.putmask(mask, new)\n\n            else:\n                raise\n\n        return [self]\n\n    def delete(self, loc) -> None:\n        \"\"\"\n        Delete given loc(-s) from block in-place.\n        \"\"\"\n        # This will be unnecessary if/when __array_function__ is implemented\n        self.values = self.values.delete(loc)\n        self.mgr_locs = self._mgr_locs.delete(loc)\n        try:\n            self._cache.clear()\n        except AttributeError:\n            # _cache not yet initialized\n            pass\n\n    @cache_readonly\n    def array_values(self) -> ExtensionArray:\n        return self.values\n\n    def get_values(self, dtype: DtypeObj | None = None) -> np.ndarray:\n        \"\"\"\n        return object dtype as boxed values, such as Timestamps/Timedelta\n        \"\"\"\n        values: ArrayLike = self.values\n        if dtype == _dtype_obj:\n            values = values.astype(object)\n        # TODO(EA2D): reshape not needed with 2D EAs\n        return np.asarray(values).reshape(self.shape)\n\n    def values_for_json(self) -> np.ndarray:\n        return np.asarray(self.values)\n\n    def interpolate(\n        self, method=\"pad\", axis=0, inplace=False, limit=None, fill_value=None, **kwargs\n    ):\n        values = self.values\n        if values.ndim == 2 and axis == 0:\n            # NDArrayBackedExtensionArray.fillna assumes axis=1\n            new_values = values.T.fillna(value=fill_value, method=method, limit=limit).T\n        else:\n            new_values = values.fillna(value=fill_value, method=method, limit=limit)\n        return self.make_block_same_class(new_values)\n\n\nclass ExtensionBlock(libinternals.Block, EABackedBlock):\n    \"\"\"\n    Block for holding extension types.\n\n    Notes\n    -----\n    This holds all 3rd-party extension array types. It's also the immediate\n    parent class for our internal extension types' blocks, CategoricalBlock.\n\n    ExtensionArrays are limited to 1-D.\n    \"\"\"\n\n    _can_consolidate = False\n    _validate_ndim = False\n    is_extension = True\n\n    values: ExtensionArray\n\n    @cache_readonly\n    def shape(self) -> Shape:\n        # TODO(EA2D): override unnecessary with 2D EAs\n        if self.ndim == 1:\n            return (len(self.values),)\n        return len(self._mgr_locs), len(self.values)\n\n    def iget(self, col):\n\n        if self.ndim == 2 and isinstance(col, tuple):\n            # TODO(EA2D): unnecessary with 2D EAs\n            col, loc = col\n            if not com.is_null_slice(col) and col != 0:\n                raise IndexError(f\"{self} only contains one item\")\n            elif isinstance(col, slice):\n                if col != slice(None):\n                    raise NotImplementedError(col)\n                return self.values[[loc]]\n            return self.values[loc]\n        else:\n            if col != 0:\n                raise IndexError(f\"{self} only contains one item\")\n            return self.values\n\n    def set_inplace(self, locs, values) -> None:\n        # NB: This is a misnomer, is supposed to be inplace but is not,\n        #  see GH#33457\n        # When an ndarray, we should have locs.tolist() == [0]\n        # When a BlockPlacement we should have list(locs) == [0]\n        self.values = values\n        try:\n            # TODO(GH33457) this can be removed\n            self._cache.clear()\n        except AttributeError:\n            # _cache not yet initialized\n            pass\n\n    def _maybe_squeeze_arg(self, arg):\n        \"\"\"\n        If necessary, squeeze a (N, 1) ndarray to (N,)\n        \"\"\"\n        # e.g. if we are passed a 2D mask for putmask\n        if isinstance(arg, np.ndarray) and arg.ndim == self.values.ndim + 1:\n            # TODO(EA2D): unnecessary with 2D EAs\n            assert arg.shape[1] == 1\n            arg = arg[:, 0]\n        return arg\n\n    @property\n    def is_view(self) -> bool:\n        \"\"\"Extension arrays are never treated as views.\"\"\"\n        return False\n\n    @cache_readonly\n    def is_numeric(self):\n        return self.values.dtype._is_numeric\n\n    def setitem(self, indexer, value):\n        \"\"\"\n        Attempt self.values[indexer] = value, possibly creating a new array.\n\n        This differs from Block.setitem by not allowing setitem to change\n        the dtype of the Block.\n\n        Parameters\n        ----------\n        indexer : tuple, list-like, array-like, slice, int\n            The subset of self.values to set\n        value : object\n            The value being set\n\n        Returns\n        -------\n        Block\n\n        Notes\n        -----\n        `indexer` is a direct slice/positional indexer. `value` must\n        be a compatible shape.\n        \"\"\"\n        if not self._can_hold_element(value):\n            # see TestSetitemFloatIntervalWithIntIntervalValues\n            return self.coerce_to_target_dtype(value).setitem(indexer, value)\n\n        if isinstance(indexer, tuple):\n            # TODO(EA2D): not needed with 2D EAs\n            # we are always 1-D\n            indexer = indexer[0]\n\n        # TODO(EA2D): not needed with 2D EAS\n        if isinstance(value, (np.ndarray, ExtensionArray)) and value.ndim == 2:\n            assert value.shape[1] == 1\n            # error: No overload variant of \"__getitem__\" of \"ExtensionArray\"\n            # matches argument type \"Tuple[slice, int]\"\n            value = value[:, 0]  # type: ignore[call-overload]\n        elif isinstance(value, ABCDataFrame):\n            # TODO: should we avoid getting here with DataFrame?\n            assert value.shape[1] == 1\n            value = value._ixs(0, axis=1)._values\n\n        check_setitem_lengths(indexer, value, self.values)\n        self.values[indexer] = value\n        return self\n\n    def take_nd(\n        self,\n        indexer,\n        axis: int = 0,\n        new_mgr_locs: BlockPlacement | None = None,\n        fill_value=lib.no_default,\n    ) -> Block:\n        \"\"\"\n        Take values according to indexer and return them as a block.\n        \"\"\"\n        if fill_value is lib.no_default:\n            fill_value = None\n\n        # TODO(EA2D): special case not needed with 2D EAs\n        # axis doesn't matter; we are really a single-dim object\n        # but are passed the axis depending on the calling routing\n        # if its REALLY axis 0, then this will be a reindex and not a take\n        new_values = self.values.take(indexer, fill_value=fill_value, allow_fill=True)\n\n        # Called from three places in managers, all of which satisfy\n        #  this assertion\n        assert not (self.ndim == 1 and new_mgr_locs is None)\n        if new_mgr_locs is None:\n            new_mgr_locs = self._mgr_locs\n\n        return self.make_block_same_class(new_values, new_mgr_locs)\n\n    def _slice(self, slicer) -> ExtensionArray:\n        \"\"\"\n        Return a slice of my values.\n\n        Parameters\n        ----------\n        slicer : slice, ndarray[int], or a tuple of these\n            Valid (non-reducing) indexer for self.values.\n\n        Returns\n        -------\n        ExtensionArray\n        \"\"\"\n        # return same dims as we currently have\n        if not isinstance(slicer, tuple) and self.ndim == 2:\n            # reached via getitem_block via _slice_take_blocks_ax0\n            # TODO(EA2D): won't be necessary with 2D EAs\n            slicer = (slicer, slice(None))\n\n        if isinstance(slicer, tuple) and len(slicer) == 2:\n            first = slicer[0]\n            if not isinstance(first, slice):\n                raise AssertionError(\n                    \"invalid slicing for a 1-ndim ExtensionArray\", first\n                )\n            # GH#32959 only full-slicers along fake-dim0 are valid\n            # TODO(EA2D): won't be necessary with 2D EAs\n            # range(1) instead of self._mgr_locs to avoid exception on [::-1]\n            #  see test_iloc_getitem_slice_negative_step_ea_block\n            new_locs = range(1)[first]\n            if len(new_locs):\n                # effectively slice(None)\n                slicer = slicer[1]\n            else:\n                raise AssertionError(\n                    \"invalid slicing for a 1-ndim ExtensionArray\", slicer\n                )\n\n        return self.values[slicer]\n\n    @final\n    def getitem_block_index(self, slicer: slice) -> ExtensionBlock:\n        \"\"\"\n        Perform __getitem__-like specialized to slicing along index.\n        \"\"\"\n        # GH#42787 in principle this is equivalent to values[..., slicer], but we don't\n        # require subclasses of ExtensionArray to support that form (for now).\n        new_values = self.values[slicer]\n        return type(self)(new_values, self._mgr_locs, ndim=self.ndim)\n\n    def fillna(\n        self, value, limit=None, inplace: bool = False, downcast=None\n    ) -> list[Block]:\n        values = self.values.fillna(value=value, limit=limit)\n        return [self.make_block_same_class(values=values)]\n\n    def diff(self, n: int, axis: int = 1) -> list[Block]:\n        if axis == 0 and n != 0:\n            # n==0 case will be a no-op so let is fall through\n            # Since we only have one column, the result will be all-NA.\n            #  Create this result by shifting along axis=0 past the length of\n            #  our values.\n            return super().diff(len(self.values), axis=0)\n        if axis == 1:\n            # TODO(EA2D): unnecessary with 2D EAs\n            # we are by definition 1D.\n            axis = 0\n        return super().diff(n, axis)\n\n    def shift(self, periods: int, axis: int = 0, fill_value: Any = None) -> list[Block]:\n        \"\"\"\n        Shift the block by `periods`.\n\n        Dispatches to underlying ExtensionArray and re-boxes in an\n        ExtensionBlock.\n        \"\"\"\n        new_values = self.values.shift(periods=periods, fill_value=fill_value)\n        return [self.make_block_same_class(new_values)]\n\n    def where(self, other, cond) -> list[Block]:\n\n        cond = extract_bool_array(cond)\n        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\n\n        other = self._maybe_squeeze_arg(other)\n        cond = self._maybe_squeeze_arg(cond)\n\n        if other is lib.no_default:\n            other = self.fill_value\n\n        icond, noop = validate_putmask(self.values, ~cond)\n        if noop:\n            return self.copy()\n\n        try:\n            result = self.values._where(cond, other)\n        except TypeError:\n            if is_interval_dtype(self.dtype):\n                # TestSetitemFloatIntervalWithIntIntervalValues\n                blk = self.coerce_to_target_dtype(other)\n                if blk.dtype == _dtype_obj:\n                    # For now at least only support casting e.g.\n                    #  Interval[int64]->Interval[float64]\n                    raise\n                return blk.where(other, cond)\n            raise\n\n        return [self.make_block_same_class(result)]\n\n    def _unstack(\n        self,\n        unstacker,\n        fill_value,\n        new_placement: npt.NDArray[np.intp],\n        needs_masking: npt.NDArray[np.bool_],\n    ):\n        # ExtensionArray-safe unstack.\n        # We override ObjectBlock._unstack, which unstacks directly on the\n        # values of the array. For EA-backed blocks, this would require\n        # converting to a 2-D ndarray of objects.\n        # Instead, we unstack an ndarray of integer positions, followed by\n        # a `take` on the actual values.\n\n        # Caller is responsible for ensuring self.shape[-1] == len(unstacker.index)\n        new_values, mask = unstacker.arange_result\n\n        # Note: these next two lines ensure that\n        #  mask.sum() == sum(len(nb.mgr_locs) for nb in blocks)\n        #  which the calling function needs in order to pass verify_integrity=False\n        #  to the BlockManager constructor\n        new_values = new_values.T[mask]\n        new_placement = new_placement[mask]\n\n        # needs_masking[i] calculated once in BlockManager.unstack tells\n        #  us if there are any -1s in the relevant indices.  When False,\n        #  that allows us to go through a faster path in 'take', among\n        #  other things avoiding e.g. Categorical._validate_scalar.\n        blocks = [\n            # TODO: could cast to object depending on fill_value?\n            type(self)(\n                self.values.take(\n                    indices, allow_fill=needs_masking[i], fill_value=fill_value\n                ),\n                BlockPlacement(place),\n                ndim=2,\n            )\n            for i, (indices, place) in enumerate(zip(new_values, new_placement))\n        ]\n        return blocks, mask\n\n\nclass NumpyBlock(libinternals.NumpyBlock, Block):\n    values: np.ndarray\n\n\nclass NumericBlock(NumpyBlock):\n    __slots__ = ()\n    is_numeric = True\n\n\nclass NDArrayBackedExtensionBlock(libinternals.NDArrayBackedBlock, EABackedBlock):\n    \"\"\"\n    Block backed by an NDArrayBackedExtensionArray\n    \"\"\"\n\n    values: NDArrayBackedExtensionArray\n\n    # error: Signature of \"is_extension\" incompatible with supertype \"Block\"\n    @cache_readonly\n    def is_extension(self) -> bool:  # type: ignore[override]\n        # i.e. datetime64tz, PeriodDtype\n        return not isinstance(self.dtype, np.dtype)\n\n    @property\n    def is_view(self) -> bool:\n        \"\"\"return a boolean if I am possibly a view\"\"\"\n        # check the ndarray values of the DatetimeIndex values\n        return self.values._ndarray.base is not None\n\n    def setitem(self, indexer, value):\n        if not self._can_hold_element(value):\n            return self.coerce_to_target_dtype(value).setitem(indexer, value)\n\n        values = self.values\n        if self.ndim > 1:\n            # Dont transpose with ndim=1 bc we would fail to invalidate\n            #  arr.freq\n            values = values.T\n        values[indexer] = value\n        return self\n\n    def where(self, other, cond) -> list[Block]:\n        arr = self.values\n\n        cond = extract_bool_array(cond)\n        if other is lib.no_default:\n            other = self.fill_value\n\n        try:\n            res_values = arr.T._where(cond, other).T\n        except (ValueError, TypeError):\n            if isinstance(self.dtype, PeriodDtype):\n                # TODO: don't special-case\n                raise\n            blk = self.coerce_to_target_dtype(other)\n            nbs = blk.where(other, cond)\n            return self._maybe_downcast(nbs, \"infer\")\n\n        nb = self.make_block_same_class(res_values)\n        return [nb]\n\n    def diff(self, n: int, axis: int = 0) -> list[Block]:\n        \"\"\"\n        1st discrete difference.\n\n        Parameters\n        ----------\n        n : int\n            Number of periods to diff.\n        axis : int, default 0\n            Axis to diff upon.\n\n        Returns\n        -------\n        A list with a new Block.\n\n        Notes\n        -----\n        The arguments here are mimicking shift so they are called correctly\n        by apply.\n        \"\"\"\n        values = self.values\n\n        new_values = values - values.shift(n, axis=axis)\n        return [self.make_block(new_values)]\n\n    def shift(self, periods: int, axis: int = 0, fill_value: Any = None) -> list[Block]:\n        values = self.values\n        new_values = values.shift(periods, fill_value=fill_value, axis=axis)\n        return [self.make_block_same_class(new_values)]\n\n    def fillna(\n        self, value, limit=None, inplace: bool = False, downcast=None\n    ) -> list[Block]:\n\n        if not self._can_hold_element(value) and self.dtype.kind != \"m\":\n            # We support filling a DatetimeTZ with a `value` whose timezone\n            #  is different by coercing to object.\n            # TODO: don't special-case td64\n            return self.coerce_to_target_dtype(value).fillna(\n                value, limit, inplace, downcast\n            )\n\n        new_values = self.values.fillna(value=value, limit=limit)\n        return [self.make_block_same_class(values=new_values)]\n\n\nclass DatetimeLikeBlock(NDArrayBackedExtensionBlock):\n    \"\"\"Block for datetime64[ns], timedelta64[ns].\"\"\"\n\n    __slots__ = ()\n    is_numeric = False\n    values: DatetimeArray | TimedeltaArray\n\n    def values_for_json(self) -> np.ndarray:\n        # special casing datetimetz to avoid conversion through\n        #  object dtype\n        return self.values._ndarray\n\n\nclass DatetimeTZBlock(DatetimeLikeBlock):\n    \"\"\"implement a datetime64 block with a tz attribute\"\"\"\n\n    values: DatetimeArray\n\n    __slots__ = ()\n    is_extension = True\n    _validate_ndim = True\n    _can_consolidate = False\n\n\nclass ObjectBlock(NumpyBlock):\n    __slots__ = ()\n    is_object = True\n\n    @maybe_split\n    def reduce(self, func, ignore_failures: bool = False) -> list[Block]:\n        \"\"\"\n        For object-dtype, we operate column-wise.\n        \"\"\"\n        assert self.ndim == 2\n\n        try:\n            res = func(self.values)\n        except TypeError:\n            if not ignore_failures:\n                raise\n            return []\n\n        assert isinstance(res, np.ndarray)\n        assert res.ndim == 1\n        res = res.reshape(1, -1)\n        return [self.make_block_same_class(res)]\n\n    @maybe_split\n    def convert(\n        self,\n        copy: bool = True,\n        datetime: bool = True,\n        numeric: bool = True,\n        timedelta: bool = True,\n    ) -> list[Block]:\n        \"\"\"\n        attempt to cast any object types to better types return a copy of\n        the block (if copy = True) by definition we ARE an ObjectBlock!!!!!\n        \"\"\"\n        res_values = soft_convert_objects(\n            self.values.ravel(),\n            datetime=datetime,\n            numeric=numeric,\n            timedelta=timedelta,\n            copy=copy,\n        )\n        res_values = ensure_block_shape(res_values, self.ndim)\n        return [self.make_block(res_values)]\n\n\nclass CategoricalBlock(ExtensionBlock):\n    # this Block type is kept for backwards-compatibility\n    __slots__ = ()\n\n    # GH#43232, GH#43334 self.values.dtype can be changed inplace until 2.0,\n    #  so this cannot be cached\n    @property\n    def dtype(self) -> DtypeObj:\n        return self.values.dtype\n\n\n# -----------------------------------------------------------------\n# Constructor Helpers\n\n\ndef maybe_coerce_values(values: ArrayLike) -> ArrayLike:\n    \"\"\"\n    Input validation for values passed to __init__. Ensure that\n    any datetime64/timedelta64 dtypes are in nanoseconds.  Ensure\n    that we do not have string dtypes.\n\n    Parameters\n    ----------\n    values : np.ndarray or ExtensionArray\n\n    Returns\n    -------\n    values : np.ndarray or ExtensionArray\n    \"\"\"\n    # Caller is responsible for ensuring PandasArray is already extracted.\n\n    if isinstance(values, np.ndarray):\n        values = ensure_wrapped_if_datetimelike(values)\n\n        if issubclass(values.dtype.type, str):\n            values = np.array(values, dtype=object)\n\n    if isinstance(values, (DatetimeArray, TimedeltaArray)) and values.freq is not None:\n        # freq is only stored in DatetimeIndex/TimedeltaIndex, not in Series/DataFrame\n        values = values._with_freq(None)\n\n    return values\n\n\ndef get_block_type(dtype: DtypeObj):\n    \"\"\"\n    Find the appropriate Block subclass to use for the given values and dtype.\n\n    Parameters\n    ----------\n    dtype : numpy or pandas dtype\n\n    Returns\n    -------\n    cls : class, subclass of Block\n    \"\"\"\n    # We use vtype and kind checks because they are much more performant\n    #  than is_foo_dtype\n    vtype = dtype.type\n    kind = dtype.kind\n\n    cls: type[Block]\n\n    if isinstance(dtype, SparseDtype):\n        # Need this first(ish) so that Sparse[datetime] is sparse\n        cls = ExtensionBlock\n    elif isinstance(dtype, CategoricalDtype):\n        cls = CategoricalBlock\n    elif vtype is Timestamp:\n        cls = DatetimeTZBlock\n    elif isinstance(dtype, PeriodDtype):\n        cls = NDArrayBackedExtensionBlock\n    elif isinstance(dtype, ExtensionDtype):\n        # Note: need to be sure PandasArray is unwrapped before we get here\n        cls = ExtensionBlock\n\n    elif kind in [\"M\", \"m\"]:\n        cls = DatetimeLikeBlock\n    elif kind in [\"f\", \"c\", \"i\", \"u\", \"b\"]:\n        cls = NumericBlock\n    else:\n        cls = ObjectBlock\n    return cls\n\n\ndef new_block_2d(values: ArrayLike, placement: BlockPlacement):\n    # new_block specialized to case with\n    #  ndim=2\n    #  isinstance(placement, BlockPlacement)\n    #  check_ndim/ensure_block_shape already checked\n    klass = get_block_type(values.dtype)\n\n    values = maybe_coerce_values(values)\n    return klass(values, ndim=2, placement=placement)\n\n\ndef new_block(values, placement, *, ndim: int) -> Block:\n    # caller is responsible for ensuring values is NOT a PandasArray\n\n    if not isinstance(placement, BlockPlacement):\n        placement = BlockPlacement(placement)\n\n    check_ndim(values, placement, ndim)\n\n    klass = get_block_type(values.dtype)\n\n    values = maybe_coerce_values(values)\n    return klass(values, ndim=ndim, placement=placement)\n\n\ndef check_ndim(values, placement: BlockPlacement, ndim: int):\n    \"\"\"\n    ndim inference and validation.\n\n    Validates that values.ndim and ndim are consistent.\n    Validates that len(values) and len(placement) are consistent.\n\n    Parameters\n    ----------\n    values : array-like\n    placement : BlockPlacement\n    ndim : int\n\n    Raises\n    ------\n    ValueError : the number of dimensions do not match\n    \"\"\"\n\n    if values.ndim > ndim:\n        # Check for both np.ndarray and ExtensionArray\n        raise ValueError(\n            \"Wrong number of dimensions. \"\n            f\"values.ndim > ndim [{values.ndim} > {ndim}]\"\n        )\n\n    elif not is_1d_only_ea_dtype(values.dtype):\n        # TODO(EA2D): special case not needed with 2D EAs\n        if values.ndim != ndim:\n            raise ValueError(\n                \"Wrong number of dimensions. \"\n                f\"values.ndim != ndim [{values.ndim} != {ndim}]\"\n            )\n        if len(placement) != len(values):\n            raise ValueError(\n                f\"Wrong number of items passed {len(values)}, \"\n                f\"placement implies {len(placement)}\"\n            )\n    elif ndim == 2 and len(placement) != 1:\n        # TODO(EA2D): special case unnecessary with 2D EAs\n        raise ValueError(\"need to split\")\n\n\ndef extract_pandas_array(\n    values: np.ndarray | ExtensionArray, dtype: DtypeObj | None, ndim: int\n) -> tuple[np.ndarray | ExtensionArray, DtypeObj | None]:\n    \"\"\"\n    Ensure that we don't allow PandasArray / PandasDtype in internals.\n    \"\"\"\n    # For now, blocks should be backed by ndarrays when possible.\n    if isinstance(values, ABCPandasArray):\n        values = values.to_numpy()\n        if ndim and ndim > 1:\n            # TODO(EA2D): special case not needed with 2D EAs\n            values = np.atleast_2d(values)\n\n    if isinstance(dtype, PandasDtype):\n        dtype = dtype.numpy_dtype\n\n    return values, dtype\n\n\n# -----------------------------------------------------------------\n\n\ndef extend_blocks(result, blocks=None) -> list[Block]:\n    \"\"\"return a new extended blocks, given the result\"\"\"\n    if blocks is None:\n        blocks = []\n    if isinstance(result, list):\n        for r in result:\n            if isinstance(r, list):\n                blocks.extend(r)\n            else:\n                blocks.append(r)\n    else:\n        assert isinstance(result, Block), type(result)\n        blocks.append(result)\n    return blocks\n\n\ndef ensure_block_shape(values: ArrayLike, ndim: int = 1) -> ArrayLike:\n    \"\"\"\n    Reshape if possible to have values.ndim == ndim.\n    \"\"\"\n\n    if values.ndim < ndim:\n        if not is_1d_only_ea_dtype(values.dtype):\n            # TODO(EA2D): https://github.com/pandas-dev/pandas/issues/23023\n            # block.shape is incorrect for \"2D\" ExtensionArrays\n            # We can't, and don't need to, reshape.\n            values = cast(\"np.ndarray | DatetimeArray | TimedeltaArray\", values)\n            values = values.reshape(1, -1)\n\n    return values\n\n\ndef to_native_types(\n    values: ArrayLike,\n    *,\n    na_rep=\"nan\",\n    quoting=None,\n    float_format=None,\n    decimal=\".\",\n    **kwargs,\n) -> np.ndarray:\n    \"\"\"convert to our native types format\"\"\"\n    values = ensure_wrapped_if_datetimelike(values)\n\n    if isinstance(values, (DatetimeArray, TimedeltaArray)):\n        result = values._format_native_types(na_rep=na_rep, **kwargs)\n        result = result.astype(object, copy=False)\n        return result\n\n    elif isinstance(values, ExtensionArray):\n        mask = isna(values)\n\n        new_values = np.asarray(values.astype(object))\n        new_values[mask] = na_rep\n        return new_values\n\n    elif values.dtype.kind == \"f\":\n        # see GH#13418: no special formatting is desired at the\n        # output (important for appropriate 'quoting' behaviour),\n        # so do not pass it through the FloatArrayFormatter\n        if float_format is None and decimal == \".\":\n            mask = isna(values)\n\n            if not quoting:\n                values = values.astype(str)\n            else:\n                values = np.array(values, dtype=\"object\")\n\n            values[mask] = na_rep\n            values = values.astype(object, copy=False)\n            return values\n\n        from pandas.io.formats.format import FloatArrayFormatter\n\n        formatter = FloatArrayFormatter(\n            values,\n            na_rep=na_rep,\n            float_format=float_format,\n            decimal=decimal,\n            quoting=quoting,\n            fixed_width=False,\n        )\n        res = formatter.get_result_as_array()\n        res = res.astype(object, copy=False)\n        return res\n\n    else:\n\n        mask = isna(values)\n        itemsize = writers.word_len(na_rep)\n\n        if values.dtype != _dtype_obj and not quoting and itemsize:\n            values = values.astype(str)\n            if values.dtype.itemsize / np.dtype(\"U1\").itemsize < itemsize:\n                # enlarge for the na_rep\n                values = values.astype(f\"<U{itemsize}\")\n        else:\n            values = np.array(values, dtype=\"object\")\n\n        values[mask] = na_rep\n        values = values.astype(object, copy=False)\n        return values\n\n\ndef external_values(values: ArrayLike) -> ArrayLike:\n    \"\"\"\n    The array that Series.values returns (public attribute).\n\n    This has some historical constraints, and is overridden in block\n    subclasses to return the correct array (e.g. period returns\n    object ndarray and datetimetz a datetime64[ns] ndarray instead of\n    proper extension array).\n    \"\"\"\n    if isinstance(values, (PeriodArray, IntervalArray)):\n        return values.astype(object)\n    elif isinstance(values, (DatetimeArray, TimedeltaArray)):\n        # NB: for datetime64tz this is different from np.asarray(values), since\n        #  that returns an object-dtype ndarray of Timestamps.\n        # Avoid FutureWarning in .astype in casting from dt64tz to dt64\n        return values._data\n    else:\n        return values\n"
    },
    {
      "filename": "pandas/tests/arrays/categorical/test_replace.py",
      "content": "import pytest\n\nimport pandas as pd\nfrom pandas import Categorical\nimport pandas._testing as tm\n\n\n@pytest.mark.parametrize(\n    \"to_replace,value,expected,flip_categories\",\n    [\n        # one-to-one\n        (1, 2, [2, 2, 3], False),\n        (1, 4, [4, 2, 3], False),\n        (4, 1, [1, 2, 3], False),\n        (5, 6, [1, 2, 3], False),\n        # many-to-one\n        ([1], 2, [2, 2, 3], False),\n        ([1, 2], 3, [3, 3, 3], False),\n        ([1, 2], 4, [4, 4, 3], False),\n        ((1, 2, 4), 5, [5, 5, 3], False),\n        ((5, 6), 2, [1, 2, 3], False),\n        ([1], [2], [2, 2, 3], False),\n        ([1, 4], [5, 2], [5, 2, 3], False),\n        # check_categorical sorts categories, which crashes on mixed dtypes\n        (3, \"4\", [1, 2, \"4\"], False),\n        ([1, 2, \"3\"], \"5\", [\"5\", \"5\", 3], True),\n    ],\n)\ndef test_replace_categorical_series(to_replace, value, expected, flip_categories):\n    # GH 31720\n\n    ser = pd.Series([1, 2, 3], dtype=\"category\")\n    result = ser.replace(to_replace, value)\n    expected = pd.Series(expected, dtype=\"category\")\n    ser.replace(to_replace, value, inplace=True)\n\n    if flip_categories:\n        expected = expected.cat.set_categories(expected.cat.categories[::-1])\n\n    tm.assert_series_equal(expected, result, check_category_order=False)\n    tm.assert_series_equal(expected, ser, check_category_order=False)\n\n\n@pytest.mark.parametrize(\n    \"to_replace, value, result, expected_error_msg\",\n    [\n        (\"b\", \"c\", [\"a\", \"c\"], \"Categorical.categories are different\"),\n        (\"c\", \"d\", [\"a\", \"b\"], None),\n        # https://github.com/pandas-dev/pandas/issues/33288\n        (\"a\", \"a\", [\"a\", \"b\"], None),\n        (\"b\", None, [\"a\", None], \"Categorical.categories length are different\"),\n    ],\n)\ndef test_replace_categorical(to_replace, value, result, expected_error_msg):\n    # GH#26988\n    cat = Categorical([\"a\", \"b\"])\n    expected = Categorical(result)\n    with tm.assert_produces_warning(FutureWarning, match=\"Series.replace\"):\n        # GH#44929 replace->_replace\n        result = cat.replace(to_replace, value)\n\n    tm.assert_categorical_equal(result, expected)\n    if to_replace == \"b\":  # the \"c\" test is supposed to be unchanged\n        with pytest.raises(AssertionError, match=expected_error_msg):\n            # ensure non-inplace call does not affect original\n            tm.assert_categorical_equal(cat, expected)\n\n    with tm.assert_produces_warning(FutureWarning, match=\"Series.replace\"):\n        # GH#44929 replace->_replace\n        cat.replace(to_replace, value, inplace=True)\n\n    tm.assert_categorical_equal(cat, expected)\n"
    },
    {
      "filename": "pandas/tests/frame/methods/test_replace.py",
      "content": "from __future__ import annotations\n\nfrom datetime import datetime\nimport re\n\nimport numpy as np\nimport pytest\n\nfrom pandas.compat import np_version_under1p20\n\nimport pandas as pd\nfrom pandas import (\n    DataFrame,\n    Index,\n    Series,\n    Timestamp,\n    date_range,\n)\nimport pandas._testing as tm\n\n\n@pytest.fixture\ndef mix_ab() -> dict[str, list[int | str]]:\n    return {\"a\": list(range(4)), \"b\": list(\"ab..\")}\n\n\n@pytest.fixture\ndef mix_abc() -> dict[str, list[float | str]]:\n    return {\"a\": list(range(4)), \"b\": list(\"ab..\"), \"c\": [\"a\", \"b\", np.nan, \"d\"]}\n\n\nclass TestDataFrameReplace:\n    def test_replace_inplace(self, datetime_frame, float_string_frame):\n        datetime_frame[\"A\"][:5] = np.nan\n        datetime_frame[\"A\"][-5:] = np.nan\n\n        tsframe = datetime_frame.copy()\n        return_value = tsframe.replace(np.nan, 0, inplace=True)\n        assert return_value is None\n        tm.assert_frame_equal(tsframe, datetime_frame.fillna(0))\n\n        # mixed type\n        mf = float_string_frame\n        mf.iloc[5:20, mf.columns.get_loc(\"foo\")] = np.nan\n        mf.iloc[-10:, mf.columns.get_loc(\"A\")] = np.nan\n\n        result = float_string_frame.replace(np.nan, 0)\n        expected = float_string_frame.fillna(value=0)\n        tm.assert_frame_equal(result, expected)\n\n        tsframe = datetime_frame.copy()\n        return_value = tsframe.replace([np.nan], [0], inplace=True)\n        assert return_value is None\n        tm.assert_frame_equal(tsframe, datetime_frame.fillna(0))\n\n    @pytest.mark.parametrize(\n        \"to_replace,values,expected\",\n        [\n            # lists of regexes and values\n            # list of [re1, re2, ..., reN] -> [v1, v2, ..., vN]\n            (\n                [r\"\\s*\\.\\s*\", r\"e|f|g\"],\n                [np.nan, \"crap\"],\n                {\n                    \"a\": [\"a\", \"b\", np.nan, np.nan],\n                    \"b\": [\"crap\"] * 3 + [\"h\"],\n                    \"c\": [\"h\", \"crap\", \"l\", \"o\"],\n                },\n            ),\n            # list of [re1, re2, ..., reN] -> [re1, re2, .., reN]\n            (\n                [r\"\\s*(\\.)\\s*\", r\"(e|f|g)\"],\n                [r\"\\1\\1\", r\"\\1_crap\"],\n                {\n                    \"a\": [\"a\", \"b\", \"..\", \"..\"],\n                    \"b\": [\"e_crap\", \"f_crap\", \"g_crap\", \"h\"],\n                    \"c\": [\"h\", \"e_crap\", \"l\", \"o\"],\n                },\n            ),\n            # list of [re1, re2, ..., reN] -> [(re1 or v1), (re2 or v2), ..., (reN\n            # or vN)]\n            (\n                [r\"\\s*(\\.)\\s*\", r\"e\"],\n                [r\"\\1\\1\", r\"crap\"],\n                {\n                    \"a\": [\"a\", \"b\", \"..\", \"..\"],\n                    \"b\": [\"crap\", \"f\", \"g\", \"h\"],\n                    \"c\": [\"h\", \"crap\", \"l\", \"o\"],\n                },\n            ),\n        ],\n    )\n    @pytest.mark.parametrize(\"inplace\", [True, False])\n    @pytest.mark.parametrize(\"use_value_regex_args\", [True, False])\n    def test_regex_replace_list_obj(\n        self, to_replace, values, expected, inplace, use_value_regex_args\n    ):\n        df = DataFrame({\"a\": list(\"ab..\"), \"b\": list(\"efgh\"), \"c\": list(\"helo\")})\n\n        if use_value_regex_args:\n            result = df.replace(value=values, regex=to_replace, inplace=inplace)\n        else:\n            result = df.replace(to_replace, values, regex=True, inplace=inplace)\n\n        if inplace:\n            assert result is None\n            result = df\n\n        expected = DataFrame(expected)\n        tm.assert_frame_equal(result, expected)\n\n    def test_regex_replace_list_mixed(self, mix_ab):\n        # mixed frame to make sure this doesn't break things\n        dfmix = DataFrame(mix_ab)\n\n        # lists of regexes and values\n        # list of [re1, re2, ..., reN] -> [v1, v2, ..., vN]\n        to_replace_res = [r\"\\s*\\.\\s*\", r\"a\"]\n        values = [np.nan, \"crap\"]\n        mix2 = {\"a\": list(range(4)), \"b\": list(\"ab..\"), \"c\": list(\"halo\")}\n        dfmix2 = DataFrame(mix2)\n        res = dfmix2.replace(to_replace_res, values, regex=True)\n        expec = DataFrame(\n            {\n                \"a\": mix2[\"a\"],\n                \"b\": [\"crap\", \"b\", np.nan, np.nan],\n                \"c\": [\"h\", \"crap\", \"l\", \"o\"],\n            }\n        )\n        tm.assert_frame_equal(res, expec)\n\n        # list of [re1, re2, ..., reN] -> [re1, re2, .., reN]\n        to_replace_res = [r\"\\s*(\\.)\\s*\", r\"(a|b)\"]\n        values = [r\"\\1\\1\", r\"\\1_crap\"]\n        res = dfmix.replace(to_replace_res, values, regex=True)\n        expec = DataFrame({\"a\": mix_ab[\"a\"], \"b\": [\"a_crap\", \"b_crap\", \"..\", \"..\"]})\n        tm.assert_frame_equal(res, expec)\n\n        # list of [re1, re2, ..., reN] -> [(re1 or v1), (re2 or v2), ..., (reN\n        # or vN)]\n        to_replace_res = [r\"\\s*(\\.)\\s*\", r\"a\", r\"(b)\"]\n        values = [r\"\\1\\1\", r\"crap\", r\"\\1_crap\"]\n        res = dfmix.replace(to_replace_res, values, regex=True)\n        expec = DataFrame({\"a\": mix_ab[\"a\"], \"b\": [\"crap\", \"b_crap\", \"..\", \"..\"]})\n        tm.assert_frame_equal(res, expec)\n\n        to_replace_res = [r\"\\s*(\\.)\\s*\", r\"a\", r\"(b)\"]\n        values = [r\"\\1\\1\", r\"crap\", r\"\\1_crap\"]\n        res = dfmix.replace(regex=to_replace_res, value=values)\n        expec = DataFrame({\"a\": mix_ab[\"a\"], \"b\": [\"crap\", \"b_crap\", \"..\", \"..\"]})\n        tm.assert_frame_equal(res, expec)\n\n    def test_regex_replace_list_mixed_inplace(self, mix_ab):\n        dfmix = DataFrame(mix_ab)\n        # the same inplace\n        # lists of regexes and values\n        # list of [re1, re2, ..., reN] -> [v1, v2, ..., vN]\n        to_replace_res = [r\"\\s*\\.\\s*\", r\"a\"]\n        values = [np.nan, \"crap\"]\n        res = dfmix.copy()\n        return_value = res.replace(to_replace_res, values, inplace=True, regex=True)\n        assert return_value is None\n        expec = DataFrame({\"a\": mix_ab[\"a\"], \"b\": [\"crap\", \"b\", np.nan, np.nan]})\n        tm.assert_frame_equal(res, expec)\n\n        # list of [re1, re2, ..., reN] -> [re1, re2, .., reN]\n        to_replace_res = [r\"\\s*(\\.)\\s*\", r\"(a|b)\"]\n        values = [r\"\\1\\1\", r\"\\1_crap\"]\n        res = dfmix.copy()\n        return_value = res.replace(to_replace_res, values, inplace=True, regex=True)\n        assert return_value is None\n        expec = DataFrame({\"a\": mix_ab[\"a\"], \"b\": [\"a_crap\", \"b_crap\", \"..\", \"..\"]})\n        tm.assert_frame_equal(res, expec)\n\n        # list of [re1, re2, ..., reN] -> [(re1 or v1), (re2 or v2), ..., (reN\n        # or vN)]\n        to_replace_res = [r\"\\s*(\\.)\\s*\", r\"a\", r\"(b)\"]\n        values = [r\"\\1\\1\", r\"crap\", r\"\\1_crap\"]\n        res = dfmix.copy()\n        return_value = res.replace(to_replace_res, values, inplace=True, regex=True)\n        assert return_value is None\n        expec = DataFrame({\"a\": mix_ab[\"a\"], \"b\": [\"crap\", \"b_crap\", \"..\", \"..\"]})\n        tm.assert_frame_equal(res, expec)\n\n        to_replace_res = [r\"\\s*(\\.)\\s*\", r\"a\", r\"(b)\"]\n        values = [r\"\\1\\1\", r\"crap\", r\"\\1_crap\"]\n        res = dfmix.copy()\n        return_value = res.replace(regex=to_replace_res, value=values, inplace=True)\n        assert return_value is None\n        expec = DataFrame({\"a\": mix_ab[\"a\"], \"b\": [\"crap\", \"b_crap\", \"..\", \"..\"]})\n        tm.assert_frame_equal(res, expec)\n\n    def test_regex_replace_dict_mixed(self, mix_abc):\n        dfmix = DataFrame(mix_abc)\n\n        # dicts\n        # single dict {re1: v1}, search the whole frame\n        # need test for this...\n\n        # list of dicts {re1: v1, re2: v2, ..., re3: v3}, search the whole\n        # frame\n        res = dfmix.replace({\"b\": r\"\\s*\\.\\s*\"}, {\"b\": np.nan}, regex=True)\n        res2 = dfmix.copy()\n        return_value = res2.replace(\n            {\"b\": r\"\\s*\\.\\s*\"}, {\"b\": np.nan}, inplace=True, regex=True\n        )\n        assert return_value is None\n        expec = DataFrame(\n            {\"a\": mix_abc[\"a\"], \"b\": [\"a\", \"b\", np.nan, np.nan], \"c\": mix_abc[\"c\"]}\n        )\n        tm.assert_frame_equal(res, expec)\n        tm.assert_frame_equal(res2, expec)\n\n        # list of dicts {re1: re11, re2: re12, ..., reN: re1N}, search the\n        # whole frame\n        res = dfmix.replace({\"b\": r\"\\s*(\\.)\\s*\"}, {\"b\": r\"\\1ty\"}, regex=True)\n        res2 = dfmix.copy()\n        return_value = res2.replace(\n            {\"b\": r\"\\s*(\\.)\\s*\"}, {\"b\": r\"\\1ty\"}, inplace=True, regex=True\n        )\n        assert return_value is None\n        expec = DataFrame(\n            {\"a\": mix_abc[\"a\"], \"b\": [\"a\", \"b\", \".ty\", \".ty\"], \"c\": mix_abc[\"c\"]}\n        )\n        tm.assert_frame_equal(res, expec)\n        tm.assert_frame_equal(res2, expec)\n\n        res = dfmix.replace(regex={\"b\": r\"\\s*(\\.)\\s*\"}, value={\"b\": r\"\\1ty\"})\n        res2 = dfmix.copy()\n        return_value = res2.replace(\n            regex={\"b\": r\"\\s*(\\.)\\s*\"}, value={\"b\": r\"\\1ty\"}, inplace=True\n        )\n        assert return_value is None\n        expec = DataFrame(\n            {\"a\": mix_abc[\"a\"], \"b\": [\"a\", \"b\", \".ty\", \".ty\"], \"c\": mix_abc[\"c\"]}\n        )\n        tm.assert_frame_equal(res, expec)\n        tm.assert_frame_equal(res2, expec)\n\n        # scalar -> dict\n        # to_replace regex, {value: value}\n        expec = DataFrame(\n            {\"a\": mix_abc[\"a\"], \"b\": [np.nan, \"b\", \".\", \".\"], \"c\": mix_abc[\"c\"]}\n        )\n        res = dfmix.replace(\"a\", {\"b\": np.nan}, regex=True)\n        res2 = dfmix.copy()\n        return_value = res2.replace(\"a\", {\"b\": np.nan}, regex=True, inplace=True)\n        assert return_value is None\n        tm.assert_frame_equal(res, expec)\n        tm.assert_frame_equal(res2, expec)\n\n        res = dfmix.replace(\"a\", {\"b\": np.nan}, regex=True)\n        res2 = dfmix.copy()\n        return_value = res2.replace(regex=\"a\", value={\"b\": np.nan}, inplace=True)\n        assert return_value is None\n        expec = DataFrame(\n            {\"a\": mix_abc[\"a\"], \"b\": [np.nan, \"b\", \".\", \".\"], \"c\": mix_abc[\"c\"]}\n        )\n        tm.assert_frame_equal(res, expec)\n        tm.assert_frame_equal(res2, expec)\n\n    def test_regex_replace_dict_nested(self, mix_abc):\n        # nested dicts will not work until this is implemented for Series\n        dfmix = DataFrame(mix_abc)\n        res = dfmix.replace({\"b\": {r\"\\s*\\.\\s*\": np.nan}}, regex=True)\n        res2 = dfmix.copy()\n        res4 = dfmix.copy()\n        return_value = res2.replace(\n            {\"b\": {r\"\\s*\\.\\s*\": np.nan}}, inplace=True, regex=True\n        )\n        assert return_value is None\n        res3 = dfmix.replace(regex={\"b\": {r\"\\s*\\.\\s*\": np.nan}})\n        return_value = res4.replace(regex={\"b\": {r\"\\s*\\.\\s*\": np.nan}}, inplace=True)\n        assert return_value is None\n        expec = DataFrame(\n            {\"a\": mix_abc[\"a\"], \"b\": [\"a\", \"b\", np.nan, np.nan], \"c\": mix_abc[\"c\"]}\n        )\n        tm.assert_frame_equal(res, expec)\n        tm.assert_frame_equal(res2, expec)\n        tm.assert_frame_equal(res3, expec)\n        tm.assert_frame_equal(res4, expec)\n\n    def test_regex_replace_dict_nested_non_first_character(self, any_string_dtype):\n        # GH 25259\n        dtype = any_string_dtype\n        df = DataFrame({\"first\": [\"abc\", \"bca\", \"cab\"]}, dtype=dtype)\n        expected = DataFrame({\"first\": [\".bc\", \"bc.\", \"c.b\"]}, dtype=dtype)\n        result = df.replace({\"a\": \".\"}, regex=True)\n        tm.assert_frame_equal(result, expected)\n\n    def test_regex_replace_dict_nested_gh4115(self):\n        df = DataFrame({\"Type\": [\"Q\", \"T\", \"Q\", \"Q\", \"T\"], \"tmp\": 2})\n        expected = DataFrame({\"Type\": [0, 1, 0, 0, 1], \"tmp\": 2})\n        result = df.replace({\"Type\": {\"Q\": 0, \"T\": 1}})\n        tm.assert_frame_equal(result, expected)\n\n    def test_regex_replace_list_to_scalar(self, mix_abc):\n        df = DataFrame(mix_abc)\n        expec = DataFrame(\n            {\n                \"a\": mix_abc[\"a\"],\n                \"b\": np.array([np.nan] * 4),\n                \"c\": [np.nan, np.nan, np.nan, \"d\"],\n            }\n        )\n        res = df.replace([r\"\\s*\\.\\s*\", \"a|b\"], np.nan, regex=True)\n        res2 = df.copy()\n        res3 = df.copy()\n        return_value = res2.replace(\n            [r\"\\s*\\.\\s*\", \"a|b\"], np.nan, regex=True, inplace=True\n        )\n        assert return_value is None\n        return_value = res3.replace(\n            regex=[r\"\\s*\\.\\s*\", \"a|b\"], value=np.nan, inplace=True\n        )\n        assert return_value is None\n        tm.assert_frame_equal(res, expec)\n        tm.assert_frame_equal(res2, expec)\n        tm.assert_frame_equal(res3, expec)\n\n    def test_regex_replace_str_to_numeric(self, mix_abc):\n        # what happens when you try to replace a numeric value with a regex?\n        df = DataFrame(mix_abc)\n        res = df.replace(r\"\\s*\\.\\s*\", 0, regex=True)\n        res2 = df.copy()\n        return_value = res2.replace(r\"\\s*\\.\\s*\", 0, inplace=True, regex=True)\n        assert return_value is None\n        res3 = df.copy()\n        return_value = res3.replace(regex=r\"\\s*\\.\\s*\", value=0, inplace=True)\n        assert return_value is None\n        expec = DataFrame({\"a\": mix_abc[\"a\"], \"b\": [\"a\", \"b\", 0, 0], \"c\": mix_abc[\"c\"]})\n        tm.assert_frame_equal(res, expec)\n        tm.assert_frame_equal(res2, expec)\n        tm.assert_frame_equal(res3, expec)\n\n    def test_regex_replace_regex_list_to_numeric(self, mix_abc):\n        df = DataFrame(mix_abc)\n        res = df.replace([r\"\\s*\\.\\s*\", \"b\"], 0, regex=True)\n        res2 = df.copy()\n        return_value = res2.replace([r\"\\s*\\.\\s*\", \"b\"], 0, regex=True, inplace=True)\n        assert return_value is None\n        res3 = df.copy()\n        return_value = res3.replace(regex=[r\"\\s*\\.\\s*\", \"b\"], value=0, inplace=True)\n        assert return_value is None\n        expec = DataFrame(\n            {\"a\": mix_abc[\"a\"], \"b\": [\"a\", 0, 0, 0], \"c\": [\"a\", 0, np.nan, \"d\"]}\n        )\n        tm.assert_frame_equal(res, expec)\n        tm.assert_frame_equal(res2, expec)\n        tm.assert_frame_equal(res3, expec)\n\n    def test_regex_replace_series_of_regexes(self, mix_abc):\n        df = DataFrame(mix_abc)\n        s1 = Series({\"b\": r\"\\s*\\.\\s*\"})\n        s2 = Series({\"b\": np.nan})\n        res = df.replace(s1, s2, regex=True)\n        res2 = df.copy()\n        return_value = res2.replace(s1, s2, inplace=True, regex=True)\n        assert return_value is None\n        res3 = df.copy()\n        return_value = res3.replace(regex=s1, value=s2, inplace=True)\n        assert return_value is None\n        expec = DataFrame(\n            {\"a\": mix_abc[\"a\"], \"b\": [\"a\", \"b\", np.nan, np.nan], \"c\": mix_abc[\"c\"]}\n        )\n        tm.assert_frame_equal(res, expec)\n        tm.assert_frame_equal(res2, expec)\n        tm.assert_frame_equal(res3, expec)\n\n    def test_regex_replace_numeric_to_object_conversion(self, mix_abc):\n        df = DataFrame(mix_abc)\n        expec = DataFrame({\"a\": [\"a\", 1, 2, 3], \"b\": mix_abc[\"b\"], \"c\": mix_abc[\"c\"]})\n        res = df.replace(0, \"a\")\n        tm.assert_frame_equal(res, expec)\n        assert res.a.dtype == np.object_\n\n    @pytest.mark.parametrize(\n        \"to_replace\", [{\"\": np.nan, \",\": \"\"}, {\",\": \"\", \"\": np.nan}]\n    )\n    def test_joint_simple_replace_and_regex_replace(self, to_replace):\n        # GH-39338\n        df = DataFrame(\n            {\n                \"col1\": [\"1,000\", \"a\", \"3\"],\n                \"col2\": [\"a\", \"\", \"b\"],\n                \"col3\": [\"a\", \"b\", \"c\"],\n            }\n        )\n        result = df.replace(regex=to_replace)\n        expected = DataFrame(\n            {\n                \"col1\": [\"1000\", \"a\", \"3\"],\n                \"col2\": [\"a\", np.nan, \"b\"],\n                \"col3\": [\"a\", \"b\", \"c\"],\n            }\n        )\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\"metachar\", [\"[]\", \"()\", r\"\\d\", r\"\\w\", r\"\\s\"])\n    def test_replace_regex_metachar(self, metachar):\n        df = DataFrame({\"a\": [metachar, \"else\"]})\n        result = df.replace({\"a\": {metachar: \"paren\"}})\n        expected = DataFrame({\"a\": [\"paren\", \"else\"]})\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"data,to_replace,expected\",\n        [\n            ([\"xax\", \"xbx\"], {\"a\": \"c\", \"b\": \"d\"}, [\"xcx\", \"xdx\"]),\n            ([\"d\", \"\", \"\"], {r\"^\\s*$\": pd.NA}, [\"d\", pd.NA, pd.NA]),\n        ],\n    )\n    def test_regex_replace_string_types(\n        self, data, to_replace, expected, frame_or_series, any_string_dtype\n    ):\n        # GH-41333, GH-35977\n        dtype = any_string_dtype\n        obj = frame_or_series(data, dtype=dtype)\n        result = obj.replace(to_replace, regex=True)\n        expected = frame_or_series(expected, dtype=dtype)\n\n        tm.assert_equal(result, expected)\n\n    def test_replace(self, datetime_frame):\n        datetime_frame[\"A\"][:5] = np.nan\n        datetime_frame[\"A\"][-5:] = np.nan\n\n        zero_filled = datetime_frame.replace(np.nan, -1e8)\n        tm.assert_frame_equal(zero_filled, datetime_frame.fillna(-1e8))\n        tm.assert_frame_equal(zero_filled.replace(-1e8, np.nan), datetime_frame)\n\n        datetime_frame[\"A\"][:5] = np.nan\n        datetime_frame[\"A\"][-5:] = np.nan\n        datetime_frame[\"B\"][:5] = -1e8\n\n        # empty\n        df = DataFrame(index=[\"a\", \"b\"])\n        tm.assert_frame_equal(df, df.replace(5, 7))\n\n        # GH 11698\n        # test for mixed data types.\n        df = DataFrame(\n            [(\"-\", pd.to_datetime(\"20150101\")), (\"a\", pd.to_datetime(\"20150102\"))]\n        )\n        df1 = df.replace(\"-\", np.nan)\n        expected_df = DataFrame(\n            [(np.nan, pd.to_datetime(\"20150101\")), (\"a\", pd.to_datetime(\"20150102\"))]\n        )\n        tm.assert_frame_equal(df1, expected_df)\n\n    def test_replace_list(self):\n        obj = {\"a\": list(\"ab..\"), \"b\": list(\"efgh\"), \"c\": list(\"helo\")}\n        dfobj = DataFrame(obj)\n\n        # lists of regexes and values\n        # list of [v1, v2, ..., vN] -> [v1, v2, ..., vN]\n        to_replace_res = [r\".\", r\"e\"]\n        values = [np.nan, \"crap\"]\n        res = dfobj.replace(to_replace_res, values)\n        expec = DataFrame(\n            {\n                \"a\": [\"a\", \"b\", np.nan, np.nan],\n                \"b\": [\"crap\", \"f\", \"g\", \"h\"],\n                \"c\": [\"h\", \"crap\", \"l\", \"o\"],\n            }\n        )\n        tm.assert_frame_equal(res, expec)\n\n        # list of [v1, v2, ..., vN] -> [v1, v2, .., vN]\n        to_replace_res = [r\".\", r\"f\"]\n        values = [r\"..\", r\"crap\"]\n        res = dfobj.replace(to_replace_res, values)\n        expec = DataFrame(\n            {\n                \"a\": [\"a\", \"b\", \"..\", \"..\"],\n                \"b\": [\"e\", \"crap\", \"g\", \"h\"],\n                \"c\": [\"h\", \"e\", \"l\", \"o\"],\n            }\n        )\n        tm.assert_frame_equal(res, expec)\n\n    def test_replace_with_empty_list(self, frame_or_series):\n        # GH 21977\n        ser = Series([[\"a\", \"b\"], [], np.nan, [1]])\n        obj = DataFrame({\"col\": ser})\n        if frame_or_series is Series:\n            obj = ser\n        expected = obj\n        result = obj.replace([], np.nan)\n        tm.assert_equal(result, expected)\n\n        # GH 19266\n        msg = (\n            \"NumPy boolean array indexing assignment cannot assign {size} \"\n            \"input values to the 1 output values where the mask is true\"\n        )\n        with pytest.raises(ValueError, match=msg.format(size=0)):\n            obj.replace({np.nan: []})\n        with pytest.raises(ValueError, match=msg.format(size=2)):\n            obj.replace({np.nan: [\"dummy\", \"alt\"]})\n\n    def test_replace_series_dict(self):\n        # from GH 3064\n        df = DataFrame({\"zero\": {\"a\": 0.0, \"b\": 1}, \"one\": {\"a\": 2.0, \"b\": 0}})\n        result = df.replace(0, {\"zero\": 0.5, \"one\": 1.0})\n        expected = DataFrame({\"zero\": {\"a\": 0.5, \"b\": 1}, \"one\": {\"a\": 2.0, \"b\": 1.0}})\n        tm.assert_frame_equal(result, expected)\n\n        result = df.replace(0, df.mean())\n        tm.assert_frame_equal(result, expected)\n\n        # series to series/dict\n        df = DataFrame({\"zero\": {\"a\": 0.0, \"b\": 1}, \"one\": {\"a\": 2.0, \"b\": 0}})\n        s = Series({\"zero\": 0.0, \"one\": 2.0})\n        result = df.replace(s, {\"zero\": 0.5, \"one\": 1.0})\n        expected = DataFrame({\"zero\": {\"a\": 0.5, \"b\": 1}, \"one\": {\"a\": 1.0, \"b\": 0.0}})\n        tm.assert_frame_equal(result, expected)\n\n        result = df.replace(s, df.mean())\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_convert(self):\n        # gh 3907\n        df = DataFrame([[\"foo\", \"bar\", \"bah\"], [\"bar\", \"foo\", \"bah\"]])\n        m = {\"foo\": 1, \"bar\": 2, \"bah\": 3}\n        rep = df.replace(m)\n        expec = Series([np.int64] * 3)\n        res = rep.dtypes\n        tm.assert_series_equal(expec, res)\n\n    def test_replace_mixed(self, float_string_frame):\n        mf = float_string_frame\n        mf.iloc[5:20, mf.columns.get_loc(\"foo\")] = np.nan\n        mf.iloc[-10:, mf.columns.get_loc(\"A\")] = np.nan\n\n        result = float_string_frame.replace(np.nan, -18)\n        expected = float_string_frame.fillna(value=-18)\n        tm.assert_frame_equal(result, expected)\n        tm.assert_frame_equal(result.replace(-18, np.nan), float_string_frame)\n\n        result = float_string_frame.replace(np.nan, -1e8)\n        expected = float_string_frame.fillna(value=-1e8)\n        tm.assert_frame_equal(result, expected)\n        tm.assert_frame_equal(result.replace(-1e8, np.nan), float_string_frame)\n\n    def test_replace_mixed_int_block_upcasting(self):\n\n        # int block upcasting\n        df = DataFrame(\n            {\n                \"A\": Series([1.0, 2.0], dtype=\"float64\"),\n                \"B\": Series([0, 1], dtype=\"int64\"),\n            }\n        )\n        expected = DataFrame(\n            {\n                \"A\": Series([1.0, 2.0], dtype=\"float64\"),\n                \"B\": Series([0.5, 1], dtype=\"float64\"),\n            }\n        )\n        result = df.replace(0, 0.5)\n        tm.assert_frame_equal(result, expected)\n\n        return_value = df.replace(0, 0.5, inplace=True)\n        assert return_value is None\n        tm.assert_frame_equal(df, expected)\n\n    def test_replace_mixed_int_block_splitting(self):\n\n        # int block splitting\n        df = DataFrame(\n            {\n                \"A\": Series([1.0, 2.0], dtype=\"float64\"),\n                \"B\": Series([0, 1], dtype=\"int64\"),\n                \"C\": Series([1, 2], dtype=\"int64\"),\n            }\n        )\n        expected = DataFrame(\n            {\n                \"A\": Series([1.0, 2.0], dtype=\"float64\"),\n                \"B\": Series([0.5, 1], dtype=\"float64\"),\n                \"C\": Series([1, 2], dtype=\"int64\"),\n            }\n        )\n        result = df.replace(0, 0.5)\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_mixed2(self):\n\n        # to object block upcasting\n        df = DataFrame(\n            {\n                \"A\": Series([1.0, 2.0], dtype=\"float64\"),\n                \"B\": Series([0, 1], dtype=\"int64\"),\n            }\n        )\n        expected = DataFrame(\n            {\n                \"A\": Series([1, \"foo\"], dtype=\"object\"),\n                \"B\": Series([0, 1], dtype=\"int64\"),\n            }\n        )\n        result = df.replace(2, \"foo\")\n        tm.assert_frame_equal(result, expected)\n\n        expected = DataFrame(\n            {\n                \"A\": Series([\"foo\", \"bar\"], dtype=\"object\"),\n                \"B\": Series([0, \"foo\"], dtype=\"object\"),\n            }\n        )\n        result = df.replace([1, 2], [\"foo\", \"bar\"])\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_mixed3(self):\n        # test case from\n        df = DataFrame(\n            {\"A\": Series([3, 0], dtype=\"int64\"), \"B\": Series([0, 3], dtype=\"int64\")}\n        )\n        result = df.replace(3, df.mean().to_dict())\n        expected = df.copy().astype(\"float64\")\n        m = df.mean()\n        expected.iloc[0, 0] = m[0]\n        expected.iloc[1, 1] = m[1]\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_nullable_int_with_string_doesnt_cast(self):\n        # GH#25438 don't cast df['a'] to float64\n        df = DataFrame({\"a\": [1, 2, 3, np.nan], \"b\": [\"some\", \"strings\", \"here\", \"he\"]})\n        df[\"a\"] = df[\"a\"].astype(\"Int64\")\n\n        res = df.replace(\"\", np.nan)\n        tm.assert_series_equal(res[\"a\"], df[\"a\"])\n\n    @pytest.mark.parametrize(\"dtype\", [\"boolean\", \"Int64\", \"Float64\"])\n    def test_replace_with_nullable_column(self, dtype):\n        # GH-44499\n        nullable_ser = Series([1, 0, 1], dtype=dtype)\n        df = DataFrame({\"A\": [\"A\", \"B\", \"x\"], \"B\": nullable_ser})\n        result = df.replace(\"x\", \"X\")\n        expected = DataFrame({\"A\": [\"A\", \"B\", \"X\"], \"B\": nullable_ser})\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_simple_nested_dict(self):\n        df = DataFrame({\"col\": range(1, 5)})\n        expected = DataFrame({\"col\": [\"a\", 2, 3, \"b\"]})\n\n        result = df.replace({\"col\": {1: \"a\", 4: \"b\"}})\n        tm.assert_frame_equal(expected, result)\n\n        # in this case, should be the same as the not nested version\n        result = df.replace({1: \"a\", 4: \"b\"})\n        tm.assert_frame_equal(expected, result)\n\n    def test_replace_simple_nested_dict_with_nonexistent_value(self):\n        df = DataFrame({\"col\": range(1, 5)})\n        expected = DataFrame({\"col\": [\"a\", 2, 3, \"b\"]})\n\n        result = df.replace({-1: \"-\", 1: \"a\", 4: \"b\"})\n        tm.assert_frame_equal(expected, result)\n\n        result = df.replace({\"col\": {-1: \"-\", 1: \"a\", 4: \"b\"}})\n        tm.assert_frame_equal(expected, result)\n\n    def test_replace_value_is_none(self, datetime_frame):\n        orig_value = datetime_frame.iloc[0, 0]\n        orig2 = datetime_frame.iloc[1, 0]\n\n        datetime_frame.iloc[0, 0] = np.nan\n        datetime_frame.iloc[1, 0] = 1\n\n        result = datetime_frame.replace(to_replace={np.nan: 0})\n        expected = datetime_frame.T.replace(to_replace={np.nan: 0}).T\n        tm.assert_frame_equal(result, expected)\n\n        result = datetime_frame.replace(to_replace={np.nan: 0, 1: -1e8})\n        tsframe = datetime_frame.copy()\n        tsframe.iloc[0, 0] = 0\n        tsframe.iloc[1, 0] = -1e8\n        expected = tsframe\n        tm.assert_frame_equal(expected, result)\n        datetime_frame.iloc[0, 0] = orig_value\n        datetime_frame.iloc[1, 0] = orig2\n\n    def test_replace_for_new_dtypes(self, datetime_frame):\n\n        # dtypes\n        tsframe = datetime_frame.copy().astype(np.float32)\n        tsframe[\"A\"][:5] = np.nan\n        tsframe[\"A\"][-5:] = np.nan\n\n        zero_filled = tsframe.replace(np.nan, -1e8)\n        tm.assert_frame_equal(zero_filled, tsframe.fillna(-1e8))\n        tm.assert_frame_equal(zero_filled.replace(-1e8, np.nan), tsframe)\n\n        tsframe[\"A\"][:5] = np.nan\n        tsframe[\"A\"][-5:] = np.nan\n        tsframe[\"B\"][:5] = -1e8\n\n        b = tsframe[\"B\"]\n        b[b == -1e8] = np.nan\n        tsframe[\"B\"] = b\n        result = tsframe.fillna(method=\"bfill\")\n        tm.assert_frame_equal(result, tsframe.fillna(method=\"bfill\"))\n\n    @pytest.mark.parametrize(\n        \"frame, to_replace, value, expected\",\n        [\n            (DataFrame({\"ints\": [1, 2, 3]}), 1, 0, DataFrame({\"ints\": [0, 2, 3]})),\n            (\n                DataFrame({\"ints\": [1, 2, 3]}, dtype=np.int32),\n                1,\n                0,\n                DataFrame({\"ints\": [0, 2, 3]}, dtype=np.int32),\n            ),\n            (\n                DataFrame({\"ints\": [1, 2, 3]}, dtype=np.int16),\n                1,\n                0,\n                DataFrame({\"ints\": [0, 2, 3]}, dtype=np.int16),\n            ),\n            (\n                DataFrame({\"bools\": [True, False, True]}),\n                False,\n                True,\n                DataFrame({\"bools\": [True, True, True]}),\n            ),\n            (\n                DataFrame({\"complex\": [1j, 2j, 3j]}),\n                1j,\n                0,\n                DataFrame({\"complex\": [0j, 2j, 3j]}),\n            ),\n            (\n                DataFrame(\n                    {\n                        \"datetime64\": Index(\n                            [\n                                datetime(2018, 5, 28),\n                                datetime(2018, 7, 28),\n                                datetime(2018, 5, 28),\n                            ]\n                        )\n                    }\n                ),\n                datetime(2018, 5, 28),\n                datetime(2018, 7, 28),\n                DataFrame({\"datetime64\": Index([datetime(2018, 7, 28)] * 3)}),\n            ),\n            # GH 20380\n            (\n                DataFrame({\"dt\": [datetime(3017, 12, 20)], \"str\": [\"foo\"]}),\n                \"foo\",\n                \"bar\",\n                DataFrame({\"dt\": [datetime(3017, 12, 20)], \"str\": [\"bar\"]}),\n            ),\n            (\n                DataFrame(\n                    {\n                        \"A\": date_range(\"20130101\", periods=3, tz=\"US/Eastern\"),\n                        \"B\": [0, np.nan, 2],\n                    }\n                ),\n                Timestamp(\"20130102\", tz=\"US/Eastern\"),\n                Timestamp(\"20130104\", tz=\"US/Eastern\"),\n                DataFrame(\n                    {\n                        \"A\": [\n                            Timestamp(\"20130101\", tz=\"US/Eastern\"),\n                            Timestamp(\"20130104\", tz=\"US/Eastern\"),\n                            Timestamp(\"20130103\", tz=\"US/Eastern\"),\n                        ],\n                        \"B\": [0, np.nan, 2],\n                    }\n                ),\n            ),\n            # GH 35376\n            (\n                DataFrame([[1, 1.0], [2, 2.0]]),\n                1.0,\n                5,\n                DataFrame([[5, 5.0], [2, 2.0]]),\n            ),\n            (\n                DataFrame([[1, 1.0], [2, 2.0]]),\n                1,\n                5,\n                DataFrame([[5, 5.0], [2, 2.0]]),\n            ),\n            (\n                DataFrame([[1, 1.0], [2, 2.0]]),\n                1.0,\n                5.0,\n                DataFrame([[5, 5.0], [2, 2.0]]),\n            ),\n            (\n                DataFrame([[1, 1.0], [2, 2.0]]),\n                1,\n                5.0,\n                DataFrame([[5, 5.0], [2, 2.0]]),\n            ),\n        ],\n    )\n    def test_replace_dtypes(self, frame, to_replace, value, expected):\n        result = getattr(frame, \"replace\")(to_replace, value)\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_input_formats_listlike(self):\n        # both dicts\n        to_rep = {\"A\": np.nan, \"B\": 0, \"C\": \"\"}\n        values = {\"A\": 0, \"B\": -1, \"C\": \"missing\"}\n        df = DataFrame(\n            {\"A\": [np.nan, 0, np.inf], \"B\": [0, 2, 5], \"C\": [\"\", \"asdf\", \"fd\"]}\n        )\n        filled = df.replace(to_rep, values)\n        expected = {k: v.replace(to_rep[k], values[k]) for k, v in df.items()}\n        tm.assert_frame_equal(filled, DataFrame(expected))\n\n        result = df.replace([0, 2, 5], [5, 2, 0])\n        expected = DataFrame(\n            {\"A\": [np.nan, 5, np.inf], \"B\": [5, 2, 0], \"C\": [\"\", \"asdf\", \"fd\"]}\n        )\n        tm.assert_frame_equal(result, expected)\n\n        # scalar to dict\n        values = {\"A\": 0, \"B\": -1, \"C\": \"missing\"}\n        df = DataFrame(\n            {\"A\": [np.nan, 0, np.nan], \"B\": [0, 2, 5], \"C\": [\"\", \"asdf\", \"fd\"]}\n        )\n        filled = df.replace(np.nan, values)\n        expected = {k: v.replace(np.nan, values[k]) for k, v in df.items()}\n        tm.assert_frame_equal(filled, DataFrame(expected))\n\n        # list to list\n        to_rep = [np.nan, 0, \"\"]\n        values = [-2, -1, \"missing\"]\n        result = df.replace(to_rep, values)\n        expected = df.copy()\n        for i in range(len(to_rep)):\n            return_value = expected.replace(to_rep[i], values[i], inplace=True)\n            assert return_value is None\n        tm.assert_frame_equal(result, expected)\n\n        msg = r\"Replacement lists must match in length\\. Expecting 3 got 2\"\n        with pytest.raises(ValueError, match=msg):\n            df.replace(to_rep, values[1:])\n\n    def test_replace_input_formats_scalar(self):\n        df = DataFrame(\n            {\"A\": [np.nan, 0, np.inf], \"B\": [0, 2, 5], \"C\": [\"\", \"asdf\", \"fd\"]}\n        )\n\n        # dict to scalar\n        to_rep = {\"A\": np.nan, \"B\": 0, \"C\": \"\"}\n        filled = df.replace(to_rep, 0)\n        expected = {k: v.replace(to_rep[k], 0) for k, v in df.items()}\n        tm.assert_frame_equal(filled, DataFrame(expected))\n\n        msg = \"value argument must be scalar, dict, or Series\"\n        with pytest.raises(TypeError, match=msg):\n            df.replace(to_rep, [np.nan, 0, \"\"])\n\n        # list to scalar\n        to_rep = [np.nan, 0, \"\"]\n        result = df.replace(to_rep, -1)\n        expected = df.copy()\n        for i in range(len(to_rep)):\n            return_value = expected.replace(to_rep[i], -1, inplace=True)\n            assert return_value is None\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_limit(self):\n        pass\n\n    def test_replace_dict_no_regex(self):\n        answer = Series(\n            {\n                0: \"Strongly Agree\",\n                1: \"Agree\",\n                2: \"Neutral\",\n                3: \"Disagree\",\n                4: \"Strongly Disagree\",\n            }\n        )\n        weights = {\n            \"Agree\": 4,\n            \"Disagree\": 2,\n            \"Neutral\": 3,\n            \"Strongly Agree\": 5,\n            \"Strongly Disagree\": 1,\n        }\n        expected = Series({0: 5, 1: 4, 2: 3, 3: 2, 4: 1})\n        result = answer.replace(weights)\n        tm.assert_series_equal(result, expected)\n\n    def test_replace_series_no_regex(self):\n        answer = Series(\n            {\n                0: \"Strongly Agree\",\n                1: \"Agree\",\n                2: \"Neutral\",\n                3: \"Disagree\",\n                4: \"Strongly Disagree\",\n            }\n        )\n        weights = Series(\n            {\n                \"Agree\": 4,\n                \"Disagree\": 2,\n                \"Neutral\": 3,\n                \"Strongly Agree\": 5,\n                \"Strongly Disagree\": 1,\n            }\n        )\n        expected = Series({0: 5, 1: 4, 2: 3, 3: 2, 4: 1})\n        result = answer.replace(weights)\n        tm.assert_series_equal(result, expected)\n\n    def test_replace_dict_tuple_list_ordering_remains_the_same(self):\n        df = DataFrame({\"A\": [np.nan, 1]})\n        res1 = df.replace(to_replace={np.nan: 0, 1: -1e8})\n        res2 = df.replace(to_replace=(1, np.nan), value=[-1e8, 0])\n        res3 = df.replace(to_replace=[1, np.nan], value=[-1e8, 0])\n\n        expected = DataFrame({\"A\": [0, -1e8]})\n        tm.assert_frame_equal(res1, res2)\n        tm.assert_frame_equal(res2, res3)\n        tm.assert_frame_equal(res3, expected)\n\n    def test_replace_doesnt_replace_without_regex(self):\n        df = DataFrame(\n            {\n                \"fol\": [1, 2, 2, 3],\n                \"T_opp\": [\"0\", \"vr\", \"0\", \"0\"],\n                \"T_Dir\": [\"0\", \"0\", \"0\", \"bt\"],\n                \"T_Enh\": [\"vo\", \"0\", \"0\", \"0\"],\n            }\n        )\n        res = df.replace({r\"\\D\": 1})\n        tm.assert_frame_equal(df, res)\n\n    def test_replace_bool_with_string(self):\n        df = DataFrame({\"a\": [True, False], \"b\": list(\"ab\")})\n        result = df.replace(True, \"a\")\n        expected = DataFrame({\"a\": [\"a\", False], \"b\": df.b})\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_pure_bool_with_string_no_op(self):\n        df = DataFrame(np.random.rand(2, 2) > 0.5)\n        result = df.replace(\"asdf\", \"fdsa\")\n        tm.assert_frame_equal(df, result)\n\n    def test_replace_bool_with_bool(self):\n        df = DataFrame(np.random.rand(2, 2) > 0.5)\n        result = df.replace(False, True)\n        expected = DataFrame(np.ones((2, 2), dtype=bool))\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_with_dict_with_bool_keys(self):\n        df = DataFrame({0: [True, False], 1: [False, True]})\n        result = df.replace({\"asdf\": \"asdb\", True: \"yes\"})\n        expected = DataFrame({0: [\"yes\", False], 1: [False, \"yes\"]})\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_dict_strings_vs_ints(self):\n        # GH#34789\n        df = DataFrame({\"Y0\": [1, 2], \"Y1\": [3, 4]})\n        result = df.replace({\"replace_string\": \"test\"})\n\n        tm.assert_frame_equal(result, df)\n\n        result = df[\"Y0\"].replace({\"replace_string\": \"test\"})\n        tm.assert_series_equal(result, df[\"Y0\"])\n\n    def test_replace_truthy(self):\n        df = DataFrame({\"a\": [True, True]})\n        r = df.replace([np.inf, -np.inf], np.nan)\n        e = df\n        tm.assert_frame_equal(r, e)\n\n    def test_nested_dict_overlapping_keys_replace_int(self):\n        # GH 27660 keep behaviour consistent for simple dictionary and\n        # nested dictionary replacement\n        df = DataFrame({\"a\": list(range(1, 5))})\n\n        result = df.replace({\"a\": dict(zip(range(1, 5), range(2, 6)))})\n        expected = df.replace(dict(zip(range(1, 5), range(2, 6))))\n        tm.assert_frame_equal(result, expected)\n\n    def test_nested_dict_overlapping_keys_replace_str(self):\n        # GH 27660\n        a = np.arange(1, 5)\n        astr = a.astype(str)\n        bstr = np.arange(2, 6).astype(str)\n        df = DataFrame({\"a\": astr})\n        result = df.replace(dict(zip(astr, bstr)))\n        expected = df.replace({\"a\": dict(zip(astr, bstr))})\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_swapping_bug(self):\n        df = DataFrame({\"a\": [True, False, True]})\n        res = df.replace({\"a\": {True: \"Y\", False: \"N\"}})\n        expect = DataFrame({\"a\": [\"Y\", \"N\", \"Y\"]})\n        tm.assert_frame_equal(res, expect)\n\n        df = DataFrame({\"a\": [0, 1, 0]})\n        res = df.replace({\"a\": {0: \"Y\", 1: \"N\"}})\n        expect = DataFrame({\"a\": [\"Y\", \"N\", \"Y\"]})\n        tm.assert_frame_equal(res, expect)\n\n    def test_replace_period(self):\n        d = {\n            \"fname\": {\n                \"out_augmented_AUG_2011.json\": pd.Period(year=2011, month=8, freq=\"M\"),\n                \"out_augmented_JAN_2011.json\": pd.Period(year=2011, month=1, freq=\"M\"),\n                \"out_augmented_MAY_2012.json\": pd.Period(year=2012, month=5, freq=\"M\"),\n                \"out_augmented_SUBSIDY_WEEK.json\": pd.Period(\n                    year=2011, month=4, freq=\"M\"\n                ),\n                \"out_augmented_AUG_2012.json\": pd.Period(year=2012, month=8, freq=\"M\"),\n                \"out_augmented_MAY_2011.json\": pd.Period(year=2011, month=5, freq=\"M\"),\n                \"out_augmented_SEP_2013.json\": pd.Period(year=2013, month=9, freq=\"M\"),\n            }\n        }\n\n        df = DataFrame(\n            [\n                \"out_augmented_AUG_2012.json\",\n                \"out_augmented_SEP_2013.json\",\n                \"out_augmented_SUBSIDY_WEEK.json\",\n                \"out_augmented_MAY_2012.json\",\n                \"out_augmented_MAY_2011.json\",\n                \"out_augmented_AUG_2011.json\",\n                \"out_augmented_JAN_2011.json\",\n            ],\n            columns=[\"fname\"],\n        )\n        assert set(df.fname.values) == set(d[\"fname\"].keys())\n\n        expected = DataFrame({\"fname\": [d[\"fname\"][k] for k in df.fname.values]})\n        assert expected.dtypes[0] == \"Period[M]\"\n        result = df.replace(d)\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_datetime(self):\n        d = {\n            \"fname\": {\n                \"out_augmented_AUG_2011.json\": Timestamp(\"2011-08\"),\n                \"out_augmented_JAN_2011.json\": Timestamp(\"2011-01\"),\n                \"out_augmented_MAY_2012.json\": Timestamp(\"2012-05\"),\n                \"out_augmented_SUBSIDY_WEEK.json\": Timestamp(\"2011-04\"),\n                \"out_augmented_AUG_2012.json\": Timestamp(\"2012-08\"),\n                \"out_augmented_MAY_2011.json\": Timestamp(\"2011-05\"),\n                \"out_augmented_SEP_2013.json\": Timestamp(\"2013-09\"),\n            }\n        }\n\n        df = DataFrame(\n            [\n                \"out_augmented_AUG_2012.json\",\n                \"out_augmented_SEP_2013.json\",\n                \"out_augmented_SUBSIDY_WEEK.json\",\n                \"out_augmented_MAY_2012.json\",\n                \"out_augmented_MAY_2011.json\",\n                \"out_augmented_AUG_2011.json\",\n                \"out_augmented_JAN_2011.json\",\n            ],\n            columns=[\"fname\"],\n        )\n        assert set(df.fname.values) == set(d[\"fname\"].keys())\n        expected = DataFrame({\"fname\": [d[\"fname\"][k] for k in df.fname.values]})\n        result = df.replace(d)\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_datetimetz(self):\n\n        # GH 11326\n        # behaving poorly when presented with a datetime64[ns, tz]\n        df = DataFrame(\n            {\n                \"A\": date_range(\"20130101\", periods=3, tz=\"US/Eastern\"),\n                \"B\": [0, np.nan, 2],\n            }\n        )\n        result = df.replace(np.nan, 1)\n        expected = DataFrame(\n            {\n                \"A\": date_range(\"20130101\", periods=3, tz=\"US/Eastern\"),\n                \"B\": Series([0, 1, 2], dtype=\"float64\"),\n            }\n        )\n        tm.assert_frame_equal(result, expected)\n\n        result = df.fillna(1)\n        tm.assert_frame_equal(result, expected)\n\n        result = df.replace(0, np.nan)\n        expected = DataFrame(\n            {\n                \"A\": date_range(\"20130101\", periods=3, tz=\"US/Eastern\"),\n                \"B\": [np.nan, np.nan, 2],\n            }\n        )\n        tm.assert_frame_equal(result, expected)\n\n        result = df.replace(\n            Timestamp(\"20130102\", tz=\"US/Eastern\"),\n            Timestamp(\"20130104\", tz=\"US/Eastern\"),\n        )\n        expected = DataFrame(\n            {\n                \"A\": [\n                    Timestamp(\"20130101\", tz=\"US/Eastern\"),\n                    Timestamp(\"20130104\", tz=\"US/Eastern\"),\n                    Timestamp(\"20130103\", tz=\"US/Eastern\"),\n                ],\n                \"B\": [0, np.nan, 2],\n            }\n        )\n        tm.assert_frame_equal(result, expected)\n\n        result = df.copy()\n        result.iloc[1, 0] = np.nan\n        result = result.replace({\"A\": pd.NaT}, Timestamp(\"20130104\", tz=\"US/Eastern\"))\n        tm.assert_frame_equal(result, expected)\n\n        # coerce to object\n        result = df.copy()\n        result.iloc[1, 0] = np.nan\n        with tm.assert_produces_warning(FutureWarning, match=\"mismatched timezone\"):\n            result = result.replace(\n                {\"A\": pd.NaT}, Timestamp(\"20130104\", tz=\"US/Pacific\")\n            )\n        expected = DataFrame(\n            {\n                \"A\": [\n                    Timestamp(\"20130101\", tz=\"US/Eastern\"),\n                    Timestamp(\"20130104\", tz=\"US/Pacific\"),\n                    # once deprecation is enforced\n                    # Timestamp(\"20130104\", tz=\"US/Pacific\").tz_convert(\"US/Eastern\"),\n                    Timestamp(\"20130103\", tz=\"US/Eastern\"),\n                ],\n                \"B\": [0, np.nan, 2],\n            }\n        )\n        tm.assert_frame_equal(result, expected)\n\n        result = df.copy()\n        result.iloc[1, 0] = np.nan\n        result = result.replace({\"A\": np.nan}, Timestamp(\"20130104\"))\n        expected = DataFrame(\n            {\n                \"A\": [\n                    Timestamp(\"20130101\", tz=\"US/Eastern\"),\n                    Timestamp(\"20130104\"),\n                    Timestamp(\"20130103\", tz=\"US/Eastern\"),\n                ],\n                \"B\": [0, np.nan, 2],\n            }\n        )\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_with_empty_dictlike(self, mix_abc):\n        # GH 15289\n        df = DataFrame(mix_abc)\n        tm.assert_frame_equal(df, df.replace({}))\n        tm.assert_frame_equal(df, df.replace(Series([], dtype=object)))\n\n        tm.assert_frame_equal(df, df.replace({\"b\": {}}))\n        tm.assert_frame_equal(df, df.replace(Series({\"b\": {}})))\n\n    @pytest.mark.parametrize(\n        \"to_replace, method, expected\",\n        [\n            (0, \"bfill\", {\"A\": [1, 1, 2], \"B\": [5, np.nan, 7], \"C\": [\"a\", \"b\", \"c\"]}),\n            (\n                np.nan,\n                \"bfill\",\n                {\"A\": [0, 1, 2], \"B\": [5.0, 7.0, 7.0], \"C\": [\"a\", \"b\", \"c\"]},\n            ),\n            (\"d\", \"ffill\", {\"A\": [0, 1, 2], \"B\": [5, np.nan, 7], \"C\": [\"a\", \"b\", \"c\"]}),\n            (\n                [0, 2],\n                \"bfill\",\n                {\"A\": [1, 1, 2], \"B\": [5, np.nan, 7], \"C\": [\"a\", \"b\", \"c\"]},\n            ),\n            (\n                [1, 2],\n                \"pad\",\n                {\"A\": [0, 0, 0], \"B\": [5, np.nan, 7], \"C\": [\"a\", \"b\", \"c\"]},\n            ),\n            (\n                (1, 2),\n                \"bfill\",\n                {\"A\": [0, 2, 2], \"B\": [5, np.nan, 7], \"C\": [\"a\", \"b\", \"c\"]},\n            ),\n            (\n                [\"b\", \"c\"],\n                \"ffill\",\n                {\"A\": [0, 1, 2], \"B\": [5, np.nan, 7], \"C\": [\"a\", \"a\", \"a\"]},\n            ),\n        ],\n    )\n    def test_replace_method(self, to_replace, method, expected):\n        # GH 19632\n        df = DataFrame({\"A\": [0, 1, 2], \"B\": [5, np.nan, 7], \"C\": [\"a\", \"b\", \"c\"]})\n\n        result = df.replace(to_replace=to_replace, value=None, method=method)\n        expected = DataFrame(expected)\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"replace_dict, final_data\",\n        [({\"a\": 1, \"b\": 1}, [[3, 3], [2, 2]]), ({\"a\": 1, \"b\": 2}, [[3, 1], [2, 3]])],\n    )\n    def test_categorical_replace_with_dict(self, replace_dict, final_data):\n        # GH 26988\n        df = DataFrame([[1, 1], [2, 2]], columns=[\"a\", \"b\"], dtype=\"category\")\n\n        final_data = np.array(final_data)\n\n        a = pd.Categorical(final_data[:, 0], categories=[3, 2])\n\n        ex_cat = [3, 2] if replace_dict[\"b\"] == 1 else [1, 3]\n        b = pd.Categorical(final_data[:, 1], categories=ex_cat)\n\n        expected = DataFrame({\"a\": a, \"b\": b})\n        result = df.replace(replace_dict, 3)\n        tm.assert_frame_equal(result, expected)\n        msg = (\n            r\"Attributes of DataFrame.iloc\\[:, 0\\] \\(column name=\\\"a\\\"\\) are \"\n            \"different\"\n        )\n        with pytest.raises(AssertionError, match=msg):\n            # ensure non-inplace call does not affect original\n            tm.assert_frame_equal(df, expected)\n        return_value = df.replace(replace_dict, 3, inplace=True)\n        assert return_value is None\n        tm.assert_frame_equal(df, expected)\n\n    @pytest.mark.parametrize(\n        \"df, to_replace, exp\",\n        [\n            (\n                {\"col1\": [1, 2, 3], \"col2\": [4, 5, 6]},\n                {4: 5, 5: 6, 6: 7},\n                {\"col1\": [1, 2, 3], \"col2\": [5, 6, 7]},\n            ),\n            (\n                {\"col1\": [1, 2, 3], \"col2\": [\"4\", \"5\", \"6\"]},\n                {\"4\": \"5\", \"5\": \"6\", \"6\": \"7\"},\n                {\"col1\": [1, 2, 3], \"col2\": [\"5\", \"6\", \"7\"]},\n            ),\n        ],\n    )\n    def test_replace_commutative(self, df, to_replace, exp):\n        # GH 16051\n        # DataFrame.replace() overwrites when values are non-numeric\n        # also added to data frame whilst issue was for series\n\n        df = DataFrame(df)\n\n        expected = DataFrame(exp)\n        result = df.replace(to_replace)\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"replacer\",\n        [\n            Timestamp(\"20170827\"),\n            np.int8(1),\n            np.int16(1),\n            np.float32(1),\n            np.float64(1),\n        ],\n    )\n    def test_replace_replacer_dtype(self, request, replacer):\n        # GH26632\n        if np.isscalar(replacer) and replacer.dtype.itemsize < 8:\n            request.node.add_marker(\n                pytest.mark.xfail(\n                    np_version_under1p20, reason=\"np.putmask doesn't coerce dtype\"\n                )\n            )\n        df = DataFrame([\"a\"])\n        result = df.replace({\"a\": replacer, \"b\": replacer})\n        expected = DataFrame([replacer])\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_after_convert_dtypes(self):\n        # GH31517\n        df = DataFrame({\"grp\": [1, 2, 3, 4, 5]}, dtype=\"Int64\")\n        result = df.replace(1, 10)\n        expected = DataFrame({\"grp\": [10, 2, 3, 4, 5]}, dtype=\"Int64\")\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_invalid_to_replace(self):\n        # GH 18634\n        # API: replace() should raise an exception if invalid argument is given\n        df = DataFrame({\"one\": [\"a\", \"b \", \"c\"], \"two\": [\"d \", \"e \", \"f \"]})\n        msg = (\n            r\"Expecting 'to_replace' to be either a scalar, array-like, \"\n            r\"dict or None, got invalid type.*\"\n        )\n        with pytest.raises(TypeError, match=msg):\n            df.replace(lambda x: x.strip())\n\n    @pytest.mark.parametrize(\"dtype\", [\"float\", \"float64\", \"int64\", \"Int64\", \"boolean\"])\n    @pytest.mark.parametrize(\"value\", [np.nan, pd.NA])\n    def test_replace_no_replacement_dtypes(self, dtype, value):\n        # https://github.com/pandas-dev/pandas/issues/32988\n        df = DataFrame(np.eye(2), dtype=dtype)\n        result = df.replace(to_replace=[None, -np.inf, np.inf], value=value)\n        tm.assert_frame_equal(result, df)\n\n    @pytest.mark.parametrize(\"replacement\", [np.nan, 5])\n    def test_replace_with_duplicate_columns(self, replacement):\n        # GH 24798\n        result = DataFrame({\"A\": [1, 2, 3], \"A1\": [4, 5, 6], \"B\": [7, 8, 9]})\n        result.columns = list(\"AAB\")\n\n        expected = DataFrame(\n            {\"A\": [1, 2, 3], \"A1\": [4, 5, 6], \"B\": [replacement, 8, 9]}\n        )\n        expected.columns = list(\"AAB\")\n\n        result[\"B\"] = result[\"B\"].replace(7, replacement)\n\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize(\"value\", [pd.Period(\"2020-01\"), pd.Interval(0, 5)])\n    def test_replace_ea_ignore_float(self, frame_or_series, value):\n        # GH#34871\n        obj = DataFrame({\"Per\": [value] * 3})\n        if frame_or_series is not DataFrame:\n            obj = obj[\"Per\"]\n\n        expected = obj.copy()\n        result = obj.replace(1.0, 0.0)\n        tm.assert_equal(expected, result)\n\n    def test_replace_value_category_type(self):\n        \"\"\"\n        Test for #23305: to ensure category dtypes are maintained\n        after replace with direct values\n        \"\"\"\n\n        # create input data\n        input_dict = {\n            \"col1\": [1, 2, 3, 4],\n            \"col2\": [\"a\", \"b\", \"c\", \"d\"],\n            \"col3\": [1.5, 2.5, 3.5, 4.5],\n            \"col4\": [\"cat1\", \"cat2\", \"cat3\", \"cat4\"],\n            \"col5\": [\"obj1\", \"obj2\", \"obj3\", \"obj4\"],\n        }\n        # explicitly cast columns as category and order them\n        input_df = DataFrame(data=input_dict).astype(\n            {\"col2\": \"category\", \"col4\": \"category\"}\n        )\n        input_df[\"col2\"] = input_df[\"col2\"].cat.reorder_categories(\n            [\"a\", \"b\", \"c\", \"d\"], ordered=True\n        )\n        input_df[\"col4\"] = input_df[\"col4\"].cat.reorder_categories(\n            [\"cat1\", \"cat2\", \"cat3\", \"cat4\"], ordered=True\n        )\n\n        # create expected dataframe\n        expected_dict = {\n            \"col1\": [1, 2, 3, 4],\n            \"col2\": [\"a\", \"b\", \"c\", \"z\"],\n            \"col3\": [1.5, 2.5, 3.5, 4.5],\n            \"col4\": [\"cat1\", \"catX\", \"cat3\", \"cat4\"],\n            \"col5\": [\"obj9\", \"obj2\", \"obj3\", \"obj4\"],\n        }\n        # explicitly cast columns as category and order them\n        expected = DataFrame(data=expected_dict).astype(\n            {\"col2\": \"category\", \"col4\": \"category\"}\n        )\n        expected[\"col2\"] = expected[\"col2\"].cat.reorder_categories(\n            [\"a\", \"b\", \"c\", \"z\"], ordered=True\n        )\n        expected[\"col4\"] = expected[\"col4\"].cat.reorder_categories(\n            [\"cat1\", \"catX\", \"cat3\", \"cat4\"], ordered=True\n        )\n\n        # replace values in input dataframe\n        input_df = input_df.replace(\"d\", \"z\")\n        input_df = input_df.replace(\"obj1\", \"obj9\")\n        result = input_df.replace(\"cat2\", \"catX\")\n\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_dict_category_type(self):\n        \"\"\"\n        Test to ensure category dtypes are maintained\n        after replace with dict values\n        \"\"\"\n        # GH#35268, GH#44940\n\n        # create input dataframe\n        input_dict = {\"col1\": [\"a\"], \"col2\": [\"obj1\"], \"col3\": [\"cat1\"]}\n        # explicitly cast columns as category\n        input_df = DataFrame(data=input_dict).astype(\n            {\"col1\": \"category\", \"col2\": \"category\", \"col3\": \"category\"}\n        )\n\n        # create expected dataframe\n        expected_dict = {\"col1\": [\"z\"], \"col2\": [\"obj9\"], \"col3\": [\"catX\"]}\n        # explicitly cast columns as category\n        expected = DataFrame(data=expected_dict).astype(\n            {\"col1\": \"category\", \"col2\": \"category\", \"col3\": \"category\"}\n        )\n\n        # replace values in input dataframe using a dict\n        result = input_df.replace({\"a\": \"z\", \"obj1\": \"obj9\", \"cat1\": \"catX\"})\n\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_with_compiled_regex(self):\n        # https://github.com/pandas-dev/pandas/issues/35680\n        df = DataFrame([\"a\", \"b\", \"c\"])\n        regex = re.compile(\"^a$\")\n        result = df.replace({regex: \"z\"}, regex=True)\n        expected = DataFrame([\"z\", \"b\", \"c\"])\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_intervals(self):\n        # https://github.com/pandas-dev/pandas/issues/35931\n        df = DataFrame({\"a\": [pd.Interval(0, 1), pd.Interval(0, 1)]})\n        result = df.replace({\"a\": {pd.Interval(0, 1): \"x\"}})\n        expected = DataFrame({\"a\": [\"x\", \"x\"]})\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_unicode(self):\n        # GH: 16784\n        columns_values_map = {\"positive\": {\"正面\": 1, \"中立\": 1, \"负面\": 0}}\n        df1 = DataFrame({\"positive\": np.ones(3)})\n        result = df1.replace(columns_values_map)\n        expected = DataFrame({\"positive\": np.ones(3)})\n        tm.assert_frame_equal(result, expected)\n\n    def test_replace_bytes(self, frame_or_series):\n        # GH#38900\n        obj = frame_or_series([\"o\"]).astype(\"|S\")\n        expected = obj.copy()\n        obj = obj.replace({None: np.nan})\n        tm.assert_equal(obj, expected)\n\n    @pytest.mark.parametrize(\n        \"data, to_replace, value, expected\",\n        [\n            ([1], [1.0], [0], [0]),\n            ([1], [1], [0], [0]),\n            ([1.0], [1.0], [0], [0.0]),\n            ([1.0], [1], [0], [0.0]),\n        ],\n    )\n    @pytest.mark.parametrize(\"box\", [list, tuple, np.array])\n    def test_replace_list_with_mixed_type(\n        self, data, to_replace, value, expected, box, frame_or_series\n    ):\n        # GH#40371\n        obj = frame_or_series(data)\n        expected = frame_or_series(expected)\n        result = obj.replace(box(to_replace), value)\n        tm.assert_equal(result, expected)\n\n\nclass TestDataFrameReplaceRegex:\n    @pytest.mark.parametrize(\n        \"data\",\n        [\n            {\"a\": list(\"ab..\"), \"b\": list(\"efgh\")},\n            {\"a\": list(\"ab..\"), \"b\": list(range(4))},\n        ],\n    )\n    @pytest.mark.parametrize(\n        \"to_replace,value\", [(r\"\\s*\\.\\s*\", np.nan), (r\"\\s*(\\.)\\s*\", r\"\\1\\1\\1\")]\n    )\n    @pytest.mark.parametrize(\"compile_regex\", [True, False])\n    @pytest.mark.parametrize(\"regex_kwarg\", [True, False])\n    @pytest.mark.parametrize(\"inplace\", [True, False])\n    def test_regex_replace_scalar(\n        self, data, to_replace, value, compile_regex, regex_kwarg, inplace\n    ):\n        df = DataFrame(data)\n        expected = df.copy()\n\n        if compile_regex:\n            to_replace = re.compile(to_replace)\n\n        if regex_kwarg:\n            regex = to_replace\n            to_replace = None\n        else:\n            regex = True\n\n        result = df.replace(to_replace, value, inplace=inplace, regex=regex)\n\n        if inplace:\n            assert result is None\n            result = df\n\n        if value is np.nan:\n            expected_replace_val = np.nan\n        else:\n            expected_replace_val = \"...\"\n\n        expected.loc[expected[\"a\"] == \".\", \"a\"] = expected_replace_val\n        tm.assert_frame_equal(result, expected)\n"
    },
    {
      "filename": "pandas/tests/indexing/test_coercion.py",
      "content": "from __future__ import annotations\n\nfrom datetime import timedelta\nimport itertools\n\nimport numpy as np\nimport pytest\n\nfrom pandas.compat import (\n    IS64,\n    is_platform_windows,\n)\n\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.api import (\n    Float64Index,\n    Int64Index,\n)\n\n###############################################################\n# Index / Series common tests which may trigger dtype coercions\n###############################################################\n\n\n@pytest.fixture(autouse=True, scope=\"class\")\ndef check_comprehensiveness(request):\n    # Iterate over combination of dtype, method and klass\n    # and ensure that each are contained within a collected test\n    cls = request.cls\n    combos = itertools.product(cls.klasses, cls.dtypes, [cls.method])\n\n    def has_test(combo):\n        klass, dtype, method = combo\n        cls_funcs = request.node.session.items\n        return any(\n            klass in x.name and dtype in x.name and method in x.name for x in cls_funcs\n        )\n\n    opts = request.config.option\n    if opts.lf or opts.keyword:\n        # If we are running with \"last-failed\" or -k foo, we expect to only\n        #  run a subset of tests.\n        yield\n\n    else:\n\n        for combo in combos:\n            if not has_test(combo):\n                raise AssertionError(\n                    f\"test method is not defined: {cls.__name__}, {combo}\"\n                )\n\n        yield\n\n\nclass CoercionBase:\n\n    klasses = [\"index\", \"series\"]\n    dtypes = [\n        \"object\",\n        \"int64\",\n        \"float64\",\n        \"complex128\",\n        \"bool\",\n        \"datetime64\",\n        \"datetime64tz\",\n        \"timedelta64\",\n        \"period\",\n    ]\n\n    @property\n    def method(self):\n        raise NotImplementedError(self)\n\n\nclass TestSetitemCoercion(CoercionBase):\n\n    method = \"setitem\"\n\n    def _assert_setitem_series_conversion(\n        self, original_series, loc_value, expected_series, expected_dtype\n    ):\n        \"\"\"test series value's coercion triggered by assignment\"\"\"\n        temp = original_series.copy()\n        temp[1] = loc_value\n        tm.assert_series_equal(temp, expected_series)\n        # check dtype explicitly for sure\n        assert temp.dtype == expected_dtype\n\n        # AFAICT the problem is in Series.__setitem__ where with integer dtype\n        #  ser[1] = 2.2 casts 2.2 to 2 instead of casting the ser to floating\n        # FIXME: dont leave commented-out\n        # .loc works different rule, temporary disable\n        # temp = original_series.copy()\n        # temp.loc[1] = loc_value\n        # tm.assert_series_equal(temp, expected_series)\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\", [(1, object), (1.1, object), (1 + 1j, object), (True, object)]\n    )\n    def test_setitem_series_object(self, val, exp_dtype):\n        obj = pd.Series(list(\"abcd\"))\n        assert obj.dtype == object\n\n        exp = pd.Series([\"a\", val, \"c\", \"d\"])\n        self._assert_setitem_series_conversion(obj, val, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\",\n        [(1, np.int64), (1.1, np.float64), (1 + 1j, np.complex128), (True, object)],\n    )\n    def test_setitem_series_int64(self, val, exp_dtype, request):\n        obj = pd.Series([1, 2, 3, 4])\n        assert obj.dtype == np.int64\n\n        if exp_dtype is np.float64:\n            exp = pd.Series([1, 1, 3, 4])\n            self._assert_setitem_series_conversion(obj, 1.1, exp, np.int64)\n            mark = pytest.mark.xfail(reason=\"GH12747 The result must be float\")\n            request.node.add_marker(mark)\n\n        exp = pd.Series([1, val, 3, 4])\n        self._assert_setitem_series_conversion(obj, val, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\", [(np.int32(1), np.int8), (np.int16(2 ** 9), np.int16)]\n    )\n    def test_setitem_series_int8(self, val, exp_dtype, request):\n        obj = pd.Series([1, 2, 3, 4], dtype=np.int8)\n        assert obj.dtype == np.int8\n\n        if exp_dtype is np.int16:\n            exp = pd.Series([1, 0, 3, 4], dtype=np.int8)\n            self._assert_setitem_series_conversion(obj, val, exp, np.int8)\n            mark = pytest.mark.xfail(\n                reason=\"BUG: it must be pd.Series([1, 1, 3, 4], dtype=np.int16\"\n            )\n            request.node.add_marker(mark)\n\n        warn = None if exp_dtype is np.int8 else FutureWarning\n        msg = \"Values are too large to be losslessly cast to int8\"\n        with tm.assert_produces_warning(warn, match=msg):\n            exp = pd.Series([1, val, 3, 4], dtype=np.int8)\n        self._assert_setitem_series_conversion(obj, val, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\",\n        [(1, np.float64), (1.1, np.float64), (1 + 1j, np.complex128), (True, object)],\n    )\n    def test_setitem_series_float64(self, val, exp_dtype):\n        obj = pd.Series([1.1, 2.2, 3.3, 4.4])\n        assert obj.dtype == np.float64\n\n        exp = pd.Series([1.1, val, 3.3, 4.4])\n        self._assert_setitem_series_conversion(obj, val, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\",\n        [\n            (1, np.complex128),\n            (1.1, np.complex128),\n            (1 + 1j, np.complex128),\n            (True, object),\n        ],\n    )\n    def test_setitem_series_complex128(self, val, exp_dtype):\n        obj = pd.Series([1 + 1j, 2 + 2j, 3 + 3j, 4 + 4j])\n        assert obj.dtype == np.complex128\n\n        exp = pd.Series([1 + 1j, val, 3 + 3j, 4 + 4j])\n        self._assert_setitem_series_conversion(obj, val, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\",\n        [\n            (1, object),\n            (\"3\", object),\n            (3, object),\n            (1.1, object),\n            (1 + 1j, object),\n            (True, np.bool_),\n        ],\n    )\n    def test_setitem_series_bool(self, val, exp_dtype):\n        obj = pd.Series([True, False, True, False])\n        assert obj.dtype == np.bool_\n\n        exp = pd.Series([True, val, True, False], dtype=exp_dtype)\n        self._assert_setitem_series_conversion(obj, val, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\",\n        [(pd.Timestamp(\"2012-01-01\"), \"datetime64[ns]\"), (1, object), (\"x\", object)],\n    )\n    def test_setitem_series_datetime64(self, val, exp_dtype):\n        obj = pd.Series(\n            [\n                pd.Timestamp(\"2011-01-01\"),\n                pd.Timestamp(\"2011-01-02\"),\n                pd.Timestamp(\"2011-01-03\"),\n                pd.Timestamp(\"2011-01-04\"),\n            ]\n        )\n        assert obj.dtype == \"datetime64[ns]\"\n\n        exp = pd.Series(\n            [\n                pd.Timestamp(\"2011-01-01\"),\n                val,\n                pd.Timestamp(\"2011-01-03\"),\n                pd.Timestamp(\"2011-01-04\"),\n            ]\n        )\n        self._assert_setitem_series_conversion(obj, val, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\",\n        [\n            (pd.Timestamp(\"2012-01-01\", tz=\"US/Eastern\"), \"datetime64[ns, US/Eastern]\"),\n            (pd.Timestamp(\"2012-01-01\", tz=\"US/Pacific\"), object),\n            (pd.Timestamp(\"2012-01-01\"), object),\n            (1, object),\n        ],\n    )\n    def test_setitem_series_datetime64tz(self, val, exp_dtype):\n        tz = \"US/Eastern\"\n        obj = pd.Series(\n            [\n                pd.Timestamp(\"2011-01-01\", tz=tz),\n                pd.Timestamp(\"2011-01-02\", tz=tz),\n                pd.Timestamp(\"2011-01-03\", tz=tz),\n                pd.Timestamp(\"2011-01-04\", tz=tz),\n            ]\n        )\n        assert obj.dtype == \"datetime64[ns, US/Eastern]\"\n\n        exp = pd.Series(\n            [\n                pd.Timestamp(\"2011-01-01\", tz=tz),\n                val,\n                # once deprecation is enforced\n                # val if getattr(val, \"tz\", None) is None else val.tz_convert(tz),\n                pd.Timestamp(\"2011-01-03\", tz=tz),\n                pd.Timestamp(\"2011-01-04\", tz=tz),\n            ]\n        )\n        warn = None\n        if getattr(val, \"tz\", None) is not None and val.tz != obj[0].tz:\n            warn = FutureWarning\n        with tm.assert_produces_warning(warn, match=\"mismatched timezones\"):\n            self._assert_setitem_series_conversion(obj, val, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\",\n        [(pd.Timedelta(\"12 day\"), \"timedelta64[ns]\"), (1, object), (\"x\", object)],\n    )\n    def test_setitem_series_timedelta64(self, val, exp_dtype):\n        obj = pd.Series(\n            [\n                pd.Timedelta(\"1 day\"),\n                pd.Timedelta(\"2 day\"),\n                pd.Timedelta(\"3 day\"),\n                pd.Timedelta(\"4 day\"),\n            ]\n        )\n        assert obj.dtype == \"timedelta64[ns]\"\n\n        exp = pd.Series(\n            [pd.Timedelta(\"1 day\"), val, pd.Timedelta(\"3 day\"), pd.Timedelta(\"4 day\")]\n        )\n        self._assert_setitem_series_conversion(obj, val, exp, exp_dtype)\n\n    def test_setitem_series_no_coercion_from_values_list(self):\n        # GH35865 - int casted to str when internally calling np.array(ser.values)\n        ser = pd.Series([\"a\", 1])\n        ser[:] = list(ser.values)\n\n        expected = pd.Series([\"a\", 1])\n\n        tm.assert_series_equal(ser, expected)\n\n    def _assert_setitem_index_conversion(\n        self, original_series, loc_key, expected_index, expected_dtype\n    ):\n        \"\"\"test index's coercion triggered by assign key\"\"\"\n        temp = original_series.copy()\n        warn = None\n        if isinstance(loc_key, int) and temp.index.dtype == np.float64:\n            # GH#33469\n            warn = FutureWarning\n        with tm.assert_produces_warning(warn):\n            temp[loc_key] = 5\n        exp = pd.Series([1, 2, 3, 4, 5], index=expected_index)\n        tm.assert_series_equal(temp, exp)\n        # check dtype explicitly for sure\n        assert temp.index.dtype == expected_dtype\n\n        temp = original_series.copy()\n        temp.loc[loc_key] = 5\n        exp = pd.Series([1, 2, 3, 4, 5], index=expected_index)\n        tm.assert_series_equal(temp, exp)\n        # check dtype explicitly for sure\n        assert temp.index.dtype == expected_dtype\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\", [(\"x\", object), (5, IndexError), (1.1, object)]\n    )\n    def test_setitem_index_object(self, val, exp_dtype):\n        obj = pd.Series([1, 2, 3, 4], index=list(\"abcd\"))\n        assert obj.index.dtype == object\n\n        if exp_dtype is IndexError:\n            temp = obj.copy()\n            msg = \"index 5 is out of bounds for axis 0 with size 4\"\n            with pytest.raises(exp_dtype, match=msg):\n                temp[5] = 5\n        else:\n            exp_index = pd.Index(list(\"abcd\") + [val])\n            self._assert_setitem_index_conversion(obj, val, exp_index, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\", [(5, np.int64), (1.1, np.float64), (\"x\", object)]\n    )\n    def test_setitem_index_int64(self, val, exp_dtype):\n        obj = pd.Series([1, 2, 3, 4])\n        assert obj.index.dtype == np.int64\n\n        exp_index = pd.Index([0, 1, 2, 3, val])\n        self._assert_setitem_index_conversion(obj, val, exp_index, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"val,exp_dtype\", [(5, IndexError), (5.1, np.float64), (\"x\", object)]\n    )\n    def test_setitem_index_float64(self, val, exp_dtype, request):\n        obj = pd.Series([1, 2, 3, 4], index=[1.1, 2.1, 3.1, 4.1])\n        assert obj.index.dtype == np.float64\n\n        if exp_dtype is IndexError:\n            # float + int -> int\n            temp = obj.copy()\n            msg = \"index 5 is out of bounds for axis 0 with size 4\"\n            with pytest.raises(exp_dtype, match=msg):\n                # GH#33469\n                depr_msg = \"Treating integers as positional\"\n                with tm.assert_produces_warning(FutureWarning, match=depr_msg):\n                    temp[5] = 5\n            mark = pytest.mark.xfail(reason=\"TODO_GH12747 The result must be float\")\n            request.node.add_marker(mark)\n        exp_index = pd.Index([1.1, 2.1, 3.1, 4.1, val])\n        self._assert_setitem_index_conversion(obj, val, exp_index, exp_dtype)\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_setitem_series_period(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_setitem_index_complex128(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_setitem_index_bool(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_setitem_index_datetime64(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_setitem_index_datetime64tz(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_setitem_index_timedelta64(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_setitem_index_period(self):\n        raise NotImplementedError\n\n\nclass TestInsertIndexCoercion(CoercionBase):\n\n    klasses = [\"index\"]\n    method = \"insert\"\n\n    def _assert_insert_conversion(self, original, value, expected, expected_dtype):\n        \"\"\"test coercion triggered by insert\"\"\"\n        target = original.copy()\n        res = target.insert(1, value)\n        tm.assert_index_equal(res, expected)\n        assert res.dtype == expected_dtype\n\n    @pytest.mark.parametrize(\n        \"insert, coerced_val, coerced_dtype\",\n        [\n            (1, 1, object),\n            (1.1, 1.1, object),\n            (False, False, object),\n            (\"x\", \"x\", object),\n        ],\n    )\n    def test_insert_index_object(self, insert, coerced_val, coerced_dtype):\n        obj = pd.Index(list(\"abcd\"))\n        assert obj.dtype == object\n\n        exp = pd.Index([\"a\", coerced_val, \"b\", \"c\", \"d\"])\n        self._assert_insert_conversion(obj, insert, exp, coerced_dtype)\n\n    @pytest.mark.parametrize(\n        \"insert, coerced_val, coerced_dtype\",\n        [\n            (1, 1, np.int64),\n            (1.1, 1.1, np.float64),\n            (False, False, object),  # GH#36319\n            (\"x\", \"x\", object),\n        ],\n    )\n    def test_insert_index_int64(self, insert, coerced_val, coerced_dtype):\n        obj = Int64Index([1, 2, 3, 4])\n        assert obj.dtype == np.int64\n\n        exp = pd.Index([1, coerced_val, 2, 3, 4])\n        self._assert_insert_conversion(obj, insert, exp, coerced_dtype)\n\n    @pytest.mark.parametrize(\n        \"insert, coerced_val, coerced_dtype\",\n        [\n            (1, 1.0, np.float64),\n            (1.1, 1.1, np.float64),\n            (False, False, object),  # GH#36319\n            (\"x\", \"x\", object),\n        ],\n    )\n    def test_insert_index_float64(self, insert, coerced_val, coerced_dtype):\n        obj = Float64Index([1.0, 2.0, 3.0, 4.0])\n        assert obj.dtype == np.float64\n\n        exp = pd.Index([1.0, coerced_val, 2.0, 3.0, 4.0])\n        self._assert_insert_conversion(obj, insert, exp, coerced_dtype)\n\n    @pytest.mark.parametrize(\n        \"fill_val,exp_dtype\",\n        [\n            (pd.Timestamp(\"2012-01-01\"), \"datetime64[ns]\"),\n            (pd.Timestamp(\"2012-01-01\", tz=\"US/Eastern\"), \"datetime64[ns, US/Eastern]\"),\n        ],\n        ids=[\"datetime64\", \"datetime64tz\"],\n    )\n    @pytest.mark.parametrize(\n        \"insert_value\",\n        [pd.Timestamp(\"2012-01-01\"), pd.Timestamp(\"2012-01-01\", tz=\"Asia/Tokyo\"), 1],\n    )\n    def test_insert_index_datetimes(self, request, fill_val, exp_dtype, insert_value):\n\n        obj = pd.DatetimeIndex(\n            [\"2011-01-01\", \"2011-01-02\", \"2011-01-03\", \"2011-01-04\"], tz=fill_val.tz\n        )\n        assert obj.dtype == exp_dtype\n\n        exp = pd.DatetimeIndex(\n            [\"2011-01-01\", fill_val.date(), \"2011-01-02\", \"2011-01-03\", \"2011-01-04\"],\n            tz=fill_val.tz,\n        )\n        self._assert_insert_conversion(obj, fill_val, exp, exp_dtype)\n\n        if fill_val.tz:\n\n            # mismatched tzawareness\n            ts = pd.Timestamp(\"2012-01-01\")\n            result = obj.insert(1, ts)\n            expected = obj.astype(object).insert(1, ts)\n            assert expected.dtype == object\n            tm.assert_index_equal(result, expected)\n\n            # mismatched tz --> cast to object (could reasonably cast to common tz)\n            ts = pd.Timestamp(\"2012-01-01\", tz=\"Asia/Tokyo\")\n            with tm.assert_produces_warning(FutureWarning, match=\"mismatched timezone\"):\n                result = obj.insert(1, ts)\n            # once deprecation is enforced:\n            # expected = obj.insert(1, ts.tz_convert(obj.dtype.tz))\n            # assert expected.dtype == obj.dtype\n            expected = obj.astype(object).insert(1, ts)\n            tm.assert_index_equal(result, expected)\n\n        else:\n            # mismatched tzawareness\n            ts = pd.Timestamp(\"2012-01-01\", tz=\"Asia/Tokyo\")\n            result = obj.insert(1, ts)\n            expected = obj.astype(object).insert(1, ts)\n            assert expected.dtype == object\n            tm.assert_index_equal(result, expected)\n\n        item = 1\n        result = obj.insert(1, item)\n        expected = obj.astype(object).insert(1, item)\n        assert expected[1] == item\n        assert expected.dtype == object\n        tm.assert_index_equal(result, expected)\n\n    def test_insert_index_timedelta64(self):\n        obj = pd.TimedeltaIndex([\"1 day\", \"2 day\", \"3 day\", \"4 day\"])\n        assert obj.dtype == \"timedelta64[ns]\"\n\n        # timedelta64 + timedelta64 => timedelta64\n        exp = pd.TimedeltaIndex([\"1 day\", \"10 day\", \"2 day\", \"3 day\", \"4 day\"])\n        self._assert_insert_conversion(\n            obj, pd.Timedelta(\"10 day\"), exp, \"timedelta64[ns]\"\n        )\n\n        for item in [pd.Timestamp(\"2012-01-01\"), 1]:\n            result = obj.insert(1, item)\n            expected = obj.astype(object).insert(1, item)\n            assert expected.dtype == object\n            tm.assert_index_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"insert, coerced_val, coerced_dtype\",\n        [\n            (pd.Period(\"2012-01\", freq=\"M\"), \"2012-01\", \"period[M]\"),\n            (pd.Timestamp(\"2012-01-01\"), pd.Timestamp(\"2012-01-01\"), object),\n            (1, 1, object),\n            (\"x\", \"x\", object),\n        ],\n    )\n    def test_insert_index_period(self, insert, coerced_val, coerced_dtype):\n        obj = pd.PeriodIndex([\"2011-01\", \"2011-02\", \"2011-03\", \"2011-04\"], freq=\"M\")\n        assert obj.dtype == \"period[M]\"\n\n        data = [\n            pd.Period(\"2011-01\", freq=\"M\"),\n            coerced_val,\n            pd.Period(\"2011-02\", freq=\"M\"),\n            pd.Period(\"2011-03\", freq=\"M\"),\n            pd.Period(\"2011-04\", freq=\"M\"),\n        ]\n        if isinstance(insert, pd.Period):\n            exp = pd.PeriodIndex(data, freq=\"M\")\n            self._assert_insert_conversion(obj, insert, exp, coerced_dtype)\n\n            # string that can be parsed to appropriate PeriodDtype\n            self._assert_insert_conversion(obj, str(insert), exp, coerced_dtype)\n\n        else:\n            result = obj.insert(0, insert)\n            expected = obj.astype(object).insert(0, insert)\n            tm.assert_index_equal(result, expected)\n\n            # TODO: ATM inserting '2012-01-01 00:00:00' when we have obj.freq==\"M\"\n            #  casts that string to Period[M], not clear that is desirable\n            if not isinstance(insert, pd.Timestamp):\n                # non-castable string\n                result = obj.insert(0, str(insert))\n                expected = obj.astype(object).insert(0, str(insert))\n                tm.assert_index_equal(result, expected)\n\n            msg = r\"Unexpected keyword arguments {'freq'}\"\n            with pytest.raises(TypeError, match=msg):\n                with tm.assert_produces_warning(FutureWarning):\n                    # passing keywords to pd.Index\n                    pd.Index(data, freq=\"M\")\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_insert_index_complex128(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_insert_index_bool(self):\n        raise NotImplementedError\n\n\nclass TestWhereCoercion(CoercionBase):\n\n    method = \"where\"\n\n    def _assert_where_conversion(\n        self, original, cond, values, expected, expected_dtype\n    ):\n        \"\"\"test coercion triggered by where\"\"\"\n        target = original.copy()\n        res = target.where(cond, values)\n        tm.assert_equal(res, expected)\n        assert res.dtype == expected_dtype\n\n    @pytest.mark.parametrize(\n        \"fill_val,exp_dtype\",\n        [(1, object), (1.1, object), (1 + 1j, object), (True, object)],\n    )\n    def test_where_object(self, index_or_series, fill_val, exp_dtype):\n        klass = index_or_series\n        obj = klass(list(\"abcd\"))\n        assert obj.dtype == object\n        cond = klass([True, False, True, False])\n\n        if fill_val is True and klass is pd.Series:\n            ret_val = 1\n        else:\n            ret_val = fill_val\n\n        exp = klass([\"a\", ret_val, \"c\", ret_val])\n        self._assert_where_conversion(obj, cond, fill_val, exp, exp_dtype)\n\n        if fill_val is True:\n            values = klass([True, False, True, True])\n        else:\n            values = klass(x * fill_val for x in [5, 6, 7, 8])\n\n        exp = klass([\"a\", values[1], \"c\", values[3]])\n        self._assert_where_conversion(obj, cond, values, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"fill_val,exp_dtype\",\n        [(1, np.int64), (1.1, np.float64), (1 + 1j, np.complex128), (True, object)],\n    )\n    def test_where_int64(self, index_or_series, fill_val, exp_dtype, request):\n        klass = index_or_series\n        if klass is pd.Index and exp_dtype is np.complex128:\n            mark = pytest.mark.xfail(reason=\"Complex Index not supported\")\n            request.node.add_marker(mark)\n\n        obj = klass([1, 2, 3, 4])\n        assert obj.dtype == np.int64\n        cond = klass([True, False, True, False])\n\n        exp = klass([1, fill_val, 3, fill_val])\n        self._assert_where_conversion(obj, cond, fill_val, exp, exp_dtype)\n\n        if fill_val is True:\n            values = klass([True, False, True, True])\n        else:\n            values = klass(x * fill_val for x in [5, 6, 7, 8])\n        exp = klass([1, values[1], 3, values[3]])\n        self._assert_where_conversion(obj, cond, values, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"fill_val, exp_dtype\",\n        [(1, np.float64), (1.1, np.float64), (1 + 1j, np.complex128), (True, object)],\n    )\n    def test_where_float64(self, index_or_series, fill_val, exp_dtype, request):\n        klass = index_or_series\n        if klass is pd.Index and exp_dtype is np.complex128:\n            mark = pytest.mark.xfail(reason=\"Complex Index not supported\")\n            request.node.add_marker(mark)\n\n        obj = klass([1.1, 2.2, 3.3, 4.4])\n        assert obj.dtype == np.float64\n        cond = klass([True, False, True, False])\n\n        exp = klass([1.1, fill_val, 3.3, fill_val])\n        self._assert_where_conversion(obj, cond, fill_val, exp, exp_dtype)\n\n        if fill_val is True:\n            values = klass([True, False, True, True])\n        else:\n            values = klass(x * fill_val for x in [5, 6, 7, 8])\n        exp = klass([1.1, values[1], 3.3, values[3]])\n        self._assert_where_conversion(obj, cond, values, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"fill_val,exp_dtype\",\n        [\n            (1, np.complex128),\n            (1.1, np.complex128),\n            (1 + 1j, np.complex128),\n            (True, object),\n        ],\n    )\n    def test_where_series_complex128(self, fill_val, exp_dtype):\n        klass = pd.Series\n        obj = klass([1 + 1j, 2 + 2j, 3 + 3j, 4 + 4j])\n        assert obj.dtype == np.complex128\n        cond = klass([True, False, True, False])\n\n        exp = klass([1 + 1j, fill_val, 3 + 3j, fill_val])\n        self._assert_where_conversion(obj, cond, fill_val, exp, exp_dtype)\n\n        if fill_val is True:\n            values = klass([True, False, True, True])\n        else:\n            values = klass(x * fill_val for x in [5, 6, 7, 8])\n        exp = klass([1 + 1j, values[1], 3 + 3j, values[3]], dtype=exp_dtype)\n        self._assert_where_conversion(obj, cond, values, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"fill_val,exp_dtype\",\n        [(1, object), (1.1, object), (1 + 1j, object), (True, np.bool_)],\n    )\n    def test_where_series_bool(self, fill_val, exp_dtype):\n        klass = pd.Series\n\n        obj = klass([True, False, True, False])\n        assert obj.dtype == np.bool_\n        cond = klass([True, False, True, False])\n\n        exp = klass([True, fill_val, True, fill_val])\n        self._assert_where_conversion(obj, cond, fill_val, exp, exp_dtype)\n\n        if fill_val is True:\n            values = klass([True, False, True, True])\n        else:\n            values = klass(x * fill_val for x in [5, 6, 7, 8])\n        exp = klass([True, values[1], True, values[3]])\n        self._assert_where_conversion(obj, cond, values, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"fill_val,exp_dtype\",\n        [\n            (pd.Timestamp(\"2012-01-01\"), \"datetime64[ns]\"),\n            (pd.Timestamp(\"2012-01-01\", tz=\"US/Eastern\"), object),\n        ],\n        ids=[\"datetime64\", \"datetime64tz\"],\n    )\n    def test_where_series_datetime64(self, fill_val, exp_dtype):\n        obj = pd.Series(\n            [\n                pd.Timestamp(\"2011-01-01\"),\n                pd.Timestamp(\"2011-01-02\"),\n                pd.Timestamp(\"2011-01-03\"),\n                pd.Timestamp(\"2011-01-04\"),\n            ]\n        )\n        assert obj.dtype == \"datetime64[ns]\"\n        cond = pd.Series([True, False, True, False])\n\n        exp = pd.Series(\n            [pd.Timestamp(\"2011-01-01\"), fill_val, pd.Timestamp(\"2011-01-03\"), fill_val]\n        )\n        self._assert_where_conversion(obj, cond, fill_val, exp, exp_dtype)\n\n        values = pd.Series(pd.date_range(fill_val, periods=4))\n        if fill_val.tz:\n            exp = pd.Series(\n                [\n                    pd.Timestamp(\"2011-01-01\"),\n                    pd.Timestamp(\"2012-01-02 00:00\", tz=\"US/Eastern\"),\n                    pd.Timestamp(\"2011-01-03\"),\n                    pd.Timestamp(\"2012-01-04 00:00\", tz=\"US/Eastern\"),\n                ]\n            )\n            self._assert_where_conversion(obj, cond, values, exp, exp_dtype)\n\n        exp = pd.Series(\n            [\n                pd.Timestamp(\"2011-01-01\"),\n                values[1],\n                pd.Timestamp(\"2011-01-03\"),\n                values[3],\n            ]\n        )\n        self._assert_where_conversion(obj, cond, values, exp, exp_dtype)\n\n    @pytest.mark.parametrize(\n        \"fill_val\",\n        [\n            pd.Timestamp(\"2012-01-01\"),\n            pd.Timestamp(\"2012-01-01\").to_datetime64(),\n            pd.Timestamp(\"2012-01-01\").to_pydatetime(),\n        ],\n    )\n    def test_where_index_datetime(self, fill_val):\n        exp_dtype = \"datetime64[ns]\"\n        obj = pd.Index(\n            [\n                pd.Timestamp(\"2011-01-01\"),\n                pd.Timestamp(\"2011-01-02\"),\n                pd.Timestamp(\"2011-01-03\"),\n                pd.Timestamp(\"2011-01-04\"),\n            ]\n        )\n        assert obj.dtype == \"datetime64[ns]\"\n        cond = pd.Index([True, False, True, False])\n\n        result = obj.where(cond, fill_val)\n        expected = pd.DatetimeIndex([obj[0], fill_val, obj[2], fill_val])\n        tm.assert_index_equal(result, expected)\n\n        values = pd.Index(pd.date_range(fill_val, periods=4))\n        exp = pd.Index(\n            [\n                pd.Timestamp(\"2011-01-01\"),\n                pd.Timestamp(\"2012-01-02\"),\n                pd.Timestamp(\"2011-01-03\"),\n                pd.Timestamp(\"2012-01-04\"),\n            ]\n        )\n\n        self._assert_where_conversion(obj, cond, values, exp, exp_dtype)\n\n    def test_where_index_datetime64tz(self):\n        fill_val = pd.Timestamp(\"2012-01-01\", tz=\"US/Eastern\")\n        exp_dtype = object\n        obj = pd.Index(\n            [\n                pd.Timestamp(\"2011-01-01\"),\n                pd.Timestamp(\"2011-01-02\"),\n                pd.Timestamp(\"2011-01-03\"),\n                pd.Timestamp(\"2011-01-04\"),\n            ]\n        )\n        assert obj.dtype == \"datetime64[ns]\"\n        cond = pd.Index([True, False, True, False])\n\n        res = obj.where(cond, fill_val)\n        expected = pd.Index([obj[0], fill_val, obj[2], fill_val], dtype=object)\n        tm.assert_index_equal(res, expected)\n\n        values = pd.Index(pd.date_range(fill_val, periods=4))\n        exp = pd.Index(\n            [\n                pd.Timestamp(\"2011-01-01\"),\n                pd.Timestamp(\"2012-01-02\", tz=\"US/Eastern\"),\n                pd.Timestamp(\"2011-01-03\"),\n                pd.Timestamp(\"2012-01-04\", tz=\"US/Eastern\"),\n            ],\n            dtype=exp_dtype,\n        )\n\n        self._assert_where_conversion(obj, cond, values, exp, exp_dtype)\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_where_index_complex128(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_where_index_bool(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_where_series_timedelta64(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_where_series_period(self):\n        raise NotImplementedError\n\n    @pytest.mark.parametrize(\n        \"value\", [pd.Timedelta(days=9), timedelta(days=9), np.timedelta64(9, \"D\")]\n    )\n    def test_where_index_timedelta64(self, value):\n        tdi = pd.timedelta_range(\"1 Day\", periods=4)\n        cond = np.array([True, False, False, True])\n\n        expected = pd.TimedeltaIndex([\"1 Day\", value, value, \"4 Days\"])\n        result = tdi.where(cond, value)\n        tm.assert_index_equal(result, expected)\n\n        # wrong-dtyped NaT\n        dtnat = np.datetime64(\"NaT\", \"ns\")\n        expected = pd.Index([tdi[0], dtnat, dtnat, tdi[3]], dtype=object)\n        assert expected[1] is dtnat\n\n        result = tdi.where(cond, dtnat)\n        tm.assert_index_equal(result, expected)\n\n    def test_where_index_period(self):\n        dti = pd.date_range(\"2016-01-01\", periods=3, freq=\"QS\")\n        pi = dti.to_period(\"Q\")\n\n        cond = np.array([False, True, False])\n\n        # Passinga  valid scalar\n        value = pi[-1] + pi.freq * 10\n        expected = pd.PeriodIndex([value, pi[1], value])\n        result = pi.where(cond, value)\n        tm.assert_index_equal(result, expected)\n\n        # Case passing ndarray[object] of Periods\n        other = np.asarray(pi + pi.freq * 10, dtype=object)\n        result = pi.where(cond, other)\n        expected = pd.PeriodIndex([other[0], pi[1], other[2]])\n        tm.assert_index_equal(result, expected)\n\n        # Passing a mismatched scalar -> casts to object\n        td = pd.Timedelta(days=4)\n        expected = pd.Index([td, pi[1], td], dtype=object)\n        result = pi.where(cond, td)\n        tm.assert_index_equal(result, expected)\n\n        per = pd.Period(\"2020-04-21\", \"D\")\n        expected = pd.Index([per, pi[1], per], dtype=object)\n        result = pi.where(cond, per)\n        tm.assert_index_equal(result, expected)\n\n\nclass TestFillnaSeriesCoercion(CoercionBase):\n\n    # not indexing, but place here for consistency\n\n    method = \"fillna\"\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_has_comprehensive_tests(self):\n        raise NotImplementedError\n\n    def _assert_fillna_conversion(self, original, value, expected, expected_dtype):\n        \"\"\"test coercion triggered by fillna\"\"\"\n        target = original.copy()\n        res = target.fillna(value)\n        tm.assert_equal(res, expected)\n        assert res.dtype == expected_dtype\n\n    @pytest.mark.parametrize(\n        \"fill_val, fill_dtype\",\n        [(1, object), (1.1, object), (1 + 1j, object), (True, object)],\n    )\n    def test_fillna_object(self, index_or_series, fill_val, fill_dtype):\n        klass = index_or_series\n        obj = klass([\"a\", np.nan, \"c\", \"d\"])\n        assert obj.dtype == object\n\n        exp = klass([\"a\", fill_val, \"c\", \"d\"])\n        self._assert_fillna_conversion(obj, fill_val, exp, fill_dtype)\n\n    @pytest.mark.parametrize(\n        \"fill_val,fill_dtype\",\n        [(1, np.float64), (1.1, np.float64), (1 + 1j, np.complex128), (True, object)],\n    )\n    def test_fillna_float64(self, index_or_series, fill_val, fill_dtype):\n        klass = index_or_series\n        obj = klass([1.1, np.nan, 3.3, 4.4])\n        assert obj.dtype == np.float64\n\n        exp = klass([1.1, fill_val, 3.3, 4.4])\n        # float + complex -> we don't support a complex Index\n        # complex for Series,\n        # object for Index\n        if fill_dtype == np.complex128 and klass == pd.Index:\n            fill_dtype = object\n        self._assert_fillna_conversion(obj, fill_val, exp, fill_dtype)\n\n    @pytest.mark.parametrize(\n        \"fill_val,fill_dtype\",\n        [\n            (1, np.complex128),\n            (1.1, np.complex128),\n            (1 + 1j, np.complex128),\n            (True, object),\n        ],\n    )\n    def test_fillna_series_complex128(self, fill_val, fill_dtype):\n        obj = pd.Series([1 + 1j, np.nan, 3 + 3j, 4 + 4j])\n        assert obj.dtype == np.complex128\n\n        exp = pd.Series([1 + 1j, fill_val, 3 + 3j, 4 + 4j])\n        self._assert_fillna_conversion(obj, fill_val, exp, fill_dtype)\n\n    @pytest.mark.parametrize(\n        \"fill_val,fill_dtype\",\n        [\n            (pd.Timestamp(\"2012-01-01\"), \"datetime64[ns]\"),\n            (pd.Timestamp(\"2012-01-01\", tz=\"US/Eastern\"), object),\n            (1, object),\n            (\"x\", object),\n        ],\n        ids=[\"datetime64\", \"datetime64tz\", \"object\", \"object\"],\n    )\n    def test_fillna_datetime(self, index_or_series, fill_val, fill_dtype):\n        klass = index_or_series\n        obj = klass(\n            [\n                pd.Timestamp(\"2011-01-01\"),\n                pd.NaT,\n                pd.Timestamp(\"2011-01-03\"),\n                pd.Timestamp(\"2011-01-04\"),\n            ]\n        )\n        assert obj.dtype == \"datetime64[ns]\"\n\n        exp = klass(\n            [\n                pd.Timestamp(\"2011-01-01\"),\n                fill_val,\n                pd.Timestamp(\"2011-01-03\"),\n                pd.Timestamp(\"2011-01-04\"),\n            ]\n        )\n        self._assert_fillna_conversion(obj, fill_val, exp, fill_dtype)\n\n    @pytest.mark.parametrize(\n        \"fill_val,fill_dtype\",\n        [\n            (pd.Timestamp(\"2012-01-01\", tz=\"US/Eastern\"), \"datetime64[ns, US/Eastern]\"),\n            (pd.Timestamp(\"2012-01-01\"), object),\n            (pd.Timestamp(\"2012-01-01\", tz=\"Asia/Tokyo\"), object),\n            (1, object),\n            (\"x\", object),\n        ],\n    )\n    def test_fillna_datetime64tz(self, index_or_series, fill_val, fill_dtype):\n        klass = index_or_series\n        tz = \"US/Eastern\"\n\n        obj = klass(\n            [\n                pd.Timestamp(\"2011-01-01\", tz=tz),\n                pd.NaT,\n                pd.Timestamp(\"2011-01-03\", tz=tz),\n                pd.Timestamp(\"2011-01-04\", tz=tz),\n            ]\n        )\n        assert obj.dtype == \"datetime64[ns, US/Eastern]\"\n\n        exp = klass(\n            [\n                pd.Timestamp(\"2011-01-01\", tz=tz),\n                fill_val,\n                # Once deprecation is enforced, this becomes:\n                # fill_val.tz_convert(tz) if getattr(fill_val, \"tz\", None)\n                #  is not None else fill_val,\n                pd.Timestamp(\"2011-01-03\", tz=tz),\n                pd.Timestamp(\"2011-01-04\", tz=tz),\n            ]\n        )\n        warn = None\n        if getattr(fill_val, \"tz\", None) is not None and fill_val.tz != obj[0].tz:\n            warn = FutureWarning\n        with tm.assert_produces_warning(warn, match=\"mismatched timezone\"):\n            self._assert_fillna_conversion(obj, fill_val, exp, fill_dtype)\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_fillna_series_int64(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_fillna_index_int64(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_fillna_series_bool(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_fillna_index_bool(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_fillna_series_timedelta64(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_fillna_series_period(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_fillna_index_timedelta64(self):\n        raise NotImplementedError\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_fillna_index_period(self):\n        raise NotImplementedError\n\n\nclass TestReplaceSeriesCoercion(CoercionBase):\n\n    klasses = [\"series\"]\n    method = \"replace\"\n\n    rep: dict[str, list] = {}\n    rep[\"object\"] = [\"a\", \"b\"]\n    rep[\"int64\"] = [4, 5]\n    rep[\"float64\"] = [1.1, 2.2]\n    rep[\"complex128\"] = [1 + 1j, 2 + 2j]\n    rep[\"bool\"] = [True, False]\n    rep[\"datetime64[ns]\"] = [pd.Timestamp(\"2011-01-01\"), pd.Timestamp(\"2011-01-03\")]\n\n    for tz in [\"UTC\", \"US/Eastern\"]:\n        # to test tz => different tz replacement\n        key = f\"datetime64[ns, {tz}]\"\n        rep[key] = [\n            pd.Timestamp(\"2011-01-01\", tz=tz),\n            pd.Timestamp(\"2011-01-03\", tz=tz),\n        ]\n\n    rep[\"timedelta64[ns]\"] = [pd.Timedelta(\"1 day\"), pd.Timedelta(\"2 day\")]\n\n    @pytest.fixture(params=[\"dict\", \"series\"])\n    def how(self, request):\n        return request.param\n\n    @pytest.fixture(\n        params=[\n            \"object\",\n            \"int64\",\n            \"float64\",\n            \"complex128\",\n            \"bool\",\n            \"datetime64[ns]\",\n            \"datetime64[ns, UTC]\",\n            \"datetime64[ns, US/Eastern]\",\n            \"timedelta64[ns]\",\n        ]\n    )\n    def from_key(self, request):\n        return request.param\n\n    @pytest.fixture(\n        params=[\n            \"object\",\n            \"int64\",\n            \"float64\",\n            \"complex128\",\n            \"bool\",\n            \"datetime64[ns]\",\n            \"datetime64[ns, UTC]\",\n            \"datetime64[ns, US/Eastern]\",\n            \"timedelta64[ns]\",\n        ],\n        ids=[\n            \"object\",\n            \"int64\",\n            \"float64\",\n            \"complex128\",\n            \"bool\",\n            \"datetime64\",\n            \"datetime64tz\",\n            \"datetime64tz\",\n            \"timedelta64\",\n        ],\n    )\n    def to_key(self, request):\n        return request.param\n\n    @pytest.fixture\n    def replacer(self, how, from_key, to_key):\n        \"\"\"\n        Object we will pass to `Series.replace`\n        \"\"\"\n        if how == \"dict\":\n            replacer = dict(zip(self.rep[from_key], self.rep[to_key]))\n        elif how == \"series\":\n            replacer = pd.Series(self.rep[to_key], index=self.rep[from_key])\n        else:\n            raise ValueError\n        return replacer\n\n    def test_replace_series(self, how, to_key, from_key, replacer):\n        index = pd.Index([3, 4], name=\"xxx\")\n        obj = pd.Series(self.rep[from_key], index=index, name=\"yyy\")\n        assert obj.dtype == from_key\n\n        if from_key.startswith(\"datetime\") and to_key.startswith(\"datetime\"):\n            # tested below\n            return\n        elif from_key in [\"datetime64[ns, US/Eastern]\", \"datetime64[ns, UTC]\"]:\n            # tested below\n            return\n\n        result = obj.replace(replacer)\n\n        if (from_key == \"float64\" and to_key in (\"int64\")) or (\n            from_key == \"complex128\" and to_key in (\"int64\", \"float64\")\n        ):\n\n            if not IS64 or is_platform_windows():\n                pytest.skip(f\"32-bit platform buggy: {from_key} -> {to_key}\")\n\n            # Expected: do not downcast by replacement\n            exp = pd.Series(self.rep[to_key], index=index, name=\"yyy\", dtype=from_key)\n\n        else:\n            exp = pd.Series(self.rep[to_key], index=index, name=\"yyy\")\n            assert exp.dtype == to_key\n\n        tm.assert_series_equal(result, exp)\n\n    @pytest.mark.parametrize(\n        \"to_key\",\n        [\"timedelta64[ns]\", \"bool\", \"object\", \"complex128\", \"float64\", \"int64\"],\n        indirect=True,\n    )\n    @pytest.mark.parametrize(\n        \"from_key\", [\"datetime64[ns, UTC]\", \"datetime64[ns, US/Eastern]\"], indirect=True\n    )\n    def test_replace_series_datetime_tz(self, how, to_key, from_key, replacer):\n        index = pd.Index([3, 4], name=\"xyz\")\n        obj = pd.Series(self.rep[from_key], index=index, name=\"yyy\")\n        assert obj.dtype == from_key\n\n        result = obj.replace(replacer)\n\n        exp = pd.Series(self.rep[to_key], index=index, name=\"yyy\")\n        assert exp.dtype == to_key\n\n        tm.assert_series_equal(result, exp)\n\n    @pytest.mark.parametrize(\n        \"to_key\",\n        [\"datetime64[ns]\", \"datetime64[ns, UTC]\", \"datetime64[ns, US/Eastern]\"],\n        indirect=True,\n    )\n    @pytest.mark.parametrize(\n        \"from_key\",\n        [\"datetime64[ns]\", \"datetime64[ns, UTC]\", \"datetime64[ns, US/Eastern]\"],\n        indirect=True,\n    )\n    def test_replace_series_datetime_datetime(self, how, to_key, from_key, replacer):\n        index = pd.Index([3, 4], name=\"xyz\")\n        obj = pd.Series(self.rep[from_key], index=index, name=\"yyy\")\n        assert obj.dtype == from_key\n\n        warn = None\n        rep_ser = pd.Series(replacer)\n        if (\n            isinstance(obj.dtype, pd.DatetimeTZDtype)\n            and isinstance(rep_ser.dtype, pd.DatetimeTZDtype)\n            and obj.dtype != rep_ser.dtype\n        ):\n            # mismatched tz DatetimeArray behavior will change to cast\n            #  for setitem-like methods with mismatched tzs GH#44940\n            warn = FutureWarning\n\n        msg = \"explicitly cast to object\"\n        with tm.assert_produces_warning(warn, match=msg):\n            result = obj.replace(replacer)\n\n        exp = pd.Series(self.rep[to_key], index=index, name=\"yyy\")\n        assert exp.dtype == to_key\n\n        tm.assert_series_equal(result, exp)\n\n    @pytest.mark.xfail(reason=\"Test not implemented\")\n    def test_replace_series_period(self):\n        raise NotImplementedError\n"
    },
    {
      "filename": "pandas/tests/series/methods/test_replace.py",
      "content": "import re\n\nimport numpy as np\nimport pytest\n\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.arrays import IntervalArray\n\n\nclass TestSeriesReplace:\n    def test_replace(self):\n        N = 100\n        ser = pd.Series(np.random.randn(N))\n        ser[0:4] = np.nan\n        ser[6:10] = 0\n\n        # replace list with a single value\n        return_value = ser.replace([np.nan], -1, inplace=True)\n        assert return_value is None\n\n        exp = ser.fillna(-1)\n        tm.assert_series_equal(ser, exp)\n\n        rs = ser.replace(0.0, np.nan)\n        ser[ser == 0.0] = np.nan\n        tm.assert_series_equal(rs, ser)\n\n        ser = pd.Series(np.fabs(np.random.randn(N)), tm.makeDateIndex(N), dtype=object)\n        ser[:5] = np.nan\n        ser[6:10] = \"foo\"\n        ser[20:30] = \"bar\"\n\n        # replace list with a single value\n        rs = ser.replace([np.nan, \"foo\", \"bar\"], -1)\n\n        assert (rs[:5] == -1).all()\n        assert (rs[6:10] == -1).all()\n        assert (rs[20:30] == -1).all()\n        assert (pd.isna(ser[:5])).all()\n\n        # replace with different values\n        rs = ser.replace({np.nan: -1, \"foo\": -2, \"bar\": -3})\n\n        assert (rs[:5] == -1).all()\n        assert (rs[6:10] == -2).all()\n        assert (rs[20:30] == -3).all()\n        assert (pd.isna(ser[:5])).all()\n\n        # replace with different values with 2 lists\n        rs2 = ser.replace([np.nan, \"foo\", \"bar\"], [-1, -2, -3])\n        tm.assert_series_equal(rs, rs2)\n\n        # replace inplace\n        return_value = ser.replace([np.nan, \"foo\", \"bar\"], -1, inplace=True)\n        assert return_value is None\n\n        assert (ser[:5] == -1).all()\n        assert (ser[6:10] == -1).all()\n        assert (ser[20:30] == -1).all()\n\n    def test_replace_nan_with_inf(self):\n        ser = pd.Series([np.nan, 0, np.inf])\n        tm.assert_series_equal(ser.replace(np.nan, 0), ser.fillna(0))\n\n        ser = pd.Series([np.nan, 0, \"foo\", \"bar\", np.inf, None, pd.NaT])\n        tm.assert_series_equal(ser.replace(np.nan, 0), ser.fillna(0))\n        filled = ser.copy()\n        filled[4] = 0\n        tm.assert_series_equal(ser.replace(np.inf, 0), filled)\n\n    def test_replace_listlike_value_listlike_target(self, datetime_series):\n        ser = pd.Series(datetime_series.index)\n        tm.assert_series_equal(ser.replace(np.nan, 0), ser.fillna(0))\n\n        # malformed\n        msg = r\"Replacement lists must match in length\\. Expecting 3 got 2\"\n        with pytest.raises(ValueError, match=msg):\n            ser.replace([1, 2, 3], [np.nan, 0])\n\n        # ser is dt64 so can't hold 1 or 2, so this replace is a no-op\n        result = ser.replace([1, 2], [np.nan, 0])\n        tm.assert_series_equal(result, ser)\n\n        ser = pd.Series([0, 1, 2, 3, 4])\n        result = ser.replace([0, 1, 2, 3, 4], [4, 3, 2, 1, 0])\n        tm.assert_series_equal(result, pd.Series([4, 3, 2, 1, 0]))\n\n    def test_replace_gh5319(self):\n        # API change from 0.12?\n        # GH 5319\n        ser = pd.Series([0, np.nan, 2, 3, 4])\n        expected = ser.ffill()\n        result = ser.replace([np.nan])\n        tm.assert_series_equal(result, expected)\n\n        ser = pd.Series([0, np.nan, 2, 3, 4])\n        expected = ser.ffill()\n        result = ser.replace(np.nan)\n        tm.assert_series_equal(result, expected)\n\n    def test_replace_datetime64(self):\n        # GH 5797\n        ser = pd.Series(pd.date_range(\"20130101\", periods=5))\n        expected = ser.copy()\n        expected.loc[2] = pd.Timestamp(\"20120101\")\n        result = ser.replace({pd.Timestamp(\"20130103\"): pd.Timestamp(\"20120101\")})\n        tm.assert_series_equal(result, expected)\n        result = ser.replace(pd.Timestamp(\"20130103\"), pd.Timestamp(\"20120101\"))\n        tm.assert_series_equal(result, expected)\n\n    def test_replace_nat_with_tz(self):\n        # GH 11792: Test with replacing NaT in a list with tz data\n        ts = pd.Timestamp(\"2015/01/01\", tz=\"UTC\")\n        s = pd.Series([pd.NaT, pd.Timestamp(\"2015/01/01\", tz=\"UTC\")])\n        result = s.replace([np.nan, pd.NaT], pd.Timestamp.min)\n        expected = pd.Series([pd.Timestamp.min, ts], dtype=object)\n        tm.assert_series_equal(expected, result)\n\n    def test_replace_timedelta_td64(self):\n        tdi = pd.timedelta_range(0, periods=5)\n        ser = pd.Series(tdi)\n\n        # Using a single dict argument means we go through replace_list\n        result = ser.replace({ser[1]: ser[3]})\n\n        expected = pd.Series([ser[0], ser[3], ser[2], ser[3], ser[4]])\n        tm.assert_series_equal(result, expected)\n\n    def test_replace_with_single_list(self):\n        ser = pd.Series([0, 1, 2, 3, 4])\n        result = ser.replace([1, 2, 3])\n        tm.assert_series_equal(result, pd.Series([0, 0, 0, 0, 4]))\n\n        s = ser.copy()\n        return_value = s.replace([1, 2, 3], inplace=True)\n        assert return_value is None\n        tm.assert_series_equal(s, pd.Series([0, 0, 0, 0, 4]))\n\n        # make sure things don't get corrupted when fillna call fails\n        s = ser.copy()\n        msg = (\n            r\"Invalid fill method\\. Expecting pad \\(ffill\\) or backfill \"\n            r\"\\(bfill\\)\\. Got crash_cymbal\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            return_value = s.replace([1, 2, 3], inplace=True, method=\"crash_cymbal\")\n            assert return_value is None\n        tm.assert_series_equal(s, ser)\n\n    def test_replace_mixed_types(self):\n        ser = pd.Series(np.arange(5), dtype=\"int64\")\n\n        def check_replace(to_rep, val, expected):\n            sc = ser.copy()\n            result = ser.replace(to_rep, val)\n            return_value = sc.replace(to_rep, val, inplace=True)\n            assert return_value is None\n            tm.assert_series_equal(expected, result)\n            tm.assert_series_equal(expected, sc)\n\n        # 3.0 can still be held in our int64 series, so we do not upcast GH#44940\n        tr, v = [3], [3.0]\n        check_replace(tr, v, ser)\n        # Note this matches what we get with the scalars 3 and 3.0\n        check_replace(tr[0], v[0], ser)\n\n        # MUST upcast to float\n        e = pd.Series([0, 1, 2, 3.5, 4])\n        tr, v = [3], [3.5]\n        check_replace(tr, v, e)\n\n        # casts to object\n        e = pd.Series([0, 1, 2, 3.5, \"a\"])\n        tr, v = [3, 4], [3.5, \"a\"]\n        check_replace(tr, v, e)\n\n        # again casts to object\n        e = pd.Series([0, 1, 2, 3.5, pd.Timestamp(\"20130101\")])\n        tr, v = [3, 4], [3.5, pd.Timestamp(\"20130101\")]\n        check_replace(tr, v, e)\n\n        # casts to object\n        e = pd.Series([0, 1, 2, 3.5, True], dtype=\"object\")\n        tr, v = [3, 4], [3.5, True]\n        check_replace(tr, v, e)\n\n        # test an object with dates + floats + integers + strings\n        dr = pd.Series(pd.date_range(\"1/1/2001\", \"1/10/2001\", freq=\"D\"))\n        result = dr.astype(object).replace([dr[0], dr[1], dr[2]], [1.0, 2, \"a\"])\n        expected = pd.Series([1.0, 2, \"a\"] + dr[3:].tolist(), dtype=object)\n        tm.assert_series_equal(result, expected)\n\n    def test_replace_bool_with_string_no_op(self):\n        s = pd.Series([True, False, True])\n        result = s.replace(\"fun\", \"in-the-sun\")\n        tm.assert_series_equal(s, result)\n\n    def test_replace_bool_with_string(self):\n        # nonexistent elements\n        s = pd.Series([True, False, True])\n        result = s.replace(True, \"2u\")\n        expected = pd.Series([\"2u\", False, \"2u\"])\n        tm.assert_series_equal(expected, result)\n\n    def test_replace_bool_with_bool(self):\n        s = pd.Series([True, False, True])\n        result = s.replace(True, False)\n        expected = pd.Series([False] * len(s))\n        tm.assert_series_equal(expected, result)\n\n    def test_replace_with_dict_with_bool_keys(self):\n        s = pd.Series([True, False, True])\n        result = s.replace({\"asdf\": \"asdb\", True: \"yes\"})\n        expected = pd.Series([\"yes\", False, \"yes\"])\n        tm.assert_series_equal(result, expected)\n\n    def test_replace_Int_with_na(self, any_int_ea_dtype):\n        # GH 38267\n        result = pd.Series([0, None], dtype=any_int_ea_dtype).replace(0, pd.NA)\n        expected = pd.Series([pd.NA, pd.NA], dtype=any_int_ea_dtype)\n        tm.assert_series_equal(result, expected)\n        result = pd.Series([0, 1], dtype=any_int_ea_dtype).replace(0, pd.NA)\n        result.replace(1, pd.NA, inplace=True)\n        tm.assert_series_equal(result, expected)\n\n    def test_replace2(self):\n        N = 100\n        ser = pd.Series(np.fabs(np.random.randn(N)), tm.makeDateIndex(N), dtype=object)\n        ser[:5] = np.nan\n        ser[6:10] = \"foo\"\n        ser[20:30] = \"bar\"\n\n        # replace list with a single value\n        rs = ser.replace([np.nan, \"foo\", \"bar\"], -1)\n\n        assert (rs[:5] == -1).all()\n        assert (rs[6:10] == -1).all()\n        assert (rs[20:30] == -1).all()\n        assert (pd.isna(ser[:5])).all()\n\n        # replace with different values\n        rs = ser.replace({np.nan: -1, \"foo\": -2, \"bar\": -3})\n\n        assert (rs[:5] == -1).all()\n        assert (rs[6:10] == -2).all()\n        assert (rs[20:30] == -3).all()\n        assert (pd.isna(ser[:5])).all()\n\n        # replace with different values with 2 lists\n        rs2 = ser.replace([np.nan, \"foo\", \"bar\"], [-1, -2, -3])\n        tm.assert_series_equal(rs, rs2)\n\n        # replace inplace\n        return_value = ser.replace([np.nan, \"foo\", \"bar\"], -1, inplace=True)\n        assert return_value is None\n        assert (ser[:5] == -1).all()\n        assert (ser[6:10] == -1).all()\n        assert (ser[20:30] == -1).all()\n\n    def test_replace_with_dictlike_and_string_dtype(self, nullable_string_dtype):\n        # GH 32621, GH#44940\n        ser = pd.Series([\"one\", \"two\", np.nan], dtype=nullable_string_dtype)\n        expected = pd.Series([\"1\", \"2\", np.nan], dtype=nullable_string_dtype)\n        result = ser.replace({\"one\": \"1\", \"two\": \"2\"})\n        tm.assert_series_equal(expected, result)\n\n    def test_replace_with_empty_dictlike(self):\n        # GH 15289\n        s = pd.Series(list(\"abcd\"))\n        tm.assert_series_equal(s, s.replace({}))\n\n        with tm.assert_produces_warning(FutureWarning):\n            empty_series = pd.Series([])\n        tm.assert_series_equal(s, s.replace(empty_series))\n\n    def test_replace_string_with_number(self):\n        # GH 15743\n        s = pd.Series([1, 2, 3])\n        result = s.replace(\"2\", np.nan)\n        expected = pd.Series([1, 2, 3])\n        tm.assert_series_equal(expected, result)\n\n    def test_replace_replacer_equals_replacement(self):\n        # GH 20656\n        # make sure all replacers are matching against original values\n        s = pd.Series([\"a\", \"b\"])\n        expected = pd.Series([\"b\", \"a\"])\n        result = s.replace({\"a\": \"b\", \"b\": \"a\"})\n        tm.assert_series_equal(expected, result)\n\n    def test_replace_unicode_with_number(self):\n        # GH 15743\n        s = pd.Series([1, 2, 3])\n        result = s.replace(\"2\", np.nan)\n        expected = pd.Series([1, 2, 3])\n        tm.assert_series_equal(expected, result)\n\n    def test_replace_mixed_types_with_string(self):\n        # Testing mixed\n        s = pd.Series([1, 2, 3, \"4\", 4, 5])\n        result = s.replace([2, \"4\"], np.nan)\n        expected = pd.Series([1, np.nan, 3, np.nan, 4, 5])\n        tm.assert_series_equal(expected, result)\n\n    @pytest.mark.parametrize(\n        \"categorical, numeric\",\n        [\n            (pd.Categorical([\"A\"], categories=[\"A\", \"B\"]), [1]),\n            (pd.Categorical([\"A\", \"B\"], categories=[\"A\", \"B\"]), [1, 2]),\n        ],\n    )\n    def test_replace_categorical(self, categorical, numeric):\n        # GH 24971, GH#23305\n        ser = pd.Series(categorical)\n        result = ser.replace({\"A\": 1, \"B\": 2})\n        expected = pd.Series(numeric).astype(\"category\")\n        if 2 not in expected.cat.categories:\n            # i.e. categories should be [1, 2] even if there are no \"B\"s present\n            # GH#44940\n            expected = expected.cat.add_categories(2)\n        tm.assert_series_equal(expected, result)\n\n    def test_replace_categorical_single(self):\n        # GH 26988\n        dti = pd.date_range(\"2016-01-01\", periods=3, tz=\"US/Pacific\")\n        s = pd.Series(dti)\n        c = s.astype(\"category\")\n\n        expected = c.copy()\n        expected = expected.cat.add_categories(\"foo\")\n        expected[2] = \"foo\"\n        expected = expected.cat.remove_unused_categories()\n        assert c[2] != \"foo\"\n\n        result = c.replace(c[2], \"foo\")\n        tm.assert_series_equal(expected, result)\n        assert c[2] != \"foo\"  # ensure non-inplace call does not alter original\n\n        return_value = c.replace(c[2], \"foo\", inplace=True)\n        assert return_value is None\n        tm.assert_series_equal(expected, c)\n\n        first_value = c[0]\n        return_value = c.replace(c[1], c[0], inplace=True)\n        assert return_value is None\n        assert c[0] == c[1] == first_value  # test replacing with existing value\n\n    def test_replace_with_no_overflowerror(self):\n        # GH 25616\n        # casts to object without Exception from OverflowError\n        s = pd.Series([0, 1, 2, 3, 4])\n        result = s.replace([3], [\"100000000000000000000\"])\n        expected = pd.Series([0, 1, 2, \"100000000000000000000\", 4])\n        tm.assert_series_equal(result, expected)\n\n        s = pd.Series([0, \"100000000000000000000\", \"100000000000000000001\"])\n        result = s.replace([\"100000000000000000000\"], [1])\n        expected = pd.Series([0, 1, \"100000000000000000001\"])\n        tm.assert_series_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"ser, to_replace, exp\",\n        [\n            ([1, 2, 3], {1: 2, 2: 3, 3: 4}, [2, 3, 4]),\n            ([\"1\", \"2\", \"3\"], {\"1\": \"2\", \"2\": \"3\", \"3\": \"4\"}, [\"2\", \"3\", \"4\"]),\n        ],\n    )\n    def test_replace_commutative(self, ser, to_replace, exp):\n        # GH 16051\n        # DataFrame.replace() overwrites when values are non-numeric\n\n        series = pd.Series(ser)\n\n        expected = pd.Series(exp)\n        result = series.replace(to_replace)\n\n        tm.assert_series_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"ser, exp\", [([1, 2, 3], [1, True, 3]), ([\"x\", 2, 3], [\"x\", True, 3])]\n    )\n    def test_replace_no_cast(self, ser, exp):\n        # GH 9113\n        # BUG: replace int64 dtype with bool coerces to int64\n\n        series = pd.Series(ser)\n        result = series.replace(2, True)\n        expected = pd.Series(exp)\n\n        tm.assert_series_equal(result, expected)\n\n    def test_replace_invalid_to_replace(self):\n        # GH 18634\n        # API: replace() should raise an exception if invalid argument is given\n        series = pd.Series([\"a\", \"b\", \"c \"])\n        msg = (\n            r\"Expecting 'to_replace' to be either a scalar, array-like, \"\n            r\"dict or None, got invalid type.*\"\n        )\n        with pytest.raises(TypeError, match=msg):\n            series.replace(lambda x: x.strip())\n\n    @pytest.mark.parametrize(\"frame\", [False, True])\n    def test_replace_nonbool_regex(self, frame):\n        obj = pd.Series([\"a\", \"b\", \"c \"])\n        if frame:\n            obj = obj.to_frame()\n\n        msg = \"'to_replace' must be 'None' if 'regex' is not a bool\"\n        with pytest.raises(ValueError, match=msg):\n            obj.replace(to_replace=[\"a\"], regex=\"foo\")\n\n    @pytest.mark.parametrize(\"frame\", [False, True])\n    def test_replace_empty_copy(self, frame):\n        obj = pd.Series([], dtype=np.float64)\n        if frame:\n            obj = obj.to_frame()\n\n        res = obj.replace(4, 5, inplace=True)\n        assert res is None\n\n        res = obj.replace(4, 5, inplace=False)\n        tm.assert_equal(res, obj)\n        assert res is not obj\n\n    def test_replace_only_one_dictlike_arg(self, fixed_now_ts):\n        # GH#33340\n\n        ser = pd.Series([1, 2, \"A\", fixed_now_ts, True])\n        to_replace = {0: 1, 2: \"A\"}\n        value = \"foo\"\n        msg = \"Series.replace cannot use dict-like to_replace and non-None value\"\n        with pytest.raises(ValueError, match=msg):\n            ser.replace(to_replace, value)\n\n        to_replace = 1\n        value = {0: \"foo\", 2: \"bar\"}\n        msg = \"Series.replace cannot use dict-value and non-None to_replace\"\n        with pytest.raises(ValueError, match=msg):\n            ser.replace(to_replace, value)\n\n    def test_replace_extension_other(self, frame_or_series):\n        # https://github.com/pandas-dev/pandas/issues/34530\n        obj = frame_or_series(pd.array([1, 2, 3], dtype=\"Int64\"))\n        result = obj.replace(\"\", \"\")  # no exception\n        # should not have changed dtype\n        tm.assert_equal(obj, result)\n\n    def _check_replace_with_method(self, ser: pd.Series):\n        df = ser.to_frame()\n\n        res = ser.replace(ser[1], method=\"pad\")\n        expected = pd.Series([ser[0], ser[0]] + list(ser[2:]), dtype=ser.dtype)\n        tm.assert_series_equal(res, expected)\n\n        res_df = df.replace(ser[1], method=\"pad\")\n        tm.assert_frame_equal(res_df, expected.to_frame())\n\n        ser2 = ser.copy()\n        res2 = ser2.replace(ser[1], method=\"pad\", inplace=True)\n        assert res2 is None\n        tm.assert_series_equal(ser2, expected)\n\n        res_df2 = df.replace(ser[1], method=\"pad\", inplace=True)\n        assert res_df2 is None\n        tm.assert_frame_equal(df, expected.to_frame())\n\n    def test_replace_ea_dtype_with_method(self, any_numeric_ea_dtype):\n        arr = pd.array([1, 2, pd.NA, 4], dtype=any_numeric_ea_dtype)\n        ser = pd.Series(arr)\n\n        self._check_replace_with_method(ser)\n\n    @pytest.mark.parametrize(\"as_categorical\", [True, False])\n    def test_replace_interval_with_method(self, as_categorical):\n        # in particular interval that can't hold NA\n\n        idx = pd.IntervalIndex.from_breaks(range(4))\n        ser = pd.Series(idx)\n        if as_categorical:\n            ser = ser.astype(\"category\")\n\n        self._check_replace_with_method(ser)\n\n    @pytest.mark.parametrize(\"as_period\", [True, False])\n    @pytest.mark.parametrize(\"as_categorical\", [True, False])\n    def test_replace_datetimelike_with_method(self, as_period, as_categorical):\n        idx = pd.date_range(\"2016-01-01\", periods=5, tz=\"US/Pacific\")\n        if as_period:\n            idx = idx.tz_localize(None).to_period(\"D\")\n\n        ser = pd.Series(idx)\n        ser.iloc[-2] = pd.NaT\n        if as_categorical:\n            ser = ser.astype(\"category\")\n\n        self._check_replace_with_method(ser)\n\n    def test_replace_with_compiled_regex(self):\n        # https://github.com/pandas-dev/pandas/issues/35680\n        s = pd.Series([\"a\", \"b\", \"c\"])\n        regex = re.compile(\"^a$\")\n        result = s.replace({regex: \"z\"}, regex=True)\n        expected = pd.Series([\"z\", \"b\", \"c\"])\n        tm.assert_series_equal(result, expected)\n\n    def test_pandas_replace_na(self):\n        # GH#43344\n        ser = pd.Series([\"AA\", \"BB\", \"CC\", \"DD\", \"EE\", \"\", pd.NA], dtype=\"string\")\n        regex_mapping = {\n            \"AA\": \"CC\",\n            \"BB\": \"CC\",\n            \"EE\": \"CC\",\n            \"CC\": \"CC-REPL\",\n        }\n        result = ser.replace(regex_mapping, regex=True)\n        exp = pd.Series([\"CC\", \"CC\", \"CC-REPL\", \"DD\", \"CC\", \"\", pd.NA], dtype=\"string\")\n        tm.assert_series_equal(result, exp)\n\n    @pytest.mark.parametrize(\n        \"dtype, input_data, to_replace, expected_data\",\n        [\n            (\"bool\", [True, False], {True: False}, [False, False]),\n            (\"int64\", [1, 2], {1: 10, 2: 20}, [10, 20]),\n            (\"Int64\", [1, 2], {1: 10, 2: 20}, [10, 20]),\n            (\"float64\", [1.1, 2.2], {1.1: 10.1, 2.2: 20.5}, [10.1, 20.5]),\n            (\"Float64\", [1.1, 2.2], {1.1: 10.1, 2.2: 20.5}, [10.1, 20.5]),\n            (\"string\", [\"one\", \"two\"], {\"one\": \"1\", \"two\": \"2\"}, [\"1\", \"2\"]),\n            (\n                pd.IntervalDtype(\"int64\"),\n                IntervalArray([pd.Interval(1, 2), pd.Interval(2, 3)]),\n                {pd.Interval(1, 2): pd.Interval(10, 20)},\n                IntervalArray([pd.Interval(10, 20), pd.Interval(2, 3)]),\n            ),\n            (\n                pd.IntervalDtype(\"float64\"),\n                IntervalArray([pd.Interval(1.0, 2.7), pd.Interval(2.8, 3.1)]),\n                {pd.Interval(1.0, 2.7): pd.Interval(10.6, 20.8)},\n                IntervalArray([pd.Interval(10.6, 20.8), pd.Interval(2.8, 3.1)]),\n            ),\n            (\n                pd.PeriodDtype(\"M\"),\n                [pd.Period(\"2020-05\", freq=\"M\")],\n                {pd.Period(\"2020-05\", freq=\"M\"): pd.Period(\"2020-06\", freq=\"M\")},\n                [pd.Period(\"2020-06\", freq=\"M\")],\n            ),\n        ],\n    )\n    def test_replace_dtype(self, dtype, input_data, to_replace, expected_data):\n        # GH#33484\n        ser = pd.Series(input_data, dtype=dtype)\n        result = ser.replace(to_replace)\n        expected = pd.Series(expected_data, dtype=dtype)\n        tm.assert_series_equal(result, expected)\n\n    def test_replace_string_dtype(self):\n        # GH#40732, GH#44940\n        ser = pd.Series([\"one\", \"two\", np.nan], dtype=\"string\")\n        res = ser.replace({\"one\": \"1\", \"two\": \"2\"})\n        expected = pd.Series([\"1\", \"2\", np.nan], dtype=\"string\")\n        tm.assert_series_equal(res, expected)\n\n        # GH#31644\n        ser2 = pd.Series([\"A\", np.nan], dtype=\"string\")\n        res2 = ser2.replace(\"A\", \"B\")\n        expected2 = pd.Series([\"B\", np.nan], dtype=\"string\")\n        tm.assert_series_equal(res2, expected2)\n\n        ser3 = pd.Series([\"A\", \"B\"], dtype=\"string\")\n        res3 = ser3.replace(\"A\", pd.NA)\n        expected3 = pd.Series([pd.NA, \"B\"], dtype=\"string\")\n        tm.assert_series_equal(res3, expected3)\n\n    def test_replace_string_dtype_list_to_replace(self):\n        # GH#41215, GH#44940\n        ser = pd.Series([\"abc\", \"def\"], dtype=\"string\")\n        res = ser.replace([\"abc\", \"any other string\"], \"xyz\")\n        expected = pd.Series([\"xyz\", \"def\"], dtype=\"string\")\n        tm.assert_series_equal(res, expected)\n\n    def test_replace_string_dtype_regex(self):\n        # GH#31644\n        ser = pd.Series([\"A\", \"B\"], dtype=\"string\")\n        res = ser.replace(r\".\", \"C\", regex=True)\n        expected = pd.Series([\"C\", \"C\"], dtype=\"string\")\n        tm.assert_series_equal(res, expected)\n\n    def test_replace_nullable_numeric(self):\n        # GH#40732, GH#44940\n\n        floats = pd.Series([1.0, 2.0, 3.999, 4.4], dtype=pd.Float64Dtype())\n        assert floats.replace({1.0: 9}).dtype == floats.dtype\n        assert floats.replace(1.0, 9).dtype == floats.dtype\n        assert floats.replace({1.0: 9.0}).dtype == floats.dtype\n        assert floats.replace(1.0, 9.0).dtype == floats.dtype\n\n        res = floats.replace(to_replace=[1.0, 2.0], value=[9.0, 10.0])\n        assert res.dtype == floats.dtype\n\n        ints = pd.Series([1, 2, 3, 4], dtype=pd.Int64Dtype())\n        assert ints.replace({1: 9}).dtype == ints.dtype\n        assert ints.replace(1, 9).dtype == ints.dtype\n        assert ints.replace({1: 9.0}).dtype == ints.dtype\n        assert ints.replace(1, 9.0).dtype == ints.dtype\n        # FIXME: ints.replace({1: 9.5}) raises bc of incorrect _can_hold_element\n"
    }
  ],
  "questions": [
    "you mean something like this `pd.Series(['A','B']).astype('string').replace('A', pd.NA)`?\r\nworks to me at least on master:\r\n```python\r\n>>> pd.Series(['A','B']).astype('string').replace('A', pd.NA)\r\n0    <NA>\r\n1       B\r\ndtype: string\r\n```",
    "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\n>>>pd.Series(['A','B']).replace(r'.','C',regex=True)\r\n0    C\r\n1    C\r\ndtype: object\r\npd.Series(['A','B']).astype('string').replace(r'.','C',regex=True)\r\n0    A\r\n1    B\r\ndtype: string\r\n```\r\n#### Problem description\r\n\r\nIt seems that replace doesn't work with the string type Series.\r\nWhy these two codes return different results?"
  ],
  "golden_answers": [
    "Oh? I get an error.\r\n```python\r\n>>>pd.Series(['A','B']).astype('string').replace('A', pd.NA)\r\nIndexError: arrays used as indices must be of integer (or boolean) type\r\n```",
    "```python\r\n>>>pd.Series(['A','B']).astype('string').replace('.','C',regex=True)\r\n0    A\r\n1    B\r\ndtype: string\r\n```\r\nThanks for answer !\r\nBut still not work.\r\nAnd also I want to ask a related question.\r\nSince the str.replace for string does not allow pd.NA for the parameter 'repl', if I want change some strings which meet a certain regex condition to pd.NA, how can I get the correct result. Thanks !"
  ],
  "questions_generated": [
    "Why does the `replace` method in Pandas behave differently for object dtype Series and string dtype Series when using regex?",
    "What might cause an `IndexError` when using `replace` with `pd.NA` in a string dtype Series, and how was this addressed in later versions?",
    "How does the function `should_use_regex` determine whether to treat `to_replace` as a regular expression?",
    "What changes were made in the Pandas master branch to resolve the issue with regex replacement in string dtype Series?",
    "Why might `pd.NA` not be a legal choice for the 'repl' parameter in the `str.replace` method, and how is this limitation handled?"
  ],
  "golden_answers_generated": [
    "The `replace` method behaves differently due to the internal handling of regex patterns and the treatment of data types. For object dtype Series, regex patterns are applied directly. However, for string dtype Series, there are additional considerations for handling missing values and type-specific behaviors, which may affect how the regex is applied.",
    "The `IndexError` occurs because `pd.NA` is not treated as a constant value like `np.nan`, leading to issues with comparison and replacement logic in earlier versions. Later versions addressed this by refining the handling of `pd.NA` in the `replace` method, ensuring compatibility with string dtype Series.",
    "The function `should_use_regex` checks if `to_replace` is a compiled regular expression or can be compiled as one. It also checks if the pattern is non-empty before deciding to treat it as a regex. This ensures that only valid and meaningful patterns are processed as regex.",
    "The master branch includes fixes that improve the handling of regex patterns in string dtype Series, possibly involving changes to how regex patterns are compiled and applied to elements, and how missing values like `pd.NA` are managed during replacement.",
    "`pd.NA` might not be a legal choice because it represents an undefined or missing value, which complicates the comparison and replacement logic. This limitation can be handled by ensuring that the `replace` method correctly interprets `pd.NA` and applies replacements where logical, as seen in improvements in later versions of Pandas."
  ]
}