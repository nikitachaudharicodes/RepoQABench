{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "27756",
  "issue_description": "# Error reading parquet from s3 with s3fs >= 0.3.0\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas as pd\r\n\r\ndf = pd.read_parquet('s3://my-bucket/df.parquet')\r\n```\r\n\r\nRaises\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/.../pandas/io/parquet.py\", line 294, in read_parquet\r\n    return impl.read(path, columns=columns, **kwargs)\r\n  File \"/.../pandas/io/parquet.py\", line 192, in read\r\n    parquet_file = self.api.ParquetFile(path, open_with=s3.s3.open)\r\nAttributeError: 'S3File' object has no attribute 's3'\r\n```\r\n\r\n#### Problem description\r\n\r\nIn version 0.3.0 s3fs removed the `S3File.s3` attribute. It is replaced by `S3File.fs` (which is inherited from `fsspec.AbstractBufferedFile.fs`.\r\n\r\nShould pandas check the s3fs version and call the right attribute based on that?\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\npython           : 3.7.3.final.0\r\npython-bits      : 64\r\nOS               : Darwin\r\nOS-release       : 18.6.0\r\nmachine          : x86_64\r\nprocessor        : i386\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : en_US.UTF-8\r\nLOCALE           : en_US.UTF-8\r\n\r\npandas           : 0.25.0\r\nnumpy            : 1.17.0\r\npytz             : 2019.1\r\ndateutil         : 2.8.0\r\npip              : 19.2.1\r\nsetuptools       : 41.0.1\r\nCython           : None\r\npytest           : 4.4.1\r\nhypothesis       : None\r\nsphinx           : 2.1.2\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : 2.8.3 (dt dec pq3 ext lo64)\r\njinja2           : 2.10.1\r\nIPython          : None\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfastparquet      : 0.3.1\r\ngcsfs            : None\r\nlxml.etree       : None\r\nmatplotlib       : None\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : None\r\npytables         : None\r\ns3fs             : 0.3.1\r\nscipy            : 1.3.0\r\nsqlalchemy       : 1.3.5\r\ntables           : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nxlsxwriter       : None\r\n\r\n</details>\r\n",
  "issue_comments": [
    {
      "id": 518261296,
      "user": "TomAugspurger",
      "body": "> Should pandas check the s3fs version and call the right attribute based on that?\r\n\r\nSure.\r\n\r\ncc @martindurant for the (possibly unintentional) API change."
    },
    {
      "id": 518261878,
      "user": "TomAugspurger",
      "body": "So the `open_with` in https://github.com/pandas-dev/pandas/blob/61362be9ea4d69b33ae421f1f98b8db50be611a2/pandas/io/parquet.py#L192 will need to depend on the version of s3fs."
    },
    {
      "id": 518263743,
      "user": "martindurant",
      "body": "Indeed this is an API change. However, I am surprised that anyone is opening a file and then using the FS methods of the attribute of that file - you presumably have the FS available directly anyway at this point. \r\n\r\nIndeed, rather than test specifically for s3 URLs, I would strongly encourage pandas to use fsspec directly, so that then you can read from any of the implementations supported by fsspec."
    },
    {
      "id": 518269737,
      "user": "CJStadler",
      "body": "Perhaps there should be a function returning both the file and the filesystem, which can be used here instead of `get_filepath_or_buffer`. That would avoid `S3File.s3`/`S3File.fs`.\r\n\r\nIf that sounds like a reasonable direction I will work on a PR."
    },
    {
      "id": 518286773,
      "user": "TomAugspurger",
      "body": "I'm not sure what's best.\n\nOn Mon, Aug 5, 2019 at 9:58 AM Chris Stadler <notifications@github.com>\nwrote:\n\n> Perhaps there should be a function returning both the file and the\n> filesystem, which can be used here instead of get_filepath_or_buffer.\n> That would avoid S3File.s3/S3File.fs.\n>\n> If that sounds like a reasonable direction I will work on a PR.\n>\n> â€”\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/issues/27756?email_source=notifications&email_token=AAKAOIX27VNYLVWZZADDDFTQDA5Z3A5CNFSM4IJLDNJ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3SCWKI#issuecomment-518269737>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAKAOIX6R6HBTG6K5TWDRYLQDA5Z3ANCNFSM4IJLDNJQ>\n> .\n>\n"
    },
    {
      "id": 518388889,
      "user": "avicennax",
      "body": "Ran into this issue today; just made a local, hacky in-vivo fix to the API break. Happy to help in any way to fix the issue properly.\r\n\r\nCheers."
    },
    {
      "id": 518391240,
      "user": "martindurant",
      "body": "For the sake of compatibility, I can make S3File.s3 -> S3File.fs alias, if that makes life easier."
    },
    {
      "id": 518712603,
      "user": "WillAyd",
      "body": "> I would strongly encourage pandas to use fsspec directly\r\n\r\nIs this compatible with the PEP 519 fspath protocol? We are dropping 3.6 soon so maybe worth looking towards that instead"
    },
    {
      "id": 518715679,
      "user": "martindurant",
      "body": "I have considered adding `__fspath__` to file types (at least ones derived from `fsspec.spec.AbstractBufferedFile`), but my reading of the PEP is that it should return *local* paths. `os.fspath` does indeed work on files returned by the `LocalFileSystem`, however."
    },
    {
      "id": 518717889,
      "user": "martindurant",
      "body": "For the interested, the implementation is as simple as\r\n```diff\r\n--- a/fsspec/spec.py\r\n+++ b/fsspec/spec.py\r\n@@ -1154,6 +1154,9 @@ class AbstractBufferedFile(io.IOBase):\r\n     def __str__(self):\r\n         return \"<File-like object %s, %s>\" % (type(self.fs).__name__, self.path)\r\n\r\n+    def __fspath__(self):\r\n+        return self.fs.protocol + \"://\" + self.path\r\n+\r\n```"
    },
    {
      "id": 519488226,
      "user": "jorisvandenbossche",
      "body": "> For the sake of compatibility, I can make S3File.s3 -> S3File.fs alias, if that makes life easier.\r\n\r\n@martindurant For compatibility with released pandas versions, that might be nice? (or at least for a while?)"
    },
    {
      "id": 519537715,
      "user": "martindurant",
      "body": "Done and released \r\n\r\nhttps://github.com/conda-forge/s3fs-feedstock/pull/25\r\nhttps://github.com/dask/s3fs/commit/990ceebb5ba73030819ddd09d5696506f0f865d7"
    },
    {
      "id": 519551603,
      "user": "jorisvandenbossche",
      "body": "Thanks a lot!"
    }
  ],
  "text_context": "# Error reading parquet from s3 with s3fs >= 0.3.0\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas as pd\r\n\r\ndf = pd.read_parquet('s3://my-bucket/df.parquet')\r\n```\r\n\r\nRaises\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/.../pandas/io/parquet.py\", line 294, in read_parquet\r\n    return impl.read(path, columns=columns, **kwargs)\r\n  File \"/.../pandas/io/parquet.py\", line 192, in read\r\n    parquet_file = self.api.ParquetFile(path, open_with=s3.s3.open)\r\nAttributeError: 'S3File' object has no attribute 's3'\r\n```\r\n\r\n#### Problem description\r\n\r\nIn version 0.3.0 s3fs removed the `S3File.s3` attribute. It is replaced by `S3File.fs` (which is inherited from `fsspec.AbstractBufferedFile.fs`.\r\n\r\nShould pandas check the s3fs version and call the right attribute based on that?\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\npython           : 3.7.3.final.0\r\npython-bits      : 64\r\nOS               : Darwin\r\nOS-release       : 18.6.0\r\nmachine          : x86_64\r\nprocessor        : i386\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : en_US.UTF-8\r\nLOCALE           : en_US.UTF-8\r\n\r\npandas           : 0.25.0\r\nnumpy            : 1.17.0\r\npytz             : 2019.1\r\ndateutil         : 2.8.0\r\npip              : 19.2.1\r\nsetuptools       : 41.0.1\r\nCython           : None\r\npytest           : 4.4.1\r\nhypothesis       : None\r\nsphinx           : 2.1.2\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : 2.8.3 (dt dec pq3 ext lo64)\r\njinja2           : 2.10.1\r\nIPython          : None\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfastparquet      : 0.3.1\r\ngcsfs            : None\r\nlxml.etree       : None\r\nmatplotlib       : None\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : None\r\npytables         : None\r\ns3fs             : 0.3.1\r\nscipy            : 1.3.0\r\nsqlalchemy       : 1.3.5\r\ntables           : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nxlsxwriter       : None\r\n\r\n</details>\r\n\n\n> Should pandas check the s3fs version and call the right attribute based on that?\r\n\r\nSure.\r\n\r\ncc @martindurant for the (possibly unintentional) API change.\n\nSo the `open_with` in https://github.com/pandas-dev/pandas/blob/61362be9ea4d69b33ae421f1f98b8db50be611a2/pandas/io/parquet.py#L192 will need to depend on the version of s3fs.\n\nIndeed this is an API change. However, I am surprised that anyone is opening a file and then using the FS methods of the attribute of that file - you presumably have the FS available directly anyway at this point. \r\n\r\nIndeed, rather than test specifically for s3 URLs, I would strongly encourage pandas to use fsspec directly, so that then you can read from any of the implementations supported by fsspec.\n\nPerhaps there should be a function returning both the file and the filesystem, which can be used here instead of `get_filepath_or_buffer`. That would avoid `S3File.s3`/`S3File.fs`.\r\n\r\nIf that sounds like a reasonable direction I will work on a PR.\n\nI'm not sure what's best.\n\nOn Mon, Aug 5, 2019 at 9:58 AM Chris Stadler <notifications@github.com>\nwrote:\n\n> Perhaps there should be a function returning both the file and the\n> filesystem, which can be used here instead of get_filepath_or_buffer.\n> That would avoid S3File.s3/S3File.fs.\n>\n> If that sounds like a reasonable direction I will work on a PR.\n>\n> â€”\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/issues/27756?email_source=notifications&email_token=AAKAOIX27VNYLVWZZADDDFTQDA5Z3A5CNFSM4IJLDNJ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3SCWKI#issuecomment-518269737>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAKAOIX6R6HBTG6K5TWDRYLQDA5Z3ANCNFSM4IJLDNJQ>\n> .\n>\n\n\nRan into this issue today; just made a local, hacky in-vivo fix to the API break. Happy to help in any way to fix the issue properly.\r\n\r\nCheers.\n\nFor the sake of compatibility, I can make S3File.s3 -> S3File.fs alias, if that makes life easier.\n\n> I would strongly encourage pandas to use fsspec directly\r\n\r\nIs this compatible with the PEP 519 fspath protocol? We are dropping 3.6 soon so maybe worth looking towards that instead\n\nI have considered adding `__fspath__` to file types (at least ones derived from `fsspec.spec.AbstractBufferedFile`), but my reading of the PEP is that it should return *local* paths. `os.fspath` does indeed work on files returned by the `LocalFileSystem`, however.\n\nFor the interested, the implementation is as simple as\r\n```diff\r\n--- a/fsspec/spec.py\r\n+++ b/fsspec/spec.py\r\n@@ -1154,6 +1154,9 @@ class AbstractBufferedFile(io.IOBase):\r\n     def __str__(self):\r\n         return \"<File-like object %s, %s>\" % (type(self.fs).__name__, self.path)\r\n\r\n+    def __fspath__(self):\r\n+        return self.fs.protocol + \"://\" + self.path\r\n+\r\n```\n\n> For the sake of compatibility, I can make S3File.s3 -> S3File.fs alias, if that makes life easier.\r\n\r\n@martindurant For compatibility with released pandas versions, that might be nice? (or at least for a while?)\n\nDone and released \r\n\r\nhttps://github.com/conda-forge/s3fs-feedstock/pull/25\r\nhttps://github.com/dask/s3fs/commit/990ceebb5ba73030819ddd09d5696506f0f865d7\n\nThanks a lot!",
  "pr_link": "https://github.com/conda-forge/s3fs-feedstock/pull/25",
  "code_context": []
}