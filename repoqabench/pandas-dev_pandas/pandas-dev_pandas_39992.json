{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "39992",
  "issue_description": "# STYLE Increase coverage of inconsistent-namespace-usage\n\nIf you already have experience contributing, then please leave this issue to newcomers - thanks :+1: \r\n\r\n---\r\n\r\nIn `.pre-commit-config.yaml`, the check `inconsistent-namespace-usage` is limited to `pandas/tests/frame/`. Let's expand it to the rest of `pandas/tests/`.\r\n\r\nThe task here is:\r\n\r\n0. make sure you're familiar with the [contributing guide](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html)\r\n1. choose a folder from the list below (e.g. `series`) and add it to the check in `.pre-commit-config.yaml`. E.g., if you chose `series`, that would be:\r\n\r\n  ```yaml\r\n      -   id: inconsistent-namespace-usage\r\n          name: 'Check for inconsistent use of pandas namespace in tests'\r\n          entry: python scripts/check_for_inconsistent_pandas_namespace.py\r\n          language: python\r\n          types: [python]\r\n          files: ^pandas/tests/(frame|series)/\r\n  ```\r\n\r\n2. temporarily add `tokenize-rt` as an additional dependency and `--replace` as an arg (these will be removed later):\r\n\r\n  ```yaml\r\n      -   id: inconsistent-namespace-usage\r\n          name: 'Check for inconsistent use of pandas namespace in tests'\r\n          entry: python scripts/check_for_inconsistent_pandas_namespace.py\r\n          language: python\r\n          types: [python]\r\n          files: ^pandas/tests/(frame|series)/\r\n          additional_dependencies: [tokenize-rt]\r\n          args: [--replace]\r\n  ```\r\n\r\n3. run this check on all files with pre-commit, i.e.:\r\n\r\n```console\r\n  $ pre-commit run inconsistent-namespace-usage --all-files\r\n  [INFO] Initializing environment for local:tokenize-rt.\r\n  [INFO] Installing environment for local.\r\n  [INFO] Once installed this environment will be reused.\r\n  [INFO] This may take a few minutes...\r\n  Check for inconsistent use of pandas namespace in tests.......................Failed\r\n  - hook id: inconsistent-namespace-usage\r\n  - files were modified by this hook\r\n  ```\r\n\r\n4. run it again - this time, it should pass\r\n\r\n  ```console\r\n  $ pre-commit run inconsistent-namespace-usage --all-files\r\n  Check for inconsistent use of pandas namespace in tests.......................Passed\r\n  ```\r\n  \r\n  Check that the other hooks still pass - if you enable pre-commit (`pre-commit install`), then this will happen automatically when you try to commit your changes (see step 6)\r\n\r\n5. revert the changes to `.pre-commit-config.yaml` (we'll update it once these changes are all so as to avoid a barrage of merge conflicts)\r\n6. commit your changes, and open a pull request. Check over your changes, make sure they look sensible, let me know if not\r\n\r\n---\r\n\r\nHere are the folders in `pandas/tests` which this check needs expanding to:\r\n\r\n- [x] series\r\n- [x] scalar\r\n- [x] resample\r\n- [x] util\r\n- [x] tseries\r\n- [x] dtypes\r\n- [x] arrays\r\n- [x] plotting\r\n- [x] tools\r\n- [x] indexing\r\n- [x] strings\r\n- [x] reductions\r\n- [x] frame\r\n- [x] arithmetic\r\n- [x] config\r\n- [x] api\r\n- [x] generic\r\n- [x] io\r\n- [x] base\r\n- [x] window\r\n- [x] internals\r\n- [x] reshape\r\n- [x] computation\r\n- [x] apply\r\n- [x] groupby\r\n- [x] tslibs\r\n- [x] libs\r\n- [x] indexes\r\n- [x] extension\r\n\r\nNo need to ask for permission to work on this, just leave a comment letting people know which folder(s) from the list above you're working on",
  "issue_comments": [
    {
      "id": 784337978,
      "user": "alexprincel",
      "body": "I ran the script for \"extension\" and it made no change to files in that folder. I checked my procedure against your example above to make sure this was not the result of a bad manipulation. When changing to series I get the same output as in your post."
    },
    {
      "id": 784338605,
      "user": "alexprincel",
      "body": "Currently working on indexes, will submit a PR as there were changes on that folder."
    },
    {
      "id": 785703819,
      "user": "jorisvandenbossche",
      "body": "@MarcoGorelli the automatic script only changes it from `pd.DataFrame(..)` to `DataFrame(..)` and not the other way around? (as previously, we only agreed to be consistent within a file, not necessarily to change *all* files to use the non-`pd.` way)"
    },
    {
      "id": 785766680,
      "user": "MarcoGorelli",
      "body": "@jorisvandenbossche if there's both, it'll choose the non-`pd.` one. If the file is already consistently using the `pd.` one, then it'll leave it untouched.\r\n\r\ne.g.\r\n```python\r\nimport pandas as pd\r\n\r\ndef test_0():\r\n    pd.DataFrame()\r\n\r\ndef test_1():\r\n    pd.DataFrame()\r\n```\r\n\r\nwould be left untouched (i.e. it would keep being consistent within the file), but\r\n\r\n```python\r\nimport pandas as pd\r\nfrom pandas import DataFrame\r\n\r\ndef test_0():\r\n    pd.DataFrame()\r\n\r\ndef test_1():\r\n    DataFrame()\r\n```\r\n\r\nwould become\r\n\r\n```python\r\nimport pandas as pd\r\nfrom pandas import DataFrame\r\n\r\ndef test_0():\r\n    DataFrame()\r\n\r\ndef test_1():\r\n    DataFrame()\r\n```"
    },
    {
      "id": 786151565,
      "user": "alexprincel",
      "body": "libs and tslibs passed without fixes, "
    },
    {
      "id": 786159100,
      "user": "alexprincel",
      "body": "computation passed without fixes"
    },
    {
      "id": 789159016,
      "user": "Varun270",
      "body": "can someone please tell me whether this issue is fixed or not ."
    },
    {
      "id": 789601508,
      "user": "MarcoGorelli",
      "body": "the unticked folders still need doing"
    },
    {
      "id": 790448739,
      "user": "thomasyu888",
      "body": "Going to try the `scalar`, `resample`, `arrays`\r\n"
    },
    {
      "id": 790459903,
      "user": "thomasyu888",
      "body": "`tseries` and `util` passed without fixes"
    },
    {
      "id": 790660607,
      "user": "01-vyom",
      "body": "`window`, `config`, `generic`,  and  `internals` passed without fixes\r\n\r\nWorking on `api` and `arithmetic`"
    },
    {
      "id": 791923571,
      "user": "sionedbaker",
      "body": "As part of pyladies-sprint-March-2021,  I looked at dir reductions"
    },
    {
      "id": 791924583,
      "user": "MarcoGorelli",
      "body": "Nice, thanks @sionedbaker ! It doesn't look like you've opened a pull request though, let us know if you want//need help with that"
    },
    {
      "id": 791950168,
      "user": "Varun270",
      "body": "I am new to open source contribution and I have cloned this repo in my system but I am unable to understand what are the corrections needed to be done. Can anyone help me, I am literally so confused."
    },
    {
      "id": 792227282,
      "user": "deepang17",
      "body": "working on `tools`"
    },
    {
      "id": 792259673,
      "user": "MarcoGorelli",
      "body": "There's only 9 files left now, so if anyone wants to close this issue then please change `files` to `^pandas/tests/` (though revert the changes to `args` and `additional_dependencies` before committing) - then we can close this issue"
    },
    {
      "id": 792260456,
      "user": "deepang17",
      "body": "Working to close this issue"
    },
    {
      "id": 792272231,
      "user": "deepang17",
      "body": "![image](https://user-images.githubusercontent.com/47976918/110239820-16781d00-7f6f-11eb-825d-f91387bc6dcf.png)\r\n\r\nAs you can see in the above image that by replacing `pd.unique(mindex)` to `unique(mindex)` we get F821 undefined name 'unique' error.\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/70c91a28bf05f1f8864f4b07bcf2066951c8a9e3/pandas/tests/test_algos.py#L494\r\n\r\nRest all files are resolved."
    },
    {
      "id": 792278517,
      "user": "deepang17",
      "body": "One solution is to exclude test_algos.py from checking for inconsistency in pre-commit.\r\n`exclude: ^pandas/tests/test_algos.py$`"
    },
    {
      "id": 792294708,
      "user": "MarcoGorelli",
      "body": "> There's only 9 files left now, so if anyone wants to close this issue then please change `files` to `^pandas/tests/` (though revert the changes to `args` and `additional_dependencies` before committing) - then we can close this issue\r\n\r\nMy bad, I missed that @sionedbaker hasn't submitted her PR for `reductions` yet. @sionedbaker , are you still working on this? If so, let's wait before merging #40286 "
    },
    {
      "id": 792834422,
      "user": "sionedbaker",
      "body": "Hi @MarcoGorelli , very sorry for taking so long to reply, but I had huge problems with pushing my changes to github (due to me having to setup 2FA but I've push changes to my fork now, and then created PR: https://github.com/pandas-dev/pandas/pull/40310\r\nI'm not sure if @deepang17 has already solved this, therefore no worries if my PR is surplus to requirements.   I very much enjoyed the session on Saturday,  but I probably need more practise with submitting this via github as I've found that part the trickiest"
    },
    {
      "id": 792935451,
      "user": "MarcoGorelli",
      "body": "No worries, thanks for your PR and happy IWD! I recommend the first 3 chapters of the [pro-git book](https://git-scm.com/book/en/v2), the rest is just practice"
    },
    {
      "id": 792964133,
      "user": "sionedbaker",
      "body": "Many thanks @MarcoGorelli   and thanks for approving the PR.   Thanks for the git book, looks good,   be really interested in working through some (very simple!) panda issues in the next few weeks, I will keep an eye on the github issues.  Be really interested in a further follow up session so will try to keep up to date with pyladies.  thanks for all your help"
    }
  ],
  "text_context": "# STYLE Increase coverage of inconsistent-namespace-usage\n\nIf you already have experience contributing, then please leave this issue to newcomers - thanks :+1: \r\n\r\n---\r\n\r\nIn `.pre-commit-config.yaml`, the check `inconsistent-namespace-usage` is limited to `pandas/tests/frame/`. Let's expand it to the rest of `pandas/tests/`.\r\n\r\nThe task here is:\r\n\r\n0. make sure you're familiar with the [contributing guide](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html)\r\n1. choose a folder from the list below (e.g. `series`) and add it to the check in `.pre-commit-config.yaml`. E.g., if you chose `series`, that would be:\r\n\r\n  ```yaml\r\n      -   id: inconsistent-namespace-usage\r\n          name: 'Check for inconsistent use of pandas namespace in tests'\r\n          entry: python scripts/check_for_inconsistent_pandas_namespace.py\r\n          language: python\r\n          types: [python]\r\n          files: ^pandas/tests/(frame|series)/\r\n  ```\r\n\r\n2. temporarily add `tokenize-rt` as an additional dependency and `--replace` as an arg (these will be removed later):\r\n\r\n  ```yaml\r\n      -   id: inconsistent-namespace-usage\r\n          name: 'Check for inconsistent use of pandas namespace in tests'\r\n          entry: python scripts/check_for_inconsistent_pandas_namespace.py\r\n          language: python\r\n          types: [python]\r\n          files: ^pandas/tests/(frame|series)/\r\n          additional_dependencies: [tokenize-rt]\r\n          args: [--replace]\r\n  ```\r\n\r\n3. run this check on all files with pre-commit, i.e.:\r\n\r\n```console\r\n  $ pre-commit run inconsistent-namespace-usage --all-files\r\n  [INFO] Initializing environment for local:tokenize-rt.\r\n  [INFO] Installing environment for local.\r\n  [INFO] Once installed this environment will be reused.\r\n  [INFO] This may take a few minutes...\r\n  Check for inconsistent use of pandas namespace in tests.......................Failed\r\n  - hook id: inconsistent-namespace-usage\r\n  - files were modified by this hook\r\n  ```\r\n\r\n4. run it again - this time, it should pass\r\n\r\n  ```console\r\n  $ pre-commit run inconsistent-namespace-usage --all-files\r\n  Check for inconsistent use of pandas namespace in tests.......................Passed\r\n  ```\r\n  \r\n  Check that the other hooks still pass - if you enable pre-commit (`pre-commit install`), then this will happen automatically when you try to commit your changes (see step 6)\r\n\r\n5. revert the changes to `.pre-commit-config.yaml` (we'll update it once these changes are all so as to avoid a barrage of merge conflicts)\r\n6. commit your changes, and open a pull request. Check over your changes, make sure they look sensible, let me know if not\r\n\r\n---\r\n\r\nHere are the folders in `pandas/tests` which this check needs expanding to:\r\n\r\n- [x] series\r\n- [x] scalar\r\n- [x] resample\r\n- [x] util\r\n- [x] tseries\r\n- [x] dtypes\r\n- [x] arrays\r\n- [x] plotting\r\n- [x] tools\r\n- [x] indexing\r\n- [x] strings\r\n- [x] reductions\r\n- [x] frame\r\n- [x] arithmetic\r\n- [x] config\r\n- [x] api\r\n- [x] generic\r\n- [x] io\r\n- [x] base\r\n- [x] window\r\n- [x] internals\r\n- [x] reshape\r\n- [x] computation\r\n- [x] apply\r\n- [x] groupby\r\n- [x] tslibs\r\n- [x] libs\r\n- [x] indexes\r\n- [x] extension\r\n\r\nNo need to ask for permission to work on this, just leave a comment letting people know which folder(s) from the list above you're working on\n\nI ran the script for \"extension\" and it made no change to files in that folder. I checked my procedure against your example above to make sure this was not the result of a bad manipulation. When changing to series I get the same output as in your post.\n\nCurrently working on indexes, will submit a PR as there were changes on that folder.\n\n@MarcoGorelli the automatic script only changes it from `pd.DataFrame(..)` to `DataFrame(..)` and not the other way around? (as previously, we only agreed to be consistent within a file, not necessarily to change *all* files to use the non-`pd.` way)\n\n@jorisvandenbossche if there's both, it'll choose the non-`pd.` one. If the file is already consistently using the `pd.` one, then it'll leave it untouched.\r\n\r\ne.g.\r\n```python\r\nimport pandas as pd\r\n\r\ndef test_0():\r\n    pd.DataFrame()\r\n\r\ndef test_1():\r\n    pd.DataFrame()\r\n```\r\n\r\nwould be left untouched (i.e. it would keep being consistent within the file), but\r\n\r\n```python\r\nimport pandas as pd\r\nfrom pandas import DataFrame\r\n\r\ndef test_0():\r\n    pd.DataFrame()\r\n\r\ndef test_1():\r\n    DataFrame()\r\n```\r\n\r\nwould become\r\n\r\n```python\r\nimport pandas as pd\r\nfrom pandas import DataFrame\r\n\r\ndef test_0():\r\n    DataFrame()\r\n\r\ndef test_1():\r\n    DataFrame()\r\n```\n\nlibs and tslibs passed without fixes, \n\ncomputation passed without fixes\n\ncan someone please tell me whether this issue is fixed or not .\n\nthe unticked folders still need doing\n\nGoing to try the `scalar`, `resample`, `arrays`\r\n\n\n`tseries` and `util` passed without fixes\n\n`window`, `config`, `generic`,  and  `internals` passed without fixes\r\n\r\nWorking on `api` and `arithmetic`\n\nAs part of pyladies-sprint-March-2021,  I looked at dir reductions\n\nNice, thanks @sionedbaker ! It doesn't look like you've opened a pull request though, let us know if you want//need help with that\n\nI am new to open source contribution and I have cloned this repo in my system but I am unable to understand what are the corrections needed to be done. Can anyone help me, I am literally so confused.\n\nworking on `tools`\n\nThere's only 9 files left now, so if anyone wants to close this issue then please change `files` to `^pandas/tests/` (though revert the changes to `args` and `additional_dependencies` before committing) - then we can close this issue\n\nWorking to close this issue\n\n![image](https://user-images.githubusercontent.com/47976918/110239820-16781d00-7f6f-11eb-825d-f91387bc6dcf.png)\r\n\r\nAs you can see in the above image that by replacing `pd.unique(mindex)` to `unique(mindex)` we get F821 undefined name 'unique' error.\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/70c91a28bf05f1f8864f4b07bcf2066951c8a9e3/pandas/tests/test_algos.py#L494\r\n\r\nRest all files are resolved.\n\nOne solution is to exclude test_algos.py from checking for inconsistency in pre-commit.\r\n`exclude: ^pandas/tests/test_algos.py$`\n\n> There's only 9 files left now, so if anyone wants to close this issue then please change `files` to `^pandas/tests/` (though revert the changes to `args` and `additional_dependencies` before committing) - then we can close this issue\r\n\r\nMy bad, I missed that @sionedbaker hasn't submitted her PR for `reductions` yet. @sionedbaker , are you still working on this? If so, let's wait before merging #40286 \n\nHi @MarcoGorelli , very sorry for taking so long to reply, but I had huge problems with pushing my changes to github (due to me having to setup 2FA but I've push changes to my fork now, and then created PR: https://github.com/pandas-dev/pandas/pull/40310\r\nI'm not sure if @deepang17 has already solved this, therefore no worries if my PR is surplus to requirements.   I very much enjoyed the session on Saturday,  but I probably need more practise with submitting this via github as I've found that part the trickiest\n\nNo worries, thanks for your PR and happy IWD! I recommend the first 3 chapters of the [pro-git book](https://git-scm.com/book/en/v2), the rest is just practice\n\nMany thanks @MarcoGorelli   and thanks for approving the PR.   Thanks for the git book, looks good,   be really interested in working through some (very simple!) panda issues in the next few weeks, I will keep an eye on the github issues.  Be really interested in a further follow up session so will try to keep up to date with pyladies.  thanks for all your help",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/40310",
  "code_context": [
    {
      "filename": "pandas/tests/reductions/test_reductions.py",
      "content": "from datetime import (\n    datetime,\n    timedelta,\n)\n\nimport numpy as np\nimport pytest\n\nimport pandas as pd\nfrom pandas import (\n    Categorical,\n    DataFrame,\n    DatetimeIndex,\n    Index,\n    NaT,\n    Period,\n    PeriodIndex,\n    RangeIndex,\n    Series,\n    Timedelta,\n    TimedeltaIndex,\n    Timestamp,\n    date_range,\n    isna,\n    timedelta_range,\n    to_timedelta,\n)\nimport pandas._testing as tm\nfrom pandas.core import nanops\n\n\ndef get_objs():\n    indexes = [\n        tm.makeBoolIndex(10, name=\"a\"),\n        tm.makeIntIndex(10, name=\"a\"),\n        tm.makeFloatIndex(10, name=\"a\"),\n        tm.makeDateIndex(10, name=\"a\"),\n        tm.makeDateIndex(10, name=\"a\").tz_localize(tz=\"US/Eastern\"),\n        tm.makePeriodIndex(10, name=\"a\"),\n        tm.makeStringIndex(10, name=\"a\"),\n        tm.makeUnicodeIndex(10, name=\"a\"),\n    ]\n\n    arr = np.random.randn(10)\n    series = [Series(arr, index=idx, name=\"a\") for idx in indexes]\n\n    objs = indexes + series\n    return objs\n\n\nobjs = get_objs()\n\n\nclass TestReductions:\n    @pytest.mark.parametrize(\"opname\", [\"max\", \"min\"])\n    @pytest.mark.parametrize(\"obj\", objs)\n    def test_ops(self, opname, obj):\n        result = getattr(obj, opname)()\n        if not isinstance(obj, PeriodIndex):\n            expected = getattr(obj.values, opname)()\n        else:\n            expected = Period(ordinal=getattr(obj.asi8, opname)(), freq=obj.freq)\n\n        if getattr(obj, \"tz\", None) is not None:\n            # We need to de-localize before comparing to the numpy-produced result\n            expected = expected.astype(\"M8[ns]\").astype(\"int64\")\n            assert result.value == expected\n        else:\n            assert result == expected\n\n    @pytest.mark.parametrize(\"opname\", [\"max\", \"min\"])\n    @pytest.mark.parametrize(\n        \"dtype, val\",\n        [\n            (\"object\", 2.0),\n            (\"float64\", 2.0),\n            (\"datetime64[ns]\", datetime(2011, 11, 1)),\n            (\"Int64\", 2),\n            (\"boolean\", True),\n        ],\n    )\n    def test_nanminmax(self, opname, dtype, val, index_or_series):\n        # GH#7261\n        klass = index_or_series\n\n        if dtype in [\"Int64\", \"boolean\"] and klass == Index:\n            pytest.skip(\"EAs can't yet be stored in an index\")\n\n        def check_missing(res):\n            if dtype == \"datetime64[ns]\":\n                return res is NaT\n            elif dtype == \"Int64\":\n                return res is pd.NA\n            else:\n                return isna(res)\n\n        obj = klass([None], dtype=dtype)\n        assert check_missing(getattr(obj, opname)())\n        assert check_missing(getattr(obj, opname)(skipna=False))\n\n        obj = klass([], dtype=dtype)\n        assert check_missing(getattr(obj, opname)())\n        assert check_missing(getattr(obj, opname)(skipna=False))\n\n        if dtype == \"object\":\n            # generic test with object only works for empty / all NaN\n            return\n\n        obj = klass([None, val], dtype=dtype)\n        assert getattr(obj, opname)() == val\n        assert check_missing(getattr(obj, opname)(skipna=False))\n\n        obj = klass([None, val, None], dtype=dtype)\n        assert getattr(obj, opname)() == val\n        assert check_missing(getattr(obj, opname)(skipna=False))\n\n    @pytest.mark.parametrize(\"opname\", [\"max\", \"min\"])\n    def test_nanargminmax(self, opname, index_or_series):\n        # GH#7261\n        klass = index_or_series\n        arg_op = \"arg\" + opname if klass is Index else \"idx\" + opname\n\n        obj = klass([NaT, datetime(2011, 11, 1)])\n        assert getattr(obj, arg_op)() == 1\n        result = getattr(obj, arg_op)(skipna=False)\n        if klass is Series:\n            assert np.isnan(result)\n        else:\n            assert result == -1\n\n        obj = klass([NaT, datetime(2011, 11, 1), NaT])\n        # check DatetimeIndex non-monotonic path\n        assert getattr(obj, arg_op)() == 1\n        result = getattr(obj, arg_op)(skipna=False)\n        if klass is Series:\n            assert np.isnan(result)\n        else:\n            assert result == -1\n\n    @pytest.mark.parametrize(\"opname\", [\"max\", \"min\"])\n    @pytest.mark.parametrize(\"dtype\", [\"M8[ns]\", \"datetime64[ns, UTC]\"])\n    def test_nanops_empty_object(self, opname, index_or_series, dtype):\n        klass = index_or_series\n        arg_op = \"arg\" + opname if klass is Index else \"idx\" + opname\n\n        obj = klass([], dtype=dtype)\n\n        assert getattr(obj, opname)() is NaT\n        assert getattr(obj, opname)(skipna=False) is NaT\n\n        with pytest.raises(ValueError, match=\"empty sequence\"):\n            getattr(obj, arg_op)()\n        with pytest.raises(ValueError, match=\"empty sequence\"):\n            getattr(obj, arg_op)(skipna=False)\n\n    def test_argminmax(self):\n        obj = Index(np.arange(5, dtype=\"int64\"))\n        assert obj.argmin() == 0\n        assert obj.argmax() == 4\n\n        obj = Index([np.nan, 1, np.nan, 2])\n        assert obj.argmin() == 1\n        assert obj.argmax() == 3\n        assert obj.argmin(skipna=False) == -1\n        assert obj.argmax(skipna=False) == -1\n\n        obj = Index([np.nan])\n        assert obj.argmin() == -1\n        assert obj.argmax() == -1\n        assert obj.argmin(skipna=False) == -1\n        assert obj.argmax(skipna=False) == -1\n\n        obj = Index([NaT, datetime(2011, 11, 1), datetime(2011, 11, 2), NaT])\n        assert obj.argmin() == 1\n        assert obj.argmax() == 2\n        assert obj.argmin(skipna=False) == -1\n        assert obj.argmax(skipna=False) == -1\n\n        obj = Index([NaT])\n        assert obj.argmin() == -1\n        assert obj.argmax() == -1\n        assert obj.argmin(skipna=False) == -1\n        assert obj.argmax(skipna=False) == -1\n\n    @pytest.mark.parametrize(\"op, expected_col\", [[\"max\", \"a\"], [\"min\", \"b\"]])\n    def test_same_tz_min_max_axis_1(self, op, expected_col):\n        # GH 10390\n        df = DataFrame(\n            date_range(\"2016-01-01 00:00:00\", periods=3, tz=\"UTC\"), columns=[\"a\"]\n        )\n        df[\"b\"] = df.a.subtract(Timedelta(seconds=3600))\n        result = getattr(df, op)(axis=1)\n        expected = df[expected_col].rename(None)\n        tm.assert_series_equal(result, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"maximum\", \"minimum\"])\n    def test_numpy_reduction_with_tz_aware_dtype(self, tz_aware_fixture, func):\n        # GH 15552\n        tz = tz_aware_fixture\n        arg = pd.to_datetime([\"2019\"]).tz_localize(tz)\n        expected = Series(arg)\n        result = getattr(np, func)(expected, expected)\n        tm.assert_series_equal(result, expected)\n\n\nclass TestIndexReductions:\n    # Note: the name TestIndexReductions indicates these tests\n    #  were moved from a Index-specific test file, _not_ that these tests are\n    #  intended long-term to be Index-specific\n\n    @pytest.mark.parametrize(\n        \"start,stop,step\",\n        [\n            (0, 400, 3),\n            (500, 0, -6),\n            (-(10 ** 6), 10 ** 6, 4),\n            (10 ** 6, -(10 ** 6), -4),\n            (0, 10, 20),\n        ],\n    )\n    def test_max_min_range(self, start, stop, step):\n        # GH#17607\n        idx = RangeIndex(start, stop, step)\n        expected = idx._int64index.max()\n        result = idx.max()\n        assert result == expected\n\n        # skipna should be irrelevant since RangeIndex should never have NAs\n        result2 = idx.max(skipna=False)\n        assert result2 == expected\n\n        expected = idx._int64index.min()\n        result = idx.min()\n        assert result == expected\n\n        # skipna should be irrelevant since RangeIndex should never have NAs\n        result2 = idx.min(skipna=False)\n        assert result2 == expected\n\n        # empty\n        idx = RangeIndex(start, stop, -step)\n        assert isna(idx.max())\n        assert isna(idx.min())\n\n    def test_minmax_timedelta64(self):\n\n        # monotonic\n        idx1 = TimedeltaIndex([\"1 days\", \"2 days\", \"3 days\"])\n        assert idx1.is_monotonic\n\n        # non-monotonic\n        idx2 = TimedeltaIndex([\"1 days\", np.nan, \"3 days\", \"NaT\"])\n        assert not idx2.is_monotonic\n\n        for idx in [idx1, idx2]:\n            assert idx.min() == Timedelta(\"1 days\")\n            assert idx.max() == Timedelta(\"3 days\")\n            assert idx.argmin() == 0\n            assert idx.argmax() == 2\n\n    @pytest.mark.parametrize(\"op\", [\"min\", \"max\"])\n    def test_minmax_timedelta_empty_or_na(self, op):\n        # Return NaT\n        obj = TimedeltaIndex([])\n        assert getattr(obj, op)() is NaT\n\n        obj = TimedeltaIndex([NaT])\n        assert getattr(obj, op)() is NaT\n\n        obj = TimedeltaIndex([NaT, NaT, NaT])\n        assert getattr(obj, op)() is NaT\n\n    def test_numpy_minmax_timedelta64(self):\n        td = timedelta_range(\"16815 days\", \"16820 days\", freq=\"D\")\n\n        assert np.min(td) == Timedelta(\"16815 days\")\n        assert np.max(td) == Timedelta(\"16820 days\")\n\n        errmsg = \"the 'out' parameter is not supported\"\n        with pytest.raises(ValueError, match=errmsg):\n            np.min(td, out=0)\n        with pytest.raises(ValueError, match=errmsg):\n            np.max(td, out=0)\n\n        assert np.argmin(td) == 0\n        assert np.argmax(td) == 5\n\n        errmsg = \"the 'out' parameter is not supported\"\n        with pytest.raises(ValueError, match=errmsg):\n            np.argmin(td, out=0)\n        with pytest.raises(ValueError, match=errmsg):\n            np.argmax(td, out=0)\n\n    def test_timedelta_ops(self):\n        # GH#4984\n        # make sure ops return Timedelta\n        s = Series(\n            [Timestamp(\"20130101\") + timedelta(seconds=i * i) for i in range(10)]\n        )\n        td = s.diff()\n\n        result = td.mean()\n        expected = to_timedelta(timedelta(seconds=9))\n        assert result == expected\n\n        result = td.to_frame().mean()\n        assert result[0] == expected\n\n        result = td.quantile(0.1)\n        expected = Timedelta(np.timedelta64(2600, \"ms\"))\n        assert result == expected\n\n        result = td.median()\n        expected = to_timedelta(\"00:00:09\")\n        assert result == expected\n\n        result = td.to_frame().median()\n        assert result[0] == expected\n\n        # GH#6462\n        # consistency in returned values for sum\n        result = td.sum()\n        expected = to_timedelta(\"00:01:21\")\n        assert result == expected\n\n        result = td.to_frame().sum()\n        assert result[0] == expected\n\n        # std\n        result = td.std()\n        expected = to_timedelta(Series(td.dropna().values).std())\n        assert result == expected\n\n        result = td.to_frame().std()\n        assert result[0] == expected\n\n        # GH#10040\n        # make sure NaT is properly handled by median()\n        s = Series([Timestamp(\"2015-02-03\"), Timestamp(\"2015-02-07\")])\n        assert s.diff().median() == timedelta(days=4)\n\n        s = Series(\n            [Timestamp(\"2015-02-03\"), Timestamp(\"2015-02-07\"), Timestamp(\"2015-02-15\")]\n        )\n        assert s.diff().median() == timedelta(days=6)\n\n    @pytest.mark.parametrize(\"opname\", [\"skew\", \"kurt\", \"sem\", \"prod\", \"var\"])\n    def test_invalid_td64_reductions(self, opname):\n        s = Series(\n            [Timestamp(\"20130101\") + timedelta(seconds=i * i) for i in range(10)]\n        )\n        td = s.diff()\n\n        msg = \"|\".join(\n            [\n                f\"reduction operation '{opname}' not allowed for this dtype\",\n                rf\"cannot perform {opname} with type timedelta64\\[ns\\]\",\n                f\"'TimedeltaArray' does not implement reduction '{opname}'\",\n            ]\n        )\n\n        with pytest.raises(TypeError, match=msg):\n            getattr(td, opname)()\n\n        with pytest.raises(TypeError, match=msg):\n            getattr(td.to_frame(), opname)(numeric_only=False)\n\n    def test_minmax_tz(self, tz_naive_fixture):\n        tz = tz_naive_fixture\n        # monotonic\n        idx1 = DatetimeIndex([\"2011-01-01\", \"2011-01-02\", \"2011-01-03\"], tz=tz)\n        assert idx1.is_monotonic\n\n        # non-monotonic\n        idx2 = DatetimeIndex(\n            [\"2011-01-01\", NaT, \"2011-01-03\", \"2011-01-02\", NaT], tz=tz\n        )\n        assert not idx2.is_monotonic\n\n        for idx in [idx1, idx2]:\n            assert idx.min() == Timestamp(\"2011-01-01\", tz=tz)\n            assert idx.max() == Timestamp(\"2011-01-03\", tz=tz)\n            assert idx.argmin() == 0\n            assert idx.argmax() == 2\n\n    @pytest.mark.parametrize(\"op\", [\"min\", \"max\"])\n    def test_minmax_nat_datetime64(self, op):\n        # Return NaT\n        obj = DatetimeIndex([])\n        assert isna(getattr(obj, op)())\n\n        obj = DatetimeIndex([NaT])\n        assert isna(getattr(obj, op)())\n\n        obj = DatetimeIndex([NaT, NaT, NaT])\n        assert isna(getattr(obj, op)())\n\n    def test_numpy_minmax_integer(self):\n        # GH#26125\n        idx = Index([1, 2, 3])\n\n        expected = idx.values.max()\n        result = np.max(idx)\n        assert result == expected\n\n        expected = idx.values.min()\n        result = np.min(idx)\n        assert result == expected\n\n        errmsg = \"the 'out' parameter is not supported\"\n        with pytest.raises(ValueError, match=errmsg):\n            np.min(idx, out=0)\n        with pytest.raises(ValueError, match=errmsg):\n            np.max(idx, out=0)\n\n        expected = idx.values.argmax()\n        result = np.argmax(idx)\n        assert result == expected\n\n        expected = idx.values.argmin()\n        result = np.argmin(idx)\n        assert result == expected\n\n        errmsg = \"the 'out' parameter is not supported\"\n        with pytest.raises(ValueError, match=errmsg):\n            np.argmin(idx, out=0)\n        with pytest.raises(ValueError, match=errmsg):\n            np.argmax(idx, out=0)\n\n    def test_numpy_minmax_range(self):\n        # GH#26125\n        idx = RangeIndex(0, 10, 3)\n\n        expected = idx._int64index.max()\n        result = np.max(idx)\n        assert result == expected\n\n        expected = idx._int64index.min()\n        result = np.min(idx)\n        assert result == expected\n\n        errmsg = \"the 'out' parameter is not supported\"\n        with pytest.raises(ValueError, match=errmsg):\n            np.min(idx, out=0)\n        with pytest.raises(ValueError, match=errmsg):\n            np.max(idx, out=0)\n\n        # No need to test again argmax/argmin compat since the implementation\n        # is the same as basic integer index\n\n    def test_numpy_minmax_datetime64(self):\n        dr = date_range(start=\"2016-01-15\", end=\"2016-01-20\")\n\n        assert np.min(dr) == Timestamp(\"2016-01-15 00:00:00\", freq=\"D\")\n        assert np.max(dr) == Timestamp(\"2016-01-20 00:00:00\", freq=\"D\")\n\n        errmsg = \"the 'out' parameter is not supported\"\n        with pytest.raises(ValueError, match=errmsg):\n            np.min(dr, out=0)\n\n        with pytest.raises(ValueError, match=errmsg):\n            np.max(dr, out=0)\n\n        assert np.argmin(dr) == 0\n        assert np.argmax(dr) == 5\n\n        errmsg = \"the 'out' parameter is not supported\"\n        with pytest.raises(ValueError, match=errmsg):\n            np.argmin(dr, out=0)\n\n        with pytest.raises(ValueError, match=errmsg):\n            np.argmax(dr, out=0)\n\n    def test_minmax_period(self):\n\n        # monotonic\n        idx1 = PeriodIndex([NaT, \"2011-01-01\", \"2011-01-02\", \"2011-01-03\"], freq=\"D\")\n        assert not idx1.is_monotonic\n        assert idx1[1:].is_monotonic\n\n        # non-monotonic\n        idx2 = PeriodIndex(\n            [\"2011-01-01\", NaT, \"2011-01-03\", \"2011-01-02\", NaT], freq=\"D\"\n        )\n        assert not idx2.is_monotonic\n\n        for idx in [idx1, idx2]:\n            assert idx.min() == Period(\"2011-01-01\", freq=\"D\")\n            assert idx.max() == Period(\"2011-01-03\", freq=\"D\")\n        assert idx1.argmin() == 1\n        assert idx2.argmin() == 0\n        assert idx1.argmax() == 3\n        assert idx2.argmax() == 2\n\n        for op in [\"min\", \"max\"]:\n            # Return NaT\n            obj = PeriodIndex([], freq=\"M\")\n            result = getattr(obj, op)()\n            assert result is NaT\n\n            obj = PeriodIndex([NaT], freq=\"M\")\n            result = getattr(obj, op)()\n            assert result is NaT\n\n            obj = PeriodIndex([NaT, NaT, NaT], freq=\"M\")\n            result = getattr(obj, op)()\n            assert result is NaT\n\n    def test_numpy_minmax_period(self):\n        pr = pd.period_range(start=\"2016-01-15\", end=\"2016-01-20\")\n\n        assert np.min(pr) == Period(\"2016-01-15\", freq=\"D\")\n        assert np.max(pr) == Period(\"2016-01-20\", freq=\"D\")\n\n        errmsg = \"the 'out' parameter is not supported\"\n        with pytest.raises(ValueError, match=errmsg):\n            np.min(pr, out=0)\n        with pytest.raises(ValueError, match=errmsg):\n            np.max(pr, out=0)\n\n        assert np.argmin(pr) == 0\n        assert np.argmax(pr) == 5\n\n        errmsg = \"the 'out' parameter is not supported\"\n        with pytest.raises(ValueError, match=errmsg):\n            np.argmin(pr, out=0)\n        with pytest.raises(ValueError, match=errmsg):\n            np.argmax(pr, out=0)\n\n    def test_min_max_categorical(self):\n\n        ci = pd.CategoricalIndex(list(\"aabbca\"), categories=list(\"cab\"), ordered=False)\n        msg = (\n            r\"Categorical is not ordered for operation min\\n\"\n            r\"you can use .as_ordered\\(\\) to change the Categorical to an ordered one\\n\"\n        )\n        with pytest.raises(TypeError, match=msg):\n            ci.min()\n        msg = (\n            r\"Categorical is not ordered for operation max\\n\"\n            r\"you can use .as_ordered\\(\\) to change the Categorical to an ordered one\\n\"\n        )\n        with pytest.raises(TypeError, match=msg):\n            ci.max()\n\n        ci = pd.CategoricalIndex(list(\"aabbca\"), categories=list(\"cab\"), ordered=True)\n        assert ci.min() == \"c\"\n        assert ci.max() == \"b\"\n\n\nclass TestSeriesReductions:\n    # Note: the name TestSeriesReductions indicates these tests\n    #  were moved from a series-specific test file, _not_ that these tests are\n    #  intended long-term to be series-specific\n\n    def test_sum_inf(self):\n        s = Series(np.random.randn(10))\n        s2 = s.copy()\n\n        s[5:8] = np.inf\n        s2[5:8] = np.nan\n\n        assert np.isinf(s.sum())\n\n        arr = np.random.randn(100, 100).astype(\"f4\")\n        arr[:, 2] = np.inf\n\n        with pd.option_context(\"mode.use_inf_as_na\", True):\n            tm.assert_almost_equal(s.sum(), s2.sum())\n\n        res = nanops.nansum(arr, axis=1)\n        assert np.isinf(res).all()\n\n    @pytest.mark.parametrize(\"dtype\", [\"float64\", \"Int64\", \"boolean\", \"object\"])\n    @pytest.mark.parametrize(\"use_bottleneck\", [True, False])\n    @pytest.mark.parametrize(\"method, unit\", [(\"sum\", 0.0), (\"prod\", 1.0)])\n    def test_empty(self, method, unit, use_bottleneck, dtype):\n        with pd.option_context(\"use_bottleneck\", use_bottleneck):\n            # GH#9422 / GH#18921\n            # Entirely empty\n            s = Series([], dtype=dtype)\n            # NA by default\n            result = getattr(s, method)()\n            assert result == unit\n\n            # Explicit\n            result = getattr(s, method)(min_count=0)\n            assert result == unit\n\n            result = getattr(s, method)(min_count=1)\n            assert isna(result)\n\n            # Skipna, default\n            result = getattr(s, method)(skipna=True)\n            result == unit\n\n            # Skipna, explicit\n            result = getattr(s, method)(skipna=True, min_count=0)\n            assert result == unit\n\n            result = getattr(s, method)(skipna=True, min_count=1)\n            assert isna(result)\n\n            result = getattr(s, method)(skipna=False, min_count=0)\n            assert result == unit\n\n            result = getattr(s, method)(skipna=False, min_count=1)\n            assert isna(result)\n\n            # All-NA\n            s = Series([np.nan], dtype=dtype)\n            # NA by default\n            result = getattr(s, method)()\n            assert result == unit\n\n            # Explicit\n            result = getattr(s, method)(min_count=0)\n            assert result == unit\n\n            result = getattr(s, method)(min_count=1)\n            assert isna(result)\n\n            # Skipna, default\n            result = getattr(s, method)(skipna=True)\n            result == unit\n\n            # skipna, explicit\n            result = getattr(s, method)(skipna=True, min_count=0)\n            assert result == unit\n\n            result = getattr(s, method)(skipna=True, min_count=1)\n            assert isna(result)\n\n            # Mix of valid, empty\n            s = Series([np.nan, 1], dtype=dtype)\n            # Default\n            result = getattr(s, method)()\n            assert result == 1.0\n\n            # Explicit\n            result = getattr(s, method)(min_count=0)\n            assert result == 1.0\n\n            result = getattr(s, method)(min_count=1)\n            assert result == 1.0\n\n            # Skipna\n            result = getattr(s, method)(skipna=True)\n            assert result == 1.0\n\n            result = getattr(s, method)(skipna=True, min_count=0)\n            assert result == 1.0\n\n            # GH#844 (changed in GH#9422)\n            df = DataFrame(np.empty((10, 0)), dtype=dtype)\n            assert (getattr(df, method)(1) == unit).all()\n\n            s = Series([1], dtype=dtype)\n            result = getattr(s, method)(min_count=2)\n            assert isna(result)\n\n            result = getattr(s, method)(skipna=False, min_count=2)\n            assert isna(result)\n\n            s = Series([np.nan], dtype=dtype)\n            result = getattr(s, method)(min_count=2)\n            assert isna(result)\n\n            s = Series([np.nan, 1], dtype=dtype)\n            result = getattr(s, method)(min_count=2)\n            assert isna(result)\n\n    @pytest.mark.parametrize(\"method, unit\", [(\"sum\", 0.0), (\"prod\", 1.0)])\n    def test_empty_multi(self, method, unit):\n        s = Series(\n            [1, np.nan, np.nan, np.nan],\n            index=pd.MultiIndex.from_product([(\"a\", \"b\"), (0, 1)]),\n        )\n        # 1 / 0 by default\n        result = getattr(s, method)(level=0)\n        expected = Series([1, unit], index=[\"a\", \"b\"])\n        tm.assert_series_equal(result, expected)\n\n        # min_count=0\n        result = getattr(s, method)(level=0, min_count=0)\n        expected = Series([1, unit], index=[\"a\", \"b\"])\n        tm.assert_series_equal(result, expected)\n\n        # min_count=1\n        result = getattr(s, method)(level=0, min_count=1)\n        expected = Series([1, np.nan], index=[\"a\", \"b\"])\n        tm.assert_series_equal(result, expected)\n\n    @pytest.mark.parametrize(\"method\", [\"mean\"])\n    @pytest.mark.parametrize(\"dtype\", [\"Float64\", \"Int64\", \"boolean\"])\n    def test_ops_consistency_on_empty_nullable(self, method, dtype):\n\n        # GH#34814\n        # consistency for nullable dtypes on empty or ALL-NA mean\n\n        # empty series\n        eser = Series([], dtype=dtype)\n        result = getattr(eser, method)()\n        assert result is pd.NA\n\n        # ALL-NA series\n        nser = Series([np.nan], dtype=dtype)\n        result = getattr(nser, method)()\n        assert result is pd.NA\n\n    @pytest.mark.parametrize(\"method\", [\"mean\", \"median\", \"std\", \"var\"])\n    def test_ops_consistency_on_empty(self, method):\n\n        # GH#7869\n        # consistency on empty\n\n        # float\n        result = getattr(Series(dtype=float), method)()\n        assert isna(result)\n\n        # timedelta64[ns]\n        tdser = Series([], dtype=\"m8[ns]\")\n        if method == \"var\":\n            msg = \"|\".join(\n                [\n                    \"operation 'var' not allowed\",\n                    r\"cannot perform var with type timedelta64\\[ns\\]\",\n                    \"'TimedeltaArray' does not implement reduction 'var'\",\n                ]\n            )\n            with pytest.raises(TypeError, match=msg):\n                getattr(tdser, method)()\n        else:\n            result = getattr(tdser, method)()\n            assert result is NaT\n\n    def test_nansum_buglet(self):\n        ser = Series([1.0, np.nan], index=[0, 1])\n        result = np.nansum(ser)\n        tm.assert_almost_equal(result, 1)\n\n    @pytest.mark.parametrize(\"use_bottleneck\", [True, False])\n    def test_sum_overflow(self, use_bottleneck):\n\n        with pd.option_context(\"use_bottleneck\", use_bottleneck):\n            # GH#6915\n            # overflowing on the smaller int dtypes\n            for dtype in [\"int32\", \"int64\"]:\n                v = np.arange(5000000, dtype=dtype)\n                s = Series(v)\n\n                result = s.sum(skipna=False)\n                assert int(result) == v.sum(dtype=\"int64\")\n                result = s.min(skipna=False)\n                assert int(result) == 0\n                result = s.max(skipna=False)\n                assert int(result) == v[-1]\n\n            for dtype in [\"float32\", \"float64\"]:\n                v = np.arange(5000000, dtype=dtype)\n                s = Series(v)\n\n                result = s.sum(skipna=False)\n                assert result == v.sum(dtype=dtype)\n                result = s.min(skipna=False)\n                assert np.allclose(float(result), 0.0)\n                result = s.max(skipna=False)\n                assert np.allclose(float(result), v[-1])\n\n    def test_empty_timeseries_reductions_return_nat(self):\n        # covers GH#11245\n        for dtype in (\"m8[ns]\", \"m8[ns]\", \"M8[ns]\", \"M8[ns, UTC]\"):\n            assert Series([], dtype=dtype).min() is NaT\n            assert Series([], dtype=dtype).max() is NaT\n            assert Series([], dtype=dtype).min(skipna=False) is NaT\n            assert Series([], dtype=dtype).max(skipna=False) is NaT\n\n    def test_numpy_argmin(self):\n        # See GH#16830\n        data = np.arange(1, 11)\n\n        s = Series(data, index=data)\n        result = np.argmin(s)\n\n        expected = np.argmin(data)\n        assert result == expected\n\n        result = s.argmin()\n\n        assert result == expected\n\n        msg = \"the 'out' parameter is not supported\"\n        with pytest.raises(ValueError, match=msg):\n            np.argmin(s, out=data)\n\n    def test_numpy_argmax(self):\n        # See GH#16830\n        data = np.arange(1, 11)\n\n        s = Series(data, index=data)\n        result = np.argmax(s)\n        expected = np.argmax(data)\n        assert result == expected\n\n        result = s.argmax()\n\n        assert result == expected\n\n        msg = \"the 'out' parameter is not supported\"\n        with pytest.raises(ValueError, match=msg):\n            np.argmax(s, out=data)\n\n    def test_idxmin(self):\n        # test idxmin\n        # _check_stat_op approach can not be used here because of isna check.\n        string_series = tm.makeStringSeries().rename(\"series\")\n\n        # add some NaNs\n        string_series[5:15] = np.NaN\n\n        # skipna or no\n        assert string_series[string_series.idxmin()] == string_series.min()\n        assert isna(string_series.idxmin(skipna=False))\n\n        # no NaNs\n        nona = string_series.dropna()\n        assert nona[nona.idxmin()] == nona.min()\n        assert nona.index.values.tolist().index(nona.idxmin()) == nona.values.argmin()\n\n        # all NaNs\n        allna = string_series * np.nan\n        assert isna(allna.idxmin())\n\n        # datetime64[ns]\n        s = Series(date_range(\"20130102\", periods=6))\n        result = s.idxmin()\n        assert result == 0\n\n        s[0] = np.nan\n        result = s.idxmin()\n        assert result == 1\n\n    def test_idxmax(self):\n        # test idxmax\n        # _check_stat_op approach can not be used here because of isna check.\n        string_series = tm.makeStringSeries().rename(\"series\")\n\n        # add some NaNs\n        string_series[5:15] = np.NaN\n\n        # skipna or no\n        assert string_series[string_series.idxmax()] == string_series.max()\n        assert isna(string_series.idxmax(skipna=False))\n\n        # no NaNs\n        nona = string_series.dropna()\n        assert nona[nona.idxmax()] == nona.max()\n        assert nona.index.values.tolist().index(nona.idxmax()) == nona.values.argmax()\n\n        # all NaNs\n        allna = string_series * np.nan\n        assert isna(allna.idxmax())\n\n        from pandas import date_range\n\n        s = Series(date_range(\"20130102\", periods=6))\n        result = s.idxmax()\n        assert result == 5\n\n        s[5] = np.nan\n        result = s.idxmax()\n        assert result == 4\n\n        # Float64Index\n        # GH#5914\n        s = Series([1, 2, 3], [1.1, 2.1, 3.1])\n        result = s.idxmax()\n        assert result == 3.1\n        result = s.idxmin()\n        assert result == 1.1\n\n        s = Series(s.index, s.index)\n        result = s.idxmax()\n        assert result == 3.1\n        result = s.idxmin()\n        assert result == 1.1\n\n    def test_all_any(self):\n        ts = tm.makeTimeSeries()\n        bool_series = ts > 0\n        assert not bool_series.all()\n        assert bool_series.any()\n\n        # Alternative types, with implicit 'object' dtype.\n        s = Series([\"abc\", True])\n        assert \"abc\" == s.any()  # 'abc' || True => 'abc'\n\n    @pytest.mark.parametrize(\"klass\", [Index, Series])\n    def test_numpy_all_any(self, klass):\n        # GH#40180\n        idx = klass([0, 1, 2])\n        assert not np.all(idx)\n        assert np.any(idx)\n        idx = Index([1, 2, 3])\n        assert np.all(idx)\n\n    def test_all_any_params(self):\n        # Check skipna, with implicit 'object' dtype.\n        s1 = Series([np.nan, True])\n        s2 = Series([np.nan, False])\n        assert s1.all(skipna=False)  # nan && True => True\n        assert s1.all(skipna=True)\n        assert np.isnan(s2.any(skipna=False))  # nan || False => nan\n        assert not s2.any(skipna=True)\n\n        # Check level.\n        s = Series([False, False, True, True, False, True], index=[0, 0, 1, 1, 2, 2])\n        tm.assert_series_equal(s.all(level=0), Series([False, True, False]))\n        tm.assert_series_equal(s.any(level=0), Series([False, True, True]))\n\n        msg = \"Option bool_only is not implemented with option level\"\n        with pytest.raises(NotImplementedError, match=msg):\n            s.any(bool_only=True, level=0)\n        with pytest.raises(NotImplementedError, match=msg):\n            s.all(bool_only=True, level=0)\n\n        # bool_only is not implemented alone.\n        # TODO GH38810 change this error message to:\n        # \"Series.any does not implement bool_only\"\n        msg = \"Series.any does not implement numeric_only\"\n        with pytest.raises(NotImplementedError, match=msg):\n            s.any(bool_only=True)\n        msg = \"Series.all does not implement numeric_only.\"\n        with pytest.raises(NotImplementedError, match=msg):\n            s.all(bool_only=True)\n\n    def test_all_any_boolean(self):\n        # Check skipna, with boolean type\n        s1 = Series([pd.NA, True], dtype=\"boolean\")\n        s2 = Series([pd.NA, False], dtype=\"boolean\")\n        assert s1.all(skipna=False) is pd.NA  # NA && True => NA\n        assert s1.all(skipna=True)\n        assert s2.any(skipna=False) is pd.NA  # NA || False => NA\n        assert not s2.any(skipna=True)\n\n        # GH-33253: all True / all False values buggy with skipna=False\n        s3 = Series([True, True], dtype=\"boolean\")\n        s4 = Series([False, False], dtype=\"boolean\")\n        assert s3.all(skipna=False)\n        assert not s4.any(skipna=False)\n\n        # Check level TODO(GH-33449) result should also be boolean\n        s = Series(\n            [False, False, True, True, False, True],\n            index=[0, 0, 1, 1, 2, 2],\n            dtype=\"boolean\",\n        )\n        tm.assert_series_equal(s.all(level=0), Series([False, True, False]))\n        tm.assert_series_equal(s.any(level=0), Series([False, True, True]))\n\n    def test_any_axis1_bool_only(self):\n        # GH#32432\n        df = DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n        result = df.any(axis=1, bool_only=True)\n        expected = Series([True, False])\n        tm.assert_series_equal(result, expected)\n\n    def test_any_all_datetimelike(self):\n        # GH#38723 these may not be the desired long-term behavior (GH#34479)\n        #  but in the interim should be internally consistent\n        dta = date_range(\"1995-01-02\", periods=3)._data\n        ser = Series(dta)\n        df = DataFrame(ser)\n\n        assert dta.all()\n        assert dta.any()\n\n        assert ser.all()\n        assert ser.any()\n\n        assert df.any().all()\n        assert df.all().all()\n\n        dta = dta.tz_localize(\"UTC\")\n        ser = Series(dta)\n        df = DataFrame(ser)\n\n        assert dta.all()\n        assert dta.any()\n\n        assert ser.all()\n        assert ser.any()\n\n        assert df.any().all()\n        assert df.all().all()\n\n        tda = dta - dta[0]\n        ser = Series(tda)\n        df = DataFrame(ser)\n\n        assert tda.any()\n        assert not tda.all()\n\n        assert ser.any()\n        assert not ser.all()\n\n        assert df.any().all()\n        assert not df.all().any()\n\n    def test_timedelta64_analytics(self):\n\n        # index min/max\n        dti = date_range(\"2012-1-1\", periods=3, freq=\"D\")\n        td = Series(dti) - Timestamp(\"20120101\")\n\n        result = td.idxmin()\n        assert result == 0\n\n        result = td.idxmax()\n        assert result == 2\n\n        # GH#2982\n        # with NaT\n        td[0] = np.nan\n\n        result = td.idxmin()\n        assert result == 1\n\n        result = td.idxmax()\n        assert result == 2\n\n        # abs\n        s1 = Series(date_range(\"20120101\", periods=3))\n        s2 = Series(date_range(\"20120102\", periods=3))\n        expected = Series(s2 - s1)\n\n        result = np.abs(s1 - s2)\n        tm.assert_series_equal(result, expected)\n\n        result = (s1 - s2).abs()\n        tm.assert_series_equal(result, expected)\n\n        # max/min\n        result = td.max()\n        expected = Timedelta(\"2 days\")\n        assert result == expected\n\n        result = td.min()\n        expected = Timedelta(\"1 days\")\n        assert result == expected\n\n    @pytest.mark.parametrize(\n        \"test_input,error_type\",\n        [\n            (Series([], dtype=\"float64\"), ValueError),\n            # For strings, or any Series with dtype 'O'\n            (Series([\"foo\", \"bar\", \"baz\"]), TypeError),\n            (Series([(1,), (2,)]), TypeError),\n            # For mixed data types\n            (Series([\"foo\", \"foo\", \"bar\", \"bar\", None, np.nan, \"baz\"]), TypeError),\n        ],\n    )\n    def test_assert_idxminmax_raises(self, test_input, error_type):\n        \"\"\"\n        Cases where ``Series.argmax`` and related should raise an exception\n        \"\"\"\n        msg = (\n            \"reduction operation 'argmin' not allowed for this dtype|\"\n            \"attempt to get argmin of an empty sequence\"\n        )\n        with pytest.raises(error_type, match=msg):\n            test_input.idxmin()\n        with pytest.raises(error_type, match=msg):\n            test_input.idxmin(skipna=False)\n        msg = (\n            \"reduction operation 'argmax' not allowed for this dtype|\"\n            \"attempt to get argmax of an empty sequence\"\n        )\n        with pytest.raises(error_type, match=msg):\n            test_input.idxmax()\n        with pytest.raises(error_type, match=msg):\n            test_input.idxmax(skipna=False)\n\n    def test_idxminmax_with_inf(self):\n        # For numeric data with NA and Inf (GH #13595)\n        s = Series([0, -np.inf, np.inf, np.nan])\n\n        assert s.idxmin() == 1\n        assert np.isnan(s.idxmin(skipna=False))\n\n        assert s.idxmax() == 2\n        assert np.isnan(s.idxmax(skipna=False))\n\n        # Using old-style behavior that treats floating point nan, -inf, and\n        # +inf as missing\n        with pd.option_context(\"mode.use_inf_as_na\", True):\n            assert s.idxmin() == 0\n            assert np.isnan(s.idxmin(skipna=False))\n            assert s.idxmax() == 0\n            np.isnan(s.idxmax(skipna=False))\n\n\nclass TestDatetime64SeriesReductions:\n    # Note: the name TestDatetime64SeriesReductions indicates these tests\n    #  were moved from a series-specific test file, _not_ that these tests are\n    #  intended long-term to be series-specific\n\n    @pytest.mark.parametrize(\n        \"nat_ser\",\n        [\n            Series([NaT, NaT]),\n            Series([NaT, Timedelta(\"nat\")]),\n            Series([Timedelta(\"nat\"), Timedelta(\"nat\")]),\n        ],\n    )\n    def test_minmax_nat_series(self, nat_ser):\n        # GH#23282\n        assert nat_ser.min() is NaT\n        assert nat_ser.max() is NaT\n        assert nat_ser.min(skipna=False) is NaT\n        assert nat_ser.max(skipna=False) is NaT\n\n    @pytest.mark.parametrize(\n        \"nat_df\",\n        [\n            DataFrame([NaT, NaT]),\n            DataFrame([NaT, Timedelta(\"nat\")]),\n            DataFrame([Timedelta(\"nat\"), Timedelta(\"nat\")]),\n        ],\n    )\n    def test_minmax_nat_dataframe(self, nat_df):\n        # GH#23282\n        assert nat_df.min()[0] is NaT\n        assert nat_df.max()[0] is NaT\n        assert nat_df.min(skipna=False)[0] is NaT\n        assert nat_df.max(skipna=False)[0] is NaT\n\n    def test_min_max(self):\n        rng = date_range(\"1/1/2000\", \"12/31/2000\")\n        rng2 = rng.take(np.random.permutation(len(rng)))\n\n        the_min = rng2.min()\n        the_max = rng2.max()\n        assert isinstance(the_min, Timestamp)\n        assert isinstance(the_max, Timestamp)\n        assert the_min == rng[0]\n        assert the_max == rng[-1]\n\n        assert rng.min() == rng[0]\n        assert rng.max() == rng[-1]\n\n    def test_min_max_series(self):\n        rng = date_range(\"1/1/2000\", periods=10, freq=\"4h\")\n        lvls = [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\", \"C\"]\n        df = DataFrame({\"TS\": rng, \"V\": np.random.randn(len(rng)), \"L\": lvls})\n\n        result = df.TS.max()\n        exp = Timestamp(df.TS.iat[-1])\n        assert isinstance(result, Timestamp)\n        assert result == exp\n\n        result = df.TS.min()\n        exp = Timestamp(df.TS.iat[0])\n        assert isinstance(result, Timestamp)\n        assert result == exp\n\n\nclass TestCategoricalSeriesReductions:\n    # Note: the name TestCategoricalSeriesReductions indicates these tests\n    #  were moved from a series-specific test file, _not_ that these tests are\n    #  intended long-term to be series-specific\n\n    @pytest.mark.parametrize(\"function\", [\"min\", \"max\"])\n    def test_min_max_unordered_raises(self, function):\n        # unordered cats have no min/max\n        cat = Series(Categorical([\"a\", \"b\", \"c\", \"d\"], ordered=False))\n        msg = f\"Categorical is not ordered for operation {function}\"\n        with pytest.raises(TypeError, match=msg):\n            getattr(cat, function)()\n\n    @pytest.mark.parametrize(\n        \"values, categories\",\n        [\n            (list(\"abc\"), list(\"abc\")),\n            (list(\"abc\"), list(\"cba\")),\n            (list(\"abc\") + [np.nan], list(\"cba\")),\n            ([1, 2, 3], [3, 2, 1]),\n            ([1, 2, 3, np.nan], [3, 2, 1]),\n        ],\n    )\n    @pytest.mark.parametrize(\"function\", [\"min\", \"max\"])\n    def test_min_max_ordered(self, values, categories, function):\n        # GH 25303\n        cat = Series(Categorical(values, categories=categories, ordered=True))\n        result = getattr(cat, function)(skipna=True)\n        expected = categories[0] if function == \"min\" else categories[2]\n        assert result == expected\n\n    @pytest.mark.parametrize(\"function\", [\"min\", \"max\"])\n    @pytest.mark.parametrize(\"skipna\", [True, False])\n    def test_min_max_ordered_with_nan_only(self, function, skipna):\n        # https://github.com/pandas-dev/pandas/issues/33450\n        cat = Series(Categorical([np.nan], categories=[1, 2], ordered=True))\n        result = getattr(cat, function)(skipna=skipna)\n        assert result is np.nan\n\n    @pytest.mark.parametrize(\"function\", [\"min\", \"max\"])\n    @pytest.mark.parametrize(\"skipna\", [True, False])\n    def test_min_max_skipna(self, function, skipna):\n        cat = Series(\n            Categorical([\"a\", \"b\", np.nan, \"a\"], categories=[\"b\", \"a\"], ordered=True)\n        )\n        result = getattr(cat, function)(skipna=skipna)\n\n        if skipna is True:\n            expected = \"b\" if function == \"min\" else \"a\"\n            assert result == expected\n        else:\n            assert result is np.nan\n\n\nclass TestSeriesMode:\n    # Note: the name TestSeriesMode indicates these tests\n    #  were moved from a series-specific test file, _not_ that these tests are\n    #  intended long-term to be series-specific\n\n    @pytest.mark.parametrize(\n        \"dropna, expected\",\n        [(True, Series([], dtype=np.float64)), (False, Series([], dtype=np.float64))],\n    )\n    def test_mode_empty(self, dropna, expected):\n        s = Series([], dtype=np.float64)\n        result = s.mode(dropna)\n        tm.assert_series_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"dropna, data, expected\",\n        [\n            (True, [1, 1, 1, 2], [1]),\n            (True, [1, 1, 1, 2, 3, 3, 3], [1, 3]),\n            (False, [1, 1, 1, 2], [1]),\n            (False, [1, 1, 1, 2, 3, 3, 3], [1, 3]),\n        ],\n    )\n    @pytest.mark.parametrize(\n        \"dt\", list(np.typecodes[\"AllInteger\"] + np.typecodes[\"Float\"])\n    )\n    def test_mode_numerical(self, dropna, data, expected, dt):\n        s = Series(data, dtype=dt)\n        result = s.mode(dropna)\n        expected = Series(expected, dtype=dt)\n        tm.assert_series_equal(result, expected)\n\n    @pytest.mark.parametrize(\"dropna, expected\", [(True, [1.0]), (False, [1, np.nan])])\n    def test_mode_numerical_nan(self, dropna, expected):\n        s = Series([1, 1, 2, np.nan, np.nan])\n        result = s.mode(dropna)\n        expected = Series(expected)\n        tm.assert_series_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"dropna, expected1, expected2, expected3\",\n        [(True, [\"b\"], [\"bar\"], [\"nan\"]), (False, [\"b\"], [np.nan], [\"nan\"])],\n    )\n    def test_mode_str_obj(self, dropna, expected1, expected2, expected3):\n        # Test string and object types.\n        data = [\"a\"] * 2 + [\"b\"] * 3\n\n        s = Series(data, dtype=\"c\")\n        result = s.mode(dropna)\n        expected1 = Series(expected1, dtype=\"c\")\n        tm.assert_series_equal(result, expected1)\n\n        data = [\"foo\", \"bar\", \"bar\", np.nan, np.nan, np.nan]\n\n        s = Series(data, dtype=object)\n        result = s.mode(dropna)\n        expected2 = Series(expected2, dtype=object)\n        tm.assert_series_equal(result, expected2)\n\n        data = [\"foo\", \"bar\", \"bar\", np.nan, np.nan, np.nan]\n\n        s = Series(data, dtype=object).astype(str)\n        result = s.mode(dropna)\n        expected3 = Series(expected3, dtype=str)\n        tm.assert_series_equal(result, expected3)\n\n    @pytest.mark.parametrize(\n        \"dropna, expected1, expected2\",\n        [(True, [\"foo\"], [\"foo\"]), (False, [\"foo\"], [np.nan])],\n    )\n    def test_mode_mixeddtype(self, dropna, expected1, expected2):\n        s = Series([1, \"foo\", \"foo\"])\n        result = s.mode(dropna)\n        expected = Series(expected1)\n        tm.assert_series_equal(result, expected)\n\n        s = Series([1, \"foo\", \"foo\", np.nan, np.nan, np.nan])\n        result = s.mode(dropna)\n        expected = Series(expected2, dtype=object)\n        tm.assert_series_equal(result, expected)\n\n    @pytest.mark.parametrize(\n        \"dropna, expected1, expected2\",\n        [\n            (\n                True,\n                [\"1900-05-03\", \"2011-01-03\", \"2013-01-02\"],\n                [\"2011-01-03\", \"2013-01-02\"],\n            ),\n            (False, [np.nan], [np.nan, \"2011-01-03\", \"2013-01-02\"]),\n        ],\n    )\n    def test_mode_datetime(self, dropna, expected1, expected2):\n        s = Series(\n            [\"2011-01-03\", \"2013-01-02\", \"1900-05-03\", \"nan\", \"nan\"], dtype=\"M8[ns]\"\n        )\n        result = s.mode(dropna)\n        expected1 = Series(expected1, dtype=\"M8[ns]\")\n        tm.assert_series_equal(result, expected1)\n\n        s = Series(\n            [\n                \"2011-01-03\",\n                \"2013-01-02\",\n                \"1900-05-03\",\n                \"2011-01-03\",\n                \"2013-01-02\",\n                \"nan\",\n                \"nan\",\n            ],\n            dtype=\"M8[ns]\",\n        )\n        result = s.mode(dropna)\n        expected2 = Series(expected2, dtype=\"M8[ns]\")\n        tm.assert_series_equal(result, expected2)\n\n    @pytest.mark.parametrize(\n        \"dropna, expected1, expected2\",\n        [\n            (True, [\"-1 days\", \"0 days\", \"1 days\"], [\"2 min\", \"1 day\"]),\n            (False, [np.nan], [np.nan, \"2 min\", \"1 day\"]),\n        ],\n    )\n    def test_mode_timedelta(self, dropna, expected1, expected2):\n        # gh-5986: Test timedelta types.\n\n        s = Series(\n            [\"1 days\", \"-1 days\", \"0 days\", \"nan\", \"nan\"], dtype=\"timedelta64[ns]\"\n        )\n        result = s.mode(dropna)\n        expected1 = Series(expected1, dtype=\"timedelta64[ns]\")\n        tm.assert_series_equal(result, expected1)\n\n        s = Series(\n            [\n                \"1 day\",\n                \"1 day\",\n                \"-1 day\",\n                \"-1 day 2 min\",\n                \"2 min\",\n                \"2 min\",\n                \"nan\",\n                \"nan\",\n            ],\n            dtype=\"timedelta64[ns]\",\n        )\n        result = s.mode(dropna)\n        expected2 = Series(expected2, dtype=\"timedelta64[ns]\")\n        tm.assert_series_equal(result, expected2)\n\n    @pytest.mark.parametrize(\n        \"dropna, expected1, expected2, expected3\",\n        [\n            (\n                True,\n                Categorical([1, 2], categories=[1, 2]),\n                Categorical([\"a\"], categories=[1, \"a\"]),\n                Categorical([3, 1], categories=[3, 2, 1], ordered=True),\n            ),\n            (\n                False,\n                Categorical([np.nan], categories=[1, 2]),\n                Categorical([np.nan, \"a\"], categories=[1, \"a\"]),\n                Categorical([np.nan, 3, 1], categories=[3, 2, 1], ordered=True),\n            ),\n        ],\n    )\n    def test_mode_category(self, dropna, expected1, expected2, expected3):\n        s = Series(Categorical([1, 2, np.nan, np.nan]))\n        result = s.mode(dropna)\n        expected1 = Series(expected1, dtype=\"category\")\n        tm.assert_series_equal(result, expected1)\n\n        s = Series(Categorical([1, \"a\", \"a\", np.nan, np.nan]))\n        result = s.mode(dropna)\n        expected2 = Series(expected2, dtype=\"category\")\n        tm.assert_series_equal(result, expected2)\n\n        s = Series(\n            Categorical(\n                [1, 1, 2, 3, 3, np.nan, np.nan], categories=[3, 2, 1], ordered=True\n            )\n        )\n        result = s.mode(dropna)\n        expected3 = Series(expected3, dtype=\"category\")\n        tm.assert_series_equal(result, expected3)\n\n    @pytest.mark.parametrize(\n        \"dropna, expected1, expected2\",\n        [(True, [2 ** 63], [1, 2 ** 63]), (False, [2 ** 63], [1, 2 ** 63])],\n    )\n    def test_mode_intoverflow(self, dropna, expected1, expected2):\n        # Test for uint64 overflow.\n        s = Series([1, 2 ** 63, 2 ** 63], dtype=np.uint64)\n        result = s.mode(dropna)\n        expected1 = Series(expected1, dtype=np.uint64)\n        tm.assert_series_equal(result, expected1)\n\n        s = Series([1, 2 ** 63], dtype=np.uint64)\n        result = s.mode(dropna)\n        expected2 = Series(expected2, dtype=np.uint64)\n        tm.assert_series_equal(result, expected2)\n\n    def test_mode_sortwarning(self):\n        # Check for the warning that is raised when the mode\n        # results cannot be sorted\n\n        expected = Series([\"foo\", np.nan])\n        s = Series([1, \"foo\", \"foo\", np.nan, np.nan])\n\n        with tm.assert_produces_warning(UserWarning):\n            result = s.mode(dropna=False)\n            result = result.sort_values().reset_index(drop=True)\n\n        tm.assert_series_equal(result, expected)\n"
    }
  ],
  "questions": [
    "@MarcoGorelli the automatic script only changes it from `pd.DataFrame(..)` to `DataFrame(..)` and not the other way around? (as previously, we only agreed to be consistent within a file, not necessarily to change *all* files to use the non-`pd.` way)"
  ],
  "golden_answers": [
    "@jorisvandenbossche if there's both, it'll choose the non-`pd.` one. If the file is already consistently using the `pd.` one, then it'll leave it untouched.\r\n\r\ne.g.\r\n```python\r\nimport pandas as pd\r\n\r\ndef test_0():\r\n    pd.DataFrame()\r\n\r\ndef test_1():\r\n    pd.DataFrame()\r\n```\r\n\r\nwould be left untouched (i.e. it would keep being consistent within the file), but\r\n\r\n```python\r\nimport pandas as pd\r\nfrom pandas import DataFrame\r\n\r\ndef test_0():\r\n    pd.DataFrame()\r\n\r\ndef test_1():\r\n    DataFrame()\r\n```\r\n\r\nwould become\r\n\r\n```python\r\nimport pandas as pd\r\nfrom pandas import DataFrame\r\n\r\ndef test_0():\r\n    DataFrame()\r\n\r\ndef test_1():\r\n    DataFrame()\r\n```"
  ],
  "questions_generated": [
    "What is the purpose of the 'inconsistent-namespace-usage' pre-commit check in the pandas repository?",
    "How should a contributor modify the `.pre-commit-config.yaml` to include a new folder for the 'inconsistent-namespace-usage' check?",
    "What steps should be followed to ensure the 'inconsistent-namespace-usage' check passes after modifying a test folder?",
    "Why is it necessary to temporarily add 'tokenize-rt' as a dependency when running the 'inconsistent-namespace-usage' check?",
    "What should a contributor do if other pre-commit hooks fail after running the 'inconsistent-namespace-usage' check?",
    "What is the role of the 'get_objs' function in the code context provided from `pandas/tests/reductions/test_reductions.py`?",
    "How does the `test_ops` method in the `TestReductions` class verify the correctness of reduction operations?"
  ],
  "golden_answers_generated": [
    "The 'inconsistent-namespace-usage' pre-commit check is designed to enforce consistent usage of the pandas namespace in test files. It ensures that references to pandas functions, classes, or modules are consistently used within the specified test directories, helping to maintain code clarity and prevent bugs related to namespace usage.",
    "To include a new folder for the 'inconsistent-namespace-usage' check, a contributor should add the folder name to the 'files' pattern within the `.pre-commit-config.yaml`. For example, to add the 'series' folder, the pattern should be modified to `^pandas/tests/(frame|series)/`.",
    "After modifying a test folder, follow these steps: 1) Update the `.pre-commit-config.yaml` to include the new folder. 2) Add `tokenize-rt` as an additional dependency and `--replace` as an argument. 3) Run the check across all files using `pre-commit run inconsistent-namespace-usage --all-files`. If the check fails initially, it will modify files. 4) Run the check again to ensure it passes. 5) Revert changes to `.pre-commit-config.yaml` and commit the changes.",
    "The 'tokenize-rt' package is temporarily added as a dependency because it is used by the script to tokenize Python code, which helps in identifying and fixing inconsistent namespace usage. This temporary addition allows for automated changes to the code, which are then reviewed before committing.",
    "If other pre-commit hooks fail after running the 'inconsistent-namespace-usage' check, the contributor should review the errors reported by the hooks. It's important to ensure that changes made for fixing namespace usage do not introduce new issues. If necessary, correct any issues identified by other hooks before committing the changes.",
    "The 'get_objs' function in the code context creates a list of index and series objects using various types of pandas indexes. It generates test data by applying random values to these indexes to form Series objects. This list of objects is used to parameterize tests in the `TestReductions` class, enabling comprehensive testing of reduction operations like 'max' and 'min' across different data types.",
    "The `test_ops` method verifies the correctness of reduction operations by parameterizing over different operations ('max', 'min') and objects generated by the `get_objs` function. It compares the result of calling the operation on the object with the expected result, which is derived from the object's values or, in the case of `PeriodIndex`, from the ordinal values. This ensures that the operations yield correct results for various types of indexes and data."
  ]
}