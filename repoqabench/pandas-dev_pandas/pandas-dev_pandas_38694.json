{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "38694",
  "issue_description": "# DOC add command to run pre-commit checks to pull request template\n\nI think we could add\r\n```bash\r\npasses `pre-commit run --from-ref=upstream/master --to-ref=HEAD --all-files`\r\n```\r\nto the pull request template (maybe it could even replace the current `black` and `flake8` ones).\r\n\r\nThe file to change would be\r\n```\r\n.github/PULL_REQUEST_TEMPLATE.md\r\n```\r\n\r\nSome of the contributing guide may also need updating if it mentions the `flake8 --diff` command.",
  "issue_comments": [
    {
      "id": 751238671,
      "user": "BobinMathew",
      "body": "Hi @MarcoGorelli \r\nDo you want this on the file?\r\n- [ ] closes #xxxx\r\n- [ ] tests added / passed\r\n- [ ] pre-commit run --from-ref=upstream/master --to-ref=HEAD\r\n- [ ] whatsnew entry\r\n"
    },
    {
      "id": 751252507,
      "user": "MarcoGorelli",
      "body": "@BobinMathew yes, but will need \"passes\" in there too, and `--all-files` (have updated the issue text)"
    },
    {
      "id": 751254787,
      "user": "BobinMathew",
      "body": "I gave a PR.\r\nChecking's still continuing.\r\n\r\n_Update: There seems to be error in \r\n**continuous-integration/travis-ci/pr — The Travis CI build could not complete due to an error**_\r\n"
    },
    {
      "id": 751278597,
      "user": "MarcoGorelli",
      "body": "Great! Can you put the issue number (#38694) in the pull request body (where it says `closes #xxxxx`) so it gets linked to this issue?\r\n\r\nTravis CI error's likely unrelated"
    },
    {
      "id": 751316714,
      "user": "BobinMathew",
      "body": "Ok @MarcoGorelli , I added the issue number"
    },
    {
      "id": 751334037,
      "user": "MarcoGorelli",
      "body": "You need to put it in the pull request body - look at other pull requests for an example, e.g. https://github.com/pandas-dev/pandas/pull/38668"
    },
    {
      "id": 751369438,
      "user": "BobinMathew",
      "body": "Hi @MarcoGorelli , I saw some errors.\r\nIs every this alright?"
    },
    {
      "id": 751510523,
      "user": "jorisvandenbossche",
      "body": "Should we actually recommend that? It's a quite complex line of cli code, and if you are using pre-commit, I suppose you will typically use it as a git commit hook?"
    },
    {
      "id": 751514111,
      "user": "MarcoGorelli",
      "body": "Is it more complicated than the current `flake8` line\r\n```\r\ngit diff upstream/master -u -- \"*.py\" | flake8 --diff\r\n```\r\n?\r\n\r\nThe command I posted gives you a cross-platform way of running all the CI code quality checks, with all the right package versions, only on the files which you've changed. You can run it even if you don't use pre-commit as a git commit hook"
    },
    {
      "id": 751516452,
      "user": "jorisvandenbossche",
      "body": "> Is it more complicated than the current flake8 line\r\n\r\nNo, but if someone proposed to *add* that line to the template (if it wasn't there yet), I would probably raise the same concern ;-) \r\nAnd I personally also never ever used that flake8 line in practice ..\r\n\r\nI am basically wondering how many of our core / regular contributors are using that. And if almost no one does (*if*! I don't know that, to be clear), not sure it should be the first thing to have contributors see when opening a PR.\r\n\r\n> The command I posted gives you a cross-platform way of running all the CI code quality checks, with all the right package versions, only on the files which you've changed. You can run it even if you don't use pre-commit as a git commit hook\r\n\r\nYes, and that sounds valuable in certain cases. \r\nBut then we should probably also add that to and explain it in the contributing docs? \r\n\r\nMaybe a general \"Ensure all linting tests pass, see here how to run them\" with a link to a clear overview in the contributing guide on (different ways) how you can run the linting might be more useful? It's more clicking, but it migth also be less scary as such a complex command without much context.\r\n\r\n"
    },
    {
      "id": 751666738,
      "user": "MarcoGorelli",
      "body": "OK, thanks for explaning :smile: \r\n\r\n> Maybe a general \"Ensure all linting tests pass, see here how to run them\" with a link to a clear overview in the contributing guide on (different ways) how you can run the linting might be more useful?\r\n\r\nSure, sounds good - I think there could be a link to https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#code-standards , and there this command could be put in place of `./ci/code_checks.sh` (which won't work on Windows and doesn't include all checks), with a short explanation of what it does (i.e. it runs all the code quality checks on all files which have changed between the current commit and `upstream/master`)"
    },
    {
      "id": 751715751,
      "user": "jorisvandenbossche",
      "body": "Yep, that sounds good to me"
    },
    {
      "id": 753639189,
      "user": "BobinMathew",
      "body": "take"
    },
    {
      "id": 757521940,
      "user": "MarcoGorelli",
      "body": "closed in #38696"
    }
  ],
  "text_context": "# DOC add command to run pre-commit checks to pull request template\n\nI think we could add\r\n```bash\r\npasses `pre-commit run --from-ref=upstream/master --to-ref=HEAD --all-files`\r\n```\r\nto the pull request template (maybe it could even replace the current `black` and `flake8` ones).\r\n\r\nThe file to change would be\r\n```\r\n.github/PULL_REQUEST_TEMPLATE.md\r\n```\r\n\r\nSome of the contributing guide may also need updating if it mentions the `flake8 --diff` command.\n\nHi @MarcoGorelli \r\nDo you want this on the file?\r\n- [ ] closes #xxxx\r\n- [ ] tests added / passed\r\n- [ ] pre-commit run --from-ref=upstream/master --to-ref=HEAD\r\n- [ ] whatsnew entry\r\n\n\n@BobinMathew yes, but will need \"passes\" in there too, and `--all-files` (have updated the issue text)\n\nI gave a PR.\r\nChecking's still continuing.\r\n\r\n_Update: There seems to be error in \r\n**continuous-integration/travis-ci/pr — The Travis CI build could not complete due to an error**_\r\n\n\nGreat! Can you put the issue number (#38694) in the pull request body (where it says `closes #xxxxx`) so it gets linked to this issue?\r\n\r\nTravis CI error's likely unrelated\n\nOk @MarcoGorelli , I added the issue number\n\nYou need to put it in the pull request body - look at other pull requests for an example, e.g. https://github.com/pandas-dev/pandas/pull/38668\n\nHi @MarcoGorelli , I saw some errors.\r\nIs every this alright?\n\nShould we actually recommend that? It's a quite complex line of cli code, and if you are using pre-commit, I suppose you will typically use it as a git commit hook?\n\nIs it more complicated than the current `flake8` line\r\n```\r\ngit diff upstream/master -u -- \"*.py\" | flake8 --diff\r\n```\r\n?\r\n\r\nThe command I posted gives you a cross-platform way of running all the CI code quality checks, with all the right package versions, only on the files which you've changed. You can run it even if you don't use pre-commit as a git commit hook\n\n> Is it more complicated than the current flake8 line\r\n\r\nNo, but if someone proposed to *add* that line to the template (if it wasn't there yet), I would probably raise the same concern ;-) \r\nAnd I personally also never ever used that flake8 line in practice ..\r\n\r\nI am basically wondering how many of our core / regular contributors are using that. And if almost no one does (*if*! I don't know that, to be clear), not sure it should be the first thing to have contributors see when opening a PR.\r\n\r\n> The command I posted gives you a cross-platform way of running all the CI code quality checks, with all the right package versions, only on the files which you've changed. You can run it even if you don't use pre-commit as a git commit hook\r\n\r\nYes, and that sounds valuable in certain cases. \r\nBut then we should probably also add that to and explain it in the contributing docs? \r\n\r\nMaybe a general \"Ensure all linting tests pass, see here how to run them\" with a link to a clear overview in the contributing guide on (different ways) how you can run the linting might be more useful? It's more clicking, but it migth also be less scary as such a complex command without much context.\r\n\r\n\n\nOK, thanks for explaning :smile: \r\n\r\n> Maybe a general \"Ensure all linting tests pass, see here how to run them\" with a link to a clear overview in the contributing guide on (different ways) how you can run the linting might be more useful?\r\n\r\nSure, sounds good - I think there could be a link to https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#code-standards , and there this command could be put in place of `./ci/code_checks.sh` (which won't work on Windows and doesn't include all checks), with a short explanation of what it does (i.e. it runs all the code quality checks on all files which have changed between the current commit and `upstream/master`)\n\nYep, that sounds good to me\n\ntake\n\nclosed in #38696",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/38668",
  "code_context": [
    {
      "filename": "pandas/plotting/_matplotlib/tools.py",
      "content": "# being a bit too dynamic\nfrom math import ceil\nfrom typing import TYPE_CHECKING, Iterable, List, Sequence, Tuple, Union\nimport warnings\n\nimport matplotlib.table\nimport matplotlib.ticker as ticker\nimport numpy as np\n\nfrom pandas._typing import FrameOrSeriesUnion\n\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.generic import ABCDataFrame, ABCIndex, ABCSeries\n\nfrom pandas.plotting._matplotlib import compat\n\nif TYPE_CHECKING:\n    from matplotlib.axes import Axes\n    from matplotlib.axis import Axis\n    from matplotlib.lines import Line2D\n    from matplotlib.table import Table\n\n\ndef format_date_labels(ax: \"Axes\", rot):\n    # mini version of autofmt_xdate\n    for label in ax.get_xticklabels():\n        label.set_ha(\"right\")\n        label.set_rotation(rot)\n    fig = ax.get_figure()\n    fig.subplots_adjust(bottom=0.2)\n\n\ndef table(\n    ax, data: FrameOrSeriesUnion, rowLabels=None, colLabels=None, **kwargs\n) -> \"Table\":\n    if isinstance(data, ABCSeries):\n        data = data.to_frame()\n    elif isinstance(data, ABCDataFrame):\n        pass\n    else:\n        raise ValueError(\"Input data must be DataFrame or Series\")\n\n    if rowLabels is None:\n        rowLabels = data.index\n\n    if colLabels is None:\n        colLabels = data.columns\n\n    cellText = data.values\n\n    table = matplotlib.table.table(\n        ax, cellText=cellText, rowLabels=rowLabels, colLabels=colLabels, **kwargs\n    )\n    return table\n\n\ndef _get_layout(nplots: int, layout=None, layout_type: str = \"box\") -> Tuple[int, int]:\n    if layout is not None:\n        if not isinstance(layout, (tuple, list)) or len(layout) != 2:\n            raise ValueError(\"Layout must be a tuple of (rows, columns)\")\n\n        nrows, ncols = layout\n\n        # Python 2 compat\n        ceil_ = lambda x: int(ceil(x))\n        if nrows == -1 and ncols > 0:\n            layout = nrows, ncols = (ceil_(float(nplots) / ncols), ncols)\n        elif ncols == -1 and nrows > 0:\n            layout = nrows, ncols = (nrows, ceil_(float(nplots) / nrows))\n        elif ncols <= 0 and nrows <= 0:\n            msg = \"At least one dimension of layout must be positive\"\n            raise ValueError(msg)\n\n        if nrows * ncols < nplots:\n            raise ValueError(\n                f\"Layout of {nrows}x{ncols} must be larger than required size {nplots}\"\n            )\n\n        return layout\n\n    if layout_type == \"single\":\n        return (1, 1)\n    elif layout_type == \"horizontal\":\n        return (1, nplots)\n    elif layout_type == \"vertical\":\n        return (nplots, 1)\n\n    layouts = {1: (1, 1), 2: (1, 2), 3: (2, 2), 4: (2, 2)}\n    try:\n        return layouts[nplots]\n    except KeyError:\n        k = 1\n        while k ** 2 < nplots:\n            k += 1\n\n        if (k - 1) * k >= nplots:\n            return k, (k - 1)\n        else:\n            return k, k\n\n\n# copied from matplotlib/pyplot.py and modified for pandas.plotting\n\n\ndef create_subplots(\n    naxes: int,\n    sharex: bool = False,\n    sharey: bool = False,\n    squeeze: bool = True,\n    subplot_kw=None,\n    ax=None,\n    layout=None,\n    layout_type: str = \"box\",\n    **fig_kw,\n):\n    \"\"\"\n    Create a figure with a set of subplots already made.\n\n    This utility wrapper makes it convenient to create common layouts of\n    subplots, including the enclosing figure object, in a single call.\n\n    Parameters\n    ----------\n    naxes : int\n      Number of required axes. Exceeded axes are set invisible. Default is\n      nrows * ncols.\n\n    sharex : bool\n      If True, the X axis will be shared amongst all subplots.\n\n    sharey : bool\n      If True, the Y axis will be shared amongst all subplots.\n\n    squeeze : bool\n\n      If True, extra dimensions are squeezed out from the returned axis object:\n        - if only one subplot is constructed (nrows=ncols=1), the resulting\n        single Axis object is returned as a scalar.\n        - for Nx1 or 1xN subplots, the returned object is a 1-d numpy object\n        array of Axis objects are returned as numpy 1-d arrays.\n        - for NxM subplots with N>1 and M>1 are returned as a 2d array.\n\n      If False, no squeezing is done: the returned axis object is always\n      a 2-d array containing Axis instances, even if it ends up being 1x1.\n\n    subplot_kw : dict\n      Dict with keywords passed to the add_subplot() call used to create each\n      subplots.\n\n    ax : Matplotlib axis object, optional\n\n    layout : tuple\n      Number of rows and columns of the subplot grid.\n      If not specified, calculated from naxes and layout_type\n\n    layout_type : {'box', 'horizontal', 'vertical'}, default 'box'\n      Specify how to layout the subplot grid.\n\n    fig_kw : Other keyword arguments to be passed to the figure() call.\n        Note that all keywords not recognized above will be\n        automatically included here.\n\n    Returns\n    -------\n    fig, ax : tuple\n      - fig is the Matplotlib Figure object\n      - ax can be either a single axis object or an array of axis objects if\n      more than one subplot was created.  The dimensions of the resulting array\n      can be controlled with the squeeze keyword, see above.\n\n    Examples\n    --------\n    x = np.linspace(0, 2*np.pi, 400)\n    y = np.sin(x**2)\n\n    # Just a figure and one subplot\n    f, ax = plt.subplots()\n    ax.plot(x, y)\n    ax.set_title('Simple plot')\n\n    # Two subplots, unpack the output array immediately\n    f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n    ax1.plot(x, y)\n    ax1.set_title('Sharing Y axis')\n    ax2.scatter(x, y)\n\n    # Four polar axes\n    plt.subplots(2, 2, subplot_kw=dict(polar=True))\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if subplot_kw is None:\n        subplot_kw = {}\n\n    if ax is None:\n        fig = plt.figure(**fig_kw)\n    else:\n        if is_list_like(ax):\n            if squeeze:\n                ax = flatten_axes(ax)\n            if layout is not None:\n                warnings.warn(\n                    \"When passing multiple axes, layout keyword is ignored\", UserWarning\n                )\n            if sharex or sharey:\n                warnings.warn(\n                    \"When passing multiple axes, sharex and sharey \"\n                    \"are ignored. These settings must be specified when creating axes\",\n                    UserWarning,\n                    stacklevel=4,\n                )\n            if ax.size == naxes:\n                fig = ax.flat[0].get_figure()\n                return fig, ax\n            else:\n                raise ValueError(\n                    f\"The number of passed axes must be {naxes}, the \"\n                    \"same as the output plot\"\n                )\n\n        fig = ax.get_figure()\n        # if ax is passed and a number of subplots is 1, return ax as it is\n        if naxes == 1:\n            if squeeze:\n                return fig, ax\n            else:\n                return fig, flatten_axes(ax)\n        else:\n            warnings.warn(\n                \"To output multiple subplots, the figure containing \"\n                \"the passed axes is being cleared\",\n                UserWarning,\n                stacklevel=4,\n            )\n            fig.clear()\n\n    nrows, ncols = _get_layout(naxes, layout=layout, layout_type=layout_type)\n    nplots = nrows * ncols\n\n    # Create empty object array to hold all axes.  It's easiest to make it 1-d\n    # so we can just append subplots upon creation, and then\n    axarr = np.empty(nplots, dtype=object)\n\n    # Create first subplot separately, so we can share it if requested\n    ax0 = fig.add_subplot(nrows, ncols, 1, **subplot_kw)\n\n    if sharex:\n        subplot_kw[\"sharex\"] = ax0\n    if sharey:\n        subplot_kw[\"sharey\"] = ax0\n    axarr[0] = ax0\n\n    # Note off-by-one counting because add_subplot uses the MATLAB 1-based\n    # convention.\n    for i in range(1, nplots):\n        kwds = subplot_kw.copy()\n        # Set sharex and sharey to None for blank/dummy axes, these can\n        # interfere with proper axis limits on the visible axes if\n        # they share axes e.g. issue #7528\n        if i >= naxes:\n            kwds[\"sharex\"] = None\n            kwds[\"sharey\"] = None\n        ax = fig.add_subplot(nrows, ncols, i + 1, **kwds)\n        axarr[i] = ax\n\n    if naxes != nplots:\n        for ax in axarr[naxes:]:\n            ax.set_visible(False)\n\n    handle_shared_axes(axarr, nplots, naxes, nrows, ncols, sharex, sharey)\n\n    if squeeze:\n        # Reshape the array to have the final desired dimension (nrow,ncol),\n        # though discarding unneeded dimensions that equal 1.  If we only have\n        # one subplot, just return it instead of a 1-element array.\n        if nplots == 1:\n            axes = axarr[0]\n        else:\n            axes = axarr.reshape(nrows, ncols).squeeze()\n    else:\n        # returned axis array will be always 2-d, even if nrows=ncols=1\n        axes = axarr.reshape(nrows, ncols)\n\n    return fig, axes\n\n\ndef _remove_labels_from_axis(axis: \"Axis\"):\n    for t in axis.get_majorticklabels():\n        t.set_visible(False)\n\n    # set_visible will not be effective if\n    # minor axis has NullLocator and NullFormatter (default)\n    if isinstance(axis.get_minor_locator(), ticker.NullLocator):\n        axis.set_minor_locator(ticker.AutoLocator())\n    if isinstance(axis.get_minor_formatter(), ticker.NullFormatter):\n        axis.set_minor_formatter(ticker.FormatStrFormatter(\"\"))\n    for t in axis.get_minorticklabels():\n        t.set_visible(False)\n\n    axis.get_label().set_visible(False)\n\n\ndef _has_externally_shared_axis(ax1: \"matplotlib.axes\", compare_axis: \"str\") -> bool:\n    \"\"\"\n    Return whether an axis is externally shared.\n\n    Parameters\n    ----------\n    ax1 : matplotlib.axes\n        Axis to query.\n    compare_axis : str\n        `\"x\"` or `\"y\"` according to whether the X-axis or Y-axis is being\n        compared.\n\n    Returns\n    -------\n    bool\n        `True` if the axis is externally shared. Otherwise `False`.\n\n    Notes\n    -----\n    If two axes with different positions are sharing an axis, they can be\n    referred to as *externally* sharing the common axis.\n\n    If two axes sharing an axis also have the same position, they can be\n    referred to as *internally* sharing the common axis (a.k.a twinning).\n\n    _handle_shared_axes() is only interested in axes externally sharing an\n    axis, regardless of whether either of the axes is also internally sharing\n    with a third axis.\n    \"\"\"\n    if compare_axis == \"x\":\n        axes = ax1.get_shared_x_axes()\n    elif compare_axis == \"y\":\n        axes = ax1.get_shared_y_axes()\n    else:\n        raise ValueError(\n            \"_has_externally_shared_axis() needs 'x' or 'y' as a second parameter\"\n        )\n\n    axes = axes.get_siblings(ax1)\n\n    # Retain ax1 and any of its siblings which aren't in the same position as it\n    ax1_points = ax1.get_position().get_points()\n\n    for ax2 in axes:\n        if not np.array_equal(ax1_points, ax2.get_position().get_points()):\n            return True\n\n    return False\n\n\ndef handle_shared_axes(\n    axarr: Iterable[\"Axes\"],\n    nplots: int,\n    naxes: int,\n    nrows: int,\n    ncols: int,\n    sharex: bool,\n    sharey: bool,\n):\n    if nplots > 1:\n        if compat.mpl_ge_3_2_0():\n            row_num = lambda x: x.get_subplotspec().rowspan.start\n            col_num = lambda x: x.get_subplotspec().colspan.start\n        else:\n            row_num = lambda x: x.rowNum\n            col_num = lambda x: x.colNum\n\n        if nrows > 1:\n            try:\n                # first find out the ax layout,\n                # so that we can correctly handle 'gaps\"\n                layout = np.zeros((nrows + 1, ncols + 1), dtype=np.bool_)\n                for ax in axarr:\n                    layout[row_num(ax), col_num(ax)] = ax.get_visible()\n\n                for ax in axarr:\n                    # only the last row of subplots should get x labels -> all\n                    # other off layout handles the case that the subplot is\n                    # the last in the column, because below is no subplot/gap.\n                    if not layout[row_num(ax) + 1, col_num(ax)]:\n                        continue\n                    if sharex or _has_externally_shared_axis(ax, \"x\"):\n                        _remove_labels_from_axis(ax.xaxis)\n\n            except IndexError:\n                # if gridspec is used, ax.rowNum and ax.colNum may different\n                # from layout shape. in this case, use last_row logic\n                for ax in axarr:\n                    if ax.is_last_row():\n                        continue\n                    if sharex or _has_externally_shared_axis(ax, \"x\"):\n                        _remove_labels_from_axis(ax.xaxis)\n\n        if ncols > 1:\n            for ax in axarr:\n                # only the first column should get y labels -> set all other to\n                # off as we only have labels in the first column and we always\n                # have a subplot there, we can skip the layout test\n                if ax.is_first_col():\n                    continue\n                if sharey or _has_externally_shared_axis(ax, \"y\"):\n                    _remove_labels_from_axis(ax.yaxis)\n\n\ndef flatten_axes(axes: Union[\"Axes\", Sequence[\"Axes\"]]) -> np.ndarray:\n    if not is_list_like(axes):\n        return np.array([axes])\n    elif isinstance(axes, (np.ndarray, ABCIndex)):\n        return np.asarray(axes).ravel()\n    return np.array(axes)\n\n\ndef set_ticks_props(\n    axes: Union[\"Axes\", Sequence[\"Axes\"]],\n    xlabelsize=None,\n    xrot=None,\n    ylabelsize=None,\n    yrot=None,\n):\n    import matplotlib.pyplot as plt\n\n    for ax in flatten_axes(axes):\n        if xlabelsize is not None:\n            plt.setp(ax.get_xticklabels(), fontsize=xlabelsize)\n        if xrot is not None:\n            plt.setp(ax.get_xticklabels(), rotation=xrot)\n        if ylabelsize is not None:\n            plt.setp(ax.get_yticklabels(), fontsize=ylabelsize)\n        if yrot is not None:\n            plt.setp(ax.get_yticklabels(), rotation=yrot)\n    return axes\n\n\ndef get_all_lines(ax: \"Axes\") -> List[\"Line2D\"]:\n    lines = ax.get_lines()\n\n    if hasattr(ax, \"right_ax\"):\n        lines += ax.right_ax.get_lines()\n\n    if hasattr(ax, \"left_ax\"):\n        lines += ax.left_ax.get_lines()\n\n    return lines\n\n\ndef get_xlim(lines: Iterable[\"Line2D\"]) -> Tuple[float, float]:\n    left, right = np.inf, -np.inf\n    for line in lines:\n        x = line.get_xdata(orig=False)\n        left = min(np.nanmin(x), left)\n        right = max(np.nanmax(x), right)\n    return left, right\n"
    },
    {
      "filename": "pandas/tests/plotting/test_misc.py",
      "content": "\"\"\" Test cases for misc plot functions \"\"\"\n\nimport numpy as np\nimport pytest\n\nimport pandas.util._test_decorators as td\n\nfrom pandas import DataFrame, Series\nimport pandas._testing as tm\nfrom pandas.tests.plotting.common import TestPlotBase, _check_plot_works\n\nimport pandas.plotting as plotting\n\npytestmark = pytest.mark.slow\n\n\n@td.skip_if_mpl\ndef test_import_error_message():\n    # GH-19810\n    df = DataFrame({\"A\": [1, 2]})\n\n    with pytest.raises(ImportError, match=\"matplotlib is required for plotting\"):\n        df.plot()\n\n\ndef test_get_accessor_args():\n    func = plotting._core.PlotAccessor._get_call_args\n\n    msg = \"Called plot accessor for type list, expected Series or DataFrame\"\n    with pytest.raises(TypeError, match=msg):\n        func(backend_name=\"\", data=[], args=[], kwargs={})\n\n    msg = \"should not be called with positional arguments\"\n    with pytest.raises(TypeError, match=msg):\n        func(backend_name=\"\", data=Series(dtype=object), args=[\"line\", None], kwargs={})\n\n    x, y, kind, kwargs = func(\n        backend_name=\"\",\n        data=DataFrame(),\n        args=[\"x\"],\n        kwargs={\"y\": \"y\", \"kind\": \"bar\", \"grid\": False},\n    )\n    assert x == \"x\"\n    assert y == \"y\"\n    assert kind == \"bar\"\n    assert kwargs == {\"grid\": False}\n\n    x, y, kind, kwargs = func(\n        backend_name=\"pandas.plotting._matplotlib\",\n        data=Series(dtype=object),\n        args=[],\n        kwargs={},\n    )\n    assert x is None\n    assert y is None\n    assert kind == \"line\"\n    assert len(kwargs) == 24\n\n\n@td.skip_if_no_mpl\nclass TestSeriesPlots(TestPlotBase):\n    def setup_method(self, method):\n        TestPlotBase.setup_method(self, method)\n        import matplotlib as mpl\n\n        mpl.rcdefaults()\n\n        self.ts = tm.makeTimeSeries()\n        self.ts.name = \"ts\"\n\n    def test_autocorrelation_plot(self):\n        from pandas.plotting import autocorrelation_plot\n\n        # Ensure no UserWarning when making plot\n        with tm.assert_produces_warning(None):\n            _check_plot_works(autocorrelation_plot, series=self.ts)\n            _check_plot_works(autocorrelation_plot, series=self.ts.values)\n\n            ax = autocorrelation_plot(self.ts, label=\"Test\")\n        self._check_legend_labels(ax, labels=[\"Test\"])\n\n    def test_lag_plot(self):\n        from pandas.plotting import lag_plot\n\n        _check_plot_works(lag_plot, series=self.ts)\n        _check_plot_works(lag_plot, series=self.ts, lag=5)\n\n    def test_bootstrap_plot(self):\n        from pandas.plotting import bootstrap_plot\n\n        _check_plot_works(bootstrap_plot, series=self.ts, size=10)\n\n\n@td.skip_if_no_mpl\nclass TestDataFramePlots(TestPlotBase):\n    @td.skip_if_no_scipy\n    @pytest.mark.parametrize(\"pass_axis\", [False, True])\n    def test_scatter_matrix_axis(self, pass_axis):\n        from pandas.plotting._matplotlib.compat import mpl_ge_3_0_0\n\n        scatter_matrix = plotting.scatter_matrix\n\n        ax = None\n        if pass_axis:\n            _, ax = self.plt.subplots(3, 3)\n\n        with tm.RNGContext(42):\n            df = DataFrame(np.random.randn(100, 3))\n\n        # we are plotting multiples on a sub-plot\n        with tm.assert_produces_warning(\n            UserWarning, raise_on_extra_warnings=mpl_ge_3_0_0()\n        ):\n            axes = _check_plot_works(\n                scatter_matrix,\n                filterwarnings=\"always\",\n                frame=df,\n                range_padding=0.1,\n                ax=ax,\n            )\n        axes0_labels = axes[0][0].yaxis.get_majorticklabels()\n\n        # GH 5662\n        expected = [\"-2\", \"0\", \"2\"]\n        self._check_text_labels(axes0_labels, expected)\n        self._check_ticks_props(axes, xlabelsize=8, xrot=90, ylabelsize=8, yrot=0)\n\n        df[0] = (df[0] - 2) / 3\n\n        # we are plotting multiples on a sub-plot\n        with tm.assert_produces_warning(UserWarning):\n            axes = _check_plot_works(\n                scatter_matrix,\n                filterwarnings=\"always\",\n                frame=df,\n                range_padding=0.1,\n                ax=ax,\n            )\n        axes0_labels = axes[0][0].yaxis.get_majorticklabels()\n        expected = [\"-1.0\", \"-0.5\", \"0.0\"]\n        self._check_text_labels(axes0_labels, expected)\n        self._check_ticks_props(axes, xlabelsize=8, xrot=90, ylabelsize=8, yrot=0)\n\n    def test_andrews_curves(self, iris):\n        from matplotlib import cm\n\n        from pandas.plotting import andrews_curves\n\n        df = iris\n        # Ensure no UserWarning when making plot\n        with tm.assert_produces_warning(None):\n            _check_plot_works(andrews_curves, frame=df, class_column=\"Name\")\n\n        rgba = (\"#556270\", \"#4ECDC4\", \"#C7F464\")\n        ax = _check_plot_works(\n            andrews_curves, frame=df, class_column=\"Name\", color=rgba\n        )\n        self._check_colors(\n            ax.get_lines()[:10], linecolors=rgba, mapping=df[\"Name\"][:10]\n        )\n\n        cnames = [\"dodgerblue\", \"aquamarine\", \"seagreen\"]\n        ax = _check_plot_works(\n            andrews_curves, frame=df, class_column=\"Name\", color=cnames\n        )\n        self._check_colors(\n            ax.get_lines()[:10], linecolors=cnames, mapping=df[\"Name\"][:10]\n        )\n\n        ax = _check_plot_works(\n            andrews_curves, frame=df, class_column=\"Name\", colormap=cm.jet\n        )\n        cmaps = [cm.jet(n) for n in np.linspace(0, 1, df[\"Name\"].nunique())]\n        self._check_colors(\n            ax.get_lines()[:10], linecolors=cmaps, mapping=df[\"Name\"][:10]\n        )\n\n        length = 10\n        df = DataFrame(\n            {\n                \"A\": np.random.rand(length),\n                \"B\": np.random.rand(length),\n                \"C\": np.random.rand(length),\n                \"Name\": [\"A\"] * length,\n            }\n        )\n\n        _check_plot_works(andrews_curves, frame=df, class_column=\"Name\")\n\n        rgba = (\"#556270\", \"#4ECDC4\", \"#C7F464\")\n        ax = _check_plot_works(\n            andrews_curves, frame=df, class_column=\"Name\", color=rgba\n        )\n        self._check_colors(\n            ax.get_lines()[:10], linecolors=rgba, mapping=df[\"Name\"][:10]\n        )\n\n        cnames = [\"dodgerblue\", \"aquamarine\", \"seagreen\"]\n        ax = _check_plot_works(\n            andrews_curves, frame=df, class_column=\"Name\", color=cnames\n        )\n        self._check_colors(\n            ax.get_lines()[:10], linecolors=cnames, mapping=df[\"Name\"][:10]\n        )\n\n        ax = _check_plot_works(\n            andrews_curves, frame=df, class_column=\"Name\", colormap=cm.jet\n        )\n        cmaps = [cm.jet(n) for n in np.linspace(0, 1, df[\"Name\"].nunique())]\n        self._check_colors(\n            ax.get_lines()[:10], linecolors=cmaps, mapping=df[\"Name\"][:10]\n        )\n\n        colors = [\"b\", \"g\", \"r\"]\n        df = DataFrame({\"A\": [1, 2, 3], \"B\": [1, 2, 3], \"C\": [1, 2, 3], \"Name\": colors})\n        ax = andrews_curves(df, \"Name\", color=colors)\n        handles, labels = ax.get_legend_handles_labels()\n        self._check_colors(handles, linecolors=colors)\n\n    def test_parallel_coordinates(self, iris):\n        from matplotlib import cm\n\n        from pandas.plotting import parallel_coordinates\n\n        df = iris\n\n        ax = _check_plot_works(parallel_coordinates, frame=df, class_column=\"Name\")\n        nlines = len(ax.get_lines())\n        nxticks = len(ax.xaxis.get_ticklabels())\n\n        rgba = (\"#556270\", \"#4ECDC4\", \"#C7F464\")\n        ax = _check_plot_works(\n            parallel_coordinates, frame=df, class_column=\"Name\", color=rgba\n        )\n        self._check_colors(\n            ax.get_lines()[:10], linecolors=rgba, mapping=df[\"Name\"][:10]\n        )\n\n        cnames = [\"dodgerblue\", \"aquamarine\", \"seagreen\"]\n        ax = _check_plot_works(\n            parallel_coordinates, frame=df, class_column=\"Name\", color=cnames\n        )\n        self._check_colors(\n            ax.get_lines()[:10], linecolors=cnames, mapping=df[\"Name\"][:10]\n        )\n\n        ax = _check_plot_works(\n            parallel_coordinates, frame=df, class_column=\"Name\", colormap=cm.jet\n        )\n        cmaps = [cm.jet(n) for n in np.linspace(0, 1, df[\"Name\"].nunique())]\n        self._check_colors(\n            ax.get_lines()[:10], linecolors=cmaps, mapping=df[\"Name\"][:10]\n        )\n\n        ax = _check_plot_works(\n            parallel_coordinates, frame=df, class_column=\"Name\", axvlines=False\n        )\n        assert len(ax.get_lines()) == (nlines - nxticks)\n\n        colors = [\"b\", \"g\", \"r\"]\n        df = DataFrame({\"A\": [1, 2, 3], \"B\": [1, 2, 3], \"C\": [1, 2, 3], \"Name\": colors})\n        ax = parallel_coordinates(df, \"Name\", color=colors)\n        handles, labels = ax.get_legend_handles_labels()\n        self._check_colors(handles, linecolors=colors)\n\n    # not sure if this is indicative of a problem\n    @pytest.mark.filterwarnings(\"ignore:Attempting to set:UserWarning\")\n    def test_parallel_coordinates_with_sorted_labels(self):\n        \"\"\" For #15908 \"\"\"\n        from pandas.plotting import parallel_coordinates\n\n        df = DataFrame(\n            {\n                \"feat\": list(range(30)),\n                \"class\": [2 for _ in range(10)]\n                + [3 for _ in range(10)]\n                + [1 for _ in range(10)],\n            }\n        )\n        ax = parallel_coordinates(df, \"class\", sort_labels=True)\n        polylines, labels = ax.get_legend_handles_labels()\n        color_label_tuples = zip(\n            [polyline.get_color() for polyline in polylines], labels\n        )\n        ordered_color_label_tuples = sorted(color_label_tuples, key=lambda x: x[1])\n        prev_next_tupels = zip(\n            list(ordered_color_label_tuples[0:-1]), list(ordered_color_label_tuples[1:])\n        )\n        for prev, nxt in prev_next_tupels:\n            # labels and colors are ordered strictly increasing\n            assert prev[1] < nxt[1] and prev[0] < nxt[0]\n\n    def test_radviz(self, iris):\n        from matplotlib import cm\n\n        from pandas.plotting import radviz\n\n        df = iris\n        # Ensure no UserWarning when making plot\n        with tm.assert_produces_warning(None):\n            _check_plot_works(radviz, frame=df, class_column=\"Name\")\n\n        rgba = (\"#556270\", \"#4ECDC4\", \"#C7F464\")\n        ax = _check_plot_works(radviz, frame=df, class_column=\"Name\", color=rgba)\n        # skip Circle drawn as ticks\n        patches = [p for p in ax.patches[:20] if p.get_label() != \"\"]\n        self._check_colors(patches[:10], facecolors=rgba, mapping=df[\"Name\"][:10])\n\n        cnames = [\"dodgerblue\", \"aquamarine\", \"seagreen\"]\n        _check_plot_works(radviz, frame=df, class_column=\"Name\", color=cnames)\n        patches = [p for p in ax.patches[:20] if p.get_label() != \"\"]\n        self._check_colors(patches, facecolors=cnames, mapping=df[\"Name\"][:10])\n\n        _check_plot_works(radviz, frame=df, class_column=\"Name\", colormap=cm.jet)\n        cmaps = [cm.jet(n) for n in np.linspace(0, 1, df[\"Name\"].nunique())]\n        patches = [p for p in ax.patches[:20] if p.get_label() != \"\"]\n        self._check_colors(patches, facecolors=cmaps, mapping=df[\"Name\"][:10])\n\n        colors = [[0.0, 0.0, 1.0, 1.0], [0.0, 0.5, 1.0, 1.0], [1.0, 0.0, 0.0, 1.0]]\n        df = DataFrame(\n            {\"A\": [1, 2, 3], \"B\": [2, 1, 3], \"C\": [3, 2, 1], \"Name\": [\"b\", \"g\", \"r\"]}\n        )\n        ax = radviz(df, \"Name\", color=colors)\n        handles, labels = ax.get_legend_handles_labels()\n        self._check_colors(handles, facecolors=colors)\n\n    def test_subplot_titles(self, iris):\n        df = iris.drop(\"Name\", axis=1).head()\n        # Use the column names as the subplot titles\n        title = list(df.columns)\n\n        # Case len(title) == len(df)\n        plot = df.plot(subplots=True, title=title)\n        assert [p.get_title() for p in plot] == title\n\n        # Case len(title) > len(df)\n        msg = (\n            \"The length of `title` must equal the number of columns if \"\n            \"using `title` of type `list` and `subplots=True`\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            df.plot(subplots=True, title=title + [\"kittens > puppies\"])\n\n        # Case len(title) < len(df)\n        with pytest.raises(ValueError, match=msg):\n            df.plot(subplots=True, title=title[:2])\n\n        # Case subplots=False and title is of type list\n        msg = (\n            \"Using `title` of type `list` is not supported unless \"\n            \"`subplots=True` is passed\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            df.plot(subplots=False, title=title)\n\n        # Case df with 3 numeric columns but layout of (2,2)\n        plot = df.drop(\"SepalWidth\", axis=1).plot(\n            subplots=True, layout=(2, 2), title=title[:-1]\n        )\n        title_list = [ax.get_title() for sublist in plot for ax in sublist]\n        assert title_list == title[:3] + [\"\"]\n\n    def test_get_standard_colors_random_seed(self):\n        # GH17525\n        df = DataFrame(np.zeros((10, 10)))\n\n        # Make sure that the np.random.seed isn't reset by get_standard_colors\n        plotting.parallel_coordinates(df, 0)\n        rand1 = np.random.random()\n        plotting.parallel_coordinates(df, 0)\n        rand2 = np.random.random()\n        assert rand1 != rand2\n\n        # Make sure it produces the same colors every time it's called\n        from pandas.plotting._matplotlib.style import get_standard_colors\n\n        color1 = get_standard_colors(1, color_type=\"random\")\n        color2 = get_standard_colors(1, color_type=\"random\")\n        assert color1 == color2\n\n    def test_get_standard_colors_default_num_colors(self):\n        from pandas.plotting._matplotlib.style import get_standard_colors\n\n        # Make sure the default color_types returns the specified amount\n        color1 = get_standard_colors(1, color_type=\"default\")\n        color2 = get_standard_colors(9, color_type=\"default\")\n        color3 = get_standard_colors(20, color_type=\"default\")\n        assert len(color1) == 1\n        assert len(color2) == 9\n        assert len(color3) == 20\n\n    def test_plot_single_color(self):\n        # Example from #20585. All 3 bars should have the same color\n        df = DataFrame(\n            {\n                \"account-start\": [\"2017-02-03\", \"2017-03-03\", \"2017-01-01\"],\n                \"client\": [\"Alice Anders\", \"Bob Baker\", \"Charlie Chaplin\"],\n                \"balance\": [-1432.32, 10.43, 30000.00],\n                \"db-id\": [1234, 2424, 251],\n                \"proxy-id\": [525, 1525, 2542],\n                \"rank\": [52, 525, 32],\n            }\n        )\n        ax = df.client.value_counts().plot.bar()\n        colors = [rect.get_facecolor() for rect in ax.get_children()[0:3]]\n        assert all(color == colors[0] for color in colors)\n\n    def test_get_standard_colors_no_appending(self):\n        # GH20726\n\n        # Make sure not to add more colors so that matplotlib can cycle\n        # correctly.\n        from matplotlib import cm\n\n        from pandas.plotting._matplotlib.style import get_standard_colors\n\n        color_before = cm.gnuplot(range(5))\n        color_after = get_standard_colors(1, color=color_before)\n        assert len(color_after) == len(color_before)\n\n        df = DataFrame(np.random.randn(48, 4), columns=list(\"ABCD\"))\n\n        color_list = cm.gnuplot(np.linspace(0, 1, 16))\n        p = df.A.plot.bar(figsize=(16, 7), color=color_list)\n        assert p.patches[1].get_facecolor() == p.patches[17].get_facecolor()\n\n    def test_dictionary_color(self):\n        # issue-8193\n        # Test plot color dictionary format\n        data_files = [\"a\", \"b\"]\n\n        expected = [(0.5, 0.24, 0.6), (0.3, 0.7, 0.7)]\n\n        df1 = DataFrame(np.random.rand(2, 2), columns=data_files)\n        dic_color = {\"b\": (0.3, 0.7, 0.7), \"a\": (0.5, 0.24, 0.6)}\n\n        # Bar color test\n        ax = df1.plot(kind=\"bar\", color=dic_color)\n        colors = [rect.get_facecolor()[0:-1] for rect in ax.get_children()[0:3:2]]\n        assert all(color == expected[index] for index, color in enumerate(colors))\n\n        # Line color test\n        ax = df1.plot(kind=\"line\", color=dic_color)\n        colors = [rect.get_color() for rect in ax.get_lines()[0:2]]\n        assert all(color == expected[index] for index, color in enumerate(colors))\n\n    def test_has_externally_shared_axis_x_axis(self):\n        # GH33819\n        # Test _has_externally_shared_axis() works for x-axis\n        func = plotting._matplotlib.tools._has_externally_shared_axis\n\n        fig = self.plt.figure()\n        plots = fig.subplots(2, 4)\n\n        # Create *externally* shared axes for first and third columns\n        plots[0][0] = fig.add_subplot(231, sharex=plots[1][0])\n        plots[0][2] = fig.add_subplot(233, sharex=plots[1][2])\n\n        # Create *internally* shared axes for second and third columns\n        plots[0][1].twinx()\n        plots[0][2].twinx()\n\n        # First  column is only externally shared\n        # Second column is only internally shared\n        # Third  column is both\n        # Fourth column is neither\n        assert func(plots[0][0], \"x\")\n        assert not func(plots[0][1], \"x\")\n        assert func(plots[0][2], \"x\")\n        assert not func(plots[0][3], \"x\")\n\n    def test_has_externally_shared_axis_y_axis(self):\n        # GH33819\n        # Test _has_externally_shared_axis() works for y-axis\n        func = plotting._matplotlib.tools._has_externally_shared_axis\n\n        fig = self.plt.figure()\n        plots = fig.subplots(4, 2)\n\n        # Create *externally* shared axes for first and third rows\n        plots[0][0] = fig.add_subplot(321, sharey=plots[0][1])\n        plots[2][0] = fig.add_subplot(325, sharey=plots[2][1])\n\n        # Create *internally* shared axes for second and third rows\n        plots[1][0].twiny()\n        plots[2][0].twiny()\n\n        # First  row is only externally shared\n        # Second row is only internally shared\n        # Third  row is both\n        # Fourth row is neither\n        assert func(plots[0][0], \"y\")\n        assert not func(plots[1][0], \"y\")\n        assert func(plots[2][0], \"y\")\n        assert not func(plots[3][0], \"y\")\n\n    def test_has_externally_shared_axis_invalid_compare_axis(self):\n        # GH33819\n        # Test _has_externally_shared_axis() raises an exception when\n        # passed an invalid value as compare_axis parameter\n        func = plotting._matplotlib.tools._has_externally_shared_axis\n\n        fig = self.plt.figure()\n        plots = fig.subplots(4, 2)\n\n        # Create arbitrary axes\n        plots[0][0] = fig.add_subplot(321, sharey=plots[0][1])\n\n        # Check that an invalid compare_axis value triggers the expected exception\n        msg = \"needs 'x' or 'y' as a second parameter\"\n        with pytest.raises(ValueError, match=msg):\n            func(plots[0][0], \"z\")\n\n    def test_externally_shared_axes(self):\n        # Example from GH33819\n        # Create data\n        df = DataFrame({\"a\": np.random.randn(1000), \"b\": np.random.randn(1000)})\n\n        # Create figure\n        fig = self.plt.figure()\n        plots = fig.subplots(2, 3)\n\n        # Create *externally* shared axes\n        plots[0][0] = fig.add_subplot(231, sharex=plots[1][0])\n        # note: no plots[0][1] that's the twin only case\n        plots[0][2] = fig.add_subplot(233, sharex=plots[1][2])\n\n        # Create *internally* shared axes\n        # note: no plots[0][0] that's the external only case\n        twin_ax1 = plots[0][1].twinx()\n        twin_ax2 = plots[0][2].twinx()\n\n        # Plot data to primary axes\n        df[\"a\"].plot(ax=plots[0][0], title=\"External share only\").set_xlabel(\n            \"this label should never be visible\"\n        )\n        df[\"a\"].plot(ax=plots[1][0])\n\n        df[\"a\"].plot(ax=plots[0][1], title=\"Internal share (twin) only\").set_xlabel(\n            \"this label should always be visible\"\n        )\n        df[\"a\"].plot(ax=plots[1][1])\n\n        df[\"a\"].plot(ax=plots[0][2], title=\"Both\").set_xlabel(\n            \"this label should never be visible\"\n        )\n        df[\"a\"].plot(ax=plots[1][2])\n\n        # Plot data to twinned axes\n        df[\"b\"].plot(ax=twin_ax1, color=\"green\")\n        df[\"b\"].plot(ax=twin_ax2, color=\"yellow\")\n\n        assert not plots[0][0].xaxis.get_label().get_visible()\n        assert plots[0][1].xaxis.get_label().get_visible()\n        assert not plots[0][2].xaxis.get_label().get_visible()\n"
    }
  ],
  "questions": [
    "Should we actually recommend that? It's a quite complex line of cli code, and if you are using pre-commit, I suppose you will typically use it as a git commit hook?",
    "Is it more complicated than the current `flake8` line\r\n```\r\ngit diff upstream/master -u -- \"*.py\" | flake8 --diff\r\n```\r\n?\r\n\r\nThe command I posted gives you a cross-platform way of running all the CI code quality checks, with all the right package versions, only on the files which you've changed. You can run it even if you don't use pre-commit as a git commit hook",
    "> Is it more complicated than the current flake8 line\r\n\r\nNo, but if someone proposed to *add* that line to the template (if it wasn't there yet), I would probably raise the same concern ;-) \r\nAnd I personally also never ever used that flake8 line in practice ..\r\n\r\nI am basically wondering how many of our core / regular contributors are using that. And if almost no one does (*if*! I don't know that, to be clear), not sure it should be the first thing to have contributors see when opening a PR.\r\n\r\n> The command I posted gives you a cross-platform way of running all the CI code quality checks, with all the right package versions, only on the files which you've changed. You can run it even if you don't use pre-commit as a git commit hook\r\n\r\nYes, and that sounds valuable in certain cases. \r\nBut then we should probably also add that to and explain it in the contributing docs? \r\n\r\nMaybe a general \"Ensure all linting tests pass, see here how to run them\" with a link to a clear overview in the contributing guide on (different ways) how you can run the linting might be more useful? It's more clicking, but it migth also be less scary as such a complex command without much context."
  ],
  "golden_answers": [
    "Is it more complicated than the current `flake8` line\r\n```\r\ngit diff upstream/master -u -- \"*.py\" | flake8 --diff\r\n```\r\n?\r\n\r\nThe command I posted gives you a cross-platform way of running all the CI code quality checks, with all the right package versions, only on the files which you've changed. You can run it even if you don't use pre-commit as a git commit hook",
    "OK, thanks for explaning :smile: \r\n\r\n> Maybe a general \"Ensure all linting tests pass, see here how to run them\" with a link to a clear overview in the contributing guide on (different ways) how you can run the linting might be more useful?\r\n\r\nSure, sounds good - I think there could be a link to https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#code-standards , and there this command could be put in place of `./ci/code_checks.sh` (which won't work on Windows and doesn't include all checks), with a short explanation of what it does (i.e. it runs all the code quality checks on all files which have changed between the current commit and `upstream/master`)",
    "OK, thanks for explaning :smile: \r\n\r\n> Maybe a general \"Ensure all linting tests pass, see here how to run them\" with a link to a clear overview in the contributing guide on (different ways) how you can run the linting might be more useful?\r\n\r\nSure, sounds good - I think there could be a link to https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#code-standards , and there this command could be put in place of `./ci/code_checks.sh` (which won't work on Windows and doesn't include all checks), with a short explanation of what it does (i.e. it runs all the code quality checks on all files which have changed between the current commit and `upstream/master`)"
  ],
  "questions_generated": [
    "What is the purpose of adding the 'pre-commit run --from-ref=upstream/master --to-ref=HEAD --all-files' command to the pull request template in the pandas repository?",
    "How does the suggested 'pre-commit' command differ from the existing 'flake8 --diff' command in the pull request template?",
    "Why might there be concerns about adding complex CLI commands to the pull request template, as discussed in the issue?",
    "What file needs to be updated to include the new 'pre-commit' command in the pull request template for the pandas repository?",
    "What additional documentation changes might be necessary if the 'pre-commit' command is added to the pull request template?"
  ],
  "golden_answers_generated": [
    "The purpose of adding this command is to ensure that all CI code quality checks are run with the correct package versions on all files changed in a pull request. This provides a cross-platform way to maintain code quality without requiring contributors to use pre-commit as a git commit hook.",
    "The suggested 'pre-commit' command runs all CI code quality checks on files changed between the upstream master and the current HEAD, ensuring that all checks are applied consistently. In contrast, the 'flake8 --diff' command specifically targets Python files that have changed and checks them for style errors. The 'pre-commit' command is more comprehensive as it encompasses multiple checks, not just style errors.",
    "There are concerns about adding complex CLI commands to the pull request template because they may be difficult for new contributors to understand and use correctly. It could discourage participation or lead to errors if contributors are not familiar with the command's purpose or how to execute it properly. Therefore, it might be better to provide a link to detailed instructions in the contributing guide.",
    "The file that needs to be updated is '.github/PULL_REQUEST_TEMPLATE.md'. This file contains the template used for creating pull requests in the repository, and it will be modified to include the new 'pre-commit' command.",
    "If the 'pre-commit' command is added to the pull request template, it may also be necessary to update the contributing guide. This would involve revising any sections that mention the 'flake8 --diff' command and providing clear instructions on how to use the 'pre-commit' command. This helps ensure that all contributors understand the new process for running code quality checks."
  ]
}