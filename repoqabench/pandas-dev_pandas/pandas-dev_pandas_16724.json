{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "16724",
  "issue_description": "# Unexpected result when setting a row by a dict\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\n\r\npersons = [\r\n    {\r\n        'name': ''.join([\r\n            np.random.choice([chr(x) for x in range(97, 97 + 26)])\r\n            for i in range(5)\r\n        ]),\r\n        'age': np.random.randint(0, 100),\r\n        'sex': np.random.choice(['male', 'female']),\r\n        'job': np.random.choice(['staff', 'cook', 'student']),\r\n        'birthday': np.random.choice(pd.date_range('1990-01-01', '2010-01-01')),\r\n        'hobby': np.random.choice(['cs', 'war3', 'dota'])\r\n    }\r\n    for i in range(10)\r\n]\r\n\r\ndf = pd.DataFrame(persons)\r\ndf.set_index('birthday', inplace=True)\r\nprint(df)\r\ndf.iloc[0] = {\r\n    'name': 'john',\r\n    'age': int(10),\r\n    'sex': 'male',\r\n    'hobby': 'nohobby',\r\n    'job': 'haha'\r\n}\r\nprint(df)\r\n```\r\n#### Problem description\r\n\r\n```\r\n             age hobby      job   name     sex\r\nbirthday\r\n2007-12-31  name   age      sex  hobby     job\r\n2004-07-31    20  dota  student  uwxhn  female\r\n2001-10-22    34  war3     cook  udknv  female\r\n2002-10-13    91  dota     cook  bofcv  female\r\n1992-05-25    54  war3     cook  tcqew    male\r\n2009-09-02    95  war3    staff  jcolr  female\r\n1998-12-15    61  war3  student  dibkw  female\r\n2004-07-03     4  war3  student  mntqh    male\r\n2000-06-08    88  war3    staff  jknxm  female\r\n2006-10-19    82    cs  student  asrpz    male\r\n\r\n```\r\n\r\nHave no idea why the keys are set to the rows.\r\n\r\n#### Expected Output\r\n```\r\n             age hobby      job   name     sex\r\nbirthday  \r\n2007-12-31    10 nohobby  haha john male\r\n2004-07-31    20  dota  student  uwxhn  female\r\n2001-10-22    34  war3     cook  udknv  female\r\n2002-10-13    91  dota     cook  bofcv  female\r\n1992-05-25    54  war3     cook  tcqew    male\r\n2009-09-02    95  war3    staff  jcolr  female\r\n1998-12-15    61  war3  student  dibkw  female\r\n2004-07-03     4  war3  student  mntqh    male\r\n2000-06-08    88  war3    staff  jknxm  female\r\n2006-10-19    82    cs  student  asrpz    male\r\n```\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.1.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 16.6.0\r\nmachine: x86_64\r\nprocessor: i386\r\nbyteorder: little\r\nLC_ALL: en_US.UTF-8\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.20.1\r\npytest: 3.0.7\r\npip: 9.0.1\r\nsetuptools: 35.0.2\r\nCython: 0.25.2\r\nnumpy: 1.12.1\r\nscipy: 0.19.0\r\nxarray: 0.9.5\r\nIPython: 6.0.0\r\nsphinx: 1.5.5\r\npatsy: 0.4.1\r\ndateutil: 2.6.0\r\npytz: 2017.2\r\nblosc: None\r\nbottleneck: 1.2.0\r\ntables: 3.4.2\r\nnumexpr: 2.6.2\r\nfeather: None\r\nmatplotlib: 2.0.2\r\nopenpyxl: 2.4.7\r\nxlrd: 1.0.0\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: 3.7.3\r\nbs4: 4.6.0\r\nhtml5lib: 0.999999999\r\nsqlalchemy: 1.1.9\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.6\r\ns3fs: None\r\npandas_gbq: None\r\npandas_datareader: None\r\n</details>\r\n",
  "issue_comments": [
    {
      "id": 309425528,
      "user": "TomAugspurger",
      "body": "Hmm, all our setting code deals with iterables, which means the `.keys()` for a dictionary. The only caveat is that Series and DataFrames are aligned before setting.\r\n\r\nI'll let Jeff weigh in, but I don't think we'll want to support this. If you want that behavior, you'll need to pass the dictionary to a `pd.Series` first."
    },
    {
      "id": 309426555,
      "user": "Yevgnen",
      "body": "Thanks for your reply. I think if this will not be supported, I think the example in the [document](http://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access) should be removed for reducing confusion.ðŸ˜…"
    },
    {
      "id": 309428040,
      "user": "TomAugspurger",
      "body": "Your example probably should work then, my mistake. It seems like we don't probably set when there are multiple dtypes?\r\n\r\n```python\r\n# two dtypes\r\nIn [44]: x = pd.DataFrame({'x': [1, 2, 3], 'y': ['3', '4', '5']})\r\n\r\nIn [46]: x.iloc[1] = {'x': 9, 'y': '99'}\r\n\r\nIn [47]: x  # set incorrectly with the keys\r\nOut[47]:\r\n   x  y\r\n0  1  3\r\n1  x  y\r\n2  3  5\r\n\r\n# single dtype\r\nIn [48]: x = pd.DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})\r\n\r\nIn [49]: x.iloc[1] = {'x': 9, 'y': 99}\r\n\r\nIn [50]: x  # sets correctly\r\nOut[50]:\r\n   x   y\r\n0  1   3\r\n1  9  99\r\n2  3   5\r\n```"
    },
    {
      "id": 309428759,
      "user": "Yevgnen",
      "body": "Probably. :-)"
    },
    {
      "id": 309495178,
      "user": "jorisvandenbossche",
      "body": "The ability to do this is certainly deliberate (I mean assigning with a dict, not the fact that it uses the keys instead of values), although I am not sure I am too happy about that :-) (way too many corner cases that come up by allowing this, eg https://github.com/pandas-dev/pandas/issues/10219)\r\n\r\nI thought there has been some related discussion about this recently, but only find https://github.com/pandas-dev/pandas/issues/16309, \r\n\r\n(side note: it's would maybe be worth opening a discussion whether we would want to deprecate this?)"
    },
    {
      "id": 309591826,
      "user": "jreback",
      "body": "I don't think this is inconsistent with setting with a ``Series``, in fact this *does* work when setting with a Series. I suppose this should work. Special casing things is not generally a good thing."
    },
    {
      "id": 550030572,
      "user": "oguzhanogreden",
      "body": "~FYI, I'm planning to give this a go soon.~"
    },
    {
      "id": 554782577,
      "user": "oguzhanogreden",
      "body": "This fails since dict is [considered a list-like](https://github.com/pandas-dev/pandas/blob/master/pandas/tests/dtypes/test_inference.py#L70) and the reported cases is handled under the assumption that it's a list, [here](https://github.com/pandas-dev/pandas/blob/master/pandas/core/indexing.py#L495).\r\n\r\nI find the `follow_split_path==True` path and the conditionals [here](https://github.com/pandas-dev/pandas/blob/master/pandas/core/indexing.py#L495-L549) quite hard to follow. If we can assume that `_can_do_equal_len` will return `False` for the case described here (and variations of it), the solution is simply distinguishing a `dict` from a `list-like` in the `else` case.\r\n\r\nI found some discussions [here](https://github.com/pandas-dev/pandas/pull/10838#discussion_r302728324) but couldn't crack it yet."
    },
    {
      "id": 559586198,
      "user": "jorisvandenbossche",
      "body": "Duplicate report: https://github.com/pandas-dev/pandas/issues/29917"
    },
    {
      "id": 859990121,
      "user": "mroeschke",
      "body": "This looks to work on master. Could use a test\r\n\r\n```\r\nIn [1]: In [48]: x = pd.DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})\r\n   ...:\r\n   ...: In [49]: x.iloc[1] = {'x': 9, 'y': 99}\r\n\r\nIn [2]: x\r\nOut[2]:\r\n   x   y\r\n0  1   3\r\n1  9  99\r\n2  3   5\r\n```"
    },
    {
      "id": 955628063,
      "user": "mroeschke",
      "body": "Looks like there's a test for this issue: `test_iloc_setitem_dictionary_value`. Closing"
    }
  ],
  "text_context": "# Unexpected result when setting a row by a dict\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\n\r\npersons = [\r\n    {\r\n        'name': ''.join([\r\n            np.random.choice([chr(x) for x in range(97, 97 + 26)])\r\n            for i in range(5)\r\n        ]),\r\n        'age': np.random.randint(0, 100),\r\n        'sex': np.random.choice(['male', 'female']),\r\n        'job': np.random.choice(['staff', 'cook', 'student']),\r\n        'birthday': np.random.choice(pd.date_range('1990-01-01', '2010-01-01')),\r\n        'hobby': np.random.choice(['cs', 'war3', 'dota'])\r\n    }\r\n    for i in range(10)\r\n]\r\n\r\ndf = pd.DataFrame(persons)\r\ndf.set_index('birthday', inplace=True)\r\nprint(df)\r\ndf.iloc[0] = {\r\n    'name': 'john',\r\n    'age': int(10),\r\n    'sex': 'male',\r\n    'hobby': 'nohobby',\r\n    'job': 'haha'\r\n}\r\nprint(df)\r\n```\r\n#### Problem description\r\n\r\n```\r\n             age hobby      job   name     sex\r\nbirthday\r\n2007-12-31  name   age      sex  hobby     job\r\n2004-07-31    20  dota  student  uwxhn  female\r\n2001-10-22    34  war3     cook  udknv  female\r\n2002-10-13    91  dota     cook  bofcv  female\r\n1992-05-25    54  war3     cook  tcqew    male\r\n2009-09-02    95  war3    staff  jcolr  female\r\n1998-12-15    61  war3  student  dibkw  female\r\n2004-07-03     4  war3  student  mntqh    male\r\n2000-06-08    88  war3    staff  jknxm  female\r\n2006-10-19    82    cs  student  asrpz    male\r\n\r\n```\r\n\r\nHave no idea why the keys are set to the rows.\r\n\r\n#### Expected Output\r\n```\r\n             age hobby      job   name     sex\r\nbirthday  \r\n2007-12-31    10 nohobby  haha john male\r\n2004-07-31    20  dota  student  uwxhn  female\r\n2001-10-22    34  war3     cook  udknv  female\r\n2002-10-13    91  dota     cook  bofcv  female\r\n1992-05-25    54  war3     cook  tcqew    male\r\n2009-09-02    95  war3    staff  jcolr  female\r\n1998-12-15    61  war3  student  dibkw  female\r\n2004-07-03     4  war3  student  mntqh    male\r\n2000-06-08    88  war3    staff  jknxm  female\r\n2006-10-19    82    cs  student  asrpz    male\r\n```\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.1.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 16.6.0\r\nmachine: x86_64\r\nprocessor: i386\r\nbyteorder: little\r\nLC_ALL: en_US.UTF-8\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.20.1\r\npytest: 3.0.7\r\npip: 9.0.1\r\nsetuptools: 35.0.2\r\nCython: 0.25.2\r\nnumpy: 1.12.1\r\nscipy: 0.19.0\r\nxarray: 0.9.5\r\nIPython: 6.0.0\r\nsphinx: 1.5.5\r\npatsy: 0.4.1\r\ndateutil: 2.6.0\r\npytz: 2017.2\r\nblosc: None\r\nbottleneck: 1.2.0\r\ntables: 3.4.2\r\nnumexpr: 2.6.2\r\nfeather: None\r\nmatplotlib: 2.0.2\r\nopenpyxl: 2.4.7\r\nxlrd: 1.0.0\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: 3.7.3\r\nbs4: 4.6.0\r\nhtml5lib: 0.999999999\r\nsqlalchemy: 1.1.9\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.6\r\ns3fs: None\r\npandas_gbq: None\r\npandas_datareader: None\r\n</details>\r\n\n\nHmm, all our setting code deals with iterables, which means the `.keys()` for a dictionary. The only caveat is that Series and DataFrames are aligned before setting.\r\n\r\nI'll let Jeff weigh in, but I don't think we'll want to support this. If you want that behavior, you'll need to pass the dictionary to a `pd.Series` first.\n\nThanks for your reply. I think if this will not be supported, I think the example in the [document](http://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access) should be removed for reducing confusion.ðŸ˜…\n\nYour example probably should work then, my mistake. It seems like we don't probably set when there are multiple dtypes?\r\n\r\n```python\r\n# two dtypes\r\nIn [44]: x = pd.DataFrame({'x': [1, 2, 3], 'y': ['3', '4', '5']})\r\n\r\nIn [46]: x.iloc[1] = {'x': 9, 'y': '99'}\r\n\r\nIn [47]: x  # set incorrectly with the keys\r\nOut[47]:\r\n   x  y\r\n0  1  3\r\n1  x  y\r\n2  3  5\r\n\r\n# single dtype\r\nIn [48]: x = pd.DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})\r\n\r\nIn [49]: x.iloc[1] = {'x': 9, 'y': 99}\r\n\r\nIn [50]: x  # sets correctly\r\nOut[50]:\r\n   x   y\r\n0  1   3\r\n1  9  99\r\n2  3   5\r\n```\n\nProbably. :-)\n\nThe ability to do this is certainly deliberate (I mean assigning with a dict, not the fact that it uses the keys instead of values), although I am not sure I am too happy about that :-) (way too many corner cases that come up by allowing this, eg https://github.com/pandas-dev/pandas/issues/10219)\r\n\r\nI thought there has been some related discussion about this recently, but only find https://github.com/pandas-dev/pandas/issues/16309, \r\n\r\n(side note: it's would maybe be worth opening a discussion whether we would want to deprecate this?)\n\nI don't think this is inconsistent with setting with a ``Series``, in fact this *does* work when setting with a Series. I suppose this should work. Special casing things is not generally a good thing.\n\n~FYI, I'm planning to give this a go soon.~\n\nThis fails since dict is [considered a list-like](https://github.com/pandas-dev/pandas/blob/master/pandas/tests/dtypes/test_inference.py#L70) and the reported cases is handled under the assumption that it's a list, [here](https://github.com/pandas-dev/pandas/blob/master/pandas/core/indexing.py#L495).\r\n\r\nI find the `follow_split_path==True` path and the conditionals [here](https://github.com/pandas-dev/pandas/blob/master/pandas/core/indexing.py#L495-L549) quite hard to follow. If we can assume that `_can_do_equal_len` will return `False` for the case described here (and variations of it), the solution is simply distinguishing a `dict` from a `list-like` in the `else` case.\r\n\r\nI found some discussions [here](https://github.com/pandas-dev/pandas/pull/10838#discussion_r302728324) but couldn't crack it yet.\n\nDuplicate report: https://github.com/pandas-dev/pandas/issues/29917\n\nThis looks to work on master. Could use a test\r\n\r\n```\r\nIn [1]: In [48]: x = pd.DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})\r\n   ...:\r\n   ...: In [49]: x.iloc[1] = {'x': 9, 'y': 99}\r\n\r\nIn [2]: x\r\nOut[2]:\r\n   x   y\r\n0  1   3\r\n1  9  99\r\n2  3   5\r\n```\n\nLooks like there's a test for this issue: `test_iloc_setitem_dictionary_value`. Closing",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/10838",
  "code_context": [
    {
      "filename": "pandas/core/indexing.py",
      "content": "# pylint: disable=W0223\n\nfrom pandas.core.index import Index, MultiIndex\nfrom pandas.compat import range, zip\nimport pandas.compat as compat\nimport pandas.core.common as com\nfrom pandas.core.common import (is_bool_indexer, is_integer_dtype,\n                                _asarray_tuplesafe, is_list_like, isnull,\n                                is_null_slice, is_full_slice,\n                                ABCSeries, ABCDataFrame, ABCPanel, is_float,\n                                _values_from_object, _infer_fill_value, is_integer)\nimport numpy as np\n\n# the supported indexers\ndef get_indexers_list():\n\n    return [\n        ('ix',   _IXIndexer),\n        ('iloc', _iLocIndexer),\n        ('loc',  _LocIndexer),\n        ('at',   _AtIndexer),\n        ('iat',  _iAtIndexer),\n    ]\n\n# \"null slice\"\n_NS = slice(None, None)\n\n# the public IndexSlicerMaker\nclass _IndexSlice(object):\n    def __getitem__(self, arg):\n        return arg\nIndexSlice = _IndexSlice()\n\nclass IndexingError(Exception):\n    pass\n\nclass _NDFrameIndexer(object):\n    _valid_types = None\n    _exception = KeyError\n\n    def __init__(self, obj, name):\n        self.obj = obj\n        self.ndim = obj.ndim\n        self.name = name\n        self.axis = None\n\n    def __call__(self, *args, **kwargs):\n        # we need to return a copy of ourselves\n        self = self.__class__(self.obj, self.name)\n\n        # set the passed in values\n        for k, v in compat.iteritems(kwargs):\n            setattr(self,k,v)\n        return self\n\n    def __iter__(self):\n        raise NotImplementedError('ix is not iterable')\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            try:\n                values = self.obj.get_value(*key)\n                if np.isscalar(values):\n                    return values\n            except Exception:\n                pass\n\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _get_label(self, label, axis=0):\n        if self.ndim == 1:\n            # for perf reasons we want to try _xs first\n            # as its basically direct indexing\n            # but will fail when the index is not present\n            # see GH5667\n            try:\n                return self.obj._xs(label, axis=axis)\n            except:\n                return self.obj[label]\n        elif (isinstance(label, tuple) and\n                isinstance(label[axis], slice)):\n            raise IndexingError('no slices here, handle elsewhere')\n\n        return self.obj._xs(label, axis=axis)\n\n    def _get_loc(self, key, axis=0):\n        return self.obj._ixs(key, axis=axis)\n\n    def _slice(self, obj, axis=0, kind=None):\n        return self.obj._slice(obj, axis=axis, kind=kind)\n\n    def _get_setitem_indexer(self, key):\n        if self.axis is not None:\n            return self._convert_tuple(key, is_setter=True)\n\n        axis = self.obj._get_axis(0)\n        if isinstance(axis, MultiIndex):\n            try:\n                return axis.get_loc(key)\n            except Exception:\n                pass\n\n        if isinstance(key, tuple) and not self.ndim < len(key):\n            return self._convert_tuple(key, is_setter=True)\n\n        try:\n            return self._convert_to_indexer(key, is_setter=True)\n        except TypeError:\n            raise IndexingError(key)\n\n    def __setitem__(self, key, value):\n        indexer = self._get_setitem_indexer(key)\n        self._setitem_with_indexer(indexer, value)\n\n    def _has_valid_type(self, k, axis):\n        raise NotImplementedError()\n\n    def _has_valid_tuple(self, key):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n            if not self._has_valid_type(k, i):\n                raise ValueError(\"Location based indexing can only have [%s] \"\n                                 \"types\" % self._valid_types)\n\n    def _should_validate_iterable(self, axis=0):\n        \"\"\" return a boolean whether this axes needs validation for a passed iterable \"\"\"\n        ax = self.obj._get_axis(axis)\n        if isinstance(ax, MultiIndex):\n            return False\n        elif ax.is_floating():\n            return False\n\n        return True\n\n    def _is_nested_tuple_indexer(self, tup):\n        if any([ isinstance(ax, MultiIndex) for ax in self.obj.axes ]):\n            return any([ is_nested_tuple(tup,ax) for ax in self.obj.axes ])\n        return False\n\n    def _convert_tuple(self, key, is_setter=False):\n        keyidx = []\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            for i in range(self.ndim):\n                if i == axis:\n                    keyidx.append(self._convert_to_indexer(key, axis=axis, is_setter=is_setter))\n                else:\n                    keyidx.append(slice(None))\n        else:\n            for i, k in enumerate(key):\n                idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n                keyidx.append(idx)\n        return tuple(keyidx)\n\n    def _convert_scalar_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, kind=self.name)\n\n    def _convert_slice_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, kind=self.name)\n\n    def _has_valid_setitem_indexer(self, indexer):\n        return True\n\n    def _has_valid_positional_setitem_indexer(self, indexer):\n        \"\"\" validate that an positional indexer cannot enlarge its target\n            will raise if needed, does not modify the indexer externally \"\"\"\n        if isinstance(indexer, dict):\n            raise IndexError(\"{0} cannot enlarge its target object\"\n                             .format(self.name))\n        else:\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n            for ax, i in zip(self.obj.axes, indexer):\n                if isinstance(i, slice):\n                    # should check the stop slice?\n                    pass\n                elif is_list_like_indexer(i):\n                    # should check the elements?\n                    pass\n                elif is_integer(i):\n                    if i >= len(ax):\n                        raise IndexError(\"{0} cannot enlarge its target object\"\n                                         .format(self.name))\n                elif isinstance(i, dict):\n                    raise IndexError(\"{0} cannot enlarge its target object\"\n                                     .format(self.name))\n\n        return True\n\n    def _setitem_with_indexer(self, indexer, value):\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        from pandas import Panel, DataFrame, Series\n        info_axis = self.obj._info_axis_number\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n\n        # if there is only one block/type, still have to take split path\n        # unless the block is one-dimensional or it can hold the value\n        if not take_split_path and self.obj._data.blocks:\n            blk, = self.obj._data.blocks\n            if 1 < blk.ndim:  # in case of dict, keys are indices\n                val = list(value.values()) if isinstance(value,dict) else value\n                take_split_path = not blk._can_hold_element(val)\n\n        if isinstance(indexer, tuple) and len(indexer) == len(self.obj.axes):\n\n            for i, ax in zip(indexer, self.obj.axes):\n\n                # if we have any multi-indexes that have non-trivial slices (not null slices)\n                # then we must take the split path, xref GH 10360\n                if isinstance(ax, MultiIndex) and not (is_integer(i) or is_null_slice(i)):\n                    take_split_path = True\n                    break\n\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = [\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes)\n                            if _i != i\n                        ]\n                        if any([not l for l in len_non_info_axes]):\n                            if not is_list_like_indexer(value):\n                                raise ValueError(\"cannot set a frame with no \"\n                                                 \"defined index and a scalar\")\n                            self.obj[key] = value\n                            return self.obj\n\n\n                        # add a new item with the dtype setup\n                        self.obj[key] = _infer_fill_value(value)\n\n                        new_indexer = convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes)\n                        self._setitem_with_indexer(new_indexer, value)\n\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = index.insert(len(index),key)\n                    self.obj._data = self.obj.reindex_axis(labels, i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj.is_copy=None\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = convert_missing_indexer(indexer)\n\n            if missing:\n\n                # reindex the axis to the new value\n                # and set inplace\n                if self.ndim == 1:\n                    index = self.obj.index\n                    new_index = index.insert(len(index),indexer)\n\n                    # this preserves dtype of the value\n                    new_values = Series([value]).values\n                    if len(self.obj.values):\n                        new_values = np.concatenate([self.obj.values,\n                                                     new_values])\n\n                    self.obj._data = self.obj._constructor(\n                        new_values, index=new_index, name=self.obj.name)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                elif self.ndim == 2:\n\n                    # no columns and scalar\n                    if not len(self.obj.columns):\n                        raise ValueError(\n                            \"cannot set a frame with no defined columns\"\n                        )\n\n                    # append a Series\n                    if isinstance(value, Series):\n\n                        value = value.reindex(index=self.obj.columns,copy=True)\n                        value.name = indexer\n\n                    # a list-list\n                    else:\n\n                        # must have conforming columns\n                        if is_list_like_indexer(value):\n                            if len(value) != len(self.obj.columns):\n                                raise ValueError(\n                                    \"cannot set a row with mismatched columns\"\n                                    )\n\n                        value = Series(value,index=self.obj.columns,name=indexer)\n\n                    self.obj._data = self.obj.append(value)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                # set using setitem (Panel and > dims)\n                elif self.ndim >= 3:\n                    return self.obj.__setitem__(indexer, value)\n\n        # set\n        item_labels = self.obj._get_axis(info_axis)\n\n        # align and set the values\n        if take_split_path:\n\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if (len(labels) == 1 and\n                    isinstance(self.obj[labels[0]].axes[0], MultiIndex)):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1:]\n                lplane_indexer = length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if is_list_like_indexer(value) and np.iterable(value) and lplane_indexer != len(value):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\n                            \"cannot set using a multi-index selection indexer \"\n                            \"with a different length than the value\"\n                        )\n\n                    # make sure we have an ndarray\n                    value = getattr(value,'values',value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj._consolidate_inplace()\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]), value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1:]\n                if info_axis > 0:\n                    plane_axis = self.obj.axes[:info_axis][0]\n                    lplane_indexer = length_of_indexer(plane_indexer[0],\n                                                       plane_axis)\n                else:\n                    lplane_indexer = 0\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice or a slice with full bounds\n                # which means essentially reassign to the columns of a multi-dim object\n                # GH6149 (null slice), GH10408 (full bounds)\n                if isinstance(pi, tuple) and all(is_null_slice(idx) or is_full_slice(idx, len(self.obj)) for idx in pi):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s._consolidate_inplace()\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            def can_do_equal_len():\n                \"\"\" return True if we have an equal len settable \"\"\"\n                if not len(labels) == 1 or not np.iterable(value):\n                    return False\n\n                l = len(value)\n                item = labels[0]\n                index = self.obj[item].index\n\n                # equal len list/ndarray\n                if len(index) == l:\n                    return True\n                elif lplane_indexer == l:\n                    return True\n\n                return False\n\n            # we need an iterable, with a ndim of at least 1\n            # eg. don't pass through np.array(0)\n            if is_list_like_indexer(value) and getattr(value,'ndim',1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame) and value.ndim > 1:\n\n                    for item in labels:\n                        # align to\n                        v = np.nan if item not in value else \\\n                                self._align_series(indexer[0], value[item])\n                        setter(item, v)\n\n                # we have an equal len ndarray/convertible to our labels\n                elif np.array(value).ndim == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value,dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an ndarray')\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif can_do_equal_len():\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an iterable')\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = maybe_convert_ix(*indexer)\n\n                # if we are setting on the info axis ONLY\n                # set using those methods to avoid block-splitting\n                # logic here\n                if len(indexer) > info_axis and is_integer(indexer[info_axis]) and all(\n                    is_null_slice(idx) for i, idx in enumerate(indexer) if i != info_axis):\n                    self.obj[item_labels[indexer[info_axis]]] = value\n                    return\n\n            if isinstance(value, (ABCSeries, dict)):\n                value = self._align_series(indexer, Series(value))\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            if isinstance(value, ABCPanel):\n                value = self._align_panel(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._consolidate_inplace()\n            self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n            self.obj._maybe_update_cacher(clear=True)\n\n    def _align_series(self, indexer, ser):\n        # indexer to assign Series can be tuple, slice, scalar\n        if isinstance(indexer, (slice, np.ndarray, list, Index)):\n            indexer = tuple([indexer])\n\n        if isinstance(indexer, tuple):\n\n            # flatten np.ndarray indexers\n            ravel = lambda i: i.ravel() if isinstance(i, np.ndarray) else i\n            indexer = tuple(map(ravel, indexer))\n\n            aligners = [not is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n            is_frame = self.obj.ndim == 2\n            is_panel = self.obj.ndim >= 3\n            obj = self.obj\n\n            # are we a single alignable value on a non-primary\n            # dim (e.g. panel: 1,2, or frame: 0) ?\n            # hence need to align to a single axis dimension\n            # rather that find all valid dims\n\n            # frame\n            if is_frame:\n                single_aligner = single_aligner and aligners[0]\n\n            # panel\n            elif is_panel:\n                single_aligner = (single_aligner and\n                                  (aligners[1] or aligners[2]))\n\n            # we have a frame, with multiple indexers on both axes; and a\n            # series, so need to broadcast (see GH5206)\n            if (sum_aligners == self.ndim and\n                    all([com.is_sequence(_) for _ in indexer])):\n                ser = ser.reindex(obj.axes[0][indexer[0]], copy=True).values\n\n                # single indexer\n                if len(indexer) > 1:\n                    l = len(indexer[1])\n                    ser = np.tile(ser, l).reshape(l, -1).T\n\n                return ser\n\n            for i, idx in enumerate(indexer):\n                ax = obj.axes[i]\n\n                # multiple aligners (or null slices)\n                if com.is_sequence(idx) or isinstance(idx, slice):\n                    if single_aligner and is_null_slice(idx):\n                        continue\n                    new_ix = ax[idx]\n                    if not is_list_like_indexer(new_ix):\n                        new_ix = Index([new_ix])\n                    else:\n                        new_ix = Index(new_ix)\n                    if ser.index.equals(new_ix) or not len(new_ix):\n                        return ser.values.copy()\n\n                    return ser.reindex(new_ix).values\n\n                # 2 dims\n                elif single_aligner and is_frame:\n\n                    # reindex along index\n                    ax = self.obj.axes[1]\n                    if ser.index.equals(ax) or not len(ax):\n                        return ser.values.copy()\n                    return ser.reindex(ax).values\n\n                # >2 dims\n                elif single_aligner:\n\n                    broadcast = []\n                    for n, labels in enumerate(self.obj._get_plane_axes(i)):\n\n                        # reindex along the matching dimensions\n                        if len(labels & ser.index):\n                            ser = ser.reindex(labels)\n                        else:\n                            broadcast.append((n, len(labels)))\n\n                    # broadcast along other dims\n                    ser = ser.values.copy()\n                    for (axis, l) in broadcast:\n                        shape = [-1] * (len(broadcast) + 1)\n                        shape[axis] = l\n                        ser = np.tile(ser, l).reshape(shape)\n\n                    if self.obj.ndim == 3:\n                        ser = ser.T\n\n                    return ser\n\n        elif np.isscalar(indexer):\n            ax = self.obj._get_axis(1)\n\n            if ser.index.equals(ax):\n                return ser.values.copy()\n\n            return ser.reindex(ax).values\n\n        raise ValueError('Incompatible indexer with Series')\n\n    def _align_frame(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n\n        if isinstance(indexer, tuple):\n\n            aligners = [not is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n\n            idx, cols = None, None\n            sindexers = []\n            for i, ix in enumerate(indexer):\n                ax = self.obj.axes[i]\n                if com.is_sequence(ix) or isinstance(ix, slice):\n                    if idx is None:\n                        idx = ax[ix].ravel()\n                    elif cols is None:\n                        cols = ax[ix].ravel()\n                    else:\n                        break\n                else:\n                    sindexers.append(i)\n\n            # panel\n            if is_panel:\n\n                # need to conform to the convention\n                # as we are not selecting on the items axis\n                # and we have a single indexer\n                # GH 7763\n                if len(sindexers) == 1 and sindexers[0] != 0:\n                    df = df.T\n\n                if idx is None:\n                    idx = df.index\n                if cols is None:\n                    cols = df.columns\n\n            if idx is not None and cols is not None:\n\n                if df.index.equals(idx) and df.columns.equals(cols):\n                    val = df.copy().values\n                else:\n                    val = df.reindex(idx, columns=cols).values\n                return val\n\n        elif ((isinstance(indexer, slice) or is_list_like_indexer(indexer))\n              and is_frame):\n            ax = self.obj.index[indexer]\n            if df.index.equals(ax):\n                val = df.copy().values\n            else:\n\n                # we have a multi-index and are trying to align\n                # with a particular, level GH3738\n                if isinstance(ax, MultiIndex) and isinstance(\n                    df.index, MultiIndex) and ax.nlevels != df.index.nlevels:\n                    raise TypeError(\"cannot align on a multi-index with out specifying the join levels\")\n\n                val = df.reindex(index=ax).values\n            return val\n\n        elif np.isscalar(indexer) and is_panel:\n            idx = self.obj.axes[1]\n            cols = self.obj.axes[2]\n\n            # by definition we are indexing on the 0th axis\n            # a passed in dataframe which is actually a transpose\n            # of what is needed\n            if idx.equals(df.index) and cols.equals(df.columns):\n                return df.copy().values\n\n            return df.reindex(idx, columns=cols).values\n\n        raise ValueError('Incompatible indexer with DataFrame')\n\n    def _align_panel(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n        raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                  \"yet!\")\n\n    def _getitem_tuple(self, tup):\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        # no multi-index, so validate all of the indexers\n        self._has_valid_tuple(tup)\n\n        # ugly hack for GH #836\n        if self._multi_take_opportunity(tup):\n            return self._multi_take(tup)\n\n        # no shortcut needed\n        retval = self.obj\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if is_null_slice(key):\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n\n        return retval\n\n    def _multi_take_opportunity(self, tup):\n        from pandas.core.generic import NDFrame\n\n        # ugly hack for GH #836\n        if not isinstance(self.obj, NDFrame):\n            return False\n\n        if not all(is_list_like_indexer(x) for x in tup):\n            return False\n\n        # just too complicated\n        for indexer, ax in zip(tup, self.obj._data.axes):\n            if isinstance(ax, MultiIndex):\n                return False\n            elif is_bool_indexer(indexer):\n                return False\n            elif not ax.is_unique:\n                return False\n\n        return True\n\n    def _multi_take(self, tup):\n        \"\"\" create the reindex map for our objects, raise the _exception if we\n        can't create the indexer\n        \"\"\"\n        try:\n            o = self.obj\n            d = dict([\n                (a, self._convert_for_reindex(t, axis=o._get_axis_number(a)))\n                for t, a in zip(tup, o._AXIS_ORDERS)\n            ])\n            return o.reindex(**d)\n        except:\n            raise self._exception\n\n    def _convert_for_reindex(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if is_bool_indexer(key):\n            key = check_bool_indexer(labels, key)\n            return labels[key]\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            if is_integer_dtype(keyarr) and not labels.is_integer():\n                keyarr = com._ensure_platform_int(keyarr)\n                return labels.take(keyarr)\n\n            return keyarr\n\n    def _handle_lowerdim_multi_index_axis0(self, tup):\n        # we have an axis0 multi-index, handle or raise\n\n        try:\n            # fast path for series or for tup devoid of slices\n            return self._get_label(tup, axis=0)\n        except TypeError:\n            # slices are unhashable\n            pass\n        except Exception as e1:\n            if isinstance(tup[0], (slice, Index)):\n                raise IndexingError(\"Handle elsewhere\")\n\n            # raise the error if we are not sorted\n            ax0 = self.obj._get_axis(0)\n            if not ax0.is_lexsorted_for_tuple(tup):\n                raise e1\n\n        return None\n\n    def _getitem_lowerdim(self, tup):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        if isinstance(ax0, MultiIndex):\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.obj.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not is_list_like_indexer(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1:]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1:]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (isinstance(section, ABCDataFrame) and i > 0\n                            and len(new_key) == 2):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key, = new_key\n\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError('not applicable')\n\n    def _getitem_nested_tuple(self, tup):\n        # we have a nested tuple so have at least 1 multi-index level\n        # we should be able to match up the dimensionaility here\n\n        # we have too many indexers for our dim, but have at least 1\n        # multi-index dimension, try to see if we have something like\n        # a tuple passed to a series with a multi-index\n        if len(tup) > self.ndim:\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n            # this is a series with a multi-index specified a tuple of selectors\n            return self._getitem_axis(tup, axis=0)\n\n        # handle the multi-axis by taking sections and reducing\n        # this is iterative\n        obj = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n\n            if is_null_slice(key):\n                axis += 1\n                continue\n\n            current_ndim = obj.ndim\n            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n            axis += 1\n\n            # if we have a scalar, we are done\n            if np.isscalar(obj) or not hasattr(obj,'ndim'):\n                break\n\n            # has the dim of the obj changed?\n            # GH 7199\n            if obj.ndim < current_ndim:\n\n                # GH 7516\n                # if had a 3 dim and are going to a 2d\n                # axes are reversed on a DataFrame\n                if i >= 1 and current_ndim == 3 and obj.ndim == 2:\n                    obj = obj.T\n\n                axis -= 1\n\n        return obj\n\n    def _getitem_axis(self, key, axis=0):\n\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n        elif is_list_like_indexer(key) and not (isinstance(key, tuple) and\n                                        isinstance(labels, MultiIndex)):\n\n            if hasattr(key, 'ndim') and key.ndim > 1:\n                raise ValueError('Cannot index with multidimensional key')\n\n            return self._getitem_iterable(key, axis=axis)\n        else:\n            if is_integer(key):\n                if axis == 0 and isinstance(labels, MultiIndex):\n                    try:\n                        return self._get_label(key, axis=axis)\n                    except (KeyError, TypeError):\n                        if self.obj.index.levels[0].is_integer():\n                            raise\n\n                # this is the fallback! (for a non-float, non-integer index)\n                if not labels.is_floating() and not labels.is_integer():\n                    return self._get_loc(key, axis=axis)\n\n            return self._get_label(key, axis=axis)\n\n    def _getitem_iterable(self, key, axis=0):\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n\n        if is_bool_indexer(key):\n            key = check_bool_indexer(labels, key)\n            inds, = key.nonzero()\n            return self.obj.take(inds, axis=axis, convert=False)\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            # have the index handle the indexer and possibly return\n            # an indexer or raising\n            indexer = labels._convert_list_indexer(keyarr, kind=self.name)\n            if indexer is not None:\n                return self.obj.take(indexer, axis=axis)\n\n            # this is not the most robust, but...\n            if (isinstance(labels, MultiIndex) and len(keyarr) and\n                    not isinstance(keyarr[0], tuple)):\n                level = 0\n            else:\n                level = None\n\n            # existing labels are unique and indexer are unique\n            if labels.is_unique and Index(keyarr).is_unique:\n\n                try:\n                    result = self.obj.reindex_axis(keyarr, axis=axis, level=level)\n\n                    # this is an error as we are trying to find\n                    # keys in a multi-index that don't exist\n                    if isinstance(labels, MultiIndex) and level is not None:\n                        if hasattr(result,'ndim') and not np.prod(result.shape) and len(keyarr):\n                            raise KeyError(\"cannot index a multi-index axis with these keys\")\n\n                    return result\n\n                except AttributeError:\n\n                    # Series\n                    if axis != 0:\n                        raise AssertionError('axis must be 0')\n                    return self.obj.reindex(keyarr, level=level)\n\n            # existing labels are non-unique\n            else:\n\n                # reindex with the specified axis\n                if axis + 1 > self.obj.ndim:\n                    raise AssertionError(\"invalid indexing error with \"\n                                         \"non-unique index\")\n\n                new_target, indexer, new_indexer = labels._reindex_non_unique(keyarr)\n\n                if new_indexer is not None:\n                    result = self.obj.take(indexer[indexer!=-1], axis=axis,\n                                           convert=False)\n\n                    result = result._reindex_with_indexers({\n                        axis: [new_target, new_indexer]\n                        }, copy=True, allow_dups=True)\n\n                else:\n                    result = self.obj.take(indexer, axis=axis,\n                                           convert=False)\n\n                return result\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        \"In the face of ambiguity, refuse the temptation to guess.\"\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        labels = self.obj._get_axis(axis)\n\n        # if we are a scalar indexer and not type correct raise\n        obj = self._convert_scalar_indexer(obj, axis)\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except KeyError:\n            if isinstance(obj, tuple) and isinstance(labels, MultiIndex):\n                if is_setter and len(obj) == labels.nlevels:\n                    return {'key': obj}\n                raise\n        except TypeError:\n            pass\n        except (ValueError):\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n            if is_setter:\n\n                # always valid\n                if self.name == 'loc':\n                    return {'key': obj}\n\n                # a positional\n                if (obj >= self.obj.shape[axis] and\n                        not isinstance(labels, MultiIndex)):\n                    raise ValueError(\"cannot set by positional indexing with \"\n                                     \"enlargement\")\n\n            return obj\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n        elif is_list_like_indexer(obj):\n            if is_bool_indexer(obj):\n                obj = check_bool_indexer(labels, obj)\n                inds, = obj.nonzero()\n                return inds\n            else:\n                if isinstance(obj, Index):\n                    objarr = obj.values\n                else:\n                    objarr = _asarray_tuplesafe(obj)\n\n                # The index may want to handle a list indexer differently\n                # by returning an indexer or raising\n                indexer = labels._convert_list_indexer(objarr, kind=self.name)\n                if indexer is not None:\n                    return indexer\n\n                # this is not the most robust, but...\n                if (isinstance(labels, MultiIndex) and\n                        not isinstance(objarr[0], tuple)):\n                    level = 0\n                    _, indexer = labels.reindex(objarr, level=level)\n\n                    # take all\n                    if indexer is None:\n                        indexer = np.arange(len(labels))\n\n                    check = labels.levels[0].get_indexer(objarr)\n                else:\n                    level = None\n\n                    # unique index\n                    if labels.is_unique:\n                        indexer = check = labels.get_indexer(objarr)\n\n                    # non-unique (dups)\n                    else:\n                        (indexer,\n                         missing) = labels.get_indexer_non_unique(objarr)\n                        check = indexer\n\n                mask = check == -1\n                if mask.any():\n                    raise KeyError('%s not in index' % objarr[mask])\n\n                return _values_from_object(indexer)\n\n        else:\n            try:\n                return labels.get_loc(obj)\n            except KeyError:\n                # allow a not found key only if we are a setter\n                if not is_list_like_indexer(obj) and is_setter:\n                    return {'key': obj}\n                raise\n\n    def _tuplify(self, loc):\n        tup = [slice(None, None) for _ in range(self.ndim)]\n        tup[0] = loc\n        return tuple(tup)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not need_slice(slice_obj):\n            return obj\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, kind='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _IXIndexer(_NDFrameIndexer):\n\n    \"\"\"A primarily label-location based indexer, with integer position\n    fallback.\n\n    ``.ix[]`` supports mixed integer and label based access. It is\n    primarily label based, but will fall back to integer positional\n    access unless the corresponding axis is of integer type.\n\n    ``.ix`` is the most general indexer and will support any of the\n    inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n    point label schemes. ``.ix`` is exceptionally useful when dealing\n    with mixed positional and label based hierachical indexes.\n\n    However, when an axis is integer based, ONLY label based access\n    and not positional access is supported. Thus, in such cases, it's\n    usually better to be explicit and use ``.iloc`` or ``.loc``.\n\n    See more at :ref:`Advanced Indexing <advanced>`.\n\n    \"\"\"\n\n    def _has_valid_type(self, key, axis):\n        if isinstance(key, slice):\n            return True\n\n        elif is_bool_indexer(key):\n            return True\n\n        elif is_list_like_indexer(key):\n            return True\n\n        else:\n\n            self._convert_scalar_indexer(key, axis)\n\n        return True\n\n\nclass _LocationIndexer(_NDFrameIndexer):\n    _exception = Exception\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _getitem_axis(self, key, axis=0):\n        raise NotImplementedError()\n\n    def _getbool_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n        key = check_bool_indexer(labels, key)\n        inds, = key.nonzero()\n        try:\n            return self.obj.take(inds, axis=axis, convert=False)\n        except Exception as detail:\n            raise self._exception(detail)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\n        obj = self.obj\n        if not need_slice(slice_obj):\n            return obj\n\n        labels = obj._get_axis(axis)\n        indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n                                       slice_obj.step)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, kind='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _LocIndexer(_LocationIndexer):\n\n    \"\"\"Purely label-location based indexer for selection by label.\n\n    ``.loc[]`` is primarily label based, but may also be used with a\n    boolean array.\n\n    Allowed inputs are:\n\n    - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n      interpreted as a *label* of the index, and **never** as an\n      integer position along the index).\n    - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n    - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n      to usual python slices, **both** the start and the stop are included!).\n    - A boolean array.\n\n    ``.loc`` will raise a ``KeyError`` when the items are not found.\n\n    See more at :ref:`Selection by Label <indexing.label>`\n\n    \"\"\"\n\n    _valid_types = (\"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n                    \"endpoints included! Can be slices of integers if the \"\n                    \"index is integers), listlike of labels, boolean\")\n    _exception = KeyError\n\n    def _has_valid_type(self, key, axis):\n        ax = self.obj._get_axis(axis)\n\n        # valid for a label where all labels are in the index\n        # slice of lables (where start-end in labels)\n        # slice of integers (only if in the lables)\n        # boolean\n\n        if isinstance(key, slice):\n            return True\n\n        elif is_bool_indexer(key):\n            return True\n\n        elif is_list_like_indexer(key):\n\n            # mi is just a passthru\n            if isinstance(key, tuple) and isinstance(ax, MultiIndex):\n                return True\n\n            # TODO: don't check the entire key unless necessary\n            if len(key) and np.all(ax.get_indexer_for(key) < 0):\n\n                raise KeyError(\"None of [%s] are in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            return True\n\n        else:\n\n            def error():\n                if isnull(key):\n                    raise ValueError(\n                        \"cannot use label indexing with a null key\")\n                raise KeyError(\"the label [%s] is not in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            try:\n                key = self._convert_scalar_indexer(key, axis)\n                if not key in ax:\n                    error()\n            except (TypeError) as e:\n\n                # python 3 type errors should be raised\n                if 'unorderable' in str(e):  # pragma: no cover\n                    error()\n                raise\n            except:\n                error()\n\n        return True\n\n    def _getitem_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n        elif is_bool_indexer(key):\n            return self._getbool_axis(key, axis=axis)\n        elif is_list_like_indexer(key):\n\n            # GH 7349\n            # possibly convert a list-like into a nested tuple\n            # but don't convert a list-like of tuples\n            if isinstance(labels, MultiIndex):\n                if not isinstance(key, tuple) and len(key) > 1 and not isinstance(key[0], tuple):\n                    key = tuple([key])\n\n            # an iterable multi-selection\n            if not (isinstance(key, tuple) and\n                    isinstance(labels, MultiIndex)):\n\n                if hasattr(key, 'ndim') and key.ndim > 1:\n                    raise ValueError('Cannot index with multidimensional key')\n\n                return self._getitem_iterable(key, axis=axis)\n\n            # nested tuple slicing\n            if is_nested_tuple(key, labels):\n                locs = labels.get_locs(key)\n                indexer = [ slice(None) ] * self.ndim\n                indexer[axis] = locs\n                return self.obj.iloc[tuple(indexer)]\n\n        # fall thru to straight lookup\n        self._has_valid_type(key, axis)\n        return self._get_label(key, axis=axis)\n\n\nclass _iLocIndexer(_LocationIndexer):\n\n    \"\"\"Purely integer-location based indexing for selection by position.\n\n    ``.iloc[]`` is primarily integer position based (from ``0`` to\n    ``length-1`` of the axis), but may also be used with a boolean\n    array.\n\n    Allowed inputs are:\n\n    - An integer, e.g. ``5``.\n    - A list or array of integers, e.g. ``[4, 3, 0]``.\n    - A slice object with ints, e.g. ``1:7``.\n    - A boolean array.\n\n    ``.iloc`` will raise ``IndexError`` if a requested indexer is\n    out-of-bounds, except *slice* indexers which allow out-of-bounds\n    indexing (this conforms with python/numpy *slice* semantics).\n\n    See more at :ref:`Selection by Position <indexing.integer>`\n\n    \"\"\"\n\n    _valid_types = (\"integer, integer slice (START point is INCLUDED, END \"\n                    \"point is EXCLUDED), listlike of integers, boolean array\")\n    _exception = IndexError\n\n    def _has_valid_type(self, key, axis):\n        if is_bool_indexer(key):\n            if hasattr(key, 'index') and isinstance(key.index, Index):\n                if key.index.inferred_type == 'integer':\n                    raise NotImplementedError(\n                        \"iLocation based boolean indexing on an integer type \"\n                        \"is not available\"\n                    )\n                raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                 \"an indexable as a mask\")\n            return True\n\n        if isinstance(key, slice):\n            return True\n        elif is_integer(key):\n            return self._is_valid_integer(key, axis)\n        elif is_list_like_indexer(key):\n            return self._is_valid_list_like(key, axis)\n        return False\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _is_valid_integer(self, key, axis):\n        # return a boolean if we have a valid integer indexer\n\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if key >= l or key < -l:\n            raise IndexError(\"single positional indexer is out-of-bounds\")\n        return True\n\n\n    def _is_valid_list_like(self, key, axis):\n        # return a boolean if we are a valid list-like (e.g. that we dont' have out-of-bounds values)\n\n        # coerce the key to not exceed the maximum size of the index\n        arr = np.array(key)\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if len(arr) and (arr.max() >= l or arr.min() < -l):\n            raise IndexError(\"positional indexers are out-of-bounds\")\n\n        return True\n\n    def _getitem_tuple(self, tup):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except:\n            pass\n\n        retval = self.obj\n        axis=0\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim<self.ndim:\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not need_slice(slice_obj):\n            return obj\n\n        slice_obj = self._convert_slice_indexer(slice_obj, axis)\n        if isinstance(slice_obj, slice):\n            return self._slice(slice_obj, axis=axis, kind='iloc')\n        else:\n            return self.obj.take(slice_obj, axis=axis, convert=False)\n\n    def _getitem_axis(self, key, axis=0):\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n\n        elif is_bool_indexer(key):\n            self._has_valid_type(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a single integer or a list of integers\n        else:\n\n            if is_list_like_indexer(key):\n\n                # validate list bounds\n                self._is_valid_list_like(key, axis)\n\n                # force an actual list\n                key = list(key)\n\n            else:\n                key = self._convert_scalar_indexer(key, axis)\n\n                if not is_integer(key):\n                    raise TypeError(\"Cannot index by location index with a \"\n                                    \"non-integer key\")\n\n                # validate the location\n                self._is_valid_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\" much simpler as we only have to deal with our valid types \"\"\"\n\n        # make need to convert a float key\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_float(obj):\n            return self._convert_scalar_indexer(obj, axis)\n\n        elif self._has_valid_type(obj, axis):\n            return obj\n\n        raise ValueError(\"Can only index by location with a [%s]\" %\n                         self._valid_types)\n\n\nclass _ScalarAccessIndexer(_NDFrameIndexer):\n\n    \"\"\" access scalars quickly \"\"\"\n\n    def _convert_key(self, key, is_setter=False):\n        return list(key)\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n\n            # we could have a convertible item here (e.g. Timestamp)\n            if not is_list_like_indexer(key):\n                key = tuple([key])\n            else:\n                raise ValueError('Invalid call for scalar access (getting)!')\n\n        key = self._convert_key(key)\n        return self.obj.get_value(*key, takeable=self._takeable)\n\n    def __setitem__(self, key, value):\n        if not isinstance(key, tuple):\n            key = self._tuplify(key)\n        if len(key) != self.obj.ndim:\n            raise ValueError('Not enough indexers for scalar access '\n                             '(setting)!')\n        key = list(self._convert_key(key, is_setter=True))\n        key.append(value)\n        self.obj.set_value(*key, takeable=self._takeable)\n\n\nclass _AtIndexer(_ScalarAccessIndexer):\n\n    \"\"\"Fast label-based scalar accessor\n\n    Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n    You can also set using these indexers.\n\n    \"\"\"\n\n    _takeable = False\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n\n        # allow arbitrary setting\n        if is_setter:\n            return list(key)\n\n        for ax, i in zip(self.obj.axes, key):\n            if ax.is_integer():\n                if not is_integer(i):\n                    raise ValueError(\"At based indexing on an integer index can only have integer \"\n                                     \"indexers\")\n            else:\n                if is_integer(i):\n                    raise ValueError(\"At based indexing on an non-integer index can only have non-integer \"\n                                     \"indexers\")\n        return key\n\nclass _iAtIndexer(_ScalarAccessIndexer):\n\n    \"\"\"Fast integer location scalar accessor.\n\n    Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n    You can also set using these indexers.\n\n    \"\"\"\n\n    _takeable = True\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require  integer args (and convert to label arguments) \"\"\"\n        for a, i in zip(self.obj.axes, key):\n            if not is_integer(i):\n                raise ValueError(\"iAt based indexing can only have integer \"\n                                 \"indexers\")\n        return key\n\n# 32-bit floating point machine epsilon\n_eps = np.finfo('f4').eps\n\n\ndef length_of_indexer(indexer, target=None):\n    \"\"\"return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        l = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += l\n        if stop is None or stop > l:\n            stop = l\n        elif stop < 0:\n            stop += l\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = -step\n        return (stop - start + step-1) // step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like_indexer(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")\n\n\ndef convert_to_index_sliceable(obj, key):\n    \"\"\"if we are index sliceable, then return my slicer, otherwise return None\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, kind='getitem')\n\n    elif isinstance(key, compat.string_types):\n\n        # we are an actual column\n        if key in obj._data.items:\n            return None\n\n        # we need a timelike key here\n        if idx.is_all_dates:\n            try:\n                return idx._get_string_slice(key)\n            except:\n                return None\n\n    return None\n\n\ndef is_index_slice(obj):\n    def _is_valid_index(x):\n        return (is_integer(x) or is_float(x)\n                and np.allclose(x, int(x), rtol=_eps, atol=0))\n\n    def _crit(v):\n        return v is None or _is_valid_index(v)\n\n    both_none = obj.start is None and obj.stop is None\n\n    return not both_none and (_crit(obj.start) and _crit(obj.stop))\n\n\ndef check_bool_indexer(ax, key):\n    # boolean indexing, need to check that the data are aligned, otherwise\n    # disallowed\n\n    # this function assumes that is_bool_indexer(key) == True\n\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(ax):\n        result = result.reindex(ax)\n        mask = com.isnull(result.values)\n        if mask.any():\n            raise IndexingError('Unalignable boolean Series key provided')\n\n        result = result.astype(bool).values\n\n    else:\n        # is_bool_indexer has already checked for nulls in the case of an\n        # object array key, so no check needed here\n        result = np.asarray(result, dtype=bool)\n\n    return result\n\n\ndef convert_missing_indexer(indexer):\n    \"\"\" reverse convert a missing indexer, which is a dict\n        return the scalar indexer and a boolean indicating if we converted \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer['key']\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False\n\n\ndef convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n    def get_indexer(_i, _idx):\n        return (axes[_i].get_loc(_idx['key'])\n                if isinstance(_idx, dict) else _idx)\n    return tuple([get_indexer(_i, _idx) for _i, _idx in enumerate(indexer)])\n\n\ndef maybe_convert_indices(indices, n):\n    \"\"\" if we have negative indicies, translate to postive here\n    if have indicies that are out-of-bounds, raise an IndexError\n    \"\"\"\n    if isinstance(indices, list):\n        indices = np.array(indices)\n        if len(indices) == 0:\n            # If list is empty, np.array will return float and cause indexing\n            # errors.\n            return np.empty(0, dtype=np.int_)\n\n    mask = indices < 0\n    if mask.any():\n        indices[mask] += n\n    mask = (indices >= n) | (indices < 0)\n    if mask.any():\n        raise IndexError(\"indices are out-of-bounds\")\n    return indices\n\n\ndef maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries, Index)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args\n\n\ndef is_nested_tuple(tup, labels):\n    # check for a compatiable nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    # are we nested tuple of: tuple,list,slice\n    for i, k in enumerate(tup):\n\n        if isinstance(k, (tuple, list, slice)):\n            return isinstance(labels, MultiIndex)\n\n    return False\n\ndef is_list_like_indexer(key):\n    # allow a list_like, but exclude NamedTuples which can be indexers\n    return is_list_like(key) and not (isinstance(key, tuple) and type(key) is not tuple)\n\ndef is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not is_list_like_indexer(key)\n\n\ndef need_slice(obj):\n    return (obj.start is not None or\n            obj.stop is not None or\n            (obj.step is not None and obj.step != 1))\n\n\ndef maybe_droplevels(index, key):\n    # drop levels\n    original_index = index\n    if isinstance(key, tuple):\n        for _ in key:\n            try:\n                index = index.droplevel(0)\n            except:\n                # we have dropped too much, so back out\n                return original_index\n    else:\n        try:\n            index = index.droplevel(0)\n        except:\n            pass\n\n    return index\n"
    },
    {
      "filename": "pandas/tests/test_indexing.py",
      "content": "# -*- coding: utf-8 -*-\n# pylint: disable-msg=W0612,E1101\nimport sys\nimport nose\nimport itertools\nimport warnings\nfrom datetime import datetime\n\nfrom pandas.compat import range, lrange, lzip, StringIO, lmap, map\nfrom pandas.tslib import NaT\nfrom numpy import nan\nfrom numpy.random import randn\nimport numpy as np\n\nimport pandas as pd\nimport pandas.core.common as com\nfrom pandas import option_context\nfrom pandas.core.api import (DataFrame, Index, Series, Panel, isnull,\n                             MultiIndex, Float64Index, Timestamp, Timedelta)\nfrom pandas.util.testing import (assert_almost_equal, assert_series_equal,\n                                 assert_frame_equal, assert_panel_equal,\n                                 assert_attr_equal)\nfrom pandas import concat, lib\nfrom pandas.io.common import PerformanceWarning\n\nimport pandas.util.testing as tm\nfrom pandas import date_range\n\n_verbose = False\n\n#-------------------------------------------------------------------------------\n# Indexing test cases\n\n\ndef _generate_indices(f, values=False):\n    \"\"\" generate the indicies\n          if values is True , use the axis values\n                    is False, use the range\n                    \"\"\"\n\n    axes = f.axes\n    if values:\n        axes = [ lrange(len(a)) for a in axes ]\n\n    return itertools.product(*axes)\n\ndef _get_value(f, i, values=False):\n    \"\"\" return the value for the location i \"\"\"\n\n    # check agains values\n    if values:\n        return f.values[i]\n\n    # this is equiv of f[col][row].....\n    #v = f\n    #for a in reversed(i):\n    #    v = v.__getitem__(a)\n    #return v\n    return f.ix[i]\n\ndef _get_result(obj, method, key, axis):\n    \"\"\" return the result for this obj with this key and this axis \"\"\"\n\n    if isinstance(key, dict):\n        key = key[axis]\n\n    # use an artifical conversion to map the key as integers to the labels\n    # so ix can work for comparisions\n    if method == 'indexer':\n        method = 'ix'\n        key    = obj._get_axis(axis)[key]\n\n    # in case we actually want 0 index slicing\n    try:\n        xp  = getattr(obj, method).__getitem__(_axify(obj,key,axis))\n    except:\n        xp  = getattr(obj, method).__getitem__(key)\n\n    return xp\n\ndef _axify(obj, key, axis):\n    # create a tuple accessor\n    if axis is not None:\n        axes = [ slice(None) ] * obj.ndim\n        axes[axis] = key\n        return tuple(axes)\n    return k\n\n\ndef _mklbl(prefix,n):\n    return [\"%s%s\" % (prefix,i)  for i in range(n)]\n\nclass TestIndexing(tm.TestCase):\n\n    _multiprocess_can_split_ = True\n\n    _objs = set(['series','frame','panel'])\n    _typs = set(['ints','labels','mixed','ts','floats','empty'])\n\n    def setUp(self):\n\n        import warnings\n        warnings.filterwarnings(action='ignore', category=FutureWarning)\n\n        self.series_ints = Series(np.random.rand(4), index=lrange(0,8,2))\n        self.frame_ints = DataFrame(np.random.randn(4, 4), index=lrange(0, 8, 2), columns=lrange(0,12,3))\n        self.panel_ints = Panel(np.random.rand(4,4,4), items=lrange(0,8,2),major_axis=lrange(0,12,3),minor_axis=lrange(0,16,4))\n\n        self.series_labels = Series(np.random.randn(4), index=list('abcd'))\n        self.frame_labels  = DataFrame(np.random.randn(4, 4), index=list('abcd'), columns=list('ABCD'))\n        self.panel_labels  = Panel(np.random.randn(4,4,4), items=list('abcd'), major_axis=list('ABCD'), minor_axis=list('ZYXW'))\n\n        self.series_mixed  = Series(np.random.randn(4), index=[2, 4, 'null', 8])\n        self.frame_mixed   = DataFrame(np.random.randn(4, 4), index=[2, 4, 'null', 8])\n        self.panel_mixed   = Panel(np.random.randn(4,4,4), items=[2,4,'null',8])\n\n        self.series_ts     = Series(np.random.randn(4), index=date_range('20130101', periods=4))\n        self.frame_ts      = DataFrame(np.random.randn(4, 4), index=date_range('20130101', periods=4))\n        self.panel_ts      = Panel(np.random.randn(4, 4, 4), items=date_range('20130101', periods=4))\n\n        #self.series_floats = Series(np.random.randn(4), index=[1.00, 2.00, 3.00, 4.00])\n        #self.frame_floats  = DataFrame(np.random.randn(4, 4), columns=[1.00, 2.00, 3.00, 4.00])\n        #self.panel_floats  = Panel(np.random.rand(4,4,4), items = [1.00,2.00,3.00,4.00])\n\n        self.frame_empty   = DataFrame({})\n        self.series_empty  = Series({})\n        self.panel_empty   = Panel({})\n\n        # form agglomerates\n        for o in self._objs:\n\n            d = dict()\n            for t in self._typs:\n                d[t] = getattr(self,'%s_%s' % (o,t),None)\n\n            setattr(self,o,d)\n\n    def check_values(self, f, func, values = False):\n\n        if f is None: return\n        axes = f.axes\n        indicies = itertools.product(*axes)\n\n        for i in indicies:\n            result = getattr(f,func)[i]\n\n            # check agains values\n            if values:\n                expected = f.values[i]\n            else:\n                expected = f\n                for a in reversed(i):\n                    expected = expected.__getitem__(a)\n\n            assert_almost_equal(result, expected)\n\n\n    def check_result(self, name, method1, key1, method2, key2, typs = None, objs = None, axes = None, fails = None):\n\n\n        def _eq(t, o, a, obj, k1, k2):\n            \"\"\" compare equal for these 2 keys \"\"\"\n\n            if a is not None and a > obj.ndim-1:\n                return\n\n            def _print(result, error = None):\n                if error is not None:\n                    error = str(error)\n                v = \"%-16.16s [%-16.16s]: [typ->%-8.8s,obj->%-8.8s,key1->(%-4.4s),key2->(%-4.4s),axis->%s] %s\" % (name,result,t,o,method1,method2,a,error or '')\n                if _verbose:\n                    com.pprint_thing(v)\n\n            try:\n\n                ### good debug location ###\n                #if name == 'bool' and t == 'empty' and o == 'series' and method1 == 'loc':\n                #    import pdb; pdb.set_trace()\n\n                rs  = getattr(obj, method1).__getitem__(_axify(obj,k1,a))\n\n                try:\n                    xp = _get_result(obj,method2,k2,a)\n                except:\n                    result = 'no comp'\n                    _print(result)\n                    return\n\n                try:\n                    if np.isscalar(rs) and np.isscalar(xp):\n                        self.assertEqual(rs, xp)\n                    elif xp.ndim == 1:\n                        assert_series_equal(rs,xp)\n                    elif xp.ndim == 2:\n                        assert_frame_equal(rs,xp)\n                    elif xp.ndim == 3:\n                        assert_panel_equal(rs,xp)\n                    result = 'ok'\n                except (AssertionError):\n                    result = 'fail'\n\n                # reverse the checks\n                if fails is True:\n                    if result == 'fail':\n                        result = 'ok (fail)'\n\n                if not result.startswith('ok'):\n                    raise AssertionError(_print(result))\n\n                _print(result)\n\n            except AssertionError:\n                raise\n            except Exception as detail:\n\n                # if we are in fails, the ok, otherwise raise it\n                if fails is not None:\n                    if isinstance(detail, fails):\n                        result = 'ok (%s)' % type(detail).__name__\n                        _print(result)\n                        return\n\n                result = type(detail).__name__\n                raise AssertionError(_print(result, error = detail))\n\n        if typs is None:\n            typs = self._typs\n\n        if objs is None:\n            objs = self._objs\n\n        if axes is not None:\n            if not isinstance(axes,(tuple,list)):\n                axes = [ axes ]\n            else:\n                axes = list(axes)\n        else:\n            axes = [ 0, 1, 2]\n\n        # check\n        for o in objs:\n            if o not in self._objs:\n                continue\n\n            d = getattr(self,o)\n            for a in axes:\n                for t in typs:\n                    if t not in self._typs:\n                        continue\n\n                    obj = d[t]\n                    if obj is not None:\n                        obj = obj.copy()\n\n                        k2 = key2\n                        _eq(t, o, a, obj, key1, k2)\n\n    def test_indexer_caching(self):\n        # GH5727\n        # make sure that indexers are in the _internal_names_set\n        n = 1000001\n        arrays = [lrange(n), lrange(n)]\n        index = MultiIndex.from_tuples(lzip(*arrays))\n        s = Series(np.zeros(n), index=index)\n        str(s)\n\n        # setitem\n        expected = Series(np.ones(n), index=index)\n        s = Series(np.zeros(n), index=index)\n        s[s==0] = 1\n        assert_series_equal(s,expected)\n\n    def test_at_and_iat_get(self):\n\n        def _check(f, func, values = False):\n\n            if f is not None:\n                indicies = _generate_indices(f, values)\n                for i in indicies:\n                    result = getattr(f,func)[i]\n                    expected = _get_value(f,i,values)\n                    assert_almost_equal(result, expected)\n\n        for o in self._objs:\n\n            d = getattr(self,o)\n\n            # iat\n            _check(d['ints'],'iat', values=True)\n            for f in [d['labels'],d['ts'],d['floats']]:\n                if f is not None:\n                    self.assertRaises(ValueError, self.check_values, f, 'iat')\n\n            # at\n            _check(d['ints'],  'at')\n            _check(d['labels'],'at')\n            _check(d['ts'],    'at')\n            _check(d['floats'],'at')\n\n    def test_at_and_iat_set(self):\n\n        def _check(f, func, values = False):\n\n            if f is not None:\n                indicies = _generate_indices(f, values)\n                for i in indicies:\n                    getattr(f,func)[i] = 1\n                    expected = _get_value(f,i,values)\n                    assert_almost_equal(expected, 1)\n\n        for t in self._objs:\n\n            d = getattr(self,t)\n\n            _check(d['ints'],'iat',values=True)\n            for f in [d['labels'],d['ts'],d['floats']]:\n                if f is not None:\n                    self.assertRaises(ValueError, _check, f, 'iat')\n\n            # at\n            _check(d['ints'],  'at')\n            _check(d['labels'],'at')\n            _check(d['ts'],    'at')\n            _check(d['floats'],'at')\n\n    def test_at_iat_coercion(self):\n\n        # as timestamp is not a tuple!\n        dates = date_range('1/1/2000', periods=8)\n        df = DataFrame(randn(8, 4), index=dates, columns=['A', 'B', 'C', 'D'])\n        s = df['A']\n\n        result = s.at[dates[5]]\n        xp     = s.values[5]\n        self.assertEqual(result, xp)\n\n        # GH 7729\n        # make sure we are boxing the returns\n        s = Series(['2014-01-01', '2014-02-02'], dtype='datetime64[ns]')\n        expected = Timestamp('2014-02-02')\n\n        for r in [ lambda : s.iat[1], lambda : s.iloc[1] ]:\n            result = r()\n            self.assertEqual(result, expected)\n\n        s = Series(['1 days','2 days'], dtype='timedelta64[ns]')\n        expected = Timedelta('2 days')\n\n        for r in [ lambda : s.iat[1], lambda : s.iloc[1] ]:\n            result = r()\n            self.assertEqual(result, expected)\n\n    def test_iat_invalid_args(self):\n        pass\n\n    def test_imethods_with_dups(self):\n\n        # GH6493\n        # iat/iloc with dups\n\n        s = Series(range(5), index=[1,1,2,2,3], dtype='int64')\n        result = s.iloc[2]\n        self.assertEqual(result,2)\n        result = s.iat[2]\n        self.assertEqual(result,2)\n\n        self.assertRaises(IndexError, lambda : s.iat[10])\n        self.assertRaises(IndexError, lambda : s.iat[-10])\n\n        result = s.iloc[[2,3]]\n        expected = Series([2,3],[2,2],dtype='int64')\n        assert_series_equal(result,expected)\n\n        df = s.to_frame()\n        result = df.iloc[2]\n        expected = Series(2, index=[0], name=2)\n        assert_series_equal(result, expected)\n\n        result = df.iat[2,0]\n        expected = 2\n        self.assertEqual(result,2)\n\n    def test_repeated_getitem_dups(self):\n        # GH 5678\n        # repeated gettitems on a dup index returing a ndarray\n        df = DataFrame(np.random.random_sample((20,5)), index=['ABCDE'[x%5] for x in range(20)])\n        expected = df.loc['A',0]\n        result = df.loc[:,0].loc['A']\n        assert_series_equal(result,expected)\n\n    def test_iloc_exceeds_bounds(self):\n\n        # GH6296\n        # iloc should allow indexers that exceed the bounds\n        df = DataFrame(np.random.random_sample((20,5)), columns=list('ABCDE'))\n        expected = df\n\n        # lists of positions should raise IndexErrror!\n        with tm.assertRaisesRegexp(IndexError, 'positional indexers are out-of-bounds'):\n            df.iloc[:,[0,1,2,3,4,5]]\n        self.assertRaises(IndexError, lambda : df.iloc[[1,30]])\n        self.assertRaises(IndexError, lambda : df.iloc[[1,-30]])\n        self.assertRaises(IndexError, lambda : df.iloc[[100]])\n\n        s = df['A']\n        self.assertRaises(IndexError, lambda : s.iloc[[100]])\n        self.assertRaises(IndexError, lambda : s.iloc[[-100]])\n\n        # still raise on a single indexer\n        with tm.assertRaisesRegexp(IndexError, 'single positional indexer is out-of-bounds'):\n            df.iloc[30]\n        self.assertRaises(IndexError, lambda : df.iloc[-30])\n\n        # GH10779\n        # single positive/negative indexer exceeding Series bounds should raise an IndexError\n        with tm.assertRaisesRegexp(IndexError, 'single positional indexer is out-of-bounds'):\n            s.iloc[30]\n        self.assertRaises(IndexError, lambda : s.iloc[-30])\n\n        # slices are ok\n        result = df.iloc[:,4:10]  # 0 < start < len < stop\n        expected = df.iloc[:,4:]\n        assert_frame_equal(result,expected)\n\n        result = df.iloc[:,-4:-10]  # stop < 0 < start < len\n        expected = df.iloc[:,:0]\n        assert_frame_equal(result,expected)\n\n        result = df.iloc[:,10:4:-1]  # 0 < stop < len < start (down)\n        expected = df.iloc[:,:4:-1]\n        assert_frame_equal(result,expected)\n\n        result = df.iloc[:,4:-10:-1]  # stop < 0 < start < len (down)\n        expected = df.iloc[:,4::-1]\n        assert_frame_equal(result,expected)\n\n        result = df.iloc[:,-10:4]  # start < 0 < stop < len\n        expected = df.iloc[:,:4]\n        assert_frame_equal(result,expected)\n\n        result = df.iloc[:,10:4]  # 0 < stop < len < start\n        expected = df.iloc[:,:0]\n        assert_frame_equal(result,expected)\n\n        result = df.iloc[:,-10:-11:-1]  # stop < start < 0 < len (down)\n        expected = df.iloc[:,:0]\n        assert_frame_equal(result,expected)\n\n        result = df.iloc[:,10:11]  # 0 < len < start < stop\n        expected = df.iloc[:,:0]\n        assert_frame_equal(result,expected)\n\n        # slice bounds exceeding is ok\n        result = s.iloc[18:30]\n        expected = s.iloc[18:]\n        assert_series_equal(result,expected)\n\n        result = s.iloc[30:]\n        expected = s.iloc[:0]\n        assert_series_equal(result,expected)\n\n        result = s.iloc[30::-1]\n        expected = s.iloc[::-1]\n        assert_series_equal(result,expected)\n\n        # doc example\n        def check(result,expected):\n            str(result)\n            result.dtypes\n            assert_frame_equal(result,expected)\n\n        dfl = DataFrame(np.random.randn(5,2),columns=list('AB'))\n        check(dfl.iloc[:,2:3],DataFrame(index=dfl.index))\n        check(dfl.iloc[:,1:3],dfl.iloc[:,[1]])\n        check(dfl.iloc[4:6],dfl.iloc[[4]])\n\n        self.assertRaises(IndexError, lambda : dfl.iloc[[4,5,6]])\n        self.assertRaises(IndexError, lambda : dfl.iloc[:,4])\n\n    def test_iloc_getitem_int(self):\n\n        # integer\n        self.check_result('integer', 'iloc', 2, 'ix', { 0 : 4, 1: 6, 2: 8 }, typs = ['ints'])\n        self.check_result('integer', 'iloc', 2, 'indexer', 2, typs = ['labels','mixed','ts','floats','empty'], fails = IndexError)\n\n    def test_iloc_getitem_neg_int(self):\n\n        # neg integer\n        self.check_result('neg int', 'iloc', -1, 'ix', { 0 : 6, 1: 9, 2: 12 }, typs = ['ints'])\n        self.check_result('neg int', 'iloc', -1, 'indexer', -1, typs = ['labels','mixed','ts','floats','empty'], fails = IndexError)\n\n    def test_iloc_getitem_list_int(self):\n\n        # list of ints\n        self.check_result('list int', 'iloc', [0,1,2], 'ix', { 0 : [0,2,4], 1 : [0,3,6], 2: [0,4,8] }, typs = ['ints'])\n        self.check_result('list int', 'iloc', [2], 'ix', { 0 : [4], 1 : [6], 2: [8] }, typs = ['ints'])\n        self.check_result('list int', 'iloc', [0,1,2], 'indexer', [0,1,2], typs = ['labels','mixed','ts','floats','empty'], fails = IndexError)\n\n        # array of ints\n        # (GH5006), make sure that a single indexer is returning the correct type\n        self.check_result('array int', 'iloc', np.array([0,1,2]), 'ix', { 0 : [0,2,4], 1 : [0,3,6], 2: [0,4,8] }, typs = ['ints'])\n        self.check_result('array int', 'iloc', np.array([2]), 'ix', { 0 : [4], 1 : [6], 2: [8] }, typs = ['ints'])\n        self.check_result('array int', 'iloc', np.array([0,1,2]), 'indexer', [0,1,2], typs = ['labels','mixed','ts','floats','empty'], fails = IndexError)\n\n    def test_iloc_getitem_neg_int_can_reach_first_index(self):\n        # GH10547 and GH10779\n        # negative integers should be able to reach index 0\n        df = DataFrame({'A': [2, 3, 5], 'B': [7, 11, 13]})\n        s = df['A']\n\n        expected = df.iloc[0]\n        result = df.iloc[-3]\n        assert_series_equal(result, expected)\n\n        expected = df.iloc[[0]]\n        result = df.iloc[[-3]]\n        assert_frame_equal(result, expected)\n\n        expected = s.iloc[0]\n        result = s.iloc[-3]\n        self.assertEqual(result, expected)\n\n        expected = s.iloc[[0]]\n        result = s.iloc[[-3]]\n        assert_series_equal(result, expected)\n\n        # check the length 1 Series case highlighted in GH10547\n        expected = pd.Series(['a'], index=['A'])\n        result = expected.iloc[[-1]]\n        assert_series_equal(result, expected)\n\n    def test_iloc_getitem_dups(self):\n\n        # no dups in panel (bug?)\n        self.check_result('list int (dups)', 'iloc', [0,1,1,3], 'ix', { 0 : [0,2,2,6], 1 : [0,3,3,9] }, objs = ['series','frame'], typs = ['ints'])\n\n        # GH 6766\n        df1 = DataFrame([{'A':None, 'B':1},{'A':2, 'B':2}])\n        df2 = DataFrame([{'A':3, 'B':3},{'A':4, 'B':4}])\n        df = concat([df1, df2], axis=1)\n\n        # cross-sectional indexing\n        result = df.iloc[0,0]\n        self.assertTrue(isnull(result))\n\n        result = df.iloc[0,:]\n        expected = Series([np.nan, 1, 3, 3], index=['A','B','A','B'], name=0)\n        assert_series_equal(result,expected)\n\n    def test_iloc_getitem_array(self):\n\n        # array like\n        s = Series(index=lrange(1,4))\n        self.check_result('array like', 'iloc', s.index, 'ix', { 0 : [2,4,6], 1 : [3,6,9], 2: [4,8,12] }, typs = ['ints'])\n\n    def test_iloc_getitem_bool(self):\n\n        # boolean indexers\n        b = [True,False,True,False,]\n        self.check_result('bool', 'iloc', b, 'ix', b, typs = ['ints'])\n        self.check_result('bool', 'iloc', b, 'ix', b, typs = ['labels','mixed','ts','floats','empty'], fails = IndexError)\n\n    def test_iloc_getitem_slice(self):\n\n        # slices\n        self.check_result('slice', 'iloc', slice(1,3), 'ix', { 0 : [2,4], 1: [3,6], 2: [4,8] }, typs = ['ints'])\n        self.check_result('slice', 'iloc', slice(1,3), 'indexer', slice(1,3), typs = ['labels','mixed','ts','floats','empty'], fails = IndexError)\n\n    def test_iloc_getitem_slice_dups(self):\n\n        df1 = DataFrame(np.random.randn(10,4),columns=['A','A','B','B'])\n        df2 = DataFrame(np.random.randint(0,10,size=20).reshape(10,2),columns=['A','C'])\n\n        # axis=1\n        df = concat([df1,df2],axis=1)\n        assert_frame_equal(df.iloc[:,:4],df1)\n        assert_frame_equal(df.iloc[:,4:],df2)\n\n        df = concat([df2,df1],axis=1)\n        assert_frame_equal(df.iloc[:,:2],df2)\n        assert_frame_equal(df.iloc[:,2:],df1)\n\n        assert_frame_equal(df.iloc[:,0:3],concat([df2,df1.iloc[:,[0]]],axis=1))\n\n        # axis=0\n        df = concat([df,df],axis=0)\n        assert_frame_equal(df.iloc[0:10,:2],df2)\n        assert_frame_equal(df.iloc[0:10,2:],df1)\n        assert_frame_equal(df.iloc[10:,:2],df2)\n        assert_frame_equal(df.iloc[10:,2:],df1)\n\n    def test_iloc_getitem_multiindex(self):\n\n        arr = np.random.randn(3, 3)\n        df = DataFrame(arr,\n                       columns=[[2,2,4],[6,8,10]],\n                       index=[[4,4,8],[8,10,12]])\n\n        rs = df.iloc[2]\n        xp = Series(arr[2],index=df.columns)\n        assert_series_equal(rs, xp)\n\n        rs = df.iloc[:,2]\n        xp = Series(arr[:, 2],index=df.index)\n        assert_series_equal(rs, xp)\n\n        rs = df.iloc[2,2]\n        xp = df.values[2,2]\n        self.assertEqual(rs, xp)\n\n        # for multiple items\n        # GH 5528\n        rs = df.iloc[[0,1]]\n        xp = df.xs(4,drop_level=False)\n        assert_frame_equal(rs,xp)\n\n        tup = zip(*[['a','a','b','b'],['x','y','x','y']])\n        index = MultiIndex.from_tuples(tup)\n        df = DataFrame(np.random.randn(4, 4), index=index)\n        rs = df.iloc[[2, 3]]\n        xp = df.xs('b',drop_level=False)\n        assert_frame_equal(rs,xp)\n\n    def test_iloc_setitem(self):\n        df = self.frame_ints\n\n        df.iloc[1,1] = 1\n        result = df.iloc[1,1]\n        self.assertEqual(result, 1)\n\n        df.iloc[:,2:3] = 0\n        expected = df.iloc[:,2:3]\n        result = df.iloc[:,2:3]\n        assert_frame_equal(result, expected)\n\n        # GH5771\n        s = Series(0,index=[4,5,6])\n        s.iloc[1:2] += 1\n        expected = Series([0,1,0],index=[4,5,6])\n        assert_series_equal(s, expected)\n\n    def test_ix_loc_setitem_consistency(self):\n\n        # GH 5771\n        # loc with slice and series\n        s = Series(0,index=[4,5,6])\n        s.loc[4:5] += 1\n        expected = Series([1,1,0],index=[4,5,6])\n        assert_series_equal(s, expected)\n\n        # GH 5928\n        # chained indexing assignment\n        df = DataFrame({'a' : [0,1,2] })\n        expected = df.copy()\n        expected.ix[[0,1,2],'a'] = -expected.ix[[0,1,2],'a']\n\n        df['a'].ix[[0,1,2]] = -df['a'].ix[[0,1,2]]\n        assert_frame_equal(df,expected)\n\n        df = DataFrame({'a' : [0,1,2], 'b' :[0,1,2] })\n        df['a'].ix[[0,1,2]] = -df['a'].ix[[0,1,2]].astype('float64') + 0.5\n        expected = DataFrame({'a' : [0.5,-0.5,-1.5], 'b' : [0,1,2] })\n        assert_frame_equal(df,expected)\n\n        # GH 8607\n        # ix setitem consistency\n        df = DataFrame(\n            {'timestamp':[1413840976, 1413842580, 1413760580],\n             'delta':[1174, 904, 161],\n             'elapsed':[7673, 9277, 1470]\n             })\n        expected = DataFrame(\n            {'timestamp':pd.to_datetime([1413840976, 1413842580, 1413760580], unit='s'),\n             'delta':[1174, 904, 161],\n             'elapsed':[7673, 9277, 1470]\n             })\n\n        df2 = df.copy()\n        df2['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n        assert_frame_equal(df2,expected)\n\n        df2 = df.copy()\n        df2.loc[:,'timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n        assert_frame_equal(df2,expected)\n\n        df2 = df.copy()\n        df2.ix[:,2] = pd.to_datetime(df['timestamp'], unit='s')\n        assert_frame_equal(df2,expected)\n\n    def test_ix_loc_consistency(self):\n\n        # GH 8613\n        # some edge cases where ix/loc should return the same\n        # this is not an exhaustive case\n\n        def compare(result, expected):\n            if lib.isscalar(expected):\n                self.assertEqual(result, expected)\n            else:\n                self.assertTrue(expected.equals(result))\n\n        # failure cases for .loc, but these work for .ix\n        df = pd.DataFrame(np.random.randn(5,4), columns=list('ABCD'))\n        for key in [ slice(1,3), tuple([slice(0,2),slice(0,2)]), tuple([slice(0,2),df.columns[0:2]]) ]:\n\n            for index in [ tm.makeStringIndex, tm.makeUnicodeIndex,\n                           tm.makeDateIndex, tm.makePeriodIndex, tm.makeTimedeltaIndex ]:\n                df.index = index(len(df.index))\n                df.ix[key]\n\n                self.assertRaises(TypeError, lambda : df.loc[key])\n\n        df = pd.DataFrame(np.random.randn(5,4), columns=list('ABCD'), index=pd.date_range('2012-01-01', periods=5))\n\n        for key in [ '2012-01-03',\n                     '2012-01-31',\n                     slice('2012-01-03','2012-01-03'),\n                     slice('2012-01-03','2012-01-04'),\n                     slice('2012-01-03','2012-01-06',2),\n                     slice('2012-01-03','2012-01-31'),\n                     tuple([[True,True,True,False,True]]),\n                     ]:\n\n            # getitem\n\n            # if the expected raises, then compare the exceptions\n            try:\n                expected = df.ix[key]\n            except KeyError:\n                self.assertRaises(KeyError, lambda : df.loc[key])\n                continue\n\n            result = df.loc[key]\n            compare(result, expected)\n\n            # setitem\n            df1 = df.copy()\n            df2 = df.copy()\n\n            df1.ix[key] = 10\n            df2.loc[key] = 10\n            compare(df2, df1)\n\n        # edge cases\n        s = Series([1,2,3,4], index=list('abde'))\n\n        result1 = s['a':'c']\n        result2 = s.ix['a':'c']\n        result3 = s.loc['a':'c']\n        assert_series_equal(result1,result2)\n        assert_series_equal(result1,result3)\n\n        # now work rather than raising KeyError\n        s = Series(range(5),[-2,-1,1,2,3])\n\n        result1 = s.ix[-10:3]\n        result2 = s.loc[-10:3]\n        assert_series_equal(result1,result2)\n\n        result1 = s.ix[0:3]\n        result2 = s.loc[0:3]\n        assert_series_equal(result1,result2)\n\n    def test_loc_setitem_multiindex(self):\n\n        # GH7190\n        index = pd.MultiIndex.from_product([np.arange(0,100), np.arange(0, 80)], names=['time', 'firm'])\n        t, n = 0, 2\n\n        df = DataFrame(np.nan,columns=['A', 'w', 'l', 'a', 'x', 'X', 'd', 'profit'], index=index)\n        df.loc[(t,n),'X'] = 0\n        result = df.loc[(t,n),'X']\n        self.assertEqual(result, 0)\n\n        df = DataFrame(-999,columns=['A', 'w', 'l', 'a', 'x', 'X', 'd', 'profit'], index=index)\n        df.loc[(t,n),'X'] = 1\n        result = df.loc[(t,n),'X']\n        self.assertEqual(result, 1)\n\n        df = DataFrame(columns=['A', 'w', 'l', 'a', 'x', 'X', 'd', 'profit'], index=index)\n        df.loc[(t,n),'X'] = 2\n        result = df.loc[(t,n),'X']\n        self.assertEqual(result, 2)\n\n        # GH 7218, assinging with 0-dim arrays\n        df = DataFrame(-999,columns=['A', 'w', 'l', 'a', 'x', 'X', 'd', 'profit'], index=index)\n        df.loc[(t,n), 'X'] = np.array(3)\n        result = df.loc[(t,n),'X']\n        self.assertEqual(result,3)\n\n    def test_loc_setitem_dups(self):\n\n        # GH 6541\n        df_orig = DataFrame({'me' : list('rttti'),\n                             'foo': list('aaade'),\n                             'bar': np.arange(5,dtype='float64')*1.34+2,\n                             'bar2': np.arange(5,dtype='float64')*-.34+2}).set_index('me')\n\n        indexer = tuple(['r',['bar','bar2']])\n        df = df_orig.copy()\n        df.loc[indexer]*=2.0\n        assert_series_equal(df.loc[indexer],2.0*df_orig.loc[indexer])\n\n        indexer = tuple(['r','bar'])\n        df = df_orig.copy()\n        df.loc[indexer]*=2.0\n        self.assertEqual(df.loc[indexer],2.0*df_orig.loc[indexer])\n\n        indexer = tuple(['t',['bar','bar2']])\n        df = df_orig.copy()\n        df.loc[indexer]*=2.0\n        assert_frame_equal(df.loc[indexer],2.0*df_orig.loc[indexer])\n\n    def test_iloc_setitem_dups(self):\n\n        # GH 6766\n        # iloc with a mask aligning from another iloc\n        df1 = DataFrame([{'A':None, 'B':1},{'A':2, 'B':2}])\n        df2 = DataFrame([{'A':3, 'B':3},{'A':4, 'B':4}])\n        df = concat([df1, df2], axis=1)\n\n        expected = df.fillna(3)\n        expected['A'] = expected['A'].astype('float64')\n        inds = np.isnan(df.iloc[:, 0])\n        mask = inds[inds].index\n        df.iloc[mask,0] = df.iloc[mask,2]\n        assert_frame_equal(df, expected)\n\n        # del a dup column across blocks\n        expected = DataFrame({ 0 : [1,2], 1 : [3,4] })\n        expected.columns=['B','B']\n        del df['A']\n        assert_frame_equal(df, expected)\n\n        # assign back to self\n        df.iloc[[0,1],[0,1]] = df.iloc[[0,1],[0,1]]\n        assert_frame_equal(df, expected)\n\n        # reversed x 2\n        df.iloc[[1,0],[0,1]] = df.iloc[[1,0],[0,1]].reset_index(drop=True)\n        df.iloc[[1,0],[0,1]] = df.iloc[[1,0],[0,1]].reset_index(drop=True)\n        assert_frame_equal(df, expected)\n\n    def test_chained_getitem_with_lists(self):\n\n        # GH6394\n        # Regression in chained getitem indexing with embedded list-like from 0.12\n        def check(result, expected):\n            tm.assert_numpy_array_equal(result,expected)\n            tm.assertIsInstance(result, np.ndarray)\n\n\n        df = DataFrame({'A': 5*[np.zeros(3)], 'B':5*[np.ones(3)]})\n        expected = df['A'].iloc[2]\n        result = df.loc[2,'A']\n        check(result, expected)\n        result2 = df.iloc[2]['A']\n        check(result2, expected)\n        result3 = df['A'].loc[2]\n        check(result3, expected)\n        result4 = df['A'].iloc[2]\n        check(result4, expected)\n\n    def test_loc_getitem_int(self):\n\n        # int label\n        self.check_result('int label', 'loc', 2, 'ix', 2, typs = ['ints'], axes = 0)\n        self.check_result('int label', 'loc', 3, 'ix', 3, typs = ['ints'], axes = 1)\n        self.check_result('int label', 'loc', 4, 'ix', 4, typs = ['ints'], axes = 2)\n        self.check_result('int label', 'loc', 2, 'ix', 2, typs = ['label'], fails = KeyError)\n\n    def test_loc_getitem_label(self):\n\n        # label\n        self.check_result('label', 'loc', 'c',    'ix', 'c',    typs = ['labels'], axes=0)\n        self.check_result('label', 'loc', 'null', 'ix', 'null', typs = ['mixed'] , axes=0)\n        self.check_result('label', 'loc', 8,      'ix', 8,      typs = ['mixed'] , axes=0)\n        self.check_result('label', 'loc', Timestamp('20130102'), 'ix', 1, typs = ['ts'], axes=0)\n        self.check_result('label', 'loc', 'c', 'ix', 'c', typs = ['empty'], fails = KeyError)\n\n    def test_loc_getitem_label_out_of_range(self):\n\n        # out of range label\n        self.check_result('label range', 'loc', 'f', 'ix', 'f', typs = ['ints','labels','mixed','ts'], fails=KeyError)\n        self.check_result('label range', 'loc', 'f', 'ix', 'f', typs = ['floats'], fails=TypeError)\n        self.check_result('label range', 'loc', 20, 'ix', 20, typs = ['ints','labels','mixed'], fails=KeyError)\n        self.check_result('label range', 'loc', 20, 'ix', 20, typs = ['ts'], axes=0, fails=TypeError)\n        self.check_result('label range', 'loc', 20, 'ix', 20, typs = ['floats'], axes=0, fails=TypeError)\n\n    def test_loc_getitem_label_list(self):\n\n        # list of labels\n        self.check_result('list lbl', 'loc', [0,2,4], 'ix', [0,2,4], typs = ['ints'], axes=0)\n        self.check_result('list lbl', 'loc', [3,6,9], 'ix', [3,6,9], typs = ['ints'], axes=1)\n        self.check_result('list lbl', 'loc', [4,8,12], 'ix', [4,8,12], typs = ['ints'], axes=2)\n        self.check_result('list lbl', 'loc', ['a','b','d'], 'ix', ['a','b','d'], typs = ['labels'], axes=0)\n        self.check_result('list lbl', 'loc', ['A','B','C'], 'ix', ['A','B','C'], typs = ['labels'], axes=1)\n        self.check_result('list lbl', 'loc', ['Z','Y','W'], 'ix', ['Z','Y','W'], typs = ['labels'], axes=2)\n        self.check_result('list lbl', 'loc', [2,8,'null'], 'ix', [2,8,'null'], typs = ['mixed'], axes=0)\n        self.check_result('list lbl', 'loc', [Timestamp('20130102'),Timestamp('20130103')], 'ix',\n                          [Timestamp('20130102'),Timestamp('20130103')], typs = ['ts'], axes=0)\n\n        self.check_result('list lbl', 'loc', [0,1,2], 'indexer', [0,1,2], typs = ['empty'], fails = KeyError)\n        self.check_result('list lbl', 'loc', [0,2,3], 'ix', [0,2,3], typs = ['ints'], axes=0, fails = KeyError)\n        self.check_result('list lbl', 'loc', [3,6,7], 'ix', [3,6,7], typs = ['ints'], axes=1, fails = KeyError)\n        self.check_result('list lbl', 'loc', [4,8,10], 'ix', [4,8,10], typs = ['ints'], axes=2, fails = KeyError)\n\n        # fails\n        self.check_result('list lbl', 'loc', [20,30,40], 'ix', [20,30,40], typs = ['ints'], axes=1, fails = KeyError)\n        self.check_result('list lbl', 'loc', [20,30,40], 'ix', [20,30,40], typs = ['ints'], axes=2, fails = KeyError)\n\n        # array like\n        self.check_result('array like', 'loc', Series(index=[0,2,4]).index, 'ix', [0,2,4], typs = ['ints'], axes=0)\n        self.check_result('array like', 'loc', Series(index=[3,6,9]).index, 'ix', [3,6,9], typs = ['ints'], axes=1)\n        self.check_result('array like', 'loc', Series(index=[4,8,12]).index, 'ix', [4,8,12], typs = ['ints'], axes=2)\n\n    def test_loc_getitem_bool(self):\n\n        # boolean indexers\n        b = [True,False,True,False]\n        self.check_result('bool', 'loc', b, 'ix', b, typs = ['ints','labels','mixed','ts','floats'])\n        self.check_result('bool', 'loc', b, 'ix', b, typs = ['empty'], fails = KeyError)\n\n    def test_loc_getitem_int_slice(self):\n\n        # ok\n        self.check_result('int slice2', 'loc', slice(2,4), 'ix', [2,4], typs = ['ints'], axes = 0)\n        self.check_result('int slice2', 'loc', slice(3,6), 'ix', [3,6], typs = ['ints'], axes = 1)\n        self.check_result('int slice2', 'loc', slice(4,8), 'ix', [4,8], typs = ['ints'], axes = 2)\n\n        # GH 3053\n        # loc should treat integer slices like label slices\n        from itertools import product\n\n        index = MultiIndex.from_tuples([t for t in product([6,7,8], ['a', 'b'])])\n        df = DataFrame(np.random.randn(6, 6), index, index)\n        result = df.loc[6:8,:]\n        expected = df.ix[6:8,:]\n        assert_frame_equal(result,expected)\n\n        index = MultiIndex.from_tuples([t for t in product([10, 20, 30], ['a', 'b'])])\n        df = DataFrame(np.random.randn(6, 6), index, index)\n        result = df.loc[20:30,:]\n        expected = df.ix[20:30,:]\n        assert_frame_equal(result,expected)\n\n        # doc examples\n        result = df.loc[10,:]\n        expected = df.ix[10,:]\n        assert_frame_equal(result,expected)\n\n        result = df.loc[:,10]\n        #expected = df.ix[:,10] (this fails)\n        expected = df[10]\n        assert_frame_equal(result,expected)\n\n    def test_loc_to_fail(self):\n\n        # GH3449\n        df = DataFrame(np.random.random((3, 3)),\n                       index=['a', 'b', 'c'],\n                       columns=['e', 'f', 'g'])\n\n        # raise a KeyError?\n        self.assertRaises(KeyError, df.loc.__getitem__, tuple([[1, 2], [1, 2]]))\n\n        # GH  7496\n        # loc should not fallback\n\n        s = Series()\n        s.loc[1] = 1\n        s.loc['a'] = 2\n\n        self.assertRaises(KeyError, lambda : s.loc[-1])\n        self.assertRaises(KeyError, lambda : s.loc[[-1, -2]])\n\n        self.assertRaises(KeyError, lambda : s.loc[['4']])\n\n        s.loc[-1] = 3\n        result = s.loc[[-1,-2]]\n        expected = Series([3,np.nan],index=[-1,-2])\n        assert_series_equal(result, expected)\n\n        s['a'] = 2\n        self.assertRaises(KeyError, lambda : s.loc[[-2]])\n\n        del s['a']\n        def f():\n            s.loc[[-2]] = 0\n        self.assertRaises(KeyError, f)\n\n        # inconsistency between .loc[values] and .loc[values,:]\n        # GH 7999\n        df = DataFrame([['a'],['b']],index=[1,2],columns=['value'])\n\n        def f():\n            df.loc[[3],:]\n        self.assertRaises(KeyError, f)\n\n        def f():\n            df.loc[[3]]\n        self.assertRaises(KeyError, f)\n\n        # at should not fallback\n        # GH 7814\n        s = Series([1,2,3], index=list('abc'))\n        result = s.at['a']\n        self.assertEqual(result, 1)\n        self.assertRaises(ValueError, lambda : s.at[0])\n\n        df = DataFrame({'A' : [1,2,3]},index=list('abc'))\n        result = df.at['a','A']\n        self.assertEqual(result, 1)\n        self.assertRaises(ValueError, lambda : df.at['a',0])\n\n        s = Series([1,2,3], index=[3,2,1])\n        result = s.at[1]\n        self.assertEqual(result, 3)\n        self.assertRaises(ValueError, lambda : s.at['a'])\n\n        df = DataFrame({0 : [1,2,3]},index=[3,2,1])\n        result = df.at[1,0]\n        self.assertEqual(result, 3)\n        self.assertRaises(ValueError, lambda : df.at['a',0])\n\n    def test_loc_getitem_label_slice(self):\n\n        # label slices (with ints)\n        self.check_result('lab slice', 'loc', slice(1,3), 'ix', slice(1,3), typs = ['labels','mixed','empty','ts','floats'], fails=TypeError)\n\n        # real label slices\n        self.check_result('lab slice', 'loc', slice('a','c'), 'ix', slice('a','c'), typs = ['labels'], axes=0)\n        self.check_result('lab slice', 'loc', slice('A','C'), 'ix', slice('A','C'), typs = ['labels'], axes=1)\n        self.check_result('lab slice', 'loc', slice('W','Z'), 'ix', slice('W','Z'), typs = ['labels'], axes=2)\n\n        self.check_result('ts  slice', 'loc', slice('20130102','20130104'), 'ix', slice('20130102','20130104'), typs = ['ts'], axes=0)\n        self.check_result('ts  slice', 'loc', slice('20130102','20130104'), 'ix', slice('20130102','20130104'), typs = ['ts'], axes=1, fails=TypeError)\n        self.check_result('ts  slice', 'loc', slice('20130102','20130104'), 'ix', slice('20130102','20130104'), typs = ['ts'], axes=2, fails=TypeError)\n\n        self.check_result('mixed slice', 'loc', slice(2,8), 'ix', slice(2,8), typs = ['mixed'], axes=0, fails=TypeError)\n        self.check_result('mixed slice', 'loc', slice(2,8), 'ix', slice(2,8), typs = ['mixed'], axes=1, fails=KeyError)\n        self.check_result('mixed slice', 'loc', slice(2,8), 'ix', slice(2,8), typs = ['mixed'], axes=2, fails=KeyError)\n\n        self.check_result('mixed slice', 'loc', slice(2,4,2), 'ix', slice(2,4,2), typs = ['mixed'], axes=0, fails=TypeError)\n\n    def test_loc_general(self):\n\n        df = DataFrame(np.random.rand(4,4),columns=['A','B','C','D'], index=['A','B','C','D'])\n\n        # want this to work\n        result = df.loc[:,\"A\":\"B\"].iloc[0:2,:]\n        self.assertTrue((result.columns == ['A','B']).all() == True)\n        self.assertTrue((result.index == ['A','B']).all() == True)\n\n        # mixed type\n        result = DataFrame({ 'a' : [Timestamp('20130101')], 'b' : [1] }).iloc[0]\n        expected = Series([ Timestamp('20130101'), 1], index=['a','b'], name=0)\n        assert_series_equal(result, expected)\n        self.assertEqual(result.dtype, object)\n\n    def test_loc_setitem_consistency(self):\n\n        # GH 6149\n        # coerce similary for setitem and loc when rows have a null-slice\n        expected = DataFrame({ 'date': Series(0,index=range(5),dtype=np.int64),\n                               'val' : Series(range(5),dtype=np.int64) })\n\n        df = DataFrame({ 'date': date_range('2000-01-01','2000-01-5'),\n                         'val' : Series(range(5),dtype=np.int64) })\n        df.loc[:,'date'] = 0\n        assert_frame_equal(df,expected)\n\n        df = DataFrame({ 'date': date_range('2000-01-01','2000-01-5'),\n                         'val' : Series(range(5),dtype=np.int64) })\n        df.loc[:,'date'] = np.array(0,dtype=np.int64)\n        assert_frame_equal(df,expected)\n\n        df = DataFrame({ 'date': date_range('2000-01-01','2000-01-5'),\n                         'val' : Series(range(5),dtype=np.int64) })\n        df.loc[:,'date'] = np.array([0,0,0,0,0],dtype=np.int64)\n        assert_frame_equal(df,expected)\n\n        expected = DataFrame({ 'date': Series('foo',index=range(5)),\n                               'val' : Series(range(5),dtype=np.int64) })\n        df = DataFrame({ 'date': date_range('2000-01-01','2000-01-5'),\n                         'val' : Series(range(5),dtype=np.int64) })\n        df.loc[:,'date'] = 'foo'\n        assert_frame_equal(df,expected)\n\n        expected = DataFrame({ 'date': Series(1.0,index=range(5)),\n                               'val' : Series(range(5),dtype=np.int64) })\n        df = DataFrame({ 'date': date_range('2000-01-01','2000-01-5'),\n                         'val' : Series(range(5),dtype=np.int64) })\n        df.loc[:,'date'] = 1.0\n        assert_frame_equal(df,expected)\n\n        # empty (essentially noops)\n        expected = DataFrame(columns=['x', 'y'])\n        expected['x'] = expected['x'].astype(np.int64)\n        df = DataFrame(columns=['x', 'y'])\n        df.loc[:, 'x'] = 1\n        assert_frame_equal(df,expected)\n\n        df = DataFrame(columns=['x', 'y'])\n        df['x'] = 1\n        assert_frame_equal(df,expected)\n\n        # .loc[:,column] setting with slice == len of the column\n        # GH10408\n        data = \"\"\"Level_0,,,Respondent,Respondent,Respondent,OtherCat,OtherCat\nLevel_1,,,Something,StartDate,EndDate,Yes/No,SomethingElse\nRegion,Site,RespondentID,,,,,\nRegion_1,Site_1,3987227376,A,5/25/2015 10:59,5/25/2015 11:22,Yes,\nRegion_1,Site_1,3980680971,A,5/21/2015 9:40,5/21/2015 9:52,Yes,Yes\nRegion_1,Site_2,3977723249,A,5/20/2015 8:27,5/20/2015 8:41,Yes,\nRegion_1,Site_2,3977723089,A,5/20/2015 8:33,5/20/2015 9:09,Yes,No\"\"\"\n\n        df = pd.read_csv(StringIO(data),header=[0,1], index_col=[0,1,2])\n        df.loc[:,('Respondent','StartDate')] = pd.to_datetime(df.loc[:,('Respondent','StartDate')])\n        df.loc[:,('Respondent','EndDate')] = pd.to_datetime(df.loc[:,('Respondent','EndDate')])\n        df.loc[:,('Respondent','Duration')] = df.loc[:,('Respondent','EndDate')] - df.loc[:,('Respondent','StartDate')]\n\n        df.loc[:,('Respondent','Duration')] = df.loc[:,('Respondent','Duration')].astype('timedelta64[s]')\n        expected = Series([1380,720,840,2160.],index=df.index,name=('Respondent','Duration'))\n        assert_series_equal(df[('Respondent','Duration')],expected)\n\n    def test_loc_setitem_frame(self):\n        df = self.frame_labels\n\n        result = df.iloc[0,0]\n\n        df.loc['a','A'] = 1\n        result = df.loc['a','A']\n        self.assertEqual(result, 1)\n\n        result = df.iloc[0,0]\n        self.assertEqual(result, 1)\n\n        df.loc[:,'B':'D'] = 0\n        expected = df.loc[:,'B':'D']\n        result = df.ix[:,1:]\n        assert_frame_equal(result, expected)\n\n        # GH 6254\n        # setting issue\n        df = DataFrame(index=[3, 5, 4], columns=['A'])\n        df.loc[[4, 3, 5], 'A'] = np.array([1, 2, 3],dtype='int64')\n        expected = DataFrame(dict(A = Series([1,2,3],index=[4, 3, 5]))).reindex(index=[3,5,4])\n        assert_frame_equal(df, expected)\n\n        # GH 6252\n        # setting with an empty frame\n        keys1 = ['@' + str(i) for i in range(5)]\n        val1 = np.arange(5,dtype='int64')\n\n        keys2 = ['@' + str(i) for i in range(4)]\n        val2 = np.arange(4,dtype='int64')\n\n        index = list(set(keys1).union(keys2))\n        df = DataFrame(index = index)\n        df['A'] = nan\n        df.loc[keys1, 'A'] = val1\n\n        df['B'] = nan\n        df.loc[keys2, 'B'] = val2\n\n        expected = DataFrame(dict(A = Series(val1,index=keys1), B = Series(val2,index=keys2))).reindex(index=index)\n        assert_frame_equal(df, expected)\n\n        # GH 8669\n        # invalid coercion of nan -> int\n        df = DataFrame({'A' : [1,2,3], 'B' : np.nan })\n        df.loc[df.B > df.A, 'B'] = df.A\n        expected = DataFrame({'A' : [1,2,3], 'B' : np.nan})\n        assert_frame_equal(df, expected)\n\n        # GH 6546\n        # setting with mixed labels\n        df = DataFrame({1:[1,2],2:[3,4],'a':['a','b']})\n\n        result = df.loc[0, [1,2]]\n        expected = Series([1,3],index=[1,2],dtype=object, name=0)\n        assert_series_equal(result, expected)\n\n        expected = DataFrame({1:[5,2],2:[6,4],'a':['a','b']})\n        df.loc[0, [1,2]] = [5,6]\n        assert_frame_equal(df, expected)\n\n    def test_loc_setitem_frame_multiples(self):\n        # multiple setting\n        df = DataFrame({ 'A' : ['foo','bar','baz'],\n                         'B' : Series(range(3),dtype=np.int64) })\n        rhs = df.loc[1:2]\n        rhs.index = df.index[0:2]\n        df.loc[0:1] = rhs\n        expected = DataFrame({ 'A' : ['bar','baz','baz'],\n                               'B' : Series([1,2,2],dtype=np.int64) })\n        assert_frame_equal(df, expected)\n\n\n        # multiple setting with frame on rhs (with M8)\n        df = DataFrame({ 'date' : date_range('2000-01-01','2000-01-5'),\n                         'val'  : Series(range(5),dtype=np.int64) })\n        expected = DataFrame({ 'date' : [Timestamp('20000101'),Timestamp('20000102'),Timestamp('20000101'),\n                                         Timestamp('20000102'),Timestamp('20000103')],\n                               'val'  : Series([0,1,0,1,2],dtype=np.int64) })\n        rhs = df.loc[0:2]\n        rhs.index = df.index[2:5]\n        df.loc[2:4] = rhs\n        assert_frame_equal(df, expected)\n\n    def test_iloc_getitem_frame(self):\n        df = DataFrame(np.random.randn(10, 4), index=lrange(0, 20, 2), columns=lrange(0,8,2))\n\n        result = df.iloc[2]\n        exp = df.ix[4]\n        assert_series_equal(result, exp)\n\n        result = df.iloc[2,2]\n        exp = df.ix[4,4]\n        self.assertEqual(result, exp)\n\n        # slice\n        result = df.iloc[4:8]\n        expected = df.ix[8:14]\n        assert_frame_equal(result, expected)\n\n        result = df.iloc[:,2:3]\n        expected = df.ix[:,4:5]\n        assert_frame_equal(result, expected)\n\n        # list of integers\n        result = df.iloc[[0,1,3]]\n        expected = df.ix[[0,2,6]]\n        assert_frame_equal(result, expected)\n\n        result = df.iloc[[0,1,3],[0,1]]\n        expected = df.ix[[0,2,6],[0,2]]\n        assert_frame_equal(result, expected)\n\n        # neg indicies\n        result = df.iloc[[-1,1,3],[-1,1]]\n        expected = df.ix[[18,2,6],[6,2]]\n        assert_frame_equal(result, expected)\n\n        # dups indicies\n        result = df.iloc[[-1,-1,1,3],[-1,1]]\n        expected = df.ix[[18,18,2,6],[6,2]]\n        assert_frame_equal(result, expected)\n\n        # with index-like\n        s = Series(index=lrange(1,5))\n        result = df.iloc[s.index]\n        expected = df.ix[[2,4,6,8]]\n        assert_frame_equal(result, expected)\n\n        # try with labelled frame\n        df = DataFrame(np.random.randn(10, 4), index=list('abcdefghij'), columns=list('ABCD'))\n\n        result = df.iloc[1,1]\n        exp = df.ix['b','B']\n        self.assertEqual(result, exp)\n\n        result = df.iloc[:,2:3]\n        expected = df.ix[:,['C']]\n        assert_frame_equal(result, expected)\n\n        # negative indexing\n        result = df.iloc[-1,-1]\n        exp = df.ix['j','D']\n        self.assertEqual(result, exp)\n\n        # out-of-bounds exception\n        self.assertRaises(IndexError, df.iloc.__getitem__, tuple([10,5]))\n\n        # trying to use a label\n        self.assertRaises(ValueError, df.iloc.__getitem__, tuple(['j','D']))\n\n    def test_iloc_getitem_panel(self):\n\n        # GH 7189\n        p = Panel(np.arange(4*3*2).reshape(4,3,2),\n                  items=['A','B','C','D'],\n                  major_axis=['a','b','c'],\n                  minor_axis=['one','two'])\n\n        result = p.iloc[1]\n        expected = p.loc['B']\n        assert_frame_equal(result, expected)\n\n        result = p.iloc[1,1]\n        expected = p.loc['B','b']\n        assert_series_equal(result, expected)\n\n        result = p.iloc[1,1,1]\n        expected = p.loc['B','b','two']\n        self.assertEqual(result,expected)\n\n        # slice\n        result = p.iloc[1:3]\n        expected = p.loc[['B','C']]\n        assert_panel_equal(result, expected)\n\n        result = p.iloc[:,0:2]\n        expected = p.loc[:,['a','b']]\n        assert_panel_equal(result, expected)\n\n        # list of integers\n        result = p.iloc[[0,2]]\n        expected = p.loc[['A','C']]\n        assert_panel_equal(result, expected)\n\n        # neg indicies\n        result = p.iloc[[-1,1],[-1,1]]\n        expected = p.loc[['D','B'],['c','b']]\n        assert_panel_equal(result, expected)\n\n        # dups indicies\n        result = p.iloc[[-1,-1,1],[-1,1]]\n        expected = p.loc[['D','D','B'],['c','b']]\n        assert_panel_equal(result, expected)\n\n        # combined\n        result = p.iloc[0,[True,True],[0,1]]\n        expected = p.loc['A',['a','b'],['one','two']]\n        assert_frame_equal(result, expected)\n\n        # out-of-bounds exception\n        self.assertRaises(IndexError, p.iloc.__getitem__, tuple([10,5]))\n        def f():\n            p.iloc[0,[True,True],[0,1,2]]\n        self.assertRaises(IndexError, f)\n\n        # trying to use a label\n        self.assertRaises(ValueError, p.iloc.__getitem__, tuple(['j','D']))\n\n        # GH\n        p = Panel(np.random.rand(4,3,2), items=['A','B','C','D'], major_axis=['U','V','W'], minor_axis=['X','Y'])\n        expected = p['A']\n\n        result = p.iloc[0,:,:]\n        assert_frame_equal(result, expected)\n\n        result = p.iloc[0,[True,True,True],:]\n        assert_frame_equal(result, expected)\n\n        result = p.iloc[0,[True,True,True],[0,1]]\n        assert_frame_equal(result, expected)\n\n        def f():\n            p.iloc[0,[True,True,True],[0,1,2]]\n        self.assertRaises(IndexError, f)\n\n        def f():\n            p.iloc[0,[True,True,True],[2]]\n        self.assertRaises(IndexError, f)\n\n        # GH 7199\n        # Panel with multi-index\n        multi_index = pd.MultiIndex.from_tuples([('ONE', 'one'),\n                                                 ('TWO', 'two'),\n                                                 ('THREE', 'three')],\n                                                names=['UPPER', 'lower'])\n\n        simple_index = [x[0] for x in multi_index]\n        wd1 = Panel(items=['First', 'Second'],\n                    major_axis=['a', 'b', 'c', 'd'],\n                    minor_axis=multi_index)\n\n        wd2 = Panel(items=['First', 'Second'],\n                    major_axis=['a', 'b', 'c', 'd'],\n                    minor_axis=simple_index)\n\n        expected1 = wd1['First'].iloc[[True, True, True, False], [0, 2]]\n        result1 = wd1.iloc[0, [True, True, True, False], [0, 2]]  # WRONG\n        assert_frame_equal(result1,expected1)\n\n        expected2 = wd2['First'].iloc[[True, True, True, False], [0, 2]]\n        result2 = wd2.iloc[0, [True, True, True, False], [0, 2]]\n        assert_frame_equal(result2,expected2)\n\n        expected1 = DataFrame(index=['a'],columns=multi_index,dtype='float64')\n        result1 = wd1.iloc[0,[0],[0,1,2]]\n        assert_frame_equal(result1,expected1)\n\n        expected2 = DataFrame(index=['a'],columns=simple_index,dtype='float64')\n        result2 = wd2.iloc[0,[0],[0,1,2]]\n        assert_frame_equal(result2,expected2)\n\n        # GH 7516\n        mi = MultiIndex.from_tuples([(0,'x'), (1,'y'), (2,'z')])\n        p = Panel(np.arange(3*3*3,dtype='int64').reshape(3,3,3), items=['a','b','c'], major_axis=mi, minor_axis=['u','v','w'])\n        result = p.iloc[:, 1, 0]\n        expected = Series([3,12,21],index=['a','b','c'], name='u')\n        assert_series_equal(result,expected)\n\n        result = p.loc[:, (1,'y'), 'u']\n        assert_series_equal(result,expected)\n\n    def test_iloc_getitem_doc_issue(self):\n\n        # multi axis slicing issue with single block\n        # surfaced in GH 6059\n\n        arr = np.random.randn(6,4)\n        index = date_range('20130101',periods=6)\n        columns = list('ABCD')\n        df = DataFrame(arr,index=index,columns=columns)\n\n        # defines ref_locs\n        df.describe()\n\n        result = df.iloc[3:5,0:2]\n        str(result)\n        result.dtypes\n\n        expected = DataFrame(arr[3:5,0:2],index=index[3:5],columns=columns[0:2])\n        assert_frame_equal(result,expected)\n\n        # for dups\n        df.columns = list('aaaa')\n        result = df.iloc[3:5,0:2]\n        str(result)\n        result.dtypes\n\n        expected = DataFrame(arr[3:5,0:2],index=index[3:5],columns=list('aa'))\n        assert_frame_equal(result,expected)\n\n        # related\n        arr = np.random.randn(6,4)\n        index = list(range(0,12,2))\n        columns = list(range(0,8,2))\n        df = DataFrame(arr,index=index,columns=columns)\n\n        df._data.blocks[0].mgr_locs\n        result = df.iloc[1:5,2:4]\n        str(result)\n        result.dtypes\n        expected = DataFrame(arr[1:5,2:4],index=index[1:5],columns=columns[2:4])\n        assert_frame_equal(result,expected)\n\n    def test_setitem_ndarray_1d(self):\n        # GH5508\n\n        # len of indexer vs length of the 1d ndarray\n        df = DataFrame(index=Index(lrange(1,11)))\n        df['foo'] = np.zeros(10, dtype=np.float64)\n        df['bar'] = np.zeros(10, dtype=np.complex)\n\n        # invalid\n        def f():\n            df.ix[2:5, 'bar'] = np.array([2.33j, 1.23+0.1j, 2.2])\n        self.assertRaises(ValueError, f)\n\n        # valid\n        df.ix[2:5, 'bar'] = np.array([2.33j, 1.23+0.1j, 2.2, 1.0])\n\n        result = df.ix[2:5, 'bar']\n        expected = Series([2.33j, 1.23+0.1j, 2.2, 1.0], index=[2,3,4,5], name='bar')\n        assert_series_equal(result, expected)\n\n        # dtype getting changed?\n        df = DataFrame(index=Index(lrange(1,11)))\n        df['foo'] = np.zeros(10, dtype=np.float64)\n        df['bar'] = np.zeros(10, dtype=np.complex)\n\n        def f():\n            df[2:5] = np.arange(1,4)*1j\n        self.assertRaises(ValueError, f)\n\n    def test_iloc_setitem_series(self):\n        df = DataFrame(np.random.randn(10, 4), index=list('abcdefghij'), columns=list('ABCD'))\n\n        df.iloc[1,1] = 1\n        result = df.iloc[1,1]\n        self.assertEqual(result, 1)\n\n        df.iloc[:,2:3] = 0\n        expected = df.iloc[:,2:3]\n        result = df.iloc[:,2:3]\n        assert_frame_equal(result, expected)\n\n        s = Series(np.random.randn(10), index=lrange(0,20,2))\n\n        s.iloc[1] = 1\n        result = s.iloc[1]\n        self.assertEqual(result, 1)\n\n        s.iloc[:4] = 0\n        expected = s.iloc[:4]\n        result = s.iloc[:4]\n        assert_series_equal(result, expected)\n\n        s= Series([-1]*6)\n        s.iloc[0::2]= [0,2,4]\n        s.iloc[1::2]= [1,3,5]\n        result  = s\n        expected= Series([0,1,2,3,4,5])\n        assert_series_equal(result, expected)\n\n    def test_iloc_setitem_list_of_lists(self):\n\n        # GH 7551\n        # list-of-list is set incorrectly in mixed vs. single dtyped frames\n        df = DataFrame(dict(A = np.arange(5,dtype='int64'), B = np.arange(5,10,dtype='int64')))\n        df.iloc[2:4] = [[10,11],[12,13]]\n        expected = DataFrame(dict(A = [0,1,10,12,4], B = [5,6,11,13,9]))\n        assert_frame_equal(df, expected)\n\n        df = DataFrame(dict(A = list('abcde'), B = np.arange(5,10,dtype='int64')))\n        df.iloc[2:4] = [['x',11],['y',13]]\n        expected = DataFrame(dict(A = ['a','b','x','y','e'], B = [5,6,11,13,9]))\n        assert_frame_equal(df, expected)\n\n    def test_iloc_getitem_multiindex(self):\n        mi_labels = DataFrame(np.random.randn(4, 3), columns=[['i', 'i', 'j'],\n                                                              ['A', 'A', 'B']],\n                              index=[['i', 'i', 'j', 'k'], ['X', 'X', 'Y','Y']])\n\n        mi_int    = DataFrame(np.random.randn(3, 3),\n                              columns=[[2,2,4],[6,8,10]],\n                              index=[[4,4,8],[8,10,12]])\n\n\n        # the first row\n        rs = mi_int.iloc[0]\n        xp = mi_int.ix[4].ix[8]\n        assert_series_equal(rs, xp, check_names=False)\n        self.assertEqual(rs.name, (4, 8))\n        self.assertEqual(xp.name, 8)\n\n        # 2nd (last) columns\n        rs = mi_int.iloc[:,2]\n        xp = mi_int.ix[:,2]\n        assert_series_equal(rs, xp)\n\n        # corner column\n        rs = mi_int.iloc[2,2]\n        xp = mi_int.ix[:,2].ix[2]\n        self.assertEqual(rs, xp)\n\n        # this is basically regular indexing\n        rs = mi_labels.iloc[2,2]\n        xp = mi_labels.ix['j'].ix[:,'j'].ix[0,0]\n        self.assertEqual(rs, xp)\n\n    def test_loc_multiindex(self):\n\n        mi_labels = DataFrame(np.random.randn(3, 3), columns=[['i', 'i', 'j'],\n                                                              ['A', 'A', 'B']],\n                              index=[['i', 'i', 'j'], ['X', 'X', 'Y']])\n\n        mi_int    = DataFrame(np.random.randn(3, 3),\n                              columns=[[2,2,4],[6,8,10]],\n                              index=[[4,4,8],[8,10,12]])\n\n        # the first row\n        rs = mi_labels.loc['i']\n        xp = mi_labels.ix['i']\n        assert_frame_equal(rs, xp)\n\n        # 2nd (last) columns\n        rs = mi_labels.loc[:,'j']\n        xp = mi_labels.ix[:,'j']\n        assert_frame_equal(rs, xp)\n\n        # corner column\n        rs = mi_labels.loc['j'].loc[:,'j']\n        xp = mi_labels.ix['j'].ix[:,'j']\n        assert_frame_equal(rs,xp)\n\n        # with a tuple\n        rs = mi_labels.loc[('i','X')]\n        xp = mi_labels.ix[('i','X')]\n        assert_frame_equal(rs,xp)\n\n        rs = mi_int.loc[4]\n        xp = mi_int.ix[4]\n        assert_frame_equal(rs,xp)\n\n        # GH6788\n        # multi-index indexer is None (meaning take all)\n        attributes = ['Attribute' + str(i) for i in range(1)]\n        attribute_values = ['Value' + str(i) for i in range(5)]\n\n        index = MultiIndex.from_product([attributes,attribute_values])\n        df = 0.1 * np.random.randn(10, 1 * 5) + 0.5\n        df = DataFrame(df, columns=index)\n        result = df[attributes]\n        assert_frame_equal(result, df)\n\n        # GH 7349\n        # loc with a multi-index seems to be doing fallback\n        df = DataFrame(np.arange(12).reshape(-1,1),index=pd.MultiIndex.from_product([[1,2,3,4],[1,2,3]]))\n\n        expected = df.loc[([1,2],),:]\n        result = df.loc[[1,2]]\n        assert_frame_equal(result, expected)\n\n        # GH 7399\n        # incomplete indexers\n        s = pd.Series(np.arange(15,dtype='int64'),MultiIndex.from_product([range(5), ['a', 'b', 'c']]))\n        expected = s.loc[:, 'a':'c']\n\n        result = s.loc[0:4, 'a':'c']\n        assert_series_equal(result, expected)\n        assert_series_equal(result, expected)\n\n        result = s.loc[:4, 'a':'c']\n        assert_series_equal(result, expected)\n        assert_series_equal(result, expected)\n\n        result = s.loc[0:, 'a':'c']\n        assert_series_equal(result, expected)\n        assert_series_equal(result, expected)\n\n        # GH 7400\n        # multiindexer gettitem with list of indexers skips wrong element\n        s = pd.Series(np.arange(15,dtype='int64'),MultiIndex.from_product([range(5), ['a', 'b', 'c']]))\n        expected = s.iloc[[6,7,8,12,13,14]]\n        result = s.loc[2:4:2, 'a':'c']\n        assert_series_equal(result, expected)\n\n    def test_multiindex_perf_warn(self):\n\n        if sys.version_info < (2, 7):\n            raise nose.SkipTest('python version < 2.7')\n\n        df = DataFrame({'jim':[0, 0, 1, 1],\n                        'joe':['x', 'x', 'z', 'y'],\n                        'jolie':np.random.rand(4)}).set_index(['jim', 'joe'])\n\n        with tm.assert_produces_warning(PerformanceWarning, clear=[pd.core.index]):\n            _ = df.loc[(1, 'z')]\n\n        df = df.iloc[[2,1,3,0]]\n        with tm.assert_produces_warning(PerformanceWarning):\n            _ = df.loc[(0,)]\n\n    def test_multiindex_get_loc(self):  # GH7724, GH2646\n\n        # ignore the warning here\n        warnings.simplefilter('ignore', PerformanceWarning)\n\n        # test indexing into a multi-index before & past the lexsort depth\n        from numpy.random import randint, choice, randn\n        cols = ['jim', 'joe', 'jolie', 'joline', 'jolia']\n\n        def validate(mi, df, key):\n            mask = np.ones(len(df)).astype('bool')\n\n            # test for all partials of this key\n            for i, k in enumerate(key):\n                mask &= df.iloc[:, i] == k\n\n                if not mask.any():\n                    self.assertNotIn(key[:i+1], mi.index)\n                    continue\n\n                self.assertIn(key[:i+1], mi.index)\n                right = df[mask].copy()\n\n                if i + 1 != len(key):  # partial key\n                    right.drop(cols[:i+1], axis=1, inplace=True)\n                    right.set_index(cols[i+1:-1], inplace=True)\n                    assert_frame_equal(mi.loc[key[:i+1]], right)\n\n                else:  # full key\n                    right.set_index(cols[:-1], inplace=True)\n                    if len(right) == 1:  # single hit\n                        right = Series(right['jolia'].values,\n                                name=right.index[0], index=['jolia'])\n                        assert_series_equal(mi.loc[key[:i+1]], right)\n                    else:  # multi hit\n                        assert_frame_equal(mi.loc[key[:i+1]], right)\n\n        def loop(mi, df, keys):\n            for key in keys:\n                validate(mi, df, key)\n\n        n, m = 1000, 50\n\n        vals = [randint(0, 10, n), choice(list('abcdefghij'), n),\n                choice(pd.date_range('20141009', periods=10).tolist(), n),\n                choice(list('ZYXWVUTSRQ'), n), randn(n)]\n        vals = list(map(tuple, zip(*vals)))\n\n        # bunch of keys for testing\n        keys = [randint(0, 11, m), choice(list('abcdefghijk'), m),\n                choice(pd.date_range('20141009', periods=11).tolist(), m),\n                choice(list('ZYXWVUTSRQP'), m)]\n        keys = list(map(tuple, zip(*keys)))\n        keys += list(map(lambda t: t[:-1], vals[::n//m]))\n\n        # covers both unique index and non-unique index\n        df = pd.DataFrame(vals, columns=cols)\n        a, b = pd.concat([df, df]), df.drop_duplicates(subset=cols[:-1])\n\n        for frame in a, b:\n            for i in range(5):  # lexsort depth\n                df = frame.copy() if i == 0 else frame.sort(columns=cols[:i])\n                mi = df.set_index(cols[:-1])\n                assert not mi.index.lexsort_depth < i\n                loop(mi, df, keys)\n\n        # restore\n        warnings.simplefilter('always', PerformanceWarning)\n\n    def test_series_getitem_multiindex(self):\n\n        # GH 6018\n        # series regression getitem with a multi-index\n\n        s = Series([1,2,3])\n        s.index = MultiIndex.from_tuples([(0,0),(1,1), (2,1)])\n\n        result = s[:,0]\n        expected = Series([1],index=[0])\n        assert_series_equal(result,expected)\n\n        result = s.ix[:,1]\n        expected = Series([2,3],index=[1,2])\n        assert_series_equal(result,expected)\n\n        # xs\n        result = s.xs(0,level=0)\n        expected = Series([1],index=[0])\n        assert_series_equal(result,expected)\n\n        result = s.xs(1,level=1)\n        expected = Series([2,3],index=[1,2])\n        assert_series_equal(result,expected)\n\n        # GH6258\n        s = Series([1,3,4,1,3,4],\n                   index=MultiIndex.from_product([list('AB'),\n                                                  list(date_range('20130903',periods=3))]))\n        result = s.xs('20130903',level=1)\n        expected = Series([1,1],index=list('AB'))\n        assert_series_equal(result,expected)\n\n        # GH5684\n        idx = MultiIndex.from_tuples([('a', 'one'), ('a', 'two'),\n                                      ('b', 'one'), ('b', 'two')])\n        s = Series([1, 2, 3, 4], index=idx)\n        s.index.set_names(['L1', 'L2'], inplace=True)\n        result = s.xs('one', level='L2')\n        expected = Series([1, 3], index=['a', 'b'])\n        expected.index.set_names(['L1'], inplace=True)\n        assert_series_equal(result, expected)\n\n    def test_ix_general(self):\n\n        # ix general issues\n\n        # GH 2817\n        data = {'amount': {0: 700, 1: 600, 2: 222, 3: 333, 4: 444},\n                'col': {0: 3.5, 1: 3.5, 2: 4.0, 3: 4.0, 4: 4.0},\n                'year': {0: 2012, 1: 2011, 2: 2012, 3: 2012, 4: 2012}}\n        df = DataFrame(data).set_index(keys=['col', 'year'])\n        key = 4.0, 2012\n\n        # emits a PerformanceWarning, ok\n        tm.assert_frame_equal(df.ix[key], df.iloc[2:])\n\n        # this is ok\n        df.sortlevel(inplace=True)\n        res = df.ix[key]\n        index = MultiIndex.from_arrays([[4] * 3, [2012] * 3],\n                                       names=['col', 'year'])\n        expected = DataFrame({'amount': [222, 333, 444]}, index=index)\n        tm.assert_frame_equal(res, expected)\n\n    def test_ix_weird_slicing(self):\n        ## http://stackoverflow.com/q/17056560/1240268\n        df = DataFrame({'one' : [1, 2, 3, np.nan, np.nan], 'two' : [1, 2, 3, 4, 5]})\n        df.ix[df['one']>1, 'two'] = -df['two']\n\n        expected = DataFrame({'one': {0: 1.0, 1: 2.0, 2: 3.0, 3: nan, 4: nan},\n                              'two': {0: 1, 1: -2, 2: -3, 3: 4, 4: 5}})\n        assert_frame_equal(df, expected)\n\n    def test_xs_multiindex(self):\n\n        # GH2903\n        columns = MultiIndex.from_tuples([('a', 'foo'), ('a', 'bar'), ('b', 'hello'), ('b', 'world')], names=['lvl0', 'lvl1'])\n        df = DataFrame(np.random.randn(4, 4), columns=columns)\n        df.sortlevel(axis=1,inplace=True)\n        result = df.xs('a', level='lvl0', axis=1)\n        expected = df.iloc[:,0:2].loc[:,'a']\n        assert_frame_equal(result,expected)\n\n        result = df.xs('foo', level='lvl1', axis=1)\n        expected = df.iloc[:, 1:2].copy()\n        expected.columns = expected.columns.droplevel('lvl1')\n        assert_frame_equal(result, expected)\n\n    def test_per_axis_per_level_getitem(self):\n\n        # GH6134\n        # example test case\n        ix = MultiIndex.from_product([_mklbl('A',5),_mklbl('B',7),_mklbl('C',4),_mklbl('D',2)])\n        df = DataFrame(np.arange(len(ix.get_values())),index=ix)\n\n        result = df.loc[(slice('A1','A3'),slice(None), ['C1','C3']),:]\n        expected = df.loc[[ tuple([a,b,c,d]) for a,b,c,d in df.index.values if (\n            a == 'A1' or a == 'A2' or a == 'A3') and (c == 'C1' or c == 'C3')]]\n        assert_frame_equal(result, expected)\n\n        expected = df.loc[[ tuple([a,b,c,d]) for a,b,c,d in df.index.values if (\n            a == 'A1' or a == 'A2' or a == 'A3') and (c == 'C1' or c == 'C2' or c == 'C3')]]\n        result = df.loc[(slice('A1','A3'),slice(None), slice('C1','C3')),:]\n        assert_frame_equal(result, expected)\n\n        # test multi-index slicing with per axis and per index controls\n        index = MultiIndex.from_tuples([('A',1),('A',2),('A',3),('B',1)],\n                                       names=['one','two'])\n        columns = MultiIndex.from_tuples([('a','foo'),('a','bar'),('b','foo'),('b','bah')],\n                                         names=['lvl0', 'lvl1'])\n\n        df = DataFrame(np.arange(16,dtype='int64').reshape(4, 4), index=index, columns=columns)\n        df = df.sortlevel(axis=0).sortlevel(axis=1)\n\n        # identity\n        result = df.loc[(slice(None),slice(None)),:]\n        assert_frame_equal(result, df)\n        result = df.loc[(slice(None),slice(None)),(slice(None),slice(None))]\n        assert_frame_equal(result, df)\n        result = df.loc[:,(slice(None),slice(None))]\n        assert_frame_equal(result, df)\n\n        # index\n        result = df.loc[(slice(None),[1]),:]\n        expected = df.iloc[[0,3]]\n        assert_frame_equal(result, expected)\n\n        result = df.loc[(slice(None),1),:]\n        expected = df.iloc[[0,3]]\n        assert_frame_equal(result, expected)\n\n        # columns\n        result = df.loc[:,(slice(None),['foo'])]\n        expected = df.iloc[:,[1,3]]\n        assert_frame_equal(result, expected)\n\n        # both\n        result = df.loc[(slice(None),1),(slice(None),['foo'])]\n        expected = df.iloc[[0,3],[1,3]]\n        assert_frame_equal(result, expected)\n\n        result = df.loc['A','a']\n        expected = DataFrame(dict(bar = [1,5,9], foo = [0,4,8]),\n                             index=Index([1,2,3],name='two'),\n                             columns=Index(['bar','foo'],name='lvl1'))\n        assert_frame_equal(result, expected)\n\n        result = df.loc[(slice(None),[1,2]),:]\n        expected = df.iloc[[0,1,3]]\n        assert_frame_equal(result, expected)\n\n        # multi-level series\n        s = Series(np.arange(len(ix.get_values())),index=ix)\n        result = s.loc['A1':'A3', :, ['C1','C3']]\n        expected = s.loc[[ tuple([a,b,c,d]) for a,b,c,d in s.index.values if (\n            a == 'A1' or a == 'A2' or a == 'A3') and (c == 'C1' or c == 'C3')]]\n        assert_series_equal(result, expected)\n\n        # boolean indexers\n        result = df.loc[(slice(None),df.loc[:,('a','bar')]>5),:]\n        expected = df.iloc[[2,3]]\n        assert_frame_equal(result, expected)\n\n        def f():\n            df.loc[(slice(None),np.array([True,False])),:]\n        self.assertRaises(ValueError, f)\n\n        # ambiguous cases\n        # these can be multiply interpreted (e.g. in this case\n        # as df.loc[slice(None),[1]] as well\n        self.assertRaises(KeyError, lambda : df.loc[slice(None),[1]])\n\n        result = df.loc[(slice(None),[1]),:]\n        expected = df.iloc[[0,3]]\n        assert_frame_equal(result, expected)\n\n        # not lexsorted\n        self.assertEqual(df.index.lexsort_depth,2)\n        df = df.sortlevel(level=1,axis=0)\n        self.assertEqual(df.index.lexsort_depth,0)\n        with tm.assertRaisesRegexp(KeyError, 'MultiIndex Slicing requires the index to be fully lexsorted tuple len \\(2\\), lexsort depth \\(0\\)'):\n            df.loc[(slice(None),df.loc[:,('a','bar')]>5),:]\n\n    def test_multiindex_slicers_non_unique(self):\n\n        # GH 7106\n        # non-unique mi index support\n        df = DataFrame(dict(A = ['foo','foo','foo','foo'],\n                            B = ['a','a','a','a'],\n                            C = [1,2,1,3],\n                            D = [1,2,3,4])).set_index(['A','B','C']).sortlevel()\n        self.assertFalse(df.index.is_unique)\n        expected = DataFrame(dict(A = ['foo','foo'],\n                                  B = ['a','a'],\n                                  C = [1,1],\n                                  D = [1,3])).set_index(['A','B','C']).sortlevel()\n        result = df.loc[(slice(None),slice(None),1),:]\n        assert_frame_equal(result, expected)\n\n        # this is equivalent of an xs expression\n        result = df.xs(1,level=2,drop_level=False)\n        assert_frame_equal(result, expected)\n\n        df = DataFrame(dict(A = ['foo','foo','foo','foo'],\n                            B = ['a','a','a','a'],\n                            C = [1,2,1,2],\n                            D = [1,2,3,4])).set_index(['A','B','C']).sortlevel()\n        self.assertFalse(df.index.is_unique)\n        expected = DataFrame(dict(A = ['foo','foo'],\n                                  B = ['a','a'],\n                                  C = [1,1],\n                                  D = [1,3])).set_index(['A','B','C']).sortlevel()\n        result = df.loc[(slice(None),slice(None),1),:]\n        self.assertFalse(result.index.is_unique)\n        assert_frame_equal(result, expected)\n\n    def test_multiindex_slicers_datetimelike(self):\n\n        # GH 7429\n        # buggy/inconsistent behavior when slicing with datetime-like\n        import datetime\n        dates = [datetime.datetime(2012,1,1,12,12,12) + datetime.timedelta(days=i) for i in range(6)]\n        freq = [1,2]\n        index = MultiIndex.from_product([dates,freq], names=['date','frequency'])\n\n        df = DataFrame(np.arange(6*2*4,dtype='int64').reshape(-1,4),index=index,columns=list('ABCD'))\n\n        # multi-axis slicing\n        idx = pd.IndexSlice\n        expected = df.iloc[[0,2,4],[0,1]]\n        result = df.loc[(slice(Timestamp('2012-01-01 12:12:12'),Timestamp('2012-01-03 12:12:12')),slice(1,1)), slice('A','B')]\n        assert_frame_equal(result,expected)\n\n        result = df.loc[(idx[Timestamp('2012-01-01 12:12:12'):Timestamp('2012-01-03 12:12:12')],idx[1:1]), slice('A','B')]\n        assert_frame_equal(result,expected)\n\n        result = df.loc[(slice(Timestamp('2012-01-01 12:12:12'),Timestamp('2012-01-03 12:12:12')),1), slice('A','B')]\n        assert_frame_equal(result,expected)\n\n        # with strings\n        result = df.loc[(slice('2012-01-01 12:12:12','2012-01-03 12:12:12'),slice(1,1)), slice('A','B')]\n        assert_frame_equal(result,expected)\n\n        result = df.loc[(idx['2012-01-01 12:12:12':'2012-01-03 12:12:12'],1), idx['A','B']]\n        assert_frame_equal(result,expected)\n\n\n    def test_multiindex_slicers_edges(self):\n\n        # GH 8132\n        # various edge cases\n        df = DataFrame({'A': ['A0'] * 5 + ['A1']*5 + ['A2']*5,\n                        'B': ['B0','B0','B1','B1','B2'] * 3,\n                        'DATE': [\"2013-06-11\",\n                                 \"2013-07-02\",\n                                 \"2013-07-09\",\n                                 \"2013-07-30\",\n                                 \"2013-08-06\",\n                                 \"2013-06-11\",\n                                 \"2013-07-02\",\n                                 \"2013-07-09\",\n                                 \"2013-07-30\",\n                                 \"2013-08-06\",\n                                 \"2013-09-03\",\n                                 \"2013-10-01\",\n                                 \"2013-07-09\",\n                                 \"2013-08-06\",\n                                 \"2013-09-03\"],\n                        'VALUES': [22, 35, 14,  9,  4, 40, 18, 4, 2, 5, 1, 2, 3,4, 2]})\n\n        df['DATE'] = pd.to_datetime(df['DATE'])\n        df1 = df.set_index(['A', 'B', 'DATE'])\n        df1 = df1.sortlevel()\n        df2 = df.set_index('DATE')\n\n        # A1 - Get all values under \"A0\" and \"A1\"\n        result = df1.loc[(slice('A1')),:]\n        expected = df1.iloc[0:10]\n        assert_frame_equal(result, expected)\n\n        # A2 - Get all values from the start to \"A2\"\n        result = df1.loc[(slice('A2')),:]\n        expected = df1\n        assert_frame_equal(result, expected)\n\n        # A3 - Get all values under \"B1\" or \"B2\"\n        result = df1.loc[(slice(None),slice('B1','B2')),:]\n        expected = df1.iloc[[2,3,4,7,8,9,12,13,14]]\n        assert_frame_equal(result, expected)\n\n        # A4 - Get all values between 2013-07-02 and 2013-07-09\n        result = df1.loc[(slice(None),slice(None),slice('20130702','20130709')),:]\n        expected = df1.iloc[[1,2,6,7,12]]\n        assert_frame_equal(result, expected)\n\n        # B1 - Get all values in B0 that are also under A0, A1 and A2\n        result = df1.loc[(slice('A2'),slice('B0')),:]\n        expected = df1.iloc[[0,1,5,6,10,11]]\n        assert_frame_equal(result, expected)\n\n        # B2 - Get all values in B0, B1 and B2 (similar to what #2 is doing for the As)\n        result = df1.loc[(slice(None),slice('B2')),:]\n        expected = df1\n        assert_frame_equal(result, expected)\n\n        # B3 - Get all values from B1 to B2 and up to 2013-08-06\n        result = df1.loc[(slice(None),slice('B1','B2'),slice('2013-08-06')),:]\n        expected = df1.iloc[[2,3,4,7,8,9,12,13]]\n        assert_frame_equal(result, expected)\n\n        # B4 - Same as A4 but the start of the date slice is not a key.\n        #      shows indexing on a partial selection slice\n        result = df1.loc[(slice(None),slice(None),slice('20130701','20130709')),:]\n        expected = df1.iloc[[1,2,6,7,12]]\n        assert_frame_equal(result, expected)\n\n    def test_per_axis_per_level_doc_examples(self):\n\n        # test index maker\n        idx = pd.IndexSlice\n\n        # from indexing.rst / advanced\n        index = MultiIndex.from_product([_mklbl('A',4),\n                                         _mklbl('B',2),\n                                         _mklbl('C',4),\n                                         _mklbl('D',2)])\n        columns = MultiIndex.from_tuples([('a','foo'),('a','bar'),\n                                          ('b','foo'),('b','bah')],\n                                         names=['lvl0', 'lvl1'])\n        df = DataFrame(np.arange(len(index)*len(columns),dtype='int64').reshape((len(index),len(columns))),\n                       index=index,\n                       columns=columns)\n        result = df.loc[(slice('A1','A3'),slice(None), ['C1','C3']),:]\n        expected = df.loc[[ tuple([a,b,c,d]) for a,b,c,d in df.index.values if (\n            a == 'A1' or a == 'A2' or a == 'A3') and (c == 'C1' or c == 'C3')]]\n        assert_frame_equal(result, expected)\n        result = df.loc[idx['A1':'A3',:,['C1','C3']],:]\n        assert_frame_equal(result, expected)\n\n        result = df.loc[(slice(None),slice(None), ['C1','C3']),:]\n        expected = df.loc[[ tuple([a,b,c,d]) for a,b,c,d in df.index.values if (\n            c == 'C1' or c == 'C3')]]\n        assert_frame_equal(result, expected)\n        result = df.loc[idx[:,:,['C1','C3']],:]\n        assert_frame_equal(result, expected)\n\n        # not sorted\n        def f():\n            df.loc['A1',(slice(None),'foo')]\n        self.assertRaises(KeyError, f)\n        df = df.sortlevel(axis=1)\n\n        # slicing\n        df.loc['A1',(slice(None),'foo')]\n        df.loc[(slice(None),slice(None), ['C1','C3']),(slice(None),'foo')]\n\n        # setitem\n        df.loc(axis=0)[:,:,['C1','C3']] = -10\n\n    def test_loc_arguments(self):\n\n        index = MultiIndex.from_product([_mklbl('A',4),\n                                         _mklbl('B',2),\n                                         _mklbl('C',4),\n                                         _mklbl('D',2)])\n        columns = MultiIndex.from_tuples([('a','foo'),('a','bar'),\n                                          ('b','foo'),('b','bah')],\n                                         names=['lvl0', 'lvl1'])\n        df = DataFrame(np.arange(len(index)*len(columns),dtype='int64').reshape((len(index),len(columns))),\n                       index=index,\n                       columns=columns).sortlevel().sortlevel(axis=1)\n\n\n        # axis 0\n        result = df.loc(axis=0)['A1':'A3',:,['C1','C3']]\n        expected = df.loc[[ tuple([a,b,c,d]) for a,b,c,d in df.index.values if (\n            a == 'A1' or a == 'A2' or a == 'A3') and (c == 'C1' or c == 'C3')]]\n        assert_frame_equal(result, expected)\n\n        result = df.loc(axis='index')[:,:,['C1','C3']]\n        expected = df.loc[[ tuple([a,b,c,d]) for a,b,c,d in df.index.values if (\n            c == 'C1' or c == 'C3')]]\n        assert_frame_equal(result, expected)\n\n        # axis 1\n        result = df.loc(axis=1)[:,'foo']\n        expected = df.loc[:,(slice(None),'foo')]\n        assert_frame_equal(result, expected)\n\n        result = df.loc(axis='columns')[:,'foo']\n        expected = df.loc[:,(slice(None),'foo')]\n        assert_frame_equal(result, expected)\n\n        # invalid axis\n        def f():\n            df.loc(axis=-1)[:,:,['C1','C3']]\n        self.assertRaises(ValueError, f)\n\n        def f():\n            df.loc(axis=2)[:,:,['C1','C3']]\n        self.assertRaises(ValueError, f)\n\n        def f():\n            df.loc(axis='foo')[:,:,['C1','C3']]\n        self.assertRaises(ValueError, f)\n\n    def test_per_axis_per_level_setitem(self):\n\n        # test index maker\n        idx = pd.IndexSlice\n\n        # test multi-index slicing with per axis and per index controls\n        index = MultiIndex.from_tuples([('A',1),('A',2),('A',3),('B',1)],\n                                       names=['one','two'])\n        columns = MultiIndex.from_tuples([('a','foo'),('a','bar'),('b','foo'),('b','bah')],\n                                         names=['lvl0', 'lvl1'])\n\n        df_orig = DataFrame(np.arange(16,dtype='int64').reshape(4, 4), index=index, columns=columns)\n        df_orig = df_orig.sortlevel(axis=0).sortlevel(axis=1)\n\n        # identity\n        df = df_orig.copy()\n        df.loc[(slice(None),slice(None)),:] = 100\n        expected = df_orig.copy()\n        expected.iloc[:,:] = 100\n        assert_frame_equal(df, expected)\n\n        df = df_orig.copy()\n        df.loc(axis=0)[:,:] = 100\n        expected = df_orig.copy()\n        expected.iloc[:,:] = 100\n        assert_frame_equal(df, expected)\n\n        df = df_orig.copy()\n        df.loc[(slice(None),slice(None)),(slice(None),slice(None))] = 100\n        expected = df_orig.copy()\n        expected.iloc[:,:] = 100\n        assert_frame_equal(df, expected)\n\n        df = df_orig.copy()\n        df.loc[:,(slice(None),slice(None))] = 100\n        expected = df_orig.copy()\n        expected.iloc[:,:] = 100\n        assert_frame_equal(df, expected)\n\n        # index\n        df = df_orig.copy()\n        df.loc[(slice(None),[1]),:] = 100\n        expected = df_orig.copy()\n        expected.iloc[[0,3]] = 100\n        assert_frame_equal(df, expected)\n\n        df = df_orig.copy()\n        df.loc[(slice(None),1),:] = 100\n        expected = df_orig.copy()\n        expected.iloc[[0,3]] = 100\n        assert_frame_equal(df, expected)\n\n        df = df_orig.copy()\n        df.loc(axis=0)[:,1] = 100\n        expected = df_orig.copy()\n        expected.iloc[[0,3]] = 100\n        assert_frame_equal(df, expected)\n\n        # columns\n        df = df_orig.copy()\n        df.loc[:,(slice(None),['foo'])] = 100\n        expected = df_orig.copy()\n        expected.iloc[:,[1,3]] = 100\n        assert_frame_equal(df, expected)\n\n        # both\n        df = df_orig.copy()\n        df.loc[(slice(None),1),(slice(None),['foo'])] = 100\n        expected = df_orig.copy()\n        expected.iloc[[0,3],[1,3]] = 100\n        assert_frame_equal(df, expected)\n\n        df = df_orig.copy()\n        df.loc[idx[:,1],idx[:,['foo']]] = 100\n        expected = df_orig.copy()\n        expected.iloc[[0,3],[1,3]] = 100\n        assert_frame_equal(df, expected)\n\n        df = df_orig.copy()\n        df.loc['A','a'] = 100\n        expected = df_orig.copy()\n        expected.iloc[0:3,0:2] = 100\n        assert_frame_equal(df, expected)\n\n        # setting with a list-like\n        df = df_orig.copy()\n        df.loc[(slice(None),1),(slice(None),['foo'])] = np.array([[100, 100], [100, 100]],dtype='int64')\n        expected = df_orig.copy()\n        expected.iloc[[0,3],[1,3]] = 100\n        assert_frame_equal(df, expected)\n\n        # not enough values\n        df = df_orig.copy()\n        def f():\n            df.loc[(slice(None),1),(slice(None),['foo'])] = np.array([[100], [100, 100]],dtype='int64')\n        self.assertRaises(ValueError, f)\n        def f():\n            df.loc[(slice(None),1),(slice(None),['foo'])] = np.array([100, 100, 100, 100],dtype='int64')\n        self.assertRaises(ValueError, f)\n\n        # with an alignable rhs\n        df = df_orig.copy()\n        df.loc[(slice(None),1),(slice(None),['foo'])] = df.loc[(slice(None),1),(slice(None),['foo'])] * 5\n        expected = df_orig.copy()\n        expected.iloc[[0,3],[1,3]] = expected.iloc[[0,3],[1,3]] * 5\n        assert_frame_equal(df, expected)\n\n        df = df_orig.copy()\n        df.loc[(slice(None),1),(slice(None),['foo'])] *= df.loc[(slice(None),1),(slice(None),['foo'])]\n        expected = df_orig.copy()\n        expected.iloc[[0,3],[1,3]] *= expected.iloc[[0,3],[1,3]]\n        assert_frame_equal(df, expected)\n\n        rhs = df_orig.loc[(slice(None),1),(slice(None),['foo'])].copy()\n        rhs.loc[:,('c','bah')] = 10\n        df = df_orig.copy()\n        df.loc[(slice(None),1),(slice(None),['foo'])] *= rhs\n        expected = df_orig.copy()\n        expected.iloc[[0,3],[1,3]] *= expected.iloc[[0,3],[1,3]]\n        assert_frame_equal(df, expected)\n\n    def test_multiindex_setitem(self):\n\n        # GH 3738\n        # setting with a multi-index right hand side\n        arrays = [np.array(['bar', 'bar', 'baz', 'qux', 'qux', 'bar']),\n                  np.array(['one', 'two', 'one', 'one', 'two', 'one']),\n                  np.arange(0, 6, 1)]\n\n        df_orig = pd.DataFrame(np.random.randn(6, 3),\n                               index=arrays,\n                               columns=['A', 'B', 'C']).sort_index()\n\n        expected = df_orig.loc[['bar']]*2\n        df = df_orig.copy()\n        df.loc[['bar']] *= 2\n        assert_frame_equal(df.loc[['bar']],expected)\n\n        # raise because these have differing levels\n        def f():\n            df.loc['bar'] *= 2\n        self.assertRaises(TypeError, f)\n\n        # from SO\n        #http://stackoverflow.com/questions/24572040/pandas-access-the-level-of-multiindex-for-inplace-operation\n        df_orig = DataFrame.from_dict({'price': {\n            ('DE', 'Coal', 'Stock'): 2,\n            ('DE', 'Gas', 'Stock'): 4,\n            ('DE', 'Elec', 'Demand'): 1,\n            ('FR', 'Gas', 'Stock'): 5,\n            ('FR', 'Solar', 'SupIm'): 0,\n            ('FR', 'Wind', 'SupIm'): 0}})\n        df_orig.index = MultiIndex.from_tuples(df_orig.index, names=['Sit', 'Com', 'Type'])\n\n        expected = df_orig.copy()\n        expected.iloc[[0,2,3]] *= 2\n\n        idx = pd.IndexSlice\n        df = df_orig.copy()\n        df.loc[idx[:,:,'Stock'],:] *= 2\n        assert_frame_equal(df, expected)\n\n        df = df_orig.copy()\n        df.loc[idx[:,:,'Stock'],'price'] *= 2\n        assert_frame_equal(df, expected)\n\n    def test_getitem_multiindex(self):\n\n        # GH 5725\n        # the 'A' happens to be a valid Timestamp so the doesn't raise the appropriate\n        # error, only in PY3 of course!\n        index = MultiIndex(levels=[['D', 'B', 'C'], [0, 26, 27, 37, 57, 67, 75, 82]],\n                           labels=[[0, 0, 0, 1, 2, 2, 2, 2, 2, 2], [1, 3, 4, 6, 0, 2, 2, 3, 5, 7]],\n                           names=['tag', 'day'])\n        arr = np.random.randn(len(index),1)\n        df = DataFrame(arr,index=index,columns=['val'])\n        result = df.val['D']\n        expected = Series(arr.ravel()[0:3],name='val',index=Index([26,37,57],name='day'))\n        assert_series_equal(result,expected)\n\n        def f():\n            df.val['A']\n        self.assertRaises(KeyError, f)\n\n        def f():\n            df.val['X']\n        self.assertRaises(KeyError, f)\n\n        # A is treated as a special Timestamp\n        index = MultiIndex(levels=[['A', 'B', 'C'], [0, 26, 27, 37, 57, 67, 75, 82]],\n                           labels=[[0, 0, 0, 1, 2, 2, 2, 2, 2, 2], [1, 3, 4, 6, 0, 2, 2, 3, 5, 7]],\n                           names=['tag', 'day'])\n        df = DataFrame(arr,index=index,columns=['val'])\n        result = df.val['A']\n        expected = Series(arr.ravel()[0:3],name='val',index=Index([26,37,57],name='day'))\n        assert_series_equal(result,expected)\n\n        def f():\n            df.val['X']\n        self.assertRaises(KeyError, f)\n\n\n        # GH 7866\n        # multi-index slicing with missing indexers\n        s = pd.Series(np.arange(9,dtype='int64'),\n                      index=pd.MultiIndex.from_product([['A','B','C'],['foo','bar','baz']],\n                                                       names=['one','two'])\n                      ).sortlevel()\n\n        expected = pd.Series(np.arange(3,dtype='int64'),\n                             index=pd.MultiIndex.from_product([['A'],['foo','bar','baz']],\n                                                              names=['one','two'])\n                             ).sortlevel()\n\n        result = s.loc[['A']]\n        assert_series_equal(result,expected)\n        result = s.loc[['A','D']]\n        assert_series_equal(result,expected)\n\n        # not any values found\n        self.assertRaises(KeyError, lambda : s.loc[['D']])\n\n        # empty ok\n        result = s.loc[[]]\n        expected = s.iloc[[]]\n        assert_series_equal(result,expected)\n\n        idx = pd.IndexSlice\n        expected = pd.Series([0,3,6],\n                             index=pd.MultiIndex.from_product([['A','B','C'],['foo']],\n                                                              names=['one','two'])\n                             ).sortlevel()\n\n        result = s.loc[idx[:,['foo']]]\n        assert_series_equal(result,expected)\n        result = s.loc[idx[:,['foo','bah']]]\n        assert_series_equal(result,expected)\n\n        # GH 8737\n        # empty indexer\n        multi_index = pd.MultiIndex.from_product((['foo', 'bar', 'baz'], ['alpha', 'beta']))\n        df = DataFrame(np.random.randn(5, 6), index=range(5), columns=multi_index)\n        df = df.sortlevel(0, axis=1)\n\n        expected = DataFrame(index=range(5),columns=multi_index.reindex([])[0])\n        result1 = df.loc[:, ([], slice(None))]\n        result2 = df.loc[:, (['foo'], [])]\n        assert_frame_equal(result1, expected)\n        assert_frame_equal(result2, expected)\n\n        # regression from < 0.14.0\n        # GH 7914\n        df = DataFrame([[np.mean, np.median],['mean','median']],\n                       columns=MultiIndex.from_tuples([('functs','mean'),\n                                                       ('functs','median')]),\n                       index=['function', 'name'])\n        result = df.loc['function',('functs','mean')]\n        self.assertEqual(result,np.mean)\n\n    def test_setitem_dtype_upcast(self):\n\n        # GH3216\n        df = DataFrame([{\"a\": 1}, {\"a\": 3, \"b\": 2}])\n        df['c'] = np.nan\n        self.assertEqual(df['c'].dtype, np.float64)\n\n        df.ix[0,'c'] = 'foo'\n        expected = DataFrame([{\"a\": 1, \"c\" : 'foo'}, {\"a\": 3, \"b\": 2, \"c\" : np.nan}])\n        assert_frame_equal(df,expected)\n\n        # GH10280\n        df = DataFrame(np.arange(6,dtype='int64').reshape(2, 3),\n                       index=list('ab'),\n                       columns=['foo', 'bar', 'baz'])\n\n        for val in [3.14, 'wxyz']:\n            left = df.copy()\n            left.loc['a', 'bar'] = val\n            right = DataFrame([[0, val, 2], [3, 4, 5]],\n                              index=list('ab'),\n                              columns=['foo', 'bar', 'baz'])\n\n            assert_frame_equal(left, right)\n            self.assertTrue(com.is_integer_dtype(left['foo']))\n            self.assertTrue(com.is_integer_dtype(left['baz']))\n\n        left = DataFrame(np.arange(6,dtype='int64').reshape(2, 3) / 10.0,\n                         index=list('ab'),\n                         columns=['foo', 'bar', 'baz'])\n        left.loc['a', 'bar'] = 'wxyz'\n\n        right = DataFrame([[0, 'wxyz', .2], [.3, .4, .5]],\n                          index=list('ab'),\n                          columns=['foo', 'bar', 'baz'])\n\n        assert_frame_equal(left, right)\n        self.assertTrue(com.is_float_dtype(left['foo']))\n        self.assertTrue(com.is_float_dtype(left['baz']))\n\n    def test_setitem_iloc(self):\n\n\n        # setitem with an iloc list\n        df = DataFrame(np.arange(9).reshape((3, 3)), index=[\"A\", \"B\", \"C\"], columns=[\"A\", \"B\", \"C\"])\n        df.iloc[[0,1],[1,2]]\n        df.iloc[[0,1],[1,2]] += 100\n\n        expected = DataFrame(np.array([0,101,102,3,104,105,6,7,8]).reshape((3, 3)), index=[\"A\", \"B\", \"C\"], columns=[\"A\", \"B\", \"C\"])\n        assert_frame_equal(df,expected)\n\n    def test_dups_fancy_indexing(self):\n\n        # GH 3455\n        from pandas.util.testing import makeCustomDataframe as mkdf\n        df= mkdf(10, 3)\n        df.columns = ['a','a','b']\n        cols = ['b','a']\n        result = df[['b','a']].columns\n        expected = Index(['b','a','a'])\n        self.assertTrue(result.equals(expected))\n\n        # across dtypes\n        df = DataFrame([[1,2,1.,2.,3.,'foo','bar']], columns=list('aaaaaaa'))\n        df.head()\n        str(df)\n        result = DataFrame([[1,2,1.,2.,3.,'foo','bar']])\n        result.columns = list('aaaaaaa')\n\n        df_v  = df.iloc[:,4]\n        res_v = result.iloc[:,4]\n\n        assert_frame_equal(df,result)\n\n        # GH 3561, dups not in selected order\n        df = DataFrame({'test': [5,7,9,11], 'test1': [4.,5,6,7], 'other': list('abcd') }, index=['A', 'A', 'B', 'C'])\n        rows = ['C', 'B']\n        expected = DataFrame({'test' : [11,9], 'test1': [ 7., 6], 'other': ['d','c']},index=rows)\n        result = df.ix[rows]\n        assert_frame_equal(result, expected)\n\n        result = df.ix[Index(rows)]\n        assert_frame_equal(result, expected)\n\n        rows = ['C','B','E']\n        expected = DataFrame({'test' : [11,9,np.nan], 'test1': [7.,6,np.nan], 'other': ['d','c',np.nan]},index=rows)\n\n        result = df.ix[rows]\n        assert_frame_equal(result, expected)\n\n        # see GH5553, make sure we use the right indexer\n        rows = ['F','G','H','C','B','E']\n        expected = DataFrame({'test' : [np.nan,np.nan,np.nan,11,9,np.nan],\n                              'test1': [np.nan,np.nan,np.nan,7.,6,np.nan],\n                              'other': [np.nan,np.nan,np.nan,'d','c',np.nan]},index=rows)\n        result = df.ix[rows]\n        assert_frame_equal(result, expected)\n\n        # inconsistent returns for unique/duplicate indices when values are missing\n        df = DataFrame(randn(4,3),index=list('ABCD'))\n        expected = df.ix[['E']]\n\n        dfnu = DataFrame(randn(5,3),index=list('AABCD'))\n        result = dfnu.ix[['E']]\n        assert_frame_equal(result, expected)\n\n        # GH 4619; duplicate indexer with missing label\n        df = DataFrame({\"A\": [0, 1, 2]})\n        result = df.ix[[0,8,0]]\n        expected = DataFrame({\"A\": [0, np.nan, 0]},index=[0,8,0])\n        assert_frame_equal(result,expected)\n\n        df = DataFrame({\"A\": list('abc')})\n        result = df.ix[[0,8,0]]\n        expected = DataFrame({\"A\": ['a', np.nan, 'a']},index=[0,8,0])\n        assert_frame_equal(result,expected)\n\n        # non unique with non unique selector\n        df = DataFrame({'test': [5,7,9,11]}, index=['A','A','B','C'])\n        expected = DataFrame({'test' : [5,7,5,7,np.nan]},index=['A','A','A','A','E'])\n        result = df.ix[['A','A','E']]\n        assert_frame_equal(result, expected)\n\n        # GH 5835\n        # dups on index and missing values\n        df = DataFrame(np.random.randn(5,5),columns=['A','B','B','B','A'])\n\n        expected = pd.concat([df.ix[:,['A','B']],DataFrame(np.nan,columns=['C'],index=df.index)],axis=1)\n        result = df.ix[:,['A','B','C']]\n        assert_frame_equal(result, expected)\n\n        # GH 6504, multi-axis indexing\n        df = DataFrame(np.random.randn(9,2), index=[1,1,1,2,2,2,3,3,3], columns=['a', 'b'])\n\n        expected = df.iloc[0:6]\n        result = df.loc[[1, 2]]\n        assert_frame_equal(result, expected)\n\n        expected = df\n        result = df.loc[:,['a', 'b']]\n        assert_frame_equal(result, expected)\n\n        expected = df.iloc[0:6,:]\n        result = df.loc[[1, 2], ['a', 'b']]\n        assert_frame_equal(result, expected)\n\n    def test_indexing_mixed_frame_bug(self):\n\n        # GH3492\n        df=DataFrame({'a':{1:'aaa',2:'bbb',3:'ccc'},'b':{1:111,2:222,3:333}})\n\n        # this works, new column is created correctly\n        df['test']=df['a'].apply(lambda x: '_' if x=='aaa' else x)\n\n        # this does not work, ie column test is not changed\n        idx=df['test']=='_'\n        temp=df.ix[idx,'a'].apply(lambda x: '-----' if x=='aaa' else x)\n        df.ix[idx,'test']=temp\n        self.assertEqual(df.iloc[0,2], '-----')\n\n        #if I look at df, then element [0,2] equals '_'. If instead I type df.ix[idx,'test'], I get '-----', finally by typing df.iloc[0,2] I get '_'.\n\n\n    def test_set_index_nan(self):\n\n        # GH 3586\n        df = DataFrame({'PRuid': {17: 'nonQC', 18: 'nonQC', 19: 'nonQC', 20: '10', 21: '11', 22: '12', 23: '13',\n                                  24: '24', 25: '35', 26: '46', 27: '47', 28: '48', 29: '59', 30: '10'},\n                        'QC': {17: 0.0, 18: 0.0, 19: 0.0, 20: nan, 21: nan, 22: nan, 23: nan, 24: 1.0, 25: nan,\n                               26: nan, 27: nan, 28: nan, 29: nan, 30: nan},\n                        'data': {17: 7.9544899999999998, 18: 8.0142609999999994, 19: 7.8591520000000008, 20: 0.86140349999999999,\n                                 21: 0.87853110000000001, 22: 0.8427041999999999, 23: 0.78587700000000005, 24: 0.73062459999999996,\n                                 25: 0.81668560000000001, 26: 0.81927080000000008, 27: 0.80705009999999999, 28: 0.81440240000000008,\n                                 29: 0.80140849999999997, 30: 0.81307740000000006},\n                        'year': {17: 2006, 18: 2007, 19: 2008, 20: 1985, 21: 1985, 22: 1985, 23: 1985,\n                                 24: 1985, 25: 1985, 26: 1985, 27: 1985, 28: 1985, 29: 1985, 30: 1986}}).reset_index()\n\n        result = df.set_index(['year','PRuid','QC']).reset_index().reindex(columns=df.columns)\n        assert_frame_equal(result,df)\n\n    def test_multi_nan_indexing(self):\n\n        # GH 3588\n        df = DataFrame({\"a\":['R1', 'R2', np.nan, 'R4'], 'b':[\"C1\", \"C2\", \"C3\" , \"C4\"], \"c\":[10, 15, np.nan , 20]})\n        result = df.set_index(['a','b'], drop=False)\n        expected = DataFrame({\"a\":['R1', 'R2', np.nan, 'R4'], 'b':[\"C1\", \"C2\", \"C3\" , \"C4\"], \"c\":[10, 15, np.nan , 20]},\n                             index = [Index(['R1','R2',np.nan,'R4'],name='a'),Index(['C1','C2','C3','C4'],name='b')])\n        assert_frame_equal(result,expected)\n\n\n    def test_iloc_panel_issue(self):\n\n        # GH 3617\n        p = Panel(randn(4, 4, 4))\n\n        self.assertEqual(p.iloc[:3, :3, :3].shape, (3,3,3))\n        self.assertEqual(p.iloc[1, :3, :3].shape, (3,3))\n        self.assertEqual(p.iloc[:3, 1, :3].shape, (3,3))\n        self.assertEqual(p.iloc[:3, :3, 1].shape, (3,3))\n        self.assertEqual(p.iloc[1, 1, :3].shape, (3,))\n        self.assertEqual(p.iloc[1, :3, 1].shape, (3,))\n        self.assertEqual(p.iloc[:3, 1, 1].shape, (3,))\n\n    def test_panel_getitem(self):\n        # GH4016, date selection returns a frame when a partial string selection\n        ind = date_range(start=\"2000\", freq=\"D\", periods=1000)\n        df = DataFrame(np.random.randn(len(ind), 5), index=ind, columns=list('ABCDE'))\n        panel = Panel(dict([ ('frame_'+c,df) for c in list('ABC') ]))\n\n        test2 = panel.ix[:, \"2002\":\"2002-12-31\"]\n        test1 = panel.ix[:, \"2002\"]\n        tm.assert_panel_equal(test1,test2)\n\n        # GH8710\n        # multi-element getting with a list\n        panel = tm.makePanel()\n\n        expected = panel.iloc[[0,1]]\n\n        result = panel.loc[['ItemA','ItemB']]\n        tm.assert_panel_equal(result,expected)\n\n        result = panel.loc[['ItemA','ItemB'],:,:]\n        tm.assert_panel_equal(result,expected)\n\n        result = panel[['ItemA','ItemB']]\n        tm.assert_panel_equal(result,expected)\n\n        result = panel.loc['ItemA':'ItemB']\n        tm.assert_panel_equal(result,expected)\n\n        result = panel.ix['ItemA':'ItemB']\n        tm.assert_panel_equal(result,expected)\n\n        result = panel.ix[['ItemA','ItemB']]\n        tm.assert_panel_equal(result,expected)\n\n        # with an object-like\n        # GH 9140\n        class TestObject:\n            def __str__(self):\n                return \"TestObject\"\n\n        obj = TestObject()\n\n        p = Panel(np.random.randn(1,5,4), items=[obj],\n                  major_axis = date_range('1/1/2000', periods=5),\n                  minor_axis=['A', 'B', 'C', 'D'])\n\n        expected = p.iloc[0]\n        result = p[obj]\n        tm.assert_frame_equal(result, expected)\n\n    def test_panel_setitem(self):\n\n        # GH 7763\n        # loc and setitem have setting differences\n        np.random.seed(0)\n        index=range(3)\n        columns = list('abc')\n\n        panel = Panel({'A' : DataFrame(np.random.randn(3, 3), index=index, columns=columns),\n                       'B' : DataFrame(np.random.randn(3, 3), index=index, columns=columns),\n                       'C' : DataFrame(np.random.randn(3, 3), index=index, columns=columns)\n                       })\n\n        replace = DataFrame(np.eye(3,3), index=range(3), columns=columns)\n        expected = Panel({ 'A' : replace, 'B' : replace, 'C' : replace })\n\n        p = panel.copy()\n        for idx in list('ABC'):\n            p[idx] = replace\n        tm.assert_panel_equal(p, expected)\n\n        p = panel.copy()\n        for idx in list('ABC'):\n            p.loc[idx,:,:] = replace\n        tm.assert_panel_equal(p, expected)\n\n\n    def test_panel_setitem_with_multiindex(self):\n\n        # 10360\n        # failing with a multi-index\n        arr = np.array([[[1,2,3],[0,0,0]],[[0,0,0],[0,0,0]]],dtype=np.float64)\n\n        # reg index\n        axes = dict(items=['A', 'B'], major_axis=[0, 1], minor_axis=['X', 'Y' ,'Z'])\n        p1 = Panel(0., **axes)\n        p1.iloc[0, 0, :] = [1, 2, 3]\n        expected = Panel(arr, **axes)\n        tm.assert_panel_equal(p1, expected)\n\n        # multi-indexes\n        axes['items'] = pd.MultiIndex.from_tuples([('A','a'), ('B','b')])\n        p2 = Panel(0., **axes)\n        p2.iloc[0, 0, :] = [1, 2, 3]\n        expected = Panel(arr, **axes)\n        tm.assert_panel_equal(p2, expected)\n\n        axes['major_axis']=pd.MultiIndex.from_tuples([('A',1),('A',2)])\n        p3 = Panel(0., **axes)\n        p3.iloc[0, 0, :] = [1, 2, 3]\n        expected = Panel(arr, **axes)\n        tm.assert_panel_equal(p3, expected)\n\n        axes['minor_axis']=pd.MultiIndex.from_product([['X'],range(3)])\n        p4 = Panel(0., **axes)\n        p4.iloc[0, 0, :] = [1, 2, 3]\n        expected = Panel(arr, **axes)\n        tm.assert_panel_equal(p4, expected)\n\n        arr = np.array([[[1,0,0],[2,0,0]],[[0,0,0],[0,0,0]]],dtype=np.float64)\n        p5 = Panel(0., **axes)\n        p5.iloc[0, :, 0] = [1, 2]\n        expected = Panel(arr, **axes)\n        tm.assert_panel_equal(p5, expected)\n\n    def test_panel_assignment(self):\n\n        # GH3777\n        wp = Panel(randn(2, 5, 4), items=['Item1', 'Item2'], major_axis=date_range('1/1/2000', periods=5), minor_axis=['A', 'B', 'C', 'D'])\n        wp2 = Panel(randn(2, 5, 4), items=['Item1', 'Item2'], major_axis=date_range('1/1/2000', periods=5), minor_axis=['A', 'B', 'C', 'D'])\n        expected = wp.loc[['Item1', 'Item2'], :, ['A', 'B']]\n\n        def f():\n            wp.loc[['Item1', 'Item2'], :, ['A', 'B']] = wp2.loc[['Item1', 'Item2'], :, ['A', 'B']]\n        self.assertRaises(NotImplementedError, f)\n\n        #wp.loc[['Item1', 'Item2'], :, ['A', 'B']] = wp2.loc[['Item1', 'Item2'], :, ['A', 'B']]\n        #result = wp.loc[['Item1', 'Item2'], :, ['A', 'B']]\n        #tm.assert_panel_equal(result,expected)\n\n    def test_multiindex_assignment(self):\n\n        # GH3777 part 2\n\n        # mixed dtype\n        df = DataFrame(np.random.randint(5,10,size=9).reshape(3, 3),\n                       columns=list('abc'),\n                       index=[[4,4,8],[8,10,12]])\n        df['d'] = np.nan\n        arr = np.array([0.,1.])\n\n        df.ix[4,'d'] = arr\n        assert_series_equal(df.ix[4,'d'],Series(arr,index=[8,10],name='d'))\n\n        # single dtype\n        df = DataFrame(np.random.randint(5,10,size=9).reshape(3, 3),\n                       columns=list('abc'),\n                       index=[[4,4,8],[8,10,12]])\n\n        df.ix[4,'c'] = arr\n        assert_series_equal(df.ix[4,'c'],Series(arr,index=[8,10],name='c',dtype='int64'))\n\n        # scalar ok\n        df.ix[4,'c'] = 10\n        assert_series_equal(df.ix[4,'c'],Series(10,index=[8,10],name='c',dtype='int64'))\n\n        # invalid assignments\n        def f():\n            df.ix[4,'c'] = [0,1,2,3]\n        self.assertRaises(ValueError, f)\n\n        def f():\n            df.ix[4,'c'] = [0]\n        self.assertRaises(ValueError, f)\n\n        # groupby example\n        NUM_ROWS = 100\n        NUM_COLS = 10\n        col_names = ['A'+num for num in map(str,np.arange(NUM_COLS).tolist())]\n        index_cols = col_names[:5]\n\n        df = DataFrame(np.random.randint(5, size=(NUM_ROWS,NUM_COLS)), dtype=np.int64, columns=col_names)\n        df = df.set_index(index_cols).sort_index()\n        grp = df.groupby(level=index_cols[:4])\n        df['new_col'] = np.nan\n\n        f_index = np.arange(5)\n        def f(name,df2):\n            return Series(np.arange(df2.shape[0]),name=df2.index.values[0]).reindex(f_index)\n        new_df = pd.concat([ f(name,df2) for name, df2 in grp ],axis=1).T\n\n        # we are actually operating on a copy here\n        # but in this case, that's ok\n        for name, df2 in grp:\n            new_vals = np.arange(df2.shape[0])\n            df.ix[name, 'new_col'] = new_vals\n\n    def test_multi_assign(self):\n\n        # GH 3626, an assignement of a sub-df to a df\n        df = DataFrame({'FC':['a','b','a','b','a','b'],\n                        'PF':[0,0,0,0,1,1],\n                        'col1':lrange(6),\n                        'col2':lrange(6,12)})\n        df.ix[1,0]=np.nan\n        df2 = df.copy()\n\n        mask=~df2.FC.isnull()\n        cols=['col1', 'col2']\n\n        dft = df2 * 2\n        dft.ix[3,3] = np.nan\n\n        expected = DataFrame({'FC':['a',np.nan,'a','b','a','b'],\n                              'PF':[0,0,0,0,1,1],\n                              'col1':Series([0,1,4,6,8,10]),\n                              'col2':[12,7,16,np.nan,20,22]})\n\n\n        # frame on rhs\n        df2.ix[mask, cols]= dft.ix[mask, cols]\n        assert_frame_equal(df2,expected)\n\n        df2.ix[mask, cols]= dft.ix[mask, cols]\n        assert_frame_equal(df2,expected)\n\n        # with an ndarray on rhs\n        df2 = df.copy()\n        df2.ix[mask, cols]= dft.ix[mask, cols].values\n        assert_frame_equal(df2,expected)\n        df2.ix[mask, cols]= dft.ix[mask, cols].values\n        assert_frame_equal(df2,expected)\n\n        # broadcasting on the rhs is required\n        df = DataFrame(dict(A = [1,2,0,0,0],B=[0,0,0,10,11],C=[0,0,0,10,11],D=[3,4,5,6,7]))\n\n        expected = df.copy()\n        mask = expected['A'] == 0\n        for col in ['A','B']:\n            expected.loc[mask,col] = df['D']\n\n        df.loc[df['A']==0,['A','B']] = df['D']\n        assert_frame_equal(df,expected)\n\n    def test_ix_assign_column_mixed(self):\n        # GH #1142\n        df = DataFrame(tm.getSeriesData())\n        df['foo'] = 'bar'\n\n        orig = df.ix[:, 'B'].copy()\n        df.ix[:, 'B'] = df.ix[:, 'B'] + 1\n        assert_series_equal(df.B, orig + 1)\n\n        # GH 3668, mixed frame with series value\n        df = DataFrame({'x':lrange(10), 'y':lrange(10,20),'z' : 'bar'})\n        expected = df.copy()\n\n        for i in range(5):\n            indexer = i*2\n            v = 1000 + i*200\n            expected.ix[indexer, 'y'] = v\n            self.assertEqual(expected.ix[indexer, 'y'], v)\n\n        df.ix[df.x % 2 == 0, 'y'] = df.ix[df.x % 2 == 0, 'y'] * 100\n        assert_frame_equal(df,expected)\n\n        # GH 4508, making sure consistency of assignments\n        df = DataFrame({'a':[1,2,3],'b':[0,1,2]})\n        df.ix[[0,2,],'b'] = [100,-100]\n        expected = DataFrame({'a' : [1,2,3], 'b' : [100,1,-100] })\n        assert_frame_equal(df,expected)\n\n        df = pd.DataFrame({'a': lrange(4) })\n        df['b'] = np.nan\n        df.ix[[1,3],'b'] = [100,-100]\n        expected = DataFrame({'a' : [0,1,2,3], 'b' : [np.nan,100,np.nan,-100] })\n        assert_frame_equal(df,expected)\n\n        # ok, but chained assignments are dangerous\n        # if we turn off chained assignement it will work\n        with option_context('chained_assignment',None):\n            df = pd.DataFrame({'a': lrange(4) })\n            df['b'] = np.nan\n            df['b'].ix[[1,3]] = [100,-100]\n            assert_frame_equal(df,expected)\n\n    def test_ix_get_set_consistency(self):\n\n        # GH 4544\n        # ix/loc get/set not consistent when\n        # a mixed int/string index\n        df = DataFrame(np.arange(16).reshape((4, 4)),\n                       columns=['a', 'b', 8, 'c'],\n                       index=['e', 7, 'f', 'g'])\n\n        self.assertEqual(df.ix['e', 8], 2)\n        self.assertEqual(df.loc['e', 8], 2)\n\n        df.ix['e', 8] = 42\n        self.assertEqual(df.ix['e', 8], 42)\n        self.assertEqual(df.loc['e', 8], 42)\n\n        df.loc['e', 8] = 45\n        self.assertEqual(df.ix['e', 8], 45)\n        self.assertEqual(df.loc['e', 8], 45)\n\n    def test_setitem_list(self):\n\n        # GH 6043\n        # ix with a list\n        df = DataFrame(index=[0,1], columns=[0])\n        df.ix[1,0] = [1,2,3]\n        df.ix[1,0] = [1,2]\n\n        result = DataFrame(index=[0,1], columns=[0])\n        result.ix[1,0] = [1,2]\n\n        assert_frame_equal(result,df)\n\n        # ix with an object\n        class TO(object):\n            def __init__(self, value):\n                self.value = value\n            def __str__(self):\n                return \"[{0}]\".format(self.value)\n            __repr__ = __str__\n            def __eq__(self, other):\n                return self.value == other.value\n            def view(self):\n                return self\n\n        df = DataFrame(index=[0,1], columns=[0])\n        df.ix[1,0] = TO(1)\n        df.ix[1,0] = TO(2)\n\n        result = DataFrame(index=[0,1], columns=[0])\n        result.ix[1,0] = TO(2)\n\n        assert_frame_equal(result,df)\n\n        # remains object dtype even after setting it back\n        df = DataFrame(index=[0,1], columns=[0])\n        df.ix[1,0] = TO(1)\n        df.ix[1,0] = np.nan\n        result = DataFrame(index=[0,1], columns=[0])\n\n        assert_frame_equal(result, df)\n\n    def test_iloc_mask(self):\n\n        # GH 3631, iloc with a mask (of a series) should raise\n        df = DataFrame(lrange(5), list('ABCDE'), columns=['a'])\n        mask = (df.a%2 == 0)\n        self.assertRaises(ValueError, df.iloc.__getitem__, tuple([mask]))\n        mask.index = lrange(len(mask))\n        self.assertRaises(NotImplementedError, df.iloc.__getitem__, tuple([mask]))\n\n        # ndarray ok\n        result = df.iloc[np.array([True] * len(mask),dtype=bool)]\n        assert_frame_equal(result,df)\n\n        # the possibilities\n        locs = np.arange(4)\n        nums = 2**locs\n        reps = lmap(bin, nums)\n        df = DataFrame({'locs':locs, 'nums':nums}, reps)\n\n        expected = {\n            (None,'')     : '0b1100',\n            (None,'.loc')  : '0b1100',\n            (None,'.iloc') : '0b1100',\n            ('index','')  : '0b11',\n            ('index','.loc')  : '0b11',\n            ('index','.iloc') : 'iLocation based boolean indexing cannot use an indexable as a mask',\n            ('locs','')      : 'Unalignable boolean Series key provided',\n            ('locs','.loc')   : 'Unalignable boolean Series key provided',\n            ('locs','.iloc')  : 'iLocation based boolean indexing on an integer type is not available',\n            }\n\n        warnings.filterwarnings(action='ignore', category=UserWarning)\n        result = dict()\n        for idx in [None, 'index', 'locs']:\n            mask = (df.nums>2).values\n            if idx:\n                mask = Series(mask, list(reversed(getattr(df, idx))))\n            for method in ['', '.loc', '.iloc']:\n                try:\n                    if method:\n                        accessor = getattr(df, method[1:])\n                    else:\n                        accessor = df\n                    ans = str(bin(accessor[mask]['nums'].sum()))\n                except Exception as e:\n                    ans = str(e)\n\n                key = tuple([idx,method])\n                r = expected.get(key)\n                if r != ans:\n                    raise AssertionError(\"[%s] does not match [%s], received [%s]\" %\n                                         (key,ans,r))\n        warnings.filterwarnings(action='always', category=UserWarning)\n\n    def test_ix_slicing_strings(self):\n        ##GH3836\n        data = {'Classification': ['SA EQUITY CFD', 'bbb', 'SA EQUITY', 'SA SSF', 'aaa'],\n                'Random': [1,2,3,4,5],\n                'X': ['correct', 'wrong','correct', 'correct','wrong']}\n        df = DataFrame(data)\n        x = df[~df.Classification.isin(['SA EQUITY CFD', 'SA EQUITY', 'SA SSF'])]\n        df.ix[x.index,'X'] = df['Classification']\n\n        expected = DataFrame({'Classification': {0: 'SA EQUITY CFD', 1: 'bbb',\n                                                2: 'SA EQUITY', 3: 'SA SSF', 4: 'aaa'},\n                            'Random': {0: 1, 1: 2, 2: 3, 3: 4, 4: 5},\n                            'X': {0: 'correct', 1: 'bbb', 2: 'correct',\n                            3: 'correct', 4: 'aaa'}})  # bug was 4: 'bbb'\n\n        assert_frame_equal(df, expected)\n\n    def test_non_unique_loc(self):\n        ## GH3659\n        ## non-unique indexer with loc slice\n        ## https://groups.google.com/forum/?fromgroups#!topic/pydata/zTm2No0crYs\n\n        # these are going to raise becuase the we are non monotonic\n        df = DataFrame({'A' : [1,2,3,4,5,6], 'B' : [3,4,5,6,7,8]}, index = [0,1,0,1,2,3])\n        self.assertRaises(KeyError, df.loc.__getitem__, tuple([slice(1,None)]))\n        self.assertRaises(KeyError, df.loc.__getitem__, tuple([slice(0,None)]))\n        self.assertRaises(KeyError, df.loc.__getitem__, tuple([slice(1,2)]))\n\n        # monotonic are ok\n        df = DataFrame({'A' : [1,2,3,4,5,6], 'B' : [3,4,5,6,7,8]}, index = [0,1,0,1,2,3]).sort(axis=0)\n        result = df.loc[1:]\n        expected = DataFrame({'A' : [2,4,5,6], 'B' : [4, 6,7,8]}, index = [1,1,2,3])\n        assert_frame_equal(result,expected)\n\n        result = df.loc[0:]\n        assert_frame_equal(result,df)\n\n        result = df.loc[1:2]\n        expected = DataFrame({'A' : [2,4,5], 'B' : [4,6,7]}, index = [1,1,2])\n        assert_frame_equal(result,expected)\n\n    def test_loc_name(self):\n        # GH 3880\n        df = DataFrame([[1, 1], [1, 1]])\n        df.index.name = 'index_name'\n        result = df.iloc[[0, 1]].index.name\n        self.assertEqual(result, 'index_name')\n\n        result = df.ix[[0, 1]].index.name\n        self.assertEqual(result, 'index_name')\n\n        result = df.loc[[0, 1]].index.name\n        self.assertEqual(result, 'index_name')\n\n    def test_iloc_non_unique_indexing(self):\n\n        #GH 4017, non-unique indexing (on the axis)\n        df = DataFrame({'A' : [0.1] * 3000, 'B' : [1] * 3000})\n        idx = np.array(lrange(30)) * 99\n        expected = df.iloc[idx]\n\n        df3 = pd.concat([df, 2*df, 3*df])\n        result = df3.iloc[idx]\n\n        assert_frame_equal(result, expected)\n\n        df2 = DataFrame({'A' : [0.1] * 1000, 'B' : [1] * 1000})\n        df2 = pd.concat([df2, 2*df2, 3*df2])\n\n        sidx = df2.index.to_series()\n        expected = df2.iloc[idx[idx<=sidx.max()]]\n\n        new_list = []\n        for r, s in expected.iterrows():\n            new_list.append(s)\n            new_list.append(s*2)\n            new_list.append(s*3)\n\n        expected = DataFrame(new_list)\n        expected = pd.concat([ expected, DataFrame(index=idx[idx>sidx.max()]) ])\n        result = df2.loc[idx]\n        assert_frame_equal(result, expected)\n\n    def test_mi_access(self):\n\n        # GH 4145\n        data = \"\"\"h1 main  h3 sub  h5\n0  a    A   1  A1   1\n1  b    B   2  B1   2\n2  c    B   3  A1   3\n3  d    A   4  B2   4\n4  e    A   5  B2   5\n5  f    B   6  A2   6\n\"\"\"\n\n        df = pd.read_csv(StringIO(data),sep='\\s+',index_col=0)\n        df2 = df.set_index(['main', 'sub']).T.sort_index(1)\n        index = Index(['h1','h3','h5'])\n        columns = MultiIndex.from_tuples([('A','A1')],names=['main','sub'])\n        expected = DataFrame([['a',1,1]],index=columns,columns=index).T\n\n        result = df2.loc[:,('A','A1')]\n        assert_frame_equal(result,expected)\n\n        result = df2[('A','A1')]\n        assert_frame_equal(result,expected)\n\n        # GH 4146, not returning a block manager when selecting a unique index\n        # from a duplicate index\n        # as of 4879, this returns a Series (which is similar to what happens with a non-unique)\n        expected = Series(['a',1,1], index=['h1','h3','h5'], name='A1')\n        result = df2['A']['A1']\n        assert_series_equal(result, expected)\n\n        # selecting a non_unique from the 2nd level\n        expected = DataFrame([['d',4,4],['e',5,5]],index=Index(['B2','B2'],name='sub'),columns=['h1','h3','h5'],).T\n        result = df2['A']['B2']\n        assert_frame_equal(result, expected)\n\n    def test_non_unique_loc_memory_error(self):\n\n        # GH 4280\n        # non_unique index with a large selection triggers a memory error\n\n        columns = list('ABCDEFG')\n        def gen_test(l,l2):\n            return pd.concat([ DataFrame(randn(l,len(columns)),index=lrange(l),columns=columns),\n                               DataFrame(np.ones((l2,len(columns))),index=[0]*l2,columns=columns) ])\n\n\n        def gen_expected(df,mask):\n            l = len(mask)\n            return pd.concat([\n                df.take([0],convert=False),\n                DataFrame(np.ones((l,len(columns))),index=[0]*l,columns=columns),\n                df.take(mask[1:],convert=False) ])\n\n        df = gen_test(900,100)\n        self.assertFalse(df.index.is_unique)\n\n        mask = np.arange(100)\n        result = df.loc[mask]\n        expected = gen_expected(df,mask)\n        assert_frame_equal(result,expected)\n\n        df = gen_test(900000,100000)\n        self.assertFalse(df.index.is_unique)\n\n        mask = np.arange(100000)\n        result = df.loc[mask]\n        expected = gen_expected(df,mask)\n        assert_frame_equal(result,expected)\n\n    def test_astype_assignment(self):\n\n        # GH4312 (iloc)\n        df_orig = DataFrame([['1','2','3','.4',5,6.,'foo']],columns=list('ABCDEFG'))\n\n        df = df_orig.copy()\n        df.iloc[:,0:2] = df.iloc[:,0:2].astype(np.int64)\n        expected = DataFrame([[1,2,'3','.4',5,6.,'foo']],columns=list('ABCDEFG'))\n        assert_frame_equal(df,expected)\n\n        df = df_orig.copy()\n        df.iloc[:,0:2] = df.iloc[:,0:2].convert_objects(datetime=True,\n                                                        numeric=True)\n        expected =  DataFrame([[1,2,'3','.4',5,6.,'foo']],columns=list('ABCDEFG'))\n        assert_frame_equal(df,expected)\n\n        # GH5702 (loc)\n        df = df_orig.copy()\n        df.loc[:,'A'] = df.loc[:,'A'].astype(np.int64)\n        expected = DataFrame([[1,'2','3','.4',5,6.,'foo']],columns=list('ABCDEFG'))\n        assert_frame_equal(df,expected)\n\n        df = df_orig.copy()\n        df.loc[:,['B','C']] = df.loc[:,['B','C']].astype(np.int64)\n        expected =  DataFrame([['1',2,3,'.4',5,6.,'foo']],columns=list('ABCDEFG'))\n        assert_frame_equal(df,expected)\n\n        # full replacements / no nans\n        df = DataFrame({'A': [1., 2., 3., 4.]})\n        df.iloc[:, 0] = df['A'].astype(np.int64)\n        expected = DataFrame({'A': [1, 2, 3, 4]})\n        assert_frame_equal(df,expected)\n\n        df = DataFrame({'A': [1., 2., 3., 4.]})\n        df.loc[:, 'A'] = df['A'].astype(np.int64)\n        expected = DataFrame({'A': [1, 2, 3, 4]})\n        assert_frame_equal(df,expected)\n\n    def test_astype_assignment_with_dups(self):\n\n        # GH 4686\n        # assignment with dups that has a dtype change\n        df = DataFrame(\n            np.arange(3).reshape((1,3)),\n            columns=pd.MultiIndex.from_tuples(\n                [('A', '1'), ('B', '1'), ('A', '2')]\n                ),\n            dtype=object\n            )\n        index = df.index.copy()\n\n        df['A'] = df['A'].astype(np.float64)\n        result = df.get_dtype_counts().sort_index()\n        expected = Series({ 'float64' : 2, 'object' : 1 }).sort_index()\n        self.assertTrue(df.index.equals(index))\n\n    def test_dups_loc(self):\n\n        # GH4726\n        # dup indexing with iloc/loc\n        df = DataFrame([[1, 2, 'foo', 'bar', Timestamp('20130101')]],\n                       columns=['a','a','a','a','a'], index=[1])\n        expected = Series([1, 2, 'foo', 'bar', Timestamp('20130101')],\n                          index=['a','a','a','a','a'], name=1)\n\n        result = df.iloc[0]\n        assert_series_equal(result, expected)\n\n        result = df.loc[1]\n        assert_series_equal(result, expected)\n\n    def test_partial_setting(self):\n\n        # GH2578, allow ix and friends to partially set\n\n        ### series ###\n        s_orig = Series([1,2,3])\n\n        s = s_orig.copy()\n        s[5] = 5\n        expected = Series([1,2,3,5],index=[0,1,2,5])\n        assert_series_equal(s,expected)\n\n        s = s_orig.copy()\n        s.loc[5] = 5\n        expected = Series([1,2,3,5],index=[0,1,2,5])\n        assert_series_equal(s,expected)\n\n        s = s_orig.copy()\n        s[5] = 5.\n        expected = Series([1,2,3,5.],index=[0,1,2,5])\n        assert_series_equal(s,expected)\n\n        s = s_orig.copy()\n        s.loc[5] = 5.\n        expected = Series([1,2,3,5.],index=[0,1,2,5])\n        assert_series_equal(s,expected)\n\n        # iloc/iat raise\n        s = s_orig.copy()\n        def f():\n            s.iloc[3] = 5.\n        self.assertRaises(IndexError, f)\n        def f():\n            s.iat[3] = 5.\n        self.assertRaises(IndexError, f)\n\n        ### frame ###\n\n        df_orig = DataFrame(np.arange(6).reshape(3,2),columns=['A','B'],dtype='int64')\n\n        # iloc/iat raise\n        df = df_orig.copy()\n        def f():\n            df.iloc[4,2] = 5.\n        self.assertRaises(IndexError, f)\n        def f():\n            df.iat[4,2] = 5.\n        self.assertRaises(IndexError, f)\n\n        # row setting where it exists\n        expected = DataFrame(dict({ 'A' : [0,4,4], 'B' : [1,5,5] }))\n        df = df_orig.copy()\n        df.iloc[1] = df.iloc[2]\n        assert_frame_equal(df,expected)\n\n        expected = DataFrame(dict({ 'A' : [0,4,4], 'B' : [1,5,5] }))\n        df = df_orig.copy()\n        df.loc[1] = df.loc[2]\n        assert_frame_equal(df,expected)\n\n        # like 2578, partial setting with dtype preservation\n        expected = DataFrame(dict({ 'A' : [0,2,4,4], 'B' : [1,3,5,5] }))\n        df = df_orig.copy()\n        df.loc[3] = df.loc[2]\n        assert_frame_equal(df,expected)\n\n        # single dtype frame, overwrite\n        expected = DataFrame(dict({ 'A' : [0,2,4], 'B' : [0,2,4] }))\n        df = df_orig.copy()\n        df.ix[:,'B'] = df.ix[:,'A']\n        assert_frame_equal(df,expected)\n\n        # mixed dtype frame, overwrite\n        expected = DataFrame(dict({ 'A' : [0,2,4], 'B' : Series([0,2,4]) }))\n        df = df_orig.copy()\n        df['B'] = df['B'].astype(np.float64)\n        df.ix[:,'B'] = df.ix[:,'A']\n        assert_frame_equal(df,expected)\n\n        # single dtype frame, partial setting\n        expected = df_orig.copy()\n        expected['C'] = df['A']\n        df = df_orig.copy()\n        df.ix[:,'C'] = df.ix[:,'A']\n        assert_frame_equal(df,expected)\n\n        # mixed frame, partial setting\n        expected = df_orig.copy()\n        expected['C'] = df['A']\n        df = df_orig.copy()\n        df.ix[:,'C'] = df.ix[:,'A']\n        assert_frame_equal(df,expected)\n\n        ### panel ###\n        p_orig = Panel(np.arange(16).reshape(2,4,2),items=['Item1','Item2'],major_axis=pd.date_range('2001/1/12',periods=4),minor_axis=['A','B'],dtype='float64')\n\n        # panel setting via item\n        p_orig = Panel(np.arange(16).reshape(2,4,2),items=['Item1','Item2'],major_axis=pd.date_range('2001/1/12',periods=4),minor_axis=['A','B'],dtype='float64')\n        expected = p_orig.copy()\n        expected['Item3'] = expected['Item1']\n        p = p_orig.copy()\n        p.loc['Item3'] = p['Item1']\n        assert_panel_equal(p,expected)\n\n        # panel with aligned series\n        expected = p_orig.copy()\n        expected = expected.transpose(2,1,0)\n        expected['C'] = DataFrame({ 'Item1' : [30,30,30,30], 'Item2' : [32,32,32,32] },index=p_orig.major_axis)\n        expected = expected.transpose(2,1,0)\n        p = p_orig.copy()\n        p.loc[:,:,'C'] = Series([30,32],index=p_orig.items)\n        assert_panel_equal(p,expected)\n\n        # GH 8473\n        dates = date_range('1/1/2000', periods=8)\n        df_orig = DataFrame(np.random.randn(8, 4), index=dates, columns=['A', 'B', 'C', 'D'])\n\n        expected = pd.concat([df_orig,DataFrame({'A' : 7},index=[dates[-1]+1])])\n        df = df_orig.copy()\n        df.loc[dates[-1]+1, 'A'] = 7\n        assert_frame_equal(df,expected)\n        df = df_orig.copy()\n        df.at[dates[-1]+1, 'A'] = 7\n        assert_frame_equal(df,expected)\n\n        expected = pd.concat([df_orig,DataFrame({0 : 7},index=[dates[-1]+1])],axis=1)\n        df = df_orig.copy()\n        df.loc[dates[-1]+1, 0] = 7\n        assert_frame_equal(df,expected)\n        df = df_orig.copy()\n        df.at[dates[-1]+1, 0] = 7\n        assert_frame_equal(df,expected)\n\n    def test_partial_setting_mixed_dtype(self):\n\n        # in a mixed dtype environment, try to preserve dtypes\n        # by appending\n        df = DataFrame([[True, 1],[False, 2]],\n                       columns = [\"female\",\"fitness\"])\n\n        s = df.loc[1].copy()\n        s.name = 2\n        expected = df.append(s)\n\n        df.loc[2] = df.loc[1]\n        assert_frame_equal(df, expected)\n\n        # columns will align\n        df = DataFrame(columns=['A','B'])\n        df.loc[0] = Series(1,index=range(4))\n        assert_frame_equal(df,DataFrame(columns=['A','B'],index=[0]))\n\n        # columns will align\n        df = DataFrame(columns=['A','B'])\n        df.loc[0] = Series(1,index=['B'])\n        assert_frame_equal(df,DataFrame([[np.nan, 1]], columns=['A','B'],index=[0],dtype='float64'))\n\n        # list-like must conform\n        df = DataFrame(columns=['A','B'])\n        def f():\n            df.loc[0] = [1,2,3]\n        self.assertRaises(ValueError, f)\n\n        # these are coerced to float unavoidably (as its a list-like to begin)\n        df = DataFrame(columns=['A','B'])\n        df.loc[3] = [6,7]\n        assert_frame_equal(df,DataFrame([[6,7]],index=[3],columns=['A','B'],dtype='float64'))\n\n    def test_partial_setting_with_datetimelike_dtype(self):\n\n        # GH9478\n        # a datetimeindex alignment issue with partial setting\n        df = pd.DataFrame(np.arange(6.).reshape(3,2), columns=list('AB'),\n                          index=pd.date_range('1/1/2000', periods=3, freq='1H'))\n        expected = df.copy()\n        expected['C'] = [expected.index[0]] + [pd.NaT,pd.NaT]\n\n        mask = df.A < 1\n        df.loc[mask, 'C'] = df.loc[mask].index\n        assert_frame_equal(df, expected)\n\n    def test_loc_setitem_datetime(self):\n\n        # GH 9516\n        dt1 = Timestamp('20130101 09:00:00')\n        dt2 = Timestamp('20130101 10:00:00')\n\n        for conv in [lambda x: x, lambda x: x.to_datetime64(),\n                     lambda x: x.to_pydatetime(), lambda x: np.datetime64(x)]:\n\n            df = pd.DataFrame()\n            df.loc[conv(dt1),'one'] = 100\n            df.loc[conv(dt2),'one'] = 200\n\n            expected = DataFrame({'one' : [100.0,200.0]},index=[dt1,dt2])\n            assert_frame_equal(df, expected)\n\n    def test_series_partial_set(self):\n        # partial set with new index\n        # Regression from GH4825\n        ser = Series([0.1, 0.2], index=[1, 2])\n\n        # loc\n        expected = Series([np.nan, 0.2, np.nan], index=[3, 2, 3])\n        result = ser.loc[[3, 2, 3]]\n        assert_series_equal(result, expected)\n\n        # raises as nothing in in the index\n        self.assertRaises(KeyError, lambda : ser.loc[[3, 3, 3]])\n\n        expected = Series([0.2, 0.2, np.nan], index=[2, 2, 3])\n        result = ser.loc[[2, 2, 3]]\n        assert_series_equal(result, expected)\n\n        expected = Series([0.3, np.nan, np.nan], index=[3, 4, 4])\n        result = Series([0.1, 0.2, 0.3], index=[1,2,3]).loc[[3,4,4]]\n        assert_series_equal(result, expected)\n\n        expected = Series([np.nan, 0.3, 0.3], index=[5, 3, 3])\n        result = Series([0.1, 0.2, 0.3, 0.4], index=[1,2,3,4]).loc[[5,3,3]]\n        assert_series_equal(result, expected)\n\n        expected = Series([np.nan, 0.4, 0.4], index=[5, 4, 4])\n        result = Series([0.1, 0.2, 0.3, 0.4], index=[1,2,3,4]).loc[[5,4,4]]\n        assert_series_equal(result, expected)\n\n        expected = Series([0.4, np.nan, np.nan], index=[7, 2, 2])\n        result = Series([0.1, 0.2, 0.3, 0.4], index=[4,5,6,7]).loc[[7,2,2]]\n        assert_series_equal(result, expected)\n\n        expected = Series([0.4, np.nan, np.nan], index=[4, 5, 5])\n        result = Series([0.1, 0.2, 0.3, 0.4], index=[1,2,3,4]).loc[[4,5,5]]\n        assert_series_equal(result, expected)\n\n        # iloc\n        expected = Series([0.2,0.2,0.1,0.1], index=[2,2,1,1])\n        result = ser.iloc[[1,1,0,0]]\n        assert_series_equal(result, expected)\n\n    def test_partial_set_invalid(self):\n\n        # GH 4940\n        # allow only setting of 'valid' values\n\n        df = tm.makeTimeDataFrame()\n\n        # don't allow not string inserts\n        def f():\n            df.loc[100.0, :] = df.ix[0]\n        self.assertRaises(TypeError, f)\n        def f():\n            df.loc[100,:] = df.ix[0]\n        self.assertRaises(TypeError, f)\n\n        def f():\n            df.ix[100.0, :] = df.ix[0]\n        self.assertRaises(ValueError, f)\n        def f():\n            df.ix[100,:] = df.ix[0]\n        self.assertRaises(ValueError, f)\n\n        # allow object conversion here\n        df.loc['a',:] = df.ix[0]\n\n    def test_partial_set_empty(self):\n\n        # GH5226\n\n        # partially set with an empty object\n        # series\n        s = Series()\n        s.loc[1] = 1\n        assert_series_equal(s,Series([1],index=[1]))\n        s.loc[3] = 3\n        assert_series_equal(s,Series([1,3],index=[1,3]))\n\n        s = Series()\n        s.loc[1] = 1.\n        assert_series_equal(s,Series([1.],index=[1]))\n        s.loc[3] = 3.\n        assert_series_equal(s,Series([1.,3.],index=[1,3]))\n\n        s = Series()\n        s.loc['foo'] = 1\n        assert_series_equal(s,Series([1],index=['foo']))\n        s.loc['bar'] = 3\n        assert_series_equal(s,Series([1,3],index=['foo','bar']))\n        s.loc[3] = 4\n        assert_series_equal(s,Series([1,3,4],index=['foo','bar',3]))\n\n        # partially set with an empty object\n        # frame\n        df = DataFrame()\n\n        def f():\n            df.loc[1] = 1\n        self.assertRaises(ValueError, f)\n        def f():\n            df.loc[1] = Series([1],index=['foo'])\n        self.assertRaises(ValueError, f)\n        def f():\n            df.loc[:,1] = 1\n        self.assertRaises(ValueError, f)\n\n        # these work as they don't really change\n        # anything but the index\n        # GH5632\n        expected = DataFrame(columns=['foo'])\n        def f():\n            df = DataFrame()\n            df['foo'] = Series([], dtype='object')\n            return df\n        assert_frame_equal(f(), expected)\n        def f():\n            df = DataFrame()\n            df['foo'] = Series(df.index)\n            return df\n        assert_frame_equal(f(), expected)\n        def f():\n            df = DataFrame()\n            df['foo'] = df.index\n            return df\n        assert_frame_equal(f(), expected)\n\n        expected = DataFrame(columns=['foo'])\n        expected['foo'] = expected['foo'].astype('float64')\n        def f():\n            df = DataFrame()\n            df['foo'] = []\n            return df\n        assert_frame_equal(f(), expected)\n        def f():\n            df = DataFrame()\n            df['foo'] = Series(range(len(df)))\n            return df\n        assert_frame_equal(f(), expected)\n        def f():\n            df = DataFrame()\n            df['foo'] = range(len(df))\n            return df\n        assert_frame_equal(f(), expected)\n\n        df = DataFrame()\n        df2 = DataFrame()\n        df2[1] = Series([1],index=['foo'])\n        df.loc[:,1] = Series([1],index=['foo'])\n        assert_frame_equal(df,DataFrame([[1]],index=['foo'],columns=[1]))\n        assert_frame_equal(df,df2)\n\n        # no index to start\n        expected = DataFrame({ 0 : Series(1,index=range(4)) },columns=['A','B',0])\n\n        df = DataFrame(columns=['A','B'])\n        df[0] = Series(1,index=range(4))\n        df.dtypes\n        str(df)\n        assert_frame_equal(df,expected)\n\n        df = DataFrame(columns=['A','B'])\n        df.loc[:,0] = Series(1,index=range(4))\n        df.dtypes\n        str(df)\n        assert_frame_equal(df,expected)\n\n        # GH5720, GH5744\n        # don't create rows when empty\n        expected = DataFrame(columns=['A','B','New'])\n        expected['A'] = expected['A'].astype('int64')\n        expected['B'] = expected['B'].astype('float64')\n        expected['New'] = expected['New'].astype('float64')\n        df = DataFrame({\"A\": [1, 2, 3], \"B\": [1.2, 4.2, 5.2]})\n        y = df[df.A > 5]\n        y['New'] = np.nan\n        assert_frame_equal(y,expected)\n        #assert_frame_equal(y,expected)\n\n        expected = DataFrame(columns=['a','b','c c','d'])\n        expected['d'] = expected['d'].astype('int64')\n        df = DataFrame(columns=['a', 'b', 'c c'])\n        df['d'] = 3\n        assert_frame_equal(df,expected)\n        assert_series_equal(df['c c'],Series(name='c c',dtype=object))\n\n        # reindex columns is ok\n        df = DataFrame({\"A\": [1, 2, 3], \"B\": [1.2, 4.2, 5.2]})\n        y = df[df.A > 5]\n        result = y.reindex(columns=['A','B','C'])\n        expected = DataFrame(columns=['A','B','C'])\n        expected['A'] = expected['A'].astype('int64')\n        expected['B'] = expected['B'].astype('float64')\n        expected['C'] = expected['C'].astype('float64')\n        assert_frame_equal(result,expected)\n\n        # GH 5756\n        # setting with empty Series\n        df = DataFrame(Series())\n        assert_frame_equal(df, DataFrame({ 0 : Series() }))\n\n        df = DataFrame(Series(name='foo'))\n        assert_frame_equal(df, DataFrame({ 'foo' : Series() }))\n\n        # GH 5932\n        # copy on empty with assignment fails\n        df = DataFrame(index=[0])\n        df = df.copy()\n        df['a'] = 0\n        expected = DataFrame(0,index=[0],columns=['a'])\n        assert_frame_equal(df, expected)\n\n        # GH 6171\n        # consistency on empty frames\n        df = DataFrame(columns=['x', 'y'])\n        df['x'] = [1, 2]\n        expected = DataFrame(dict(x = [1,2], y = [np.nan,np.nan]))\n        assert_frame_equal(df, expected, check_dtype=False)\n\n        df = DataFrame(columns=['x', 'y'])\n        df['x'] = ['1', '2']\n        expected = DataFrame(dict(x = ['1','2'], y = [np.nan,np.nan]),dtype=object)\n        assert_frame_equal(df, expected)\n\n        df = DataFrame(columns=['x', 'y'])\n        df.loc[0, 'x'] = 1\n        expected = DataFrame(dict(x = [1], y = [np.nan]))\n        assert_frame_equal(df, expected, check_dtype=False)\n\n    def test_cache_updating(self):\n        # GH 4939, make sure to update the cache on setitem\n\n        df = tm.makeDataFrame()\n        df['A'] # cache series\n        df.ix[\"Hello Friend\"] = df.ix[0]\n        self.assertIn(\"Hello Friend\", df['A'].index)\n        self.assertIn(\"Hello Friend\", df['B'].index)\n\n        panel = tm.makePanel()\n        panel.ix[0] # get first item into cache\n        panel.ix[:, :, 'A+1'] = panel.ix[:, :, 'A'] + 1\n        self.assertIn(\"A+1\", panel.ix[0].columns)\n        self.assertIn(\"A+1\", panel.ix[1].columns)\n\n        # 5216\n        # make sure that we don't try to set a dead cache\n        a = np.random.rand(10, 3)\n        df = DataFrame(a, columns=['x', 'y', 'z'])\n        tuples = [(i, j) for i in range(5) for j in range(2)]\n        index = MultiIndex.from_tuples(tuples)\n        df.index = index\n\n        # setting via chained assignment\n        # but actually works, since everything is a view\n        df.loc[0]['z'].iloc[0] = 1.\n        result = df.loc[(0,0),'z']\n        self.assertEqual(result, 1)\n\n        # correct setting\n        df.loc[(0,0),'z'] = 2\n        result = df.loc[(0,0),'z']\n        self.assertEqual(result, 2)\n\n        # 10264\n        df = DataFrame(np.zeros((5,5),dtype='int64'),columns=['a','b','c','d','e'],index=range(5))\n        df['f'] = 0\n        df.f.values[3] = 1\n        y = df.iloc[np.arange(2,len(df))]\n        df.f.values[3] = 2\n        expected = DataFrame(np.zeros((5,6),dtype='int64'),columns=['a','b','c','d','e','f'],index=range(5))\n        expected.at[3,'f'] = 2\n        assert_frame_equal(df, expected)\n        expected = Series([0,0,0,2,0],name='f')\n        assert_series_equal(df.f, expected)\n\n    def test_slice_consolidate_invalidate_item_cache(self):\n\n        # this is chained assignment, but will 'work'\n        with option_context('chained_assignment',None):\n\n            # #3970\n            df = DataFrame({ \"aa\":lrange(5), \"bb\":[2.2]*5})\n\n            # Creates a second float block\n            df[\"cc\"] = 0.0\n\n            # caches a reference to the 'bb' series\n            df[\"bb\"]\n\n            # repr machinery triggers consolidation\n            repr(df)\n\n            # Assignment to wrong series\n            df['bb'].iloc[0] = 0.17\n            df._clear_item_cache()\n            self.assertAlmostEqual(df['bb'][0], 0.17)\n\n    def test_setitem_cache_updating(self):\n        # GH 5424\n        cont = ['one', 'two','three', 'four', 'five', 'six', 'seven']\n\n        for do_ref in [False,False]:\n            df = DataFrame({'a' : cont, \"b\":cont[3:]+cont[:3] ,'c' : np.arange(7)})\n\n            # ref the cache\n            if do_ref:\n                df.ix[0,\"c\"]\n\n            # set it\n            df.ix[7,'c'] = 1\n\n            self.assertEqual(df.ix[0,'c'], 0.0)\n            self.assertEqual(df.ix[7,'c'], 1.0)\n\n        # GH 7084\n        # not updating cache on series setting with slices\n        expected = DataFrame({'A': [600, 600, 600]}, index=date_range('5/7/2014', '5/9/2014'))\n        out = DataFrame({'A': [0, 0, 0]}, index=date_range('5/7/2014', '5/9/2014'))\n        df = DataFrame({'C': ['A', 'A', 'A'], 'D': [100, 200, 300]})\n\n        #loop through df to update out\n        six = Timestamp('5/7/2014')\n        eix = Timestamp('5/9/2014')\n        for ix, row in df.iterrows():\n            out.loc[six:eix,row['C']] = out.loc[six:eix,row['C']] + row['D']\n\n        assert_frame_equal(out, expected)\n        assert_series_equal(out['A'], expected['A'])\n\n        # try via a chain indexing\n        # this actually works\n        out = DataFrame({'A': [0, 0, 0]}, index=date_range('5/7/2014', '5/9/2014'))\n        for ix, row in df.iterrows():\n            v = out[row['C']][six:eix] + row['D']\n            out[row['C']][six:eix] = v\n\n        assert_frame_equal(out, expected)\n        assert_series_equal(out['A'], expected['A'])\n\n        out = DataFrame({'A': [0, 0, 0]}, index=date_range('5/7/2014', '5/9/2014'))\n        for ix, row in df.iterrows():\n            out.loc[six:eix,row['C']] += row['D']\n\n        assert_frame_equal(out, expected)\n        assert_series_equal(out['A'], expected['A'])\n\n    def test_setitem_chained_setfault(self):\n\n        # GH6026\n        # setfaults under numpy 1.7.1 (ok on 1.8)\n        data = ['right', 'left', 'left', 'left', 'right', 'left', 'timeout']\n        mdata = ['right', 'left', 'left', 'left', 'right', 'left', 'none']\n\n        df = DataFrame({'response': np.array(data)})\n        mask = df.response == 'timeout'\n        df.response[mask] = 'none'\n        assert_frame_equal(df, DataFrame({'response': mdata }))\n\n        recarray = np.rec.fromarrays([data], names=['response'])\n        df = DataFrame(recarray)\n        mask = df.response == 'timeout'\n        df.response[mask] = 'none'\n        assert_frame_equal(df, DataFrame({'response': mdata }))\n\n        df = DataFrame({'response': data, 'response1' : data })\n        mask = df.response == 'timeout'\n        df.response[mask] = 'none'\n        assert_frame_equal(df, DataFrame({'response': mdata, 'response1' : data }))\n\n        # GH 6056\n        expected = DataFrame(dict(A = [np.nan,'bar','bah','foo','bar']))\n        df = DataFrame(dict(A = np.array(['foo','bar','bah','foo','bar'])))\n        df['A'].iloc[0] = np.nan\n        result = df.head()\n        assert_frame_equal(result, expected)\n\n        df = DataFrame(dict(A = np.array(['foo','bar','bah','foo','bar'])))\n        df.A.iloc[0] = np.nan\n        result = df.head()\n        assert_frame_equal(result, expected)\n\n    def test_detect_chained_assignment(self):\n\n        pd.set_option('chained_assignment','raise')\n\n        # work with the chain\n        expected = DataFrame([[-5,1],[-6,3]],columns=list('AB'))\n        df = DataFrame(np.arange(4).reshape(2,2),columns=list('AB'),dtype='int64')\n        self.assertIsNone(df.is_copy)\n        df['A'][0] = -5\n        df['A'][1] = -6\n        assert_frame_equal(df, expected)\n\n        # test with the chaining\n        df = DataFrame({ 'A' : Series(range(2),dtype='int64'), 'B' : np.array(np.arange(2,4),dtype=np.float64)})\n        self.assertIsNone(df.is_copy)\n        def f():\n            df['A'][0] = -5\n        self.assertRaises(com.SettingWithCopyError, f)\n        def f():\n            df['A'][1] = np.nan\n        self.assertRaises(com.SettingWithCopyError, f)\n        self.assertIsNone(df['A'].is_copy)\n\n        # using a copy (the chain), fails\n        df = DataFrame({ 'A' : Series(range(2),dtype='int64'), 'B' : np.array(np.arange(2,4),dtype=np.float64)})\n        def f():\n            df.loc[0]['A'] = -5\n        self.assertRaises(com.SettingWithCopyError, f)\n\n        # doc example\n        df = DataFrame({'a' : ['one', 'one', 'two',\n                               'three', 'two', 'one', 'six'],\n                        'c' : Series(range(7),dtype='int64') })\n        self.assertIsNone(df.is_copy)\n        expected = DataFrame({'a' : ['one', 'one', 'two',\n                                     'three', 'two', 'one', 'six'],\n                              'c' : [42,42,2,3,4,42,6]})\n\n        def f():\n            indexer = df.a.str.startswith('o')\n            df[indexer]['c'] = 42\n        self.assertRaises(com.SettingWithCopyError, f)\n\n        expected = DataFrame({'A':[111,'bbb','ccc'],'B':[1,2,3]})\n        df = DataFrame({'A':['aaa','bbb','ccc'],'B':[1,2,3]})\n        def f():\n            df['A'][0] = 111\n        self.assertRaises(com.SettingWithCopyError, f)\n        def f():\n            df.loc[0]['A'] = 111\n        self.assertRaises(com.SettingWithCopyError, f)\n\n        df.loc[0,'A'] = 111\n        assert_frame_equal(df,expected)\n\n        # make sure that is_copy is picked up reconstruction\n        # GH5475\n        df = DataFrame({\"A\": [1,2]})\n        self.assertIsNone(df.is_copy)\n        with tm.ensure_clean('__tmp__pickle') as path:\n            df.to_pickle(path)\n            df2 = pd.read_pickle(path)\n            df2[\"B\"] = df2[\"A\"]\n            df2[\"B\"] = df2[\"A\"]\n\n        # a suprious raise as we are setting the entire column here\n        # GH5597\n        from string import ascii_letters as letters\n\n        def random_text(nobs=100):\n            df = []\n            for i in range(nobs):\n                idx= np.random.randint(len(letters), size=2)\n                idx.sort()\n                df.append([letters[idx[0]:idx[1]]])\n\n            return DataFrame(df, columns=['letters'])\n\n        df = random_text(100000)\n\n        # always a copy\n        x = df.iloc[[0,1,2]]\n        self.assertIsNotNone(x.is_copy)\n        x = df.iloc[[0,1,2,4]]\n        self.assertIsNotNone(x.is_copy)\n\n        # explicity copy\n        indexer = df.letters.apply(lambda x : len(x) > 10)\n        df = df.ix[indexer].copy()\n        self.assertIsNone(df.is_copy)\n        df['letters'] = df['letters'].apply(str.lower)\n\n        # implicity take\n        df = random_text(100000)\n        indexer = df.letters.apply(lambda x : len(x) > 10)\n        df = df.ix[indexer]\n        self.assertIsNotNone(df.is_copy)\n        df['letters'] = df['letters'].apply(str.lower)\n\n        # implicity take 2\n        df = random_text(100000)\n        indexer = df.letters.apply(lambda x : len(x) > 10)\n        df = df.ix[indexer]\n        self.assertIsNotNone(df.is_copy)\n        df.loc[:,'letters'] = df['letters'].apply(str.lower)\n\n        # should be ok even though it's a copy!\n        self.assertIsNone(df.is_copy)\n        df['letters'] = df['letters'].apply(str.lower)\n        self.assertIsNone(df.is_copy)\n\n        df = random_text(100000)\n        indexer = df.letters.apply(lambda x : len(x) > 10)\n        df.ix[indexer,'letters'] = df.ix[indexer,'letters'].apply(str.lower)\n\n        # an identical take, so no copy\n        df = DataFrame({'a' : [1]}).dropna()\n        self.assertIsNone(df.is_copy)\n        df['a'] += 1\n\n        # inplace ops\n        # original from: http://stackoverflow.com/questions/20508968/series-fillna-in-a-multiindex-dataframe-does-not-fill-is-this-a-bug\n        a = [12, 23]\n        b = [123, None]\n        c = [1234, 2345]\n        d = [12345, 23456]\n        tuples = [('eyes', 'left'), ('eyes', 'right'), ('ears', 'left'), ('ears', 'right')]\n        events = {('eyes', 'left'): a, ('eyes', 'right'): b, ('ears', 'left'): c, ('ears', 'right'): d}\n        multiind = MultiIndex.from_tuples(tuples, names=['part', 'side'])\n        zed = DataFrame(events, index=['a', 'b'], columns=multiind)\n        def f():\n            zed['eyes']['right'].fillna(value=555, inplace=True)\n        self.assertRaises(com.SettingWithCopyError, f)\n\n        df = DataFrame(np.random.randn(10,4))\n        s = df.iloc[:,0]\n        s = s.order()\n        assert_series_equal(s,df.iloc[:,0].order())\n        assert_series_equal(s,df[0].order())\n\n        # false positives GH6025\n        df = DataFrame ({'column1':['a', 'a', 'a'], 'column2': [4,8,9] })\n        str(df)\n        df['column1'] = df['column1'] + 'b'\n        str(df)\n        df = df [df['column2']!=8]\n        str(df)\n        df['column1'] = df['column1'] + 'c'\n        str(df)\n\n        # from SO: http://stackoverflow.com/questions/24054495/potential-bug-setting-value-for-undefined-column-using-iloc\n        df = DataFrame(np.arange(0,9), columns=['count'])\n        df['group'] = 'b'\n        def f():\n            df.iloc[0:5]['group'] = 'a'\n        self.assertRaises(com.SettingWithCopyError, f)\n\n        # mixed type setting\n        # same dtype & changing dtype\n        df = DataFrame(dict(A=date_range('20130101',periods=5),B=np.random.randn(5),C=np.arange(5,dtype='int64'),D=list('abcde')))\n\n        def f():\n            df.ix[2]['D'] = 'foo'\n        self.assertRaises(com.SettingWithCopyError, f)\n        def f():\n            df.ix[2]['C'] = 'foo'\n        self.assertRaises(com.SettingWithCopyError, f)\n        def f():\n            df['C'][2] = 'foo'\n        self.assertRaises(com.SettingWithCopyError, f)\n\n    def test_setting_with_copy_bug(self):\n\n        # operating on a copy\n        df = pd.DataFrame({'a': list(range(4)), 'b': list('ab..'), 'c': ['a', 'b', np.nan, 'd']})\n        mask = pd.isnull(df.c)\n\n        def f():\n            df[['c']][mask] = df[['b']][mask]\n        self.assertRaises(com.SettingWithCopyError, f)\n\n        # invalid warning as we are returning a new object\n        # GH 8730\n        df1 = DataFrame({'x': Series(['a','b','c']), 'y': Series(['d','e','f'])})\n        df2 = df1[['x']]\n\n        # this should not raise\n        df2['y'] = ['g', 'h', 'i']\n\n    def test_detect_chained_assignment_warnings(self):\n\n        # warnings\n        with option_context('chained_assignment','warn'):\n            df = DataFrame({'A':['aaa','bbb','ccc'],'B':[1,2,3]})\n            with tm.assert_produces_warning(expected_warning=com.SettingWithCopyWarning):\n                df.loc[0]['A'] = 111\n\n    def test_float64index_slicing_bug(self):\n        # GH 5557, related to slicing a float index\n        ser = {256: 2321.0, 1: 78.0, 2: 2716.0, 3: 0.0, 4: 369.0, 5: 0.0, 6: 269.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 3536.0, 11: 0.0, 12: 24.0, 13: 0.0, 14: 931.0, 15: 0.0, 16: 101.0, 17: 78.0, 18: 9643.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 63761.0, 23: 0.0, 24: 446.0, 25: 0.0, 26: 34773.0, 27: 0.0, 28: 729.0, 29: 78.0, 30: 0.0, 31: 0.0, 32: 3374.0, 33: 0.0, 34: 1391.0, 35: 0.0, 36: 361.0, 37: 0.0, 38: 61808.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 6677.0, 43: 0.0, 44: 802.0, 45: 0.0, 46: 2691.0, 47: 0.0, 48: 3582.0, 49: 0.0, 50: 734.0, 51: 0.0, 52: 627.0, 53: 70.0, 54: 2584.0, 55: 0.0, 56: 324.0, 57: 0.0, 58: 605.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 3989.0, 63: 10.0, 64: 42.0, 65: 0.0, 66: 904.0, 67: 0.0, 68: 88.0, 69: 70.0, 70: 8172.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 64902.0, 75: 0.0, 76: 347.0, 77: 0.0, 78: 36605.0, 79: 0.0, 80: 379.0, 81: 70.0, 82: 0.0, 83: 0.0, 84: 3001.0, 85: 0.0, 86: 1630.0, 87: 7.0, 88: 364.0, 89: 0.0, 90: 67404.0, 91: 9.0, 92: 0.0, 93: 0.0, 94: 7685.0, 95: 0.0, 96: 1017.0, 97: 0.0, 98: 2831.0, 99: 0.0, 100: 2963.0, 101: 0.0, 102: 854.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 67744.0, 127: 22.0, 128: 264.0, 129: 0.0, 260: 197.0, 268: 0.0, 265: 0.0, 269: 0.0, 261: 0.0, 266: 1198.0, 267: 0.0, 262: 2629.0, 258: 775.0, 257: 0.0, 263: 0.0, 259: 0.0, 264: 163.0, 250: 10326.0, 251: 0.0, 252: 1228.0, 253: 0.0, 254: 2769.0, 255: 0.0}\n\n        # smoke test for the repr\n        s = Series(ser)\n        result  = s.value_counts()\n        str(result)\n\n    def test_floating_index_doc_example(self):\n\n        index = Index([1.5, 2, 3, 4.5, 5])\n        s = Series(range(5),index=index)\n        self.assertEqual(s[3], 2)\n        self.assertEqual(s.ix[3], 2)\n        self.assertEqual(s.loc[3], 2)\n        self.assertEqual(s.iloc[3], 3)\n\n    def test_floating_index(self):\n\n        # related 236\n        # scalar/slicing of a float index\n        s = Series(np.arange(5), index=np.arange(5) * 2.5, dtype=np.int64)\n\n        # label based slicing\n        result1 = s[1.0:3.0]\n        result2 = s.ix[1.0:3.0]\n        result3 = s.loc[1.0:3.0]\n        assert_series_equal(result1, result2)\n        assert_series_equal(result1, result3)\n\n        # exact indexing when found\n        result1 = s[5.0]\n        result2 = s.loc[5.0]\n        result3 = s.ix[5.0]\n        self.assertEqual(result1, result2)\n        self.assertEqual(result1, result3)\n\n        result1 = s[5]\n        result2 = s.loc[5]\n        result3 = s.ix[5]\n        self.assertEqual(result1, result2)\n        self.assertEqual(result1, result3)\n\n        self.assertEqual(s[5.0], s[5])\n\n        # value not found (and no fallbacking at all)\n\n        # scalar integers\n        self.assertRaises(KeyError, lambda : s.loc[4])\n        self.assertRaises(KeyError, lambda : s.ix[4])\n        self.assertRaises(KeyError, lambda : s[4])\n\n        # fancy floats/integers create the correct entry (as nan)\n        # fancy tests\n        expected = Series([2, 0], index=Float64Index([5.0, 0.0]))\n        for fancy_idx in [[5.0, 0.0], [5, 0], np.array([5.0, 0.0]), np.array([5, 0])]:\n            assert_series_equal(s[fancy_idx], expected)\n            assert_series_equal(s.loc[fancy_idx], expected)\n            assert_series_equal(s.ix[fancy_idx], expected)\n\n        # all should return the same as we are slicing 'the same'\n        result1 = s.loc[2:5]\n        result2 = s.loc[2.0:5.0]\n        result3 = s.loc[2.0:5]\n        result4 = s.loc[2.1:5]\n        assert_series_equal(result1, result2)\n        assert_series_equal(result1, result3)\n        assert_series_equal(result1, result4)\n\n        # previously this did fallback indexing\n        result1 = s[2:5]\n        result2 = s[2.0:5.0]\n        result3 = s[2.0:5]\n        result4 = s[2.1:5]\n        assert_series_equal(result1, result2)\n        assert_series_equal(result1, result3)\n        assert_series_equal(result1, result4)\n\n        result1 = s.ix[2:5]\n        result2 = s.ix[2.0:5.0]\n        result3 = s.ix[2.0:5]\n        result4 = s.ix[2.1:5]\n        assert_series_equal(result1, result2)\n        assert_series_equal(result1, result3)\n        assert_series_equal(result1, result4)\n\n        # combined test\n        result1 = s.loc[2:5]\n        result2 = s.ix[2:5]\n        result3 = s[2:5]\n\n        assert_series_equal(result1, result2)\n        assert_series_equal(result1, result3)\n\n        # list selection\n        result1 = s[[0.0,5,10]]\n        result2 = s.loc[[0.0,5,10]]\n        result3 = s.ix[[0.0,5,10]]\n        result4 = s.iloc[[0,2,4]]\n        assert_series_equal(result1, result2)\n        assert_series_equal(result1, result3)\n        assert_series_equal(result1, result4)\n\n        result1 = s[[1.6,5,10]]\n        result2 = s.loc[[1.6,5,10]]\n        result3 = s.ix[[1.6,5,10]]\n        assert_series_equal(result1, result2)\n        assert_series_equal(result1, result3)\n        assert_series_equal(result1, Series([np.nan,2,4],index=[1.6,5,10]))\n\n        result1 = s[[0,1,2]]\n        result2 = s.ix[[0,1,2]]\n        result3 = s.loc[[0,1,2]]\n        assert_series_equal(result1, result2)\n        assert_series_equal(result1, result3)\n        assert_series_equal(result1, Series([0.0,np.nan,np.nan],index=[0,1,2]))\n\n        result1 = s.loc[[2.5, 5]]\n        result2 = s.ix[[2.5, 5]]\n        assert_series_equal(result1, result2)\n        assert_series_equal(result1, Series([1,2],index=[2.5,5.0]))\n\n        result1 = s[[2.5]]\n        result2 = s.ix[[2.5]]\n        result3 = s.loc[[2.5]]\n        assert_series_equal(result1, result2)\n        assert_series_equal(result1, result3)\n        assert_series_equal(result1, Series([1],index=[2.5]))\n\n    def test_scalar_indexer(self):\n        # float indexing checked above\n\n        def check_invalid(index, loc=None, iloc=None, ix=None, getitem=None):\n\n            # related 236/4850\n            # trying to access with a float index\n            s = Series(np.arange(len(index)),index=index)\n\n            if iloc is None:\n                iloc = TypeError\n            self.assertRaises(iloc, lambda : s.iloc[3.5])\n            if loc is None:\n                loc = TypeError\n            self.assertRaises(loc, lambda : s.loc[3.5])\n            if ix is None:\n                ix = TypeError\n            self.assertRaises(ix, lambda : s.ix[3.5])\n            if getitem is None:\n                getitem = TypeError\n            self.assertRaises(getitem, lambda : s[3.5])\n\n        for index in [ tm.makeStringIndex, tm.makeUnicodeIndex, tm.makeIntIndex,\n                       tm.makeDateIndex, tm.makePeriodIndex ]:\n            check_invalid(index())\n        check_invalid(Index(np.arange(5) * 2.5),loc=KeyError, ix=KeyError, getitem=KeyError)\n\n        def check_index(index, error):\n            index = index()\n            s = Series(np.arange(len(index)),index=index)\n\n            # positional selection\n            result1 = s[5]\n            result2 = s[5.0]\n            result3 = s.iloc[5]\n            result4 = s.iloc[5.0]\n\n            # by value\n            self.assertRaises(error, lambda : s.loc[5])\n            self.assertRaises(error, lambda : s.loc[5.0])\n\n            # this is fallback, so it works\n            result5 = s.ix[5]\n            result6 = s.ix[5.0]\n\n            self.assertEqual(result1, result2)\n            self.assertEqual(result1, result3)\n            self.assertEqual(result1, result4)\n            self.assertEqual(result1, result5)\n            self.assertEqual(result1, result6)\n\n        # string-like\n        for index in [ tm.makeStringIndex, tm.makeUnicodeIndex ]:\n            check_index(index, KeyError)\n\n        # datetimelike\n        for index in [ tm.makeDateIndex, tm.makeTimedeltaIndex, tm.makePeriodIndex ]:\n            check_index(index, TypeError)\n\n        # exact indexing when found on IntIndex\n        s = Series(np.arange(10),dtype='int64')\n\n        result1 = s[5.0]\n        result2 = s.loc[5.0]\n        result3 = s.ix[5.0]\n        result4 = s[5]\n        result5 = s.loc[5]\n        result6 = s.ix[5]\n        self.assertEqual(result1, result2)\n        self.assertEqual(result1, result3)\n        self.assertEqual(result1, result4)\n        self.assertEqual(result1, result5)\n        self.assertEqual(result1, result6)\n\n    def test_slice_indexer(self):\n\n        def check_iloc_compat(s):\n            # invalid type for iloc (but works with a warning)\n            with self.assert_produces_warning(FutureWarning):\n                s.iloc[6.0:8]\n            with self.assert_produces_warning(FutureWarning):\n                s.iloc[6.0:8.0]\n            with self.assert_produces_warning(FutureWarning):\n                s.iloc[6:8.0]\n\n        def check_slicing_positional(index):\n\n            s = Series(np.arange(len(index))+10,index=index)\n\n            # these are all positional\n            result1 = s[2:5]\n            result2 = s.ix[2:5]\n            result3 = s.iloc[2:5]\n            assert_series_equal(result1, result2)\n            assert_series_equal(result1, result3)\n\n            # loc will fail\n            self.assertRaises(TypeError, lambda : s.loc[2:5])\n\n            # make all float slicing fail\n            self.assertRaises(TypeError, lambda : s[2.0:5])\n            self.assertRaises(TypeError, lambda : s[2.0:5.0])\n            self.assertRaises(TypeError, lambda : s[2:5.0])\n\n            self.assertRaises(TypeError, lambda : s.ix[2.0:5])\n            self.assertRaises(TypeError, lambda : s.ix[2.0:5.0])\n            self.assertRaises(TypeError, lambda : s.ix[2:5.0])\n\n            self.assertRaises(TypeError, lambda : s.loc[2.0:5])\n            self.assertRaises(TypeError, lambda : s.loc[2.0:5.0])\n            self.assertRaises(TypeError, lambda : s.loc[2:5.0])\n\n            check_iloc_compat(s)\n\n        # all index types except int, float\n        for index in [ tm.makeStringIndex, tm.makeUnicodeIndex,\n                       tm.makeDateIndex, tm.makeTimedeltaIndex, tm.makePeriodIndex ]:\n            check_slicing_positional(index())\n\n        ############\n        # IntIndex #\n        ############\n        index = tm.makeIntIndex()\n        s = Series(np.arange(len(index),dtype='int64')+10,index+5)\n\n        # this is positional\n        result1 = s[2:5]\n        result4 = s.iloc[2:5]\n        assert_series_equal(result1, result4)\n\n        # these are all label based\n        result2 = s.ix[2:5]\n        result3 = s.loc[2:5]\n        assert_series_equal(result2, result3)\n\n        # float slicers on an int index\n        expected = Series([11,12,13],index=[6,7,8])\n        for method in [lambda x: x.loc, lambda x: x.ix]:\n            result = method(s)[6.0:8.5]\n            assert_series_equal(result, expected)\n\n            result = method(s)[5.5:8.5]\n            assert_series_equal(result, expected)\n\n            result = method(s)[5.5:8.0]\n            assert_series_equal(result, expected)\n\n        # make all float slicing fail for [] with an int index\n        self.assertRaises(TypeError, lambda : s[6.0:8])\n        self.assertRaises(TypeError, lambda : s[6.0:8.0])\n        self.assertRaises(TypeError, lambda : s[6:8.0])\n\n        check_iloc_compat(s)\n\n        ##############\n        # FloatIndex #\n        ##############\n        s.index = s.index.astype('float64')\n\n        # these are all value based\n        result1 = s[6:8]\n        result2 = s.ix[6:8]\n        result3 = s.loc[6:8]\n        assert_series_equal(result1, result2)\n        assert_series_equal(result1, result3)\n\n        # these are valid for all methods\n        # these are treated like labels (e.g. the rhs IS included)\n        def compare(slicers, expected):\n            for method in [lambda x: x, lambda x: x.loc, lambda x: x.ix ]:\n                for slices in slicers:\n\n                    result = method(s)[slices]\n                    assert_series_equal(result, expected)\n\n        compare([slice(6.0,8),slice(6.0,8.0),slice(6,8.0)],\n                s[(s.index>=6.0)&(s.index<=8)])\n        compare([slice(6.5,8),slice(6.5,8.5)],\n                s[(s.index>=6.5)&(s.index<=8.5)])\n        compare([slice(6,8.5)],\n                s[(s.index>=6.0)&(s.index<=8.5)])\n        compare([slice(6.5,6.5)],\n                s[(s.index>=6.5)&(s.index<=6.5)])\n\n        check_iloc_compat(s)\n\n    def test_set_ix_out_of_bounds_axis_0(self):\n        df = pd.DataFrame(randn(2, 5), index=[\"row%s\" % i for i in range(2)], columns=[\"col%s\" % i for i in range(5)])\n        self.assertRaises(ValueError, df.ix.__setitem__, (2, 0), 100)\n\n    def test_set_ix_out_of_bounds_axis_1(self):\n        df = pd.DataFrame(randn(5, 2), index=[\"row%s\" % i for i in range(5)], columns=[\"col%s\" % i for i in range(2)])\n        self.assertRaises(ValueError, df.ix.__setitem__, (0 , 2), 100)\n\n    def test_iloc_empty_list_indexer_is_ok(self):\n        from pandas.util.testing import makeCustomDataframe as mkdf\n        df = mkdf(5, 2)\n        # vertical empty\n        assert_frame_equal(df.iloc[:, []], df.iloc[:, :0],\n                           check_index_type=True, check_column_type=True)\n        # horizontal empty\n        assert_frame_equal(df.iloc[[], :], df.iloc[:0, :],\n                           check_index_type=True, check_column_type=True)\n        # horizontal empty\n        assert_frame_equal(df.iloc[[]], df.iloc[:0, :],\n                           check_index_type=True, check_column_type=True)\n\n    def test_loc_empty_list_indexer_is_ok(self):\n        from pandas.util.testing import makeCustomDataframe as mkdf\n        df = mkdf(5, 2)\n        # vertical empty\n        assert_frame_equal(df.loc[:, []], df.iloc[:, :0],\n                           check_index_type=True, check_column_type=True)\n        # horizontal empty\n        assert_frame_equal(df.loc[[], :], df.iloc[:0, :],\n                           check_index_type=True, check_column_type=True)\n        # horizontal empty\n        assert_frame_equal(df.loc[[]], df.iloc[:0, :],\n                           check_index_type=True, check_column_type=True)\n\n    def test_ix_empty_list_indexer_is_ok(self):\n        from pandas.util.testing import makeCustomDataframe as mkdf\n        df = mkdf(5, 2)\n        # vertical empty\n        assert_frame_equal(df.ix[:, []], df.iloc[:, :0],\n                           check_index_type=True, check_column_type=True)\n        # horizontal empty\n        assert_frame_equal(df.ix[[], :], df.iloc[:0, :],\n                           check_index_type=True, check_column_type=True)\n        # horizontal empty\n        assert_frame_equal(df.ix[[]], df.iloc[:0, :],\n                           check_index_type=True, check_column_type=True)\n\n    def test_deprecate_float_indexers(self):\n\n        # GH 4892\n        # deprecate allowing float indexers that are equal to ints to be used\n        # as indexers in non-float indices\n\n        import warnings\n        warnings.filterwarnings(action='error', category=FutureWarning)\n\n        def check_index(index):\n            i = index(5)\n\n            for s in  [ Series(np.arange(len(i)),index=i), DataFrame(np.random.randn(len(i),len(i)),index=i,columns=i) ]:\n                self.assertRaises(FutureWarning, lambda :\n                                  s.iloc[3.0])\n\n                # setting\n                def f():\n                    s.iloc[3.0] = 0\n                self.assertRaises(FutureWarning, f)\n\n            # fallsback to position selection ,series only\n            s = Series(np.arange(len(i)),index=i)\n            s[3]\n            self.assertRaises(FutureWarning, lambda : s[3.0])\n\n        for index in [ tm.makeStringIndex, tm.makeUnicodeIndex,\n                       tm.makeDateIndex, tm.makeTimedeltaIndex, tm.makePeriodIndex ]:\n            check_index(index)\n\n        # ints\n        i = index(5)\n        for s in [ Series(np.arange(len(i))), DataFrame(np.random.randn(len(i),len(i)),index=i,columns=i) ]:\n            self.assertRaises(FutureWarning, lambda :\n                              s.iloc[3.0])\n\n            # on some arch's this doesn't provide a warning (and thus raise)\n            # and some it does\n            try:\n                s[3.0]\n            except:\n                pass\n\n            # setting\n            def f():\n                s.iloc[3.0] = 0\n            self.assertRaises(FutureWarning, f)\n\n        # floats: these are all ok!\n        i = np.arange(5.)\n\n        for s in [ Series(np.arange(len(i)),index=i), DataFrame(np.random.randn(len(i),len(i)),index=i,columns=i) ]:\n            with tm.assert_produces_warning(False):\n                s[3.0]\n\n            with tm.assert_produces_warning(False):\n                s[3]\n\n            self.assertRaises(FutureWarning, lambda :\n                              s.iloc[3.0])\n\n            with tm.assert_produces_warning(False):\n                s.iloc[3]\n\n            with tm.assert_produces_warning(False):\n                s.loc[3.0]\n\n            with tm.assert_produces_warning(False):\n                s.loc[3]\n\n            def f():\n                s.iloc[3.0] = 0\n            self.assertRaises(FutureWarning, f)\n\n        # slices\n        for index in [ tm.makeIntIndex, tm.makeFloatIndex,\n                       tm.makeStringIndex, tm.makeUnicodeIndex,\n                       tm.makeDateIndex, tm.makePeriodIndex ]:\n\n            index = index(5)\n            for s in [ Series(range(5),index=index), DataFrame(np.random.randn(5,2),index=index) ]:\n\n                # getitem\n                self.assertRaises(FutureWarning, lambda :\n                                  s.iloc[3.0:4])\n                self.assertRaises(FutureWarning, lambda :\n                                  s.iloc[3.0:4.0])\n                self.assertRaises(FutureWarning, lambda :\n                                  s.iloc[3:4.0])\n\n                # setitem\n                def f():\n                    s.iloc[3.0:4] = 0\n                self.assertRaises(FutureWarning, f)\n                def f():\n                    s.iloc[3:4.0] = 0\n                self.assertRaises(FutureWarning, f)\n                def f():\n                    s.iloc[3.0:4.0] = 0\n                self.assertRaises(FutureWarning, f)\n\n        warnings.filterwarnings(action='ignore', category=FutureWarning)\n\n    def test_float_index_to_mixed(self):\n        df = DataFrame({0.0: np.random.rand(10),\n                        1.0: np.random.rand(10)})\n        df['a'] = 10\n        tm.assert_frame_equal(DataFrame({0.0: df[0.0],\n                                         1.0: df[1.0],\n                                         'a': [10] * 10}),\n                              df)\n\n    def test_duplicate_ix_returns_series(self):\n        df = DataFrame(np.random.randn(3, 3), index=[0.1, 0.2, 0.2],\n                       columns=list('abc'))\n        r = df.ix[0.2, 'a']\n        e = df.loc[0.2, 'a']\n        tm.assert_series_equal(r, e)\n\n    def test_float_index_non_scalar_assignment(self):\n        df = DataFrame({'a': [1,2,3], 'b': [3,4,5]},index=[1.,2.,3.])\n        df.loc[df.index[:2]] = 1\n        expected = DataFrame({'a':[1,1,3],'b':[1,1,5]},index=df.index)\n        tm.assert_frame_equal(expected, df)\n\n        df = DataFrame({'a': [1,2,3], 'b': [3,4,5]},index=[1.,2.,3.])\n        df2 = df.copy()\n        df.loc[df.index] = df.loc[df.index]\n        tm.assert_frame_equal(df,df2)\n\n    def test_float_index_at_iat(self):\n        s = pd.Series([1, 2, 3], index=[0.1, 0.2, 0.3])\n        for el, item in s.iteritems():\n            self.assertEqual(s.at[el], item)\n        for i in range(len(s)):\n            self.assertEqual(s.iat[i], i + 1)\n\n    def test_rhs_alignment(self):\n        # GH8258, tests that both rows & columns are aligned to what is\n        # assigned to. covers both uniform data-type & multi-type cases\n        def run_tests(df, rhs, right):\n            # label, index, slice\n            r, i, s = list('bcd'), [1, 2, 3], slice(1, 4)\n            c, j, l = ['joe', 'jolie'], [1, 2], slice(1, 3)\n\n            left = df.copy()\n            left.loc[r, c] = rhs\n            assert_frame_equal(left, right)\n\n            left = df.copy()\n            left.iloc[i, j] = rhs\n            assert_frame_equal(left, right)\n\n            left = df.copy()\n            left.ix[s, l] = rhs\n            assert_frame_equal(left, right)\n\n            left = df.copy()\n            left.ix[i, j] = rhs\n            assert_frame_equal(left, right)\n\n            left = df.copy()\n            left.ix[r, c] = rhs\n            assert_frame_equal(left, right)\n\n        xs = np.arange(20).reshape(5, 4)\n        cols = ['jim', 'joe', 'jolie', 'joline']\n        df = pd.DataFrame(xs, columns=cols, index=list('abcde'))\n\n        # right hand side; permute the indices and multiplpy by -2\n        rhs = - 2 * df.iloc[3:0:-1, 2:0:-1]\n\n        # expected `right` result; just multiply by -2\n        right = df.copy()\n        right.iloc[1:4, 1:3] *= -2\n\n        # run tests with uniform dtypes\n        run_tests(df, rhs, right)\n\n        # make frames multi-type & re-run tests\n        for frame in [df, rhs, right]:\n            frame['joe'] = frame['joe'].astype('float64')\n            frame['jolie'] = frame['jolie'].map('@{0}'.format)\n\n        run_tests(df, rhs, right)\n\n    def test_str_label_slicing_with_negative_step(self):\n        SLC = pd.IndexSlice\n\n        def assert_slices_equivalent(l_slc, i_slc):\n            assert_series_equal(s.loc[l_slc], s.iloc[i_slc])\n\n            if not idx.is_integer:\n                # For integer indices, ix and plain getitem are position-based.\n                assert_series_equal(s[l_slc], s.iloc[i_slc])\n                assert_series_equal(s.ix[l_slc], s.iloc[i_slc])\n\n        for idx in [_mklbl('A', 20), np.arange(20) + 100,\n                    np.linspace(100, 150, 20)]:\n            idx = Index(idx)\n            s = Series(np.arange(20), index=idx)\n            assert_slices_equivalent(SLC[idx[9]::-1], SLC[9::-1])\n            assert_slices_equivalent(SLC[:idx[9]:-1], SLC[:8:-1])\n            assert_slices_equivalent(SLC[idx[13]:idx[9]:-1], SLC[13:8:-1])\n            assert_slices_equivalent(SLC[idx[9]:idx[13]:-1], SLC[:0])\n\n    def test_multiindex_label_slicing_with_negative_step(self):\n        s = Series(np.arange(20),\n                   MultiIndex.from_product([list('abcde'), np.arange(4)]))\n        SLC = pd.IndexSlice\n\n        def assert_slices_equivalent(l_slc, i_slc):\n            assert_series_equal(s.loc[l_slc], s.iloc[i_slc])\n            assert_series_equal(s[l_slc], s.iloc[i_slc])\n            assert_series_equal(s.ix[l_slc], s.iloc[i_slc])\n\n        assert_slices_equivalent(SLC[::-1], SLC[::-1])\n\n        assert_slices_equivalent(SLC['d'::-1], SLC[15::-1])\n        assert_slices_equivalent(SLC[('d',)::-1], SLC[15::-1])\n\n        assert_slices_equivalent(SLC[:'d':-1], SLC[:11:-1])\n        assert_slices_equivalent(SLC[:('d',):-1], SLC[:11:-1])\n\n        assert_slices_equivalent(SLC['d':'b':-1], SLC[15:3:-1])\n        assert_slices_equivalent(SLC[('d',):'b':-1], SLC[15:3:-1])\n        assert_slices_equivalent(SLC['d':('b',):-1], SLC[15:3:-1])\n        assert_slices_equivalent(SLC[('d',):('b',):-1], SLC[15:3:-1])\n        assert_slices_equivalent(SLC['b':'d':-1], SLC[:0])\n\n        assert_slices_equivalent(SLC[('c', 2)::-1], SLC[10::-1])\n        assert_slices_equivalent(SLC[:('c', 2):-1], SLC[:9:-1])\n        assert_slices_equivalent(SLC[('e', 0):('c', 2):-1], SLC[16:9:-1])\n\n    def test_slice_with_zero_step_raises(self):\n        s = Series(np.arange(20), index=_mklbl('A', 20))\n        self.assertRaisesRegexp(ValueError, 'slice step cannot be zero',\n                                lambda: s[::0])\n        self.assertRaisesRegexp(ValueError, 'slice step cannot be zero',\n                                lambda: s.loc[::0])\n        self.assertRaisesRegexp(ValueError, 'slice step cannot be zero',\n                                lambda: s.ix[::0])\n\n    def test_indexing_assignment_dict_already_exists(self):\n        df = pd.DataFrame({'x': [1, 2, 6],\n                           'y': [2, 2, 8],\n                           'z': [-5, 0, 5]}).set_index('z')\n        expected = df.copy()\n        rhs = dict(x=9, y=99)\n        df.loc[5] = rhs\n        expected.loc[5] = [9, 99]\n        tm.assert_frame_equal(df, expected)\n\n    def test_indexing_dtypes_on_empty(self):\n        # Check that .iloc and .ix return correct dtypes GH9983\n        df = DataFrame({'a':[1,2,3],'b':['b','b2','b3']})\n        df2 = df.ix[[],:]\n\n        self.assertEqual(df2.loc[:,'a'].dtype, np.int64)\n        assert_series_equal(df2.loc[:,'a'], df2.iloc[:,0])\n        assert_series_equal(df2.loc[:,'a'], df2.ix[:,0])\n\n\n\nclass TestCategoricalIndex(tm.TestCase):\n\n    def setUp(self):\n\n        self.df = DataFrame({'A' : np.arange(6,dtype='int64'),\n                             'B' : Series(list('aabbca')).astype('category',categories=list('cab')) }).set_index('B')\n        self.df2 = DataFrame({'A' : np.arange(6,dtype='int64'),\n                              'B' : Series(list('aabbca')).astype('category',categories=list('cabe')) }).set_index('B')\n        self.df3 = DataFrame({'A' : np.arange(6,dtype='int64'),\n                              'B' : Series([1,1,2,1,3,2]).astype('category',categories=[3,2,1],ordered=True) }).set_index('B')\n        self.df4 = DataFrame({'A' : np.arange(6,dtype='int64'),\n                              'B' : Series([1,1,2,1,3,2]).astype('category',categories=[3,2,1],ordered=False) }).set_index('B')\n\n\n    def test_loc_scalar(self):\n\n        result = self.df.loc['a']\n        expected = DataFrame({'A' : [0,1,5],\n                              'B' : Series(list('aaa')).astype('category',categories=list('cab')) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n\n        df = self.df.copy()\n        df.loc['a'] = 20\n        expected = DataFrame({'A' : [20,20,2,3,4,20],\n                              'B' : Series(list('aabbca')).astype('category',categories=list('cab')) }).set_index('B')\n        assert_frame_equal(df, expected)\n\n        # value not in the categories\n        self.assertRaises(KeyError, lambda : df.loc['d'])\n\n        def f():\n            df.loc['d'] = 10\n        self.assertRaises(TypeError, f)\n\n        def f():\n            df.loc['d','A'] = 10\n        self.assertRaises(TypeError, f)\n\n        def f():\n            df.loc['d','C'] = 10\n        self.assertRaises(TypeError, f)\n\n    def test_loc_listlike(self):\n\n        # list of labels\n        result = self.df.loc[['c','a']]\n        expected = self.df.iloc[[4,0,1,5]]\n        assert_frame_equal(result, expected)\n\n        result = self.df2.loc[['a','b','e']]\n        expected = DataFrame({'A' : [0,1,5,2,3,np.nan],\n                              'B' : Series(list('aaabbe')).astype('category',categories=list('cabe')) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        # element in the categories but not in the values\n        self.assertRaises(KeyError, lambda : self.df2.loc['e'])\n\n        # assign is ok\n        df = self.df2.copy()\n        df.loc['e'] = 20\n        result = df.loc[['a','b','e']]\n        expected = DataFrame({'A' : [0,1,5,2,3,20],\n                              'B' : Series(list('aaabbe')).astype('category',categories=list('cabe')) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        df = self.df2.copy()\n        result = df.loc[['a','b','e']]\n        expected = DataFrame({'A' : [0,1,5,2,3,np.nan],\n                              'B' : Series(list('aaabbe')).astype('category',categories=list('cabe')) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n\n        # not all labels in the categories\n        self.assertRaises(KeyError, lambda : self.df2.loc[['a','d']])\n\n    def test_read_only_source(self):\n        # GH 10043\n        rw_array = np.eye(10)\n        rw_df = DataFrame(rw_array)\n\n        ro_array = np.eye(10)\n        ro_array.setflags(write=False)\n        ro_df = DataFrame(ro_array)\n\n        assert_frame_equal(rw_df.iloc[[1,2,3]],ro_df.iloc[[1,2,3]])\n        assert_frame_equal(rw_df.iloc[[1]],ro_df.iloc[[1]])\n        assert_series_equal(rw_df.iloc[1],ro_df.iloc[1])\n        assert_frame_equal(rw_df.iloc[1:3],ro_df.iloc[1:3])\n\n        assert_frame_equal(rw_df.loc[[1,2,3]],ro_df.loc[[1,2,3]])\n        assert_frame_equal(rw_df.loc[[1]],ro_df.loc[[1]])\n        assert_series_equal(rw_df.loc[1],ro_df.loc[1])\n        assert_frame_equal(rw_df.loc[1:3],ro_df.loc[1:3])\n\n    def test_reindexing(self):\n\n        # reindexing\n        # convert to a regular index\n        result = self.df2.reindex(['a','b','e'])\n        expected = DataFrame({'A' : [0,1,5,2,3,np.nan],\n                              'B' : Series(list('aaabbe')) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        result = self.df2.reindex(['a','b'])\n        expected = DataFrame({'A' : [0,1,5,2,3],\n                              'B' : Series(list('aaabb')) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        result = self.df2.reindex(['e'])\n        expected = DataFrame({'A' : [np.nan],\n                              'B' : Series(['e']) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        result = self.df2.reindex(['d'])\n        expected = DataFrame({'A' : [np.nan],\n                              'B' : Series(['d']) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        # since we are actually reindexing with a Categorical\n        # then return a Categorical\n        cats = list('cabe')\n\n        result = self.df2.reindex(pd.Categorical(['a','d'],categories=cats))\n        expected = DataFrame({'A' : [0,1,5,np.nan],\n                              'B' : Series(list('aaad')).astype('category',categories=cats) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        result = self.df2.reindex(pd.Categorical(['a'],categories=cats))\n        expected = DataFrame({'A' : [0,1,5],\n                              'B' : Series(list('aaa')).astype('category',categories=cats) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        result = self.df2.reindex(['a','b','e'])\n        expected = DataFrame({'A' : [0,1,5,2,3,np.nan],\n                              'B' : Series(list('aaabbe')) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        result = self.df2.reindex(['a','b'])\n        expected = DataFrame({'A' : [0,1,5,2,3],\n                              'B' : Series(list('aaabb')) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        result = self.df2.reindex(['e'])\n        expected = DataFrame({'A' : [np.nan],\n                              'B' : Series(['e']) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        # give back the type of categorical that we received\n        result = self.df2.reindex(pd.Categorical(['a','d'],categories=cats,ordered=True))\n        expected = DataFrame({'A' : [0,1,5,np.nan],\n                              'B' : Series(list('aaad')).astype('category',categories=cats,ordered=True) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        result = self.df2.reindex(pd.Categorical(['a','d'],categories=['a','d']))\n        expected = DataFrame({'A' : [0,1,5,np.nan],\n                              'B' : Series(list('aaad')).astype('category',categories=['a','d']) }).set_index('B')\n        assert_frame_equal(result, expected)\n\n        # passed duplicate indexers are not allowed\n        self.assertRaises(ValueError, lambda : self.df2.reindex(['a','a']))\n\n        # args NotImplemented ATM\n        self.assertRaises(NotImplementedError, lambda : self.df2.reindex(['a'],method='ffill'))\n        self.assertRaises(NotImplementedError, lambda : self.df2.reindex(['a'],level=1))\n        self.assertRaises(NotImplementedError, lambda : self.df2.reindex(['a'],limit=2))\n\n    def test_loc_slice(self):\n\n        # slicing\n        # not implemented ATM\n        # GH9748\n\n        self.assertRaises(TypeError, lambda : self.df.loc[1:5])\n\n        #result = df.loc[1:5]\n        #expected = df.iloc[[1,2,3,4]]\n        #assert_frame_equal(result, expected)\n\n    def test_boolean_selection(self):\n\n        df3 = self.df3\n        df4 = self.df4\n\n        result = df3[df3.index == 'a']\n        expected = df3.iloc[[]]\n        assert_frame_equal(result,expected)\n\n        result = df4[df4.index == 'a']\n        expected = df4.iloc[[]]\n        assert_frame_equal(result,expected)\n\n        result = df3[df3.index == 1]\n        expected = df3.iloc[[0,1,3]]\n        assert_frame_equal(result,expected)\n\n        result = df4[df4.index == 1]\n        expected = df4.iloc[[0,1,3]]\n        assert_frame_equal(result,expected)\n\n        # since we have an ordered categorical\n\n        # CategoricalIndex([1, 1, 2, 1, 3, 2],\n        #         categories=[3, 2, 1],\n        #         ordered=True,\n        #         name=u'B')\n        result = df3[df3.index < 2]\n        expected = df3.iloc[[4]]\n        assert_frame_equal(result,expected)\n\n        result = df3[df3.index > 1]\n        expected = df3.iloc[[]]\n        assert_frame_equal(result,expected)\n\n        # unordered\n        # cannot be compared\n\n        # CategoricalIndex([1, 1, 2, 1, 3, 2],\n        #         categories=[3, 2, 1],\n        #         ordered=False,\n        #         name=u'B')\n        self.assertRaises(TypeError, lambda : df4[df4.index < 2])\n        self.assertRaises(TypeError, lambda : df4[df4.index > 1])\n\nclass TestSeriesNoneCoercion(tm.TestCase):\n    EXPECTED_RESULTS = [\n        # For numeric series, we should coerce to NaN.\n        ([1, 2, 3], [np.nan, 2, 3]),\n        ([1.0, 2.0, 3.0], [np.nan, 2.0, 3.0]),\n\n        # For datetime series, we should coerce to NaT.\n        ([datetime(2000, 1, 1), datetime(2000, 1, 2), datetime(2000, 1, 3)],\n         [NaT, datetime(2000, 1, 2), datetime(2000, 1, 3)]),\n\n        # For objects, we should preserve the None value.\n        ([\"foo\", \"bar\", \"baz\"], [None, \"bar\", \"baz\"]),\n    ]\n\n    def test_coercion_with_setitem(self):\n        for start_data, expected_result in self.EXPECTED_RESULTS:\n            start_series = Series(start_data)\n            start_series[0] = None\n\n            expected_series = Series(expected_result)\n\n            assert_attr_equal('dtype', start_series, expected_series)\n            tm.assert_numpy_array_equal(\n                start_series.values,\n                expected_series.values, strict_nan=True)\n\n    def test_coercion_with_loc_setitem(self):\n        for start_data, expected_result in self.EXPECTED_RESULTS:\n            start_series = Series(start_data)\n            start_series.loc[0] = None\n\n            expected_series = Series(expected_result)\n\n            assert_attr_equal('dtype', start_series, expected_series)\n            tm.assert_numpy_array_equal(\n                start_series.values,\n                expected_series.values, strict_nan=True)\n\n    def test_coercion_with_setitem_and_series(self):\n        for start_data, expected_result in self.EXPECTED_RESULTS:\n            start_series = Series(start_data)\n            start_series[start_series == start_series[0]] = None\n\n            expected_series = Series(expected_result)\n\n            assert_attr_equal('dtype', start_series, expected_series)\n            tm.assert_numpy_array_equal(\n                start_series.values,\n                expected_series.values, strict_nan=True)\n\n    def test_coercion_with_loc_and_series(self):\n        for start_data, expected_result in self.EXPECTED_RESULTS:\n            start_series = Series(start_data)\n            start_series.loc[start_series == start_series[0]] = None\n\n            expected_series = Series(expected_result)\n\n            assert_attr_equal('dtype', start_series, expected_series)\n            tm.assert_numpy_array_equal(\n                start_series.values,\n                expected_series.values, strict_nan=True)\n\n\nclass TestDataframeNoneCoercion(tm.TestCase):\n    EXPECTED_SINGLE_ROW_RESULTS = [\n        # For numeric series, we should coerce to NaN.\n        ([1, 2, 3], [np.nan, 2, 3]),\n        ([1.0, 2.0, 3.0], [np.nan, 2.0, 3.0]),\n\n        # For datetime series, we should coerce to NaT.\n        ([datetime(2000, 1, 1), datetime(2000, 1, 2), datetime(2000, 1, 3)],\n         [NaT, datetime(2000, 1, 2), datetime(2000, 1, 3)]),\n\n        # For objects, we should preserve the None value.\n        ([\"foo\", \"bar\", \"baz\"], [None, \"bar\", \"baz\"]),\n    ]\n\n    def test_coercion_with_loc(self):\n        for start_data, expected_result, in self.EXPECTED_SINGLE_ROW_RESULTS:\n            start_dataframe = DataFrame({'foo': start_data})\n            start_dataframe.loc[0, ['foo']] = None\n\n            expected_dataframe = DataFrame({'foo': expected_result})\n\n            assert_attr_equal('dtype', start_dataframe['foo'], expected_dataframe['foo'])\n            tm.assert_numpy_array_equal(\n                start_dataframe['foo'].values,\n                expected_dataframe['foo'].values, strict_nan=True)\n\n    def test_coercion_with_setitem_and_dataframe(self):\n        for start_data, expected_result, in self.EXPECTED_SINGLE_ROW_RESULTS:\n            start_dataframe = DataFrame({'foo': start_data})\n            start_dataframe[start_dataframe['foo'] == start_dataframe['foo'][0]] = None\n\n            expected_dataframe = DataFrame({'foo': expected_result})\n\n            assert_attr_equal('dtype', start_dataframe['foo'], expected_dataframe['foo'])\n            tm.assert_numpy_array_equal(\n                start_dataframe['foo'].values,\n                expected_dataframe['foo'].values, strict_nan=True)\n\n    def test_none_coercion_loc_and_dataframe(self):\n        for start_data, expected_result, in self.EXPECTED_SINGLE_ROW_RESULTS:\n            start_dataframe = DataFrame({'foo': start_data})\n            start_dataframe.loc[start_dataframe['foo'] == start_dataframe['foo'][0]] = None\n\n            expected_dataframe = DataFrame({'foo': expected_result})\n\n            assert_attr_equal('dtype', start_dataframe['foo'], expected_dataframe['foo'])\n            tm.assert_numpy_array_equal(\n                start_dataframe['foo'].values,\n                expected_dataframe['foo'].values, strict_nan=True)\n\n    def test_none_coercion_mixed_dtypes(self):\n        start_dataframe = DataFrame({\n            'a': [1, 2, 3],\n            'b': [1.0, 2.0, 3.0],\n            'c': [datetime(2000, 1, 1), datetime(2000, 1, 2), datetime(2000, 1, 3)],\n            'd': ['a', 'b', 'c']})\n        start_dataframe.iloc[0] = None\n\n        expected_dataframe = DataFrame({\n            'a': [np.nan, 2, 3],\n            'b': [np.nan, 2.0, 3.0],\n            'c': [NaT, datetime(2000, 1, 2), datetime(2000, 1, 3)],\n            'd': [None, 'b', 'c']})\n\n        for column in expected_dataframe.columns:\n            assert_attr_equal('dtype', start_dataframe[column], expected_dataframe[column])\n            tm.assert_numpy_array_equal(\n                start_dataframe[column].values,\n                expected_dataframe[column].values, strict_nan=True)\n\n\nif __name__ == '__main__':\n    nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],\n                   exit=False)\n"
    }
  ]
}