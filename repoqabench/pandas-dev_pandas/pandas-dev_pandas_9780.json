{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "9780",
  "issue_description": "# pd.merge() doesn't merge int and str column dtypes but no warning or error\n\nWhen merging an int dtype with a str dtype the join does not work:\n\n``` python\n>>> import pandas as pd\n>>> df1 = pd.DataFrame({\"A\":[0]})\n>>> df2 = pd.DataFrame({\"A\":[\"0\"]})\n>>> pd.merge(df1, df2, on=[\"A\"])\nEmpty DataFrame\nColumns: [A]\nIndex: []\n```\n\nI think it would be better to get a warning that the join is performed on incompatible column dtypes.\n\nThis is my pandas version:\n\n```\n>>> pd.show_versions()                                                                                                                                    \n\nINSTALLED VERSIONS\n------------------\ncommit: None\npython: 2.7.9.final.0\npython-bits: 64\nOS: Darwin\nOS-release: 13.4.0\nmachine: x86_64\nprocessor: i386\nbyteorder: little\nLC_ALL: None\nLANG: en_US.UTF-8\n\npandas: 0.15.2\nnose: 1.3.4\nCython: 0.21\nnumpy: 1.9.2\nscipy: 0.15.1                                                                                                                                                          \nstatsmodels: 0.6.1\nIPython: 2.2.0\nsphinx: 1.2.3\npatsy: 0.3.0\ndateutil: 2.4.1\npytz: 2014.9\nbottleneck: None\ntables: 3.1.1\nnumexpr: 2.3.1\nmatplotlib: 1.4.3\nopenpyxl: 1.8.5\nxlrd: 0.9.3\nxlwt: 0.7.5\nxlsxwriter: 0.5.7\nlxml: 3.4.0\nbs4: 4.3.2\nhtml5lib: None\nhttplib2: None\napiclient: None\nrpy2: 2.5.6\nsqlalchemy: 0.9.7\npymysql: None\npsycopg2: None\n```\n\nThanks for all your work on pandas!\n",
  "issue_comments": [
    {
      "id": 88883521,
      "user": "jreback",
      "body": "You are doing an inner merge, which doesn't match. Not sure if we could reliably detect this, as it involves a computation to figure out that you have strings that looks like numbers.\n\n```\nIn [8]: >>> pd.merge(df1, df2, on=[\"A\"],how='outer')\nOut[8]: \n   A\n0  0\n1  0\n\nIn [9]: >>> pd.merge(df1, df2, on=[\"A\"],how='outer').dtypes\nOut[9]: \nA    float64\ndtype: object\n```\n\nyou can also do\n\n`df.convert_objects(convert_numeric=True)` to force the objects to become numbers\n"
    },
    {
      "id": 89393712,
      "user": "inodb",
      "body": "Thanks for your reply and the quick fix. I actually don't think that one should check whether the string represents numbers or not. I think it is more about whether the dtypes of the columns with the same name match. If you do an inner merge on DataFrames with no matching columns you get a MergeError. I think it would make sense to also throw one if there are matching columns but their dtypes can't be silently cast to match. Especially if one specifically sets the option `on=[\"A\"]`.\n"
    },
    {
      "id": 246909286,
      "user": "sudk1896",
      "body": "@inodb @jreback: I would like to take a stab at this. From what I can understand, I need to check the datatypes of the columns that are to be merged, and if they're unequal then throw an error. Could you tell me what type of error ? Thanks.\n"
    },
    {
      "id": 246966727,
      "user": "jreback",
      "body": "this should raise a `ValueError` if the dtypes for the on columns don't match\n"
    },
    {
      "id": 246967203,
      "user": "jorisvandenbossche",
      "body": "Suppose the case of an int and float column. I don't think it should raise if you want to merge on those columns? (can eg already typically occur when having NaNs in one of both)\n"
    },
    {
      "id": 246967835,
      "user": "jreback",
      "body": "right we care about 'obvious' mismatches here that by-definition cannot match. so `object` vs `int/float` (or datetimelike vs `int/float/object`). We will need to `lib.infer_dtype` to make this more specific (e.g. `string/unicode` cannot match `int`)\n"
    },
    {
      "id": 247013104,
      "user": "jorisvandenbossche",
      "body": "Personally, I would leave this as a responsibility of the user. \nAlthough I understand that the example above can be confusing at first, trying to guess when the user passed wrong dtypes by accident instead of on purpose seems like adding complexity that is not really worth it (but it's a trade-off of course) \n\nSomething else, currently, as @jreback shows above (https://github.com/pydata/pandas/issues/9780#issuecomment-88883521), the strings of `df2` get coerced to numeric values on merging:\n\n```\nIn [57]: pd.merge(df1, df2, on=[\"A\"],how='outer').dtypes\nOut[57]: \nA    int64\ndtype: object\n```\n\nI suppose this happens on purpose? IMO it should return object array and keep the original values (like `pd.concat` does)\n"
    },
    {
      "id": 247016056,
      "user": "jreback",
      "body": "@jorisvandenbossche yes, we should certainly not coerce on mixed types in merging, unless they are losslessly convertible (e.g. int & float), so maybe make a separate issue.\n\nBut I think we should raise on str/numeric, and datetimelike/(str or numeric), it is simply not possible (and if the user _really_ wants that, then its just a concat).\n"
    },
    {
      "id": 247020186,
      "user": "jorisvandenbossche",
      "body": "> and if the user really wants that, then its just a concat\n\nThat's a good point :-)\n"
    },
    {
      "id": 247036528,
      "user": "jorisvandenbossche",
      "body": "> yes, we should certainly not coerce on mixed types in merging, unless they are losslessly convertible (e.g. int & float), so maybe make a separate issue.\n\nOn a second thought, if we disallow merging on str/numeric (the case of the initial example), I don't think are cases left that we would allow but  where no coercing should happen? (for which I wanted to open an new issue)\n"
    },
    {
      "id": 247044778,
      "user": "jreback",
      "body": "@jorisvandenbossche can you show example / elaborate on your last?\n\n> On a second thought, if we disallow merging on str/numeric (the case of the initial example), I don't think are cases left that we would allow but where no coercing should happen? (for which I wanted to open an new issue)\n"
    },
    {
      "id": 247046017,
      "user": "jorisvandenbossche",
      "body": "Well, the original example above has a dataframe with integers in the key column, and another dataframe with strings in the key column. They are now coerced to integers, something I think should not happen:\n\n```\nIn [62]: df1 = pd.DataFrame({\"A\":[0], \"B\":[1]})\n\nIn [63]: df2 = pd.DataFrame({\"A\":[\"0\"], \"B\":[2]})\n\nIn [64]: pd.merge(df1, df2, on=[\"A\"],how='outer')\nOut[64]: \n   A  B_x  B_y\n0  0  1.0  NaN\n1  0  NaN  2.0\n\nIn [65]: pd.merge(df1, df2, on=[\"A\"],how='outer').A.dtype\nOut[65]: dtype('int64')\n\nIn [66]: pd.merge(df1, df2, on=[\"A\"],how='outer').A.values\nOut[66]: array([0, 0])\n```\n\nAnd I wanted to open an new issue for this. But, this is also an example where we would want to raise an error about \"incompatible columns to merge on\". \nSo would there still be cases where we would not raise such an error, but still happens unwanted coercing?\n"
    },
    {
      "id": 247048387,
      "user": "jreback",
      "body": "ah I c. I think this should raise a nice errors message (maybe saying that you might want to use `pd.concat`), which will simply work.\n\nconcat\n\n```\nIn [16]: pd.concat([df1,df2])\nOut[16]:\n   A\n0  0\n0  0\n\nIn [17]: pd.concat([df1,df2]).dtypes\nOut[17]:\nA    object\ndtype: object\n\nIn [18]: pd.concat([df1,df2]).values\nOut[18]:\narray([[0],\n       ['0']], dtype=object)\n```\n\nmerge\n\n```\nIn [19]: pd.merge(df1, df2, on ='A')\nOut[19]:\nEmpty DataFrame\nColumns: [A]\nIndex: []\n\nIn [20]: pd.merge(df1, df2, on ='A', how='outer')\nOut[20]:\n   A\n0  0\n1  0\n\nIn [21]: pd.merge(df1, df2, on ='A', how='outer').dtypes\nOut[21]:\nA    int64\ndtype: object\n```\n\nso [20,21] are wrong (this should be `object`).\n\nBut I would actually simply raise `ValueError` on the merge. Its a mistake on the users part.\n"
    },
    {
      "id": 374374905,
      "user": "kylebarron",
      "body": "Was #18764 included in the Pandas 0.22.0 release? It looks like @jreback added that to the 0.22.0 milestone on Dec 7, 2017, and it was merged to master 19 days before 0.22.0 was released, but the initial example still fails for me on 0.22.0:\r\n\r\n>    ```py\r\n>    >>> import pandas as pd\r\n>    >>> df1 = pd.DataFrame({\"A\": [0]})\r\n>    >>> df2 = pd.DataFrame({\"A\": [\"0\"]})\r\n>    >>> pd.merge(df1, df2, on=[\"A\"])\r\n>    Empty DataFrame\r\n>    Columns: [A]\r\n>    Index: []\r\n>    ``` \r\n\r\n```py\r\n>>> pd.show_versions()\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.4.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.13.0-37-generic\r\nmachine: x86_64\r\nprocessor: x86_64\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.22.0\r\npytest: 3.4.0\r\npip: 9.0.1\r\nsetuptools: 38.5.1\r\nCython: 0.27.3\r\nnumpy: 1.14.1\r\nscipy: 1.0.0\r\npyarrow: 0.8.0\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.7.1\r\npatsy: 0.5.0\r\ndateutil: 2.6.1\r\npytz: 2018.3\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: 0.4.0\r\nmatplotlib: 2.1.2\r\nopenpyxl: 2.5.0\r\nxlrd: 1.1.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 1.0.2\r\nlxml: 4.1.1\r\nbs4: 4.6.0\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.2.3\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: 0.1.4\r\npandas_gbq: None\r\npandas_datareader: None\r\n```"
    },
    {
      "id": 374391152,
      "user": "TomAugspurger",
      "body": "https://github.com/pandas-dev/pandas/pull/18674 will be in the 0.23 release.\r\n\r\nThe 0.22 release just had one change. You can always view the release notes for a version at http://pandas.pydata.org/pandas-docs/stable/whatsnew.html."
    }
  ],
  "text_context": "# pd.merge() doesn't merge int and str column dtypes but no warning or error\n\nWhen merging an int dtype with a str dtype the join does not work:\n\n``` python\n>>> import pandas as pd\n>>> df1 = pd.DataFrame({\"A\":[0]})\n>>> df2 = pd.DataFrame({\"A\":[\"0\"]})\n>>> pd.merge(df1, df2, on=[\"A\"])\nEmpty DataFrame\nColumns: [A]\nIndex: []\n```\n\nI think it would be better to get a warning that the join is performed on incompatible column dtypes.\n\nThis is my pandas version:\n\n```\n>>> pd.show_versions()                                                                                                                                    \n\nINSTALLED VERSIONS\n------------------\ncommit: None\npython: 2.7.9.final.0\npython-bits: 64\nOS: Darwin\nOS-release: 13.4.0\nmachine: x86_64\nprocessor: i386\nbyteorder: little\nLC_ALL: None\nLANG: en_US.UTF-8\n\npandas: 0.15.2\nnose: 1.3.4\nCython: 0.21\nnumpy: 1.9.2\nscipy: 0.15.1                                                                                                                                                          \nstatsmodels: 0.6.1\nIPython: 2.2.0\nsphinx: 1.2.3\npatsy: 0.3.0\ndateutil: 2.4.1\npytz: 2014.9\nbottleneck: None\ntables: 3.1.1\nnumexpr: 2.3.1\nmatplotlib: 1.4.3\nopenpyxl: 1.8.5\nxlrd: 0.9.3\nxlwt: 0.7.5\nxlsxwriter: 0.5.7\nlxml: 3.4.0\nbs4: 4.3.2\nhtml5lib: None\nhttplib2: None\napiclient: None\nrpy2: 2.5.6\nsqlalchemy: 0.9.7\npymysql: None\npsycopg2: None\n```\n\nThanks for all your work on pandas!\n\n\nYou are doing an inner merge, which doesn't match. Not sure if we could reliably detect this, as it involves a computation to figure out that you have strings that looks like numbers.\n\n```\nIn [8]: >>> pd.merge(df1, df2, on=[\"A\"],how='outer')\nOut[8]: \n   A\n0  0\n1  0\n\nIn [9]: >>> pd.merge(df1, df2, on=[\"A\"],how='outer').dtypes\nOut[9]: \nA    float64\ndtype: object\n```\n\nyou can also do\n\n`df.convert_objects(convert_numeric=True)` to force the objects to become numbers\n\n\nThanks for your reply and the quick fix. I actually don't think that one should check whether the string represents numbers or not. I think it is more about whether the dtypes of the columns with the same name match. If you do an inner merge on DataFrames with no matching columns you get a MergeError. I think it would make sense to also throw one if there are matching columns but their dtypes can't be silently cast to match. Especially if one specifically sets the option `on=[\"A\"]`.\n\n\n@inodb @jreback: I would like to take a stab at this. From what I can understand, I need to check the datatypes of the columns that are to be merged, and if they're unequal then throw an error. Could you tell me what type of error ? Thanks.\n\n\nthis should raise a `ValueError` if the dtypes for the on columns don't match\n\n\nSuppose the case of an int and float column. I don't think it should raise if you want to merge on those columns? (can eg already typically occur when having NaNs in one of both)\n\n\nright we care about 'obvious' mismatches here that by-definition cannot match. so `object` vs `int/float` (or datetimelike vs `int/float/object`). We will need to `lib.infer_dtype` to make this more specific (e.g. `string/unicode` cannot match `int`)\n\n\nPersonally, I would leave this as a responsibility of the user. \nAlthough I understand that the example above can be confusing at first, trying to guess when the user passed wrong dtypes by accident instead of on purpose seems like adding complexity that is not really worth it (but it's a trade-off of course) \n\nSomething else, currently, as @jreback shows above (https://github.com/pydata/pandas/issues/9780#issuecomment-88883521), the strings of `df2` get coerced to numeric values on merging:\n\n```\nIn [57]: pd.merge(df1, df2, on=[\"A\"],how='outer').dtypes\nOut[57]: \nA    int64\ndtype: object\n```\n\nI suppose this happens on purpose? IMO it should return object array and keep the original values (like `pd.concat` does)\n\n\n@jorisvandenbossche yes, we should certainly not coerce on mixed types in merging, unless they are losslessly convertible (e.g. int & float), so maybe make a separate issue.\n\nBut I think we should raise on str/numeric, and datetimelike/(str or numeric), it is simply not possible (and if the user _really_ wants that, then its just a concat).\n\n\n> and if the user really wants that, then its just a concat\n\nThat's a good point :-)\n\n\n> yes, we should certainly not coerce on mixed types in merging, unless they are losslessly convertible (e.g. int & float), so maybe make a separate issue.\n\nOn a second thought, if we disallow merging on str/numeric (the case of the initial example), I don't think are cases left that we would allow but  where no coercing should happen? (for which I wanted to open an new issue)\n\n\n@jorisvandenbossche can you show example / elaborate on your last?\n\n> On a second thought, if we disallow merging on str/numeric (the case of the initial example), I don't think are cases left that we would allow but where no coercing should happen? (for which I wanted to open an new issue)\n\n\nWell, the original example above has a dataframe with integers in the key column, and another dataframe with strings in the key column. They are now coerced to integers, something I think should not happen:\n\n```\nIn [62]: df1 = pd.DataFrame({\"A\":[0], \"B\":[1]})\n\nIn [63]: df2 = pd.DataFrame({\"A\":[\"0\"], \"B\":[2]})\n\nIn [64]: pd.merge(df1, df2, on=[\"A\"],how='outer')\nOut[64]: \n   A  B_x  B_y\n0  0  1.0  NaN\n1  0  NaN  2.0\n\nIn [65]: pd.merge(df1, df2, on=[\"A\"],how='outer').A.dtype\nOut[65]: dtype('int64')\n\nIn [66]: pd.merge(df1, df2, on=[\"A\"],how='outer').A.values\nOut[66]: array([0, 0])\n```\n\nAnd I wanted to open an new issue for this. But, this is also an example where we would want to raise an error about \"incompatible columns to merge on\". \nSo would there still be cases where we would not raise such an error, but still happens unwanted coercing?\n\n\nah I c. I think this should raise a nice errors message (maybe saying that you might want to use `pd.concat`), which will simply work.\n\nconcat\n\n```\nIn [16]: pd.concat([df1,df2])\nOut[16]:\n   A\n0  0\n0  0\n\nIn [17]: pd.concat([df1,df2]).dtypes\nOut[17]:\nA    object\ndtype: object\n\nIn [18]: pd.concat([df1,df2]).values\nOut[18]:\narray([[0],\n       ['0']], dtype=object)\n```\n\nmerge\n\n```\nIn [19]: pd.merge(df1, df2, on ='A')\nOut[19]:\nEmpty DataFrame\nColumns: [A]\nIndex: []\n\nIn [20]: pd.merge(df1, df2, on ='A', how='outer')\nOut[20]:\n   A\n0  0\n1  0\n\nIn [21]: pd.merge(df1, df2, on ='A', how='outer').dtypes\nOut[21]:\nA    int64\ndtype: object\n```\n\nso [20,21] are wrong (this should be `object`).\n\nBut I would actually simply raise `ValueError` on the merge. Its a mistake on the users part.\n\n\nWas #18764 included in the Pandas 0.22.0 release? It looks like @jreback added that to the 0.22.0 milestone on Dec 7, 2017, and it was merged to master 19 days before 0.22.0 was released, but the initial example still fails for me on 0.22.0:\r\n\r\n>    ```py\r\n>    >>> import pandas as pd\r\n>    >>> df1 = pd.DataFrame({\"A\": [0]})\r\n>    >>> df2 = pd.DataFrame({\"A\": [\"0\"]})\r\n>    >>> pd.merge(df1, df2, on=[\"A\"])\r\n>    Empty DataFrame\r\n>    Columns: [A]\r\n>    Index: []\r\n>    ``` \r\n\r\n```py\r\n>>> pd.show_versions()\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.4.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.13.0-37-generic\r\nmachine: x86_64\r\nprocessor: x86_64\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.22.0\r\npytest: 3.4.0\r\npip: 9.0.1\r\nsetuptools: 38.5.1\r\nCython: 0.27.3\r\nnumpy: 1.14.1\r\nscipy: 1.0.0\r\npyarrow: 0.8.0\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.7.1\r\npatsy: 0.5.0\r\ndateutil: 2.6.1\r\npytz: 2018.3\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: 0.4.0\r\nmatplotlib: 2.1.2\r\nopenpyxl: 2.5.0\r\nxlrd: 1.1.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 1.0.2\r\nlxml: 4.1.1\r\nbs4: 4.6.0\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.2.3\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: 0.1.4\r\npandas_gbq: None\r\npandas_datareader: None\r\n```\n\nhttps://github.com/pandas-dev/pandas/pull/18674 will be in the 0.23 release.\r\n\r\nThe 0.22 release just had one change. You can always view the release notes for a version at http://pandas.pydata.org/pandas-docs/stable/whatsnew.html.",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/18674",
  "code_context": [
    {
      "filename": "pandas/core/reshape/merge.py",
      "content": "\"\"\"\nSQL-style merge routines\n\"\"\"\n\nimport copy\nimport warnings\nimport string\n\nimport numpy as np\nfrom pandas.compat import range, lzip, zip, map, filter\nimport pandas.compat as compat\n\nfrom pandas import (Categorical, Series, DataFrame,\n                    Index, MultiIndex, Timedelta)\nfrom pandas.core.frame import _merge_doc\nfrom pandas.core.dtypes.common import (\n    is_datetime64tz_dtype,\n    is_datetime64_dtype,\n    needs_i8_conversion,\n    is_int64_dtype,\n    is_categorical_dtype,\n    is_integer_dtype,\n    is_float_dtype,\n    is_numeric_dtype,\n    is_integer,\n    is_int_or_datetime_dtype,\n    is_dtype_equal,\n    is_bool,\n    is_list_like,\n    is_datetimelike,\n    _ensure_int64,\n    _ensure_float64,\n    _ensure_object,\n    _get_dtype)\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.internals import (items_overlap_with_suffix,\n                                   concatenate_block_managers)\nfrom pandas.util._decorators import Appender, Substitution\n\nfrom pandas.core.sorting import is_int64_overflow_possible\nimport pandas.core.algorithms as algos\nimport pandas.core.sorting as sorting\nimport pandas.core.common as com\nfrom pandas._libs import hashtable as libhashtable, join as libjoin, lib\nfrom pandas.errors import MergeError\n\n\n@Substitution('\\nleft : DataFrame')\n@Appender(_merge_doc, indents=0)\ndef merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n          left_index=False, right_index=False, sort=False,\n          suffixes=('_x', '_y'), copy=True, indicator=False,\n          validate=None):\n    op = _MergeOperation(left, right, how=how, on=on, left_on=left_on,\n                         right_on=right_on, left_index=left_index,\n                         right_index=right_index, sort=sort, suffixes=suffixes,\n                         copy=copy, indicator=indicator,\n                         validate=validate)\n    return op.get_result()\n\n\nif __debug__:\n    merge.__doc__ = _merge_doc % '\\nleft : DataFrame'\n\n\ndef _groupby_and_merge(by, on, left, right, _merge_pieces,\n                       check_duplicates=True):\n    \"\"\"\n    groupby & merge; we are always performing a left-by type operation\n\n    Parameters\n    ----------\n    by: field to group\n    on: duplicates field\n    left: left frame\n    right: right frame\n    _merge_pieces: function for merging\n    check_duplicates: boolean, default True\n        should we check & clean duplicates\n    \"\"\"\n\n    pieces = []\n    if not isinstance(by, (list, tuple)):\n        by = [by]\n\n    lby = left.groupby(by, sort=False)\n\n    # if we can groupby the rhs\n    # then we can get vastly better perf\n    try:\n\n        # we will check & remove duplicates if indicated\n        if check_duplicates:\n            if on is None:\n                on = []\n            elif not isinstance(on, (list, tuple)):\n                on = [on]\n\n            if right.duplicated(by + on).any():\n                right = right.drop_duplicates(by + on, keep='last')\n        rby = right.groupby(by, sort=False)\n    except KeyError:\n        rby = None\n\n    for key, lhs in lby:\n\n        if rby is None:\n            rhs = right\n        else:\n            try:\n                rhs = right.take(rby.indices[key])\n            except KeyError:\n                # key doesn't exist in left\n                lcols = lhs.columns.tolist()\n                cols = lcols + [r for r in right.columns\n                                if r not in set(lcols)]\n                merged = lhs.reindex(columns=cols)\n                merged.index = range(len(merged))\n                pieces.append(merged)\n                continue\n\n        merged = _merge_pieces(lhs, rhs)\n\n        # make sure join keys are in the merged\n        # TODO, should _merge_pieces do this?\n        for k in by:\n            try:\n                if k in merged:\n                    merged[k] = key\n            except KeyError:\n                pass\n\n        pieces.append(merged)\n\n    # preserve the original order\n    # if we have a missing piece this can be reset\n    from pandas.core.reshape.concat import concat\n    result = concat(pieces, ignore_index=True)\n    result = result.reindex(columns=pieces[0].columns, copy=False)\n    return result, lby\n\n\ndef merge_ordered(left, right, on=None,\n                  left_on=None, right_on=None,\n                  left_by=None, right_by=None,\n                  fill_method=None, suffixes=('_x', '_y'),\n                  how='outer'):\n    \"\"\"Perform merge with optional filling/interpolation designed for ordered\n    data like time series data. Optionally perform group-wise merge (see\n    examples)\n\n    Parameters\n    ----------\n    left : DataFrame\n    right : DataFrame\n    on : label or list\n        Field names to join on. Must be found in both DataFrames.\n    left_on : label or list, or array-like\n        Field names to join on in left DataFrame. Can be a vector or list of\n        vectors of the length of the DataFrame to use a particular vector as\n        the join key instead of columns\n    right_on : label or list, or array-like\n        Field names to join on in right DataFrame or vector/list of vectors per\n        left_on docs\n    left_by : column name or list of column names\n        Group left DataFrame by group columns and merge piece by piece with\n        right DataFrame\n    right_by : column name or list of column names\n        Group right DataFrame by group columns and merge piece by piece with\n        left DataFrame\n    fill_method : {'ffill', None}, default None\n        Interpolation method for data\n    suffixes : 2-length sequence (tuple, list, ...)\n        Suffix to apply to overlapping column names in the left and right\n        side, respectively\n    how : {'left', 'right', 'outer', 'inner'}, default 'outer'\n        * left: use only keys from left frame (SQL: left outer join)\n        * right: use only keys from right frame (SQL: right outer join)\n        * outer: use union of keys from both frames (SQL: full outer join)\n        * inner: use intersection of keys from both frames (SQL: inner join)\n\n        .. versionadded:: 0.19.0\n\n    Examples\n    --------\n    >>> A                      >>> B\n          key  lvalue group        key  rvalue\n    0   a       1     a        0     b       1\n    1   c       2     a        1     c       2\n    2   e       3     a        2     d       3\n    3   a       1     b\n    4   c       2     b\n    5   e       3     b\n\n    >>> merge_ordered(A, B, fill_method='ffill', left_by='group')\n       key  lvalue group  rvalue\n    0    a       1     a     NaN\n    1    b       1     a       1\n    2    c       2     a       2\n    3    d       2     a       3\n    4    e       3     a       3\n    5    f       3     a       4\n    6    a       1     b     NaN\n    7    b       1     b       1\n    8    c       2     b       2\n    9    d       2     b       3\n    10   e       3     b       3\n    11   f       3     b       4\n\n    Returns\n    -------\n    merged : DataFrame\n        The output type will the be same as 'left', if it is a subclass\n        of DataFrame.\n\n    See also\n    --------\n    merge\n    merge_asof\n\n    \"\"\"\n    def _merger(x, y):\n        # perform the ordered merge operation\n        op = _OrderedMerge(x, y, on=on, left_on=left_on, right_on=right_on,\n                           suffixes=suffixes, fill_method=fill_method,\n                           how=how)\n        return op.get_result()\n\n    if left_by is not None and right_by is not None:\n        raise ValueError('Can only group either left or right frames')\n    elif left_by is not None:\n        result, _ = _groupby_and_merge(left_by, on, left, right,\n                                       lambda x, y: _merger(x, y),\n                                       check_duplicates=False)\n    elif right_by is not None:\n        result, _ = _groupby_and_merge(right_by, on, right, left,\n                                       lambda x, y: _merger(y, x),\n                                       check_duplicates=False)\n    else:\n        result = _merger(left, right)\n    return result\n\n\ndef merge_asof(left, right, on=None,\n               left_on=None, right_on=None,\n               left_index=False, right_index=False,\n               by=None, left_by=None, right_by=None,\n               suffixes=('_x', '_y'),\n               tolerance=None,\n               allow_exact_matches=True,\n               direction='backward'):\n    \"\"\"Perform an asof merge. This is similar to a left-join except that we\n    match on nearest key rather than equal keys.\n\n    Both DataFrames must be sorted by the key.\n\n    For each row in the left DataFrame:\n\n      - A \"backward\" search selects the last row in the right DataFrame whose\n        'on' key is less than or equal to the left's key.\n\n      - A \"forward\" search selects the first row in the right DataFrame whose\n        'on' key is greater than or equal to the left's key.\n\n      - A \"nearest\" search selects the row in the right DataFrame whose 'on'\n        key is closest in absolute distance to the left's key.\n\n    The default is \"backward\" and is compatible in versions below 0.20.0.\n    The direction parameter was added in version 0.20.0 and introduces\n    \"forward\" and \"nearest\".\n\n    Optionally match on equivalent keys with 'by' before searching with 'on'.\n\n    .. versionadded:: 0.19.0\n\n    Parameters\n    ----------\n    left : DataFrame\n    right : DataFrame\n    on : label\n        Field name to join on. Must be found in both DataFrames.\n        The data MUST be ordered. Furthermore this must be a numeric column,\n        such as datetimelike, integer, or float. On or left_on/right_on\n        must be given.\n    left_on : label\n        Field name to join on in left DataFrame.\n    right_on : label\n        Field name to join on in right DataFrame.\n    left_index : boolean\n        Use the index of the left DataFrame as the join key.\n\n        .. versionadded:: 0.19.2\n\n    right_index : boolean\n        Use the index of the right DataFrame as the join key.\n\n        .. versionadded:: 0.19.2\n\n    by : column name or list of column names\n        Match on these columns before performing merge operation.\n    left_by : column name\n        Field names to match on in the left DataFrame.\n\n        .. versionadded:: 0.19.2\n\n    right_by : column name\n        Field names to match on in the right DataFrame.\n\n        .. versionadded:: 0.19.2\n\n    suffixes : 2-length sequence (tuple, list, ...)\n        Suffix to apply to overlapping column names in the left and right\n        side, respectively.\n    tolerance : integer or Timedelta, optional, default None\n        Select asof tolerance within this range; must be compatible\n        with the merge index.\n    allow_exact_matches : boolean, default True\n\n        - If True, allow matching with the same 'on' value\n          (i.e. less-than-or-equal-to / greater-than-or-equal-to)\n        - If False, don't match the same 'on' value\n          (i.e., stricly less-than / strictly greater-than)\n\n    direction : 'backward' (default), 'forward', or 'nearest'\n        Whether to search for prior, subsequent, or closest matches.\n\n        .. versionadded:: 0.20.0\n\n\n    Returns\n    -------\n    merged : DataFrame\n\n    Examples\n    --------\n    >>> left = pd.DataFrame({'a': [1, 5, 10], 'left_val': ['a', 'b', 'c']})\n    >>> left\n        a left_val\n    0   1        a\n    1   5        b\n    2  10        c\n\n    >>> right = pd.DataFrame({'a': [1, 2, 3, 6, 7],\n    ...                       'right_val': [1, 2, 3, 6, 7]})\n    >>> right\n       a  right_val\n    0  1          1\n    1  2          2\n    2  3          3\n    3  6          6\n    4  7          7\n\n    >>> pd.merge_asof(left, right, on='a')\n        a left_val  right_val\n    0   1        a          1\n    1   5        b          3\n    2  10        c          7\n\n    >>> pd.merge_asof(left, right, on='a', allow_exact_matches=False)\n        a left_val  right_val\n    0   1        a        NaN\n    1   5        b        3.0\n    2  10        c        7.0\n\n    >>> pd.merge_asof(left, right, on='a', direction='forward')\n        a left_val  right_val\n    0   1        a        1.0\n    1   5        b        6.0\n    2  10        c        NaN\n\n    >>> pd.merge_asof(left, right, on='a', direction='nearest')\n        a left_val  right_val\n    0   1        a          1\n    1   5        b          6\n    2  10        c          7\n\n    We can use indexed DataFrames as well.\n\n    >>> left = pd.DataFrame({'left_val': ['a', 'b', 'c']}, index=[1, 5, 10])\n    >>> left\n       left_val\n    1         a\n    5         b\n    10        c\n\n    >>> right = pd.DataFrame({'right_val': [1, 2, 3, 6, 7]},\n    ...                      index=[1, 2, 3, 6, 7])\n    >>> right\n       right_val\n    1          1\n    2          2\n    3          3\n    6          6\n    7          7\n\n    >>> pd.merge_asof(left, right, left_index=True, right_index=True)\n       left_val  right_val\n    1         a          1\n    5         b          3\n    10        c          7\n\n    Here is a real-world times-series example\n\n    >>> quotes\n                         time ticker     bid     ask\n    0 2016-05-25 13:30:00.023   GOOG  720.50  720.93\n    1 2016-05-25 13:30:00.023   MSFT   51.95   51.96\n    2 2016-05-25 13:30:00.030   MSFT   51.97   51.98\n    3 2016-05-25 13:30:00.041   MSFT   51.99   52.00\n    4 2016-05-25 13:30:00.048   GOOG  720.50  720.93\n    5 2016-05-25 13:30:00.049   AAPL   97.99   98.01\n    6 2016-05-25 13:30:00.072   GOOG  720.50  720.88\n    7 2016-05-25 13:30:00.075   MSFT   52.01   52.03\n\n    >>> trades\n                         time ticker   price  quantity\n    0 2016-05-25 13:30:00.023   MSFT   51.95        75\n    1 2016-05-25 13:30:00.038   MSFT   51.95       155\n    2 2016-05-25 13:30:00.048   GOOG  720.77       100\n    3 2016-05-25 13:30:00.048   GOOG  720.92       100\n    4 2016-05-25 13:30:00.048   AAPL   98.00       100\n\n    By default we are taking the asof of the quotes\n\n    >>> pd.merge_asof(trades, quotes,\n    ...                       on='time',\n    ...                       by='ticker')\n                         time ticker   price  quantity     bid     ask\n    0 2016-05-25 13:30:00.023   MSFT   51.95        75   51.95   51.96\n    1 2016-05-25 13:30:00.038   MSFT   51.95       155   51.97   51.98\n    2 2016-05-25 13:30:00.048   GOOG  720.77       100  720.50  720.93\n    3 2016-05-25 13:30:00.048   GOOG  720.92       100  720.50  720.93\n    4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\n\n    We only asof within 2ms between the quote time and the trade time\n\n    >>> pd.merge_asof(trades, quotes,\n    ...                       on='time',\n    ...                       by='ticker',\n    ...                       tolerance=pd.Timedelta('2ms'))\n                         time ticker   price  quantity     bid     ask\n    0 2016-05-25 13:30:00.023   MSFT   51.95        75   51.95   51.96\n    1 2016-05-25 13:30:00.038   MSFT   51.95       155     NaN     NaN\n    2 2016-05-25 13:30:00.048   GOOG  720.77       100  720.50  720.93\n    3 2016-05-25 13:30:00.048   GOOG  720.92       100  720.50  720.93\n    4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\n\n    We only asof within 10ms between the quote time and the trade time\n    and we exclude exact matches on time. However *prior* data will\n    propagate forward\n\n    >>> pd.merge_asof(trades, quotes,\n    ...                       on='time',\n    ...                       by='ticker',\n    ...                       tolerance=pd.Timedelta('10ms'),\n    ...                       allow_exact_matches=False)\n                         time ticker   price  quantity     bid     ask\n    0 2016-05-25 13:30:00.023   MSFT   51.95        75     NaN     NaN\n    1 2016-05-25 13:30:00.038   MSFT   51.95       155   51.97   51.98\n    2 2016-05-25 13:30:00.048   GOOG  720.77       100  720.50  720.93\n    3 2016-05-25 13:30:00.048   GOOG  720.92       100  720.50  720.93\n    4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\n\n    See also\n    --------\n    merge\n    merge_ordered\n\n    \"\"\"\n    op = _AsOfMerge(left, right,\n                    on=on, left_on=left_on, right_on=right_on,\n                    left_index=left_index, right_index=right_index,\n                    by=by, left_by=left_by, right_by=right_by,\n                    suffixes=suffixes,\n                    how='asof', tolerance=tolerance,\n                    allow_exact_matches=allow_exact_matches,\n                    direction=direction)\n    return op.get_result()\n\n\n# TODO: transformations??\n# TODO: only copy DataFrames when modification necessary\nclass _MergeOperation(object):\n    \"\"\"\n    Perform a database (SQL) merge operation between two DataFrame objects\n    using either columns as keys or their row indexes\n    \"\"\"\n    _merge_type = 'merge'\n\n    def __init__(self, left, right, how='inner', on=None,\n                 left_on=None, right_on=None, axis=1,\n                 left_index=False, right_index=False, sort=True,\n                 suffixes=('_x', '_y'), copy=True, indicator=False,\n                 validate=None):\n        self.left = self.orig_left = left\n        self.right = self.orig_right = right\n        self.how = how\n        self.axis = axis\n\n        self.on = com._maybe_make_list(on)\n        self.left_on = com._maybe_make_list(left_on)\n        self.right_on = com._maybe_make_list(right_on)\n\n        self.copy = copy\n        self.suffixes = suffixes\n        self.sort = sort\n\n        self.left_index = left_index\n        self.right_index = right_index\n\n        self.indicator = indicator\n\n        if isinstance(self.indicator, compat.string_types):\n            self.indicator_name = self.indicator\n        elif isinstance(self.indicator, bool):\n            self.indicator_name = '_merge' if self.indicator else None\n        else:\n            raise ValueError(\n                'indicator option can only accept boolean or string arguments')\n\n        if not isinstance(left, DataFrame):\n            raise ValueError('can not merge DataFrame with instance of '\n                             'type {left}'.format(left=type(left)))\n        if not isinstance(right, DataFrame):\n            raise ValueError('can not merge DataFrame with instance of '\n                             'type {right}'.format(right=type(right)))\n\n        if not is_bool(left_index):\n            raise ValueError(\n                'left_index parameter must be of type bool, not '\n                '{left_index}'.format(left_index=type(left_index)))\n        if not is_bool(right_index):\n            raise ValueError(\n                'right_index parameter must be of type bool, not '\n                '{right_index}'.format(right_index=type(right_index)))\n\n        # warn user when merging between different levels\n        if left.columns.nlevels != right.columns.nlevels:\n            msg = ('merging between different levels can give an unintended '\n                   'result ({left} levels on the left, {right} on the right)'\n                   ).format(left=left.columns.nlevels,\n                            right=right.columns.nlevels)\n            warnings.warn(msg, UserWarning)\n\n        self._validate_specification()\n\n        # note this function has side effects\n        (self.left_join_keys,\n         self.right_join_keys,\n         self.join_names) = self._get_merge_keys()\n\n        # validate the merge keys dtypes. We may need to coerce\n        # to avoid incompat dtypes\n        self._maybe_coerce_merge_keys()\n\n        # If argument passed to validate,\n        # check if columns specified as unique\n        # are in fact unique.\n        if validate is not None:\n            self._validate(validate)\n\n    def get_result(self):\n        if self.indicator:\n            self.left, self.right = self._indicator_pre_merge(\n                self.left, self.right)\n\n        join_index, left_indexer, right_indexer = self._get_join_info()\n\n        ldata, rdata = self.left._data, self.right._data\n        lsuf, rsuf = self.suffixes\n\n        llabels, rlabels = items_overlap_with_suffix(ldata.items, lsuf,\n                                                     rdata.items, rsuf)\n\n        lindexers = {1: left_indexer} if left_indexer is not None else {}\n        rindexers = {1: right_indexer} if right_indexer is not None else {}\n\n        result_data = concatenate_block_managers(\n            [(ldata, lindexers), (rdata, rindexers)],\n            axes=[llabels.append(rlabels), join_index],\n            concat_axis=0, copy=self.copy)\n\n        typ = self.left._constructor\n        result = typ(result_data).__finalize__(self, method=self._merge_type)\n\n        if self.indicator:\n            result = self._indicator_post_merge(result)\n\n        self._maybe_add_join_keys(result, left_indexer, right_indexer)\n\n        self._maybe_restore_index_levels(result)\n\n        return result\n\n    def _indicator_pre_merge(self, left, right):\n\n        columns = left.columns.union(right.columns)\n\n        for i in ['_left_indicator', '_right_indicator']:\n            if i in columns:\n                raise ValueError(\"Cannot use `indicator=True` option when \"\n                                 \"data contains a column named {name}\"\n                                 .format(name=i))\n        if self.indicator_name in columns:\n            raise ValueError(\n                \"Cannot use name of an existing column for indicator column\")\n\n        left = left.copy()\n        right = right.copy()\n\n        left['_left_indicator'] = 1\n        left['_left_indicator'] = left['_left_indicator'].astype('int8')\n\n        right['_right_indicator'] = 2\n        right['_right_indicator'] = right['_right_indicator'].astype('int8')\n\n        return left, right\n\n    def _indicator_post_merge(self, result):\n\n        result['_left_indicator'] = result['_left_indicator'].fillna(0)\n        result['_right_indicator'] = result['_right_indicator'].fillna(0)\n\n        result[self.indicator_name] = Categorical((result['_left_indicator'] +\n                                                   result['_right_indicator']),\n                                                  categories=[1, 2, 3])\n        result[self.indicator_name] = (\n            result[self.indicator_name]\n            .cat.rename_categories(['left_only', 'right_only', 'both']))\n\n        result = result.drop(labels=['_left_indicator', '_right_indicator'],\n                             axis=1)\n        return result\n\n    def _maybe_restore_index_levels(self, result):\n        \"\"\"\n        Restore index levels specified as `on` parameters\n\n        Here we check for cases where `self.left_on` and `self.right_on` pairs\n        each reference an index level in their respective DataFrames. The\n        joined columns corresponding to these pairs are then restored to the\n        index of `result`.\n\n        **Note:** This method has side effects. It modifies `result` in-place\n\n        Parameters\n        ----------\n        result: DataFrame\n            merge result\n\n        Returns\n        -------\n        None\n        \"\"\"\n        names_to_restore = []\n        for name, left_key, right_key in zip(self.join_names,\n                                             self.left_on,\n                                             self.right_on):\n            if (self.orig_left._is_level_reference(left_key) and\n                    self.orig_right._is_level_reference(right_key) and\n                    name not in result.index.names):\n\n                names_to_restore.append(name)\n\n        if names_to_restore:\n            result.set_index(names_to_restore, inplace=True)\n\n    def _maybe_add_join_keys(self, result, left_indexer, right_indexer):\n\n        left_has_missing = None\n        right_has_missing = None\n\n        keys = zip(self.join_names, self.left_on, self.right_on)\n        for i, (name, lname, rname) in enumerate(keys):\n            if not _should_fill(lname, rname):\n                continue\n\n            take_left, take_right = None, None\n\n            if name in result:\n\n                if left_indexer is not None and right_indexer is not None:\n                    if name in self.left:\n\n                        if left_has_missing is None:\n                            left_has_missing = (left_indexer == -1).any()\n\n                        if left_has_missing:\n                            take_right = self.right_join_keys[i]\n\n                            if not is_dtype_equal(result[name].dtype,\n                                                  self.left[name].dtype):\n                                take_left = self.left[name]._values\n\n                    elif name in self.right:\n\n                        if right_has_missing is None:\n                            right_has_missing = (right_indexer == -1).any()\n\n                        if right_has_missing:\n                            take_left = self.left_join_keys[i]\n\n                            if not is_dtype_equal(result[name].dtype,\n                                                  self.right[name].dtype):\n                                take_right = self.right[name]._values\n\n            elif left_indexer is not None \\\n                    and isinstance(self.left_join_keys[i], np.ndarray):\n\n                take_left = self.left_join_keys[i]\n                take_right = self.right_join_keys[i]\n\n            if take_left is not None or take_right is not None:\n\n                if take_left is None:\n                    lvals = result[name]._values\n                else:\n                    lfill = na_value_for_dtype(take_left.dtype)\n                    lvals = algos.take_1d(take_left, left_indexer,\n                                          fill_value=lfill)\n\n                if take_right is None:\n                    rvals = result[name]._values\n                else:\n                    rfill = na_value_for_dtype(take_right.dtype)\n                    rvals = algos.take_1d(take_right, right_indexer,\n                                          fill_value=rfill)\n\n                # if we have an all missing left_indexer\n                # make sure to just use the right values\n                mask = left_indexer == -1\n                if mask.all():\n                    key_col = rvals\n                else:\n                    key_col = Index(lvals).where(~mask, rvals)\n\n                if result._is_label_reference(name):\n                    result[name] = key_col\n                elif result._is_level_reference(name):\n                    if isinstance(result.index, MultiIndex):\n                        idx_list = [result.index.get_level_values(level_name)\n                                    if level_name != name else key_col\n                                    for level_name in result.index.names]\n\n                        result.set_index(idx_list, inplace=True)\n                    else:\n                        result.index = Index(key_col, name=name)\n                else:\n                    result.insert(i, name or 'key_{i}'.format(i=i), key_col)\n\n    def _get_join_indexers(self):\n        \"\"\" return the join indexers \"\"\"\n        return _get_join_indexers(self.left_join_keys,\n                                  self.right_join_keys,\n                                  sort=self.sort,\n                                  how=self.how)\n\n    def _get_join_info(self):\n        left_ax = self.left._data.axes[self.axis]\n        right_ax = self.right._data.axes[self.axis]\n\n        if self.left_index and self.right_index and self.how != 'asof':\n            join_index, left_indexer, right_indexer = \\\n                left_ax.join(right_ax, how=self.how, return_indexers=True,\n                             sort=self.sort)\n        elif self.right_index and self.how == 'left':\n            join_index, left_indexer, right_indexer = \\\n                _left_join_on_index(left_ax, right_ax, self.left_join_keys,\n                                    sort=self.sort)\n\n        elif self.left_index and self.how == 'right':\n            join_index, right_indexer, left_indexer = \\\n                _left_join_on_index(right_ax, left_ax, self.right_join_keys,\n                                    sort=self.sort)\n        else:\n            (left_indexer,\n             right_indexer) = self._get_join_indexers()\n\n            if self.right_index:\n                if len(self.left) > 0:\n                    join_index = self.left.index.take(left_indexer)\n                else:\n                    join_index = self.right.index.take(right_indexer)\n                    left_indexer = np.array([-1] * len(join_index))\n            elif self.left_index:\n                if len(self.right) > 0:\n                    join_index = self.right.index.take(right_indexer)\n                else:\n                    join_index = self.left.index.take(left_indexer)\n                    right_indexer = np.array([-1] * len(join_index))\n            else:\n                join_index = Index(np.arange(len(left_indexer)))\n\n        if len(join_index) == 0:\n            join_index = join_index.astype(object)\n        return join_index, left_indexer, right_indexer\n\n    def _get_merge_keys(self):\n        \"\"\"\n        Note: has side effects (copy/delete key columns)\n\n        Parameters\n        ----------\n        left\n        right\n        on\n\n        Returns\n        -------\n        left_keys, right_keys\n        \"\"\"\n        left_keys = []\n        right_keys = []\n        join_names = []\n        right_drop = []\n        left_drop = []\n        left, right = self.left, self.right\n\n        is_lkey = lambda x: isinstance(\n            x, (np.ndarray, Series)) and len(x) == len(left)\n        is_rkey = lambda x: isinstance(\n            x, (np.ndarray, Series)) and len(x) == len(right)\n\n        # Note that pd.merge_asof() has separate 'on' and 'by' parameters. A\n        # user could, for example, request 'left_index' and 'left_by'. In a\n        # regular pd.merge(), users cannot specify both 'left_index' and\n        # 'left_on'. (Instead, users have a MultiIndex). That means the\n        # self.left_on in this function is always empty in a pd.merge(), but\n        # a pd.merge_asof(left_index=True, left_by=...) will result in a\n        # self.left_on array with a None in the middle of it. This requires\n        # a work-around as designated in the code below.\n        # See _validate_specification() for where this happens.\n\n        # ugh, spaghetti re #733\n        if _any(self.left_on) and _any(self.right_on):\n            for lk, rk in zip(self.left_on, self.right_on):\n                if is_lkey(lk):\n                    left_keys.append(lk)\n                    if is_rkey(rk):\n                        right_keys.append(rk)\n                        join_names.append(None)  # what to do?\n                    else:\n                        if rk is not None:\n                            right_keys.append(\n                                right._get_label_or_level_values(rk))\n                            join_names.append(rk)\n                        else:\n                            # work-around for merge_asof(right_index=True)\n                            right_keys.append(right.index)\n                            join_names.append(right.index.name)\n                else:\n                    if not is_rkey(rk):\n                        if rk is not None:\n                            right_keys.append(\n                                right._get_label_or_level_values(rk))\n                        else:\n                            # work-around for merge_asof(right_index=True)\n                            right_keys.append(right.index)\n                        if lk is not None and lk == rk:\n                            # avoid key upcast in corner case (length-0)\n                            if len(left) > 0:\n                                right_drop.append(rk)\n                            else:\n                                left_drop.append(lk)\n                    else:\n                        right_keys.append(rk)\n                    if lk is not None:\n                        left_keys.append(left._get_label_or_level_values(lk))\n                        join_names.append(lk)\n                    else:\n                        # work-around for merge_asof(left_index=True)\n                        left_keys.append(left.index)\n                        join_names.append(left.index.name)\n        elif _any(self.left_on):\n            for k in self.left_on:\n                if is_lkey(k):\n                    left_keys.append(k)\n                    join_names.append(None)\n                else:\n                    left_keys.append(left._get_label_or_level_values(k))\n                    join_names.append(k)\n            if isinstance(self.right.index, MultiIndex):\n                right_keys = [lev._values.take(lab)\n                              for lev, lab in zip(self.right.index.levels,\n                                                  self.right.index.labels)]\n            else:\n                right_keys = [self.right.index.values]\n        elif _any(self.right_on):\n            for k in self.right_on:\n                if is_rkey(k):\n                    right_keys.append(k)\n                    join_names.append(None)\n                else:\n                    right_keys.append(right._get_label_or_level_values(k))\n                    join_names.append(k)\n            if isinstance(self.left.index, MultiIndex):\n                left_keys = [lev._values.take(lab)\n                             for lev, lab in zip(self.left.index.levels,\n                                                 self.left.index.labels)]\n            else:\n                left_keys = [self.left.index.values]\n\n        if left_drop:\n            self.left = self.left._drop_labels_or_levels(left_drop)\n\n        if right_drop:\n            self.right = self.right._drop_labels_or_levels(right_drop)\n\n        return left_keys, right_keys, join_names\n\n    def _maybe_coerce_merge_keys(self):\n        # we have valid mergees but we may have to further\n        # coerce these if they are originally incompatible types\n        #\n        # for example if these are categorical, but are not dtype_equal\n        # or if we have object and integer dtypes\n\n        for lk, rk, name in zip(self.left_join_keys,\n                                self.right_join_keys,\n                                self.join_names):\n            if (len(lk) and not len(rk)) or (not len(lk) and len(rk)):\n                continue\n\n            lk_is_cat = is_categorical_dtype(lk)\n            rk_is_cat = is_categorical_dtype(rk)\n\n            # if either left or right is a categorical\n            # then the must match exactly in categories & ordered\n            if lk_is_cat and rk_is_cat:\n                if lk.is_dtype_equal(rk):\n                    continue\n\n            elif lk_is_cat or rk_is_cat:\n                pass\n\n            elif is_dtype_equal(lk.dtype, rk.dtype):\n                continue\n\n            # if we are numeric, then allow differing\n            # kinds to proceed, eg. int64 and int8, int and float\n            # further if we are object, but we infer to\n            # the same, then proceed\n            if is_numeric_dtype(lk) and is_numeric_dtype(rk):\n                if lk.dtype.kind == rk.dtype.kind:\n                    pass\n\n                # check whether ints and floats\n                elif is_integer_dtype(rk) and is_float_dtype(lk):\n                    if not (lk == lk.astype(rk.dtype)).all():\n                        warnings.warn('You are merging on int and float '\n                                      'columns where the float values '\n                                      'are not equal to their int '\n                                      'representation', UserWarning)\n\n                elif is_float_dtype(rk) and is_integer_dtype(lk):\n                    if not (rk == rk.astype(lk.dtype)).all():\n                        warnings.warn('You are merging on int and float '\n                                      'columns where the float values '\n                                      'are not equal to their int '\n                                      'representation', UserWarning)\n\n                # let's infer and see if we are ok\n                elif lib.infer_dtype(lk) == lib.infer_dtype(rk):\n                    pass\n\n            # Check if we are trying to merge on obviously\n            # incompatible dtypes GH 9780\n            elif is_numeric_dtype(lk) and not is_numeric_dtype(rk):\n                msg = (\"You are trying to merge on {lk_dtype} and \"\n                       \"{rk_dtype} columns. If you wish to proceed \"\n                       \"you should use pd.concat\".format(lk_dtype=lk.dtype,\n                                                         rk_dtype=rk.dtype))\n                raise ValueError(msg)\n            elif not is_numeric_dtype(lk) and is_numeric_dtype(rk):\n                msg = (\"You are trying to merge on {lk_dtype} and \"\n                       \"{rk_dtype} columns. If you wish to proceed \"\n                       \"you should use pd.concat\".format(lk_dtype=lk.dtype,\n                                                         rk_dtype=rk.dtype))\n                raise ValueError(msg)\n            elif is_datetimelike(lk) and not is_datetimelike(rk):\n                msg = (\"You are trying to merge on {lk_dtype} and \"\n                       \"{rk_dtype} columns. If you wish to proceed \"\n                       \"you should use pd.concat\".format(lk_dtype=lk.dtype,\n                                                         rk_dtype=rk.dtype))\n                raise ValueError(msg)\n            elif not is_datetimelike(lk) and is_datetimelike(rk):\n                msg = (\"You are trying to merge on {lk_dtype} and \"\n                       \"{rk_dtype} columns. If you wish to proceed \"\n                       \"you should use pd.concat\".format(lk_dtype=lk.dtype,\n                                                         rk_dtype=rk.dtype))\n                raise ValueError(msg)\n\n            # Houston, we have a problem!\n            # let's coerce to object if the dtypes aren't\n            # categorical, otherwise coerce to the category\n            # dtype. If we coerced categories to object,\n            # then we would lose type information on some\n            # columns, and end up trying to merge\n            # incompatible dtypes. See GH 16900.\n            else:\n                if name in self.left.columns:\n                    typ = lk.categories.dtype if lk_is_cat else object\n                    self.left = self.left.assign(\n                        **{name: self.left[name].astype(typ)})\n                if name in self.right.columns:\n                    typ = rk.categories.dtype if rk_is_cat else object\n                    self.right = self.right.assign(\n                        **{name: self.right[name].astype(typ)})\n\n    def _validate_specification(self):\n        # Hm, any way to make this logic less complicated??\n        if self.on is None and self.left_on is None and self.right_on is None:\n\n            if self.left_index and self.right_index:\n                self.left_on, self.right_on = (), ()\n            elif self.left_index:\n                if self.right_on is None:\n                    raise MergeError('Must pass right_on or right_index=True')\n            elif self.right_index:\n                if self.left_on is None:\n                    raise MergeError('Must pass left_on or left_index=True')\n            else:\n                # use the common columns\n                common_cols = self.left.columns.intersection(\n                    self.right.columns)\n                if len(common_cols) == 0:\n                    raise MergeError('No common columns to perform merge on')\n                if not common_cols.is_unique:\n                    raise MergeError(\"Data columns not unique: {common!r}\"\n                                     .format(common=common_cols))\n                self.left_on = self.right_on = common_cols\n        elif self.on is not None:\n            if self.left_on is not None or self.right_on is not None:\n                raise MergeError('Can only pass argument \"on\" OR \"left_on\" '\n                                 'and \"right_on\", not a combination of both.')\n            self.left_on = self.right_on = self.on\n        elif self.left_on is not None:\n            n = len(self.left_on)\n            if self.right_index:\n                if len(self.left_on) != self.right.index.nlevels:\n                    raise ValueError('len(left_on) must equal the number '\n                                     'of levels in the index of \"right\"')\n                self.right_on = [None] * n\n        elif self.right_on is not None:\n            n = len(self.right_on)\n            if self.left_index:\n                if len(self.right_on) != self.left.index.nlevels:\n                    raise ValueError('len(right_on) must equal the number '\n                                     'of levels in the index of \"left\"')\n                self.left_on = [None] * n\n        if len(self.right_on) != len(self.left_on):\n            raise ValueError(\"len(right_on) must equal len(left_on)\")\n\n    def _validate(self, validate):\n\n        # Check uniqueness of each\n        if self.left_index:\n            left_unique = self.orig_left.index.is_unique\n        else:\n            left_unique = MultiIndex.from_arrays(self.left_join_keys\n                                                 ).is_unique\n\n        if self.right_index:\n            right_unique = self.orig_right.index.is_unique\n        else:\n            right_unique = MultiIndex.from_arrays(self.right_join_keys\n                                                  ).is_unique\n\n        # Check data integrity\n        if validate in [\"one_to_one\", \"1:1\"]:\n            if not left_unique and not right_unique:\n                raise MergeError(\"Merge keys are not unique in either left\"\n                                 \" or right dataset; not a one-to-one merge\")\n            elif not left_unique:\n                raise MergeError(\"Merge keys are not unique in left dataset;\"\n                                 \" not a one-to-one merge\")\n            elif not right_unique:\n                raise MergeError(\"Merge keys are not unique in right dataset;\"\n                                 \" not a one-to-one merge\")\n\n        elif validate in [\"one_to_many\", \"1:m\"]:\n            if not left_unique:\n                raise MergeError(\"Merge keys are not unique in left dataset;\"\n                                 \"not a one-to-many merge\")\n\n        elif validate in [\"many_to_one\", \"m:1\"]:\n            if not right_unique:\n                raise MergeError(\"Merge keys are not unique in right dataset;\"\n                                 \" not a many-to-one merge\")\n\n        elif validate in ['many_to_many', 'm:m']:\n            pass\n\n        else:\n            raise ValueError(\"Not a valid argument for validate\")\n\n\ndef _get_join_indexers(left_keys, right_keys, sort=False, how='inner',\n                       **kwargs):\n    \"\"\"\n\n    Parameters\n    ----------\n    left_keys: ndarray, Index, Series\n    right_keys: ndarray, Index, Series\n    sort: boolean, default False\n    how: string {'inner', 'outer', 'left', 'right'}, default 'inner'\n\n    Returns\n    -------\n    tuple of (left_indexer, right_indexer)\n        indexers into the left_keys, right_keys\n\n    \"\"\"\n    from functools import partial\n\n    assert len(left_keys) == len(right_keys), \\\n        'left_key and right_keys must be the same length'\n\n    # bind `sort` arg. of _factorize_keys\n    fkeys = partial(_factorize_keys, sort=sort)\n\n    # get left & right join labels and num. of levels at each location\n    llab, rlab, shape = map(list, zip(* map(fkeys, left_keys, right_keys)))\n\n    # get flat i8 keys from label lists\n    lkey, rkey = _get_join_keys(llab, rlab, shape, sort)\n\n    # factorize keys to a dense i8 space\n    # `count` is the num. of unique keys\n    # set(lkey) | set(rkey) == range(count)\n    lkey, rkey, count = fkeys(lkey, rkey)\n\n    # preserve left frame order if how == 'left' and sort == False\n    kwargs = copy.copy(kwargs)\n    if how == 'left':\n        kwargs['sort'] = sort\n    join_func = _join_functions[how]\n\n    return join_func(lkey, rkey, count, **kwargs)\n\n\nclass _OrderedMerge(_MergeOperation):\n    _merge_type = 'ordered_merge'\n\n    def __init__(self, left, right, on=None, left_on=None, right_on=None,\n                 left_index=False, right_index=False, axis=1,\n                 suffixes=('_x', '_y'), copy=True,\n                 fill_method=None, how='outer'):\n\n        self.fill_method = fill_method\n        _MergeOperation.__init__(self, left, right, on=on, left_on=left_on,\n                                 left_index=left_index,\n                                 right_index=right_index,\n                                 right_on=right_on, axis=axis,\n                                 how=how, suffixes=suffixes,\n                                 sort=True  # factorize sorts\n                                 )\n\n    def get_result(self):\n        join_index, left_indexer, right_indexer = self._get_join_info()\n\n        # this is a bit kludgy\n        ldata, rdata = self.left._data, self.right._data\n        lsuf, rsuf = self.suffixes\n\n        llabels, rlabels = items_overlap_with_suffix(ldata.items, lsuf,\n                                                     rdata.items, rsuf)\n\n        if self.fill_method == 'ffill':\n            left_join_indexer = libjoin.ffill_indexer(left_indexer)\n            right_join_indexer = libjoin.ffill_indexer(right_indexer)\n        else:\n            left_join_indexer = left_indexer\n            right_join_indexer = right_indexer\n\n        lindexers = {\n            1: left_join_indexer} if left_join_indexer is not None else {}\n        rindexers = {\n            1: right_join_indexer} if right_join_indexer is not None else {}\n\n        result_data = concatenate_block_managers(\n            [(ldata, lindexers), (rdata, rindexers)],\n            axes=[llabels.append(rlabels), join_index],\n            concat_axis=0, copy=self.copy)\n\n        typ = self.left._constructor\n        result = typ(result_data).__finalize__(self, method=self._merge_type)\n\n        self._maybe_add_join_keys(result, left_indexer, right_indexer)\n\n        return result\n\n\ndef _asof_function(direction, on_type):\n    name = 'asof_join_{dir}_{on}'.format(dir=direction, on=on_type)\n    return getattr(libjoin, name, None)\n\n\ndef _asof_by_function(direction, on_type, by_type):\n    name = 'asof_join_{dir}_{on}_by_{by}'.format(\n        dir=direction, on=on_type, by=by_type)\n    return getattr(libjoin, name, None)\n\n\n_type_casters = {\n    'int64_t': _ensure_int64,\n    'double': _ensure_float64,\n    'object': _ensure_object,\n}\n\n_cython_types = {\n    'uint8': 'uint8_t',\n    'uint32': 'uint32_t',\n    'uint16': 'uint16_t',\n    'uint64': 'uint64_t',\n    'int8': 'int8_t',\n    'int32': 'int32_t',\n    'int16': 'int16_t',\n    'int64': 'int64_t',\n    'float16': 'error',\n    'float32': 'float',\n    'float64': 'double',\n}\n\n\ndef _get_cython_type(dtype):\n    \"\"\" Given a dtype, return a C name like 'int64_t' or 'double' \"\"\"\n    type_name = _get_dtype(dtype).name\n    ctype = _cython_types.get(type_name, 'object')\n    if ctype == 'error':\n        raise MergeError('unsupported type: {type}'.format(type=type_name))\n    return ctype\n\n\ndef _get_cython_type_upcast(dtype):\n    \"\"\" Upcast a dtype to 'int64_t', 'double', or 'object' \"\"\"\n    if is_integer_dtype(dtype):\n        return 'int64_t'\n    elif is_float_dtype(dtype):\n        return 'double'\n    else:\n        return 'object'\n\n\nclass _AsOfMerge(_OrderedMerge):\n    _merge_type = 'asof_merge'\n\n    def __init__(self, left, right, on=None, left_on=None, right_on=None,\n                 left_index=False, right_index=False,\n                 by=None, left_by=None, right_by=None,\n                 axis=1, suffixes=('_x', '_y'), copy=True,\n                 fill_method=None,\n                 how='asof', tolerance=None,\n                 allow_exact_matches=True,\n                 direction='backward'):\n\n        self.by = by\n        self.left_by = left_by\n        self.right_by = right_by\n        self.tolerance = tolerance\n        self.allow_exact_matches = allow_exact_matches\n        self.direction = direction\n\n        _OrderedMerge.__init__(self, left, right, on=on, left_on=left_on,\n                               right_on=right_on, left_index=left_index,\n                               right_index=right_index, axis=axis,\n                               how=how, suffixes=suffixes,\n                               fill_method=fill_method)\n\n    def _validate_specification(self):\n        super(_AsOfMerge, self)._validate_specification()\n\n        # we only allow on to be a single item for on\n        if len(self.left_on) != 1 and not self.left_index:\n            raise MergeError(\"can only asof on a key for left\")\n\n        if len(self.right_on) != 1 and not self.right_index:\n            raise MergeError(\"can only asof on a key for right\")\n\n        if self.left_index and isinstance(self.left.index, MultiIndex):\n            raise MergeError(\"left can only have one index\")\n\n        if self.right_index and isinstance(self.right.index, MultiIndex):\n            raise MergeError(\"right can only have one index\")\n\n        # set 'by' columns\n        if self.by is not None:\n            if self.left_by is not None or self.right_by is not None:\n                raise MergeError('Can only pass by OR left_by '\n                                 'and right_by')\n            self.left_by = self.right_by = self.by\n        if self.left_by is None and self.right_by is not None:\n            raise MergeError('missing left_by')\n        if self.left_by is not None and self.right_by is None:\n            raise MergeError('missing right_by')\n\n        # add 'by' to our key-list so we can have it in the\n        # output as a key\n        if self.left_by is not None:\n            if not is_list_like(self.left_by):\n                self.left_by = [self.left_by]\n            if not is_list_like(self.right_by):\n                self.right_by = [self.right_by]\n\n            if len(self.left_by) != len(self.right_by):\n                raise MergeError('left_by and right_by must be same length')\n\n            self.left_on = self.left_by + list(self.left_on)\n            self.right_on = self.right_by + list(self.right_on)\n\n        # check 'direction' is valid\n        if self.direction not in ['backward', 'forward', 'nearest']:\n            raise MergeError('direction invalid: {direction}'\n                             .format(direction=self.direction))\n\n    @property\n    def _asof_key(self):\n        \"\"\" This is our asof key, the 'on' \"\"\"\n        return self.left_on[-1]\n\n    def _get_merge_keys(self):\n\n        # note this function has side effects\n        (left_join_keys,\n         right_join_keys,\n         join_names) = super(_AsOfMerge, self)._get_merge_keys()\n\n        # validate index types are the same\n        for i, (lk, rk) in enumerate(zip(left_join_keys, right_join_keys)):\n            if not is_dtype_equal(lk.dtype, rk.dtype):\n                raise MergeError(\"incompatible merge keys [{i}] {lkdtype} and \"\n                                 \"{rkdtype}, must be the same type\"\n                                 .format(i=i, lkdtype=lk.dtype,\n                                         rkdtype=rk.dtype))\n\n        # validate tolerance; must be a Timedelta if we have a DTI\n        if self.tolerance is not None:\n\n            if self.left_index:\n                lt = self.left.index\n            else:\n                lt = left_join_keys[-1]\n\n            msg = (\"incompatible tolerance {tolerance}, must be compat \"\n                   \"with type {lkdtype}\".format(\n                       tolerance=type(self.tolerance),\n                       lkdtype=lt.dtype))\n\n            if is_datetime64_dtype(lt) or is_datetime64tz_dtype(lt):\n                if not isinstance(self.tolerance, Timedelta):\n                    raise MergeError(msg)\n                if self.tolerance < Timedelta(0):\n                    raise MergeError(\"tolerance must be positive\")\n\n            elif is_int64_dtype(lt):\n                if not is_integer(self.tolerance):\n                    raise MergeError(msg)\n                if self.tolerance < 0:\n                    raise MergeError(\"tolerance must be positive\")\n\n            else:\n                raise MergeError(\"key must be integer or timestamp\")\n\n        # validate allow_exact_matches\n        if not is_bool(self.allow_exact_matches):\n            msg = \"allow_exact_matches must be boolean, passed {passed}\"\n            raise MergeError(msg.format(passed=self.allow_exact_matches))\n\n        return left_join_keys, right_join_keys, join_names\n\n    def _get_join_indexers(self):\n        \"\"\" return the join indexers \"\"\"\n\n        def flip(xs):\n            \"\"\" unlike np.transpose, this returns an array of tuples \"\"\"\n            labels = list(string.ascii_lowercase[:len(xs)])\n            dtypes = [x.dtype for x in xs]\n            labeled_dtypes = list(zip(labels, dtypes))\n            return np.array(lzip(*xs), labeled_dtypes)\n\n        # values to compare\n        left_values = (self.left.index.values if self.left_index else\n                       self.left_join_keys[-1])\n        right_values = (self.right.index.values if self.right_index else\n                        self.right_join_keys[-1])\n        tolerance = self.tolerance\n\n        # we required sortedness in the join keys\n        msg = \"{side} keys must be sorted\"\n        if not Index(left_values).is_monotonic:\n            raise ValueError(msg.format(side='left'))\n        if not Index(right_values).is_monotonic:\n            raise ValueError(msg.format(side='right'))\n\n        # initial type conversion as needed\n        if needs_i8_conversion(left_values):\n            left_values = left_values.view('i8')\n            right_values = right_values.view('i8')\n            if tolerance is not None:\n                tolerance = tolerance.value\n\n        # a \"by\" parameter requires special handling\n        if self.left_by is not None:\n            # remove 'on' parameter from values if one existed\n            if self.left_index and self.right_index:\n                left_by_values = self.left_join_keys\n                right_by_values = self.right_join_keys\n            else:\n                left_by_values = self.left_join_keys[0:-1]\n                right_by_values = self.right_join_keys[0:-1]\n\n            # get tuple representation of values if more than one\n            if len(left_by_values) == 1:\n                left_by_values = left_by_values[0]\n                right_by_values = right_by_values[0]\n            else:\n                left_by_values = flip(left_by_values)\n                right_by_values = flip(right_by_values)\n\n            # upcast 'by' parameter because HashTable is limited\n            by_type = _get_cython_type_upcast(left_by_values.dtype)\n            by_type_caster = _type_casters[by_type]\n            left_by_values = by_type_caster(left_by_values)\n            right_by_values = by_type_caster(right_by_values)\n\n            # choose appropriate function by type\n            on_type = _get_cython_type(left_values.dtype)\n            func = _asof_by_function(self.direction, on_type, by_type)\n            return func(left_values,\n                        right_values,\n                        left_by_values,\n                        right_by_values,\n                        self.allow_exact_matches,\n                        tolerance)\n        else:\n            # choose appropriate function by type\n            on_type = _get_cython_type(left_values.dtype)\n            func = _asof_function(self.direction, on_type)\n            return func(left_values,\n                        right_values,\n                        self.allow_exact_matches,\n                        tolerance)\n\n\ndef _get_multiindex_indexer(join_keys, index, sort):\n    from functools import partial\n\n    # bind `sort` argument\n    fkeys = partial(_factorize_keys, sort=sort)\n\n    # left & right join labels and num. of levels at each location\n    rlab, llab, shape = map(list, zip(* map(fkeys, index.levels, join_keys)))\n    if sort:\n        rlab = list(map(np.take, rlab, index.labels))\n    else:\n        i8copy = lambda a: a.astype('i8', subok=False, copy=True)\n        rlab = list(map(i8copy, index.labels))\n\n    # fix right labels if there were any nulls\n    for i in range(len(join_keys)):\n        mask = index.labels[i] == -1\n        if mask.any():\n            # check if there already was any nulls at this location\n            # if there was, it is factorized to `shape[i] - 1`\n            a = join_keys[i][llab[i] == shape[i] - 1]\n            if a.size == 0 or not a[0] != a[0]:\n                shape[i] += 1\n\n            rlab[i][mask] = shape[i] - 1\n\n    # get flat i8 join keys\n    lkey, rkey = _get_join_keys(llab, rlab, shape, sort)\n\n    # factorize keys to a dense i8 space\n    lkey, rkey, count = fkeys(lkey, rkey)\n\n    return libjoin.left_outer_join(lkey, rkey, count, sort=sort)\n\n\ndef _get_single_indexer(join_key, index, sort=False):\n    left_key, right_key, count = _factorize_keys(join_key, index, sort=sort)\n\n    left_indexer, right_indexer = libjoin.left_outer_join(\n        _ensure_int64(left_key),\n        _ensure_int64(right_key),\n        count, sort=sort)\n\n    return left_indexer, right_indexer\n\n\ndef _left_join_on_index(left_ax, right_ax, join_keys, sort=False):\n    if len(join_keys) > 1:\n        if not ((isinstance(right_ax, MultiIndex) and\n                 len(join_keys) == right_ax.nlevels)):\n            raise AssertionError(\"If more than one join key is given then \"\n                                 \"'right_ax' must be a MultiIndex and the \"\n                                 \"number of join keys must be the number of \"\n                                 \"levels in right_ax\")\n\n        left_indexer, right_indexer = \\\n            _get_multiindex_indexer(join_keys, right_ax, sort=sort)\n    else:\n        jkey = join_keys[0]\n\n        left_indexer, right_indexer = \\\n            _get_single_indexer(jkey, right_ax, sort=sort)\n\n    if sort or len(left_ax) != len(left_indexer):\n        # if asked to sort or there are 1-to-many matches\n        join_index = left_ax.take(left_indexer)\n        return join_index, left_indexer, right_indexer\n\n    # left frame preserves order & length of its index\n    return left_ax, None, right_indexer\n\n\ndef _right_outer_join(x, y, max_groups):\n    right_indexer, left_indexer = libjoin.left_outer_join(y, x, max_groups)\n    return left_indexer, right_indexer\n\n\n_join_functions = {\n    'inner': libjoin.inner_join,\n    'left': libjoin.left_outer_join,\n    'right': _right_outer_join,\n    'outer': libjoin.full_outer_join,\n}\n\n\ndef _factorize_keys(lk, rk, sort=True):\n    if is_datetime64tz_dtype(lk) and is_datetime64tz_dtype(rk):\n        lk = lk.values\n        rk = rk.values\n\n    # if we exactly match in categories, allow us to factorize on codes\n    if (is_categorical_dtype(lk) and\n            is_categorical_dtype(rk) and\n            lk.is_dtype_equal(rk)):\n        klass = libhashtable.Int64Factorizer\n        lk = _ensure_int64(lk.codes)\n        rk = _ensure_int64(rk.codes)\n    elif is_int_or_datetime_dtype(lk) and is_int_or_datetime_dtype(rk):\n        klass = libhashtable.Int64Factorizer\n        lk = _ensure_int64(com._values_from_object(lk))\n        rk = _ensure_int64(com._values_from_object(rk))\n    else:\n        klass = libhashtable.Factorizer\n        lk = _ensure_object(lk)\n        rk = _ensure_object(rk)\n\n    rizer = klass(max(len(lk), len(rk)))\n\n    llab = rizer.factorize(lk)\n    rlab = rizer.factorize(rk)\n\n    count = rizer.get_count()\n\n    if sort:\n        uniques = rizer.uniques.to_array()\n        llab, rlab = _sort_labels(uniques, llab, rlab)\n\n    # NA group\n    lmask = llab == -1\n    lany = lmask.any()\n    rmask = rlab == -1\n    rany = rmask.any()\n\n    if lany or rany:\n        if lany:\n            np.putmask(llab, lmask, count)\n        if rany:\n            np.putmask(rlab, rmask, count)\n        count += 1\n\n    return llab, rlab, count\n\n\ndef _sort_labels(uniques, left, right):\n    if not isinstance(uniques, np.ndarray):\n        # tuplesafe\n        uniques = Index(uniques).values\n\n    llength = len(left)\n    labels = np.concatenate([left, right])\n\n    _, new_labels = sorting.safe_sort(uniques, labels, na_sentinel=-1)\n    new_labels = _ensure_int64(new_labels)\n    new_left, new_right = new_labels[:llength], new_labels[llength:]\n\n    return new_left, new_right\n\n\ndef _get_join_keys(llab, rlab, shape, sort):\n\n    # how many levels can be done without overflow\n    pred = lambda i: not is_int64_overflow_possible(shape[:i])\n    nlev = next(filter(pred, range(len(shape), 0, -1)))\n\n    # get keys for the first `nlev` levels\n    stride = np.prod(shape[1:nlev], dtype='i8')\n    lkey = stride * llab[0].astype('i8', subok=False, copy=False)\n    rkey = stride * rlab[0].astype('i8', subok=False, copy=False)\n\n    for i in range(1, nlev):\n        with np.errstate(divide='ignore'):\n            stride //= shape[i]\n        lkey += llab[i] * stride\n        rkey += rlab[i] * stride\n\n    if nlev == len(shape):  # all done!\n        return lkey, rkey\n\n    # densify current keys to avoid overflow\n    lkey, rkey, count = _factorize_keys(lkey, rkey, sort=sort)\n\n    llab = [lkey] + llab[nlev:]\n    rlab = [rkey] + rlab[nlev:]\n    shape = [count] + shape[nlev:]\n\n    return _get_join_keys(llab, rlab, shape, sort)\n\n\ndef _should_fill(lname, rname):\n    if (not isinstance(lname, compat.string_types) or\n            not isinstance(rname, compat.string_types)):\n        return True\n    return lname == rname\n\n\ndef _any(x):\n    return x is not None and com._any_not_none(*x)\n"
    },
    {
      "filename": "pandas/tests/reshape/merge/test_merge.py",
      "content": "# pylint: disable=E1103\n\nimport pytest\nfrom datetime import datetime, date\nfrom numpy.random import randn\nfrom numpy import nan\nimport numpy as np\nimport random\nimport re\n\nimport pandas as pd\nfrom pandas.compat import lrange, lzip\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge, MergeError\nfrom pandas.util.testing import assert_frame_equal, assert_series_equal\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.common import (\n    is_categorical_dtype,\n    is_object_dtype,\n)\nfrom pandas import DataFrame, Index, MultiIndex, Series, Categorical\nimport pandas.util.testing as tm\nfrom pandas.api.types import CategoricalDtype as CDT\n\n\nN = 50\nNGROUPS = 8\n\n\ndef get_test_data(ngroups=NGROUPS, n=N):\n    unique_groups = lrange(ngroups)\n    arr = np.asarray(np.tile(unique_groups, n // ngroups))\n\n    if len(arr) < n:\n        arr = np.asarray(list(arr) + unique_groups[:n - len(arr)])\n\n    random.shuffle(arr)\n    return arr\n\n\nclass TestMerge(object):\n\n    def setup_method(self, method):\n        # aggregate multiple columns\n        self.df = DataFrame({'key1': get_test_data(),\n                             'key2': get_test_data(),\n                             'data1': np.random.randn(N),\n                             'data2': np.random.randn(N)})\n\n        # exclude a couple keys for fun\n        self.df = self.df[self.df['key2'] > 1]\n\n        self.df2 = DataFrame({'key1': get_test_data(n=N // 5),\n                              'key2': get_test_data(ngroups=NGROUPS // 2,\n                                                    n=N // 5),\n                              'value': np.random.randn(N // 5)})\n\n        self.left = DataFrame({'key': ['a', 'b', 'c', 'd', 'e', 'e', 'a'],\n                               'v1': np.random.randn(7)})\n        self.right = DataFrame({'v2': np.random.randn(4)},\n                               index=['d', 'b', 'c', 'a'])\n\n    def test_merge_inner_join_empty(self):\n        # GH 15328\n        df_empty = pd.DataFrame()\n        df_a = pd.DataFrame({'a': [1, 2]}, index=[0, 1], dtype='int64')\n        result = pd.merge(df_empty, df_a, left_index=True, right_index=True)\n        expected = pd.DataFrame({'a': []}, index=[], dtype='int64')\n        assert_frame_equal(result, expected)\n\n    def test_merge_common(self):\n        joined = merge(self.df, self.df2)\n        exp = merge(self.df, self.df2, on=['key1', 'key2'])\n        tm.assert_frame_equal(joined, exp)\n\n    def test_merge_index_as_on_arg(self):\n        # GH14355\n\n        left = self.df.set_index('key1')\n        right = self.df2.set_index('key1')\n        result = merge(left, right, on='key1')\n        expected = merge(self.df, self.df2, on='key1').set_index('key1')\n        assert_frame_equal(result, expected)\n\n    def test_merge_index_singlekey_right_vs_left(self):\n        left = DataFrame({'key': ['a', 'b', 'c', 'd', 'e', 'e', 'a'],\n                          'v1': np.random.randn(7)})\n        right = DataFrame({'v2': np.random.randn(4)},\n                          index=['d', 'b', 'c', 'a'])\n\n        merged1 = merge(left, right, left_on='key',\n                        right_index=True, how='left', sort=False)\n        merged2 = merge(right, left, right_on='key',\n                        left_index=True, how='right', sort=False)\n        assert_frame_equal(merged1, merged2.loc[:, merged1.columns])\n\n        merged1 = merge(left, right, left_on='key',\n                        right_index=True, how='left', sort=True)\n        merged2 = merge(right, left, right_on='key',\n                        left_index=True, how='right', sort=True)\n        assert_frame_equal(merged1, merged2.loc[:, merged1.columns])\n\n    def test_merge_index_singlekey_inner(self):\n        left = DataFrame({'key': ['a', 'b', 'c', 'd', 'e', 'e', 'a'],\n                          'v1': np.random.randn(7)})\n        right = DataFrame({'v2': np.random.randn(4)},\n                          index=['d', 'b', 'c', 'a'])\n\n        # inner join\n        result = merge(left, right, left_on='key', right_index=True,\n                       how='inner')\n        expected = left.join(right, on='key').loc[result.index]\n        assert_frame_equal(result, expected)\n\n        result = merge(right, left, right_on='key', left_index=True,\n                       how='inner')\n        expected = left.join(right, on='key').loc[result.index]\n        assert_frame_equal(result, expected.loc[:, result.columns])\n\n    def test_merge_misspecified(self):\n        pytest.raises(ValueError, merge, self.left, self.right,\n                      left_index=True)\n        pytest.raises(ValueError, merge, self.left, self.right,\n                      right_index=True)\n\n        pytest.raises(ValueError, merge, self.left, self.left,\n                      left_on='key', on='key')\n\n        pytest.raises(ValueError, merge, self.df, self.df2,\n                      left_on=['key1'], right_on=['key1', 'key2'])\n\n    def test_index_and_on_parameters_confusion(self):\n        pytest.raises(ValueError, merge, self.df, self.df2, how='left',\n                      left_index=False, right_index=['key1', 'key2'])\n        pytest.raises(ValueError, merge, self.df, self.df2, how='left',\n                      left_index=['key1', 'key2'], right_index=False)\n        pytest.raises(ValueError, merge, self.df, self.df2, how='left',\n                      left_index=['key1', 'key2'],\n                      right_index=['key1', 'key2'])\n\n    def test_merge_overlap(self):\n        merged = merge(self.left, self.left, on='key')\n        exp_len = (self.left['key'].value_counts() ** 2).sum()\n        assert len(merged) == exp_len\n        assert 'v1_x' in merged\n        assert 'v1_y' in merged\n\n    def test_merge_different_column_key_names(self):\n        left = DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n                          'value': [1, 2, 3, 4]})\n        right = DataFrame({'rkey': ['foo', 'bar', 'qux', 'foo'],\n                           'value': [5, 6, 7, 8]})\n\n        merged = left.merge(right, left_on='lkey', right_on='rkey',\n                            how='outer', sort=True)\n\n        exp = pd.Series(['bar', 'baz', 'foo', 'foo', 'foo', 'foo', np.nan],\n                        name='lkey')\n        tm.assert_series_equal(merged['lkey'], exp)\n\n        exp = pd.Series(['bar', np.nan, 'foo', 'foo', 'foo', 'foo', 'qux'],\n                        name='rkey')\n        tm.assert_series_equal(merged['rkey'], exp)\n\n        exp = pd.Series([2, 3, 1, 1, 4, 4, np.nan], name='value_x')\n        tm.assert_series_equal(merged['value_x'], exp)\n\n        exp = pd.Series([6, np.nan, 5, 8, 5, 8, 7], name='value_y')\n        tm.assert_series_equal(merged['value_y'], exp)\n\n    def test_merge_copy(self):\n        left = DataFrame({'a': 0, 'b': 1}, index=lrange(10))\n        right = DataFrame({'c': 'foo', 'd': 'bar'}, index=lrange(10))\n\n        merged = merge(left, right, left_index=True,\n                       right_index=True, copy=True)\n\n        merged['a'] = 6\n        assert (left['a'] == 0).all()\n\n        merged['d'] = 'peekaboo'\n        assert (right['d'] == 'bar').all()\n\n    def test_merge_nocopy(self):\n        left = DataFrame({'a': 0, 'b': 1}, index=lrange(10))\n        right = DataFrame({'c': 'foo', 'd': 'bar'}, index=lrange(10))\n\n        merged = merge(left, right, left_index=True,\n                       right_index=True, copy=False)\n\n        merged['a'] = 6\n        assert (left['a'] == 6).all()\n\n        merged['d'] = 'peekaboo'\n        assert (right['d'] == 'peekaboo').all()\n\n    def test_intelligently_handle_join_key(self):\n        # #733, be a bit more 1337 about not returning unconsolidated DataFrame\n\n        left = DataFrame({'key': [1, 1, 2, 2, 3],\n                          'value': lrange(5)}, columns=['value', 'key'])\n        right = DataFrame({'key': [1, 1, 2, 3, 4, 5],\n                           'rvalue': lrange(6)})\n\n        joined = merge(left, right, on='key', how='outer')\n        expected = DataFrame({'key': [1, 1, 1, 1, 2, 2, 3, 4, 5],\n                              'value': np.array([0, 0, 1, 1, 2, 3, 4,\n                                                 np.nan, np.nan]),\n                              'rvalue': [0, 1, 0, 1, 2, 2, 3, 4, 5]},\n                             columns=['value', 'key', 'rvalue'])\n        assert_frame_equal(joined, expected)\n\n    def test_merge_join_key_dtype_cast(self):\n        # #8596\n\n        df1 = DataFrame({'key': [1], 'v1': [10]})\n        df2 = DataFrame({'key': [2], 'v1': [20]})\n        df = merge(df1, df2, how='outer')\n        assert df['key'].dtype == 'int64'\n\n        df1 = DataFrame({'key': [True], 'v1': [1]})\n        df2 = DataFrame({'key': [False], 'v1': [0]})\n        df = merge(df1, df2, how='outer')\n\n        # GH13169\n        # this really should be bool\n        assert df['key'].dtype == 'object'\n\n        df1 = DataFrame({'val': [1]})\n        df2 = DataFrame({'val': [2]})\n        lkey = np.array([1])\n        rkey = np.array([2])\n        df = merge(df1, df2, left_on=lkey, right_on=rkey, how='outer')\n        assert df['key_0'].dtype == 'int64'\n\n    def test_handle_join_key_pass_array(self):\n        left = DataFrame({'key': [1, 1, 2, 2, 3],\n                          'value': lrange(5)}, columns=['value', 'key'])\n        right = DataFrame({'rvalue': lrange(6)})\n        key = np.array([1, 1, 2, 3, 4, 5])\n\n        merged = merge(left, right, left_on='key', right_on=key, how='outer')\n        merged2 = merge(right, left, left_on=key, right_on='key', how='outer')\n\n        assert_series_equal(merged['key'], merged2['key'])\n        assert merged['key'].notna().all()\n        assert merged2['key'].notna().all()\n\n        left = DataFrame({'value': lrange(5)}, columns=['value'])\n        right = DataFrame({'rvalue': lrange(6)})\n        lkey = np.array([1, 1, 2, 2, 3])\n        rkey = np.array([1, 1, 2, 3, 4, 5])\n\n        merged = merge(left, right, left_on=lkey, right_on=rkey, how='outer')\n        tm.assert_series_equal(merged['key_0'], Series([1, 1, 1, 1, 2,\n                                                        2, 3, 4, 5],\n                                                       name='key_0'))\n\n        left = DataFrame({'value': lrange(3)})\n        right = DataFrame({'rvalue': lrange(6)})\n\n        key = np.array([0, 1, 1, 2, 2, 3], dtype=np.int64)\n        merged = merge(left, right, left_index=True, right_on=key, how='outer')\n        tm.assert_series_equal(merged['key_0'], Series(key, name='key_0'))\n\n    def test_no_overlap_more_informative_error(self):\n        dt = datetime.now()\n        df1 = DataFrame({'x': ['a']}, index=[dt])\n\n        df2 = DataFrame({'y': ['b', 'c']}, index=[dt, dt])\n        pytest.raises(MergeError, merge, df1, df2)\n\n    def test_merge_non_unique_indexes(self):\n\n        dt = datetime(2012, 5, 1)\n        dt2 = datetime(2012, 5, 2)\n        dt3 = datetime(2012, 5, 3)\n        dt4 = datetime(2012, 5, 4)\n\n        df1 = DataFrame({'x': ['a']}, index=[dt])\n        df2 = DataFrame({'y': ['b', 'c']}, index=[dt, dt])\n        _check_merge(df1, df2)\n\n        # Not monotonic\n        df1 = DataFrame({'x': ['a', 'b', 'q']}, index=[dt2, dt, dt4])\n        df2 = DataFrame({'y': ['c', 'd', 'e', 'f', 'g', 'h']},\n                        index=[dt3, dt3, dt2, dt2, dt, dt])\n        _check_merge(df1, df2)\n\n        df1 = DataFrame({'x': ['a', 'b']}, index=[dt, dt])\n        df2 = DataFrame({'y': ['c', 'd']}, index=[dt, dt])\n        _check_merge(df1, df2)\n\n    def test_merge_non_unique_index_many_to_many(self):\n        dt = datetime(2012, 5, 1)\n        dt2 = datetime(2012, 5, 2)\n        dt3 = datetime(2012, 5, 3)\n        df1 = DataFrame({'x': ['a', 'b', 'c', 'd']},\n                        index=[dt2, dt2, dt, dt])\n        df2 = DataFrame({'y': ['e', 'f', 'g', ' h', 'i']},\n                        index=[dt2, dt2, dt3, dt, dt])\n        _check_merge(df1, df2)\n\n    def test_left_merge_empty_dataframe(self):\n        left = DataFrame({'key': [1], 'value': [2]})\n        right = DataFrame({'key': []})\n\n        result = merge(left, right, on='key', how='left')\n        assert_frame_equal(result, left)\n\n        result = merge(right, left, on='key', how='right')\n        assert_frame_equal(result, left)\n\n    def test_merge_left_empty_right_empty(self):\n        # GH 10824\n        left = pd.DataFrame([], columns=['a', 'b', 'c'])\n        right = pd.DataFrame([], columns=['x', 'y', 'z'])\n\n        exp_in = pd.DataFrame([], columns=['a', 'b', 'c', 'x', 'y', 'z'],\n                              index=pd.Index([], dtype=object),\n                              dtype=object)\n\n        for kwarg in [dict(left_index=True, right_index=True),\n                      dict(left_index=True, right_on='x'),\n                      dict(left_on='a', right_index=True),\n                      dict(left_on='a', right_on='x')]:\n\n            result = pd.merge(left, right, how='inner', **kwarg)\n            tm.assert_frame_equal(result, exp_in)\n            result = pd.merge(left, right, how='left', **kwarg)\n            tm.assert_frame_equal(result, exp_in)\n            result = pd.merge(left, right, how='right', **kwarg)\n            tm.assert_frame_equal(result, exp_in)\n            result = pd.merge(left, right, how='outer', **kwarg)\n            tm.assert_frame_equal(result, exp_in)\n\n    def test_merge_left_empty_right_notempty(self):\n        # GH 10824\n        left = pd.DataFrame([], columns=['a', 'b', 'c'])\n        right = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n                             columns=['x', 'y', 'z'])\n\n        exp_out = pd.DataFrame({'a': np.array([np.nan] * 3, dtype=object),\n                                'b': np.array([np.nan] * 3, dtype=object),\n                                'c': np.array([np.nan] * 3, dtype=object),\n                                'x': [1, 4, 7],\n                                'y': [2, 5, 8],\n                                'z': [3, 6, 9]},\n                               columns=['a', 'b', 'c', 'x', 'y', 'z'])\n        exp_in = exp_out[0:0]  # make empty DataFrame keeping dtype\n        # result will have object dtype\n        exp_in.index = exp_in.index.astype(object)\n\n        def check1(exp, kwarg):\n            result = pd.merge(left, right, how='inner', **kwarg)\n            tm.assert_frame_equal(result, exp)\n            result = pd.merge(left, right, how='left', **kwarg)\n            tm.assert_frame_equal(result, exp)\n\n        def check2(exp, kwarg):\n            result = pd.merge(left, right, how='right', **kwarg)\n            tm.assert_frame_equal(result, exp)\n            result = pd.merge(left, right, how='outer', **kwarg)\n            tm.assert_frame_equal(result, exp)\n\n        for kwarg in [dict(left_index=True, right_index=True),\n                      dict(left_index=True, right_on='x')]:\n            check1(exp_in, kwarg)\n            check2(exp_out, kwarg)\n\n        kwarg = dict(left_on='a', right_index=True)\n        check1(exp_in, kwarg)\n        exp_out['a'] = [0, 1, 2]\n        check2(exp_out, kwarg)\n\n        kwarg = dict(left_on='a', right_on='x')\n        check1(exp_in, kwarg)\n        exp_out['a'] = np.array([np.nan] * 3, dtype=object)\n        check2(exp_out, kwarg)\n\n    def test_merge_left_notempty_right_empty(self):\n        # GH 10824\n        left = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n                            columns=['a', 'b', 'c'])\n        right = pd.DataFrame([], columns=['x', 'y', 'z'])\n\n        exp_out = pd.DataFrame({'a': [1, 4, 7],\n                                'b': [2, 5, 8],\n                                'c': [3, 6, 9],\n                                'x': np.array([np.nan] * 3, dtype=object),\n                                'y': np.array([np.nan] * 3, dtype=object),\n                                'z': np.array([np.nan] * 3, dtype=object)},\n                               columns=['a', 'b', 'c', 'x', 'y', 'z'])\n        exp_in = exp_out[0:0]  # make empty DataFrame keeping dtype\n        # result will have object dtype\n        exp_in.index = exp_in.index.astype(object)\n\n        def check1(exp, kwarg):\n            result = pd.merge(left, right, how='inner', **kwarg)\n            tm.assert_frame_equal(result, exp)\n            result = pd.merge(left, right, how='right', **kwarg)\n            tm.assert_frame_equal(result, exp)\n\n        def check2(exp, kwarg):\n            result = pd.merge(left, right, how='left', **kwarg)\n            tm.assert_frame_equal(result, exp)\n            result = pd.merge(left, right, how='outer', **kwarg)\n            tm.assert_frame_equal(result, exp)\n\n            for kwarg in [dict(left_index=True, right_index=True),\n                          dict(left_index=True, right_on='x'),\n                          dict(left_on='a', right_index=True),\n                          dict(left_on='a', right_on='x')]:\n                check1(exp_in, kwarg)\n                check2(exp_out, kwarg)\n\n    def test_merge_nosort(self):\n        # #2098, anything to do?\n\n        from datetime import datetime\n\n        d = {\"var1\": np.random.randint(0, 10, size=10),\n             \"var2\": np.random.randint(0, 10, size=10),\n             \"var3\": [datetime(2012, 1, 12), datetime(2011, 2, 4),\n                      datetime(\n                      2010, 2, 3), datetime(2012, 1, 12),\n                      datetime(\n                      2011, 2, 4), datetime(2012, 4, 3),\n                      datetime(\n                      2012, 3, 4), datetime(2008, 5, 1),\n                      datetime(2010, 2, 3), datetime(2012, 2, 3)]}\n        df = DataFrame.from_dict(d)\n        var3 = df.var3.unique()\n        var3.sort()\n        new = DataFrame.from_dict({\"var3\": var3,\n                                   \"var8\": np.random.random(7)})\n\n        result = df.merge(new, on=\"var3\", sort=False)\n        exp = merge(df, new, on='var3', sort=False)\n        assert_frame_equal(result, exp)\n\n        assert (df.var3.unique() == result.var3.unique()).all()\n\n    def test_merge_nan_right(self):\n        df1 = DataFrame({\"i1\": [0, 1], \"i2\": [0, 1]})\n        df2 = DataFrame({\"i1\": [0], \"i3\": [0]})\n        result = df1.join(df2, on=\"i1\", rsuffix=\"_\")\n        expected = (DataFrame({'i1': {0: 0.0, 1: 1}, 'i2': {0: 0, 1: 1},\n                               'i1_': {0: 0, 1: np.nan},\n                               'i3': {0: 0.0, 1: np.nan},\n                               None: {0: 0, 1: 0}})\n                    .set_index(None)\n                    .reset_index()[['i1', 'i2', 'i1_', 'i3']])\n        assert_frame_equal(result, expected, check_dtype=False)\n\n        df1 = DataFrame({\"i1\": [0, 1], \"i2\": [0.5, 1.5]})\n        df2 = DataFrame({\"i1\": [0], \"i3\": [0.7]})\n        result = df1.join(df2, rsuffix=\"_\", on='i1')\n        expected = (DataFrame({'i1': {0: 0, 1: 1}, 'i1_': {0: 0.0, 1: nan},\n                               'i2': {0: 0.5, 1: 1.5},\n                               'i3': {0: 0.69999999999999996,\n                                      1: nan}})\n                    [['i1', 'i2', 'i1_', 'i3']])\n        assert_frame_equal(result, expected)\n\n    def test_merge_type(self):\n        class NotADataFrame(DataFrame):\n\n            @property\n            def _constructor(self):\n                return NotADataFrame\n\n        nad = NotADataFrame(self.df)\n        result = nad.merge(self.df2, on='key1')\n\n        assert isinstance(result, NotADataFrame)\n\n    def test_join_append_timedeltas(self):\n\n        import datetime as dt\n        from pandas import NaT\n\n        # timedelta64 issues with join/merge\n        # GH 5695\n\n        d = {'d': dt.datetime(2013, 11, 5, 5, 56), 't': dt.timedelta(0, 22500)}\n        df = DataFrame(columns=list('dt'))\n        df = df.append(d, ignore_index=True)\n        result = df.append(d, ignore_index=True)\n        expected = DataFrame({'d': [dt.datetime(2013, 11, 5, 5, 56),\n                                    dt.datetime(2013, 11, 5, 5, 56)],\n                              't': [dt.timedelta(0, 22500),\n                                    dt.timedelta(0, 22500)]})\n        assert_frame_equal(result, expected)\n\n        td = np.timedelta64(300000000)\n        lhs = DataFrame(Series([td, td], index=[\"A\", \"B\"]))\n        rhs = DataFrame(Series([td], index=[\"A\"]))\n\n        result = lhs.join(rhs, rsuffix='r', how=\"left\")\n        expected = DataFrame({'0': Series([td, td], index=list('AB')),\n                              '0r': Series([td, NaT], index=list('AB'))})\n        assert_frame_equal(result, expected)\n\n    def test_other_datetime_unit(self):\n        # GH 13389\n        df1 = pd.DataFrame({'entity_id': [101, 102]})\n        s = pd.Series([None, None], index=[101, 102], name='days')\n\n        for dtype in ['datetime64[D]', 'datetime64[h]', 'datetime64[m]',\n                      'datetime64[s]', 'datetime64[ms]', 'datetime64[us]',\n                      'datetime64[ns]']:\n\n            df2 = s.astype(dtype).to_frame('days')\n            # coerces to datetime64[ns], thus sholuld not be affected\n            assert df2['days'].dtype == 'datetime64[ns]'\n\n            result = df1.merge(df2, left_on='entity_id', right_index=True)\n\n            exp = pd.DataFrame({'entity_id': [101, 102],\n                                'days': np.array(['nat', 'nat'],\n                                                 dtype='datetime64[ns]')},\n                               columns=['entity_id', 'days'])\n            tm.assert_frame_equal(result, exp)\n\n    def test_other_timedelta_unit(self):\n        # GH 13389\n        df1 = pd.DataFrame({'entity_id': [101, 102]})\n        s = pd.Series([None, None], index=[101, 102], name='days')\n\n        for dtype in ['timedelta64[D]', 'timedelta64[h]', 'timedelta64[m]',\n                      'timedelta64[s]', 'timedelta64[ms]', 'timedelta64[us]',\n                      'timedelta64[ns]']:\n\n            df2 = s.astype(dtype).to_frame('days')\n            assert df2['days'].dtype == dtype\n\n            result = df1.merge(df2, left_on='entity_id', right_index=True)\n\n            exp = pd.DataFrame({'entity_id': [101, 102],\n                                'days': np.array(['nat', 'nat'],\n                                                 dtype=dtype)},\n                               columns=['entity_id', 'days'])\n            tm.assert_frame_equal(result, exp)\n\n    def test_overlapping_columns_error_message(self):\n        df = DataFrame({'key': [1, 2, 3],\n                        'v1': [4, 5, 6],\n                        'v2': [7, 8, 9]})\n        df2 = DataFrame({'key': [1, 2, 3],\n                         'v1': [4, 5, 6],\n                         'v2': [7, 8, 9]})\n\n        df.columns = ['key', 'foo', 'foo']\n        df2.columns = ['key', 'bar', 'bar']\n        expected = DataFrame({'key': [1, 2, 3],\n                              'v1': [4, 5, 6],\n                              'v2': [7, 8, 9],\n                              'v3': [4, 5, 6],\n                              'v4': [7, 8, 9]})\n        expected.columns = ['key', 'foo', 'foo', 'bar', 'bar']\n        assert_frame_equal(merge(df, df2), expected)\n\n        # #2649, #10639\n        df2.columns = ['key1', 'foo', 'foo']\n        pytest.raises(ValueError, merge, df, df2)\n\n    def test_merge_on_datetime64tz(self):\n\n        # GH11405\n        left = pd.DataFrame({'key': pd.date_range('20151010', periods=2,\n                                                  tz='US/Eastern'),\n                             'value': [1, 2]})\n        right = pd.DataFrame({'key': pd.date_range('20151011', periods=3,\n                                                   tz='US/Eastern'),\n                              'value': [1, 2, 3]})\n\n        expected = DataFrame({'key': pd.date_range('20151010', periods=4,\n                                                   tz='US/Eastern'),\n                              'value_x': [1, 2, np.nan, np.nan],\n                              'value_y': [np.nan, 1, 2, 3]})\n        result = pd.merge(left, right, on='key', how='outer')\n        assert_frame_equal(result, expected)\n\n        left = pd.DataFrame({'value': pd.date_range('20151010', periods=2,\n                                                    tz='US/Eastern'),\n                             'key': [1, 2]})\n        right = pd.DataFrame({'value': pd.date_range('20151011', periods=2,\n                                                     tz='US/Eastern'),\n                              'key': [2, 3]})\n        expected = DataFrame({\n            'value_x': list(pd.date_range('20151010', periods=2,\n                                          tz='US/Eastern')) + [pd.NaT],\n            'value_y': [pd.NaT] + list(pd.date_range('20151011', periods=2,\n                                                     tz='US/Eastern')),\n            'key': [1, 2, 3]})\n        result = pd.merge(left, right, on='key', how='outer')\n        assert_frame_equal(result, expected)\n        assert result['value_x'].dtype == 'datetime64[ns, US/Eastern]'\n        assert result['value_y'].dtype == 'datetime64[ns, US/Eastern]'\n\n    def test_merge_non_unique_period_index(self):\n        # GH #16871\n        index = pd.period_range('2016-01-01', periods=16, freq='M')\n        df = DataFrame([i for i in range(len(index))],\n                       index=index, columns=['pnum'])\n        df2 = concat([df, df])\n        result = df.merge(df2, left_index=True, right_index=True, how='inner')\n        expected = DataFrame(\n            np.tile(np.arange(16, dtype=np.int64).repeat(2).reshape(-1, 1), 2),\n            columns=['pnum_x', 'pnum_y'], index=df2.sort_index().index)\n        tm.assert_frame_equal(result, expected)\n\n    def test_merge_on_periods(self):\n        left = pd.DataFrame({'key': pd.period_range('20151010', periods=2,\n                                                    freq='D'),\n                             'value': [1, 2]})\n        right = pd.DataFrame({'key': pd.period_range('20151011', periods=3,\n                                                     freq='D'),\n                              'value': [1, 2, 3]})\n\n        expected = DataFrame({'key': pd.period_range('20151010', periods=4,\n                                                     freq='D'),\n                              'value_x': [1, 2, np.nan, np.nan],\n                              'value_y': [np.nan, 1, 2, 3]})\n        result = pd.merge(left, right, on='key', how='outer')\n        assert_frame_equal(result, expected)\n\n        left = pd.DataFrame({'value': pd.period_range('20151010', periods=2,\n                                                      freq='D'),\n                             'key': [1, 2]})\n        right = pd.DataFrame({'value': pd.period_range('20151011', periods=2,\n                                                       freq='D'),\n                              'key': [2, 3]})\n\n        exp_x = pd.period_range('20151010', periods=2, freq='D')\n        exp_y = pd.period_range('20151011', periods=2, freq='D')\n        expected = DataFrame({'value_x': list(exp_x) + [pd.NaT],\n                              'value_y': [pd.NaT] + list(exp_y),\n                              'key': [1, 2, 3]})\n        result = pd.merge(left, right, on='key', how='outer')\n        assert_frame_equal(result, expected)\n        assert result['value_x'].dtype == 'object'\n        assert result['value_y'].dtype == 'object'\n\n    def test_indicator(self):\n        # PR #10054. xref #7412 and closes #8790.\n        df1 = DataFrame({'col1': [0, 1], 'col_left': [\n                        'a', 'b'], 'col_conflict': [1, 2]})\n        df1_copy = df1.copy()\n\n        df2 = DataFrame({'col1': [1, 2, 3, 4, 5], 'col_right': [2, 2, 2, 2, 2],\n                         'col_conflict': [1, 2, 3, 4, 5]})\n        df2_copy = df2.copy()\n\n        df_result = DataFrame({\n            'col1': [0, 1, 2, 3, 4, 5],\n            'col_conflict_x': [1, 2, np.nan, np.nan, np.nan, np.nan],\n            'col_left': ['a', 'b', np.nan, np.nan, np.nan, np.nan],\n            'col_conflict_y': [np.nan, 1, 2, 3, 4, 5],\n            'col_right': [np.nan, 2, 2, 2, 2, 2]})\n        df_result['_merge'] = Categorical(\n            ['left_only', 'both', 'right_only',\n             'right_only', 'right_only', 'right_only'],\n            categories=['left_only', 'right_only', 'both'])\n\n        df_result = df_result[['col1', 'col_conflict_x', 'col_left',\n                               'col_conflict_y', 'col_right', '_merge']]\n\n        test = merge(df1, df2, on='col1', how='outer', indicator=True)\n        assert_frame_equal(test, df_result)\n        test = df1.merge(df2, on='col1', how='outer', indicator=True)\n        assert_frame_equal(test, df_result)\n\n        # No side effects\n        assert_frame_equal(df1, df1_copy)\n        assert_frame_equal(df2, df2_copy)\n\n        # Check with custom name\n        df_result_custom_name = df_result\n        df_result_custom_name = df_result_custom_name.rename(\n            columns={'_merge': 'custom_name'})\n\n        test_custom_name = merge(\n            df1, df2, on='col1', how='outer', indicator='custom_name')\n        assert_frame_equal(test_custom_name, df_result_custom_name)\n        test_custom_name = df1.merge(\n            df2, on='col1', how='outer', indicator='custom_name')\n        assert_frame_equal(test_custom_name, df_result_custom_name)\n\n        # Check only accepts strings and booleans\n        with pytest.raises(ValueError):\n            merge(df1, df2, on='col1', how='outer', indicator=5)\n        with pytest.raises(ValueError):\n            df1.merge(df2, on='col1', how='outer', indicator=5)\n\n        # Check result integrity\n\n        test2 = merge(df1, df2, on='col1', how='left', indicator=True)\n        assert (test2._merge != 'right_only').all()\n        test2 = df1.merge(df2, on='col1', how='left', indicator=True)\n        assert (test2._merge != 'right_only').all()\n\n        test3 = merge(df1, df2, on='col1', how='right', indicator=True)\n        assert (test3._merge != 'left_only').all()\n        test3 = df1.merge(df2, on='col1', how='right', indicator=True)\n        assert (test3._merge != 'left_only').all()\n\n        test4 = merge(df1, df2, on='col1', how='inner', indicator=True)\n        assert (test4._merge == 'both').all()\n        test4 = df1.merge(df2, on='col1', how='inner', indicator=True)\n        assert (test4._merge == 'both').all()\n\n        # Check if working name in df\n        for i in ['_right_indicator', '_left_indicator', '_merge']:\n            df_badcolumn = DataFrame({'col1': [1, 2], i: [2, 2]})\n\n            with pytest.raises(ValueError):\n                merge(df1, df_badcolumn, on='col1',\n                      how='outer', indicator=True)\n            with pytest.raises(ValueError):\n                df1.merge(df_badcolumn, on='col1', how='outer', indicator=True)\n\n        # Check for name conflict with custom name\n        df_badcolumn = DataFrame(\n            {'col1': [1, 2], 'custom_column_name': [2, 2]})\n\n        with pytest.raises(ValueError):\n            merge(df1, df_badcolumn, on='col1', how='outer',\n                  indicator='custom_column_name')\n        with pytest.raises(ValueError):\n            df1.merge(df_badcolumn, on='col1', how='outer',\n                      indicator='custom_column_name')\n\n        # Merge on multiple columns\n        df3 = DataFrame({'col1': [0, 1], 'col2': ['a', 'b']})\n\n        df4 = DataFrame({'col1': [1, 1, 3], 'col2': ['b', 'x', 'y']})\n\n        hand_coded_result = DataFrame({'col1': [0, 1, 1, 3],\n                                       'col2': ['a', 'b', 'x', 'y']})\n        hand_coded_result['_merge'] = Categorical(\n            ['left_only', 'both', 'right_only', 'right_only'],\n            categories=['left_only', 'right_only', 'both'])\n\n        test5 = merge(df3, df4, on=['col1', 'col2'],\n                      how='outer', indicator=True)\n        assert_frame_equal(test5, hand_coded_result)\n        test5 = df3.merge(df4, on=['col1', 'col2'],\n                          how='outer', indicator=True)\n        assert_frame_equal(test5, hand_coded_result)\n\n    def test_validation(self):\n        left = DataFrame({'a': ['a', 'b', 'c', 'd'],\n                          'b': ['cat', 'dog', 'weasel', 'horse']},\n                         index=range(4))\n\n        right = DataFrame({'a': ['a', 'b', 'c', 'd', 'e'],\n                           'c': ['meow', 'bark', 'um... weasel noise?',\n                                 'nay', 'chirp']},\n                          index=range(5))\n\n        # Make sure no side effects.\n        left_copy = left.copy()\n        right_copy = right.copy()\n\n        result = merge(left, right, left_index=True, right_index=True,\n                       validate='1:1')\n        assert_frame_equal(left, left_copy)\n        assert_frame_equal(right, right_copy)\n\n        # make sure merge still correct\n        expected = DataFrame({'a_x': ['a', 'b', 'c', 'd'],\n                              'b': ['cat', 'dog', 'weasel', 'horse'],\n                              'a_y': ['a', 'b', 'c', 'd'],\n                              'c': ['meow', 'bark', 'um... weasel noise?',\n                                    'nay']},\n                             index=range(4),\n                             columns=['a_x', 'b', 'a_y', 'c'])\n\n        result = merge(left, right, left_index=True, right_index=True,\n                       validate='one_to_one')\n        assert_frame_equal(result, expected)\n\n        expected_2 = DataFrame({'a': ['a', 'b', 'c', 'd'],\n                                'b': ['cat', 'dog', 'weasel', 'horse'],\n                                'c': ['meow', 'bark', 'um... weasel noise?',\n                                      'nay']},\n                               index=range(4))\n\n        result = merge(left, right, on='a', validate='1:1')\n        assert_frame_equal(left, left_copy)\n        assert_frame_equal(right, right_copy)\n        assert_frame_equal(result, expected_2)\n\n        result = merge(left, right, on='a', validate='one_to_one')\n        assert_frame_equal(result, expected_2)\n\n        # One index, one column\n        expected_3 = DataFrame({'b': ['cat', 'dog', 'weasel', 'horse'],\n                                'a': ['a', 'b', 'c', 'd'],\n                                'c': ['meow', 'bark', 'um... weasel noise?',\n                                      'nay']},\n                               columns=['b', 'a', 'c'],\n                               index=range(4))\n\n        left_index_reset = left.set_index('a')\n        result = merge(left_index_reset, right, left_index=True,\n                       right_on='a', validate='one_to_one')\n        assert_frame_equal(result, expected_3)\n\n        # Dups on right\n        right_w_dups = right.append(pd.DataFrame({'a': ['e'], 'c': ['moo']},\n                                    index=[4]))\n        merge(left, right_w_dups, left_index=True, right_index=True,\n              validate='one_to_many')\n\n        with pytest.raises(MergeError):\n            merge(left, right_w_dups, left_index=True, right_index=True,\n                  validate='one_to_one')\n\n        with pytest.raises(MergeError):\n            merge(left, right_w_dups, on='a', validate='one_to_one')\n\n        # Dups on left\n        left_w_dups = left.append(pd.DataFrame({'a': ['a'], 'c': ['cow']},\n                                               index=[3]))\n        merge(left_w_dups, right, left_index=True, right_index=True,\n              validate='many_to_one')\n\n        with pytest.raises(MergeError):\n            merge(left_w_dups, right, left_index=True, right_index=True,\n                  validate='one_to_one')\n\n        with pytest.raises(MergeError):\n            merge(left_w_dups, right, on='a', validate='one_to_one')\n\n        # Dups on both\n        merge(left_w_dups, right_w_dups, on='a', validate='many_to_many')\n\n        with pytest.raises(MergeError):\n            merge(left_w_dups, right_w_dups, left_index=True,\n                  right_index=True, validate='many_to_one')\n\n        with pytest.raises(MergeError):\n            merge(left_w_dups, right_w_dups, on='a',\n                  validate='one_to_many')\n\n        # Check invalid arguments\n        with pytest.raises(ValueError):\n            merge(left, right, on='a', validate='jibberish')\n\n        # Two column merge, dups in both, but jointly no dups.\n        left = DataFrame({'a': ['a', 'a', 'b', 'b'],\n                          'b': [0, 1, 0, 1],\n                          'c': ['cat', 'dog', 'weasel', 'horse']},\n                         index=range(4))\n\n        right = DataFrame({'a': ['a', 'a', 'b'],\n                           'b': [0, 1, 0],\n                           'd': ['meow', 'bark', 'um... weasel noise?']},\n                          index=range(3))\n\n        expected_multi = DataFrame({'a': ['a', 'a', 'b'],\n                                    'b': [0, 1, 0],\n                                    'c': ['cat', 'dog', 'weasel'],\n                                    'd': ['meow', 'bark',\n                                          'um... weasel noise?']},\n                                   index=range(3))\n\n        with pytest.raises(MergeError):\n            merge(left, right, on='a', validate='1:1')\n\n        result = merge(left, right, on=['a', 'b'], validate='1:1')\n        assert_frame_equal(result, expected_multi)\n\n    def test_merge_two_empty_df_no_division_error(self):\n        # GH17776, PR #17846\n        a = pd.DataFrame({'a': [], 'b': [], 'c': []})\n        with np.errstate(divide='raise'):\n            merge(a, a, on=('a', 'b'))\n\n\ndef _check_merge(x, y):\n    for how in ['inner', 'left', 'outer']:\n        result = x.join(y, how=how)\n\n        expected = merge(x.reset_index(), y.reset_index(), how=how,\n                         sort=True)\n        expected = expected.set_index('index')\n\n        # TODO check_names on merge?\n        assert_frame_equal(result, expected, check_names=False)\n\n\nclass TestMergeMulti(object):\n\n    def setup_method(self, method):\n        self.index = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],\n                                        ['one', 'two', 'three']],\n                                labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],\n                                        [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],\n                                names=['first', 'second'])\n        self.to_join = DataFrame(np.random.randn(10, 3), index=self.index,\n                                 columns=['j_one', 'j_two', 'j_three'])\n\n        # a little relevant example with NAs\n        key1 = ['bar', 'bar', 'bar', 'foo', 'foo', 'baz', 'baz', 'qux',\n                'qux', 'snap']\n        key2 = ['two', 'one', 'three', 'one', 'two', 'one', 'two', 'two',\n                'three', 'one']\n\n        data = np.random.randn(len(key1))\n        self.data = DataFrame({'key1': key1, 'key2': key2,\n                               'data': data})\n\n    def test_merge_on_multikey(self):\n        joined = self.data.join(self.to_join, on=['key1', 'key2'])\n\n        join_key = Index(lzip(self.data['key1'], self.data['key2']))\n        indexer = self.to_join.index.get_indexer(join_key)\n        ex_values = self.to_join.values.take(indexer, axis=0)\n        ex_values[indexer == -1] = np.nan\n        expected = self.data.join(DataFrame(ex_values,\n                                            columns=self.to_join.columns))\n\n        # TODO: columns aren't in the same order yet\n        assert_frame_equal(joined, expected.loc[:, joined.columns])\n\n        left = self.data.join(self.to_join, on=['key1', 'key2'], sort=True)\n        right = expected.loc[:, joined.columns].sort_values(['key1', 'key2'],\n                                                            kind='mergesort')\n        assert_frame_equal(left, right)\n\n    def test_left_join_multi_index(self):\n        icols = ['1st', '2nd', '3rd']\n\n        def bind_cols(df):\n            iord = lambda a: 0 if a != a else ord(a)\n            f = lambda ts: ts.map(iord) - ord('a')\n            return (f(df['1st']) + f(df['3rd']) * 1e2 +\n                    df['2nd'].fillna(0) * 1e4)\n\n        def run_asserts(left, right):\n            for sort in [False, True]:\n                res = left.join(right, on=icols, how='left', sort=sort)\n\n                assert len(left) < len(res) + 1\n                assert not res['4th'].isna().any()\n                assert not res['5th'].isna().any()\n\n                tm.assert_series_equal(\n                    res['4th'], - res['5th'], check_names=False)\n                result = bind_cols(res.iloc[:, :-2])\n                tm.assert_series_equal(res['4th'], result, check_names=False)\n                assert result.name is None\n\n                if sort:\n                    tm.assert_frame_equal(\n                        res, res.sort_values(icols, kind='mergesort'))\n\n                out = merge(left, right.reset_index(), on=icols,\n                            sort=sort, how='left')\n\n                res.index = np.arange(len(res))\n                tm.assert_frame_equal(out, res)\n\n        lc = list(map(chr, np.arange(ord('a'), ord('z') + 1)))\n        left = DataFrame(np.random.choice(lc, (5000, 2)),\n                         columns=['1st', '3rd'])\n        left.insert(1, '2nd', np.random.randint(0, 1000, len(left)))\n\n        i = np.random.permutation(len(left))\n        right = left.iloc[i].copy()\n\n        left['4th'] = bind_cols(left)\n        right['5th'] = - bind_cols(right)\n        right.set_index(icols, inplace=True)\n\n        run_asserts(left, right)\n\n        # inject some nulls\n        left.loc[1::23, '1st'] = np.nan\n        left.loc[2::37, '2nd'] = np.nan\n        left.loc[3::43, '3rd'] = np.nan\n        left['4th'] = bind_cols(left)\n\n        i = np.random.permutation(len(left))\n        right = left.iloc[i, :-1]\n        right['5th'] = - bind_cols(right)\n        right.set_index(icols, inplace=True)\n\n        run_asserts(left, right)\n\n    def test_merge_right_vs_left(self):\n        # compare left vs right merge with multikey\n        for sort in [False, True]:\n            merged1 = self.data.merge(self.to_join, left_on=['key1', 'key2'],\n                                      right_index=True, how='left', sort=sort)\n\n            merged2 = self.to_join.merge(self.data, right_on=['key1', 'key2'],\n                                         left_index=True, how='right',\n                                         sort=sort)\n\n            merged2 = merged2.loc[:, merged1.columns]\n            assert_frame_equal(merged1, merged2)\n\n    def test_compress_group_combinations(self):\n\n        # ~ 40000000 possible unique groups\n        key1 = tm.rands_array(10, 10000)\n        key1 = np.tile(key1, 2)\n        key2 = key1[::-1]\n\n        df = DataFrame({'key1': key1, 'key2': key2,\n                        'value1': np.random.randn(20000)})\n\n        df2 = DataFrame({'key1': key1[::2], 'key2': key2[::2],\n                         'value2': np.random.randn(10000)})\n\n        # just to hit the label compression code path\n        merge(df, df2, how='outer')\n\n    def test_left_join_index_preserve_order(self):\n\n        left = DataFrame({'k1': [0, 1, 2] * 8,\n                          'k2': ['foo', 'bar'] * 12,\n                          'v': np.array(np.arange(24), dtype=np.int64)})\n\n        index = MultiIndex.from_tuples([(2, 'bar'), (1, 'foo')])\n        right = DataFrame({'v2': [5, 7]}, index=index)\n\n        result = left.join(right, on=['k1', 'k2'])\n\n        expected = left.copy()\n        expected['v2'] = np.nan\n        expected.loc[(expected.k1 == 2) & (expected.k2 == 'bar'), 'v2'] = 5\n        expected.loc[(expected.k1 == 1) & (expected.k2 == 'foo'), 'v2'] = 7\n\n        tm.assert_frame_equal(result, expected)\n        tm.assert_frame_equal(\n            result.sort_values(['k1', 'k2'], kind='mergesort'),\n            left.join(right, on=['k1', 'k2'], sort=True))\n\n        # test join with multi dtypes blocks\n        left = DataFrame({'k1': [0, 1, 2] * 8,\n                          'k2': ['foo', 'bar'] * 12,\n                          'k3': np.array([0, 1, 2] * 8, dtype=np.float32),\n                          'v': np.array(np.arange(24), dtype=np.int32)})\n\n        index = MultiIndex.from_tuples([(2, 'bar'), (1, 'foo')])\n        right = DataFrame({'v2': [5, 7]}, index=index)\n\n        result = left.join(right, on=['k1', 'k2'])\n\n        expected = left.copy()\n        expected['v2'] = np.nan\n        expected.loc[(expected.k1 == 2) & (expected.k2 == 'bar'), 'v2'] = 5\n        expected.loc[(expected.k1 == 1) & (expected.k2 == 'foo'), 'v2'] = 7\n\n        tm.assert_frame_equal(result, expected)\n        tm.assert_frame_equal(\n            result.sort_values(['k1', 'k2'], kind='mergesort'),\n            left.join(right, on=['k1', 'k2'], sort=True))\n\n        # do a right join for an extra test\n        joined = merge(right, left, left_index=True,\n                       right_on=['k1', 'k2'], how='right')\n        tm.assert_frame_equal(joined.loc[:, expected.columns], expected)\n\n    def test_left_join_index_multi_match_multiindex(self):\n        left = DataFrame([\n            ['X', 'Y', 'C', 'a'],\n            ['W', 'Y', 'C', 'e'],\n            ['V', 'Q', 'A', 'h'],\n            ['V', 'R', 'D', 'i'],\n            ['X', 'Y', 'D', 'b'],\n            ['X', 'Y', 'A', 'c'],\n            ['W', 'Q', 'B', 'f'],\n            ['W', 'R', 'C', 'g'],\n            ['V', 'Y', 'C', 'j'],\n            ['X', 'Y', 'B', 'd']],\n            columns=['cola', 'colb', 'colc', 'tag'],\n            index=[3, 2, 0, 1, 7, 6, 4, 5, 9, 8])\n\n        right = DataFrame([\n            ['W', 'R', 'C', 0],\n            ['W', 'Q', 'B', 3],\n            ['W', 'Q', 'B', 8],\n            ['X', 'Y', 'A', 1],\n            ['X', 'Y', 'A', 4],\n            ['X', 'Y', 'B', 5],\n            ['X', 'Y', 'C', 6],\n            ['X', 'Y', 'C', 9],\n            ['X', 'Q', 'C', -6],\n            ['X', 'R', 'C', -9],\n            ['V', 'Y', 'C', 7],\n            ['V', 'R', 'D', 2],\n            ['V', 'R', 'D', -1],\n            ['V', 'Q', 'A', -3]],\n            columns=['col1', 'col2', 'col3', 'val'])\n\n        right.set_index(['col1', 'col2', 'col3'], inplace=True)\n        result = left.join(right, on=['cola', 'colb', 'colc'], how='left')\n\n        expected = DataFrame([\n            ['X', 'Y', 'C', 'a', 6],\n            ['X', 'Y', 'C', 'a', 9],\n            ['W', 'Y', 'C', 'e', nan],\n            ['V', 'Q', 'A', 'h', -3],\n            ['V', 'R', 'D', 'i', 2],\n            ['V', 'R', 'D', 'i', -1],\n            ['X', 'Y', 'D', 'b', nan],\n            ['X', 'Y', 'A', 'c', 1],\n            ['X', 'Y', 'A', 'c', 4],\n            ['W', 'Q', 'B', 'f', 3],\n            ['W', 'Q', 'B', 'f', 8],\n            ['W', 'R', 'C', 'g', 0],\n            ['V', 'Y', 'C', 'j', 7],\n            ['X', 'Y', 'B', 'd', 5]],\n            columns=['cola', 'colb', 'colc', 'tag', 'val'],\n            index=[3, 3, 2, 0, 1, 1, 7, 6, 6, 4, 4, 5, 9, 8])\n\n        tm.assert_frame_equal(result, expected)\n\n        result = left.join(right, on=['cola', 'colb', 'colc'],\n                           how='left', sort=True)\n\n        tm.assert_frame_equal(\n            result,\n            expected.sort_values(['cola', 'colb', 'colc'], kind='mergesort'))\n\n        # GH7331 - maintain left frame order in left merge\n        right.reset_index(inplace=True)\n        right.columns = left.columns[:3].tolist() + right.columns[-1:].tolist()\n        result = merge(left, right, how='left', on=left.columns[:-1].tolist())\n        expected.index = np.arange(len(expected))\n        tm.assert_frame_equal(result, expected)\n\n    def test_left_join_index_multi_match(self):\n        left = DataFrame([\n            ['c', 0],\n            ['b', 1],\n            ['a', 2],\n            ['b', 3]],\n            columns=['tag', 'val'],\n            index=[2, 0, 1, 3])\n\n        right = DataFrame([\n            ['a', 'v'],\n            ['c', 'w'],\n            ['c', 'x'],\n            ['d', 'y'],\n            ['a', 'z'],\n            ['c', 'r'],\n            ['e', 'q'],\n            ['c', 's']],\n            columns=['tag', 'char'])\n\n        right.set_index('tag', inplace=True)\n        result = left.join(right, on='tag', how='left')\n\n        expected = DataFrame([\n            ['c', 0, 'w'],\n            ['c', 0, 'x'],\n            ['c', 0, 'r'],\n            ['c', 0, 's'],\n            ['b', 1, nan],\n            ['a', 2, 'v'],\n            ['a', 2, 'z'],\n            ['b', 3, nan]],\n            columns=['tag', 'val', 'char'],\n            index=[2, 2, 2, 2, 0, 1, 1, 3])\n\n        tm.assert_frame_equal(result, expected)\n\n        result = left.join(right, on='tag', how='left', sort=True)\n        tm.assert_frame_equal(\n            result, expected.sort_values('tag', kind='mergesort'))\n\n        # GH7331 - maintain left frame order in left merge\n        result = merge(left, right.reset_index(), how='left', on='tag')\n        expected.index = np.arange(len(expected))\n        tm.assert_frame_equal(result, expected)\n\n    def test_left_merge_na_buglet(self):\n        left = DataFrame({'id': list('abcde'), 'v1': randn(5),\n                          'v2': randn(5), 'dummy': list('abcde'),\n                          'v3': randn(5)},\n                         columns=['id', 'v1', 'v2', 'dummy', 'v3'])\n        right = DataFrame({'id': ['a', 'b', np.nan, np.nan, np.nan],\n                           'sv3': [1.234, 5.678, np.nan, np.nan, np.nan]})\n\n        merged = merge(left, right, on='id', how='left')\n\n        rdf = right.drop(['id'], axis=1)\n        expected = left.join(rdf)\n        tm.assert_frame_equal(merged, expected)\n\n    def test_merge_na_keys(self):\n        data = [[1950, \"A\", 1.5],\n                [1950, \"B\", 1.5],\n                [1955, \"B\", 1.5],\n                [1960, \"B\", np.nan],\n                [1970, \"B\", 4.],\n                [1950, \"C\", 4.],\n                [1960, \"C\", np.nan],\n                [1965, \"C\", 3.],\n                [1970, \"C\", 4.]]\n\n        frame = DataFrame(data, columns=[\"year\", \"panel\", \"data\"])\n\n        other_data = [[1960, 'A', np.nan],\n                      [1970, 'A', np.nan],\n                      [1955, 'A', np.nan],\n                      [1965, 'A', np.nan],\n                      [1965, 'B', np.nan],\n                      [1955, 'C', np.nan]]\n        other = DataFrame(other_data, columns=['year', 'panel', 'data'])\n\n        result = frame.merge(other, how='outer')\n\n        expected = frame.fillna(-999).merge(other.fillna(-999), how='outer')\n        expected = expected.replace(-999, np.nan)\n\n        tm.assert_frame_equal(result, expected)\n\n    def test_join_multi_levels(self):\n\n        # GH 3662\n        # merge multi-levels\n        household = (\n            DataFrame(\n                dict(household_id=[1, 2, 3],\n                     male=[0, 1, 0],\n                     wealth=[196087.3, 316478.7, 294750]),\n                columns=['household_id', 'male', 'wealth'])\n            .set_index('household_id'))\n        portfolio = (\n            DataFrame(\n                dict(household_id=[1, 2, 2, 3, 3, 3, 4],\n                     asset_id=[\"nl0000301109\", \"nl0000289783\", \"gb00b03mlx29\",\n                               \"gb00b03mlx29\", \"lu0197800237\", \"nl0000289965\",\n                               np.nan],\n                     name=[\"ABN Amro\", \"Robeco\", \"Royal Dutch Shell\",\n                           \"Royal Dutch Shell\",\n                           \"AAB Eastern Europe Equity Fund\",\n                           \"Postbank BioTech Fonds\", np.nan],\n                     share=[1.0, 0.4, 0.6, 0.15, 0.6, 0.25, 1.0]),\n                columns=['household_id', 'asset_id', 'name', 'share'])\n            .set_index(['household_id', 'asset_id']))\n        result = household.join(portfolio, how='inner')\n        expected = (\n            DataFrame(\n                dict(male=[0, 1, 1, 0, 0, 0],\n                     wealth=[196087.3, 316478.7, 316478.7,\n                             294750.0, 294750.0, 294750.0],\n                     name=['ABN Amro', 'Robeco', 'Royal Dutch Shell',\n                           'Royal Dutch Shell',\n                           'AAB Eastern Europe Equity Fund',\n                           'Postbank BioTech Fonds'],\n                     share=[1.00, 0.40, 0.60, 0.15, 0.60, 0.25],\n                     household_id=[1, 2, 2, 3, 3, 3],\n                     asset_id=['nl0000301109', 'nl0000289783', 'gb00b03mlx29',\n                               'gb00b03mlx29', 'lu0197800237',\n                               'nl0000289965']))\n            .set_index(['household_id', 'asset_id'])\n            .reindex(columns=['male', 'wealth', 'name', 'share']))\n        assert_frame_equal(result, expected)\n\n        assert_frame_equal(result, expected)\n\n        # equivalency\n        result2 = (merge(household.reset_index(), portfolio.reset_index(),\n                         on=['household_id'], how='inner')\n                   .set_index(['household_id', 'asset_id']))\n        assert_frame_equal(result2, expected)\n\n        result = household.join(portfolio, how='outer')\n        expected = (concat([\n            expected,\n            (DataFrame(\n                dict(share=[1.00]),\n                index=MultiIndex.from_tuples(\n                    [(4, np.nan)],\n                    names=['household_id', 'asset_id'])))\n        ], axis=0).reindex(columns=expected.columns))\n        assert_frame_equal(result, expected)\n\n        # invalid cases\n        household.index.name = 'foo'\n\n        def f():\n            household.join(portfolio, how='inner')\n        pytest.raises(ValueError, f)\n\n        portfolio2 = portfolio.copy()\n        portfolio2.index.set_names(['household_id', 'foo'])\n\n        def f():\n            portfolio2.join(portfolio, how='inner')\n        pytest.raises(ValueError, f)\n\n    def test_join_multi_levels2(self):\n\n        # some more advanced merges\n        # GH6360\n        household = (\n            DataFrame(\n                dict(household_id=[1, 2, 2, 3, 3, 3, 4],\n                     asset_id=[\"nl0000301109\", \"nl0000301109\", \"gb00b03mlx29\",\n                               \"gb00b03mlx29\", \"lu0197800237\", \"nl0000289965\",\n                               np.nan],\n                     share=[1.0, 0.4, 0.6, 0.15, 0.6, 0.25, 1.0]),\n                columns=['household_id', 'asset_id', 'share'])\n            .set_index(['household_id', 'asset_id']))\n\n        log_return = DataFrame(dict(\n            asset_id=[\"gb00b03mlx29\", \"gb00b03mlx29\",\n                      \"gb00b03mlx29\", \"lu0197800237\", \"lu0197800237\"],\n            t=[233, 234, 235, 180, 181],\n            log_return=[.09604978, -.06524096, .03532373, .03025441, .036997]\n        )).set_index([\"asset_id\", \"t\"])\n\n        expected = (\n            DataFrame(dict(\n                household_id=[2, 2, 2, 3, 3, 3, 3, 3],\n                asset_id=[\"gb00b03mlx29\", \"gb00b03mlx29\",\n                          \"gb00b03mlx29\", \"gb00b03mlx29\",\n                          \"gb00b03mlx29\", \"gb00b03mlx29\",\n                          \"lu0197800237\", \"lu0197800237\"],\n                t=[233, 234, 235, 233, 234, 235, 180, 181],\n                share=[0.6, 0.6, 0.6, 0.15, 0.15, 0.15, 0.6, 0.6],\n                log_return=[.09604978, -.06524096, .03532373,\n                            .09604978, -.06524096, .03532373,\n                            .03025441, .036997]\n            ))\n            .set_index([\"household_id\", \"asset_id\", \"t\"])\n            .reindex(columns=['share', 'log_return']))\n\n        def f():\n            household.join(log_return, how='inner')\n        pytest.raises(NotImplementedError, f)\n\n        # this is the equivalency\n        result = (merge(household.reset_index(), log_return.reset_index(),\n                        on=['asset_id'], how='inner')\n                  .set_index(['household_id', 'asset_id', 't']))\n        assert_frame_equal(result, expected)\n\n        expected = (\n            DataFrame(dict(\n                household_id=[1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4],\n                asset_id=[\"nl0000301109\", \"nl0000289783\", \"gb00b03mlx29\",\n                          \"gb00b03mlx29\", \"gb00b03mlx29\",\n                          \"gb00b03mlx29\", \"gb00b03mlx29\", \"gb00b03mlx29\",\n                          \"lu0197800237\", \"lu0197800237\",\n                          \"nl0000289965\", None],\n                t=[None, None, 233, 234, 235, 233, 234,\n                   235, 180, 181, None, None],\n                share=[1.0, 0.4, 0.6, 0.6, 0.6, 0.15,\n                       0.15, 0.15, 0.6, 0.6, 0.25, 1.0],\n                log_return=[None, None, .09604978, -.06524096, .03532373,\n                            .09604978, -.06524096, .03532373,\n                            .03025441, .036997, None, None]\n            ))\n            .set_index([\"household_id\", \"asset_id\", \"t\"]))\n\n        def f():\n            household.join(log_return, how='outer')\n        pytest.raises(NotImplementedError, f)\n\n\nclass TestMergeDtypes(object):\n\n    @pytest.mark.parametrize('right_vals', [\n        ['foo', 'bar'],\n        Series(['foo', 'bar']).astype('category'),\n        [1, 2],\n        [1.0, 2.0],\n        Series([1, 2], dtype='uint64'),\n        Series([1, 2], dtype='int32')\n    ]\n    )\n    def test_different(self, right_vals):\n\n        left = DataFrame({'A': ['foo', 'bar'],\n                          'B': Series(['foo', 'bar']).astype('category'),\n                          'C': [1, 2],\n                          'D': [1.0, 2.0],\n                          'E': Series([1, 2], dtype='uint64'),\n                          'F': Series([1, 2], dtype='int32')})\n        right = DataFrame({'A': right_vals})\n\n        # GH 9780\n        # We allow merging on object and categorical cols and cast\n        # categorical cols to object\n        if (is_categorical_dtype(right['A'].dtype) or\n           is_object_dtype(right['A'].dtype)):\n            result = pd.merge(left, right, on='A')\n            assert is_object_dtype(result.A.dtype)\n\n        # GH 9780\n        # We raise for merging on object col and int/float col and\n        # merging on categorical col and int/float col\n        else:\n            msg = (\"You are trying to merge on \"\n                   \"{lk_dtype} and {rk_dtype} columns. \"\n                   \"If you wish to proceed you should use \"\n                   \"pd.concat\".format(lk_dtype=left['A'].dtype,\n                                      rk_dtype=right['A'].dtype))\n            with tm.assert_raises_regex(ValueError, msg):\n                pd.merge(left, right, on='A')\n\n    @pytest.mark.parametrize('d1', [np.int64, np.int32,\n                                    np.int16, np.int8, np.uint8])\n    @pytest.mark.parametrize('d2', [np.int64, np.float64,\n                                    np.float32, np.float16])\n    def test_join_multi_dtypes(self, d1, d2):\n\n        dtype1 = np.dtype(d1)\n        dtype2 = np.dtype(d2)\n\n        left = DataFrame({'k1': np.array([0, 1, 2] * 8, dtype=dtype1),\n                          'k2': ['foo', 'bar'] * 12,\n                          'v': np.array(np.arange(24), dtype=np.int64)})\n\n        index = MultiIndex.from_tuples([(2, 'bar'), (1, 'foo')])\n        right = DataFrame({'v2': np.array([5, 7], dtype=dtype2)}, index=index)\n\n        result = left.join(right, on=['k1', 'k2'])\n\n        expected = left.copy()\n\n        if dtype2.kind == 'i':\n            dtype2 = np.dtype('float64')\n        expected['v2'] = np.array(np.nan, dtype=dtype2)\n        expected.loc[(expected.k1 == 2) & (expected.k2 == 'bar'), 'v2'] = 5\n        expected.loc[(expected.k1 == 1) & (expected.k2 == 'foo'), 'v2'] = 7\n\n        tm.assert_frame_equal(result, expected)\n\n        result = left.join(right, on=['k1', 'k2'], sort=True)\n        expected.sort_values(['k1', 'k2'], kind='mergesort', inplace=True)\n        tm.assert_frame_equal(result, expected)\n\n    @pytest.mark.parametrize('int_vals, float_vals, exp_vals', [\n        ([1, 2, 3], [1.0, 2.0, 3.0], {'X': [1, 2, 3], 'Y': [1.0, 2.0, 3.0]}),\n        ([1, 2, 3], [1.0, 3.0], {'X': [1, 3], 'Y': [1.0, 3.0]}),\n        ([1, 2], [1.0, 2.0, 3.0], {'X': [1, 2], 'Y': [1.0, 2.0]}),\n    ])\n    def test_merge_on_ints_floats(self, int_vals, float_vals, exp_vals):\n        # GH 16572\n        # Check that float column is not cast to object if\n        # merging on float and int columns\n        A = DataFrame({'X': int_vals})\n        B = DataFrame({'Y': float_vals})\n        expected = DataFrame(exp_vals)\n\n        result = A.merge(B, left_on='X', right_on='Y')\n        assert_frame_equal(result, expected)\n\n        result = B.merge(A, left_on='Y', right_on='X')\n        assert_frame_equal(result, expected[['Y', 'X']])\n\n    def test_merge_on_ints_floats_warning(self):\n        # GH 16572\n        # merge will produce a warning when merging on int and\n        # float columns where the float values are not exactly\n        # equal to their int representation\n        A = DataFrame({'X': [1, 2, 3]})\n        B = DataFrame({'Y': [1.1, 2.5, 3.0]})\n        expected = DataFrame({'X': [3], 'Y': [3.0]})\n\n        with tm.assert_produces_warning(UserWarning):\n            result = A.merge(B, left_on='X', right_on='Y')\n            assert_frame_equal(result, expected)\n\n        with tm.assert_produces_warning(UserWarning):\n            result = B.merge(A, left_on='Y', right_on='X')\n            assert_frame_equal(result, expected[['Y', 'X']])\n\n    @pytest.mark.parametrize('df1_vals, df2_vals', [\n        ([0, 1, 2], [\"0\", \"1\", \"2\"]),\n        ([0.0, 1.0, 2.0], [\"0\", \"1\", \"2\"]),\n        ([0, 1, 2], [u\"0\", u\"1\", u\"2\"]),\n        (pd.date_range('1/1/2011', periods=2, freq='D'), ['2011-01-01',\n                                                          '2011-01-02']),\n        (pd.date_range('1/1/2011', periods=2, freq='D'), [0, 1]),\n        (pd.date_range('1/1/2011', periods=2, freq='D'), [0.0, 1.0]),\n        ([0, 1, 2], Series(['a', 'b', 'a']).astype('category')),\n        ([0.0, 1.0, 2.0], Series(['a', 'b', 'a']).astype('category')),\n    ])\n    def test_merge_incompat_dtypes(self, df1_vals, df2_vals):\n        # GH 9780\n        # Raise a ValueError when a user tries to merge on\n        # dtypes that are incompatible (e.g., obj and int/float)\n\n        df1 = DataFrame({'A': df1_vals})\n        df2 = DataFrame({'A': df2_vals})\n\n        msg = (\"You are trying to merge on {lk_dtype} and \"\n               \"{rk_dtype} columns. If you wish to proceed \"\n               \"you should use pd.concat\".format(lk_dtype=df1['A'].dtype,\n                                                 rk_dtype=df2['A'].dtype))\n        msg = re.escape(msg)\n        with tm.assert_raises_regex(ValueError, msg):\n            pd.merge(df1, df2, on=['A'])\n\n        # Check that error still raised when swapping order of dataframes\n        msg = (\"You are trying to merge on {lk_dtype} and \"\n               \"{rk_dtype} columns. If you wish to proceed \"\n               \"you should use pd.concat\".format(lk_dtype=df2['A'].dtype,\n                                                 rk_dtype=df1['A'].dtype))\n        msg = re.escape(msg)\n        with tm.assert_raises_regex(ValueError, msg):\n            pd.merge(df2, df1, on=['A'])\n\n\n@pytest.fixture\ndef left():\n    np.random.seed(1234)\n    return DataFrame(\n        {'X': Series(np.random.choice(\n            ['foo', 'bar'],\n            size=(10,))).astype(CDT(['foo', 'bar'])),\n         'Y': np.random.choice(['one', 'two', 'three'], size=(10,))})\n\n\n@pytest.fixture\ndef right():\n    np.random.seed(1234)\n    return DataFrame(\n        {'X': Series(['foo', 'bar']).astype(CDT(['foo', 'bar'])),\n         'Z': [1, 2]})\n\n\nclass TestMergeCategorical(object):\n\n    def test_identical(self, left):\n        # merging on the same, should preserve dtypes\n        merged = pd.merge(left, left, on='X')\n        result = merged.dtypes.sort_index()\n        expected = Series([CategoricalDtype(),\n                           np.dtype('O'),\n                           np.dtype('O')],\n                          index=['X', 'Y_x', 'Y_y'])\n        assert_series_equal(result, expected)\n\n    def test_basic(self, left, right):\n        # we have matching Categorical dtypes in X\n        # so should preserve the merged column\n        merged = pd.merge(left, right, on='X')\n        result = merged.dtypes.sort_index()\n        expected = Series([CategoricalDtype(),\n                           np.dtype('O'),\n                           np.dtype('int64')],\n                          index=['X', 'Y', 'Z'])\n        assert_series_equal(result, expected)\n\n    def test_merge_categorical(self):\n        # GH 9426\n\n        right = DataFrame({'c': {0: 'a',\n                                 1: 'b',\n                                 2: 'c',\n                                 3: 'd',\n                                 4: 'e'},\n                           'd': {0: 'null',\n                                 1: 'null',\n                                 2: 'null',\n                                 3: 'null',\n                                 4: 'null'}})\n        left = DataFrame({'a': {0: 'f',\n                                1: 'f',\n                                2: 'f',\n                                3: 'f',\n                                4: 'f'},\n                          'b': {0: 'g',\n                                1: 'g',\n                                2: 'g',\n                                3: 'g',\n                                4: 'g'}})\n        df = pd.merge(left, right, how='left', left_on='b', right_on='c')\n\n        # object-object\n        expected = df.copy()\n\n        # object-cat\n        # note that we propagate the category\n        # because we don't have any matching rows\n        cright = right.copy()\n        cright['d'] = cright['d'].astype('category')\n        result = pd.merge(left, cright, how='left', left_on='b', right_on='c')\n        expected['d'] = expected['d'].astype(CategoricalDtype(['null']))\n        tm.assert_frame_equal(result, expected)\n\n        # cat-object\n        cleft = left.copy()\n        cleft['b'] = cleft['b'].astype('category')\n        result = pd.merge(cleft, cright, how='left', left_on='b', right_on='c')\n        tm.assert_frame_equal(result, expected)\n\n        # cat-cat\n        cright = right.copy()\n        cright['d'] = cright['d'].astype('category')\n        cleft = left.copy()\n        cleft['b'] = cleft['b'].astype('category')\n        result = pd.merge(cleft, cright, how='left', left_on='b', right_on='c')\n        tm.assert_frame_equal(result, expected)\n\n    def test_other_columns(self, left, right):\n        # non-merge columns should preserve if possible\n        right = right.assign(Z=right.Z.astype('category'))\n\n        merged = pd.merge(left, right, on='X')\n        result = merged.dtypes.sort_index()\n        expected = Series([CategoricalDtype(),\n                           np.dtype('O'),\n                           CategoricalDtype()],\n                          index=['X', 'Y', 'Z'])\n        assert_series_equal(result, expected)\n\n        # categories are preserved\n        assert left.X.values.is_dtype_equal(merged.X.values)\n        assert right.Z.values.is_dtype_equal(merged.Z.values)\n\n    @pytest.mark.parametrize(\n        'change', [lambda x: x,\n                   lambda x: x.astype(CDT(['foo', 'bar', 'bah'])),\n                   lambda x: x.astype(CDT(ordered=True))])\n    @pytest.mark.parametrize('how', ['inner', 'outer', 'left', 'right'])\n    def test_dtype_on_merged_different(self, change, how, left, right):\n        # our merging columns, X now has 2 different dtypes\n        # so we must be object as a result\n\n        X = change(right.X.astype('object'))\n        right = right.assign(X=X)\n        assert is_categorical_dtype(left.X.values)\n        # assert not left.X.values.is_dtype_equal(right.X.values)\n\n        merged = pd.merge(left, right, on='X', how=how)\n\n        result = merged.dtypes.sort_index()\n        expected = Series([np.dtype('O'),\n                           np.dtype('O'),\n                           np.dtype('int64')],\n                          index=['X', 'Y', 'Z'])\n        assert_series_equal(result, expected)\n\n    def test_self_join_multiple_categories(self):\n        # GH 16767\n        # non-duplicates should work with multiple categories\n        m = 5\n        df = pd.DataFrame({\n            'a': ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'] * m,\n            'b': ['t', 'w', 'x', 'y', 'z'] * 2 * m,\n            'c': [letter\n                  for each in ['m', 'n', 'u', 'p', 'o']\n                  for letter in [each] * 2 * m],\n            'd': [letter\n                  for each in ['aa', 'bb', 'cc', 'dd', 'ee',\n                               'ff', 'gg', 'hh', 'ii', 'jj']\n                  for letter in [each] * m]})\n\n        # change them all to categorical variables\n        df = df.apply(lambda x: x.astype('category'))\n\n        # self-join should equal ourselves\n        result = pd.merge(df, df, on=list(df.columns))\n\n        assert_frame_equal(result, df)\n\n    def test_dtype_on_categorical_dates(self):\n        # GH 16900\n        # dates should not be coerced to ints\n\n        df = pd.DataFrame(\n            [[date(2001, 1, 1), 1.1],\n             [date(2001, 1, 2), 1.3]],\n            columns=['date', 'num2']\n        )\n        df['date'] = df['date'].astype('category')\n\n        df2 = pd.DataFrame(\n            [[date(2001, 1, 1), 1.3],\n             [date(2001, 1, 3), 1.4]],\n            columns=['date', 'num4']\n        )\n        df2['date'] = df2['date'].astype('category')\n\n        expected_outer = pd.DataFrame([\n            [pd.Timestamp('2001-01-01'), 1.1, 1.3],\n            [pd.Timestamp('2001-01-02'), 1.3, np.nan],\n            [pd.Timestamp('2001-01-03'), np.nan, 1.4]],\n            columns=['date', 'num2', 'num4']\n        )\n        result_outer = pd.merge(df, df2, how='outer', on=['date'])\n        assert_frame_equal(result_outer, expected_outer)\n\n        expected_inner = pd.DataFrame(\n            [[pd.Timestamp('2001-01-01'), 1.1, 1.3]],\n            columns=['date', 'num2', 'num4']\n        )\n        result_inner = pd.merge(df, df2, how='inner', on=['date'])\n        assert_frame_equal(result_inner, expected_inner)\n\n    @pytest.mark.parametrize('ordered', [True, False])\n    @pytest.mark.parametrize('category_column,categories,expected_categories',\n                             [([False, True, True, False], [True, False],\n                               [True, False]),\n                              ([2, 1, 1, 2], [1, 2], [1, 2]),\n                              (['False', 'True', 'True', 'False'],\n                               ['True', 'False'], ['True', 'False'])])\n    def test_merging_with_bool_or_int_cateorical_column(self, category_column,\n                                                        categories,\n                                                        expected_categories,\n                                                        ordered):\n        # GH 17187\n        # merging with a boolean/int categorical column\n        df1 = pd.DataFrame({'id': [1, 2, 3, 4],\n                            'cat': category_column})\n        df1['cat'] = df1['cat'].astype(CDT(categories, ordered=ordered))\n        df2 = pd.DataFrame({'id': [2, 4], 'num': [1, 9]})\n        result = df1.merge(df2)\n        expected = pd.DataFrame({'id': [2, 4], 'cat': expected_categories,\n                                 'num': [1, 9]})\n        expected['cat'] = expected['cat'].astype(\n            CDT(categories, ordered=ordered))\n        assert_frame_equal(expected, result)\n\n\n@pytest.fixture\ndef left_df():\n    return DataFrame({'a': [20, 10, 0]}, index=[2, 1, 0])\n\n\n@pytest.fixture\ndef right_df():\n    return DataFrame({'b': [300, 100, 200]}, index=[3, 1, 2])\n\n\nclass TestMergeOnIndexes(object):\n\n    @pytest.mark.parametrize(\n        \"how, sort, expected\",\n        [('inner', False, DataFrame({'a': [20, 10],\n                                     'b': [200, 100]},\n                                    index=[2, 1])),\n         ('inner', True, DataFrame({'a': [10, 20],\n                                    'b': [100, 200]},\n                                   index=[1, 2])),\n         ('left', False, DataFrame({'a': [20, 10, 0],\n                                    'b': [200, 100, np.nan]},\n                                   index=[2, 1, 0])),\n         ('left', True, DataFrame({'a': [0, 10, 20],\n                                   'b': [np.nan, 100, 200]},\n                                  index=[0, 1, 2])),\n         ('right', False, DataFrame({'a': [np.nan, 10, 20],\n                                     'b': [300, 100, 200]},\n                                    index=[3, 1, 2])),\n         ('right', True, DataFrame({'a': [10, 20, np.nan],\n                                    'b': [100, 200, 300]},\n                                   index=[1, 2, 3])),\n         ('outer', False, DataFrame({'a': [0, 10, 20, np.nan],\n                                     'b': [np.nan, 100, 200, 300]},\n                                    index=[0, 1, 2, 3])),\n         ('outer', True, DataFrame({'a': [0, 10, 20, np.nan],\n                                    'b': [np.nan, 100, 200, 300]},\n                                   index=[0, 1, 2, 3]))])\n    def test_merge_on_indexes(self, left_df, right_df, how, sort, expected):\n\n        result = pd.merge(left_df, right_df,\n                          left_index=True,\n                          right_index=True,\n                          how=how,\n                          sort=sort)\n        tm.assert_frame_equal(result, expected)\n"
    }
  ],
  "questions": [
    "@inodb @jreback: I would like to take a stab at this. From what I can understand, I need to check the datatypes of the columns that are to be merged, and if they're unequal then throw an error. Could you tell me what type of error ? Thanks.",
    "@jorisvandenbossche can you show example / elaborate on your last?\n\n> On a second thought, if we disallow merging on str/numeric (the case of the initial example), I don't think are cases left that we would allow but where no coercing should happen? (for which I wanted to open an new issue)",
    "Well, the original example above has a dataframe with integers in the key column, and another dataframe with strings in the key column. They are now coerced to integers, something I think should not happen:\n\n```\nIn [62]: df1 = pd.DataFrame({\"A\":[0], \"B\":[1]})\n\nIn [63]: df2 = pd.DataFrame({\"A\":[\"0\"], \"B\":[2]})\n\nIn [64]: pd.merge(df1, df2, on=[\"A\"],how='outer')\nOut[64]: \n   A  B_x  B_y\n0  0  1.0  NaN\n1  0  NaN  2.0\n\nIn [65]: pd.merge(df1, df2, on=[\"A\"],how='outer').A.dtype\nOut[65]: dtype('int64')\n\nIn [66]: pd.merge(df1, df2, on=[\"A\"],how='outer').A.values\nOut[66]: array([0, 0])\n```\n\nAnd I wanted to open an new issue for this. But, this is also an example where we would want to raise an error about \"incompatible columns to merge on\". \nSo would there still be cases where we would not raise such an error, but still happens unwanted coercing?",
    "Was #18764 included in the Pandas 0.22.0 release? It looks like @jreback added that to the 0.22.0 milestone on Dec 7, 2017, and it was merged to master 19 days before 0.22.0 was released, but the initial example still fails for me on 0.22.0:\r\n\r\n>    ```py\r\n>    >>> import pandas as pd\r\n>    >>> df1 = pd.DataFrame({\"A\": [0]})\r\n>    >>> df2 = pd.DataFrame({\"A\": [\"0\"]})\r\n>    >>> pd.merge(df1, df2, on=[\"A\"])\r\n>    Empty DataFrame\r\n>    Columns: [A]\r\n>    Index: []\r\n>    ``` \r\n\r\n```py\r\n>>> pd.show_versions()\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.4.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.13.0-37-generic\r\nmachine: x86_64\r\nprocessor: x86_64\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.22.0\r\npytest: 3.4.0\r\npip: 9.0.1\r\nsetuptools: 38.5.1\r\nCython: 0.27.3\r\nnumpy: 1.14.1\r\nscipy: 1.0.0\r\npyarrow: 0.8.0\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.7.1\r\npatsy: 0.5.0\r\ndateutil: 2.6.1\r\npytz: 2018.3\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: 0.4.0\r\nmatplotlib: 2.1.2\r\nopenpyxl: 2.5.0\r\nxlrd: 1.1.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 1.0.2\r\nlxml: 4.1.1\r\nbs4: 4.6.0\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.2.3\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: 0.1.4\r\npandas_gbq: None\r\npandas_datareader: None\r\n```"
  ],
  "golden_answers": [
    "this should raise a `ValueError` if the dtypes for the on columns don't match",
    "Well, the original example above has a dataframe with integers in the key column, and another dataframe with strings in the key column. They are now coerced to integers, something I think should not happen:\n\n```\nIn [62]: df1 = pd.DataFrame({\"A\":[0], \"B\":[1]})\n\nIn [63]: df2 = pd.DataFrame({\"A\":[\"0\"], \"B\":[2]})\n\nIn [64]: pd.merge(df1, df2, on=[\"A\"],how='outer')\nOut[64]: \n   A  B_x  B_y\n0  0  1.0  NaN\n1  0  NaN  2.0\n\nIn [65]: pd.merge(df1, df2, on=[\"A\"],how='outer').A.dtype\nOut[65]: dtype('int64')\n\nIn [66]: pd.merge(df1, df2, on=[\"A\"],how='outer').A.values\nOut[66]: array([0, 0])\n```\n\nAnd I wanted to open an new issue for this. But, this is also an example where we would want to raise an error about \"incompatible columns to merge on\". \nSo would there still be cases where we would not raise such an error, but still happens unwanted coercing?",
    "ah I c. I think this should raise a nice errors message (maybe saying that you might want to use `pd.concat`), which will simply work.\n\nconcat\n\n```\nIn [16]: pd.concat([df1,df2])\nOut[16]:\n   A\n0  0\n0  0\n\nIn [17]: pd.concat([df1,df2]).dtypes\nOut[17]:\nA    object\ndtype: object\n\nIn [18]: pd.concat([df1,df2]).values\nOut[18]:\narray([[0],\n       ['0']], dtype=object)\n```\n\nmerge\n\n```\nIn [19]: pd.merge(df1, df2, on ='A')\nOut[19]:\nEmpty DataFrame\nColumns: [A]\nIndex: []\n\nIn [20]: pd.merge(df1, df2, on ='A', how='outer')\nOut[20]:\n   A\n0  0\n1  0\n\nIn [21]: pd.merge(df1, df2, on ='A', how='outer').dtypes\nOut[21]:\nA    int64\ndtype: object\n```\n\nso [20,21] are wrong (this should be `object`).\n\nBut I would actually simply raise `ValueError` on the merge. Its a mistake on the users part.",
    "https://github.com/pandas-dev/pandas/pull/18674 will be in the 0.23 release.\r\n\r\nThe 0.22 release just had one change. You can always view the release notes for a version at http://pandas.pydata.org/pandas-docs/stable/whatsnew.html."
  ],
  "questions_generated": [
    "Why does pd.merge() return an empty DataFrame when merging columns of int and str dtypes, and what would be an appropriate solution?",
    "In the context of the pandas-dev/pandas repository, how does the merge function handle dtype mismatches, and what changes are suggested to improve this behavior?",
    "How does the merge function in pandas determine which dtypes are incompatible for merging, according to the discussion?",
    "What are the key components of the pandas merge function's implementation in the provided code context?",
    "How can a user explicitly convert column dtypes to avoid issues when using pd.merge()?",
    "What are the potential implications of implementing a dtype check in the pandas merge function, and how might it affect existing code?"
  ],
  "golden_answers_generated": [
    "The pd.merge() function performs an inner join by default, which results in an empty DataFrame when trying to match on columns with incompatible dtypes, such as int and str. An appropriate solution could be to raise a warning or error when attempting to merge columns with incompatible dtypes. This would alert the user to the mismatch. Alternatively, converting the dtypes to be compatible before merging would prevent this issue.",
    "Currently, the pandas merge function does not provide any warnings or errors when trying to merge columns with mismatched dtypes like int and str, which results in an empty DataFrame. The suggested improvement is to raise a ValueError when there are obvious dtype mismatches that cannot be silently cast to match, enhancing the user's ability to debug and correct their data before merging.",
    "According to the discussion, the merge function should raise a ValueError for 'obvious' mismatches, such as when one column is of 'object' dtype and the other is of 'int/float' dtype. The suggestion is to not raise errors for int and float dtype combinations, as they can typically be cast to a compatible dtype.",
    "The merge function is implemented in the pandas/core/reshape/merge.py file. It utilizes the _MergeOperation class to perform the merge operation. The function accepts parameters like how, on, left_on, right_on, and suffixes, among others, to customize the merge behavior. It also imports several utility functions and constants from pandas.core.dtypes to handle dtype checks and conversions.",
    "To avoid dtype mismatch issues when using pd.merge(), a user can explicitly convert the column dtypes to a common type before merging. For instance, using the df.convert_objects(convert_numeric=True) method can convert strings that look like numbers to numeric types. Alternatively, users can use the astype() method to convert columns to a specific dtype manually.",
    "Implementing a dtype check that raises an error for mismatched dtypes in the pandas merge function could improve error detection and data integrity. However, it might also affect existing code by breaking merges that previously returned empty DataFrames without warnings. Users may need to update their data preprocessing steps to ensure compatible dtypes before merging, which could involve additional data conversion or cleaning processes."
  ]
}