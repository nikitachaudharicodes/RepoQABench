{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "49939",
  "issue_description": "# DOC: better explain the automatic alignment process\n\n### Pandas version checks\n\n- [X] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)\n\n\n### Location of the documentation\n\nThroughtout https://pandas.pydata.org/pandas-docs/stable/index.html\n\n### Documentation problem\n\n> I'd like to mention documentation again, for emphasis.  A someone who found the automatic data alignment 'confusing', I think I offer a unique perspective to this problem (at least on this thread).  For example, I'm currently dealing with numpy shape.  When looking at the documentation for np.shape it would have been helpful if it simply mentioned that it was row X columns when I looked np.shape rather the just \"array dimensions\" (same amount of characters!).  Smirk, if you wish, but these minor details here and there repeated can go along way to helping folks new to these frameworks out.\r\n> \r\n\r\nOriginally reported by @blazespinnaker [here](https://github.com/pandas-dev/pandas/pull/49694#issuecomment-1328701631)\n\n### Suggested fix for documentation\n\n> For this problem, a quick note in different operations such as sum could say \r\n> \r\n> `\r\n> *Note automatic data alignment:  as with all pandas operations, automatic data alignment is performed.  If sum does not find values with matching indicies than NaN will used as the total.   \r\n> `\r\n> \r\n> An example would even be even more awesome.\r\n> \r\n> \r\n> Note that my text is probably very poor, but ideally it would be written in a way to make alignment less confusing to new users.\r\n> \r\n> \r\n\r\nOriginally reported by @blazespinnaker [here](https://github.com/pandas-dev/pandas/pull/49694#issuecomment-1328701631)",
  "issue_comments": [
    {
      "id": 1329891816,
      "user": "jbrockmendel",
      "body": "I wouldn’t object to deprecating automatic alignment"
    },
    {
      "id": 1330665194,
      "user": "MarcoGorelli",
      "body": "> I wouldn’t object to deprecating automatic alignment\r\n\r\nReally? I hadn't even realised this was on the table. If so, then I love this idea.\r\n\r\nWould the idea be:\r\n- if indices are already aligned, proceed as per status quo\r\n- if they're not aligned, then throw an error, advising users to call `.align`?\r\n\r\nLike this, then advanced users who really use the power of indices just need to add an extra `.align` call, and beginner/intermediate users won't have surprises because of unexpected \"magical\" alignment under the hood. Similarly to #49946\r\n\r\nThis would also be similar to @blazespinnaker 's comment https://github.com/pandas-dev/pandas/pull/49694#issuecomment-1321287026 , except that instead of there being a global option to control this, users would get a loud and clear error. In which case, thanks @blazespinnaker , and I'm sorry for having said that your comment was off-topic (I still think it's better to keep this discussion separate from PDEP0005 though)\r\n\r\nExample of where to get to:\r\n```python\r\n>>> ser1 = pd.Series([1,2,3])\r\n>>> ser2 = pd.Series([4, 1, 2], index=[0, 1, 3])\r\n>>> ser1 + ser2\r\n---\r\nValueError: Operands are not aligned. Do `left, right = left.align(right, axis=0, copy=False)` before operating.\r\n```"
    },
    {
      "id": 1331977223,
      "user": "MarcoGorelli",
      "body": "I guess it's time for another @pandas-dev/pandas-core @pandas-dev/pandas-triage tag ... before putting together another PDEP, anyone have any initial thoughts on deprecating automatic alignment?\r\n\r\nI like the idea, as it would mean:\r\n- simplifying the codebase\r\n- fewer surprises for users\r\n- advanced users relying on automatic alignment can just add an extra `.align` call and proceed as before"
    },
    {
      "id": 1332232115,
      "user": "Dr-Irv",
      "body": "Related #47554 \r\n\r\nOne thing to consider is that this would mess up doing chaining.  For example, right now, you can do `(s1 + s2).dropna()`, but if you have to align first, I don't see how to do that in a chain.\r\n\r\nThere are some advantages to automatic alignment, in terms of when exploring data, it helps you identify missing data quite easily.\r\n"
    },
    {
      "id": 1332296620,
      "user": "MarcoGorelli",
      "body": "For chaining, you could do\r\n```python\r\nfunctools.reduce(lambda lhs, rhs: lhs + rhs, s1.align(s2)).dropna()\r\n```\r\nThis is kinda advanced, perhaps, but I think it's only advanced users that intentionally rely on automated alignment anyway.\r\n\r\nFor identifying missing data, I think this would be even better - a loud and clear error immediately alerts you of missing data, whereas silent automated alignment introduces `NaN`s which propagate throughout subsequent operations and can go undetected"
    },
    {
      "id": 1333086085,
      "user": "rhshadrach",
      "body": "I'm pretty negative on deprecating this, to me auto-alignment is one of the key features of pandas that makes data wrangling significantly easier. I think having `functools.reduce(lambda lhs, rhs: lhs + rhs, s1.align(s2))` as an alternative to `s1 + s2` highlights this.\r\n\r\nIn my use, data at various levels of aggregation for products can be uniquely indexed by `(location, product id, time)`. Various data is specified by a subset of these. For example, product description or size is by `(product id, )` alone; a forecast model will have parameters that depend only on `(location, product id)`; price of a product on `(location, product id, time)`; manufacturer on `(product id, time)`. By using these as a multiindex, one can combine various data sources naturally. For example:\r\n\r\n```\r\ndf1 = pd.DataFrame({'a': [1, 1, 2], 'b': [3, 4, 5], 'c': [6, 7, 8]}).set_index(['a', 'b'])\r\ndf2 = pd.DataFrame({'a': [1, 2], 'd': [10, 100]}).set_index('a')\r\nresult = df1['c'] * df2['d']\r\nprint(result)\r\n# a  b\r\n# 1  3     60\r\n#    4     70\r\n# 2  5    800\r\n# dtype: int64\r\n```\r\n\r\nThis is natural and pleasant. Without this, each operation needs to first join to a temporary frame.\r\n"
    },
    {
      "id": 1333465553,
      "user": "MarcoGorelli",
      "body": "That's a nice example, thanks Richard!\r\n\r\nAn alternative suggested by Brock was to only deprecate auto-alignment in dunder operations. So in your example,\r\n```\r\n>>> df1['c'] * df2['d']\r\nValueError: Operands are not aligned, use align before operating or use .mul instead of *\r\n```\r\nwork throw an error, but\r\n```\r\ndf1['c'].mul(df2['d'])\r\n```\r\nwould work as it currently does\r\n\r\nThis would retain the natural and pleasant functionality for advanced users, whilst ending up with fewer surprises for others"
    },
    {
      "id": 1336483133,
      "user": "rhshadrach",
      "body": "Thanks @MarcoGorelli - while still having a way use these dunders with alignment does make me less negative to this proposal, I still think there are issues. Please correct any of these if they are wrong!\r\n\r\n - There would be no \"natural\" equivalent to `df[\"a\"] + df[\"b\"]` when a user wants to the operation while method chaining\r\n - There would be an inconsistent behavior between `df.__add__` and `df.add`.\r\n - By only having alignment via `.add` et al, the user is forced into functional syntax if they want alignment. This can quite unreadable for even moderately complex formulae.\r\n\r\nMore generally, it seems to me the main motivation behind this proposal is that it would make pandas easier for new users. If there are other motivations (@jbrockmendel - I'm curious what your motivation is in particular), I think they would be good to identify. While I'm all for making pandas easier new users, I do not think we should be doing so at the expense of expert usage."
    },
    {
      "id": 1337878818,
      "user": "jbrockmendel",
      "body": "> (@jbrockmendel - I'm curious what your motivation is in particular)\r\n\r\nI am not actively advocating the idea.  I suggested it as an alternative to the NoIndex-mode given that the motivation seemed to be \"automatic alignment is a major pain point\"."
    },
    {
      "id": 1366642985,
      "user": "blazespinnaker",
      "body": "A place where documentation could be very helpful is in auto alignment and correlation.   The results can be very surprising at their confidence even though what you're doing makes no sense at all."
    },
    {
      "id": 1366669144,
      "user": "MarcoGorelli",
      "body": "Thanks @rhshadrach , those are some valid points\r\n\r\nYou're right about what my main motivation is\r\n\r\nMaybe we just need to document this more clearly, with a visible note in every operation which aligns redirecting to some page in the user guide\r\n\r\n---\r\n\r\nI've updated this to be a docs issue. If anyone would like to work on it, please do comment, happy to help out, it would be good to get better docs on this one"
    },
    {
      "id": 1493146817,
      "user": "EltarrLok",
      "body": "take"
    },
    {
      "id": 1614864412,
      "user": "rsm-23",
      "body": "Hey @MarcoGorelli  I can take this up. I would need some guidance though :)"
    },
    {
      "id": 1616629070,
      "user": "MarcoGorelli",
      "body": "nice, thanks! I think all that's needed are some notes saying that in general, pandas operations align on the index, perhaps starting with `.corr` (which was part of the motivation for the issue)"
    },
    {
      "id": 1616681811,
      "user": "rsm-23",
      "body": "take"
    },
    {
      "id": 1616689060,
      "user": "rsm-23",
      "body": "@MarcoGorelli  once this looks fine, I can create PRs for other functions. "
    },
    {
      "id": 1617633213,
      "user": "rsm-23",
      "body": "@MarcoGorelli please review the PR when you get time."
    }
  ],
  "text_context": "# DOC: better explain the automatic alignment process\n\n### Pandas version checks\n\n- [X] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)\n\n\n### Location of the documentation\n\nThroughtout https://pandas.pydata.org/pandas-docs/stable/index.html\n\n### Documentation problem\n\n> I'd like to mention documentation again, for emphasis.  A someone who found the automatic data alignment 'confusing', I think I offer a unique perspective to this problem (at least on this thread).  For example, I'm currently dealing with numpy shape.  When looking at the documentation for np.shape it would have been helpful if it simply mentioned that it was row X columns when I looked np.shape rather the just \"array dimensions\" (same amount of characters!).  Smirk, if you wish, but these minor details here and there repeated can go along way to helping folks new to these frameworks out.\r\n> \r\n\r\nOriginally reported by @blazespinnaker [here](https://github.com/pandas-dev/pandas/pull/49694#issuecomment-1328701631)\n\n### Suggested fix for documentation\n\n> For this problem, a quick note in different operations such as sum could say \r\n> \r\n> `\r\n> *Note automatic data alignment:  as with all pandas operations, automatic data alignment is performed.  If sum does not find values with matching indicies than NaN will used as the total.   \r\n> `\r\n> \r\n> An example would even be even more awesome.\r\n> \r\n> \r\n> Note that my text is probably very poor, but ideally it would be written in a way to make alignment less confusing to new users.\r\n> \r\n> \r\n\r\nOriginally reported by @blazespinnaker [here](https://github.com/pandas-dev/pandas/pull/49694#issuecomment-1328701631)\n\nI wouldn’t object to deprecating automatic alignment\n\n> I wouldn’t object to deprecating automatic alignment\r\n\r\nReally? I hadn't even realised this was on the table. If so, then I love this idea.\r\n\r\nWould the idea be:\r\n- if indices are already aligned, proceed as per status quo\r\n- if they're not aligned, then throw an error, advising users to call `.align`?\r\n\r\nLike this, then advanced users who really use the power of indices just need to add an extra `.align` call, and beginner/intermediate users won't have surprises because of unexpected \"magical\" alignment under the hood. Similarly to #49946\r\n\r\nThis would also be similar to @blazespinnaker 's comment https://github.com/pandas-dev/pandas/pull/49694#issuecomment-1321287026 , except that instead of there being a global option to control this, users would get a loud and clear error. In which case, thanks @blazespinnaker , and I'm sorry for having said that your comment was off-topic (I still think it's better to keep this discussion separate from PDEP0005 though)\r\n\r\nExample of where to get to:\r\n```python\r\n>>> ser1 = pd.Series([1,2,3])\r\n>>> ser2 = pd.Series([4, 1, 2], index=[0, 1, 3])\r\n>>> ser1 + ser2\r\n---\r\nValueError: Operands are not aligned. Do `left, right = left.align(right, axis=0, copy=False)` before operating.\r\n```\n\nI guess it's time for another @pandas-dev/pandas-core @pandas-dev/pandas-triage tag ... before putting together another PDEP, anyone have any initial thoughts on deprecating automatic alignment?\r\n\r\nI like the idea, as it would mean:\r\n- simplifying the codebase\r\n- fewer surprises for users\r\n- advanced users relying on automatic alignment can just add an extra `.align` call and proceed as before\n\nRelated #47554 \r\n\r\nOne thing to consider is that this would mess up doing chaining.  For example, right now, you can do `(s1 + s2).dropna()`, but if you have to align first, I don't see how to do that in a chain.\r\n\r\nThere are some advantages to automatic alignment, in terms of when exploring data, it helps you identify missing data quite easily.\r\n\n\nFor chaining, you could do\r\n```python\r\nfunctools.reduce(lambda lhs, rhs: lhs + rhs, s1.align(s2)).dropna()\r\n```\r\nThis is kinda advanced, perhaps, but I think it's only advanced users that intentionally rely on automated alignment anyway.\r\n\r\nFor identifying missing data, I think this would be even better - a loud and clear error immediately alerts you of missing data, whereas silent automated alignment introduces `NaN`s which propagate throughout subsequent operations and can go undetected\n\nI'm pretty negative on deprecating this, to me auto-alignment is one of the key features of pandas that makes data wrangling significantly easier. I think having `functools.reduce(lambda lhs, rhs: lhs + rhs, s1.align(s2))` as an alternative to `s1 + s2` highlights this.\r\n\r\nIn my use, data at various levels of aggregation for products can be uniquely indexed by `(location, product id, time)`. Various data is specified by a subset of these. For example, product description or size is by `(product id, )` alone; a forecast model will have parameters that depend only on `(location, product id)`; price of a product on `(location, product id, time)`; manufacturer on `(product id, time)`. By using these as a multiindex, one can combine various data sources naturally. For example:\r\n\r\n```\r\ndf1 = pd.DataFrame({'a': [1, 1, 2], 'b': [3, 4, 5], 'c': [6, 7, 8]}).set_index(['a', 'b'])\r\ndf2 = pd.DataFrame({'a': [1, 2], 'd': [10, 100]}).set_index('a')\r\nresult = df1['c'] * df2['d']\r\nprint(result)\r\n# a  b\r\n# 1  3     60\r\n#    4     70\r\n# 2  5    800\r\n# dtype: int64\r\n```\r\n\r\nThis is natural and pleasant. Without this, each operation needs to first join to a temporary frame.\r\n\n\nThat's a nice example, thanks Richard!\r\n\r\nAn alternative suggested by Brock was to only deprecate auto-alignment in dunder operations. So in your example,\r\n```\r\n>>> df1['c'] * df2['d']\r\nValueError: Operands are not aligned, use align before operating or use .mul instead of *\r\n```\r\nwork throw an error, but\r\n```\r\ndf1['c'].mul(df2['d'])\r\n```\r\nwould work as it currently does\r\n\r\nThis would retain the natural and pleasant functionality for advanced users, whilst ending up with fewer surprises for others\n\nThanks @MarcoGorelli - while still having a way use these dunders with alignment does make me less negative to this proposal, I still think there are issues. Please correct any of these if they are wrong!\r\n\r\n - There would be no \"natural\" equivalent to `df[\"a\"] + df[\"b\"]` when a user wants to the operation while method chaining\r\n - There would be an inconsistent behavior between `df.__add__` and `df.add`.\r\n - By only having alignment via `.add` et al, the user is forced into functional syntax if they want alignment. This can quite unreadable for even moderately complex formulae.\r\n\r\nMore generally, it seems to me the main motivation behind this proposal is that it would make pandas easier for new users. If there are other motivations (@jbrockmendel - I'm curious what your motivation is in particular), I think they would be good to identify. While I'm all for making pandas easier new users, I do not think we should be doing so at the expense of expert usage.\n\n> (@jbrockmendel - I'm curious what your motivation is in particular)\r\n\r\nI am not actively advocating the idea.  I suggested it as an alternative to the NoIndex-mode given that the motivation seemed to be \"automatic alignment is a major pain point\".\n\nA place where documentation could be very helpful is in auto alignment and correlation.   The results can be very surprising at their confidence even though what you're doing makes no sense at all.\n\nThanks @rhshadrach , those are some valid points\r\n\r\nYou're right about what my main motivation is\r\n\r\nMaybe we just need to document this more clearly, with a visible note in every operation which aligns redirecting to some page in the user guide\r\n\r\n---\r\n\r\nI've updated this to be a docs issue. If anyone would like to work on it, please do comment, happy to help out, it would be good to get better docs on this one\n\ntake\n\nHey @MarcoGorelli  I can take this up. I would need some guidance though :)\n\nnice, thanks! I think all that's needed are some notes saying that in general, pandas operations align on the index, perhaps starting with `.corr` (which was part of the motivation for the issue)\n\ntake\n\n@MarcoGorelli  once this looks fine, I can create PRs for other functions. \n\n@MarcoGorelli please review the PR when you get time.",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/49694",
  "code_context": [
    {
      "filename": "web/pandas_web.py",
      "content": "#!/usr/bin/env python3\n\"\"\"\nSimple static site generator for the pandas web.\n\npandas_web.py takes a directory as parameter, and copies all the files into the\ntarget directory after converting markdown files into html and rendering both\nmarkdown and html files with a context. The context is obtained by parsing\nthe file ``config.yml`` in the root of the source directory.\n\nThe file should contain:\n```\nmain:\n  template_path: <path_to_the_jinja2_templates_directory>\n  base_template: <template_file_all_other_files_will_extend>\n  ignore:\n  - <list_of_files_in_the_source_that_will_not_be_copied>\n  github_repo_url: <organization/repo-name>\n  context_preprocessors:\n  - <list_of_functions_that_will_enrich_the_context_parsed_in_this_file>\n  markdown_extensions:\n  - <list_of_markdown_extensions_that_will_be_loaded>\n```\n\nThe rest of the items in the file will be added directly to the context.\n\"\"\"\nimport argparse\nimport collections\nimport datetime\nimport importlib\nimport json\nimport operator\nimport os\nimport pathlib\nimport re\nimport shutil\nimport sys\nimport time\nimport typing\n\nimport feedparser\nimport jinja2\nimport markdown\nimport requests\nimport yaml\n\napi_token = os.environ.get(\"GITHUB_TOKEN\")\nif api_token is not None:\n    GITHUB_API_HEADERS = {\"Authorization\": f\"Bearer {api_token}\"}\nelse:\n    GITHUB_API_HEADERS = {}\n\n\nclass Preprocessors:\n    \"\"\"\n    Built-in context preprocessors.\n\n    Context preprocessors are functions that receive the context used to\n    render the templates, and enriches it with additional information.\n\n    The original context is obtained by parsing ``config.yml``, and\n    anything else needed just be added with context preprocessors.\n    \"\"\"\n\n    @staticmethod\n    def current_year(context):\n        \"\"\"\n        Add the current year to the context, so it can be used for the copyright\n        note, or other places where it is needed.\n        \"\"\"\n        context[\"current_year\"] = datetime.datetime.now().year\n        return context\n\n    @staticmethod\n    def navbar_add_info(context):\n        \"\"\"\n        Items in the main navigation bar can be direct links, or dropdowns with\n        subitems. This context preprocessor adds a boolean field\n        ``has_subitems`` that tells which one of them every element is. It\n        also adds a ``slug`` field to be used as a CSS id.\n        \"\"\"\n        for i, item in enumerate(context[\"navbar\"]):\n            context[\"navbar\"][i] = dict(\n                item,\n                has_subitems=isinstance(item[\"target\"], list),\n                slug=(item[\"name\"].replace(\" \", \"-\").lower()),\n            )\n        return context\n\n    @staticmethod\n    def blog_add_posts(context):\n        \"\"\"\n        Given the blog feed defined in the configuration yaml, this context\n        preprocessor fetches the posts in the feeds, and returns the relevant\n        information for them (sorted from newest to oldest).\n        \"\"\"\n        tag_expr = re.compile(\"<.*?>\")\n        posts = []\n        # posts from the file system\n        if context[\"blog\"][\"posts_path\"]:\n            posts_path = os.path.join(\n                context[\"source_path\"], *context[\"blog\"][\"posts_path\"].split(\"/\")\n            )\n            for fname in os.listdir(posts_path):\n                if fname.startswith(\"index.\"):\n                    continue\n                link = (\n                    f\"/{context['blog']['posts_path']}\"\n                    f\"/{os.path.splitext(fname)[0]}.html\"\n                )\n                md = markdown.Markdown(\n                    extensions=context[\"main\"][\"markdown_extensions\"]\n                )\n                with open(os.path.join(posts_path, fname)) as f:\n                    html = md.convert(f.read())\n                title = md.Meta[\"title\"][0]\n                summary = re.sub(tag_expr, \"\", html)\n                try:\n                    body_position = summary.index(title) + len(title)\n                except ValueError:\n                    raise ValueError(\n                        f'Blog post \"{fname}\" should have a markdown header '\n                        f'corresponding to its \"Title\" element \"{title}\"'\n                    )\n                summary = \" \".join(summary[body_position:].split(\" \")[:30])\n                posts.append(\n                    {\n                        \"title\": title,\n                        \"author\": context[\"blog\"][\"author\"],\n                        \"published\": datetime.datetime.strptime(\n                            md.Meta[\"date\"][0], \"%Y-%m-%d\"\n                        ),\n                        \"feed\": context[\"blog\"][\"feed_name\"],\n                        \"link\": link,\n                        \"description\": summary,\n                        \"summary\": summary,\n                    }\n                )\n        # posts from rss feeds\n        for feed_url in context[\"blog\"][\"feed\"]:\n            feed_data = feedparser.parse(feed_url)\n            for entry in feed_data.entries:\n                published = datetime.datetime.fromtimestamp(\n                    time.mktime(entry.published_parsed)\n                )\n                summary = re.sub(tag_expr, \"\", entry.summary)\n                posts.append(\n                    {\n                        \"title\": entry.title,\n                        \"author\": entry.author,\n                        \"published\": published,\n                        \"feed\": feed_data[\"feed\"][\"title\"],\n                        \"link\": entry.link,\n                        \"description\": entry.description,\n                        \"summary\": summary,\n                    }\n                )\n        posts.sort(key=operator.itemgetter(\"published\"), reverse=True)\n        context[\"blog\"][\"posts\"] = posts[: context[\"blog\"][\"num_posts\"]]\n        return context\n\n    @staticmethod\n    def maintainers_add_info(context):\n        \"\"\"\n        Given the active maintainers defined in the yaml file, it fetches\n        the GitHub user information for them.\n        \"\"\"\n        repeated = set(context[\"maintainers\"][\"active\"]) & set(\n            context[\"maintainers\"][\"inactive\"]\n        )\n        if repeated:\n            raise ValueError(f\"Maintainers {repeated} are both active and inactive\")\n\n        maintainers_info = {}\n        for user in (\n            context[\"maintainers\"][\"active\"] + context[\"maintainers\"][\"inactive\"]\n        ):\n            resp = requests.get(\n                f\"https://api.github.com/users/{user}\", headers=GITHUB_API_HEADERS\n            )\n            if resp.status_code == 403:\n                sys.stderr.write(\n                    \"WARN: GitHub API quota exceeded when fetching maintainers\\n\"\n                )\n                # if we exceed github api quota, we use the github info\n                # of maintainers saved with the website\n                resp_bkp = requests.get(\n                    context[\"main\"][\"production_url\"] + \"maintainers.json\"\n                )\n                resp_bkp.raise_for_status()\n                maintainers_info = resp_bkp.json()\n                break\n\n            resp.raise_for_status()\n            maintainers_info[user] = resp.json()\n\n        context[\"maintainers\"][\"github_info\"] = maintainers_info\n\n        # save the data fetched from github to use it in case we exceed\n        # git github api quota in the future\n        with open(pathlib.Path(context[\"target_path\"]) / \"maintainers.json\", \"w\") as f:\n            json.dump(maintainers_info, f)\n\n        return context\n\n    @staticmethod\n    def home_add_releases(context):\n        context[\"releases\"] = []\n\n        github_repo_url = context[\"main\"][\"github_repo_url\"]\n        resp = requests.get(\n            f\"https://api.github.com/repos/{github_repo_url}/releases\",\n            headers=GITHUB_API_HEADERS,\n        )\n        if resp.status_code == 403:\n            sys.stderr.write(\"WARN: GitHub API quota exceeded when fetching releases\\n\")\n            resp_bkp = requests.get(context[\"main\"][\"production_url\"] + \"releases.json\")\n            resp_bkp.raise_for_status()\n            releases = resp_bkp.json()\n        else:\n            resp.raise_for_status()\n            releases = resp.json()\n\n        with open(pathlib.Path(context[\"target_path\"]) / \"releases.json\", \"w\") as f:\n            json.dump(releases, f, default=datetime.datetime.isoformat)\n\n        for release in releases:\n            if release[\"prerelease\"]:\n                continue\n            published = datetime.datetime.strptime(\n                release[\"published_at\"], \"%Y-%m-%dT%H:%M:%SZ\"\n            )\n            context[\"releases\"].append(\n                {\n                    \"name\": release[\"tag_name\"].lstrip(\"v\"),\n                    \"tag\": release[\"tag_name\"],\n                    \"published\": published,\n                    \"url\": (\n                        release[\"assets\"][0][\"browser_download_url\"]\n                        if release[\"assets\"]\n                        else \"\"\n                    ),\n                }\n            )\n\n        return context\n\n    @staticmethod\n    def roadmap_pdeps(context):\n        \"\"\"\n        PDEP's (pandas enhancement proposals) are not part of the bar\n        navigation. They are included as lists in the \"Roadmap\" page\n        and linked from there. This preprocessor obtains the list of\n        PDEP's in different status from the directory tree and GitHub.\n        \"\"\"\n        KNOWN_STATUS = {\n            \"Under discussion\",\n            \"Accepted\",\n            \"Implemented\",\n            \"Rejected\",\n            \"Withdrawn\",\n        }\n        context[\"pdeps\"] = collections.defaultdict(list)\n\n        # accepted, rejected and implemented\n        pdeps_path = (\n            pathlib.Path(context[\"source_path\"]) / context[\"roadmap\"][\"pdeps_path\"]\n        )\n        for pdep in sorted(pdeps_path.iterdir()):\n            if pdep.suffix != \".md\":\n                continue\n            with pdep.open() as f:\n                title = f.readline()[2:]  # removing markdown title \"# \"\n                status = None\n                for line in f:\n                    if line.startswith(\"- Status: \"):\n                        status = line.strip().split(\": \", 1)[1]\n                        break\n                if status not in KNOWN_STATUS:\n                    raise RuntimeError(\n                        f'PDEP \"{pdep}\" status \"{status}\" is unknown. '\n                        f\"Should be one of: {KNOWN_STATUS}\"\n                    )\n            html_file = pdep.with_suffix(\".html\").name\n            context[\"pdeps\"][status].append(\n                {\n                    \"title\": title,\n                    \"url\": f\"pdeps/{html_file}\",\n                }\n            )\n\n        # under discussion\n        github_repo_url = context[\"main\"][\"github_repo_url\"]\n        resp = requests.get(\n            \"https://api.github.com/search/issues?\"\n            f\"q=is:pr is:open label:PDEP repo:{github_repo_url}\",\n            headers=GITHUB_API_HEADERS,\n        )\n        if resp.status_code == 403:\n            sys.stderr.write(\"WARN: GitHub API quota exceeded when fetching pdeps\\n\")\n            resp_bkp = requests.get(context[\"main\"][\"production_url\"] + \"pdeps.json\")\n            resp_bkp.raise_for_status()\n            pdeps = resp_bkp.json()\n        else:\n            resp.raise_for_status()\n            pdeps = resp.json()\n\n        with open(pathlib.Path(context[\"target_path\"]) / \"pdeps.json\", \"w\") as f:\n            json.dump(pdeps, f)\n\n        for pdep in sorted(pdeps[\"items\"], key=operator.itemgetter(\"title\")):\n            context[\"pdeps\"][\"Under discussion\"].append(\n                {\"title\": pdep[\"title\"], \"url\": pdep[\"html_url\"]}\n            )\n\n        return context\n\n\ndef get_callable(obj_as_str: str) -> object:\n    \"\"\"\n    Get a Python object from its string representation.\n\n    For example, for ``sys.stdout.write`` would import the module ``sys``\n    and return the ``write`` function.\n    \"\"\"\n    components = obj_as_str.split(\".\")\n    attrs = []\n    while components:\n        try:\n            obj = importlib.import_module(\".\".join(components))\n        except ImportError:\n            attrs.insert(0, components.pop())\n        else:\n            break\n\n    if not obj:\n        raise ImportError(f'Could not import \"{obj_as_str}\"')\n\n    for attr in attrs:\n        obj = getattr(obj, attr)\n\n    return obj\n\n\ndef get_context(config_fname: str, **kwargs):\n    \"\"\"\n    Load the config yaml as the base context, and enrich it with the\n    information added by the context preprocessors defined in the file.\n    \"\"\"\n    with open(config_fname) as f:\n        context = yaml.safe_load(f)\n\n    context[\"source_path\"] = os.path.dirname(config_fname)\n    context.update(kwargs)\n\n    preprocessors = (\n        get_callable(context_prep)\n        for context_prep in context[\"main\"][\"context_preprocessors\"]\n    )\n    for preprocessor in preprocessors:\n        context = preprocessor(context)\n        msg = f\"{preprocessor.__name__} is missing the return statement\"\n        assert context is not None, msg\n\n    return context\n\n\ndef get_source_files(source_path: str) -> typing.Generator[str, None, None]:\n    \"\"\"\n    Generate the list of files present in the source directory.\n    \"\"\"\n    for root, dirs, fnames in os.walk(source_path):\n        root = os.path.relpath(root, source_path)\n        for fname in fnames:\n            yield os.path.join(root, fname)\n\n\ndef extend_base_template(content: str, base_template: str) -> str:\n    \"\"\"\n    Wrap document to extend the base template, before it is rendered with\n    Jinja2.\n    \"\"\"\n    result = '{% extends \"' + base_template + '\" %}'\n    result += \"{% block body %}\"\n    result += content\n    result += \"{% endblock %}\"\n    return result\n\n\ndef main(\n    source_path: str,\n    target_path: str,\n) -> int:\n    \"\"\"\n    Copy every file in the source directory to the target directory.\n\n    For ``.md`` and ``.html`` files, render them with the context\n    before copying them. ``.md`` files are transformed to HTML.\n    \"\"\"\n    config_fname = os.path.join(source_path, \"config.yml\")\n\n    shutil.rmtree(target_path, ignore_errors=True)\n    os.makedirs(target_path, exist_ok=True)\n\n    sys.stderr.write(\"Generating context...\\n\")\n    context = get_context(config_fname, target_path=target_path)\n    sys.stderr.write(\"Context generated\\n\")\n\n    templates_path = os.path.join(source_path, context[\"main\"][\"templates_path\"])\n    jinja_env = jinja2.Environment(loader=jinja2.FileSystemLoader(templates_path))\n\n    for fname in get_source_files(source_path):\n        if os.path.normpath(fname) in context[\"main\"][\"ignore\"]:\n            continue\n\n        sys.stderr.write(f\"Processing {fname}\\n\")\n        dirname = os.path.dirname(fname)\n        os.makedirs(os.path.join(target_path, dirname), exist_ok=True)\n\n        extension = os.path.splitext(fname)[-1]\n        if extension in (\".html\", \".md\"):\n            with open(os.path.join(source_path, fname)) as f:\n                content = f.read()\n            if extension == \".md\":\n                body = markdown.markdown(\n                    content, extensions=context[\"main\"][\"markdown_extensions\"]\n                )\n                # Apply Bootstrap's table formatting manually\n                # Python-Markdown doesn't let us config table attributes by hand\n                body = body.replace(\"<table>\", '<table class=\"table table-bordered\">')\n                content = extend_base_template(body, context[\"main\"][\"base_template\"])\n            context[\"base_url\"] = \"\".join([\"../\"] * os.path.normpath(fname).count(\"/\"))\n            content = jinja_env.from_string(content).render(**context)\n            fname = os.path.splitext(fname)[0] + \".html\"\n            with open(os.path.join(target_path, fname), \"w\") as f:\n                f.write(content)\n        else:\n            shutil.copy(\n                os.path.join(source_path, fname), os.path.join(target_path, dirname)\n            )\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Documentation builder.\")\n    parser.add_argument(\n        \"source_path\", help=\"path to the source directory (must contain config.yml)\"\n    )\n    parser.add_argument(\n        \"--target-path\", default=\"build\", help=\"directory where to write the output\"\n    )\n    args = parser.parse_args()\n    sys.exit(main(args.source_path, args.target_path))\n"
    }
  ],
  "questions": [
    "> I wouldn’t object to deprecating automatic alignment\r\n\r\nReally? I hadn't even realised this was on the table. If so, then I love this idea.\r\n\r\nWould the idea be:\r\n- if indices are already aligned, proceed as per status quo\r\n- if they're not aligned, then throw an error, advising users to call `.align`?\r\n\r\nLike this, then advanced users who really use the power of indices just need to add an extra `.align` call, and beginner/intermediate users won't have surprises because of unexpected \"magical\" alignment under the hood. Similarly to #49946\r\n\r\nThis would also be similar to @blazespinnaker 's comment https://github.com/pandas-dev/pandas/pull/49694#issuecomment-1321287026 , except that instead of there being a global option to control this, users would get a loud and clear error. In which case, thanks @blazespinnaker , and I'm sorry for having said that your comment was off-topic (I still think it's better to keep this discussion separate from PDEP0005 though)\r\n\r\nExample of where to get to:\r\n```python\r\n>>> ser1 = pd.Series([1,2,3])\r\n>>> ser2 = pd.Series([4, 1, 2], index=[0, 1, 3])\r\n>>> ser1 + ser2\r\n---\r\nValueError: Operands are not aligned. Do `left, right = left.align(right, axis=0, copy=False)` before operating.\r\n```",
    "I guess it's time for another @pandas-dev/pandas-core @pandas-dev/pandas-triage tag ... before putting together another PDEP, anyone have any initial thoughts on deprecating automatic alignment?\r\n\r\nI like the idea, as it would mean:\r\n- simplifying the codebase\r\n- fewer surprises for users\r\n- advanced users relying on automatic alignment can just add an extra `.align` call and proceed as before"
  ],
  "golden_answers": [
    "I guess it's time for another @pandas-dev/pandas-core @pandas-dev/pandas-triage tag ... before putting together another PDEP, anyone have any initial thoughts on deprecating automatic alignment?\r\n\r\nI like the idea, as it would mean:\r\n- simplifying the codebase\r\n- fewer surprises for users\r\n- advanced users relying on automatic alignment can just add an extra `.align` call and proceed as before",
    "Related #47554 \r\n\r\nOne thing to consider is that this would mess up doing chaining.  For example, right now, you can do `(s1 + s2).dropna()`, but if you have to align first, I don't see how to do that in a chain.\r\n\r\nThere are some advantages to automatic alignment, in terms of when exploring data, it helps you identify missing data quite easily."
  ],
  "questions_generated": [
    "What is the main concern raised in the issue regarding Pandas' automatic data alignment feature?",
    "In the context of the issue, what is suggested as a potential improvement to the Pandas documentation?",
    "How does the issue reporter propose handling situations where indices are not aligned in Pandas operations?",
    "What are the potential benefits of deprecating automatic data alignment in Pandas, as discussed in the issue comments?",
    "How might the proposed changes to the alignment feature affect advanced users of Pandas?",
    "What is the role of context preprocessors in the code structure of the repository, as mentioned in the code context?"
  ],
  "golden_answers_generated": [
    "The main concern raised is that the automatic data alignment feature can be confusing for new users. The documentation lacks clarity on how this feature works, particularly in operations like 'sum'. The suggestion is to improve the documentation by explicitly mentioning how alignment works and providing examples to make it less confusing.",
    "The suggestion is to add a note in the documentation for operations such as 'sum' to indicate that automatic data alignment is performed. It should explain that if there are no matching indices, NaN will be used. Additionally, including examples would be beneficial to illustrate how this feature works.",
    "The issue discusses the possibility of deprecating automatic alignment in favor of requiring explicit alignment by users. The idea is to throw an error if indices are not aligned and advise users to call the '.align()' method, thus preventing unexpected behavior from 'magical' alignment.",
    "Deprecating automatic data alignment could lead to more predictable behavior for users, as it would prevent surprises due to unexpected alignment. Users, especially beginners, would receive clear errors and guidance on how to align data explicitly using the '.align()' method, enhancing clarity and ease of use.",
    "For advanced users, the proposed changes mean they would need to add an extra '.align()' call if indices are not already aligned. While this adds a step, it provides more control and transparency over the alignment process, ensuring that operations are performed as expected.",
    "Context preprocessors in the repository are functions that enrich the context used to render templates. They take the original context parsed from 'config.yml' and add additional information needed for rendering, such as the current year for copyright notices. This modular approach helps maintain organized and dynamic content generation for the Pandas web documentation."
  ]
}