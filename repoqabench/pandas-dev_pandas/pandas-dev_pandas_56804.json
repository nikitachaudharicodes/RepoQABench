{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "56804",
  "issue_description": "# DOC: fix EX03 errors in docstrings\n\npandas has a script for validating docstrings\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/b7e2202459eadc9dd599cbe58251ecc930798b97/ci/code_checks.sh#L72-L172\r\n\r\nCurrently, some methods fail the EX03 check.\r\n\r\nThe task here is:\r\n- take 2-4 methods\r\n- run: scripts/validate_docstrings.py --format=actions --errors=EX03 `method-name`\r\n- check if validation docstrings passes for those methods, and if it‚Äôs necessary fix the docstrings according to whatever error is reported\r\n- remove those methods from¬†code_checks.sh\r\n- commit, push, open pull request\r\n\r\nPlease don't comment `take` as multiple people can work on this issue. You also don't need to ask for permission to work on this, just comment on which methods are you going to work.\r\n\r\nIf you're new contributor, please check the [contributing guide](https://pandas.pydata.org/docs/dev/development/contributing.html)\r\n\r\nthanks @MarcoGorelli for giving me the idea for this issue.",
  "issue_comments": [
    {
      "id": 1884179535,
      "user": "roadrollerdafjorst",
      "body": "I can take the first two methods.\r\n- `pandas.Series.dt.day_name`\r\n- `pandas.Series.str.len`"
    },
    {
      "id": 1884204069,
      "user": "luke396",
      "body": "I will work for:\r\n`pandas.Series.cat.set_categories`\r\n`pandas.Series.plot.bar`\r\n`pandas.Series.plot.hist`"
    },
    {
      "id": 1884362573,
      "user": "luke396",
      "body": "Just to be sure, and to clarify for later contributors, the error EX03 refers to all possible flake8 errors.\r\n\r\nReference #27977."
    },
    {
      "id": 1884520575,
      "user": "svrashank",
      "body": "Working on : \r\n* pandas.Series.plot.line \r\n* pandas.Series.to_sql  "
    },
    {
      "id": 1884614808,
      "user": "Deekshita-S",
      "body": "working on:\r\n\r\n- pandas.DataFrame.loc  \r\n-  pandas.DataFrame.iloc \r\n-  pandas.DataFrame.describe"
    },
    {
      "id": 1885402362,
      "user": "asishm",
      "body": "I wrote a comment but accidentally deleted it ü§¶‚Äç‚ôÇÔ∏è\r\n\r\ntl;dr - if a method is passed to `validate_docstrings.py` it ignores all the other arguments and returns all errors."
    },
    {
      "id": 1885545003,
      "user": "lukasld",
      "body": "Im new to this and maybe I overlook something fundamental: <br> I wanted to take on some of these docstrings, I however run into an issue and am not sure what I am doing wrong.\r\n<p>\r\nAfter executing:\r\n\r\n```\r\npython3 validate_docstrings.py --format=actions --errors=EX03 pandas.errors.SpecificationError\r\n```\r\nI get a list of `flake8 - errors`:\r\n\r\n```\r\nflake8 error: line 4, col 40: E261 at least two spaces before inline comment\r\n...\r\n```\r\nHowever, after adding an extra space and saving the docstring for `SpecificationError` in this case in\r\n```\r\n./pandas/errors/__init__.py\r\n``` \r\nand rerunning the above `validation_docstrings.py` again, the script returns the same errors, as if the change had no effect."
    },
    {
      "id": 1885582336,
      "user": "lukasld",
      "body": "Otherwise id take:\r\n\r\n- `pandas.errors.SettingWithCopyWarning`\r\n- `pandas.errors.SpecificationError`\r\n- `pandas.errors.UndefinedVariableError`"
    },
    {
      "id": 1886184772,
      "user": "tiffanyxiao",
      "body": "Working on: \r\n- pandas.errors.DatabaseError \r\n- pandas.errors.IndexingError\r\n- pandas.errors.InvalidColumnName\r\nThank you!"
    },
    {
      "id": 1886427296,
      "user": "svrashank",
      "body": "So for `pandas.Series.plot.line` its giving following errors: \r\n* `Unknown parameters {'color'}`\r\n* `flake8 error: line 4, col 4: E121 continuation line under-indented for hanging indent`\r\n* `flake8 error: line 6, col 4: E123 closing bracket does not match indentation of opening bracket's line`\r\nI am new to this , can someone help me in understanding 'line 4,col 4' of what ? I can't seem to locate where it is pointing me towards. Thanks in advance"
    },
    {
      "id": 1886447083,
      "user": "jordan-d-murphy",
      "body": "Hi all, I've opened a PR for the following \r\n\r\npandas.core.groupby.DataFrameGroupBy.describe \r\npandas.core.groupby.DataFrameGroupBy.idxmax \r\npandas.core.groupby.DataFrameGroupBy.idxmin \r\npandas.core.groupby.DataFrameGroupBy.value_counts "
    },
    {
      "id": 1886526581,
      "user": "jordan-d-murphy",
      "body": "Hi all, I've opened a PR for the following\r\n\r\npandas.core.resample.Resampler.fillna \r\npandas.core.groupby.SeriesGroupBy.describe \r\npandas.DataFrame.last \r\npandas.DataFrame.plot.hist  "
    },
    {
      "id": 1886738518,
      "user": "jordan-d-murphy",
      "body": "Hi all, I've opened a PR for the following\r\n\r\npandas.DataFrame.idxmax \r\npandas.DataFrame.idxmin \r\npandas.DataFrame.pivot "
    },
    {
      "id": 1886808667,
      "user": "svrashank",
      "body": "> Im new to this and maybe I overlook something fundamental: I wanted to take on some of these docstrings, I however run into an issue and am not sure what I am doing wrong.\r\n> \r\n> After executing:\r\n> \r\n> ```\r\n> python3 validate_docstrings.py --format=actions --errors=EX03 pandas.errors.SpecificationError\r\n> ```\r\n> \r\n> I get a list of `flake8 - errors`:\r\n> \r\n> ```\r\n> flake8 error: line 4, col 40: E261 at least two spaces before inline comment\r\n> ...\r\n> ```\r\n> \r\n> However, after adding an extra space and saving the docstring for `SpecificationError` in this case in\r\n> \r\n> ```\r\n> ./pandas/errors/__init__.py\r\n> ```\r\n> \r\n> and rerunning the above `validation_docstrings.py` again, the script returns the same errors, as if the change had no effect.\r\n\r\nEven I am new and facing similar issue . Even after making the changes the error logs don't change "
    },
    {
      "id": 1886817794,
      "user": "asishm",
      "body": "**Explanation of what to look for:**\r\n\r\n\r\nEX03 is the errors for the example code-blocks in a function/method's documentation\r\n\r\nfor `pandas.errors.SpecificationError` the examples show:\r\n\r\n```py\r\nExamples\r\n--------\r\n>>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2],\r\n...                    'B': range(5),\r\n...                    'C': range(5)})\r\n>>> df.groupby('A').B.agg({'foo': 'count'}) # doctest: +SKIP\r\n... # SpecificationError: nested renamer is not supported\r\n\r\n>>> df.groupby('A').agg({'B': {'foo': ['sum', 'max']}}) # doctest: +SKIP\r\n... # SpecificationError: nested renamer is not supported\r\n\r\n>>> df.groupby('A').agg(['min', 'min']) # doctest: +SKIP\r\n... # SpecificationError: nested renamer is not supported\r\n```\r\n\r\nline 4 here would be the 4th line in the examples which is `>>> df.groupby('A').B.agg({'foo': 'count'}) # doctest: +SKIP` \r\n\r\nline 6 would be `>>> df.groupby('A').agg({'B': {'foo': ['sum', 'max']}}) # doctest: +SKIP`"
    },
    {
      "id": 1886839260,
      "user": "natmokval",
      "body": "> EX03 is the errors for the example code-blocks in a function/method's documentation\r\n> \r\n> for `pandas.errors.SpecificationError` the examples show:\r\n> \r\n> ```python\r\n> Examples\r\n> --------\r\n> >>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2],\r\n> ...                    'B': range(5),\r\n> ...                    'C': range(5)})\r\n> >>> df.groupby('A').B.agg({'foo': 'count'}) # doctest: +SKIP\r\n> ... # SpecificationError: nested renamer is not supported\r\n> \r\n> >>> df.groupby('A').agg({'B': {'foo': ['sum', 'max']}}) # doctest: +SKIP\r\n> ... # SpecificationError: nested renamer is not supported\r\n> \r\n> >>> df.groupby('A').agg(['min', 'min']) # doctest: +SKIP\r\n> ... # SpecificationError: nested renamer is not supported\r\n> ```\r\n> \r\n> line 4 here would be the 4th line in the examples which is `>>> df.groupby('A').B.agg({'foo': 'count'}) # doctest: +SKIP`\r\n> \r\n> line 6 would be `>>> df.groupby('A').agg({'B': {'foo': ['sum', 'max']}}) # doctest: +SKIP`\r\n\r\n@asishm what kind of flake8 errors did you get?"
    },
    {
      "id": 1886850195,
      "user": "asishm",
      "body": "```\r\n        flake8 error: line 4, col 40: E261 at least two spaces before inline comment\r\n        flake8 error: line 6, col 52: E261 at least two spaces before inline comment\r\n        flake8 error: line 8, col 36: E261 at least two spaces before inline comment\r\n```\r\n\r\nthere's also a non flake8 error reported `See Also section not found` for the above.\r\n\r\nsee https://github.com/pandas-dev/pandas/issues/56804#issuecomment-1885402362 and https://github.com/pandas-dev/pandas/pull/56827#issuecomment-1886625433 for details @natmokval "
    },
    {
      "id": 1886865140,
      "user": "jordan-d-murphy",
      "body": "@asishm can you try adding a space before each of these `#` symbols ![image](https://github.com/pandas-dev/pandas/assets/35613487/6307cc8a-c89a-45ac-b161-fa3902c428af)"
    },
    {
      "id": 1886867556,
      "user": "asishm",
      "body": "yeah that's the fix - sorry if it wasn't clear, it was more of an explanation for people that had trouble figuring out the lines affected."
    },
    {
      "id": 1886871539,
      "user": "jordan-d-murphy",
      "body": "Okay! Makes sense. Hope the photo might help someone else then üôÇ"
    },
    {
      "id": 1887381275,
      "user": "lukasld",
      "body": "> > Im new to this and maybe I overlook something fundamental: I wanted to take on some of these docstrings, I however run into an issue and am not sure what I am doing wrong.\r\n> > After executing:\r\n> > ```\r\n> > python3 validate_docstrings.py --format=actions --errors=EX03 pandas.errors.SpecificationError\r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > I get a list of `flake8 - errors`:\r\n> > ```\r\n> > flake8 error: line 4, col 40: E261 at least two spaces before inline comment\r\n> > ...\r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > However, after adding an extra space and saving the docstring for `SpecificationError` in this case in\r\n> > ```\r\n> > ./pandas/errors/__init__.py\r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > and rerunning the above `validation_docstrings.py` again, the script returns the same errors, as if the change had no effect.\r\n> \r\n> Even I am new and facing similar issue . Even after making the changes the error logs don't change\r\n\r\nMaybe it `numpydoc` or another library is caching the results? Not sure..."
    },
    {
      "id": 1888057355,
      "user": "jordan-d-murphy",
      "body": "I've fixed the following: \r\n\r\npandas.Series.to_latex \r\npandas.read_pickle\r\npandas.DataFrame.to_latex\r\npandas.core.resample.Resampler.pipe"
    },
    {
      "id": 1888741870,
      "user": "jordan-d-murphy",
      "body": "I'll take these:\r\n\r\n pandas.core.resample.Resampler.interpolate \r\n pandas.pivot  \r\n pandas.merge_asof \r\n pandas.wide_to_long\r\n pandas.Index.rename \r\n pandas.Index.isin \r\n pandas.IndexSlice "
    },
    {
      "id": 1890291051,
      "user": "luke396",
      "body": "This is the name of the method that I have put together, and no one has yet taken on it. (Most likely there is an error, as this is what I checked completely manually, and let me know directly if someone finds an error). \r\n\r\n- [x] pandas.errors.CategoricalConversionWarning \r\n- [x] pandas.errors.ChainedAssignmentError \r\n- [x] pandas.errors.ClosedFileError  \r\n- [x] pandas.errors.NumExprClobberingError \r\n- [x] pandas.errors.PossibleDataLossError \r\n- [x] pandas.errors.PossiblePrecisionLoss \r\n- [x] pandas.errors.SettingWithCopyError \r\n- [x] pandas.errors.ValueLabelTypeMismatch \r\n- [x] pandas.Timestamp.ceil \r\n- [x] pandas.Timestamp.floor\r\n- [x] pandas.Timestamp.round \r\n- [x] pandas.ExcelWriter \r\n- [x] pandas.read_json \r\n- [x] pandas.io.json.build_table_schema \r\n- [x] pandas.io.formats.style.Styler.to_latex \r\n- [x] pandas.read_parquet \r\n- [x] pandas.DataFrame.to_sql \r\n- [x] pandas.read_stata \r\n- [x] pandas.plotting.scatter_matrix \r\n- [x] pandas.Index.droplevel \r\n- [x] pandas.CategoricalIndex.set_categories \r\n- [x] pandas.MultiIndex.names \r\n- [x] pandas.MultiIndex.droplevel \r\n- [x] pandas.DatetimeIndex.month_name\r\n- [x] pandas.DatetimeIndex.day_name\r\n- [x] pandas.core.window.rolling.Rolling.corr\r\n- [x] pandas.Grouper\r\n- [x] pandas.core.groupby.SeriesGroupBy.apply\r\n- [x] pandas.core.groupby.DataFrameGroupBy.apply\r\n- [x] pandas.core.groupby.SeriesGroupBy.transform\r\n- [x] pandas.core.groupby.SeriesGroupBy.pipe\r\n- [x] pandas.core.groupby.DataFrameGroupBy.pipe\r\n- [x] pandas.core.groupby.DataFrameGroupBy.boxplot\r\n- [x] pandas.core.groupby.DataFrameGroupBy.hist\r\n- [x] pandas.io.formats.style.Styler.map\r\n- [x] pandas.io.formats.style.Styler.apply_index\r\n- [x] pandas.io.formats.style.Styler.map_index\r\n- [x] pandas.io.formats.style.Styler.format\r\n- [x] pandas.io.formats.style.Styler.format_index\r\n- [x] pandas.io.formats.style.Styler.relabel_index\r\n- [x] pandas.io.formats.style.Styler.hide\r\n- [x] pandas.io.formats.style.Styler.set_td_classes\r\n- [x] pandas.io.formats.style.Styler.set_tooltips\r\n- [x] pandas.io.formats.style.Styler.set_uuid\r\n- [x] pandas.io.formats.style.Styler.pipe\r\n- [x] pandas.io.formats.style.Styler.highlight_between\r\n- [x] pandas.io.formats.style.Styler.highlight_quantile\r\n- [x] pandas.io.formats.style.Styler.background_gradient\r\n- [x] pandas.io.formats.style.Styler.text_gradient\r\n- [x] pandas.DataFrame.values\r\n- [x] pandas.DataFrame.groupby\r\n- [x] pandas.DataFrame.skew\r\n- [x] pandas.DataFrame.var\r\n- [x] pandas.DataFrame.sort_values\r\n- [ ] pandas.DataFrame.tz_convert\r\n- [x] pandas.DataFrame.tz_localize\r\n- [ ] pandas.DataFrame.plot.bar\r\n- [x] pandas.DataFrame.plot.hexbin\r\n- [x] pandas.DataFrame.plot.hist\r\n- [x] pandas.DataFrame.plot.line\r\n- [x] pandas.DataFrame.hist"
    },
    {
      "id": 1890291315,
      "user": "luke396",
      "body": "And take \r\n\r\n- pandas.errors.CategoricalConversionWarning\r\n- pandas.errors.ChainedAssignmentError\r\n- pandas.errors.ClosedFileError\r\n- pandas.errors.NumExprClobberingError"
    },
    {
      "id": 1890331657,
      "user": "tqa236",
      "body": "work on\r\n- pandas.MultiIndex.names\r\n- pandas.MultiIndex.droplevel\r\n"
    },
    {
      "id": 1890513961,
      "user": "asishm",
      "body": "PR opened for the following:\r\n\r\n- pandas.DataFrame.var\r\n- pandas.DatetimeIndex.day_name\r\n- pandas.core.groupby.DataFrameGroupBy.apply\r\n- pandas.DatetimeIndex.month_name\r\n- pandas.core.groupby.DataFrameGroupBy.hist\r\n- pandas.core.groupby.SeriesGroupBy.apply\r\n- pandas.core.groupby.SeriesGroupBy.transform\r\n- pandas.DataFrame.plot.hist\r\n- pandas.DataFrame.tz_localize\r\n- pandas.CategoricalIndex.set_categories\r\n- pandas.core.groupby.DataFrameGroupBy.boxplot\r\n- pandas.core.groupby.SeriesGroupBy.pipe\r\n- pandas.DataFrame.plot.bar\r\n- pandas.DataFrame.tz_convert\r\n- pandas.core.groupby.DataFrameGroupBy.pipe\r\n- pandas.DataFrame.skew\r\n- pandas.core.window.rolling.Rolling.corr"
    },
    {
      "id": 1890819116,
      "user": "erichxchen",
      "body": "Working on:\r\n- pandas.DataFrame.hist\r\n- pandas.read_json\r\n- pandas.DataFrame.to_sql"
    },
    {
      "id": 1890833306,
      "user": "erichxchen",
      "body": "Hi @natmokval, the command line `scripts/validate_docstrings.py --format=actions --errors=EX03 method-name` outputs all kind of errors, not just the EX03 errors.\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/c778746f2219601ac3c38f4f287f9a4e68905655/scripts/validate_docstrings.py#L444-L458"
    },
    {
      "id": 1890847708,
      "user": "yuanx749",
      "body": "working on:\r\n\r\n- pandas.errors.PossibleDataLossError\r\n- pandas.errors.PossiblePrecisionLoss\r\n- pandas.errors.SettingWithCopyError\r\n- pandas.errors.ValueLabelTypeMismatch"
    }
  ],
  "text_context": "# DOC: fix EX03 errors in docstrings\n\npandas has a script for validating docstrings\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/b7e2202459eadc9dd599cbe58251ecc930798b97/ci/code_checks.sh#L72-L172\r\n\r\nCurrently, some methods fail the EX03 check.\r\n\r\nThe task here is:\r\n- take 2-4 methods\r\n- run: scripts/validate_docstrings.py --format=actions --errors=EX03 `method-name`\r\n- check if validation docstrings passes for those methods, and if it‚Äôs necessary fix the docstrings according to whatever error is reported\r\n- remove those methods from¬†code_checks.sh\r\n- commit, push, open pull request\r\n\r\nPlease don't comment `take` as multiple people can work on this issue. You also don't need to ask for permission to work on this, just comment on which methods are you going to work.\r\n\r\nIf you're new contributor, please check the [contributing guide](https://pandas.pydata.org/docs/dev/development/contributing.html)\r\n\r\nthanks @MarcoGorelli for giving me the idea for this issue.\n\nI can take the first two methods.\r\n- `pandas.Series.dt.day_name`\r\n- `pandas.Series.str.len`\n\nI will work for:\r\n`pandas.Series.cat.set_categories`\r\n`pandas.Series.plot.bar`\r\n`pandas.Series.plot.hist`\n\nJust to be sure, and to clarify for later contributors, the error EX03 refers to all possible flake8 errors.\r\n\r\nReference #27977.\n\nWorking on : \r\n* pandas.Series.plot.line \r\n* pandas.Series.to_sql  \n\nworking on:\r\n\r\n- pandas.DataFrame.loc  \r\n-  pandas.DataFrame.iloc \r\n-  pandas.DataFrame.describe\n\nI wrote a comment but accidentally deleted it ü§¶‚Äç‚ôÇÔ∏è\r\n\r\ntl;dr - if a method is passed to `validate_docstrings.py` it ignores all the other arguments and returns all errors.\n\nIm new to this and maybe I overlook something fundamental: <br> I wanted to take on some of these docstrings, I however run into an issue and am not sure what I am doing wrong.\r\n<p>\r\nAfter executing:\r\n\r\n```\r\npython3 validate_docstrings.py --format=actions --errors=EX03 pandas.errors.SpecificationError\r\n```\r\nI get a list of `flake8 - errors`:\r\n\r\n```\r\nflake8 error: line 4, col 40: E261 at least two spaces before inline comment\r\n...\r\n```\r\nHowever, after adding an extra space and saving the docstring for `SpecificationError` in this case in\r\n```\r\n./pandas/errors/__init__.py\r\n``` \r\nand rerunning the above `validation_docstrings.py` again, the script returns the same errors, as if the change had no effect.\n\nOtherwise id take:\r\n\r\n- `pandas.errors.SettingWithCopyWarning`\r\n- `pandas.errors.SpecificationError`\r\n- `pandas.errors.UndefinedVariableError`\n\nWorking on: \r\n- pandas.errors.DatabaseError \r\n- pandas.errors.IndexingError\r\n- pandas.errors.InvalidColumnName\r\nThank you!\n\nSo for `pandas.Series.plot.line` its giving following errors: \r\n* `Unknown parameters {'color'}`\r\n* `flake8 error: line 4, col 4: E121 continuation line under-indented for hanging indent`\r\n* `flake8 error: line 6, col 4: E123 closing bracket does not match indentation of opening bracket's line`\r\nI am new to this , can someone help me in understanding 'line 4,col 4' of what ? I can't seem to locate where it is pointing me towards. Thanks in advance\n\nHi all, I've opened a PR for the following \r\n\r\npandas.core.groupby.DataFrameGroupBy.describe \r\npandas.core.groupby.DataFrameGroupBy.idxmax \r\npandas.core.groupby.DataFrameGroupBy.idxmin \r\npandas.core.groupby.DataFrameGroupBy.value_counts \n\nHi all, I've opened a PR for the following\r\n\r\npandas.core.resample.Resampler.fillna \r\npandas.core.groupby.SeriesGroupBy.describe \r\npandas.DataFrame.last \r\npandas.DataFrame.plot.hist  \n\nHi all, I've opened a PR for the following\r\n\r\npandas.DataFrame.idxmax \r\npandas.DataFrame.idxmin \r\npandas.DataFrame.pivot \n\n> Im new to this and maybe I overlook something fundamental: I wanted to take on some of these docstrings, I however run into an issue and am not sure what I am doing wrong.\r\n> \r\n> After executing:\r\n> \r\n> ```\r\n> python3 validate_docstrings.py --format=actions --errors=EX03 pandas.errors.SpecificationError\r\n> ```\r\n> \r\n> I get a list of `flake8 - errors`:\r\n> \r\n> ```\r\n> flake8 error: line 4, col 40: E261 at least two spaces before inline comment\r\n> ...\r\n> ```\r\n> \r\n> However, after adding an extra space and saving the docstring for `SpecificationError` in this case in\r\n> \r\n> ```\r\n> ./pandas/errors/__init__.py\r\n> ```\r\n> \r\n> and rerunning the above `validation_docstrings.py` again, the script returns the same errors, as if the change had no effect.\r\n\r\nEven I am new and facing similar issue . Even after making the changes the error logs don't change \n\n**Explanation of what to look for:**\r\n\r\n\r\nEX03 is the errors for the example code-blocks in a function/method's documentation\r\n\r\nfor `pandas.errors.SpecificationError` the examples show:\r\n\r\n```py\r\nExamples\r\n--------\r\n>>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2],\r\n...                    'B': range(5),\r\n...                    'C': range(5)})\r\n>>> df.groupby('A').B.agg({'foo': 'count'}) # doctest: +SKIP\r\n... # SpecificationError: nested renamer is not supported\r\n\r\n>>> df.groupby('A').agg({'B': {'foo': ['sum', 'max']}}) # doctest: +SKIP\r\n... # SpecificationError: nested renamer is not supported\r\n\r\n>>> df.groupby('A').agg(['min', 'min']) # doctest: +SKIP\r\n... # SpecificationError: nested renamer is not supported\r\n```\r\n\r\nline 4 here would be the 4th line in the examples which is `>>> df.groupby('A').B.agg({'foo': 'count'}) # doctest: +SKIP` \r\n\r\nline 6 would be `>>> df.groupby('A').agg({'B': {'foo': ['sum', 'max']}}) # doctest: +SKIP`\n\n> EX03 is the errors for the example code-blocks in a function/method's documentation\r\n> \r\n> for `pandas.errors.SpecificationError` the examples show:\r\n> \r\n> ```python\r\n> Examples\r\n> --------\r\n> >>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2],\r\n> ...                    'B': range(5),\r\n> ...                    'C': range(5)})\r\n> >>> df.groupby('A').B.agg({'foo': 'count'}) # doctest: +SKIP\r\n> ... # SpecificationError: nested renamer is not supported\r\n> \r\n> >>> df.groupby('A').agg({'B': {'foo': ['sum', 'max']}}) # doctest: +SKIP\r\n> ... # SpecificationError: nested renamer is not supported\r\n> \r\n> >>> df.groupby('A').agg(['min', 'min']) # doctest: +SKIP\r\n> ... # SpecificationError: nested renamer is not supported\r\n> ```\r\n> \r\n> line 4 here would be the 4th line in the examples which is `>>> df.groupby('A').B.agg({'foo': 'count'}) # doctest: +SKIP`\r\n> \r\n> line 6 would be `>>> df.groupby('A').agg({'B': {'foo': ['sum', 'max']}}) # doctest: +SKIP`\r\n\r\n@asishm what kind of flake8 errors did you get?\n\n```\r\n        flake8 error: line 4, col 40: E261 at least two spaces before inline comment\r\n        flake8 error: line 6, col 52: E261 at least two spaces before inline comment\r\n        flake8 error: line 8, col 36: E261 at least two spaces before inline comment\r\n```\r\n\r\nthere's also a non flake8 error reported `See Also section not found` for the above.\r\n\r\nsee https://github.com/pandas-dev/pandas/issues/56804#issuecomment-1885402362 and https://github.com/pandas-dev/pandas/pull/56827#issuecomment-1886625433 for details @natmokval \n\n@asishm can you try adding a space before each of these `#` symbols ![image](https://github.com/pandas-dev/pandas/assets/35613487/6307cc8a-c89a-45ac-b161-fa3902c428af)\n\nyeah that's the fix - sorry if it wasn't clear, it was more of an explanation for people that had trouble figuring out the lines affected.\n\nOkay! Makes sense. Hope the photo might help someone else then üôÇ\n\n> > Im new to this and maybe I overlook something fundamental: I wanted to take on some of these docstrings, I however run into an issue and am not sure what I am doing wrong.\r\n> > After executing:\r\n> > ```\r\n> > python3 validate_docstrings.py --format=actions --errors=EX03 pandas.errors.SpecificationError\r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > I get a list of `flake8 - errors`:\r\n> > ```\r\n> > flake8 error: line 4, col 40: E261 at least two spaces before inline comment\r\n> > ...\r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > However, after adding an extra space and saving the docstring for `SpecificationError` in this case in\r\n> > ```\r\n> > ./pandas/errors/__init__.py\r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > and rerunning the above `validation_docstrings.py` again, the script returns the same errors, as if the change had no effect.\r\n> \r\n> Even I am new and facing similar issue . Even after making the changes the error logs don't change\r\n\r\nMaybe it `numpydoc` or another library is caching the results? Not sure...\n\nI've fixed the following: \r\n\r\npandas.Series.to_latex \r\npandas.read_pickle\r\npandas.DataFrame.to_latex\r\npandas.core.resample.Resampler.pipe\n\nI'll take these:\r\n\r\n pandas.core.resample.Resampler.interpolate \r\n pandas.pivot  \r\n pandas.merge_asof \r\n pandas.wide_to_long\r\n pandas.Index.rename \r\n pandas.Index.isin \r\n pandas.IndexSlice \n\nThis is the name of the method that I have put together, and no one has yet taken on it. (Most likely there is an error, as this is what I checked completely manually, and let me know directly if someone finds an error). \r\n\r\n- [x] pandas.errors.CategoricalConversionWarning \r\n- [x] pandas.errors.ChainedAssignmentError \r\n- [x] pandas.errors.ClosedFileError  \r\n- [x] pandas.errors.NumExprClobberingError \r\n- [x] pandas.errors.PossibleDataLossError \r\n- [x] pandas.errors.PossiblePrecisionLoss \r\n- [x] pandas.errors.SettingWithCopyError \r\n- [x] pandas.errors.ValueLabelTypeMismatch \r\n- [x] pandas.Timestamp.ceil \r\n- [x] pandas.Timestamp.floor\r\n- [x] pandas.Timestamp.round \r\n- [x] pandas.ExcelWriter \r\n- [x] pandas.read_json \r\n- [x] pandas.io.json.build_table_schema \r\n- [x] pandas.io.formats.style.Styler.to_latex \r\n- [x] pandas.read_parquet \r\n- [x] pandas.DataFrame.to_sql \r\n- [x] pandas.read_stata \r\n- [x] pandas.plotting.scatter_matrix \r\n- [x] pandas.Index.droplevel \r\n- [x] pandas.CategoricalIndex.set_categories \r\n- [x] pandas.MultiIndex.names \r\n- [x] pandas.MultiIndex.droplevel \r\n- [x] pandas.DatetimeIndex.month_name\r\n- [x] pandas.DatetimeIndex.day_name\r\n- [x] pandas.core.window.rolling.Rolling.corr\r\n- [x] pandas.Grouper\r\n- [x] pandas.core.groupby.SeriesGroupBy.apply\r\n- [x] pandas.core.groupby.DataFrameGroupBy.apply\r\n- [x] pandas.core.groupby.SeriesGroupBy.transform\r\n- [x] pandas.core.groupby.SeriesGroupBy.pipe\r\n- [x] pandas.core.groupby.DataFrameGroupBy.pipe\r\n- [x] pandas.core.groupby.DataFrameGroupBy.boxplot\r\n- [x] pandas.core.groupby.DataFrameGroupBy.hist\r\n- [x] pandas.io.formats.style.Styler.map\r\n- [x] pandas.io.formats.style.Styler.apply_index\r\n- [x] pandas.io.formats.style.Styler.map_index\r\n- [x] pandas.io.formats.style.Styler.format\r\n- [x] pandas.io.formats.style.Styler.format_index\r\n- [x] pandas.io.formats.style.Styler.relabel_index\r\n- [x] pandas.io.formats.style.Styler.hide\r\n- [x] pandas.io.formats.style.Styler.set_td_classes\r\n- [x] pandas.io.formats.style.Styler.set_tooltips\r\n- [x] pandas.io.formats.style.Styler.set_uuid\r\n- [x] pandas.io.formats.style.Styler.pipe\r\n- [x] pandas.io.formats.style.Styler.highlight_between\r\n- [x] pandas.io.formats.style.Styler.highlight_quantile\r\n- [x] pandas.io.formats.style.Styler.background_gradient\r\n- [x] pandas.io.formats.style.Styler.text_gradient\r\n- [x] pandas.DataFrame.values\r\n- [x] pandas.DataFrame.groupby\r\n- [x] pandas.DataFrame.skew\r\n- [x] pandas.DataFrame.var\r\n- [x] pandas.DataFrame.sort_values\r\n- [ ] pandas.DataFrame.tz_convert\r\n- [x] pandas.DataFrame.tz_localize\r\n- [ ] pandas.DataFrame.plot.bar\r\n- [x] pandas.DataFrame.plot.hexbin\r\n- [x] pandas.DataFrame.plot.hist\r\n- [x] pandas.DataFrame.plot.line\r\n- [x] pandas.DataFrame.hist\n\nAnd take \r\n\r\n- pandas.errors.CategoricalConversionWarning\r\n- pandas.errors.ChainedAssignmentError\r\n- pandas.errors.ClosedFileError\r\n- pandas.errors.NumExprClobberingError\n\nwork on\r\n- pandas.MultiIndex.names\r\n- pandas.MultiIndex.droplevel\r\n\n\nPR opened for the following:\r\n\r\n- pandas.DataFrame.var\r\n- pandas.DatetimeIndex.day_name\r\n- pandas.core.groupby.DataFrameGroupBy.apply\r\n- pandas.DatetimeIndex.month_name\r\n- pandas.core.groupby.DataFrameGroupBy.hist\r\n- pandas.core.groupby.SeriesGroupBy.apply\r\n- pandas.core.groupby.SeriesGroupBy.transform\r\n- pandas.DataFrame.plot.hist\r\n- pandas.DataFrame.tz_localize\r\n- pandas.CategoricalIndex.set_categories\r\n- pandas.core.groupby.DataFrameGroupBy.boxplot\r\n- pandas.core.groupby.SeriesGroupBy.pipe\r\n- pandas.DataFrame.plot.bar\r\n- pandas.DataFrame.tz_convert\r\n- pandas.core.groupby.DataFrameGroupBy.pipe\r\n- pandas.DataFrame.skew\r\n- pandas.core.window.rolling.Rolling.corr\n\nWorking on:\r\n- pandas.DataFrame.hist\r\n- pandas.read_json\r\n- pandas.DataFrame.to_sql\n\nHi @natmokval, the command line `scripts/validate_docstrings.py --format=actions --errors=EX03 method-name` outputs all kind of errors, not just the EX03 errors.\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/c778746f2219601ac3c38f4f287f9a4e68905655/scripts/validate_docstrings.py#L444-L458\n\nworking on:\r\n\r\n- pandas.errors.PossibleDataLossError\r\n- pandas.errors.PossiblePrecisionLoss\r\n- pandas.errors.SettingWithCopyError\r\n- pandas.errors.ValueLabelTypeMismatch",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/56827",
  "code_context": [
    {
      "filename": "scripts/validate_docstrings.py",
      "content": "#!/usr/bin/env python3\n\"\"\"\nAnalyze docstrings to detect errors.\n\nIf no argument is provided, it does a quick check of docstrings and returns\na csv with all API functions and results of basic checks.\n\nIf a function or method is provided in the form \"pandas.function\",\n\"pandas.module.class.method\", etc. a list of all errors in the docstring for\nthe specified function or method.\n\nUsage::\n    $ ./validate_docstrings.py\n    $ ./validate_docstrings.py pandas.DataFrame.head\n\"\"\"\nfrom __future__ import annotations\n\nimport argparse\nimport doctest\nimport importlib\nimport json\nimport os\nimport pathlib\nimport subprocess\nimport sys\nimport tempfile\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom numpydoc.docscrape import get_doc_object\nfrom numpydoc.validate import (\n    Validator,\n    validate,\n)\n\n# With template backend, matplotlib plots nothing\nmatplotlib.use(\"template\")\n\n# Styler methods are Jinja2 objects who's docstrings we don't own.\nIGNORE_VALIDATION = {\n    \"Styler.env\",\n    \"Styler.template_html\",\n    \"Styler.template_html_style\",\n    \"Styler.template_html_table\",\n    \"Styler.template_latex\",\n    \"Styler.template_string\",\n    \"Styler.loader\",\n    \"errors.InvalidComparison\",\n    \"errors.LossySetitemError\",\n    \"errors.NoBufferPresent\",\n    \"errors.IncompatibilityWarning\",\n    \"errors.PyperclipException\",\n    \"errors.PyperclipWindowsException\",\n}\nPRIVATE_CLASSES = [\"NDFrame\", \"IndexOpsMixin\"]\nERROR_MSGS = {\n    \"GL04\": \"Private classes ({mentioned_private_classes}) should not be \"\n    \"mentioned in public docstrings\",\n    \"GL05\": \"Use 'array-like' rather than 'array_like' in docstrings.\",\n    \"SA05\": \"{reference_name} in `See Also` section does not need `pandas` \"\n    \"prefix, use {right_reference} instead.\",\n    \"EX03\": \"flake8 error: line {line_number}, col {col_number}: {error_code} \"\n    \"{error_message}\",\n    \"EX04\": \"Do not import {imported_library}, as it is imported \"\n    \"automatically for the examples (numpy as np, pandas as pd)\",\n}\n\n\ndef pandas_error(code, **kwargs):\n    \"\"\"\n    Copy of the numpydoc error function, since ERROR_MSGS can't be updated\n    with our custom errors yet.\n    \"\"\"\n    return (code, ERROR_MSGS[code].format(**kwargs))\n\n\ndef get_api_items(api_doc_fd):\n    \"\"\"\n    Yield information about all public API items.\n\n    Parse api.rst file from the documentation, and extract all the functions,\n    methods, classes, attributes... This should include all pandas public API.\n\n    Parameters\n    ----------\n    api_doc_fd : file descriptor\n        A file descriptor of the API documentation page, containing the table\n        of contents with all the public API.\n\n    Yields\n    ------\n    name : str\n        The name of the object (e.g. 'pandas.Series.str.upper).\n    func : function\n        The object itself. In most cases this will be a function or method,\n        but it can also be classes, properties, cython objects...\n    section : str\n        The name of the section in the API page where the object item is\n        located.\n    subsection : str\n        The name of the subsection in the API page where the object item is\n        located.\n    \"\"\"\n    current_module = \"pandas\"\n    previous_line = current_section = current_subsection = \"\"\n    position = None\n    for line in api_doc_fd:\n        line_stripped = line.strip()\n        if len(line_stripped) == len(previous_line):\n            if set(line_stripped) == set(\"-\"):\n                current_section = previous_line\n                continue\n            if set(line_stripped) == set(\"~\"):\n                current_subsection = previous_line\n                continue\n\n        if line_stripped.startswith(\".. currentmodule::\"):\n            current_module = line_stripped.replace(\".. currentmodule::\", \"\").strip()\n            continue\n\n        if line_stripped == \".. autosummary::\":\n            position = \"autosummary\"\n            continue\n\n        if position == \"autosummary\":\n            if line_stripped == \"\":\n                position = \"items\"\n                continue\n\n        if position == \"items\":\n            if line_stripped == \"\":\n                position = None\n                continue\n            if line_stripped in IGNORE_VALIDATION:\n                continue\n            func = importlib.import_module(current_module)\n            for part in line_stripped.split(\".\"):\n                func = getattr(func, part)\n\n            yield (\n                f\"{current_module}.{line_stripped}\",\n                func,\n                current_section,\n                current_subsection,\n            )\n\n        previous_line = line_stripped\n\n\nclass PandasDocstring(Validator):\n    def __init__(self, func_name: str, doc_obj=None) -> None:\n        self.func_name = func_name\n        if doc_obj is None:\n            doc_obj = get_doc_object(Validator._load_obj(func_name))\n        super().__init__(doc_obj)\n\n    @property\n    def name(self):\n        return self.func_name\n\n    @property\n    def mentioned_private_classes(self):\n        return [klass for klass in PRIVATE_CLASSES if klass in self.raw_doc]\n\n    @property\n    def examples_source_code(self):\n        lines = doctest.DocTestParser().get_examples(self.raw_doc)\n        return [line.source for line in lines]\n\n    def validate_pep8(self):\n        if not self.examples:\n            return\n\n        # F401 is needed to not generate flake8 errors in examples\n        # that do not user numpy or pandas\n        content = \"\".join(\n            (\n                \"import numpy as np  # noqa: F401\\n\",\n                \"import pandas as pd  # noqa: F401\\n\",\n                *self.examples_source_code,\n            )\n        )\n\n        error_messages = []\n\n        file = tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", delete=False)\n        try:\n            file.write(content)\n            file.flush()\n            cmd = [\n                \"python\",\n                \"-m\",\n                \"flake8\",\n                \"--format=%(row)d\\t%(col)d\\t%(code)s\\t%(text)s\",\n                \"--max-line-length=88\",\n                \"--ignore=E203,E3,W503,W504,E402,E731\",\n                file.name,\n            ]\n            response = subprocess.run(cmd, capture_output=True, check=False, text=True)\n            for output in (\"stdout\", \"stderr\"):\n                out = getattr(response, output)\n                out = out.replace(file.name, \"\")\n                messages = out.strip(\"\\n\").splitlines()\n                if messages:\n                    error_messages.extend(messages)\n        finally:\n            file.close()\n            os.unlink(file.name)\n\n        for error_message in error_messages:\n            line_number, col_number, error_code, message = error_message.split(\n                \"\\t\", maxsplit=3\n            )\n            # Note: we subtract 2 from the line number because\n            # 'import numpy as np\\nimport pandas as pd\\n'\n            # is prepended to the docstrings.\n            yield error_code, message, int(line_number) - 2, int(col_number)\n\n    def non_hyphenated_array_like(self):\n        return \"array_like\" in self.raw_doc\n\n\ndef pandas_validate(func_name: str):\n    \"\"\"\n    Call the numpydoc validation, and add the errors specific to pandas.\n\n    Parameters\n    ----------\n    func_name : str\n        Name of the object of the docstring to validate.\n\n    Returns\n    -------\n    dict\n        Information about the docstring and the errors found.\n    \"\"\"\n    func_obj = Validator._load_obj(func_name)\n    # Some objects are instances, e.g. IndexSlice, which numpydoc can't validate\n    doc_obj = get_doc_object(func_obj, doc=func_obj.__doc__)\n    doc = PandasDocstring(func_name, doc_obj)\n    result = validate(doc_obj)\n\n    mentioned_errs = doc.mentioned_private_classes\n    if mentioned_errs:\n        result[\"errors\"].append(\n            pandas_error(\"GL04\", mentioned_private_classes=\", \".join(mentioned_errs))\n        )\n\n    if doc.see_also:\n        result[\"errors\"].extend(\n            pandas_error(\n                \"SA05\",\n                reference_name=rel_name,\n                right_reference=rel_name[len(\"pandas.\") :],\n            )\n            for rel_name in doc.see_also\n            if rel_name.startswith(\"pandas.\")\n        )\n\n    result[\"examples_errs\"] = \"\"\n    if doc.examples:\n        for error_code, error_message, line_number, col_number in doc.validate_pep8():\n            result[\"errors\"].append(\n                pandas_error(\n                    \"EX03\",\n                    error_code=error_code,\n                    error_message=error_message,\n                    line_number=line_number,\n                    col_number=col_number,\n                )\n            )\n        examples_source_code = \"\".join(doc.examples_source_code)\n        result[\"errors\"].extend(\n            pandas_error(\"EX04\", imported_library=wrong_import)\n            for wrong_import in (\"numpy\", \"pandas\")\n            if f\"import {wrong_import}\" in examples_source_code\n        )\n\n    if doc.non_hyphenated_array_like():\n        result[\"errors\"].append(pandas_error(\"GL05\"))\n\n    plt.close(\"all\")\n    return result\n\n\ndef validate_all(prefix, ignore_deprecated=False, ignore_functions=None):\n    \"\"\"\n    Execute the validation of all docstrings, and return a dict with the\n    results.\n\n    Parameters\n    ----------\n    prefix : str or None\n        If provided, only the docstrings that start with this pattern will be\n        validated. If None, all docstrings will be validated.\n    ignore_deprecated: bool, default False\n        If True, deprecated objects are ignored when validating docstrings.\n    ignore_functions: list of str or None, default None\n        If not None, contains a list of function to ignore\n\n    Returns\n    -------\n    dict\n        A dictionary with an item for every function/method... containing\n        all the validation information.\n    \"\"\"\n    result = {}\n    seen = {}\n\n    ignore_functions = set(ignore_functions or [])\n\n    for func_name, _, section, subsection in get_all_api_items():\n        if func_name in ignore_functions:\n            continue\n        if prefix and not func_name.startswith(prefix):\n            continue\n        doc_info = pandas_validate(func_name)\n        if ignore_deprecated and doc_info[\"deprecated\"]:\n            continue\n        result[func_name] = doc_info\n\n        shared_code_key = doc_info[\"file\"], doc_info[\"file_line\"]\n        shared_code = seen.get(shared_code_key, \"\")\n        result[func_name].update(\n            {\n                \"in_api\": True,\n                \"section\": section,\n                \"subsection\": subsection,\n                \"shared_code_with\": shared_code,\n            }\n        )\n\n        seen[shared_code_key] = func_name\n\n    return result\n\n\ndef get_all_api_items():\n    base_path = pathlib.Path(__file__).parent.parent\n    api_doc_fnames = pathlib.Path(base_path, \"doc\", \"source\", \"reference\")\n    for api_doc_fname in api_doc_fnames.glob(\"*.rst\"):\n        with open(api_doc_fname, encoding=\"utf-8\") as f:\n            yield from get_api_items(f)\n\n\ndef print_validate_all_results(\n    prefix: str,\n    errors: list[str] | None,\n    output_format: str,\n    ignore_deprecated: bool,\n    ignore_functions: list[str] | None,\n):\n    if output_format not in (\"default\", \"json\", \"actions\"):\n        raise ValueError(f'Unknown output_format \"{output_format}\"')\n\n    result = validate_all(prefix, ignore_deprecated, ignore_functions)\n\n    if output_format == \"json\":\n        sys.stdout.write(json.dumps(result))\n        return 0\n\n    prefix = \"##[error]\" if output_format == \"actions\" else \"\"\n    exit_status = 0\n    for name, res in result.items():\n        for err_code, err_desc in res[\"errors\"]:\n            if errors and err_code not in errors:\n                continue\n            sys.stdout.write(\n                f'{prefix}{res[\"file\"]}:{res[\"file_line\"]}:'\n                f\"{err_code}:{name}:{err_desc}\\n\"\n            )\n            exit_status += 1\n\n    return exit_status\n\n\ndef print_validate_one_results(func_name: str) -> None:\n    def header(title, width=80, char=\"#\") -> str:\n        full_line = char * width\n        side_len = (width - len(title) - 2) // 2\n        adj = \"\" if len(title) % 2 == 0 else \" \"\n        title_line = f\"{char * side_len} {title}{adj} {char * side_len}\"\n\n        return f\"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\"\n\n    result = pandas_validate(func_name)\n\n    sys.stderr.write(header(f\"Docstring ({func_name})\"))\n    sys.stderr.write(f\"{result['docstring']}\\n\")\n\n    sys.stderr.write(header(\"Validation\"))\n    if result[\"errors\"]:\n        sys.stderr.write(f'{len(result[\"errors\"])} Errors found for `{func_name}`:\\n')\n        for err_code, err_desc in result[\"errors\"]:\n            sys.stderr.write(f\"\\t{err_code}\\t{err_desc}\\n\")\n    else:\n        sys.stderr.write(f'Docstring for \"{func_name}\" correct. :)\\n')\n\n    if result[\"examples_errs\"]:\n        sys.stderr.write(header(\"Doctests\"))\n        sys.stderr.write(result[\"examples_errs\"])\n\n\ndef main(func_name, prefix, errors, output_format, ignore_deprecated, ignore_functions):\n    \"\"\"\n    Main entry point. Call the validation for one or for all docstrings.\n    \"\"\"\n    if func_name is None:\n        return print_validate_all_results(\n            prefix,\n            errors,\n            output_format,\n            ignore_deprecated,\n            ignore_functions,\n        )\n    else:\n        print_validate_one_results(func_name)\n        return 0\n\n\nif __name__ == \"__main__\":\n    format_opts = \"default\", \"json\", \"actions\"\n    func_help = (\n        \"function or method to validate (e.g. pandas.DataFrame.head) \"\n        \"if not provided, all docstrings are validated and returned \"\n        \"as JSON\"\n    )\n    argparser = argparse.ArgumentParser(description=\"validate pandas docstrings\")\n    argparser.add_argument(\"function\", nargs=\"?\", default=None, help=func_help)\n    argparser.add_argument(\n        \"--format\",\n        default=\"default\",\n        choices=format_opts,\n        help=\"format of the output when validating \"\n        \"multiple docstrings (ignored when validating one). \"\n        \"It can be {str(format_opts)[1:-1]}\",\n    )\n    argparser.add_argument(\n        \"--prefix\",\n        default=None,\n        help=\"pattern for the \"\n        \"docstring names, in order to decide which ones \"\n        'will be validated. A prefix \"pandas.Series.str.\"'\n        \"will make the script validate all the docstrings \"\n        \"of methods starting by this pattern. It is \"\n        \"ignored if parameter function is provided\",\n    )\n    argparser.add_argument(\n        \"--errors\",\n        default=None,\n        help=\"comma separated \"\n        \"list of error codes to validate. By default it \"\n        \"validates all errors (ignored when validating \"\n        \"a single docstring)\",\n    )\n    argparser.add_argument(\n        \"--ignore_deprecated\",\n        default=False,\n        action=\"store_true\",\n        help=\"if this flag is set, \"\n        \"deprecated objects are ignored when validating \"\n        \"all docstrings\",\n    )\n    argparser.add_argument(\n        \"--ignore_functions\",\n        nargs=\"*\",\n        help=\"function or method to not validate \"\n        \"(e.g. pandas.DataFrame.head). \"\n        \"Inverse of the `function` argument.\",\n    )\n\n    args = argparser.parse_args()\n    sys.exit(\n        main(\n            args.function,\n            args.prefix,\n            args.errors.split(\",\") if args.errors else None,\n            args.format,\n            args.ignore_deprecated,\n            args.ignore_functions,\n        )\n    )\n"
    }
  ]
}