{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "11823",
  "issue_description": "# Dataframe loading with duplicated columns and usecols\n\nI'm using pandas 0.17.1\n\n``` python\nimport pandas as pd\n  pd.__version__\n```\n\n`Out:'0.17.1'`\n\nWhen column names are duplicated \n\n``` python\ncols = ['A', 'A', 'B']\nwith open('pandas.csv', 'w') as f:\n  f.write('1,2,3')\n```\n\nwe can still load dataframe\n\n``` python\npd.read_csv('pandas.csv',\n            header=None,\n            names=cols,\n           )\n```\n\n with explainable behaviour\n\n```\nOut:\n     A    A    B\n0    2    2    3\n```\n\nThen we might want to load some of the columns with python engine\n\n``` python\npd.read_csv('pandas.csv',\n            engine='python',\n            header=None,\n            names=cols,\n            usecols=cols\n           )\n```\n\nand get different but still explainable result\n\n```\nOut:\n     A    B\n0    1    3\n```\n\nBut then we switch back to c-engine\n\n``` python\npd.read_csv('pandas.csv',\n            engine='c',\n            header=None,\n            names=cols,\n            usecols=cols\n           )\n```\n\nand get the following\n\n```\nOut:\n     A    A    B\n0    2    2    NaN\n```\n\nwhich is:\n(a) different (which is not good in my opinion)\n(b) looks like bug\n",
  "issue_comments": [
    {
      "id": 163962321,
      "user": "jreback",
      "body": "we had an issue about this IIRC, but can't seem to locate it.\n\ncan you replace the top with some self-reproducing examples that demonstrate this? (use StringIO and in-line data)\n\n(its actually an easy fix, just need some tests cases). The issue is that we pass a dict of the results to the DataFrame constructor.\n"
    },
    {
      "id": 165682662,
      "user": "sxwang",
      "body": "Maybe I'm missing something, but this doesn't appear to be an easy fix ...\nThe c parser `pandas/parser.pyx` first converts the `usecols` to a set, removing duplicates:\n\nin `cdef class TextReader, function __init__`:\n\n``` python\n        # suboptimal\n        if usecols is not None:\n            self.has_usecols = 1\n            self.usecols = set(usecols)\n```\n\nBut then it seems that when it's reading the file, it stops after `len(usecols)` values are read. So in the example above, that 3rd column is never read:\nIn `TextReader._convert_column_data`:\n\n``` python\n            elif self.usecols and nused == len(self.usecols):\n                # Once we've gathered all requested columns, stop. GH5766\n                break\n```\n\nThis occurs before the dict of the result is passed to the DataFrame constructor.\nI'm wondering why `usecols` needs to be a set. Apart from that, any suggestions?\n"
    },
    {
      "id": 165788762,
      "user": "jreback",
      "body": "@sxwang yeh might be a bit more involved :)\n\nYou can try to change `usecols` to a list and see where that takes you\n"
    },
    {
      "id": 166499519,
      "user": "sxwang",
      "body": "Ok, I think `usecols` does not need to be a set, I changed it to a list, that seems to fix it for the c engine. I also updated the python engine to handle duplicated columns/usecols and now it should behave the same.\n"
    },
    {
      "id": 216395100,
      "user": "gfyoung",
      "body": "Just jumping in now: while I am +1 for changing `usecols` to a `list`, I am -0.5 for declaring the situation described in the issue as being a bug for `pandas`.  If you are using duplicate names and then specifying those same duplicate `str` names as `usecols`, that is inherently ambiguous IMO.  If you want to be crystal clear, you should be using integer indices instead.\n"
    },
    {
      "id": 221129835,
      "user": "gfyoung",
      "body": "Having played around with this issue for a little bit, the fix is not very clear-cut, and in fact the changes made in #11882 were not very robust.  This is because the underlying code currently assumes that we iterate through the column names in the original file _only once_ because we assume that the column names in `usecols` are unique.  This results in phenomenon like this using the changes in #11882:\n\n``` python\n>>> data = '1,2,3'\n>>> names = ['A', 'A', 'B']\n>>> read_csv(StringIO(data), names=names, usecols=[0,1,1], engine='c')\n   A  A.1    B\n0  1    2  NaN\n>>> read_csv(StringIO(data), names=names, usecols=[0,1,1], engine='python')\n   A  A.1\n0  1    2\n```\n\nThat leads to a couple of points and questions:\n\n1) A complete fix would involve refactoring the column iterations so that it varies depending on whether we have a `usecols` attribute (i.e. non-null) or not.  Is that complexity worth it?\n\n2) Duplicate string names - allowed or not?  I'm in the NOT camp because that is inherently ambiguous, especially if we have duplicate column names.  Duplicate integer indices are more acceptable IMO.\n\n3) How much should we allow the user to duplicate?  For example, should we allow `usecols=[1] * 1000` if `names=['a', 'b']`?\n\n<b>OR...</b>\n\nWhat is the use case exactly for being able to duplicate `usecols` like this?  Can we go for simple documentation change that says we process ONLY unique column names / indices and error if there are duplicates?\n"
    },
    {
      "id": 479455388,
      "user": "kimsey0",
      "body": "I've just been hit by this bug as well. I expected `pd.read_csv('pandas.csv', header=0, usecols=['A', 'B'])` to give the same result as `pd.read_csv('pandas.csv', header=0)` for a CSV file:\r\n\r\n```\r\nA,A,B\r\n1,2,3\r\n```\r\n\r\nI understand why this can't be changed now due to backwards compatibility, but it would at least be nice to document for parameter `usecols`."
    },
    {
      "id": 480892408,
      "user": "gfyoung",
      "body": "@kimsey : You're more than welcome to submit a PR for this!  A test for this might also be useful as well.  Duplicate columns in a CSV are quite buggy, so we mangle the second \"A\"."
    },
    {
      "id": 480895263,
      "user": "kimsey0",
      "body": "@gfyoung: I'd be happy to send a PR, but what for? Just a documentation change and a test?"
    },
    {
      "id": 480909595,
      "user": "gfyoung",
      "body": "Yep, that’s exactly right."
    },
    {
      "id": 488984555,
      "user": "kimsey0",
      "body": "I just came back to this and now I realize, I'm not even sure what behavior I'm supposed to be testing for. When using duplicate names and usecols, since I now know that the behavior I described in my first comment isn't correct, I'd then expect the first column with each name to be kept:\r\n\r\n``` python\r\n@pytest.mark.parametrize(\"names,usecols\", [\r\n    ([\"a\", \"a\", \"b\"], [\"a\", \"b\"]),\r\n    ([\"a\", \"a\", \"b\"], [\"a\", \"a\", \"b\"])\r\n])\r\ndef test_usecols_with_duplicate_names(all_parsers, names, usecols):\r\n    data = \"\"\"\\\r\n1,2,3\r\n4,5,6\r\n7,8,9\r\n10,11,12\"\"\"\r\n    parser = all_parsers\r\n    result = parser.read_csv(StringIO(data), names=names, usecols=usecols)\r\n\r\n    expected = DataFrame([[1, 3], [4, 6], [7, 9],\r\n                          [10, 12]], columns=[\"a\", \"b\"])\r\n    tm.assert_frame_equal(result, expected)\r\n```\r\n\r\nHowever, there's still a difference between the Python engine, in which this passes, and the C engine, in which the actual result is:\r\n```\r\n    a   b\r\n0   1   2\r\n1   4   5\r\n2   7   8\r\n3  10  11\r\n```\r\n\r\nIn any case, I'd expect the exact same result with `header=0` and the `names` put into the header."
    },
    {
      "id": 488986153,
      "user": "gfyoung",
      "body": "The discrepancy: Is this on the first iteration of the parameterization (of `names` and `usecols`)?  How about the second one?  Are those consistent?"
    },
    {
      "id": 488987152,
      "user": "kimsey0",
      "body": "It's the same result (the one above) for both parameterizations."
    },
    {
      "id": 489019475,
      "user": "gfyoung",
      "body": "Ah, I see what's happening.  Can you add the column names directly into `StringIO` data?  Passing in `names` with a duplicate column name is discouraged.\r\n\r\nThus, you should be only parameterizing on `usecols`."
    },
    {
      "id": 489024078,
      "user": "kimsey0",
      "body": "I have a separate test for `usecols` with a header which works as expected (keeps first column for each name). Passing in `names` may be discouraged, but it's not prevented, so shouldn't the behavior still be tested and documented?"
    },
    {
      "id": 489024591,
      "user": "gfyoung",
      "body": "No, it should not.  It only remains so that people have time to remove it from their code.  You should have seen a warning about this when you ran the test."
    },
    {
      "id": 489025455,
      "user": "kimsey0",
      "body": "I see. And you wouldn't want to test for that warning (and the error in the future)?"
    },
    {
      "id": 489027338,
      "user": "gfyoung",
      "body": "We already have tests for this behavior.  Warnings like that would absolutely have to have tests."
    },
    {
      "id": 489032963,
      "user": "kimsey0",
      "body": "Ah! I searched for \"Duplicate names specified\" and didn't find anything, but it's just specified as tests for `UserWarning`. I'll just keep the test with header names then."
    }
  ],
  "text_context": "# Dataframe loading with duplicated columns and usecols\n\nI'm using pandas 0.17.1\n\n``` python\nimport pandas as pd\n  pd.__version__\n```\n\n`Out:'0.17.1'`\n\nWhen column names are duplicated \n\n``` python\ncols = ['A', 'A', 'B']\nwith open('pandas.csv', 'w') as f:\n  f.write('1,2,3')\n```\n\nwe can still load dataframe\n\n``` python\npd.read_csv('pandas.csv',\n            header=None,\n            names=cols,\n           )\n```\n\n with explainable behaviour\n\n```\nOut:\n     A    A    B\n0    2    2    3\n```\n\nThen we might want to load some of the columns with python engine\n\n``` python\npd.read_csv('pandas.csv',\n            engine='python',\n            header=None,\n            names=cols,\n            usecols=cols\n           )\n```\n\nand get different but still explainable result\n\n```\nOut:\n     A    B\n0    1    3\n```\n\nBut then we switch back to c-engine\n\n``` python\npd.read_csv('pandas.csv',\n            engine='c',\n            header=None,\n            names=cols,\n            usecols=cols\n           )\n```\n\nand get the following\n\n```\nOut:\n     A    A    B\n0    2    2    NaN\n```\n\nwhich is:\n(a) different (which is not good in my opinion)\n(b) looks like bug\n\n\nwe had an issue about this IIRC, but can't seem to locate it.\n\ncan you replace the top with some self-reproducing examples that demonstrate this? (use StringIO and in-line data)\n\n(its actually an easy fix, just need some tests cases). The issue is that we pass a dict of the results to the DataFrame constructor.\n\n\nMaybe I'm missing something, but this doesn't appear to be an easy fix ...\nThe c parser `pandas/parser.pyx` first converts the `usecols` to a set, removing duplicates:\n\nin `cdef class TextReader, function __init__`:\n\n``` python\n        # suboptimal\n        if usecols is not None:\n            self.has_usecols = 1\n            self.usecols = set(usecols)\n```\n\nBut then it seems that when it's reading the file, it stops after `len(usecols)` values are read. So in the example above, that 3rd column is never read:\nIn `TextReader._convert_column_data`:\n\n``` python\n            elif self.usecols and nused == len(self.usecols):\n                # Once we've gathered all requested columns, stop. GH5766\n                break\n```\n\nThis occurs before the dict of the result is passed to the DataFrame constructor.\nI'm wondering why `usecols` needs to be a set. Apart from that, any suggestions?\n\n\n@sxwang yeh might be a bit more involved :)\n\nYou can try to change `usecols` to a list and see where that takes you\n\n\nOk, I think `usecols` does not need to be a set, I changed it to a list, that seems to fix it for the c engine. I also updated the python engine to handle duplicated columns/usecols and now it should behave the same.\n\n\nJust jumping in now: while I am +1 for changing `usecols` to a `list`, I am -0.5 for declaring the situation described in the issue as being a bug for `pandas`.  If you are using duplicate names and then specifying those same duplicate `str` names as `usecols`, that is inherently ambiguous IMO.  If you want to be crystal clear, you should be using integer indices instead.\n\n\nHaving played around with this issue for a little bit, the fix is not very clear-cut, and in fact the changes made in #11882 were not very robust.  This is because the underlying code currently assumes that we iterate through the column names in the original file _only once_ because we assume that the column names in `usecols` are unique.  This results in phenomenon like this using the changes in #11882:\n\n``` python\n>>> data = '1,2,3'\n>>> names = ['A', 'A', 'B']\n>>> read_csv(StringIO(data), names=names, usecols=[0,1,1], engine='c')\n   A  A.1    B\n0  1    2  NaN\n>>> read_csv(StringIO(data), names=names, usecols=[0,1,1], engine='python')\n   A  A.1\n0  1    2\n```\n\nThat leads to a couple of points and questions:\n\n1) A complete fix would involve refactoring the column iterations so that it varies depending on whether we have a `usecols` attribute (i.e. non-null) or not.  Is that complexity worth it?\n\n2) Duplicate string names - allowed or not?  I'm in the NOT camp because that is inherently ambiguous, especially if we have duplicate column names.  Duplicate integer indices are more acceptable IMO.\n\n3) How much should we allow the user to duplicate?  For example, should we allow `usecols=[1] * 1000` if `names=['a', 'b']`?\n\n<b>OR...</b>\n\nWhat is the use case exactly for being able to duplicate `usecols` like this?  Can we go for simple documentation change that says we process ONLY unique column names / indices and error if there are duplicates?\n\n\nI've just been hit by this bug as well. I expected `pd.read_csv('pandas.csv', header=0, usecols=['A', 'B'])` to give the same result as `pd.read_csv('pandas.csv', header=0)` for a CSV file:\r\n\r\n```\r\nA,A,B\r\n1,2,3\r\n```\r\n\r\nI understand why this can't be changed now due to backwards compatibility, but it would at least be nice to document for parameter `usecols`.\n\n@kimsey : You're more than welcome to submit a PR for this!  A test for this might also be useful as well.  Duplicate columns in a CSV are quite buggy, so we mangle the second \"A\".\n\n@gfyoung: I'd be happy to send a PR, but what for? Just a documentation change and a test?\n\nYep, that’s exactly right.\n\nI just came back to this and now I realize, I'm not even sure what behavior I'm supposed to be testing for. When using duplicate names and usecols, since I now know that the behavior I described in my first comment isn't correct, I'd then expect the first column with each name to be kept:\r\n\r\n``` python\r\n@pytest.mark.parametrize(\"names,usecols\", [\r\n    ([\"a\", \"a\", \"b\"], [\"a\", \"b\"]),\r\n    ([\"a\", \"a\", \"b\"], [\"a\", \"a\", \"b\"])\r\n])\r\ndef test_usecols_with_duplicate_names(all_parsers, names, usecols):\r\n    data = \"\"\"\\\r\n1,2,3\r\n4,5,6\r\n7,8,9\r\n10,11,12\"\"\"\r\n    parser = all_parsers\r\n    result = parser.read_csv(StringIO(data), names=names, usecols=usecols)\r\n\r\n    expected = DataFrame([[1, 3], [4, 6], [7, 9],\r\n                          [10, 12]], columns=[\"a\", \"b\"])\r\n    tm.assert_frame_equal(result, expected)\r\n```\r\n\r\nHowever, there's still a difference between the Python engine, in which this passes, and the C engine, in which the actual result is:\r\n```\r\n    a   b\r\n0   1   2\r\n1   4   5\r\n2   7   8\r\n3  10  11\r\n```\r\n\r\nIn any case, I'd expect the exact same result with `header=0` and the `names` put into the header.\n\nThe discrepancy: Is this on the first iteration of the parameterization (of `names` and `usecols`)?  How about the second one?  Are those consistent?\n\nIt's the same result (the one above) for both parameterizations.\n\nAh, I see what's happening.  Can you add the column names directly into `StringIO` data?  Passing in `names` with a duplicate column name is discouraged.\r\n\r\nThus, you should be only parameterizing on `usecols`.\n\nI have a separate test for `usecols` with a header which works as expected (keeps first column for each name). Passing in `names` may be discouraged, but it's not prevented, so shouldn't the behavior still be tested and documented?\n\nNo, it should not.  It only remains so that people have time to remove it from their code.  You should have seen a warning about this when you ran the test.\n\nI see. And you wouldn't want to test for that warning (and the error in the future)?\n\nWe already have tests for this behavior.  Warnings like that would absolutely have to have tests.\n\nAh! I searched for \"Duplicate names specified\" and didn't find anything, but it's just specified as tests for `UserWarning`. I'll just keep the test with header names then.",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/53683",
  "code_context": [
    {
      "filename": "pandas/tests/io/parser/test_mangle_dupes.py",
      "content": "\"\"\"\nTests that duplicate columns are handled appropriately when parsed by the\nCSV engine. In general, the expected result is that they are either thoroughly\nde-duplicated (if mangling requested) or ignored otherwise.\n\"\"\"\nfrom io import StringIO\n\nimport pytest\n\nfrom pandas import DataFrame\nimport pandas._testing as tm\n\nskip_pyarrow = pytest.mark.usefixtures(\"pyarrow_skip\")\n\n\n@skip_pyarrow\ndef test_basic(all_parsers):\n    parser = all_parsers\n\n    data = \"a,a,b,b,b\\n1,2,3,4,5\"\n    result = parser.read_csv(StringIO(data), sep=\",\")\n\n    expected = DataFrame([[1, 2, 3, 4, 5]], columns=[\"a\", \"a.1\", \"b\", \"b.1\", \"b.2\"])\n    tm.assert_frame_equal(result, expected)\n\n\n@skip_pyarrow\ndef test_basic_names(all_parsers):\n    # See gh-7160\n    parser = all_parsers\n\n    data = \"a,b,a\\n0,1,2\\n3,4,5\"\n    expected = DataFrame([[0, 1, 2], [3, 4, 5]], columns=[\"a\", \"b\", \"a.1\"])\n\n    result = parser.read_csv(StringIO(data))\n    tm.assert_frame_equal(result, expected)\n\n\ndef test_basic_names_raise(all_parsers):\n    # See gh-7160\n    parser = all_parsers\n\n    data = \"0,1,2\\n3,4,5\"\n    with pytest.raises(ValueError, match=\"Duplicate names\"):\n        parser.read_csv(StringIO(data), names=[\"a\", \"b\", \"a\"])\n\n\n@skip_pyarrow\n@pytest.mark.parametrize(\n    \"data,expected\",\n    [\n        (\"a,a,a.1\\n1,2,3\", DataFrame([[1, 2, 3]], columns=[\"a\", \"a.2\", \"a.1\"])),\n        (\n            \"a,a,a.1,a.1.1,a.1.1.1,a.1.1.1.1\\n1,2,3,4,5,6\",\n            DataFrame(\n                [[1, 2, 3, 4, 5, 6]],\n                columns=[\"a\", \"a.2\", \"a.1\", \"a.1.1\", \"a.1.1.1\", \"a.1.1.1.1\"],\n            ),\n        ),\n        (\n            \"a,a,a.3,a.1,a.2,a,a\\n1,2,3,4,5,6,7\",\n            DataFrame(\n                [[1, 2, 3, 4, 5, 6, 7]],\n                columns=[\"a\", \"a.4\", \"a.3\", \"a.1\", \"a.2\", \"a.5\", \"a.6\"],\n            ),\n        ),\n    ],\n)\ndef test_thorough_mangle_columns(all_parsers, data, expected):\n    # see gh-17060\n    parser = all_parsers\n\n    result = parser.read_csv(StringIO(data))\n    tm.assert_frame_equal(result, expected)\n\n\n@skip_pyarrow\n@pytest.mark.parametrize(\n    \"data,names,expected\",\n    [\n        (\n            \"a,b,b\\n1,2,3\",\n            [\"a.1\", \"a.1\", \"a.1.1\"],\n            DataFrame(\n                [[\"a\", \"b\", \"b\"], [\"1\", \"2\", \"3\"]], columns=[\"a.1\", \"a.1.1\", \"a.1.1.1\"]\n            ),\n        ),\n        (\n            \"a,b,c,d,e,f\\n1,2,3,4,5,6\",\n            [\"a\", \"a\", \"a.1\", \"a.1.1\", \"a.1.1.1\", \"a.1.1.1.1\"],\n            DataFrame(\n                [[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"], [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]],\n                columns=[\"a\", \"a.1\", \"a.1.1\", \"a.1.1.1\", \"a.1.1.1.1\", \"a.1.1.1.1.1\"],\n            ),\n        ),\n        (\n            \"a,b,c,d,e,f,g\\n1,2,3,4,5,6,7\",\n            [\"a\", \"a\", \"a.3\", \"a.1\", \"a.2\", \"a\", \"a\"],\n            DataFrame(\n                [\n                    [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"],\n                    [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"],\n                ],\n                columns=[\"a\", \"a.1\", \"a.3\", \"a.1.1\", \"a.2\", \"a.2.1\", \"a.3.1\"],\n            ),\n        ),\n    ],\n)\ndef test_thorough_mangle_names(all_parsers, data, names, expected):\n    # see gh-17095\n    parser = all_parsers\n\n    with pytest.raises(ValueError, match=\"Duplicate names\"):\n        parser.read_csv(StringIO(data), names=names)\n\n\n@skip_pyarrow\ndef test_mangled_unnamed_placeholders(all_parsers):\n    # xref gh-13017\n    orig_key = \"0\"\n    parser = all_parsers\n\n    orig_value = [1, 2, 3]\n    df = DataFrame({orig_key: orig_value})\n\n    # This test recursively updates `df`.\n    for i in range(3):\n        expected = DataFrame()\n\n        for j in range(i + 1):\n            col_name = \"Unnamed: 0\" + f\".{1*j}\" * min(j, 1)\n            expected.insert(loc=0, column=col_name, value=[0, 1, 2])\n\n        expected[orig_key] = orig_value\n        df = parser.read_csv(StringIO(df.to_csv()))\n\n        tm.assert_frame_equal(df, expected)\n\n\n@skip_pyarrow\ndef test_mangle_dupe_cols_already_exists(all_parsers):\n    # GH#14704\n    parser = all_parsers\n\n    data = \"a,a,a.1,a,a.3,a.1,a.1.1\\n1,2,3,4,5,6,7\"\n    result = parser.read_csv(StringIO(data))\n    expected = DataFrame(\n        [[1, 2, 3, 4, 5, 6, 7]],\n        columns=[\"a\", \"a.2\", \"a.1\", \"a.4\", \"a.3\", \"a.1.2\", \"a.1.1\"],\n    )\n    tm.assert_frame_equal(result, expected)\n\n\n@skip_pyarrow\ndef test_mangle_dupe_cols_already_exists_unnamed_col(all_parsers):\n    # GH#14704\n    parser = all_parsers\n\n    data = \",Unnamed: 0,,Unnamed: 2\\n1,2,3,4\"\n    result = parser.read_csv(StringIO(data))\n    expected = DataFrame(\n        [[1, 2, 3, 4]],\n        columns=[\"Unnamed: 0.1\", \"Unnamed: 0\", \"Unnamed: 2.1\", \"Unnamed: 2\"],\n    )\n    tm.assert_frame_equal(result, expected)\n\n\n@skip_pyarrow\n@pytest.mark.parametrize(\"usecol, engine\", [([0, 1, 1], \"python\"), ([0, 1, 1], \"c\")])\ndef test_mangle_cols_names(all_parsers, usecol, engine):\n    # GH 11823\n    parser = all_parsers\n    data = \"1,2,3\"\n    names = [\"A\", \"A\", \"B\"]\n    with pytest.raises(ValueError, match=\"Duplicate names\"):\n        parser.read_csv(StringIO(data), names=names, usecols=usecol, engine=engine)\n"
    }
  ],
  "questions": [
    "we had an issue about this IIRC, but can't seem to locate it.\n\ncan you replace the top with some self-reproducing examples that demonstrate this? (use StringIO and in-line data)\n\n(its actually an easy fix, just need some tests cases). The issue is that we pass a dict of the results to the DataFrame constructor.",
    "Maybe I'm missing something, but this doesn't appear to be an easy fix ...\nThe c parser `pandas/parser.pyx` first converts the `usecols` to a set, removing duplicates:\n\nin `cdef class TextReader, function __init__`:\n\n``` python\n        # suboptimal\n        if usecols is not None:\n            self.has_usecols = 1\n            self.usecols = set(usecols)\n```\n\nBut then it seems that when it's reading the file, it stops after `len(usecols)` values are read. So in the example above, that 3rd column is never read:\nIn `TextReader._convert_column_data`:\n\n``` python\n            elif self.usecols and nused == len(self.usecols):\n                # Once we've gathered all requested columns, stop. GH5766\n                break\n```\n\nThis occurs before the dict of the result is passed to the DataFrame constructor.\nI'm wondering why `usecols` needs to be a set. Apart from that, any suggestions?",
    "Having played around with this issue for a little bit, the fix is not very clear-cut, and in fact the changes made in #11882 were not very robust.  This is because the underlying code currently assumes that we iterate through the column names in the original file _only once_ because we assume that the column names in `usecols` are unique.  This results in phenomenon like this using the changes in #11882:\n\n``` python\n>>> data = '1,2,3'\n>>> names = ['A', 'A', 'B']\n>>> read_csv(StringIO(data), names=names, usecols=[0,1,1], engine='c')\n   A  A.1    B\n0  1    2  NaN\n>>> read_csv(StringIO(data), names=names, usecols=[0,1,1], engine='python')\n   A  A.1\n0  1    2\n```\n\nThat leads to a couple of points and questions:\n\n1) A complete fix would involve refactoring the column iterations so that it varies depending on whether we have a `usecols` attribute (i.e. non-null) or not.  Is that complexity worth it?\n\n2) Duplicate string names - allowed or not?  I'm in the NOT camp because that is inherently ambiguous, especially if we have duplicate column names.  Duplicate integer indices are more acceptable IMO.\n\n3) How much should we allow the user to duplicate?  For example, should we allow `usecols=[1] * 1000` if `names=['a', 'b']`?\n\n<b>OR...</b>\n\nWhat is the use case exactly for being able to duplicate `usecols` like this?  Can we go for simple documentation change that says we process ONLY unique column names / indices and error if there are duplicates?",
    "The discrepancy: Is this on the first iteration of the parameterization (of `names` and `usecols`)?  How about the second one?  Are those consistent?",
    "Ah, I see what's happening.  Can you add the column names directly into `StringIO` data?  Passing in `names` with a duplicate column name is discouraged.\r\n\r\nThus, you should be only parameterizing on `usecols`."
  ],
  "golden_answers": [
    "Maybe I'm missing something, but this doesn't appear to be an easy fix ...\nThe c parser `pandas/parser.pyx` first converts the `usecols` to a set, removing duplicates:\n\nin `cdef class TextReader, function __init__`:\n\n``` python\n        # suboptimal\n        if usecols is not None:\n            self.has_usecols = 1\n            self.usecols = set(usecols)\n```\n\nBut then it seems that when it's reading the file, it stops after `len(usecols)` values are read. So in the example above, that 3rd column is never read:\nIn `TextReader._convert_column_data`:\n\n``` python\n            elif self.usecols and nused == len(self.usecols):\n                # Once we've gathered all requested columns, stop. GH5766\n                break\n```\n\nThis occurs before the dict of the result is passed to the DataFrame constructor.\nI'm wondering why `usecols` needs to be a set. Apart from that, any suggestions?",
    "@sxwang yeh might be a bit more involved :)\n\nYou can try to change `usecols` to a list and see where that takes you",
    "I've just been hit by this bug as well. I expected `pd.read_csv('pandas.csv', header=0, usecols=['A', 'B'])` to give the same result as `pd.read_csv('pandas.csv', header=0)` for a CSV file:\r\n\r\n```\r\nA,A,B\r\n1,2,3\r\n```\r\n\r\nI understand why this can't be changed now due to backwards compatibility, but it would at least be nice to document for parameter `usecols`.",
    "Ah, I see what's happening.  Can you add the column names directly into `StringIO` data?  Passing in `names` with a duplicate column name is discouraged.\r\n\r\nThus, you should be only parameterizing on `usecols`.",
    "I have a separate test for `usecols` with a header which works as expected (keeps first column for each name). Passing in `names` may be discouraged, but it's not prevented, so shouldn't the behavior still be tested and documented?"
  ],
  "questions_generated": [
    "Why does the C-engine in pandas convert 'usecols' to a set, and how does this impact the handling of duplicated columns?",
    "What is the discrepancy between the Python and C parsers in handling duplicated column names with the 'usecols' parameter?",
    "What is the suggested solution to address the issue of duplicated columns when using 'usecols' in the C-engine, and what challenges might arise from this change?",
    "Why does the issue of duplicated column names with 'usecols' not appear to be a straightforward bug in pandas, according to the discussion?",
    "How do the test cases in 'pandas/tests/io/parser/test_mangle_dupes.py' illustrate the handling of duplicate columns, and what is the expected behavior?"
  ],
  "golden_answers_generated": [
    "In the C-engine implementation of pandas' read_csv function, 'usecols' is converted to a set to eliminate duplicates, as seen in the 'TextReader' class initialization. This impacts the handling of duplicated columns because sets inherently do not allow duplicate values. Consequently, when using 'usecols' with duplicated columns, only unique columns are retained, which can lead to unexpected behavior such as the omission of some columns when reading the CSV file.",
    "The Python parser allows the use of duplicated column names with the 'usecols' parameter and interprets them as separate columns, resulting in behavior that matches the specified column order. In contrast, the C parser converts 'usecols' to a set, which removes duplicates. This leads to the C parser potentially stopping after reading the number of unique columns in 'usecols', resulting in different behavior from the Python parser, such as missing columns or NaN values.",
    "The suggested solution is to change 'usecols' from a set to a list, allowing duplicated column names to be preserved. This change aims to align the behavior of the C-engine with the Python engine. However, challenges might include ensuring that this modification does not introduce other unintended side effects or performance issues, as sets are typically used for their efficiency in checking membership and removing duplicates.",
    "The issue is not considered a straightforward bug because using duplicate names and specifying those same duplicate names in 'usecols' is inherently ambiguous. The pandas library is designed with certain assumptions about column uniqueness, and deviating from this can lead to unexpected behavior. The discussion suggests that although there is room for improvement in consistency between parsers, the situation arises from user input ambiguity rather than a clear defect in the library's logic.",
    "The test cases in 'test_mangle_dupes.py' demonstrate how pandas handles duplicate columns during CSV parsing. For example, test cases such as 'test_basic' and 'test_basic_names' showcase the creation of DataFrames where duplicate columns are automatically mangled by appending suffixes like '.1', '.2', etc., to ensure uniqueness. The expected behavior is that when duplicate columns are present, they should either be thoroughly de-duplicated through mangling or ignored based on the parser's settings. These test cases help verify that pandas correctly handles duplicates and aligns with the specified behavior."
  ]
}