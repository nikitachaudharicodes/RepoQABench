{
  "repo_name": "pandas-dev_pandas",
  "issue_id": "2311",
  "issue_description": "# Wish: Input / output for Open Document Spreadsheet (ODS)\n\nIt would be nice to have, along with XLS and XLSX, also support for ODS (used notably by OpenOffice.org and Libreoffice, but not only that). \n\nThe main problem I saw is that there's a plethora of libraries to handle that: however not sure which is the \"best\" one (with a licensing that would fit with pandas).\n",
  "issue_comments": [
    {
      "id": 11415188,
      "user": "paulproteus",
      "body": "It seems to me the best option for this would be:\n- Start with a simple test case for input and output, and handle that using this library: http://simple-odspy.sourceforge.net/ -- sample code: http://simple-odspy.sourceforge.net/?q=node/5\n- If there are more complex cases where simple-odspy is not enough, one can use the more heavyweight http://pypi.python.org/pypi/odfpy library\n\nThis would be a rather substantial bit of work.\n\nA good start for the test cases would be to look at pandas/io/tests/test_excel.py and write test cases that mirror what is in that file.\n"
    },
    {
      "id": 56499306,
      "user": "H0R5E",
      "body": "+1 for this feature.\n\nWorking on an open-source data wrangling project and I would like to be able to interact with spreadsheet software that is not Excel.\n"
    },
    {
      "id": 56537436,
      "user": "jtratner",
      "body": "@H0R5E for now, you could just convert the resulting excel file to ODS (it's pretty much a simple set of numbers, nothing more): http://stackoverflow.com/questions/15257032/python-convert-excel-file-xls-or-xlsx-to-from-ods or you could use json as an intermediary and use `tablib` to export to ODS: https://pypi.python.org/pypi/tablib\n"
    },
    {
      "id": 62874685,
      "user": "robertmuil",
      "body": "+1 for this!\n"
    },
    {
      "id": 63241805,
      "user": "davidovitch",
      "body": "I want to tune in with some additional notes:\n- [odfpy](https://github.com/eea/odfpy) is now living on Github, and seems to get some attention now and then.\n- I bumped into [ezodf](https://github.com/T0ha/ezodf), which, contrary to simple-odspy, seems to be still under development. It does not depend on odfpy. The docs are [here](http://packages.python.org/ezodf), and some examples [here](https://github.com/T0ha/ezodf/tree/master/examples).\n\nBased on some initial looks, ezodf has a straight forward interface. For example, loading an ods spreadsheet into a DataFrame could go as follows:\n\n``` python\nimport pandas as pd\nimport ezodf\ndoc = ezodf.opendoc('somefile.ods')\n\nprint(\"Spreadsheet contains %d sheets.\\n\" % len(doc.sheets))\nfor sheet in doc.sheets:\n    if sheet.name == 'data':\n        data = sheet\n    print(\"Sheet name: '%s'\" % sheet.name)\n    print(\"Size of Sheet : (rows=%d, cols=%d)\" % (sheet.nrows(), sheet.ncols()) )\n    print(\"-\"*40)\n\n# a random cell\npos = (row, col)\ndata.get_cell(pos).display_form\n\ndf_dict = {}\nfor i, col in enumerate(data.columns()):\n    # col is a list that contains all the cells (rows of that column)\n    # assume the column name is on the first row\n    colname = col[0].display_form\n    df_dict[colname] = []\n    print(colname)\n    for j, row in enumerate(col):\n        # ignore the header\n        if j == 0:\n            continue\n        else:\n            df_dict[col_name].append(row.display_form)\n# and convert to a DataFrame\ndf = pd.DataFrame(df_dict)\n```\n\nI have no idea how odfpy and ezodf compare performance wise, or how their different memory footprints are for very large spreadsheets. I haven't tried to use odfpy because that seems more complicated to get going with. I also have not checked how robust the writing process of ezodf is. I'll try to see if I can get something similar going as for pandas/io/tests/test_excel.py. \n\nI will also mention @sorenroug from odfpy and @T0ha from ezodf just in case someone from upstream is interested in this discussion.\n"
    },
    {
      "id": 63556987,
      "user": "davidovitch",
      "body": "After a short exploration, it seems doable to create an ods prototype reader based on the structure of pandas/io/excel.py using the ezodf module. I've forked pandas [here](https://github.com/davidovitch/pandas) and will implement an ods prototype reader in the io-ods branch. \n"
    },
    {
      "id": 64939161,
      "user": "jtratner",
      "body": "@davidovitch - one thing to keep in mind if you choose to handle both writing and reading: you can register an ODS writer in the excel module (just implementing the required methods as listed in the code) and then you can just add a simple subclass of the excel writer tests and get a ton of test cases for free. Just a thought.\n"
    },
    {
      "id": 97719317,
      "user": "davidovitch",
      "body": "I would like to give an update on the current status. My [fork](https://github.com/davidovitch/pandas) can currently read ODF ODS files, but writing is not implemented yet. The corresponding pull request is still pending review, and it has been a lot more work than I originally anticipated.\n\nJust a few days ago I bumped into yet another library to read/write spreadsheet: [pyexcel](https://github.com/chfw/pyexcel). What is different about this library is that it aims at creating a single API for all the different read/write libraries, and it builds on all the existing libraries out there (ezodf, xlrd, etc). This is actually kind of similar to what pandas currently has, and to what I am trying to extend in PR #9070. So I am wondering, would it make sense to use a single API library (with optional dependencies to all the relevant readers/writers for the different spreadsheet types) instead of developing something similar, but tailored to pandas use case? I am speculating that a lot of code in io/excel.py could be removed when relying on pyexcel, but it adds yet another dependency. At this stage I am not sure how all different edge cases on data types and other magic happening inside the spreadsheet interpretation differs between the current pandas implementation and pyexcel. \n"
    },
    {
      "id": 136961103,
      "user": "davidovitch",
      "body": "The ods reader is not ready for the upcoming 0.17 release. PR #9070 is closed (see the PR for a technical discussion), and a new improved PR will be made by someone at some point in the future. I have a working version in the [ezodf_reader](https://github.com/davidovitch/pandas/tree/ezodf_reader) branch of my pandas fork in case someone wants to have a look at it. Suggestions and improvements are welcome :-)\n"
    },
    {
      "id": 140695120,
      "user": "H0R5E",
      "body": "@davidovitch thanks for your efforts! Its a shame that that reading and writing to ODF is not better supported in python, otherwise I'm sure this would be less of an ordeal.\n"
    },
    {
      "id": 153016604,
      "user": "PBrockmann",
      "body": "Working on how to structure data for paleoclimatology community, I would like to promote ODS as the standard format.  Then of course, pandas with this possible reading and writing at ODS format would become the natural way to start nice analysis.\n\n+2 and more for this feature that seems so closed to be released.\n"
    },
    {
      "id": 153159487,
      "user": "naught101",
      "body": "You should almost certainly be using netcdf for paleoclimate data. It's more or less industry standard. Checkout the python package 'xray' for a nice way to interface with it.\n\nOn 3 November 2015 12:30:20 am AEDT, Patrick Brockmann notifications@github.com wrote:\n\n> Working on how to structure data for paleoclimatology community, I\n> would like to promote ODS as the standard format.  Then of course,\n> pandas with this possible reading and writing at ODS format would\n> become the natural way for IO and start nice analysis.\n> \n> +2 and more for this feature that seems so closed to be released.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/pydata/pandas/issues/2311#issuecomment-153016604\n\n## \n\nSent from my Android device with K-9 Mail. Please excuse my brevity.\n"
    },
    {
      "id": 153187504,
      "user": "PBrockmann",
      "body": "@naught101: I know quite well netCDF format and some conventions like CF (Climate and Forecast) widely used in the Earth System Modelling community but it seems that the PaleoClimate one has also good argument to keep working with others standard. An article that is under discussion describes this motivation and promote a JSON-LD format. Read https://www.authorea.com/users/17200/articles/19163/_show_article and please feel free to contribute it. \nIn my understanding, the data themselves are not problematic, the difficulty comes more from the metadata that are in many aspect hierachical. Netcdf attributs are in this case not very well designed.\nOn the other hand, describe those metadata with a simple spreadsheet with a dotted notation in an open source format like ODS (I will do a proposition in this way) could be interesting because it will not radically change the behaviour of PaleoClimate scientists that widelly work with spreadsheets.\nAll this, to say that if pandas could allow IO from ODS, it could be a good motivation to start their analysis with pandas.  \n"
    },
    {
      "id": 153257808,
      "user": "shoyer",
      "body": "@PBrockmann If your metadata is hierarchical, maybe it would be appropriate to use the hierarchical features of netCDF4/HDF5? Just a thought. In any case, I think we agree regardless that ODS support would be valuable for pandas.\n"
    },
    {
      "id": 160306853,
      "user": "hnykda",
      "body": "Is there any progress on this? Thanks\n"
    },
    {
      "id": 160477811,
      "user": "jreback",
      "body": "@hnykda there is a PR #9070 that is not far away, but needs some work if you'd like to pick it up.\n"
    },
    {
      "id": 160573882,
      "user": "hnykda",
      "body": "Will take a look at it. Thank you for pointing it out. \n"
    },
    {
      "id": 274235051,
      "user": "jameserrico",
      "body": "On a similar note has anyone considered Google Sheets?  There are some limits to the size of a sheet (http://gappstips.com/google-sheets/google-spreadsheet-limitations/) that probably make it only usable for some cases but there are quite a lot of datasets that would fit within this restrictions and the ease of collaboration with Sheets is nice."
    },
    {
      "id": 307256187,
      "user": "detrout",
      "body": "@jameserrico There's a library https://github.com/embr/gcat that can read from google drive. I have a fork that I updated to work with python3 https://github.com/detrout/gcat but upstream hasn't merged the pull-request\r\n\r\nIt knows how to return pandas data frames. I.e. I have some code like this:\r\n```python\r\n    book = gcat.get_file(book_name, fmt='pandas_excel')\r\n    experiments = book.parse('Experiments', header=0)`"
    },
    {
      "id": 308931610,
      "user": "detrout",
      "body": "I have a standalone reader styled like pandas.io.excel with tests.\r\nhttps://github.com/detrout/pandasodf\r\n\r\nIt uses odfpy as that seems like its still maintained. Any comments, or should I try reformatting into a pull request creating  pandas/io/odf.py?\r\n\r\nI thought the .read_odf method seemed more reasonable, than overloading .read_excel"
    },
    {
      "id": 308932362,
      "user": "naught101",
      "body": "> I thought the .read_odf method seemed more reasonable, than overloading .read_excel \r\n\r\nMakes sense. Perhaps there could be a `read_spreadsheet` that calls `read_csv`, `read_excel`, `read_odf` etc, depending on the extension?"
    },
    {
      "id": 309091634,
      "user": "detrout",
      "body": "@naught101 The general reader might have some difficulties since there are differences in what the various formats support. CSV/TSV only have a single table, while Excel & ODF can have multiple tables per file. \r\n\r\nAlso I'm currently contemplating passing the raw odfpy xml cell node for the converters callable, so those would be quite difficult to write if you didn't know the source file type."
    },
    {
      "id": 320587113,
      "user": "davidovitch",
      "body": "> I thought the .read_odf method seemed more reasonable, than overloading .read_excel\r\n\r\n@detrout FYI, maybe things have changed since, but at the time of PR #9070 there was a very clear decision by the pandas devs not to do that and to keep ```read_excel``` for both the Excel and Open Document Format families."
    },
    {
      "id": 465905980,
      "user": "TrigonaMinima",
      "body": "@jreback is https://github.com/pandas-dev/pandas/pull/9070 the right starting point on this or do you suggest starting with something else?"
    },
    {
      "id": 465921282,
      "user": "jreback",
      "body": "yes that issue is a good starting point\r\n\r\nnote that the internal code org has changed a lot since then "
    },
    {
      "id": 508277129,
      "user": "H0R5E",
      "body": "Great to see the ODS reader implemented. Well done! I'm not sure this should have been closed though, as writing still isn't supported.\r\n\r\n"
    },
    {
      "id": 508277425,
      "user": "jreback",
      "body": "i would open a new issue for write support (if it’s really needed)"
    }
  ],
  "text_context": "# Wish: Input / output for Open Document Spreadsheet (ODS)\n\nIt would be nice to have, along with XLS and XLSX, also support for ODS (used notably by OpenOffice.org and Libreoffice, but not only that). \n\nThe main problem I saw is that there's a plethora of libraries to handle that: however not sure which is the \"best\" one (with a licensing that would fit with pandas).\n\n\nIt seems to me the best option for this would be:\n- Start with a simple test case for input and output, and handle that using this library: http://simple-odspy.sourceforge.net/ -- sample code: http://simple-odspy.sourceforge.net/?q=node/5\n- If there are more complex cases where simple-odspy is not enough, one can use the more heavyweight http://pypi.python.org/pypi/odfpy library\n\nThis would be a rather substantial bit of work.\n\nA good start for the test cases would be to look at pandas/io/tests/test_excel.py and write test cases that mirror what is in that file.\n\n\n+1 for this feature.\n\nWorking on an open-source data wrangling project and I would like to be able to interact with spreadsheet software that is not Excel.\n\n\n@H0R5E for now, you could just convert the resulting excel file to ODS (it's pretty much a simple set of numbers, nothing more): http://stackoverflow.com/questions/15257032/python-convert-excel-file-xls-or-xlsx-to-from-ods or you could use json as an intermediary and use `tablib` to export to ODS: https://pypi.python.org/pypi/tablib\n\n\n+1 for this!\n\n\nI want to tune in with some additional notes:\n- [odfpy](https://github.com/eea/odfpy) is now living on Github, and seems to get some attention now and then.\n- I bumped into [ezodf](https://github.com/T0ha/ezodf), which, contrary to simple-odspy, seems to be still under development. It does not depend on odfpy. The docs are [here](http://packages.python.org/ezodf), and some examples [here](https://github.com/T0ha/ezodf/tree/master/examples).\n\nBased on some initial looks, ezodf has a straight forward interface. For example, loading an ods spreadsheet into a DataFrame could go as follows:\n\n``` python\nimport pandas as pd\nimport ezodf\ndoc = ezodf.opendoc('somefile.ods')\n\nprint(\"Spreadsheet contains %d sheets.\\n\" % len(doc.sheets))\nfor sheet in doc.sheets:\n    if sheet.name == 'data':\n        data = sheet\n    print(\"Sheet name: '%s'\" % sheet.name)\n    print(\"Size of Sheet : (rows=%d, cols=%d)\" % (sheet.nrows(), sheet.ncols()) )\n    print(\"-\"*40)\n\n# a random cell\npos = (row, col)\ndata.get_cell(pos).display_form\n\ndf_dict = {}\nfor i, col in enumerate(data.columns()):\n    # col is a list that contains all the cells (rows of that column)\n    # assume the column name is on the first row\n    colname = col[0].display_form\n    df_dict[colname] = []\n    print(colname)\n    for j, row in enumerate(col):\n        # ignore the header\n        if j == 0:\n            continue\n        else:\n            df_dict[col_name].append(row.display_form)\n# and convert to a DataFrame\ndf = pd.DataFrame(df_dict)\n```\n\nI have no idea how odfpy and ezodf compare performance wise, or how their different memory footprints are for very large spreadsheets. I haven't tried to use odfpy because that seems more complicated to get going with. I also have not checked how robust the writing process of ezodf is. I'll try to see if I can get something similar going as for pandas/io/tests/test_excel.py. \n\nI will also mention @sorenroug from odfpy and @T0ha from ezodf just in case someone from upstream is interested in this discussion.\n\n\nAfter a short exploration, it seems doable to create an ods prototype reader based on the structure of pandas/io/excel.py using the ezodf module. I've forked pandas [here](https://github.com/davidovitch/pandas) and will implement an ods prototype reader in the io-ods branch. \n\n\n@davidovitch - one thing to keep in mind if you choose to handle both writing and reading: you can register an ODS writer in the excel module (just implementing the required methods as listed in the code) and then you can just add a simple subclass of the excel writer tests and get a ton of test cases for free. Just a thought.\n\n\nI would like to give an update on the current status. My [fork](https://github.com/davidovitch/pandas) can currently read ODF ODS files, but writing is not implemented yet. The corresponding pull request is still pending review, and it has been a lot more work than I originally anticipated.\n\nJust a few days ago I bumped into yet another library to read/write spreadsheet: [pyexcel](https://github.com/chfw/pyexcel). What is different about this library is that it aims at creating a single API for all the different read/write libraries, and it builds on all the existing libraries out there (ezodf, xlrd, etc). This is actually kind of similar to what pandas currently has, and to what I am trying to extend in PR #9070. So I am wondering, would it make sense to use a single API library (with optional dependencies to all the relevant readers/writers for the different spreadsheet types) instead of developing something similar, but tailored to pandas use case? I am speculating that a lot of code in io/excel.py could be removed when relying on pyexcel, but it adds yet another dependency. At this stage I am not sure how all different edge cases on data types and other magic happening inside the spreadsheet interpretation differs between the current pandas implementation and pyexcel. \n\n\nThe ods reader is not ready for the upcoming 0.17 release. PR #9070 is closed (see the PR for a technical discussion), and a new improved PR will be made by someone at some point in the future. I have a working version in the [ezodf_reader](https://github.com/davidovitch/pandas/tree/ezodf_reader) branch of my pandas fork in case someone wants to have a look at it. Suggestions and improvements are welcome :-)\n\n\n@davidovitch thanks for your efforts! Its a shame that that reading and writing to ODF is not better supported in python, otherwise I'm sure this would be less of an ordeal.\n\n\nWorking on how to structure data for paleoclimatology community, I would like to promote ODS as the standard format.  Then of course, pandas with this possible reading and writing at ODS format would become the natural way to start nice analysis.\n\n+2 and more for this feature that seems so closed to be released.\n\n\nYou should almost certainly be using netcdf for paleoclimate data. It's more or less industry standard. Checkout the python package 'xray' for a nice way to interface with it.\n\nOn 3 November 2015 12:30:20 am AEDT, Patrick Brockmann notifications@github.com wrote:\n\n> Working on how to structure data for paleoclimatology community, I\n> would like to promote ODS as the standard format.  Then of course,\n> pandas with this possible reading and writing at ODS format would\n> become the natural way for IO and start nice analysis.\n> \n> +2 and more for this feature that seems so closed to be released.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/pydata/pandas/issues/2311#issuecomment-153016604\n\n## \n\nSent from my Android device with K-9 Mail. Please excuse my brevity.\n\n\n@naught101: I know quite well netCDF format and some conventions like CF (Climate and Forecast) widely used in the Earth System Modelling community but it seems that the PaleoClimate one has also good argument to keep working with others standard. An article that is under discussion describes this motivation and promote a JSON-LD format. Read https://www.authorea.com/users/17200/articles/19163/_show_article and please feel free to contribute it. \nIn my understanding, the data themselves are not problematic, the difficulty comes more from the metadata that are in many aspect hierachical. Netcdf attributs are in this case not very well designed.\nOn the other hand, describe those metadata with a simple spreadsheet with a dotted notation in an open source format like ODS (I will do a proposition in this way) could be interesting because it will not radically change the behaviour of PaleoClimate scientists that widelly work with spreadsheets.\nAll this, to say that if pandas could allow IO from ODS, it could be a good motivation to start their analysis with pandas.  \n\n\n@PBrockmann If your metadata is hierarchical, maybe it would be appropriate to use the hierarchical features of netCDF4/HDF5? Just a thought. In any case, I think we agree regardless that ODS support would be valuable for pandas.\n\n\nIs there any progress on this? Thanks\n\n\n@hnykda there is a PR #9070 that is not far away, but needs some work if you'd like to pick it up.\n\n\nWill take a look at it. Thank you for pointing it out. \n\n\nOn a similar note has anyone considered Google Sheets?  There are some limits to the size of a sheet (http://gappstips.com/google-sheets/google-spreadsheet-limitations/) that probably make it only usable for some cases but there are quite a lot of datasets that would fit within this restrictions and the ease of collaboration with Sheets is nice.\n\n@jameserrico There's a library https://github.com/embr/gcat that can read from google drive. I have a fork that I updated to work with python3 https://github.com/detrout/gcat but upstream hasn't merged the pull-request\r\n\r\nIt knows how to return pandas data frames. I.e. I have some code like this:\r\n```python\r\n    book = gcat.get_file(book_name, fmt='pandas_excel')\r\n    experiments = book.parse('Experiments', header=0)`\n\nI have a standalone reader styled like pandas.io.excel with tests.\r\nhttps://github.com/detrout/pandasodf\r\n\r\nIt uses odfpy as that seems like its still maintained. Any comments, or should I try reformatting into a pull request creating  pandas/io/odf.py?\r\n\r\nI thought the .read_odf method seemed more reasonable, than overloading .read_excel\n\n> I thought the .read_odf method seemed more reasonable, than overloading .read_excel \r\n\r\nMakes sense. Perhaps there could be a `read_spreadsheet` that calls `read_csv`, `read_excel`, `read_odf` etc, depending on the extension?\n\n@naught101 The general reader might have some difficulties since there are differences in what the various formats support. CSV/TSV only have a single table, while Excel & ODF can have multiple tables per file. \r\n\r\nAlso I'm currently contemplating passing the raw odfpy xml cell node for the converters callable, so those would be quite difficult to write if you didn't know the source file type.\n\n> I thought the .read_odf method seemed more reasonable, than overloading .read_excel\r\n\r\n@detrout FYI, maybe things have changed since, but at the time of PR #9070 there was a very clear decision by the pandas devs not to do that and to keep ```read_excel``` for both the Excel and Open Document Format families.\n\n@jreback is https://github.com/pandas-dev/pandas/pull/9070 the right starting point on this or do you suggest starting with something else?\n\nyes that issue is a good starting point\r\n\r\nnote that the internal code org has changed a lot since then \n\nGreat to see the ODS reader implemented. Well done! I'm not sure this should have been closed though, as writing still isn't supported.\r\n\r\n\n\ni would open a new issue for write support (if it’s really needed)",
  "pr_link": "https://github.com/pandas-dev/pandas/pull/9070",
  "code_context": [
    {
      "filename": "pandas/io/excel.py",
      "content": "\"\"\"\nModule parse to/from Excel\n\"\"\"\n\n#----------------------------------------------------------------------\n# ExcelFile class\nfrom __future__ import print_function\n\nimport os\nimport re\nimport datetime\nimport abc\nimport numpy as np\n\nfrom pandas.core.frame import DataFrame\nfrom pandas.io.parsers import TextParser\nfrom pandas.io.common import _is_url, _urlopen\nfrom pandas.tseries.period import Period\nfrom pandas import json\nfrom pandas.compat import (map, zip, reduce, range, lrange, u, add_metaclass,\n                           BytesIO, string_types)\nfrom pandas.core import config\nfrom pandas.core.common import pprint_thing\nimport pandas.compat as compat\nimport pandas.compat.openpyxl_compat as openpyxl_compat\nimport pandas.core.common as com\nfrom warnings import warn\nfrom distutils.version import LooseVersion\n\n__all__ = [\"read_excel\", \"ExcelWriter\", \"ExcelFile\"]\n\n_writer_extensions = [\"xlsx\", \"xls\", \"xlsm\"]\n_writers = {}\n_readers = {}\n_reader_extensions = {}\n\n\ndef register_writer(klass):\n    \"\"\"Adds engine to the excel writer registry. You must use this method to\n    integrate with ``to_excel``. Also adds config options for any new\n    ``supported_extensions`` defined on the writer.\"\"\"\n    if not compat.callable(klass):\n        raise ValueError(\"Can only register callables as engines\")\n    engine_name = klass.engine\n    _writers[engine_name] = klass\n    for ext in klass.supported_extensions:\n        if ext.startswith('.'):\n            ext = ext[1:]\n        if ext not in _writer_extensions:\n            config.register_option(\"io.excel.%s.writer\" % ext,\n                                   engine_name, validator=str)\n            _writer_extensions.append(ext)\n\n\ndef get_writer(engine_name):\n    if engine_name == 'openpyxl':\n        try:\n            import openpyxl\n\n            # with version-less openpyxl engine\n            # make sure we make the intelligent choice for the user\n            if LooseVersion(openpyxl.__version__) < '2.0.0':\n                 return _writers['openpyxl1']\n            else:\n                 return _writers['openpyxl2']\n        except ImportError:\n            # fall through to normal exception handling below\n            pass\n\n    try:\n        return _writers[engine_name]\n    except KeyError:\n        raise ValueError(\"No Excel writer '%s'\" % engine_name)\n\n\nclass BaseFile(object):\n    \"\"\"Base class for excel readers\n\n    A file class can be initialized even if the engine is not installed.\n    If the engine is not installed, io_class and workbook_factory are None.\n    When attempting to use open_workbook while workbook_factory is None, the\n    relevant ImportError is raised.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Set the engine name, and extension. If the engine is not installed,\n        io_class and workbook_factory are both None.\n        \"\"\"\n        self.io_class = None\n        self.workbook_factory = None\n\n    def open_workbook(self, *args, **kwargs):\n        \"\"\"Explicitely load the engine again (and trigger an ImportError in the\n        process) if workbook_factory is set to None.\n        \"\"\"\n        # try to load the engine again and raise import error if required\n        if self.workbook_factory is None:\n            self.load_engine()\n        # just in case the user passes an already opened workbook of io_class\n        if len(args) > 0 and isinstance(args[0], self.io_class):\n            self.book = args[0]\n        else:\n            self.book = self.workbook_factory(*args, **kwargs)\n        return self.book\n\n    def create_reader(self, io, engine=None):\n        \"\"\"Create the appropriate reader object based on io and optionally\n        engine.\n\n        Paratemeters\n        ------------\n        io : string, file-like object or xlrd/ezodf workbook\n            If a string, expected to be a path to xls, xlsx, or ods file.\n            File-like objects or buffers are only supported for xlrd types.\n\n        engine: string, default None\n            If io is not a buffer or path, this must be set to identify io.\n            Acceptable values are None, xlrd, or ezodf\n\n        Returns\n        -------\n        engine : string\n            Engine used for reading the io\n\n        book : object\n            The spreadsheet book class created by the engine.\n        \"\"\"\n\n        if engine is not None:\n            try:\n                reader = _readers[engine]\n            except KeyError:\n                msg = 'Excel reader engine \"%s\" is not implemented' % engine\n                raise NotImplementedError(msg)\n            # load_engine throws the relevant import error if not installed\n            reader.load_engine()\n            reader.open_workbook(io)\n            return reader\n\n        if isinstance(io, compat.string_types):\n            ext = io.split('.')[-1]\n            try:\n                reader = _reader_extensions[ext]\n            except KeyError:\n                msg = 'No reader implemented for extension \"%s\"' % ext\n                raise NotImplementedError(msg)\n            reader.load_engine()\n            if _is_url(io):\n                data = _urlopen(io).read()\n                reader.read_buffer(data)\n            else:\n                reader.open_workbook(io)\n            return reader\n\n        # try to determine the reader type based on properties of installed\n        # reader modules.\n        for engine, reader in compat.iteritems(_readers):\n            # only try to import readers that have not been imported before\n            if reader.io_class is None:\n                try:\n                    reader.load_engine()\n                # if the reader is not installed, the user could not have\n                # passed the corresponding reader.io_class, so it is safe\n                # to assume that io is not the current reader\n                except ImportError:\n                    continue\n            # Does the io type match the currently selected reader?\n            if isinstance(io, reader.io_class):\n                reader.engine = engine\n                reader.book = io\n                return reader\n            # xlrd has some additional/alternative reading mechanisms:\n            elif engine=='xlrd' and hasattr(io, \"read\"):\n                # N.B. xlrd.Book has a read attribute too\n                reader.read_buffer(io.read())\n                return reader\n\n        raise ValueError('Must explicitly set engine if not passing in buffer '\n                         'or path for io.')\n\n\nclass XLRDFile(BaseFile):\n    \"\"\"File reader class for MS Excel spreadsheets (depends on xlrd)\n    \"\"\"\n    extensions = ['xls', 'xlsx', 'xlsm']\n    engine = 'xlrd'\n\n    def load_engine(self):\n        import xlrd  # throw an ImportError if we need to\n        ver = tuple(map(int, xlrd.__VERSION__.split(\".\")[:2]))\n        if ver < (0, 9):  # pragma: no cover\n            raise ImportError(\"pandas requires xlrd >= 0.9.0 for excel \"\n                              \"support, current version \" + xlrd.__VERSION__)\n        else:\n            self.workbook_factory = xlrd.open_workbook\n            self.io_class = xlrd.Book\n\n    def read_buffer(self, data):\n        \"\"\"Read from a buffer\n        \"\"\"\n        return self.open_workbook(file_contents=data)\n\n\nclass EZODFFile(BaseFile):\n    \"\"\"File reader class for ODF spreadsheets (depends on ezodf)\n    \"\"\"\n    extensions = ['ods']\n    engine = 'ezodf'\n\n    def load_engine(self):\n        import ezodf # throw an ImportError if we need to\n        self.workbook_factory = ezodf.opendoc\n        self.io_class = ezodf.document.PackagedDocument\n\n    def read_buffer(self, *args, **kwargs):\n        \"\"\"\n        \"\"\"\n        msg = 'Can not read ODF spreadsheet from a buffer or URL.'\n        raise NotImplementedError(msg)\n\n\n# register all supported readers\ndef register_readers():\n    \"\"\"\n    Establish which readers are supported and/or installed.\n    \"\"\"\n\n    def populate(reader):\n        _readers[reader.engine] = reader\n        for ext in reader.extensions:\n            _reader_extensions[ext] = reader\n\n    populate(XLRDFile())\n    populate(EZODFFile())\n\nregister_readers()\n\n\ndef read_excel(io, sheetname=0, **kwds):\n    \"\"\"Read an Excel/ods table into a pandas DataFrame\n\n    Parameters\n    ----------\n    io : string, file-like object, or xlrd workbook for MS Excel files. For an\n        ods file (Open Document Formant), string or ezodf workbook is required.\n        The string could be a URL. Valid URL schemes include http, ftp, s3,\n        and file. For file URLs, a host is expected. For instance, a local\n        file could be file://localhost/path/to/workbook.xlsx\n    sheetname : string, int, mixed list of strings/ints, or None, default 0\n\n        Strings are used for sheet names, Integers are used in zero-indexed sheet\n        positions.\n\n        Lists of strings/integers are used to request multiple sheets.\n\n        Specify None to get all sheets.\n\n        str|int -> DataFrame is returned.\n        list|None -> Dict of DataFrames is returned, with keys representing sheets.\n\n        Available Cases\n\n        * Defaults to 0 -> 1st sheet as a DataFrame\n        * 1 -> 2nd sheet as a DataFrame\n        * \"Sheet1\" -> 1st sheet as a DataFrame\n        * [0,1,\"Sheet5\"] -> 1st, 2nd & 5th sheet as a dictionary of DataFrames\n        * None -> All sheets as a dictionary of DataFrames\n\n    header : int, default 0\n        Row to use for the column labels of the parsed DataFrame\n    skiprows : list-like\n        Rows to skip at the beginning (0-indexed)\n    skip_footer : int, default 0\n        Rows at the end to skip (0-indexed)\n    converters : dict, default None\n        Dict of functions for converting values in certain columns. Keys can\n        either be integers or column labels, values are functions that take one\n        input argument, the Excel/ods cell content, and return the transformed\n        content.\n    index_col : int, default None\n        Column to use as the row labels of the DataFrame. Pass None if\n        there is no such column\n    parse_cols : int or list, default None\n        * If None then parse all columns,\n        * If int then indicates last column to be parsed\n        * If list of ints then indicates list of column numbers to be parsed\n        * If string then indicates comma separated list of column names and\n          column ranges (e.g. \"A:E\" or \"A,C,E:F\")\n    na_values : list-like, default None\n        List of additional strings to recognize as NA/NaN\n    keep_default_na : bool, default True\n        If na_values are specified and keep_default_na is False the default NaN\n        values are overridden, otherwise they're appended to\n    verbose : boolean, default False\n        Indicate number of NA values placed in non-numeric columns\n    engine: string, default None\n        If io is not a buffer or path, this must be set to identify io.\n        Acceptable values are None, xlrd, or ezodf\n    convert_float : boolean, default True\n        convert integral floats to int (i.e., 1.0 --> 1). If False, all numeric\n        data will be read in as floats: Excel/ods stores all numbers as floats\n        internally\n    has_index_names : boolean, default False\n        True if the cols defined in index_col have an index name and are\n        not in the header. Index name will be placed on a separate line below\n        the header.\n\n    Returns\n    -------\n    parsed : DataFrame or Dict of DataFrames\n        DataFrame from the passed in Excel file.  See notes in sheetname argument\n        for more information on when a Dict of Dataframes is returned.\n\n    \"\"\"\n    engine = kwds.pop('engine', None)\n\n    return ExcelFile(io, engine=engine).parse(sheetname=sheetname, **kwds)\n\n\nclass ExcelFile(object):\n    \"\"\"\n    Class for parsing tabular excel sheets into DataFrame objects.\n    Uses xlrd and/or ezodf. See ExcelFile.parse for more documentation\n\n    Parameters\n    ----------\n    io : string, file-like object or xlrd/ezodf workbook\n        If a string, expected to be a path to xls, xlsx, or ods file\n    engine: string, default None\n        If io is not a buffer or path, this must be set to identify io.\n        Acceptable values are None, xlrd, or ezodf\n    \"\"\"\n    def __init__(self, io, **kwds):\n        self.io = io\n\n        engine = kwds.pop('engine', None)\n        self.reader = BaseFile().create_reader(io, engine=engine)\n\n    def parse(self, sheetname=0, header=0, skiprows=None, skip_footer=0,\n              index_col=None, parse_cols=None, parse_dates=False,\n              date_parser=None, na_values=None, thousands=None, chunksize=None,\n              convert_float=True, has_index_names=False, converters=None, **kwds):\n        \"\"\"Read an Excel table into DataFrame\n\n        Parameters\n        ----------\n        sheetname : string, int, mixed list of strings/ints, or None, default 0\n\n            Strings are used for sheet names, Integers are used in zero-indexed sheet\n            positions.\n\n            Lists of strings/integers are used to request multiple sheets.\n\n            Specify None to get all sheets.\n\n            str|int -> DataFrame is returned.\n            list|None -> Dict of DataFrames is returned, with keys representing sheets.\n\n            Available Cases\n\n            * Defaults to 0 -> 1st sheet as a DataFrame\n            * 1 -> 2nd sheet as a DataFrame\n            * \"Sheet1\" -> 1st sheet as a DataFrame\n            * [0,1,\"Sheet5\"] -> 1st, 2nd & 5th sheet as a dictionary of DataFrames\n            * None -> All sheets as a dictionary of DataFrames\n        header : int, default 0\n            Row to use for the column labels of the parsed DataFrame\n        skiprows : list-like\n            Rows to skip at the beginning (0-indexed)\n        skip_footer : int, default 0\n            Rows at the end to skip (0-indexed)\n        converters : dict, default None\n            Dict of functions for converting values in certain columns. Keys can\n            either be integers or column labels\n        index_col : int, default None\n            Column to use as the row labels of the DataFrame. Pass None if\n            there is no such column\n        parse_cols : int or list, default None\n            * If None then parse all columns\n            * If int then indicates last column to be parsed\n            * If list of ints then indicates list of column numbers to be\n              parsed\n            * If string then indicates comma separated list of column names and\n              column ranges (e.g. \"A:E\" or \"A,C,E:F\")\n        parse_dates : boolean, default False\n            Parse date Excel values,\n        date_parser : function default None\n            Date parsing function\n        na_values : list-like, default None\n            List of additional strings to recognize as NA/NaN\n        thousands : str, default None\n            Thousands separator\n        chunksize : int, default None\n            Size of file chunk to read for lazy evaluation.\n        convert_float : boolean, default True\n            convert integral floats to int (i.e., 1.0 --> 1). If False, all\n            numeric data will be read in as floats: Excel stores all numbers as\n            floats internally.\n        has_index_names : boolean, default False\n            True if the cols defined in index_col have an index name and are\n            not in the header\n        verbose : boolean, default False\n            Set to True to print a single statement when reading each\n            excel sheet.\n\n        Returns\n        -------\n        parsed : DataFrame or Dict of DataFrames\n            DataFrame from the passed in Excel file.  See notes in sheetname argument\n            for more information on when a Dict of Dataframes is returned.\n        \"\"\"\n        skipfooter = kwds.pop('skipfooter', None)\n        if skipfooter is not None:\n            skip_footer = skipfooter\n\n        if self.reader.engine == 'ezodf':\n            parser = self._parse_ods\n        elif self.reader.engine == 'xlrd':\n            parser = self._parse_excel\n        else:\n            raise ValueError('Engine is not specified.')\n\n        return parser(sheetname=sheetname, header=header,\n                      skiprows=skiprows,\n                      index_col=index_col,\n                      has_index_names=has_index_names,\n                      parse_cols=parse_cols,\n                      parse_dates=parse_dates,\n                      date_parser=date_parser, na_values=na_values,\n                      thousands=thousands, chunksize=chunksize,\n                      skip_footer=skip_footer,\n                      convert_float=convert_float,\n                      converters=converters,\n                      **kwds)\n\n    def _should_parse(self, i, parse_cols):\n\n        def _range2cols(areas):\n            \"\"\"\n            Convert comma separated list of column names and column ranges to a\n            list of 0-based column indexes.\n\n            >>> _range2cols('A:E')\n            [0, 1, 2, 3, 4]\n            >>> _range2cols('A,C,Z:AB')\n            [0, 2, 25, 26, 27]\n            \"\"\"\n            def _excel2num(x):\n                \"Convert Excel column name like 'AB' to 0-based column index\"\n                return reduce(lambda s, a: s * 26 + ord(a) - ord('A') + 1,\n                              x.upper().strip(), 0) - 1\n\n            cols = []\n            for rng in areas.split(','):\n                if ':' in rng:\n                    rng = rng.split(':')\n                    cols += lrange(_excel2num(rng[0]), _excel2num(rng[1]) + 1)\n                else:\n                    cols.append(_excel2num(rng))\n            return cols\n\n        if isinstance(parse_cols, int):\n            return i <= parse_cols\n        elif isinstance(parse_cols, compat.string_types):\n            return i in _range2cols(parse_cols)\n        else:\n            return i in parse_cols\n\n    def _parse_excel(self, sheetname=0, header=0, skiprows=None, skip_footer=0,\n                     index_col=None, has_index_names=None, parse_cols=None,\n                     parse_dates=False, date_parser=None, na_values=None,\n                     thousands=None, chunksize=None, convert_float=True,\n                     verbose=False, **kwds):\n        import xlrd\n        from xlrd import (xldate, XL_CELL_DATE,\n                          XL_CELL_ERROR, XL_CELL_BOOLEAN,\n                          XL_CELL_NUMBER)\n\n        epoch1904 = self.reader.book.datemode\n\n        def _parse_cell(cell_contents, cell_typ):\n            \"\"\"converts the contents of the cell into a pandas\n               appropriate object\"\"\"\n\n            if cell_typ == XL_CELL_DATE:\n                if xlrd_0_9_3:\n                    # Use the newer xlrd datetime handling.\n                    cell_contents = xldate.xldate_as_datetime(cell_contents,\n                                                              epoch1904)\n\n                    # Excel doesn't distinguish between dates and time,\n                    # so we treat dates on the epoch as times only.\n                    # Also, Excel supports 1900 and 1904 epochs.\n                    year = (cell_contents.timetuple())[0:3]\n                    if ((not epoch1904 and year == (1899, 12, 31))\n                            or (epoch1904 and year == (1904, 1, 1))):\n                        cell_contents = datetime.time(cell_contents.hour,\n                                              cell_contents.minute,\n                                              cell_contents.second,\n                                              cell_contents.microsecond)\n                else:\n                    # Use the xlrd <= 0.9.2 date handling.\n                    dt = xldate.xldate_as_tuple(cell_contents, epoch1904)\n\n                    if dt[0] < datetime.MINYEAR:\n                        cell_contents = datetime.time(*dt[3:])\n                    else:\n                        cell_contents = datetime.datetime(*dt)\n\n            elif cell_typ == XL_CELL_ERROR:\n                cell_contents = np.nan\n            elif cell_typ == XL_CELL_BOOLEAN:\n                cell_contents = bool(cell_contents)\n            elif convert_float and cell_typ == XL_CELL_NUMBER:\n                # GH5394 - Excel 'numbers' are always floats\n                # it's a minimal perf hit and less suprising\n                val = int(cell_contents)\n                if val == cell_contents:\n                    cell_contents = val\n            return cell_contents\n\n        # xlrd >= 0.9.3 can return datetime objects directly.\n        if LooseVersion(xlrd.__VERSION__) >= LooseVersion(\"0.9.3\"):\n            xlrd_0_9_3 = True\n        else:\n            xlrd_0_9_3 = False\n\n        ret_dict = False\n\n        # Keep sheetname to maintain backwards compatibility.\n        if isinstance(sheetname, list):\n            sheets = sheetname\n            ret_dict = True\n        elif sheetname is None:\n            sheets = self.sheet_names\n            ret_dict = True\n        else:\n            sheets = [sheetname]\n\n        # handle same-type duplicates.\n        sheets = list(set(sheets))\n\n        output = {}\n\n        for asheetname in sheets:\n            if verbose:\n                print(\"Reading sheet %s\" % asheetname)\n\n            if isinstance(asheetname, compat.string_types):\n                sheet = self.reader.book.sheet_by_name(asheetname)\n            else:  # assume an integer if not a string\n                sheet = self.reader.book.sheet_by_index(asheetname)\n\n            data = []\n            should_parse = {}\n\n            for i in range(sheet.nrows):\n                row = []\n                for j, (value, typ) in enumerate(zip(sheet.row_values(i),\n                                                     sheet.row_types(i))):\n                    if parse_cols is not None and j not in should_parse:\n                        should_parse[j] = self._should_parse(j, parse_cols)\n\n                    if parse_cols is None or should_parse[j]:\n                        row.append(_parse_cell(value, typ))\n                data.append(row)\n\n            if sheet.nrows == 0:\n                return DataFrame()\n\n            if header is not None:\n                data[header] = _trim_excel_header(data[header])\n\n            parser = TextParser(data, header=header, index_col=index_col,\n                                has_index_names=has_index_names,\n                                na_values=na_values,\n                                thousands=thousands,\n                                parse_dates=parse_dates,\n                                date_parser=date_parser,\n                                skiprows=skiprows,\n                                skip_footer=skip_footer,\n                                chunksize=chunksize,\n                                **kwds)\n\n            output[asheetname] = parser.read()\n\n        if ret_dict:\n            return output\n        else:\n            return output[asheetname]\n\n    def _parse_ods(self, sheetname=0, header=0, skiprows=None, skip_footer=0,\n                   index_col=None, has_index_names=None, parse_cols=None,\n                   parse_dates=False, date_parser=None, na_values=None,\n                   thousands=None, chunksize=None, convert_float=True,\n                   verbose=False, **kwds):\n        # adds support for parsing ODS files, see PR #9070\n\n        def _parse_cell(cell):\n            \"\"\"converts the contents of the cell into a pandas\n               appropriate object\"\"\"\n            if isinstance(cell.value, float):\n                value = cell.value\n                if convert_float:\n                    # GH5394 - Excel and ODS 'numbers' are always floats\n                    # it's a minimal perf hit and less suprising\n                    # FIXME: this goes wrong when int(cell.value) returns\n                    # a long (>1e18)\n                    val = int(cell.value)\n                    if val == cell.value:\n                        value = val\n            elif isinstance(cell.value, compat.string_types):\n                typ = cell.value_type\n                if typ == 'date' or typ == 'time':\n                    value = self._parse_datetime(cell)\n                else:\n                    value = cell.value\n            elif isinstance(cell.value, bool):\n                value = cell.value\n            # empty cells have None as value, type, currency, formula.\n            # xlrd assigns empty string to empty cells, ezodf assigns None\n            # test_excel.ExcelReaderTests.test_reader_converters expects empty\n            # cells to be an empty string\n            elif isinstance(cell.value, type(None)):\n                value = ''\n            else:\n                value = np.nan\n            return value\n\n        ret_dict = False\n        # find numbers for the date/time object conversion\n        self.regex = re.compile('[[0-9]*[\\\\.[0-9]+]*]*')\n\n        # Keep sheetname to maintain backwards compatibility.\n        if isinstance(sheetname, list):\n            sheets = sheetname\n            ret_dict = True\n        elif sheetname is None:\n            sheets = self.sheet_names\n            ret_dict = True\n        else:\n            sheets = [sheetname]\n\n        # handle same-type duplicates.\n        sheets = list(set(sheets))\n\n        output = {}\n\n        for asheetname in sheets:\n            if verbose:\n                print(\"Reading sheet %s\" % asheetname)\n\n            # sheetname can be index or string\n            sheet = self.reader.book.sheets[asheetname]\n\n            data = []\n            should_parse = {}\n            for i in range(sheet.nrows()):\n                row = []\n                for j, cell in enumerate(sheet.row(i)):\n\n                    if parse_cols is not None and j not in should_parse:\n                        should_parse[j] = self._should_parse(j, parse_cols)\n\n                    if parse_cols is None or should_parse[j]:\n                        row.append(_parse_cell(cell))\n\n                data.append(row)\n\n            parser = TextParser(data, header=header, index_col=index_col,\n                                has_index_names=has_index_names,\n                                na_values=na_values,\n                                thousands=thousands,\n                                parse_dates=parse_dates,\n                                date_parser=date_parser,\n                                skiprows=skiprows,\n                                skip_footer=skip_footer,\n                                chunksize=chunksize,\n                                **kwds)\n            output[asheetname] = parser.read()\n\n        if ret_dict:\n            return output\n        else:\n            return output[asheetname]\n\n    def _parse_datetime(self, cell):\n        \"\"\"Parse the date or time from on ods cell to a datetime object.\n        Formats returned by ezodf are documented here:\n        https://pythonhosted.org/ezodf/tableobjects.html#cell-class\n\n        Because time cells can also be timedeltas, all time fields that exceed\n        23 hours are converted to a timedelta object.\n\n        Date string value formats: 'yyyy-mm-dd' or 'yyyy-mm-ddThh:mm:ss'\n\n        Time string value format: 'PThhHmmMss,ffffS'\n        \"\"\"\n\n        def _sec_split_micro(seconds):\n            \"\"\"Split a floatingpoint second value into an integer second value\n            and an integer microsecond value.\n            \"\"\"\n            sec = float(seconds)\n            sec_i = int(sec)\n            microsec = int(round((sec - sec_i)*1e6, 0))\n            return sec_i, microsec\n\n        def _timedelta(items):\n            \"\"\"\n            Possible formats for formulas are:\n                'of:=TIME(%H;%M;%S)'\n                'of:=TIME(%H;%M;%S.%fS)'\n            Possible formats for values are:\n                'PT%HH%MM%S.%fS'\n                'PT%HH%MM%SS'\n            \"\"\"\n            hours, minutes, seconds = items\n            return datetime.timedelta(hours=int(hours), minutes=int(minutes),\n                                      seconds=float(seconds))\n\n        def _time(items):\n            hours, minutes, seconds = items\n            sec_i, microsec = _sec_split_micro(seconds)\n            return datetime.time(int(hours), int(minutes), sec_i, microsec)\n\n        def _datetime(items):\n            \"\"\"\n            Possible formats for values are:\n                '%Y-%m-%d'\n                '%Y-%m-%dT%H:%M:%S'\n                '%Y-%m-%dT%H:%M:%S.%f'\n            \"\"\"\n\n            if len(items) == 3:\n                year, month, day = [int(k) for k in items]\n                return datetime.datetime(year, month, day)\n            else:\n                year, month, day, hours, minutes = [int(k) for k in items[:-1]]\n                # seconds can be a float, convert to microseconds\n                sec_i, microsec = _sec_split_micro(items[-1])\n                return datetime.datetime(year, month, day, hours, minutes,\n                                         sec_i, microsec)\n\n        # Only consider the value fields, formula's can contain just cell refs.\n        # Note that cell formatting determines if a value type is time, date or\n        # just a number. By using the cell value, cell type is consistent with\n        # what the user will see/format in LibreOffice\n        items = self.regex.findall(cell.value)\n        if cell.value_type == 'date':\n            value = _datetime(items)\n        else:\n            try:\n                # will fail when hours > 23, which is possible in LibreOffice\n                value = _time(items)\n            except ValueError:\n                value = _timedelta(items)\n\n        return value\n\n    def _print_ods_cellinfo(self, cell):\n        \"\"\"Convienent for debugging purposes: print all ods cell data.\n        Cell attributes are documented here:\n        https://pythonhosted.org/ezodf/tableobjects.html#id2\n        \"\"\"\n        print('   plaintext:', cell.plaintext())  # no formatting\n        # formatted, but what is difference with value?\n        print('display_form:', cell.display_form)  # format, ?=plaintext\n        print('       value:', cell.value)       # data handled\n        print('  value_type:', cell.value_type)  # data type\n        print('     formula:', cell.formula)\n        print('    currency:', cell.currency)\n\n    @property\n    def sheet_names(self):\n        if self.reader.engine == 'ezodf':\n            # book.sheet.names() is a generator for ezodf\n            return [sheetname for sheetname in self.reader.book.sheets.names()]\n        else:\n            return self.reader.book.sheet_names()\n\n    def close(self):\n        \"\"\"close io if necessary\"\"\"\n        if hasattr(self.io, 'close'):\n            self.io.close()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.close()\n\n\ndef _trim_excel_header(row):\n    # trim header row so auto-index inference works\n    # xlrd uses '' , openpyxl None\n    while len(row) > 0 and (row[0] == '' or row[0] is None):\n        row = row[1:]\n    return row\n\n\ndef _conv_value(val):\n    # Convert numpy types to Python types for the Excel writers.\n    if com.is_integer(val):\n        val = int(val)\n    elif com.is_float(val):\n        val = float(val)\n    elif com.is_bool(val):\n        val = bool(val)\n    elif isinstance(val, Period):\n        val = \"%s\" % val\n    elif com.is_list_like(val):\n        val = str(val)\n\n    return val\n\n\n@add_metaclass(abc.ABCMeta)\nclass ExcelWriter(object):\n    \"\"\"\n    Class for writing DataFrame objects into excel sheets, default is to use\n    xlwt for xls, openpyxl for xlsx.  See DataFrame.to_excel for typical usage.\n\n    Parameters\n    ----------\n    path : string\n        Path to xls or xlsx file.\n    engine : string (optional)\n        Engine to use for writing. If None, defaults to\n        ``io.excel.<extension>.writer``.  NOTE: can only be passed as a keyword\n        argument.\n    date_format : string, default None\n        Format string for dates written into Excel files (e.g. 'YYYY-MM-DD')\n    datetime_format : string, default None\n        Format string for datetime objects written into Excel files\n        (e.g. 'YYYY-MM-DD HH:MM:SS')\n\n    Notes\n    -----\n    For compatibility with CSV writers, ExcelWriter serializes lists\n    and dicts to strings before writing.\n    \"\"\"\n    # Defining an ExcelWriter implementation (see abstract methods for more...)\n\n    # - Mandatory\n    #   - ``write_cells(self, cells, sheet_name=None, startrow=0, startcol=0)``\n    #     --> called to write additional DataFrames to disk\n    #   - ``supported_extensions`` (tuple of supported extensions), used to\n    #      check that engine supports the given extension.\n    #   - ``engine`` - string that gives the engine name. Necessary to\n    #     instantiate class directly and bypass ``ExcelWriterMeta`` engine\n    #     lookup.\n    #   - ``save(self)`` --> called to save file to disk\n    # - Mostly mandatory (i.e. should at least exist)\n    #   - book, cur_sheet, path\n\n    # - Optional:\n    #   - ``__init__(self, path, engine=None, **kwargs)`` --> always called\n    #     with path as first argument.\n\n    # You also need to register the class with ``register_writer()``.\n    # Technically, ExcelWriter implementations don't need to subclass\n    # ExcelWriter.\n    def __new__(cls, path, engine=None, **kwargs):\n        # only switch class if generic(ExcelWriter)\n        if issubclass(cls, ExcelWriter):\n            if engine is None:\n                if isinstance(path, string_types):\n                    ext = os.path.splitext(path)[-1][1:]\n                else:\n                    ext = 'xlsx'\n\n                try:\n                    engine = config.get_option('io.excel.%s.writer' % ext)\n                except KeyError:\n                    error = ValueError(\"No engine for filetype: '%s'\" % ext)\n                    raise error\n            cls = get_writer(engine)\n\n        return object.__new__(cls)\n\n    # declare external properties you can count on\n    book = None\n    curr_sheet = None\n    path = None\n\n    @abc.abstractproperty\n    def supported_extensions(self):\n        \"extensions that writer engine supports\"\n        pass\n\n    @abc.abstractproperty\n    def engine(self):\n        \"name of engine\"\n        pass\n\n    @abc.abstractmethod\n    def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0):\n        \"\"\"\n        Write given formated cells into Excel an excel sheet\n\n        Parameters\n        ----------\n        cells : generator\n            cell of formated data to save to Excel sheet\n        sheet_name : string, default None\n            Name of Excel sheet, if None, then use self.cur_sheet\n        startrow: upper left cell row to dump data frame\n        startcol: upper left cell column to dump data frame\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def save(self):\n        \"\"\"\n        Save workbook to disk.\n        \"\"\"\n        pass\n\n    def __init__(self, path, engine=None,\n                 date_format=None, datetime_format=None, **engine_kwargs):\n        # validate that this engine can handle the extension\n        if isinstance(path, string_types):\n            ext = os.path.splitext(path)[-1]\n        else:\n            ext = 'xls' if engine == 'xlwt' else 'xlsx'\n\n        self.check_extension(ext)\n\n        self.path = path\n        self.sheets = {}\n        self.cur_sheet = None\n\n        if date_format is None:\n            self.date_format = 'YYYY-MM-DD'\n        else:\n            self.date_format = date_format\n        if datetime_format is None:\n            self.datetime_format = 'YYYY-MM-DD HH:MM:SS'\n        else:\n            self.datetime_format = datetime_format\n\n    def _get_sheet_name(self, sheet_name):\n        if sheet_name is None:\n            sheet_name = self.cur_sheet\n        if sheet_name is None:  # pragma: no cover\n            raise ValueError('Must pass explicit sheet_name or set '\n                             'cur_sheet property')\n        return sheet_name\n\n    @classmethod\n    def check_extension(cls, ext):\n        \"\"\"checks that path's extension against the Writer's supported\n        extensions.  If it isn't supported, raises UnsupportedFiletypeError.\"\"\"\n        if ext.startswith('.'):\n            ext = ext[1:]\n        if not any(ext in extension for extension in cls.supported_extensions):\n            msg = (u(\"Invalid extension for engine '%s': '%s'\") %\n                   (pprint_thing(cls.engine), pprint_thing(ext)))\n            raise ValueError(msg)\n        else:\n            return True\n\n    # Allow use as a contextmanager\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.close()\n\n    def close(self):\n        \"\"\"synonym for save, to make it more file-like\"\"\"\n        return self.save()\n\n\nclass _Openpyxl1Writer(ExcelWriter):\n    engine = 'openpyxl1'\n    supported_extensions = ('.xlsx', '.xlsm')\n    openpyxl_majorver = 1\n\n    def __init__(self, path, engine=None, **engine_kwargs):\n        if not openpyxl_compat.is_compat(major_ver=self.openpyxl_majorver):\n            raise ValueError('Installed openpyxl is not supported at this '\n                             'time. Use {0}.x.y.'\n                             .format(self.openpyxl_majorver))\n        # Use the openpyxl module as the Excel writer.\n        from openpyxl.workbook import Workbook\n\n        super(_Openpyxl1Writer, self).__init__(path, **engine_kwargs)\n\n        # Create workbook object with default optimized_write=True.\n        self.book = Workbook()\n        # Openpyxl 1.6.1 adds a dummy sheet. We remove it.\n        if self.book.worksheets:\n            self.book.remove_sheet(self.book.worksheets[0])\n\n    def save(self):\n        \"\"\"\n        Save workbook to disk.\n        \"\"\"\n        return self.book.save(self.path)\n\n    def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0):\n        # Write the frame cells using openpyxl.\n        from openpyxl.cell import get_column_letter\n\n        sheet_name = self._get_sheet_name(sheet_name)\n\n        if sheet_name in self.sheets:\n            wks = self.sheets[sheet_name]\n        else:\n            wks = self.book.create_sheet()\n            wks.title = sheet_name\n            self.sheets[sheet_name] = wks\n\n        for cell in cells:\n            colletter = get_column_letter(startcol + cell.col + 1)\n            xcell = wks.cell(\"%s%s\" % (colletter, startrow + cell.row + 1))\n            xcell.value = _conv_value(cell.val)\n            style = None\n            if cell.style:\n                style = self._convert_to_style(cell.style)\n                for field in style.__fields__:\n                    xcell.style.__setattr__(field,\n                                            style.__getattribute__(field))\n\n            if isinstance(cell.val, datetime.datetime):\n                xcell.style.number_format.format_code = self.datetime_format\n            elif isinstance(cell.val, datetime.date):\n                xcell.style.number_format.format_code = self.date_format\n\n            if cell.mergestart is not None and cell.mergeend is not None:\n                cletterstart = get_column_letter(startcol + cell.col + 1)\n                cletterend = get_column_letter(startcol + cell.mergeend + 1)\n\n                wks.merge_cells('%s%s:%s%s' % (cletterstart,\n                                               startrow + cell.row + 1,\n                                               cletterend,\n                                               startrow + cell.mergestart + 1))\n\n                # Excel requires that the format of the first cell in a merged\n                # range is repeated in the rest of the merged range.\n                if style:\n                    first_row = startrow + cell.row + 1\n                    last_row = startrow + cell.mergestart + 1\n                    first_col = startcol + cell.col + 1\n                    last_col = startcol + cell.mergeend + 1\n\n                    for row in range(first_row, last_row + 1):\n                        for col in range(first_col, last_col + 1):\n                            if row == first_row and col == first_col:\n                                # Ignore first cell. It is already handled.\n                                continue\n                            colletter = get_column_letter(col)\n                            xcell = wks.cell(\"%s%s\" % (colletter, row))\n                            for field in style.__fields__:\n                                xcell.style.__setattr__(\n                                    field, style.__getattribute__(field))\n\n    @classmethod\n    def _convert_to_style(cls, style_dict):\n        \"\"\"\n        converts a style_dict to an openpyxl style object\n        Parameters\n        ----------\n        style_dict: style dictionary to convert\n        \"\"\"\n\n        from openpyxl.style import Style\n        xls_style = Style()\n        for key, value in style_dict.items():\n            for nk, nv in value.items():\n                if key == \"borders\":\n                    (xls_style.borders.__getattribute__(nk)\n                     .__setattr__('border_style', nv))\n                else:\n                    xls_style.__getattribute__(key).__setattr__(nk, nv)\n\n        return xls_style\n\nregister_writer(_Openpyxl1Writer)\n\n\nclass _OpenpyxlWriter(_Openpyxl1Writer):\n    engine = 'openpyxl'\n\nregister_writer(_OpenpyxlWriter)\n\n\nclass _Openpyxl2Writer(_Openpyxl1Writer):\n    \"\"\"\n    Note: Support for OpenPyxl v2 is currently EXPERIMENTAL (GH7565).\n    \"\"\"\n    engine = 'openpyxl2'\n    openpyxl_majorver = 2\n\n    def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0):\n        # Write the frame cells using openpyxl.\n        from openpyxl.cell import get_column_letter\n\n        sheet_name = self._get_sheet_name(sheet_name)\n\n        if sheet_name in self.sheets:\n            wks = self.sheets[sheet_name]\n        else:\n            wks = self.book.create_sheet()\n            wks.title = sheet_name\n            self.sheets[sheet_name] = wks\n\n        for cell in cells:\n            colletter = get_column_letter(startcol + cell.col + 1)\n            xcell = wks.cell(\"%s%s\" % (colletter, startrow + cell.row + 1))\n            xcell.value = _conv_value(cell.val)\n            style_kwargs = {}\n\n            # Apply format codes before cell.style to allow override\n            if isinstance(cell.val, datetime.datetime):\n                style_kwargs.update(self._convert_to_style_kwargs({\n                        'number_format':{'format_code': self.datetime_format}}))\n            elif isinstance(cell.val, datetime.date):\n                style_kwargs.update(self._convert_to_style_kwargs({\n                        'number_format':{'format_code': self.date_format}}))\n\n            if cell.style:\n                style_kwargs.update(self._convert_to_style_kwargs(cell.style))\n\n            if style_kwargs:\n                xcell.style = xcell.style.copy(**style_kwargs)\n\n            if cell.mergestart is not None and cell.mergeend is not None:\n                cletterstart = get_column_letter(startcol + cell.col + 1)\n                cletterend = get_column_letter(startcol + cell.mergeend + 1)\n\n                wks.merge_cells('%s%s:%s%s' % (cletterstart,\n                                               startrow + cell.row + 1,\n                                               cletterend,\n                                               startrow + cell.mergestart + 1))\n\n                # Excel requires that the format of the first cell in a merged\n                # range is repeated in the rest of the merged range.\n                if style_kwargs:\n                    first_row = startrow + cell.row + 1\n                    last_row = startrow + cell.mergestart + 1\n                    first_col = startcol + cell.col + 1\n                    last_col = startcol + cell.mergeend + 1\n\n                    for row in range(first_row, last_row + 1):\n                        for col in range(first_col, last_col + 1):\n                            if row == first_row and col == first_col:\n                                # Ignore first cell. It is already handled.\n                                continue\n                            colletter = get_column_letter(col)\n                            xcell = wks.cell(\"%s%s\" % (colletter, row))\n                            xcell.style = xcell.style.copy(**style_kwargs)\n\n    @classmethod\n    def _convert_to_style_kwargs(cls, style_dict):\n        \"\"\"\n        Convert a style_dict to a set of kwargs suitable for initializing\n        or updating-on-copy an openpyxl v2 style object\n        Parameters\n        ----------\n        style_dict : dict\n            A dict with zero or more of the following keys (or their synonyms).\n                'font'\n                'fill'\n                'border' ('borders')\n                'alignment'\n                'number_format'\n                'protection'\n        Returns\n        -------\n        style_kwargs : dict\n            A dict with the same, normalized keys as ``style_dict`` but each\n            value has been replaced with a native openpyxl style object of the\n            appropriate class.\n        \"\"\"\n\n        _style_key_map = {\n            'borders': 'border',\n        }\n\n        style_kwargs = {}\n        for k, v in style_dict.items():\n            if k in _style_key_map:\n                k = _style_key_map[k]\n            _conv_to_x = getattr(cls, '_convert_to_{0}'.format(k),\n                    lambda x: None)\n            new_v = _conv_to_x(v)\n            if new_v:\n                style_kwargs[k] = new_v\n\n        return style_kwargs\n\n\n    @classmethod\n    def _convert_to_color(cls, color_spec):\n        \"\"\"\n        Convert ``color_spec`` to an openpyxl v2 Color object\n        Parameters\n        ----------\n        color_spec : str, dict\n            A 32-bit ARGB hex string, or a dict with zero or more of the\n            following keys.\n                'rgb'\n                'indexed'\n                'auto'\n                'theme'\n                'tint'\n                'index'\n                'type'\n        Returns\n        -------\n        color : openpyxl.styles.Color\n        \"\"\"\n\n        from openpyxl.styles import Color\n\n        if isinstance(color_spec, str):\n            return Color(color_spec)\n        else:\n            return Color(**color_spec)\n\n\n    @classmethod\n    def _convert_to_font(cls, font_dict):\n        \"\"\"\n        Convert ``font_dict`` to an openpyxl v2 Font object\n        Parameters\n        ----------\n        font_dict : dict\n            A dict with zero or more of the following keys (or their synonyms).\n                'name'\n                'size' ('sz')\n                'bold' ('b')\n                'italic' ('i')\n                'underline' ('u')\n                'strikethrough' ('strike')\n                'color'\n                'vertAlign' ('vertalign')\n                'charset'\n                'scheme'\n                'family'\n                'outline'\n                'shadow'\n                'condense'\n        Returns\n        -------\n        font : openpyxl.styles.Font\n        \"\"\"\n\n        from openpyxl.styles import Font\n\n        _font_key_map = {\n            'sz': 'size',\n            'b': 'bold',\n            'i': 'italic',\n            'u': 'underline',\n            'strike': 'strikethrough',\n            'vertalign': 'vertAlign',\n        }\n\n        font_kwargs = {}\n        for k, v in font_dict.items():\n            if k in _font_key_map:\n                k = _font_key_map[k]\n            if k == 'color':\n                v = cls._convert_to_color(v)\n            font_kwargs[k] = v\n\n        return Font(**font_kwargs)\n\n\n    @classmethod\n    def _convert_to_stop(cls, stop_seq):\n        \"\"\"\n        Convert ``stop_seq`` to a list of openpyxl v2 Color objects,\n        suitable for initializing the ``GradientFill`` ``stop`` parameter.\n        Parameters\n        ----------\n        stop_seq : iterable\n            An iterable that yields objects suitable for consumption by\n            ``_convert_to_color``.\n        Returns\n        -------\n        stop : list of openpyxl.styles.Color\n        \"\"\"\n\n        return map(cls._convert_to_color, stop_seq)\n\n\n    @classmethod\n    def _convert_to_fill(cls, fill_dict):\n        \"\"\"\n        Convert ``fill_dict`` to an openpyxl v2 Fill object\n        Parameters\n        ----------\n        fill_dict : dict\n            A dict with one or more of the following keys (or their synonyms),\n                'fill_type' ('patternType', 'patterntype')\n                'start_color' ('fgColor', 'fgcolor')\n                'end_color' ('bgColor', 'bgcolor')\n            or one or more of the following keys (or their synonyms).\n                'type' ('fill_type')\n                'degree'\n                'left'\n                'right'\n                'top'\n                'bottom'\n                'stop'\n        Returns\n        -------\n        fill : openpyxl.styles.Fill\n        \"\"\"\n\n        from openpyxl.styles import PatternFill, GradientFill\n\n        _pattern_fill_key_map = {\n            'patternType': 'fill_type',\n            'patterntype': 'fill_type',\n            'fgColor': 'start_color',\n            'fgcolor': 'start_color',\n            'bgColor': 'end_color',\n            'bgcolor': 'end_color',\n        }\n\n        _gradient_fill_key_map = {\n            'fill_type': 'type',\n        }\n\n        pfill_kwargs = {}\n        gfill_kwargs = {}\n        for k, v in fill_dict.items():\n            pk = gk = None\n            if k in _pattern_fill_key_map:\n                pk = _pattern_fill_key_map[k]\n            if k in _gradient_fill_key_map:\n                gk = _gradient_fill_key_map[k]\n            if pk in ['start_color', 'end_color']:\n                v = cls._convert_to_color(v)\n            if gk == 'stop':\n                v = cls._convert_to_stop(v)\n            if pk:\n                pfill_kwargs[pk] = v\n            elif gk:\n                gfill_kwargs[gk] = v\n            else:\n                pfill_kwargs[k] = v\n                gfill_kwargs[k] = v\n\n        try:\n            return PatternFill(**pfill_kwargs)\n        except TypeError:\n            return GradientFill(**gfill_kwargs)\n\n\n    @classmethod\n    def _convert_to_side(cls, side_spec):\n        \"\"\"\n        Convert ``side_spec`` to an openpyxl v2 Side object\n        Parameters\n        ----------\n        side_spec : str, dict\n            A string specifying the border style, or a dict with zero or more\n            of the following keys (or their synonyms).\n                'style' ('border_style')\n                'color'\n        Returns\n        -------\n        side : openpyxl.styles.Side\n        \"\"\"\n\n        from openpyxl.styles import Side\n\n        _side_key_map = {\n            'border_style': 'style',\n        }\n\n        if isinstance(side_spec, str):\n            return Side(style=side_spec)\n\n        side_kwargs = {}\n        for k, v in side_spec.items():\n            if k in _side_key_map:\n                k = _side_key_map[k]\n            if k == 'color':\n                v = cls._convert_to_color(v)\n            side_kwargs[k] = v\n\n        return Side(**side_kwargs)\n\n\n    @classmethod\n    def _convert_to_border(cls, border_dict):\n        \"\"\"\n        Convert ``border_dict`` to an openpyxl v2 Border object\n        Parameters\n        ----------\n        border_dict : dict\n            A dict with zero or more of the following keys (or their synonyms).\n                'left'\n                'right'\n                'top'\n                'bottom'\n                'diagonal'\n                'diagonal_direction'\n                'vertical'\n                'horizontal'\n                'diagonalUp' ('diagonalup')\n                'diagonalDown' ('diagonaldown')\n                'outline'\n        Returns\n        -------\n        border : openpyxl.styles.Border\n        \"\"\"\n\n        from openpyxl.styles import Border\n\n        _border_key_map = {\n            'diagonalup': 'diagonalUp',\n            'diagonaldown': 'diagonalDown',\n        }\n\n        border_kwargs = {}\n        for k, v in border_dict.items():\n            if k in _border_key_map:\n                k = _border_key_map[k]\n            if k == 'color':\n                v = cls._convert_to_color(v)\n            if k in ['left', 'right', 'top', 'bottom', 'diagonal']:\n                v = cls._convert_to_side(v)\n            border_kwargs[k] = v\n\n        return Border(**border_kwargs)\n\n\n    @classmethod\n    def _convert_to_alignment(cls, alignment_dict):\n        \"\"\"\n        Convert ``alignment_dict`` to an openpyxl v2 Alignment object\n        Parameters\n        ----------\n        alignment_dict : dict\n            A dict with zero or more of the following keys (or their synonyms).\n                'horizontal'\n                'vertical'\n                'text_rotation'\n                'wrap_text'\n                'shrink_to_fit'\n                'indent'\n        Returns\n        -------\n        alignment : openpyxl.styles.Alignment\n        \"\"\"\n\n        from openpyxl.styles import Alignment\n\n        return Alignment(**alignment_dict)\n\n\n    @classmethod\n    def _convert_to_number_format(cls, number_format_dict):\n        \"\"\"\n        Convert ``number_format_dict`` to an openpyxl v2.1.0 number format\n        initializer.\n        Parameters\n        ----------\n        number_format_dict : dict\n            A dict with zero or more of the following keys.\n                'format_code' : str\n        Returns\n        -------\n        number_format : str\n        \"\"\"\n        try:\n            # >= 2.0.0 < 2.1.0\n            from openpyxl.styles import NumberFormat\n            return NumberFormat(**number_format_dict)\n        except:\n            # >= 2.1.0\n            return number_format_dict['format_code']\n\n    @classmethod\n    def _convert_to_protection(cls, protection_dict):\n        \"\"\"\n        Convert ``protection_dict`` to an openpyxl v2 Protection object.\n        Parameters\n        ----------\n        protection_dict : dict\n            A dict with zero or more of the following keys.\n                'locked'\n                'hidden'\n        Returns\n        -------\n        \"\"\"\n\n        from openpyxl.styles import Protection\n\n        return Protection(**protection_dict)\n\n\nregister_writer(_Openpyxl2Writer)\n\n\nclass _XlwtWriter(ExcelWriter):\n    engine = 'xlwt'\n    supported_extensions = ('.xls',)\n\n    def __init__(self, path, engine=None, encoding=None, **engine_kwargs):\n        # Use the xlwt module as the Excel writer.\n        import xlwt\n\n        super(_XlwtWriter, self).__init__(path, **engine_kwargs)\n\n        if encoding is None:\n            encoding = 'ascii'\n        self.book = xlwt.Workbook(encoding=encoding)\n        self.fm_datetime = xlwt.easyxf(num_format_str=self.datetime_format)\n        self.fm_date = xlwt.easyxf(num_format_str=self.date_format)\n\n    def save(self):\n        \"\"\"\n        Save workbook to disk.\n        \"\"\"\n        return self.book.save(self.path)\n\n    def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0):\n        # Write the frame cells using xlwt.\n\n        sheet_name = self._get_sheet_name(sheet_name)\n\n        if sheet_name in self.sheets:\n            wks = self.sheets[sheet_name]\n        else:\n            wks = self.book.add_sheet(sheet_name)\n            self.sheets[sheet_name] = wks\n\n        style_dict = {}\n\n        for cell in cells:\n            val = _conv_value(cell.val)\n\n            num_format_str = None\n            if isinstance(cell.val, datetime.datetime):\n                num_format_str = self.datetime_format\n            elif isinstance(cell.val, datetime.date):\n                num_format_str = self.date_format\n\n            stylekey = json.dumps(cell.style)\n            if num_format_str:\n                stylekey += num_format_str\n\n            if stylekey in style_dict:\n                style = style_dict[stylekey]\n            else:\n                style = self._convert_to_style(cell.style, num_format_str)\n                style_dict[stylekey] = style\n\n            if cell.mergestart is not None and cell.mergeend is not None:\n                wks.write_merge(startrow + cell.row,\n                                startrow + cell.mergestart,\n                                startcol + cell.col,\n                                startcol + cell.mergeend,\n                                val, style)\n            else:\n                wks.write(startrow + cell.row,\n                          startcol + cell.col,\n                          val, style)\n\n    @classmethod\n    def _style_to_xlwt(cls, item, firstlevel=True, field_sep=',',\n                       line_sep=';'):\n        \"\"\"helper which recursively generate an xlwt easy style string\n        for example:\n\n            hstyle = {\"font\": {\"bold\": True},\n            \"border\": {\"top\": \"thin\",\n                    \"right\": \"thin\",\n                    \"bottom\": \"thin\",\n                    \"left\": \"thin\"},\n            \"align\": {\"horiz\": \"center\"}}\n            will be converted to\n            font: bold on; \\\n                    border: top thin, right thin, bottom thin, left thin; \\\n                    align: horiz center;\n        \"\"\"\n        if hasattr(item, 'items'):\n            if firstlevel:\n                it = [\"%s: %s\" % (key, cls._style_to_xlwt(value, False))\n                      for key, value in item.items()]\n                out = \"%s \" % (line_sep).join(it)\n                return out\n            else:\n                it = [\"%s %s\" % (key, cls._style_to_xlwt(value, False))\n                      for key, value in item.items()]\n                out = \"%s \" % (field_sep).join(it)\n                return out\n        else:\n            item = \"%s\" % item\n            item = item.replace(\"True\", \"on\")\n            item = item.replace(\"False\", \"off\")\n            return item\n\n    @classmethod\n    def _convert_to_style(cls, style_dict, num_format_str=None):\n        \"\"\"\n        converts a style_dict to an xlwt style object\n        Parameters\n        ----------\n        style_dict: style dictionary to convert\n        num_format_str: optional number format string\n        \"\"\"\n        import xlwt\n\n        if style_dict:\n            xlwt_stylestr = cls._style_to_xlwt(style_dict)\n            style = xlwt.easyxf(xlwt_stylestr, field_sep=',', line_sep=';')\n        else:\n            style = xlwt.XFStyle()\n        if num_format_str is not None:\n            style.num_format_str = num_format_str\n\n        return style\n\nregister_writer(_XlwtWriter)\n\n\nclass _XlsxWriter(ExcelWriter):\n    engine = 'xlsxwriter'\n    supported_extensions = ('.xlsx',)\n\n    def __init__(self, path, engine=None,\n                 date_format=None, datetime_format=None, **engine_kwargs):\n        # Use the xlsxwriter module as the Excel writer.\n        import xlsxwriter\n\n        super(_XlsxWriter, self).__init__(path, engine=engine,\n                                          date_format=date_format,\n                                          datetime_format=datetime_format,\n                                          **engine_kwargs)\n\n        self.book = xlsxwriter.Workbook(path, **engine_kwargs)\n\n    def save(self):\n        \"\"\"\n        Save workbook to disk.\n        \"\"\"\n        return self.book.close()\n\n    def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0):\n        # Write the frame cells using xlsxwriter.\n\n        sheet_name = self._get_sheet_name(sheet_name)\n\n        if sheet_name in self.sheets:\n            wks = self.sheets[sheet_name]\n        else:\n            wks = self.book.add_worksheet(sheet_name)\n            self.sheets[sheet_name] = wks\n\n        style_dict = {}\n\n        for cell in cells:\n            val = _conv_value(cell.val)\n\n            num_format_str = None\n            if isinstance(cell.val, datetime.datetime):\n                num_format_str = self.datetime_format\n            elif isinstance(cell.val, datetime.date):\n                num_format_str = self.date_format\n\n            stylekey = json.dumps(cell.style)\n            if num_format_str:\n                stylekey += num_format_str\n\n            if stylekey in style_dict:\n                style = style_dict[stylekey]\n            else:\n                style = self._convert_to_style(cell.style, num_format_str)\n                style_dict[stylekey] = style\n\n            if cell.mergestart is not None and cell.mergeend is not None:\n                wks.merge_range(startrow + cell.row,\n                                startcol + cell.col,\n                                startrow + cell.mergestart,\n                                startcol + cell.mergeend,\n                                cell.val, style)\n            else:\n                wks.write(startrow + cell.row,\n                          startcol + cell.col,\n                          val, style)\n\n    def _convert_to_style(self, style_dict, num_format_str=None):\n        \"\"\"\n        converts a style_dict to an xlsxwriter format object\n        Parameters\n        ----------\n        style_dict: style dictionary to convert\n        num_format_str: optional number format string\n        \"\"\"\n\n        # If there is no formatting we don't create a format object.\n        if num_format_str is None and style_dict is None:\n            return None\n\n        # Create a XlsxWriter format object.\n        xl_format = self.book.add_format()\n\n        if num_format_str is not None:\n            xl_format.set_num_format(num_format_str)\n\n        if style_dict is None:\n            return xl_format\n\n        # Map the cell font to XlsxWriter font properties.\n        if style_dict.get('font'):\n            font = style_dict['font']\n            if font.get('bold'):\n                xl_format.set_bold()\n\n        # Map the alignment to XlsxWriter alignment properties.\n        alignment = style_dict.get('alignment')\n        if alignment:\n            if (alignment.get('horizontal')\n                    and alignment['horizontal'] == 'center'):\n                xl_format.set_align('center')\n            if (alignment.get('vertical')\n                    and alignment['vertical'] == 'top'):\n                xl_format.set_align('top')\n\n        # Map the cell borders to XlsxWriter border properties.\n        if style_dict.get('borders'):\n            xl_format.set_border()\n\n        return xl_format\n\nregister_writer(_XlsxWriter)\n"
    },
    {
      "filename": "pandas/io/tests/test_excel.py",
      "content": "# pylint: disable=E1101\n\nfrom pandas.compat import u, range, map, openpyxl_compat, BytesIO, iteritems\nfrom pandas import compat\nfrom datetime import datetime, date, time, timedelta\nimport sys\nimport os\nfrom distutils.version import LooseVersion\n\nimport operator\nimport functools\nimport nose\n\nfrom numpy import nan\nimport numpy as np\nfrom numpy.testing.decorators import slow\n\nfrom pandas import DataFrame, Index, MultiIndex\nfrom pandas.io.parsers import read_csv\nfrom pandas.io.excel import (\n    ExcelFile, ExcelWriter, read_excel, _XlwtWriter, _Openpyxl1Writer,\n    _Openpyxl2Writer, register_writer, _XlsxWriter\n)\nfrom pandas.io.common import URLError\nfrom pandas.util.testing import ensure_clean\nfrom pandas.core.config import set_option, get_option\nimport pandas.util.testing as tm\nimport pandas as pd\n\n\ndef _skip_if_no_xlrd():\n    try:\n        import xlrd\n        ver = tuple(map(int, xlrd.__VERSION__.split(\".\")[:2]))\n        if ver < (0, 9):\n            raise nose.SkipTest('xlrd < 0.9, skipping')\n    except ImportError:\n        raise nose.SkipTest('xlrd not installed, skipping')\n\n\ndef _skip_if_no_xlwt():\n    try:\n        import xlwt  # NOQA\n    except ImportError:\n        raise nose.SkipTest('xlwt not installed, skipping')\n\n\ndef _skip_if_no_openpyxl():\n    try:\n        import openpyxl  # NOQA\n    except ImportError:\n        raise nose.SkipTest('openpyxl not installed, skipping')\n\n\ndef _skip_if_no_xlsxwriter():\n    try:\n        import xlsxwriter  # NOQA\n    except ImportError:\n        raise nose.SkipTest('xlsxwriter not installed, skipping')\n\n\ndef _skip_if_no_ezodf():\n    try:\n        import ezodf  # NOQA\n    except ImportError:\n        raise nose.SkipTest('ezodf not installed, skipping')\n\n\ndef _skip_if_no_excelsuite():\n    _skip_if_no_xlrd()\n    _skip_if_no_xlwt()\n    _skip_if_no_openpyxl()\n\n\n_seriesd = tm.getSeriesData()\n_tsd = tm.getTimeSeriesData()\n_frame = DataFrame(_seriesd)[:10]\n_frame2 = DataFrame(_seriesd, columns=['D', 'C', 'B', 'A'])[:10]\n_tsframe = tm.makeTimeDataFrame()[:5]\n_mixed_frame = _frame.copy()\n_mixed_frame['foo'] = 'bar'\n\n\nclass SharedItems(object):\n    def setUp(self):\n        self.dirpath = tm.get_data_path()\n        self.frame = _frame.copy()\n        self.frame2 = _frame2.copy()\n        self.tsframe = _tsframe.copy()\n        self.mixed_frame = _mixed_frame.copy()\n\n    def read_csv(self, *args, **kwds):\n        kwds = kwds.copy()\n        kwds['engine'] = 'python'\n        return read_csv(*args, **kwds)\n\n    def get_data(self, basename, csv=True):\n        \"\"\"\n        Return a DataFrame as read by the Python csv engine and a DataFrame\n        as read by the ExcelFile engine. Test data path is defined by\n        pandas.util.testing.get_data_path()\n\n        Parameters\n        ----------\n\n        basename : str\n            File base name, excluding file extension.\n\n        csv : boolean, default=True\n            When True, basename.csv is returned\n        \"\"\"\n\n        excel = ExcelFile(os.path.join(self.dirpath, basename + self.ext))\n        if csv:\n            # the reference is obtained form read_csv with Python engine\n            pref = os.path.join(self.dirpath, basename + '.csv')\n            dfref = self.read_csv(pref, index_col=0, parse_dates=True)\n            return dfref, excel\n        else:\n            return excel\n\n\nclass ReadingTestsBase(SharedItems):\n    # This is based on ExcelWriterBase\n    #\n    # Base class for test cases to run with different Excel readers.\n    # To add a reader test, define the following:\n    # 1. A check_skip function that skips your tests if your reader isn't\n    #    installed.\n    # 2. Add a property ext, which is the file extension that your reader\n    #    reades from. (needs to start with '.' so it's a valid path)\n    # 3. Add a property engine_name, which is the name of the reader class.\n    #    For the reader this is not used for anything at the moment.\n\n    def setUp(self):\n        self.check_skip()\n        super(ReadingTestsBase, self).setUp()\n\n    def test_parse_cols_int(self):\n\n        dfref, excel = self.get_data('test1')\n        dfref = dfref.reindex(columns=['A', 'B', 'C'])\n        df1 = excel.parse('Sheet1', index_col=0, parse_dates=True,\n                         parse_cols=3)\n        df2 = excel.parse('Sheet2', skiprows=[1], index_col=0,\n                          parse_dates=True, parse_cols=3)\n        # TODO add index to xls file)\n        tm.assert_frame_equal(df1, dfref, check_names=False)\n        tm.assert_frame_equal(df2, dfref, check_names=False)\n\n    def test_parse_cols_list(self):\n\n        dfref, excel = self.get_data('test1')\n        dfref = dfref.reindex(columns=['B', 'C'])\n        df1 = excel.parse('Sheet1', index_col=0, parse_dates=True,\n                         parse_cols=[0, 2, 3])\n        df2 = excel.parse('Sheet2', skiprows=[1], index_col=0,\n                          parse_dates=True,\n                          parse_cols=[0, 2, 3])\n        # TODO add index to xls file)\n        tm.assert_frame_equal(df1, dfref, check_names=False)\n        tm.assert_frame_equal(df2, dfref, check_names=False)\n\n    def test_parse_cols_str(self):\n\n        dfref, excel = self.get_data('test1')\n\n        df1 = dfref.reindex(columns=['A', 'B', 'C'])\n        df2 = excel.parse('Sheet1', index_col=0, parse_dates=True,\n                         parse_cols='A:D')\n        df3 = excel.parse('Sheet2', skiprows=[1], index_col=0,\n                          parse_dates=True, parse_cols='A:D')\n        # TODO add index to xls, read xls ignores index name ?\n        tm.assert_frame_equal(df2, df1, check_names=False)\n        tm.assert_frame_equal(df3, df1, check_names=False)\n\n        df1 = dfref.reindex(columns=['B', 'C'])\n        df2 = excel.parse('Sheet1', index_col=0, parse_dates=True,\n                         parse_cols='A,C,D')\n        df3 = excel.parse('Sheet2', skiprows=[1], index_col=0,\n                          parse_dates=True,\n                          parse_cols='A,C,D')\n        # TODO add index to xls file\n        tm.assert_frame_equal(df2, df1, check_names=False)\n        tm.assert_frame_equal(df3, df1, check_names=False)\n\n        df1 = dfref.reindex(columns=['B', 'C'])\n        df2 = excel.parse('Sheet1', index_col=0, parse_dates=True,\n                         parse_cols='A,C:D')\n        df3 = excel.parse('Sheet2', skiprows=[1], index_col=0,\n                          parse_dates=True,\n                          parse_cols='A,C:D')\n        tm.assert_frame_equal(df2, df1, check_names=False)\n        tm.assert_frame_equal(df3, df1, check_names=False)\n\n    def test_excel_stop_iterator(self):\n\n        excel = self.get_data('test2', csv=False)\n\n        parsed = excel.parse('Sheet1')\n        expected = DataFrame([['aaaa', 'bbbbb']], columns=['Test', 'Test1'])\n        tm.assert_frame_equal(parsed, expected)\n\n    def test_excel_cell_error_na(self):\n\n        excel = self.get_data('test3', csv=False)\n\n        parsed = excel.parse('Sheet1')\n        expected = DataFrame([[np.nan]], columns=['Test'])\n        tm.assert_frame_equal(parsed, expected)\n\n    def test_excel_passes_na(self):\n\n        excel = self.get_data('test4', csv=False)\n\n        parsed = excel.parse('Sheet1', keep_default_na=False,\n                             na_values=['apple'])\n        expected = DataFrame([['NA'], [1], ['NA'], [np.nan], ['rabbit']],\n                             columns=['Test'])\n        tm.assert_frame_equal(parsed, expected)\n\n        parsed = excel.parse('Sheet1', keep_default_na=True,\n                             na_values=['apple'])\n        expected = DataFrame([[np.nan], [1], [np.nan], [np.nan], ['rabbit']],\n                             columns=['Test'])\n        tm.assert_frame_equal(parsed, expected)\n\n    def test_excel_table_sheet_by_index(self):\n\n        dfref, excel = self.get_data('test1')\n\n        df1 = excel.parse(0, index_col=0, parse_dates=True)\n        df2 = excel.parse(1, skiprows=[1], index_col=0, parse_dates=True)\n        tm.assert_frame_equal(df1, dfref, check_names=False)\n        tm.assert_frame_equal(df2, dfref, check_names=False)\n\n        df3 = excel.parse(0, index_col=0, parse_dates=True, skipfooter=1)\n        df4 = excel.parse(0, index_col=0, parse_dates=True, skip_footer=1)\n        tm.assert_frame_equal(df3, df1.ix[:-1])\n        tm.assert_frame_equal(df3, df4)\n\n        if self.ext == '.ods':\n            self.assertRaises(KeyError, excel.parse, 'asdf')\n        else:\n            import xlrd\n            self.assertRaises(xlrd.XLRDError, excel.parse, 'asdf')\n\n    def test_excel_table(self):\n\n        dfref, excel = self.get_data('test1')\n\n        df1 = excel.parse('Sheet1', index_col=0, parse_dates=True)\n        df2 = excel.parse('Sheet2', skiprows=[1], index_col=0,\n                          parse_dates=True)\n        # TODO add index to file\n        tm.assert_frame_equal(df1, dfref, check_names=False)\n        tm.assert_frame_equal(df2, dfref, check_names=False)\n\n        df3 = excel.parse('Sheet1', index_col=0, parse_dates=True,\n                          skipfooter=1)\n        df4 = excel.parse('Sheet1', index_col=0, parse_dates=True,\n                          skip_footer=1)\n        tm.assert_frame_equal(df3, df1.ix[:-1])\n        tm.assert_frame_equal(df3, df4)\n\n    def test_reader_special_dtypes(self):\n\n        expected = DataFrame.from_items([\n            (\"IntCol\", [1, 2, -3, 4, 0]),\n            (\"FloatCol\", [1.25, 2.25, 1.83, 1.92, 0.0000000005]),\n            (\"BoolCol\", [True, False, True, True, False]),\n            (\"StrCol\", [1, 2, 3, 4, 5]),\n            # GH5394 - this is why convert_float isn't vectorized\n            (\"Str2Col\", [\"a\", 3, \"c\", \"d\", \"e\"]),\n            (\"DateCol\", [datetime(2013, 10, 30), datetime(2013, 10, 31),\n                         datetime(1905, 1, 1), datetime(2013, 12, 14),\n                         datetime(2015, 3, 14)])\n        ])\n\n        pth = os.path.join(self.dirpath, 'test_types' + self.ext)\n\n        # should read in correctly and infer types\n        actual = read_excel(pth, 'Sheet1')\n        tm.assert_frame_equal(actual, expected)\n\n        # if not coercing number, then int comes in as float\n        float_expected = expected.copy()\n        float_expected[\"IntCol\"] = float_expected[\"IntCol\"].astype(float)\n        float_expected.loc[1, \"Str2Col\"] = 3.0\n        actual = read_excel(pth, 'Sheet1', convert_float=False)\n        tm.assert_frame_equal(actual, float_expected)\n\n        # check setting Index (assuming xls and xlsx are the same here)\n        for icol, name in enumerate(expected.columns):\n            actual = read_excel(pth, 'Sheet1', index_col=icol)\n            exp = expected.set_index(name)\n            tm.assert_frame_equal(actual, exp)\n\n        # convert_float and converters should be different but both accepted\n        expected[\"StrCol\"] = expected[\"StrCol\"].apply(str)\n        actual = read_excel(pth, 'Sheet1', converters={\"StrCol\": str})\n        tm.assert_frame_equal(actual, expected)\n\n        no_convert_float = float_expected.copy()\n        no_convert_float[\"StrCol\"] = no_convert_float[\"StrCol\"].apply(str)\n        actual = read_excel(pth, 'Sheet1', converters={\"StrCol\": str},\n                           convert_float=False)\n        tm.assert_frame_equal(actual, no_convert_float)\n\n    # GH8212 - support for converters and missing values\n    def test_reader_converters(self):\n\n        pth = os.path.join(self.dirpath, 'test_converters' + self.ext)\n\n        expected = DataFrame.from_items([\n            (\"IntCol\", [1, 2, -3, -1000, 0]),\n            (\"FloatCol\", [12.5, np.nan, 18.3, 19.2, 0.000000005]),\n            (\"BoolCol\", ['Found', 'Found', 'Found', 'Not found', 'Found']),\n            (\"StrCol\", ['1', np.nan, '3', '4', '5']),\n        ])\n\n        converters = {'IntCol': lambda x: int(x) if x != '' else -1000,\n                      'FloatCol': lambda x: 10 * x if x else np.nan,\n                      2: lambda x: 'Found' if x != '' else 'Not found',\n                      3: lambda x: str(x) if x else '',\n                      }\n\n        # should read in correctly and set types of single cells (not array dtypes)\n        actual = read_excel(pth, 'Sheet1', converters=converters)\n        tm.assert_frame_equal(actual, expected)\n\n    def test_reading_all_sheets(self):\n        # Test reading all sheetnames by setting sheetname to None,\n        # Ensure a dict is returned.\n        # See PR #9450\n        pth = os.path.join(self.dirpath, 'test_multisheet' + self.ext)\n        dfs = read_excel(pth, sheetname=None)\n        expected_keys = ['Alpha', 'Beta', 'Charlie']\n        tm.assert_contains_all(expected_keys, dfs.keys())\n\n    def test_reading_multiple_specific_sheets(self):\n        # Test reading specific sheetnames by specifying a mixed list\n        # of integers and strings, and confirm that duplicated sheet\n        # references (positions/names) are removed properly.\n        # Ensure a dict is returned\n        # See PR #9450\n        pth = os.path.join(self.dirpath, 'test_multisheet' + self.ext)\n        # Explicitly request duplicates. Only the set should be returned.\n        expected_keys = [2, 'Charlie', 'Charlie']\n        dfs = read_excel(pth, sheetname=expected_keys)\n        expected_keys = list(set(expected_keys))\n        tm.assert_contains_all(expected_keys, dfs.keys())\n        assert len(expected_keys) == len(dfs.keys())\n\n\nclass OdsReaderTests(ReadingTestsBase, tm.TestCase):\n    ext = '.ods'\n    engine_name = 'ezodf'\n    check_skip = staticmethod(_skip_if_no_ezodf)\n\n    def test_read_ezodf_book(self):\n\n        import ezodf\n        pth = os.path.join(self.dirpath, 'test1' + self.ext)\n        book = ezodf.opendoc(pth)\n        result1 = ExcelFile(book).parse()\n        result2 = read_excel(book)\n\n        df = read_excel(pth)\n        tm.assert_frame_equal(df, result1)\n        tm.assert_frame_equal(df, result2)\n\n    def test_types_datetime(self):\n\n        expected = DataFrame.from_items([\n            (\"UnicodeCol\", ['øø', 'ææ', 'åå', 'oø', '€£$¥', '£@$', 'ÅøØæÆ@']),\n            (\"ExpCol\", [8.50E-010, 8.50E+012, 9.00E-055, 8.50E+011, 8.5E-10,\n                        5E-10, 5E-10]),\n            (\"BoolCol\", [True, False, True, True, False, False, False]),\n            (\"TimeCol\", [time(hour=23, microsecond=1),\n                         time(hour=2),\n                         time(hour=1, minute=1, second=1),\n                         timedelta(days=1, hours=2, minutes=1, seconds=1,\n                                   microseconds=1),\n                         timedelta(hours=866, minutes=1, seconds=1,\n                                   microseconds=1),\n                         time(2, 59, 40, 500000),\n                         time(23, 59, 59, 100)]),\n            (\"DateTimeCol\", [datetime(2014, 10, 10, 10),\n                             datetime(1900, 2, 1, 2),\n                             datetime(2014, 1, 1, 23, 15, 15),\n                             datetime(2011, 2, 3, 4, 5, 6),\n                             datetime(1900, 7, 8, 9, 0, 1),\n                             datetime(2015, 5, 7, 9, 33, 23),\n                             datetime(2015, 5, 7, 2, 33, 23, 300000)]),\n            (\"DateCol\", [datetime(2014,3,2), datetime(1900,2,1),\n                         datetime(1899,12,30), datetime(2100,12,11),\n                         datetime(1850,11,3), datetime(2950,11,3),\n                         datetime(2015,7,6)]),\n            (\"TimeInDateFormat\", [datetime(1899,12,30,1) for k in range(7)])\n        ])\n\n        pth = os.path.join(self.dirpath, 'test_types_datetime' + self.ext)\n        dfs = read_excel(pth)\n        tm.assert_frame_equal(dfs, expected)\n\n\nclass XlrdTests(ReadingTestsBase):\n    \"\"\"\n    This is the base class for the xlrd tests, and 3 different file formats\n    are supported: xls, xlsx, xlsm\n    \"\"\"\n\n    def test_excel_read_buffer(self):\n\n        pth = os.path.join(self.dirpath, 'test1' + self.ext)\n        f = open(pth, 'rb')\n        xls = ExcelFile(f)\n        # it works\n        xls.parse('Sheet1', index_col=0, parse_dates=True)\n\n    def test_read_xlrd_Book(self):\n        _skip_if_no_xlwt()\n\n        import xlrd\n        df = self.frame\n        with ensure_clean('.xls') as pth:\n            df.to_excel(pth, \"SheetA\")\n            book = xlrd.open_workbook(pth)\n\n            with ExcelFile(book, engine=\"xlrd\") as xl:\n                result = xl.parse(\"SheetA\")\n                tm.assert_frame_equal(df, result)\n\n            result = read_excel(book, sheetname=\"SheetA\", engine=\"xlrd\")\n            tm.assert_frame_equal(df, result)\n\n    @tm.network\n    def test_read_from_http_url(self):\n        # TODO: remove this when merging into master\n        url = ('https://raw.github.com/davidovitch/pandas/master/'\n               'pandas/io/tests/data/test1' + self.ext)\n#        url = ('https://raw.github.com/pydata/pandas/master/'\n#               'pandas/io/tests/data/test' + self.ext)\n        url_table = read_excel(url)\n        dirpath = tm.get_data_path()\n        localtable = os.path.join(dirpath, 'test1' + self.ext)\n        local_table = read_excel(localtable)\n        tm.assert_frame_equal(url_table, local_table)\n\n    @slow\n    def test_read_from_file_url(self):\n\n        # FILE\n        if sys.version_info[:2] < (2, 6):\n            raise nose.SkipTest(\"file:// not supported with Python < 2.6\")\n        dirpath = tm.get_data_path()\n        localtable = os.path.join(dirpath, 'test1' + self.ext)\n        local_table = read_excel(localtable)\n\n        try:\n            url_table = read_excel('file://localhost/' + localtable)\n        except URLError:\n            # fails on some systems\n            import platform\n            raise nose.SkipTest(\"failing on %s\" %\n                                ' '.join(platform.uname()).strip())\n\n        tm.assert_frame_equal(url_table, local_table)\n\n    def test_reader_closes_file(self):\n\n        pth = os.path.join(self.dirpath, 'test1' + self.ext)\n        f = open(pth, 'rb')\n        with ExcelFile(f) as xlsx:\n            # parses okay\n            xlsx.parse('Sheet1', index_col=0)\n\n        self.assertTrue(f.closed)\n\n    def test_creating_and_reading_multiple_sheets(self):\n        # Test reading multiple sheets, from a runtime created excel file\n        # with multiple sheets.\n        # See PR #9450\n\n        _skip_if_no_xlwt()\n        _skip_if_no_openpyxl()\n\n        def tdf(sheetname):\n            d, i = [11,22,33], [1,2,3]\n            return DataFrame(d,i,columns=[sheetname])\n\n        sheets = ['AAA','BBB','CCC']\n\n        dfs = [tdf(s) for s in sheets]\n        dfs = dict(zip(sheets,dfs))\n\n        with ensure_clean(self.ext) as pth:\n            with ExcelWriter(pth) as ew:\n                for sheetname, df in compat.iteritems(dfs):\n                    df.to_excel(ew,sheetname)\n            dfs_returned = pd.read_excel(pth,sheetname=sheets)\n            for s in sheets:\n                tm.assert_frame_equal(dfs[s],dfs_returned[s])\n\n    def test_reader_seconds(self):\n        # Test reading times with and without milliseconds. GH5945.\n        import xlrd\n\n        if LooseVersion(xlrd.__VERSION__) >= LooseVersion(\"0.9.3\"):\n            # Xlrd >= 0.9.3 can handle Excel milliseconds.\n            expected = DataFrame.from_items([(\"Time\",\n                                              [time(1, 2, 3),\n                                               time(2, 45, 56, 100000),\n                                               time(4, 29, 49, 200000),\n                                               time(6, 13, 42, 300000),\n                                               time(7, 57, 35, 400000),\n                                               time(9, 41, 28, 500000),\n                                               time(11, 25, 21, 600000),\n                                               time(13, 9, 14, 700000),\n                                               time(14, 53, 7, 800000),\n                                               time(16, 37, 0, 900000),\n                                               time(18, 20, 54)])])\n        else:\n            # Xlrd < 0.9.3 rounds Excel milliseconds.\n            expected = DataFrame.from_items([(\"Time\",\n                                              [time(1, 2, 3),\n                                               time(2, 45, 56),\n                                               time(4, 29, 49),\n                                               time(6, 13, 42),\n                                               time(7, 57, 35),\n                                               time(9, 41, 29),\n                                               time(11, 25, 22),\n                                               time(13, 9, 15),\n                                               time(14, 53, 8),\n                                               time(16, 37, 1),\n                                               time(18, 20, 54)])])\n\n        epoch_1900 = os.path.join(self.dirpath, 'times_1900' + self.ext)\n        epoch_1904 = os.path.join(self.dirpath, 'times_1904' + self.ext)\n\n        actual = read_excel(epoch_1900, 'Sheet1')\n        tm.assert_frame_equal(actual, expected)\n\n        actual = read_excel(epoch_1904, 'Sheet1')\n        tm.assert_frame_equal(actual, expected)\n\n    # GH6403\n    def test_read_excel_blank(self):\n        _skip_if_no_xlrd()\n\n        blank = os.path.join(self.dirpath, 'blank.xls')\n        actual = read_excel(blank, 'Sheet1')\n        tm.assert_frame_equal(actual, DataFrame())\n\n        blank = os.path.join(self.dirpath, 'blank.xlsx')\n        actual = read_excel(blank, 'Sheet1')\n        tm.assert_frame_equal(actual, DataFrame())\n\n    def test_read_excel_blank_with_header(self):\n        _skip_if_no_xlrd()\n\n        expected = DataFrame(columns=['col_1', 'col_2'])\n        blank = os.path.join(self.dirpath, 'blank_with_header.xls')\n        actual = read_excel(blank, 'Sheet1')\n        tm.assert_frame_equal(actual, expected)\n\n        blank = os.path.join(self.dirpath, 'blank_with_header.xlsx')\n        actual = read_excel(blank, 'Sheet1')\n        tm.assert_frame_equal(actual, expected)\n\nclass XlsReaderTests(XlrdTests, tm.TestCase):\n    ext = '.xls'\n    engine_name = 'xlrd'\n    check_skip = staticmethod(_skip_if_no_xlrd)\n\n\nclass XlsxReaderTests(XlrdTests, tm.TestCase):\n    ext = '.xlsx'\n    engine_name = 'xlrd'\n    check_skip = staticmethod(_skip_if_no_xlrd)\n\n\nclass XlsmReaderTests(XlrdTests, tm.TestCase):\n    ext = '.xlsm'\n    engine_name = 'xlrd'\n    check_skip = staticmethod(_skip_if_no_xlrd)\n\n\nclass ExcelWriterBase(SharedItems):\n    # Base class for test cases to run with different Excel writers.\n    # To add a writer test, define the following:\n    # 1. A check_skip function that skips your tests if your writer isn't\n    #    installed.\n    # 2. Add a property ext, which is the file extension that your writer\n    #    writes to. (needs to start with '.' so it's a valid path)\n    # 3. Add a property engine_name, which is the name of the writer class.\n\n    # Test with MultiIndex and Hierarchical Rows as merged cells.\n    merge_cells = True\n\n    def setUp(self):\n        self.check_skip()\n        super(ExcelWriterBase, self).setUp()\n        self.option_name = 'io.excel.%s.writer' % self.ext.strip('.')\n        self.prev_engine = get_option(self.option_name)\n        set_option(self.option_name, self.engine_name)\n\n    def tearDown(self):\n        set_option(self.option_name, self.prev_engine)\n\n    def test_excel_sheet_by_name_raise(self):\n        _skip_if_no_xlrd()\n        import xlrd\n\n        with ensure_clean(self.ext) as pth:\n            gt = DataFrame(np.random.randn(10, 2))\n            gt.to_excel(pth)\n            xl = ExcelFile(pth)\n            df = xl.parse(0)\n            tm.assert_frame_equal(gt, df)\n\n            self.assertRaises(xlrd.XLRDError, xl.parse, '0')\n\n    def test_excelwriter_contextmanager(self):\n        _skip_if_no_xlrd()\n\n        with ensure_clean(self.ext) as pth:\n            with ExcelWriter(pth) as writer:\n                self.frame.to_excel(writer, 'Data1')\n                self.frame2.to_excel(writer, 'Data2')\n\n            with ExcelFile(pth) as reader:\n                found_df = reader.parse('Data1')\n                found_df2 = reader.parse('Data2')\n                tm.assert_frame_equal(found_df, self.frame)\n                tm.assert_frame_equal(found_df2, self.frame2)\n\n    def test_roundtrip(self):\n        _skip_if_no_xlrd()\n\n        with ensure_clean(self.ext) as path:\n            self.frame['A'][:5] = nan\n\n            self.frame.to_excel(path, 'test1')\n            self.frame.to_excel(path, 'test1', columns=['A', 'B'])\n            self.frame.to_excel(path, 'test1', header=False)\n            self.frame.to_excel(path, 'test1', index=False)\n\n            # test roundtrip\n            self.frame.to_excel(path, 'test1')\n            recons = read_excel(path, 'test1', index_col=0)\n            tm.assert_frame_equal(self.frame, recons)\n\n            self.frame.to_excel(path, 'test1', index=False)\n            recons = read_excel(path, 'test1', index_col=None)\n            recons.index = self.frame.index\n            tm.assert_frame_equal(self.frame, recons)\n\n            self.frame.to_excel(path, 'test1', na_rep='NA')\n            recons = read_excel(path, 'test1', index_col=0, na_values=['NA'])\n            tm.assert_frame_equal(self.frame, recons)\n\n            # GH 3611\n            self.frame.to_excel(path, 'test1', na_rep='88')\n            recons = read_excel(path, 'test1', index_col=0, na_values=['88'])\n            tm.assert_frame_equal(self.frame, recons)\n\n            self.frame.to_excel(path, 'test1', na_rep='88')\n            recons = read_excel(path, 'test1', index_col=0,\n                                na_values=[88, 88.0])\n            tm.assert_frame_equal(self.frame, recons)\n\n            # GH 6573\n            self.frame.to_excel(path, 'Sheet1')\n            recons = read_excel(path, index_col=0)\n            tm.assert_frame_equal(self.frame, recons)\n\n            self.frame.to_excel(path, '0')\n            recons = read_excel(path, index_col=0)\n            tm.assert_frame_equal(self.frame, recons)\n\n    def test_mixed(self):\n        _skip_if_no_xlrd()\n\n        with ensure_clean(self.ext) as path:\n            self.mixed_frame.to_excel(path, 'test1')\n            reader = ExcelFile(path)\n            recons = reader.parse('test1', index_col=0)\n            tm.assert_frame_equal(self.mixed_frame, recons)\n\n    def test_tsframe(self):\n        _skip_if_no_xlrd()\n\n        df = tm.makeTimeDataFrame()[:5]\n\n        with ensure_clean(self.ext) as path:\n            df.to_excel(path, 'test1')\n            reader = ExcelFile(path)\n            recons = reader.parse('test1')\n            tm.assert_frame_equal(df, recons)\n\n    def test_basics_with_nan(self):\n        _skip_if_no_xlrd()\n        with ensure_clean(self.ext) as path:\n            self.frame['A'][:5] = nan\n            self.frame.to_excel(path, 'test1')\n            self.frame.to_excel(path, 'test1', columns=['A', 'B'])\n            self.frame.to_excel(path, 'test1', header=False)\n            self.frame.to_excel(path, 'test1', index=False)\n\n    def test_int_types(self):\n        _skip_if_no_xlrd()\n\n        for np_type in (np.int8, np.int16, np.int32, np.int64):\n\n            with ensure_clean(self.ext) as path:\n                # Test np.int values read come back as int (rather than float\n                # which is Excel's format).\n                frame = DataFrame(np.random.randint(-10, 10, size=(10, 2)),\n                                  dtype=np_type)\n                frame.to_excel(path, 'test1')\n                reader = ExcelFile(path)\n                recons = reader.parse('test1')\n                int_frame = frame.astype(np.int64)\n                tm.assert_frame_equal(int_frame, recons)\n                recons2 = read_excel(path, 'test1')\n                tm.assert_frame_equal(int_frame, recons2)\n\n                # test with convert_float=False comes back as float\n                float_frame = frame.astype(float)\n                recons = read_excel(path, 'test1', convert_float=False)\n                tm.assert_frame_equal(recons, float_frame)\n\n    def test_float_types(self):\n        _skip_if_no_xlrd()\n\n        for np_type in (np.float16, np.float32, np.float64):\n            with ensure_clean(self.ext) as path:\n                # Test np.float values read come back as float.\n                frame = DataFrame(np.random.random_sample(10), dtype=np_type)\n                frame.to_excel(path, 'test1')\n                reader = ExcelFile(path)\n                recons = reader.parse('test1').astype(np_type)\n                tm.assert_frame_equal(frame, recons, check_dtype=False)\n\n    def test_bool_types(self):\n        _skip_if_no_xlrd()\n\n        for np_type in (np.bool8, np.bool_):\n            with ensure_clean(self.ext) as path:\n                # Test np.bool values read come back as float.\n                frame = (DataFrame([1, 0, True, False], dtype=np_type))\n                frame.to_excel(path, 'test1')\n                reader = ExcelFile(path)\n                recons = reader.parse('test1').astype(np_type)\n                tm.assert_frame_equal(frame, recons)\n\n    def test_inf_roundtrip(self):\n        _skip_if_no_xlrd()\n\n        frame = DataFrame([(1, np.inf), (2, 3), (5, -np.inf)])\n        with ensure_clean(self.ext) as path:\n            frame.to_excel(path, 'test1')\n            reader = ExcelFile(path)\n            recons = reader.parse('test1')\n            tm.assert_frame_equal(frame, recons)\n\n    def test_sheets(self):\n        _skip_if_no_xlrd()\n\n        with ensure_clean(self.ext) as path:\n            self.frame['A'][:5] = nan\n\n            self.frame.to_excel(path, 'test1')\n            self.frame.to_excel(path, 'test1', columns=['A', 'B'])\n            self.frame.to_excel(path, 'test1', header=False)\n            self.frame.to_excel(path, 'test1', index=False)\n\n            # Test writing to separate sheets\n            writer = ExcelWriter(path)\n            self.frame.to_excel(writer, 'test1')\n            self.tsframe.to_excel(writer, 'test2')\n            writer.save()\n            reader = ExcelFile(path)\n            recons = reader.parse('test1', index_col=0)\n            tm.assert_frame_equal(self.frame, recons)\n            recons = reader.parse('test2', index_col=0)\n            tm.assert_frame_equal(self.tsframe, recons)\n            np.testing.assert_equal(2, len(reader.sheet_names))\n            np.testing.assert_equal('test1', reader.sheet_names[0])\n            np.testing.assert_equal('test2', reader.sheet_names[1])\n\n    def test_colaliases(self):\n        _skip_if_no_xlrd()\n\n        with ensure_clean(self.ext) as path:\n            self.frame['A'][:5] = nan\n\n            self.frame.to_excel(path, 'test1')\n            self.frame.to_excel(path, 'test1', columns=['A', 'B'])\n            self.frame.to_excel(path, 'test1', header=False)\n            self.frame.to_excel(path, 'test1', index=False)\n\n            # column aliases\n            col_aliases = Index(['AA', 'X', 'Y', 'Z'])\n            self.frame2.to_excel(path, 'test1', header=col_aliases)\n            reader = ExcelFile(path)\n            rs = reader.parse('test1', index_col=0)\n            xp = self.frame2.copy()\n            xp.columns = col_aliases\n            tm.assert_frame_equal(xp, rs)\n\n    def test_roundtrip_indexlabels(self):\n        _skip_if_no_xlrd()\n\n        with ensure_clean(self.ext) as path:\n\n            self.frame['A'][:5] = nan\n\n            self.frame.to_excel(path, 'test1')\n            self.frame.to_excel(path, 'test1', columns=['A', 'B'])\n            self.frame.to_excel(path, 'test1', header=False)\n            self.frame.to_excel(path, 'test1', index=False)\n\n            # test index_label\n            frame = (DataFrame(np.random.randn(10, 2)) >= 0)\n            frame.to_excel(path, 'test1',\n                           index_label=['test'],\n                           merge_cells=self.merge_cells)\n            reader = ExcelFile(path)\n            recons = reader.parse('test1',\n                                  index_col=0,\n                                  has_index_names=self.merge_cells\n                                  ).astype(np.int64)\n            frame.index.names = ['test']\n            self.assertEqual(frame.index.names, recons.index.names)\n\n            frame = (DataFrame(np.random.randn(10, 2)) >= 0)\n            frame.to_excel(path,\n                           'test1',\n                           index_label=['test', 'dummy', 'dummy2'],\n                           merge_cells=self.merge_cells)\n            reader = ExcelFile(path)\n            recons = reader.parse('test1',\n                                  index_col=0,\n                                  has_index_names=self.merge_cells\n                                  ).astype(np.int64)\n            frame.index.names = ['test']\n            self.assertEqual(frame.index.names, recons.index.names)\n\n            frame = (DataFrame(np.random.randn(10, 2)) >= 0)\n            frame.to_excel(path,\n                           'test1',\n                           index_label='test',\n                           merge_cells=self.merge_cells)\n            reader = ExcelFile(path)\n            recons = reader.parse('test1',\n                                  index_col=0,\n                                  has_index_names=self.merge_cells\n                                  ).astype(np.int64)\n            frame.index.names = ['test']\n            tm.assert_frame_equal(frame, recons.astype(bool))\n\n        with ensure_clean(self.ext) as path:\n\n            self.frame.to_excel(path,\n                                'test1',\n                                columns=['A', 'B', 'C', 'D'],\n                                index=False, merge_cells=self.merge_cells)\n            # take 'A' and 'B' as indexes (same row as cols 'C', 'D')\n            df = self.frame.copy()\n            df = df.set_index(['A', 'B'])\n\n            reader = ExcelFile(path)\n            recons = reader.parse('test1', index_col=[0, 1])\n            tm.assert_frame_equal(df, recons, check_less_precise=True)\n\n    def test_excel_roundtrip_indexname(self):\n        _skip_if_no_xlrd()\n\n        df = DataFrame(np.random.randn(10, 4))\n        df.index.name = 'foo'\n\n        with ensure_clean(self.ext) as path:\n            df.to_excel(path, merge_cells=self.merge_cells)\n\n            xf = ExcelFile(path)\n            result = xf.parse(xf.sheet_names[0],\n                              index_col=0,\n                              has_index_names=self.merge_cells)\n\n            tm.assert_frame_equal(result, df)\n            self.assertEqual(result.index.name, 'foo')\n\n    def test_excel_roundtrip_datetime(self):\n        _skip_if_no_xlrd()\n\n        # datetime.date, not sure what to test here exactly\n        tsf = self.tsframe.copy()\n        with ensure_clean(self.ext) as path:\n\n            tsf.index = [x.date() for x in self.tsframe.index]\n            tsf.to_excel(path, 'test1', merge_cells=self.merge_cells)\n            reader = ExcelFile(path)\n            recons = reader.parse('test1')\n            tm.assert_frame_equal(self.tsframe, recons)\n\n    # GH4133 - excel output format strings\n    def test_excel_date_datetime_format(self):\n        _skip_if_no_xlrd()\n        df = DataFrame([[date(2014, 1, 31),\n                         date(1999, 9, 24)],\n                        [datetime(1998, 5, 26, 23, 33, 4),\n                         datetime(2014, 2, 28, 13, 5, 13)]],\n                       index=['DATE', 'DATETIME'], columns=['X', 'Y'])\n        df_expected = DataFrame([[datetime(2014, 1, 31),\n                                  datetime(1999, 9, 24)],\n                                 [datetime(1998, 5, 26, 23, 33, 4),\n                                  datetime(2014, 2, 28, 13, 5, 13)]],\n                                index=['DATE', 'DATETIME'], columns=['X', 'Y'])\n\n        with ensure_clean(self.ext) as filename1:\n            with ensure_clean(self.ext) as filename2:\n                writer1 = ExcelWriter(filename1)\n                writer2 = ExcelWriter(filename2,\n                  date_format='DD.MM.YYYY',\n                  datetime_format='DD.MM.YYYY HH-MM-SS')\n\n                df.to_excel(writer1, 'test1')\n                df.to_excel(writer2, 'test1')\n\n                writer1.close()\n                writer2.close()\n\n                reader1 = ExcelFile(filename1)\n                reader2 = ExcelFile(filename2)\n\n                rs1 = reader1.parse('test1', index_col=None)\n                rs2 = reader2.parse('test1', index_col=None)\n\n                tm.assert_frame_equal(rs1, rs2)\n\n                # since the reader returns a datetime object for dates, we need\n                # to use df_expected to check the result\n                tm.assert_frame_equal(rs2, df_expected)\n\n    def test_to_excel_periodindex(self):\n        _skip_if_no_xlrd()\n\n        frame = self.tsframe\n        xp = frame.resample('M', kind='period')\n\n        with ensure_clean(self.ext) as path:\n            xp.to_excel(path, 'sht1')\n\n            reader = ExcelFile(path)\n            rs = reader.parse('sht1', index_col=0, parse_dates=True)\n            tm.assert_frame_equal(xp, rs.to_period('M'))\n\n    def test_to_excel_multiindex(self):\n        _skip_if_no_xlrd()\n\n        frame = self.frame\n        arrays = np.arange(len(frame.index) * 2).reshape(2, -1)\n        new_index = MultiIndex.from_arrays(arrays,\n                                           names=['first', 'second'])\n        frame.index = new_index\n\n        with ensure_clean(self.ext) as path:\n            frame.to_excel(path, 'test1', header=False)\n            frame.to_excel(path, 'test1', columns=['A', 'B'])\n\n            # round trip\n            frame.to_excel(path, 'test1', merge_cells=self.merge_cells)\n            reader = ExcelFile(path)\n            df = reader.parse('test1', index_col=[0, 1],\n                              parse_dates=False,\n                              has_index_names=self.merge_cells)\n            tm.assert_frame_equal(frame, df)\n            self.assertEqual(frame.index.names, df.index.names)\n\n    def test_to_excel_multiindex_dates(self):\n        _skip_if_no_xlrd()\n\n        # try multiindex with dates\n        tsframe = self.tsframe.copy()\n        new_index = [tsframe.index, np.arange(len(tsframe.index))]\n        tsframe.index = MultiIndex.from_arrays(new_index)\n\n        with ensure_clean(self.ext) as path:\n            tsframe.index.names = ['time', 'foo']\n            tsframe.to_excel(path, 'test1', merge_cells=self.merge_cells)\n            reader = ExcelFile(path)\n            recons = reader.parse('test1',\n                                  index_col=[0, 1],\n                                  has_index_names=self.merge_cells)\n\n            tm.assert_frame_equal(tsframe, recons)\n            self.assertEqual(recons.index.names, ('time', 'foo'))\n\n    def test_to_excel_multiindex_no_write_index(self):\n        _skip_if_no_xlrd()\n\n        # Test writing and re-reading a MI witout the index. GH 5616.\n\n        # Initial non-MI frame.\n        frame1 = pd.DataFrame({'a': [10, 20], 'b': [30, 40], 'c': [50, 60]})\n\n        # Add a MI.\n        frame2 = frame1.copy()\n        multi_index = pd.MultiIndex.from_tuples([(70, 80), (90, 100)])\n        frame2.index = multi_index\n\n        with ensure_clean(self.ext) as path:\n\n            # Write out to Excel without the index.\n            frame2.to_excel(path, 'test1', index=False)\n\n            # Read it back in.\n            reader = ExcelFile(path)\n            frame3 = reader.parse('test1')\n\n            # Test that it is the same as the initial frame.\n            tm.assert_frame_equal(frame1, frame3)\n\n    def test_to_excel_float_format(self):\n        _skip_if_no_xlrd()\n\n        df = DataFrame([[0.123456, 0.234567, 0.567567],\n                        [12.32112, 123123.2, 321321.2]],\n                        index=['A', 'B'], columns=['X', 'Y', 'Z'])\n\n        with ensure_clean(self.ext) as filename:\n            df.to_excel(filename, 'test1', float_format='%.2f')\n\n            reader = ExcelFile(filename)\n            rs = reader.parse('test1', index_col=None)\n            xp = DataFrame([[0.12, 0.23, 0.57],\n                            [12.32, 123123.20, 321321.20]],\n                            index=['A', 'B'], columns=['X', 'Y', 'Z'])\n            tm.assert_frame_equal(rs, xp)\n\n    def test_to_excel_output_encoding(self):\n        _skip_if_no_xlrd()\n        ext = self.ext\n        filename = '__tmp_to_excel_float_format__.' + ext\n        df = DataFrame([[u('\\u0192'), u('\\u0193'), u('\\u0194')],\n                        [u('\\u0195'), u('\\u0196'), u('\\u0197')]],\n                        index=[u('A\\u0192'), 'B'], columns=[u('X\\u0193'), 'Y', 'Z'])\n\n        with ensure_clean(filename) as filename:\n            df.to_excel(filename, sheet_name='TestSheet', encoding='utf8')\n            result = read_excel(filename, 'TestSheet', encoding='utf8')\n            tm.assert_frame_equal(result, df)\n\n    def test_to_excel_unicode_filename(self):\n        _skip_if_no_xlrd()\n        with ensure_clean(u('\\u0192u.') + self.ext) as filename:\n            try:\n                f = open(filename, 'wb')\n            except UnicodeEncodeError:\n                raise nose.SkipTest('no unicode file names on this system')\n            else:\n                f.close()\n\n            df = DataFrame([[0.123456, 0.234567, 0.567567],\n                            [12.32112, 123123.2, 321321.2]],\n                            index=['A', 'B'], columns=['X', 'Y', 'Z'])\n\n            df.to_excel(filename, 'test1', float_format='%.2f')\n\n            reader = ExcelFile(filename)\n            rs = reader.parse('test1', index_col=None)\n            xp = DataFrame([[0.12, 0.23, 0.57],\n                            [12.32, 123123.20, 321321.20]],\n                            index=['A', 'B'], columns=['X', 'Y', 'Z'])\n            tm.assert_frame_equal(rs, xp)\n\n    # def test_to_excel_header_styling_xls(self):\n\n    #     import StringIO\n    #     s = StringIO(\n    #     \"\"\"Date,ticker,type,value\n    #     2001-01-01,x,close,12.2\n    #     2001-01-01,x,open ,12.1\n    #     2001-01-01,y,close,12.2\n    #     2001-01-01,y,open ,12.1\n    #     2001-02-01,x,close,12.2\n    #     2001-02-01,x,open ,12.1\n    #     2001-02-01,y,close,12.2\n    #     2001-02-01,y,open ,12.1\n    #     2001-03-01,x,close,12.2\n    #     2001-03-01,x,open ,12.1\n    #     2001-03-01,y,close,12.2\n    #     2001-03-01,y,open ,12.1\"\"\")\n    #     df = read_csv(s, parse_dates=[\"Date\"])\n    #     pdf = df.pivot_table(values=\"value\", rows=[\"ticker\"],\n    #                                          cols=[\"Date\", \"type\"])\n\n    #     try:\n    #         import xlwt\n    #         import xlrd\n    #     except ImportError:\n    #         raise nose.SkipTest\n\n    #     filename = '__tmp_to_excel_header_styling_xls__.xls'\n    #     pdf.to_excel(filename, 'test1')\n\n    #     wbk = xlrd.open_workbook(filename,\n    #                              formatting_info=True)\n    #     self.assertEqual([\"test1\"], wbk.sheet_names())\n    #     ws = wbk.sheet_by_name('test1')\n    #     self.assertEqual([(0, 1, 5, 7), (0, 1, 3, 5), (0, 1, 1, 3)],\n    #                       ws.merged_cells)\n    #     for i in range(0, 2):\n    #         for j in range(0, 7):\n    #             xfx = ws.cell_xf_index(0, 0)\n    #             cell_xf = wbk.xf_list[xfx]\n    #             font = wbk.font_list\n    #             self.assertEqual(1, font[cell_xf.font_index].bold)\n    #             self.assertEqual(1, cell_xf.border.top_line_style)\n    #             self.assertEqual(1, cell_xf.border.right_line_style)\n    #             self.assertEqual(1, cell_xf.border.bottom_line_style)\n    #             self.assertEqual(1, cell_xf.border.left_line_style)\n    #             self.assertEqual(2, cell_xf.alignment.hor_align)\n    #     os.remove(filename)\n    # def test_to_excel_header_styling_xlsx(self):\n    #     import StringIO\n    #     s = StringIO(\n    #     \"\"\"Date,ticker,type,value\n    #     2001-01-01,x,close,12.2\n    #     2001-01-01,x,open ,12.1\n    #     2001-01-01,y,close,12.2\n    #     2001-01-01,y,open ,12.1\n    #     2001-02-01,x,close,12.2\n    #     2001-02-01,x,open ,12.1\n    #     2001-02-01,y,close,12.2\n    #     2001-02-01,y,open ,12.1\n    #     2001-03-01,x,close,12.2\n    #     2001-03-01,x,open ,12.1\n    #     2001-03-01,y,close,12.2\n    #     2001-03-01,y,open ,12.1\"\"\")\n    #     df = read_csv(s, parse_dates=[\"Date\"])\n    #     pdf = df.pivot_table(values=\"value\", rows=[\"ticker\"],\n    #                                          cols=[\"Date\", \"type\"])\n    #     try:\n    #         import openpyxl\n    #         from openpyxl.cell import get_column_letter\n    #     except ImportError:\n    #         raise nose.SkipTest\n    #     if openpyxl.__version__ < '1.6.1':\n    #         raise nose.SkipTest\n    #     # test xlsx_styling\n    #     filename = '__tmp_to_excel_header_styling_xlsx__.xlsx'\n    #     pdf.to_excel(filename, 'test1')\n    #     wbk = openpyxl.load_workbook(filename)\n    #     self.assertEqual([\"test1\"], wbk.get_sheet_names())\n    #     ws = wbk.get_sheet_by_name('test1')\n    #     xlsaddrs = [\"%s2\" % chr(i) for i in range(ord('A'), ord('H'))]\n    #     xlsaddrs += [\"A%s\" % i for i in range(1, 6)]\n    #     xlsaddrs += [\"B1\", \"D1\", \"F1\"]\n    #     for xlsaddr in xlsaddrs:\n    #         cell = ws.cell(xlsaddr)\n    #         self.assertTrue(cell.style.font.bold)\n    #         self.assertEqual(openpyxl.style.Border.BORDER_THIN,\n    #                           cell.style.borders.top.border_style)\n    #         self.assertEqual(openpyxl.style.Border.BORDER_THIN,\n    #                           cell.style.borders.right.border_style)\n    #         self.assertEqual(openpyxl.style.Border.BORDER_THIN,\n    #                           cell.style.borders.bottom.border_style)\n    #         self.assertEqual(openpyxl.style.Border.BORDER_THIN,\n    #                           cell.style.borders.left.border_style)\n    #         self.assertEqual(openpyxl.style.Alignment.HORIZONTAL_CENTER,\n    #                           cell.style.alignment.horizontal)\n    #     mergedcells_addrs = [\"C1\", \"E1\", \"G1\"]\n    #     for maddr in mergedcells_addrs:\n    #         self.assertTrue(ws.cell(maddr).merged)\n    #     os.remove(filename)\n\n    def test_excel_010_hemstring(self):\n        _skip_if_no_xlrd()\n\n        if self.merge_cells:\n            raise nose.SkipTest('Skip tests for merged MI format.')\n\n        from pandas.util.testing import makeCustomDataframe as mkdf\n        # ensure limited functionality in 0.10\n        # override of #2370 until sorted out in 0.11\n\n        def roundtrip(df, header=True, parser_hdr=0, index=True):\n\n            with ensure_clean(self.ext) as path:\n                df.to_excel(path, header=header, merge_cells=self.merge_cells, index=index)\n                xf = pd.ExcelFile(path)\n                res = xf.parse(xf.sheet_names[0], header=parser_hdr)\n                return res\n\n        nrows = 5\n        ncols = 3\n        for use_headers in (True, False):\n            for i in range(1, 4):  # row multindex upto nlevel=3\n                for j in range(1, 4):  # col \"\"\n                    df = mkdf(nrows, ncols, r_idx_nlevels=i, c_idx_nlevels=j)\n\n                    #this if will be removed once multi column excel writing\n                    #is implemented for now fixing #9794\n                    if j>1:\n                        with tm.assertRaises(NotImplementedError):\n                            res = roundtrip(df, use_headers, index=False)\n                    else:\n                        res = roundtrip(df, use_headers)\n\n                    if use_headers:\n                        self.assertEqual(res.shape, (nrows, ncols + i))\n                    else:\n                        # first row taken as columns\n                        self.assertEqual(res.shape, (nrows - 1, ncols + i))\n\n                    # no nans\n                    for r in range(len(res.index)):\n                        for c in range(len(res.columns)):\n                            self.assertTrue(res.ix[r, c] is not np.nan)\n\n        res = roundtrip(DataFrame([0]))\n        self.assertEqual(res.shape, (1, 1))\n        self.assertTrue(res.ix[0, 0] is not np.nan)\n\n        res = roundtrip(DataFrame([0]), False, None)\n        self.assertEqual(res.shape, (1, 2))\n        self.assertTrue(res.ix[0, 0] is not np.nan)\n\n    def test_excel_010_hemstring_raises_NotImplementedError(self):\n        # This test was failing only for j>1 and header=False,\n        # So I reproduced a simple test.\n        _skip_if_no_xlrd()\n\n        if self.merge_cells:\n            raise nose.SkipTest('Skip tests for merged MI format.')\n\n        from pandas.util.testing import makeCustomDataframe as mkdf\n        # ensure limited functionality in 0.10\n        # override of #2370 until sorted out in 0.11\n\n        def roundtrip2(df, header=True, parser_hdr=0, index=True):\n\n            with ensure_clean(self.ext) as path:\n                df.to_excel(path, header=header, merge_cells=self.merge_cells, index=index)\n                xf = pd.ExcelFile(path)\n                res = xf.parse(xf.sheet_names[0], header=parser_hdr)\n                return res\n\n        nrows = 5; ncols = 3\n        j = 2; i = 1\n        df = mkdf(nrows, ncols, r_idx_nlevels=i, c_idx_nlevels=j)\n        with tm.assertRaises(NotImplementedError):\n            res = roundtrip2(df, header=False, index=False)\n\n\n    def test_duplicated_columns(self):\n        # Test for issue #5235.\n        _skip_if_no_xlrd()\n\n        with ensure_clean(self.ext) as path:\n            write_frame = DataFrame([[1, 2, 3], [1, 2, 3], [1, 2, 3]])\n            colnames = ['A', 'B', 'B']\n\n            write_frame.columns = colnames\n            write_frame.to_excel(path, 'test1')\n\n            read_frame = read_excel(path, 'test1')\n            read_frame.columns = colnames\n\n            tm.assert_frame_equal(write_frame, read_frame)\n\n    def test_swapped_columns(self):\n        # Test for issue #5427.\n        _skip_if_no_xlrd()\n\n        with ensure_clean(self.ext) as path:\n            write_frame = DataFrame({'A': [1, 1, 1],\n                                     'B': [2, 2, 2]})\n            write_frame.to_excel(path, 'test1', columns=['B', 'A'])\n\n            read_frame = read_excel(path, 'test1', header=0)\n\n            tm.assert_series_equal(write_frame['A'], read_frame['A'])\n            tm.assert_series_equal(write_frame['B'], read_frame['B'])\n\n    def test_datetimes(self):\n\n        # Test writing and reading datetimes. For issue #9139. (xref #9185)\n        _skip_if_no_xlrd()\n\n        datetimes = [datetime(2013, 1, 13, 1, 2, 3),\n                     datetime(2013, 1, 13, 2, 45, 56),\n                     datetime(2013, 1, 13, 4, 29, 49),\n                     datetime(2013, 1, 13, 6, 13, 42),\n                     datetime(2013, 1, 13, 7, 57, 35),\n                     datetime(2013, 1, 13, 9, 41, 28),\n                     datetime(2013, 1, 13, 11, 25, 21),\n                     datetime(2013, 1, 13, 13, 9, 14),\n                     datetime(2013, 1, 13, 14, 53, 7),\n                     datetime(2013, 1, 13, 16, 37, 0),\n                     datetime(2013, 1, 13, 18, 20, 52)]\n\n        with ensure_clean(self.ext) as path:\n            write_frame = DataFrame.from_items([('A', datetimes)])\n            write_frame.to_excel(path, 'Sheet1')\n            read_frame = read_excel(path, 'Sheet1', header=0)\n\n            tm.assert_series_equal(write_frame['A'], read_frame['A'])\n\n    # GH7074\n    def test_bytes_io(self):\n        _skip_if_no_xlrd()\n\n        bio = BytesIO()\n        df = DataFrame(np.random.randn(10, 2))\n        writer = ExcelWriter(bio)\n        df.to_excel(writer)\n        writer.save()\n        bio.seek(0)\n        reread_df = pd.read_excel(bio)\n        tm.assert_frame_equal(df, reread_df)\n\n    # GH8188\n    def test_write_lists_dict(self):\n        _skip_if_no_xlrd()\n\n        df = pd.DataFrame({'mixed': ['a', ['b', 'c'], {'d': 'e', 'f': 2}],\n                           'numeric': [1, 2, 3.0],\n                           'str': ['apple', 'banana', 'cherry']})\n        expected = df.copy()\n        expected.mixed = expected.mixed.apply(str)\n        expected.numeric = expected.numeric.astype('int64')\n        with ensure_clean(self.ext) as path:\n            df.to_excel(path, 'Sheet1')\n            read = read_excel(path, 'Sheet1', header=0)\n            tm.assert_frame_equal(read, expected)\n\n\ndef raise_wrapper(major_ver):\n    def versioned_raise_wrapper(orig_method):\n        @functools.wraps(orig_method)\n        def wrapped(self, *args, **kwargs):\n            _skip_if_no_openpyxl()\n            if openpyxl_compat.is_compat(major_ver=major_ver):\n                orig_method(self, *args, **kwargs)\n            else:\n                msg = 'Installed openpyxl is not supported at this time\\. Use.+'\n                with tm.assertRaisesRegexp(ValueError, msg):\n                    orig_method(self, *args, **kwargs)\n        return wrapped\n    return versioned_raise_wrapper\n\n\ndef raise_on_incompat_version(major_ver):\n    def versioned_raise_on_incompat_version(cls):\n        methods = filter(operator.methodcaller('startswith', 'test_'), dir(cls))\n        for method in methods:\n            setattr(cls, method, raise_wrapper(major_ver)(getattr(cls, method)))\n        return cls\n    return versioned_raise_on_incompat_version\n\n\n@raise_on_incompat_version(1)\nclass OpenpyxlTests(ExcelWriterBase, tm.TestCase):\n    ext = '.xlsx'\n    engine_name = 'openpyxl1'\n    check_skip = staticmethod(lambda *args, **kwargs: None)\n\n    def test_to_excel_styleconverter(self):\n        _skip_if_no_openpyxl()\n        if not openpyxl_compat.is_compat(major_ver=1):\n            raise nose.SkipTest('incompatiable openpyxl version')\n\n        import openpyxl\n\n        hstyle = {\"font\": {\"bold\": True},\n                  \"borders\": {\"top\": \"thin\",\n                              \"right\": \"thin\",\n                              \"bottom\": \"thin\",\n                              \"left\": \"thin\"},\n                  \"alignment\": {\"horizontal\": \"center\", \"vertical\": \"top\"}}\n\n        xlsx_style = _Openpyxl1Writer._convert_to_style(hstyle)\n        self.assertTrue(xlsx_style.font.bold)\n        self.assertEqual(openpyxl.style.Border.BORDER_THIN,\n                         xlsx_style.borders.top.border_style)\n        self.assertEqual(openpyxl.style.Border.BORDER_THIN,\n                         xlsx_style.borders.right.border_style)\n        self.assertEqual(openpyxl.style.Border.BORDER_THIN,\n                         xlsx_style.borders.bottom.border_style)\n        self.assertEqual(openpyxl.style.Border.BORDER_THIN,\n                         xlsx_style.borders.left.border_style)\n        self.assertEqual(openpyxl.style.Alignment.HORIZONTAL_CENTER,\n                         xlsx_style.alignment.horizontal)\n        self.assertEqual(openpyxl.style.Alignment.VERTICAL_TOP,\n                         xlsx_style.alignment.vertical)\n\n\n@raise_on_incompat_version(2)\nclass Openpyxl2Tests(ExcelWriterBase, tm.TestCase):\n    ext = '.xlsx'\n    engine_name = 'openpyxl2'\n    check_skip = staticmethod(lambda *args, **kwargs: None)\n\n    def test_to_excel_styleconverter(self):\n        _skip_if_no_openpyxl()\n        if not openpyxl_compat.is_compat(major_ver=2):\n            raise nose.SkipTest('incompatiable openpyxl version')\n\n        import openpyxl\n        from openpyxl import styles\n\n        hstyle = {\n            \"font\": {\n                \"color\": '00FF0000',\n                \"bold\": True,\n            },\n            \"borders\": {\n                \"top\": \"thin\",\n                \"right\": \"thin\",\n                \"bottom\": \"thin\",\n                \"left\": \"thin\",\n            },\n            \"alignment\": {\n                \"horizontal\": \"center\",\n                \"vertical\": \"top\",\n            },\n            \"fill\": {\n                \"patternType\": 'solid',\n                'fgColor': {\n                    'rgb': '006666FF',\n                    'tint': 0.3,\n                },\n            },\n            \"number_format\": {\n                \"format_code\": \"0.00\"\n            },\n            \"protection\": {\n                \"locked\": True,\n                \"hidden\": False,\n            },\n        }\n\n        font_color = styles.Color('00FF0000')\n        font = styles.Font(bold=True, color=font_color)\n        side = styles.Side(style=styles.borders.BORDER_THIN)\n        border = styles.Border(top=side, right=side, bottom=side, left=side)\n        alignment = styles.Alignment(horizontal='center', vertical='top')\n        fill_color = styles.Color(rgb='006666FF', tint=0.3)\n        fill = styles.PatternFill(patternType='solid', fgColor=fill_color)\n\n        # ahh openpyxl API changes\n        ver = openpyxl.__version__\n        if ver >= LooseVersion('2.0.0') and ver < LooseVersion('2.1.0'):\n            number_format = styles.NumberFormat(format_code='0.00')\n        else:\n            number_format = '0.00' # XXX: Only works with openpyxl-2.1.0\n\n        protection = styles.Protection(locked=True, hidden=False)\n\n        kw = _Openpyxl2Writer._convert_to_style_kwargs(hstyle)\n        self.assertEqual(kw['font'], font)\n        self.assertEqual(kw['border'], border)\n        self.assertEqual(kw['alignment'], alignment)\n        self.assertEqual(kw['fill'], fill)\n        self.assertEqual(kw['number_format'], number_format)\n        self.assertEqual(kw['protection'], protection)\n\n\n    def test_write_cells_merge_styled(self):\n        _skip_if_no_openpyxl()\n        if not openpyxl_compat.is_compat(major_ver=2):\n            raise nose.SkipTest('incompatiable openpyxl version')\n\n        from pandas.core.format import ExcelCell\n        from openpyxl import styles\n\n        sheet_name='merge_styled'\n\n        sty_b1 = {'font': {'color': '00FF0000'}}\n        sty_a2 = {'font': {'color': '0000FF00'}}\n\n        initial_cells = [\n            ExcelCell(col=1, row=0, val=42, style=sty_b1),\n            ExcelCell(col=0, row=1, val=99, style=sty_a2),\n        ]\n\n        sty_merged = {'font': { 'color': '000000FF', 'bold': True }}\n        sty_kwargs = _Openpyxl2Writer._convert_to_style_kwargs(sty_merged)\n        openpyxl_sty_merged = styles.Style(**sty_kwargs)\n        merge_cells = [\n            ExcelCell(col=0, row=0, val='pandas',\n                    mergestart=1, mergeend=1, style=sty_merged),\n        ]\n\n        with ensure_clean('.xlsx') as path:\n            writer = _Openpyxl2Writer(path)\n            writer.write_cells(initial_cells, sheet_name=sheet_name)\n            writer.write_cells(merge_cells, sheet_name=sheet_name)\n\n            wks = writer.sheets[sheet_name]\n            xcell_b1 = wks.cell('B1')\n            xcell_a2 = wks.cell('A2')\n            self.assertEqual(xcell_b1.style, openpyxl_sty_merged)\n            self.assertEqual(xcell_a2.style, openpyxl_sty_merged)\n\n\nclass XlwtTests(ExcelWriterBase, tm.TestCase):\n    ext = '.xls'\n    engine_name = 'xlwt'\n    check_skip = staticmethod(_skip_if_no_xlwt)\n\n    def test_excel_raise_error_on_multiindex_columns_and_no_index(self):\n        _skip_if_no_xlwt()\n        # MultiIndex as columns is not yet implemented 9794\n        cols = pd.MultiIndex.from_tuples([('site', ''),\n                                          ('2014', 'height'),\n                                          ('2014', 'weight')])\n        df = pd.DataFrame(np.random.randn(10, 3), columns=cols)\n        with tm.assertRaises(NotImplementedError):\n            with ensure_clean(self.ext) as path:\n                df.to_excel(path, index=False)\n\n    def test_excel_warns_verbosely_on_multiindex_columns_and_index_true(self):\n        _skip_if_no_xlwt()\n        cols = pd.MultiIndex.from_tuples([('site', ''),\n                                          ('2014', 'height'),\n                                          ('2014', 'weight')])\n        df = pd.DataFrame(np.random.randn(10, 3), columns=cols)\n        with tm.assert_produces_warning(UserWarning):\n            with ensure_clean(self.ext) as path:\n                df.to_excel(path, index=True)\n\n    def test_excel_multiindex_index(self):\n        _skip_if_no_xlwt()\n        # MultiIndex as index works so assert no error #9794\n        cols = pd.MultiIndex.from_tuples([('site', ''),\n                                          ('2014', 'height'),\n                                          ('2014', 'weight')])\n        df = pd.DataFrame(np.random.randn(3, 10), index=cols)\n        with ensure_clean(self.ext) as path:\n            df.to_excel(path, index=False)\n\n    def test_to_excel_styleconverter(self):\n        _skip_if_no_xlwt()\n\n        import xlwt\n\n        hstyle = {\"font\": {\"bold\": True},\n                  \"borders\": {\"top\": \"thin\",\n                              \"right\": \"thin\",\n                              \"bottom\": \"thin\",\n                              \"left\": \"thin\"},\n                  \"alignment\": {\"horizontal\": \"center\", \"vertical\": \"top\"}}\n\n        xls_style = _XlwtWriter._convert_to_style(hstyle)\n        self.assertTrue(xls_style.font.bold)\n        self.assertEqual(xlwt.Borders.THIN, xls_style.borders.top)\n        self.assertEqual(xlwt.Borders.THIN, xls_style.borders.right)\n        self.assertEqual(xlwt.Borders.THIN, xls_style.borders.bottom)\n        self.assertEqual(xlwt.Borders.THIN, xls_style.borders.left)\n        self.assertEqual(xlwt.Alignment.HORZ_CENTER, xls_style.alignment.horz)\n        self.assertEqual(xlwt.Alignment.VERT_TOP, xls_style.alignment.vert)\n\n\nclass XlsxWriterTests(ExcelWriterBase, tm.TestCase):\n    ext = '.xlsx'\n    engine_name = 'xlsxwriter'\n    check_skip = staticmethod(_skip_if_no_xlsxwriter)\n\n    def test_column_format(self):\n        # Test that column formats are applied to cells. Test for issue #9167.\n        # Applicable to xlsxwriter only.\n        _skip_if_no_xlsxwriter()\n\n        import warnings\n        with warnings.catch_warnings():\n            # Ignore the openpyxl lxml warning.\n            warnings.simplefilter(\"ignore\")\n            _skip_if_no_openpyxl()\n            import openpyxl\n\n        with ensure_clean(self.ext) as path:\n            frame = DataFrame({'A': [123456, 123456],\n                               'B': [123456, 123456]})\n\n            writer = ExcelWriter(path)\n            frame.to_excel(writer)\n\n            # Add a number format to col B and ensure it is applied to cells.\n            num_format = '#,##0'\n            write_workbook = writer.book\n            write_worksheet = write_workbook.worksheets()[0]\n            col_format = write_workbook.add_format({'num_format': num_format})\n            write_worksheet.set_column('B:B', None, col_format)\n            writer.save()\n\n            read_workbook = openpyxl.load_workbook(path)\n            read_worksheet = read_workbook.get_sheet_by_name(name='Sheet1')\n\n            # Get the number format from the cell. This method is backward\n            # compatible with older versions of openpyxl.\n            cell = read_worksheet.cell('B2')\n\n            try:\n                read_num_format = cell.style.number_format._format_code\n            except:\n                read_num_format = cell.style.number_format\n\n            self.assertEqual(read_num_format, num_format)\n\n\nclass OpenpyxlTests_NoMerge(ExcelWriterBase, tm.TestCase):\n    ext = '.xlsx'\n    engine_name = 'openpyxl'\n    check_skip = staticmethod(_skip_if_no_openpyxl)\n\n    # Test < 0.13 non-merge behaviour for MultiIndex and Hierarchical Rows.\n    merge_cells = False\n\n\nclass XlwtTests_NoMerge(ExcelWriterBase, tm.TestCase):\n    ext = '.xls'\n    engine_name = 'xlwt'\n    check_skip = staticmethod(_skip_if_no_xlwt)\n\n    # Test < 0.13 non-merge behaviour for MultiIndex and Hierarchical Rows.\n    merge_cells = False\n\n\nclass XlsxWriterTests_NoMerge(ExcelWriterBase, tm.TestCase):\n    ext = '.xlsx'\n    engine_name = 'xlsxwriter'\n    check_skip = staticmethod(_skip_if_no_xlsxwriter)\n\n    # Test < 0.13 non-merge behaviour for MultiIndex and Hierarchical Rows.\n    merge_cells = False\n\n\nclass ExcelWriterEngineTests(tm.TestCase):\n\n    def test_ExcelWriter_dispatch(self):\n        with tm.assertRaisesRegexp(ValueError, 'No engine'):\n            ExcelWriter('nothing')\n\n        try:\n            import xlsxwriter\n            writer_klass = _XlsxWriter\n        except ImportError:\n            _skip_if_no_openpyxl()\n            if not openpyxl_compat.is_compat(major_ver=1):\n                raise nose.SkipTest('incompatible openpyxl version')\n            writer_klass = _Openpyxl1Writer\n\n        with ensure_clean('.xlsx') as path:\n            writer = ExcelWriter(path)\n            tm.assertIsInstance(writer, writer_klass)\n\n        _skip_if_no_xlwt()\n        with ensure_clean('.xls') as path:\n            writer = ExcelWriter(path)\n            tm.assertIsInstance(writer, _XlwtWriter)\n\n    def test_register_writer(self):\n        # some awkward mocking to test out dispatch and such actually works\n        called_save = []\n        called_write_cells = []\n\n        class DummyClass(ExcelWriter):\n            called_save = False\n            called_write_cells = False\n            supported_extensions = ['test', 'xlsx', 'xls']\n            engine = 'dummy'\n\n            def save(self):\n                called_save.append(True)\n\n            def write_cells(self, *args, **kwargs):\n                called_write_cells.append(True)\n\n        def check_called(func):\n            func()\n            self.assertTrue(len(called_save) >= 1)\n            self.assertTrue(len(called_write_cells) >= 1)\n            del called_save[:]\n            del called_write_cells[:]\n\n        register_writer(DummyClass)\n        writer = ExcelWriter('something.test')\n        tm.assertIsInstance(writer, DummyClass)\n        df = tm.makeCustomDataframe(1, 1)\n        panel = tm.makePanel()\n        func = lambda: df.to_excel('something.test')\n        check_called(func)\n        check_called(lambda: panel.to_excel('something.test'))\n        val = get_option('io.excel.xlsx.writer')\n        set_option('io.excel.xlsx.writer', 'dummy')\n        check_called(lambda: df.to_excel('something.xlsx'))\n        check_called(lambda: df.to_excel('something.xls', engine='dummy'))\n        set_option('io.excel.xlsx.writer', val)\n\n\nif __name__ == '__main__':\n    nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],\n                   exit=False)\n"
    }
  ],
  "questions": [
    "It seems to me the best option for this would be:\n- Start with a simple test case for input and output, and handle that using this library: http://simple-odspy.sourceforge.net/ -- sample code: http://simple-odspy.sourceforge.net/?q=node/5\n- If there are more complex cases where simple-odspy is not enough, one can use the more heavyweight http://pypi.python.org/pypi/odfpy library\n\nThis would be a rather substantial bit of work.\n\nA good start for the test cases would be to look at pandas/io/tests/test_excel.py and write test cases that mirror what is in that file.",
    "I would like to give an update on the current status. My [fork](https://github.com/davidovitch/pandas) can currently read ODF ODS files, but writing is not implemented yet. The corresponding pull request is still pending review, and it has been a lot more work than I originally anticipated.\n\nJust a few days ago I bumped into yet another library to read/write spreadsheet: [pyexcel](https://github.com/chfw/pyexcel). What is different about this library is that it aims at creating a single API for all the different read/write libraries, and it builds on all the existing libraries out there (ezodf, xlrd, etc). This is actually kind of similar to what pandas currently has, and to what I am trying to extend in PR #9070. So I am wondering, would it make sense to use a single API library (with optional dependencies to all the relevant readers/writers for the different spreadsheet types) instead of developing something similar, but tailored to pandas use case? I am speculating that a lot of code in io/excel.py could be removed when relying on pyexcel, but it adds yet another dependency. At this stage I am not sure how all different edge cases on data types and other magic happening inside the spreadsheet interpretation differs between the current pandas implementation and pyexcel.",
    "I have a standalone reader styled like pandas.io.excel with tests.\r\nhttps://github.com/detrout/pandasodf\r\n\r\nIt uses odfpy as that seems like its still maintained. Any comments, or should I try reformatting into a pull request creating  pandas/io/odf.py?\r\n\r\nI thought the .read_odf method seemed more reasonable, than overloading .read_excel",
    "> I thought the .read_odf method seemed more reasonable, than overloading .read_excel \r\n\r\nMakes sense. Perhaps there could be a `read_spreadsheet` that calls `read_csv`, `read_excel`, `read_odf` etc, depending on the extension?"
  ],
  "golden_answers": [
    "@H0R5E for now, you could just convert the resulting excel file to ODS (it's pretty much a simple set of numbers, nothing more): http://stackoverflow.com/questions/15257032/python-convert-excel-file-xls-or-xlsx-to-from-ods or you could use json as an intermediary and use `tablib` to export to ODS: https://pypi.python.org/pypi/tablib",
    "The ods reader is not ready for the upcoming 0.17 release. PR #9070 is closed (see the PR for a technical discussion), and a new improved PR will be made by someone at some point in the future. I have a working version in the [ezodf_reader](https://github.com/davidovitch/pandas/tree/ezodf_reader) branch of my pandas fork in case someone wants to have a look at it. Suggestions and improvements are welcome :-)",
    "> I thought the .read_odf method seemed more reasonable, than overloading .read_excel \r\n\r\nMakes sense. Perhaps there could be a `read_spreadsheet` that calls `read_csv`, `read_excel`, `read_odf` etc, depending on the extension?",
    "> I thought the .read_odf method seemed more reasonable, than overloading .read_excel\r\n\r\n@detrout FYI, maybe things have changed since, but at the time of PR #9070 there was a very clear decision by the pandas devs not to do that and to keep ```read_excel``` for both the Excel and Open Document Format families."
  ],
  "questions_generated": [
    "What is the primary wish expressed in this issue regarding the pandas library?",
    "What are the potential libraries mentioned for handling ODS files, and what are their characteristics?",
    "How does the existing pandas code structure support different Excel file formats?",
    "What is the suggested approach for implementing ODS support in pandas according to the discussion?",
    "What are the challenges mentioned in selecting the appropriate library for ODS support in pandas?",
    "What is the role of the 'register_writer' function in the pandas/io/excel.py file?",
    "How does ezodf facilitate the loading of an ODS spreadsheet into a pandas DataFrame?",
    "What is the significance of the 'get_writer' function in the context of Excel file handling in pandas?"
  ],
  "golden_answers_generated": [
    "The primary wish expressed in this issue is to add support for reading and writing Open Document Spreadsheet (ODS) files, in addition to the existing support for XLS and XLSX files.",
    "The potential libraries mentioned for handling ODS files are simple-odspy and odfpy. Simple-odspy is suggested for simple test cases, while odfpy, which is more heavyweight, can be used for more complex cases. Additionally, ezodf is mentioned as a library that is still under development and does not depend on odfpy.",
    "The existing pandas code structure supports different Excel file formats through the use of writer and reader registries. Functions like 'register_writer' are used to register new engines and integrate them with pandas' 'to_excel' functionality. The code maintains lists of supported writer and reader extensions to manage different file formats.",
    "The suggested approach for implementing ODS support in pandas is to start with a simple test case using the simple-odspy library and, if needed, use the more complex odfpy library for more advanced functionality. Test cases should be created mirroring those in pandas/io/tests/test_excel.py.",
    "The challenges mentioned include the plethora of available libraries for handling ODS files and the uncertainty about which library is the 'best' one, particularly in terms of licensing compatibility with pandas.",
    "The 'register_writer' function is responsible for adding an engine to the Excel writer registry. It ensures that any new supported extensions defined on the writer are properly integrated with pandas' 'to_excel' functionality and adds corresponding configuration options.",
    "Ezodf facilitates the loading of an ODS spreadsheet into a pandas DataFrame by opening the ODS document, iterating over sheets to find the desired data, and then constructing a dictionary from the columns and rows of the sheet. This dictionary is then converted into a DataFrame.",
    "The 'get_writer' function is significant as it retrieves the appropriate writer engine for a given engine name. It ensures compatibility with different versions of external libraries, such as openpyxl, to handle specific Excel file formats within pandas."
  ]
}